{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": false,
    "_uuid": "e1baa7518f18a7ff1f2767df1b29c051955502ff"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow_addons as tfa\n",
    "from os import listdir, makedirs\n",
    "from os.path import isfile, join, basename, splitext, isfile, exists\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.metrics import top_k_categorical_accuracy, CategoricalHinge, Recall, Precision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "# from tensorflow.keras import metrics\n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.compat.v2.keras.layers import Input\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import random, os, sys\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.initializers import *\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.layers import Layer\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "tf.compat.v1.disable_eager_execution\n",
    "pd.set_option('precision', 30)\n",
    "np.set_printoptions(precision = 30)\n",
    "\n",
    "\n",
    "#np.random.seed(368)\n",
    "#tf.random.set_seed(368)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Size : <TensorSliceDataset shapes: (((4,), (5,)), (3,)), types: ((tf.float64, tf.float64), tf.int32)>\n",
      "Total Filtered Size : <TensorSliceDataset shapes: (((4,), (5,)), (3,)), types: ((tf.float64, tf.float64), tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "xfile='C:\\\\workspace\\\\j6stock\\\\xau_usd_OHLC2.0Tp1.0Cl100Vp.txt'\n",
    "\n",
    "seq_len = 60*6 #60*10 # 3 days + 2 features is enough memory\n",
    "batch_size = int(2048/3)       # Batch size\n",
    "# mini_batch_size = 64       # Batch size\n",
    "\n",
    "learning_rate = 0.001  #0.0001  # Learning rate (default is 0.001)\n",
    "epochs = 500\n",
    "dropout_rate= 0.5\n",
    "\n",
    "y_column = 6\n",
    "compute_val_at = 0\n",
    "acc_filtered_r = 0.8\n",
    "\n",
    "\n",
    "upperTailFilter = 0.4\n",
    "lowerTailFilter = 0.4\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import debug as tf_debug\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt2\n",
    "import pandas as pd\n",
    "from pandas import datetime\n",
    "import math, time\n",
    "import itertools\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers.core import Dense, Dropout, Activation\n",
    "#from keras.layers.recurrent import LSTM\n",
    "#from keras.models import load_model\n",
    "#import keras\n",
    "import pandas as pd ## can be remove once pandas_datareader 0.7 using\n",
    "pd.core.common.is_list_like = pd.api.types.is_list_like ## can be remove once pandas_datareader 0.7 using\n",
    "import pandas_datareader.data as web\n",
    "\n",
    "\n",
    "\n",
    "def get_stock_data(normalize=True, ma=[]):\n",
    "    \"\"\"\n",
    "    Return a dataframe of that stock and normalize all the values. \n",
    "    (Optional: create moving average)\n",
    "    \"\"\"\n",
    "    global upperTailFilter, lowerTailFilter\n",
    "    \n",
    "    df = pd.read_csv(filepath_or_buffer  = xfile )\n",
    "    #TODO Use previous close instead of open\n",
    "    df['change'] = df['close'] - df['open']\n",
    "    df['tail_upper'] = df['high'].copy()\n",
    "    df['tail_lower'] = df['low'].copy()\n",
    "    for i, row in df.iterrows():\n",
    "        df.at[i, 'tail_upper'] = df.at[i, 'high'] - (df.at[i, 'open'] if df.at[i, 'open'] > df.at[i, 'close'] else df.at[i, 'close'])\n",
    "        df.at[i, 'tail_lower'] = (df.at[i, 'close'] if df.at[i, 'close'] < df.at[i, 'open'] else df.at[i, 'open']) - df.at[i, 'low']\n",
    "    \n",
    "    df.dropna(inplace=True)\n",
    "    df.drop('open', axis=1, inplace=True)\n",
    "    df.drop('high', axis=1, inplace=True)\n",
    "    df.drop('low', axis=1, inplace=True)\n",
    "    # Moving Average    \n",
    "    if ma != []:\n",
    "        for moving in ma:\n",
    "            df['{}ma'.format(moving)] = df['close'].rolling(window=moving).mean() \n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    if normalize:\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        #df['open'] = min_max_scaler.fit_transform(df.open.values.reshape(-1,1))\n",
    "        #df['high'] = min_max_scaler.fit_transform(df.high.values.reshape(-1,1))\n",
    "        #df['low'] = min_max_scaler.fit_transform(df.low.values.reshape(-1,1))\n",
    "        #df['vol'] = min_max_scaler.fit_transform(df.vol.values.reshape(-1,1))\n",
    "        df['close'] = min_max_scaler.fit_transform(df['close'].values.reshape(-1,1))\n",
    "#         df['change'] = min_max_scaler.fit_transform(df['change'].values.reshape(-1,1)) # no rescale for keep the negative value\n",
    "        df['tail_upper'] = min_max_scaler.fit_transform(df['tail_upper'].values.reshape(-1,1))\n",
    "        upperTailFilter = min_max_scaler.transform([[upperTailFilter]])[0][0] \n",
    "        df['tail_lower'] = min_max_scaler.fit_transform(df['tail_lower'].values.reshape(-1,1))\n",
    "        lowerTailFilter = min_max_scaler.transform([[lowerTailFilter]])[0][0] \n",
    "        \n",
    "        if ma != []:\n",
    "            for moving in ma:\n",
    "                df['{}ma'.format(moving)] = min_max_scaler.fit_transform(df['{}ma'.format(moving)].values.reshape(-1,1))   \n",
    "                #pd.concat([min_max_scaler.fit_transform(df['{}ma'.format(moving)].values.reshape(-1,1)), df], axis=1)\n",
    "                ma_data = df['{}ma'.format(moving)]\n",
    "                df.drop(labels=['{}ma'.format(moving)], axis=1, inplace=True)\n",
    "                df = pd.concat([ma_data, df], axis=1)\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    \n",
    "    # Move y_result to the rightmost for the ease of training\n",
    "    adj_close = df['y_result']\n",
    "    df.drop(labels=['y_result'], axis=1, inplace=True)\n",
    "    df = pd.concat([df, adj_close], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "#df = get_stock_data( ma=[50, 100, 200])\n",
    "df = get_stock_data(ma=[5, 60, 240])\n",
    "\n",
    "# amount_of_features = len(df.columns)-1+(input2Length*-1)\n",
    "\n",
    "# def load_data(stock, seq_len):\n",
    "#     print (\"Amount of features = {}\".format(amount_of_features))\n",
    "#     data = stock.as_matrix()\n",
    "#     sequence_length = seq_len + 1 # index starting from 0\n",
    "#     x_result = []\n",
    "#     x_result2 = []\n",
    "#     y_result = []\n",
    "#     for index in range(seq_len, len(data) ): # maxmimum date = lastest date - sequence length\n",
    "#         x_result.append(data[index-seq_len: index,\n",
    "#                              :-1 + (input2Length*-1) # -2 is ignore Input2 features\n",
    "#                             ]) # index : index + 22days\n",
    "#         x_result2.append(data[index, -1 + (input2Length*-1):-1])\n",
    "#         y_result.append(data[index ,-1]);\n",
    "\n",
    "#     x_result, x_result2, y_result = shuffle(x_result, x_result2, y_result , random_state=2)\n",
    "\n",
    "#     #print('---', data[0])\n",
    "#     #print('---', x_result[0])\n",
    "#     #print('---', y_result[0])\n",
    "#     x_result = np.array(x_result)\n",
    "#     x_result2 = np.array(x_result2)\n",
    "#     y_result = np.array(y_result)\n",
    "#     print (\"Amount of data = {}\".format(y_result.shape[0]))\n",
    "\n",
    "#     percentageSplit = 0.5 # 60% split\n",
    "#     row = round(percentageSplit * y_result.shape[0]) \n",
    "#     print (\"Split = {}\".format(row))\n",
    " \n",
    "#     X_train = x_result[:int(row), :] \n",
    "#     X_train2 = x_result2[:int(row), :] \n",
    "#     y_train = y_result[:int(row)] \n",
    "#     print (\"Amount of training data = {}\".format(y_train.shape[0]))\n",
    "#     X_test = x_result[int(row):, :]\n",
    "#     X_test2 = x_result2[int(row):, :]\n",
    "#     y_test = y_result[int(row):]\n",
    "#     # filter for 1 and -1 for validation only\n",
    "#     X_test = X_test[y_test[:]!=0,:]\n",
    "#     X_test2 = X_test2[y_test[:]!=0,:]\n",
    "#     y_test = y_test[y_test[:]!=0]\n",
    "    \n",
    "#     # split 50% again for test and validation set\n",
    "#     row = round(percentageSplit * y_test.shape[0]) \n",
    "#     X_val = X_test[int(row):, :]\n",
    "#     X_val2 = X_test2[int(row):, :]\n",
    "#     y_val = y_test[int(row):]\n",
    "#     print (\"Amount of validation data = {}\".format(y_val.shape[0]))\n",
    "#     X_test = X_test[:int(row), :]\n",
    "#     X_test2 = X_test2[:int(row), :]\n",
    "#     y_test = y_test[:int(row)]\n",
    "#     print (\"Amount of testing data = {}\".format(y_test.shape[0]))\n",
    "#     #print(result.shape[0], len(y_result), int(row), y_result[int(row):])\n",
    "#     #X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], amount_of_features-1))\n",
    "#     #X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], amount_of_features-1))    \n",
    "#     return [X_train, X_train2, y_train, X_test, X_test2, y_test, X_val, X_val2, y_val]\n",
    "\n",
    "\n",
    "\n",
    "classes = [1, 0, -1]\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(classes)\n",
    "lb.transform([-1, 0, 1])\n",
    "\n",
    "df_to_dataset = df[[ 'change', '5ma', '60ma', '240ma'\n",
    "                   ]].copy()\n",
    "df_to_dataset_input2 = df[[ 'tail_upper', 'tail_lower', 'change' ,'cross_360p_high', 'cross_1440p_high'\n",
    "                          ]].copy()\n",
    "\n",
    "amount_of_features = len(df_to_dataset.columns)\n",
    "input2Length = len(df_to_dataset_input2.columns)\n",
    "\n",
    "df.drop(labels=['close'], axis=1, inplace=True)\n",
    "df.drop(labels=['change'], axis=1, inplace=True)\n",
    "df.drop(labels=['tail_upper'], axis=1, inplace=True)\n",
    "df.drop(labels=['tail_lower'], axis=1, inplace=True)\n",
    "df.drop(labels=['cross_360p_high'], axis=1, inplace=True)\n",
    "df.drop(labels=['cross_1440p_high'], axis=1, inplace=True)\n",
    "\n",
    "df_to_dataset_y = lb.transform(df[['y_result']].copy())\n",
    "df.drop(labels=['y_result'], axis=1, inplace=True)\n",
    "\n",
    "train_data_no = int(len(df_to_dataset_y)/2)\n",
    "test_data_no = int(train_data_no/2)\n",
    "v_data_no = test_data_no\n",
    "\n",
    "train_x_1 = df_to_dataset.iloc[:train_data_no].values\n",
    "train_x_2 = df_to_dataset_input2.iloc[:train_data_no].values\n",
    "train_y = df_to_dataset_y[:train_data_no]                                                   \n",
    "\n",
    "test_x_1 = df_to_dataset.iloc[train_data_no:train_data_no+test_data_no].values\n",
    "test_x_2 = df_to_dataset_input2.iloc[train_data_no:train_data_no+test_data_no].values\n",
    "test_y = df_to_dataset_y[train_data_no:train_data_no+test_data_no]                                                   \n",
    "\n",
    "v_x_1 = df_to_dataset.iloc[train_data_no+test_data_no:].values\n",
    "v_x_2 = df_to_dataset_input2.iloc[train_data_no+test_data_no:].values\n",
    "v_y = df_to_dataset_y[train_data_no+test_data_no:]                                                   \n",
    "\n",
    "\n",
    "def make_window_dataset(ds, window_size=seq_len, shift=1, stride=1):\n",
    "  windows = ds.window(window_size, shift=shift, stride=stride)\n",
    "\n",
    "  def batch(sub):\n",
    "    ret = ()\n",
    "    for index in range(2):\n",
    "      ret = ret + ( sub[index].batch(window_size, drop_remainder=True), )\n",
    "    return ret\n",
    "  def sub_to_batch(sub, sub2): \n",
    "    return tf.data.Dataset.zip((batch(sub), (sub2.batch(window_size, drop_remainder=True))))\n",
    "  \n",
    "  windows = windows.flat_map(sub_to_batch)\n",
    "  windows = windows.map(lambda sub1, sub2: ((sub1[0], sub1[1][-1:][0]), (sub2[-1:][0] #, sub2[-1:][0]\n",
    "                                                                        )))\n",
    "  return windows\n",
    "\n",
    "def filter_fn(a, b):\n",
    "#   return a[1][0]>=upperTailFilter or a[1][1]>=lowerTailFilter or a[1][3]==1 or a[1][4]==1\n",
    "  return a[1][4]==1\n",
    "\n",
    "train_dataset_x = tf.data.Dataset.from_tensor_slices(((train_x_1, train_x_2),(train_y)))\n",
    "train_dataset = make_window_dataset(train_dataset_x).filter(filter_fn).cache().batch(batch_size, drop_remainder=True) \n",
    "\n",
    "test_dataset_x = tf.data.Dataset.from_tensor_slices(((test_x_1, test_x_2),(test_y)))\n",
    "test_dataset = make_window_dataset(test_dataset_x).filter(filter_fn).cache().batch(batch_size, drop_remainder=True)\n",
    "\n",
    "v_dataset_x = tf.data.Dataset.from_tensor_slices(((v_x_1, v_x_2),(v_y)))\n",
    "v_dataset = make_window_dataset(v_dataset_x).filter(filter_fn).cache().batch(batch_size, drop_remainder=True)\n",
    "\n",
    "\n",
    "print('Total Size : {}'.format(train_dataset_x))\n",
    "print('Total Filtered Size : {}'.format(v_dataset_x))\n",
    "\n",
    "\n",
    "# X_tr, X_tr2, lab_tr, X_test, X_test2, lab_test, X_vld, X_vld2, lab_vld = load_data(df, seq_len)\n",
    "# y_tr = lb.transform(lab_tr)\n",
    "# y_vld = lb.transform(lab_vld)\n",
    "# y_test = lb.transform(lab_test)\n",
    "\n",
    "\n",
    "# train_X = X_tr\n",
    "# train_X2 = X_tr2\n",
    "# train_y = y_tr\n",
    "# valid_X = X_vld\n",
    "# valid_X2 = X_vld2\n",
    "# valid_y = y_vld\n",
    "# test_X = X_test\n",
    "# test_X2 = X_test2\n",
    "# test_y = y_test\n",
    "\n",
    "# print(train_X.shape)\n",
    "# print(train_y[0])\n",
    "# print(train_y[1])\n",
    "# print(train_y[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/shujian/transformer-with-lstm\n",
    "\n",
    "try:\n",
    "    from dataloader import TokenList, pad_to_longest\n",
    "    # for transformer\n",
    "except: pass\n",
    "\n",
    "\n",
    "\n",
    "embed_size = 60\n",
    "\n",
    "class LayerNormalization(Layer):\n",
    "    def __init__(self, eps=1e-6, **kwargs):\n",
    "        self.eps = eps\n",
    "        super(LayerNormalization, self).__init__(**kwargs)\n",
    "    def build(self, input_shape):\n",
    "        self.gamma = self.add_weight(name='gamma', shape=input_shape[-1:],\n",
    "                                     initializer=Ones(), trainable=True)\n",
    "        self.beta = self.add_weight(name='beta', shape=input_shape[-1:],\n",
    "                                    initializer=Zeros(), trainable=True)\n",
    "        super(LayerNormalization, self).build(input_shape)\n",
    "    def call(self, x):\n",
    "        mean = K.mean(x, axis=-1, keepdims=True)\n",
    "        std = K.std(x, axis=-1, keepdims=True)\n",
    "        return self.gamma * (x - mean) / (std + self.eps) + self.beta\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "class ScaledDotProductAttention():\n",
    "    def __init__(self, d_model, attn_dropout=0.1):\n",
    "        self.temper = np.sqrt(d_model)\n",
    "        self.dropout = Dropout(attn_dropout)\n",
    "    def __call__(self, q, k, v, mask):\n",
    "        attn = Lambda(lambda x:K.batch_dot(x[0],x[1],axes=[2,2])/self.temper)([q, k])\n",
    "        if mask is not None:\n",
    "            mmask = Lambda(lambda x:(-1e+10)*(1-x))(mask)\n",
    "            attn = Add()([attn, mmask])\n",
    "        attn = Activation('softmax')(attn)\n",
    "        attn = self.dropout(attn)\n",
    "        output = Lambda(lambda x:K.batch_dot(x[0], x[1]))([attn, v])\n",
    "        return output, attn\n",
    "\n",
    "class MultiHeadAttention():\n",
    "    # mode 0 - big martixes, faster; mode 1 - more clear implementation\n",
    "    def __init__(self, n_head, d_model, d_k, d_v, dropout, mode=0, use_norm=True):\n",
    "        self.mode = mode\n",
    "        self.n_head = n_head\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        self.dropout = dropout\n",
    "        if mode == 0:\n",
    "            self.qs_layer = Dense(n_head*d_k, use_bias=False)\n",
    "            self.ks_layer = Dense(n_head*d_k, use_bias=False)\n",
    "            self.vs_layer = Dense(n_head*d_v, use_bias=False)\n",
    "        elif mode == 1:\n",
    "            self.qs_layers = []\n",
    "            self.ks_layers = []\n",
    "            self.vs_layers = []\n",
    "            for _ in range(n_head):\n",
    "                self.qs_layers.append(TimeDistributed(Dense(d_k, use_bias=False)))\n",
    "                self.ks_layers.append(TimeDistributed(Dense(d_k, use_bias=False)))\n",
    "                self.vs_layers.append(TimeDistributed(Dense(d_v, use_bias=False)))\n",
    "        self.attention = ScaledDotProductAttention(d_model)\n",
    "        self.layer_norm = LayerNormalization() if use_norm else None\n",
    "        self.w_o = TimeDistributed(Dense(d_model))\n",
    "\n",
    "    def __call__(self, q, k, v, mask=None):\n",
    "        d_k, d_v = self.d_k, self.d_v\n",
    "        n_head = self.n_head\n",
    "\n",
    "        if self.mode == 0:\n",
    "            qs = self.qs_layer(q)  # [batch_size, len_q, n_head*d_k]\n",
    "            ks = self.ks_layer(k)\n",
    "            vs = self.vs_layer(v)\n",
    "\n",
    "            def reshape1(x):\n",
    "                s = tf.shape(x)   # [batch_size, len_q, n_head * d_k]\n",
    "                x = tf.reshape(x, [s[0], s[1], n_head, d_k])\n",
    "                x = tf.transpose(x, [2, 0, 1, 3])  \n",
    "                x = tf.reshape(x, [-1, s[1], d_k])  # [n_head * batch_size, len_q, d_k]\n",
    "                return x\n",
    "            qs = Lambda(reshape1)(qs)\n",
    "            ks = Lambda(reshape1)(ks)\n",
    "            vs = Lambda(reshape1)(vs)\n",
    "\n",
    "            if mask is not None:\n",
    "                mask = Lambda(lambda x:K.repeat_elements(x, n_head, 0))(mask)\n",
    "            head, attn = self.attention(qs, ks, vs, mask=mask)  \n",
    "                \n",
    "            def reshape2(x):\n",
    "                s = tf.shape(x)   # [n_head * batch_size, len_v, d_v]\n",
    "                x = tf.reshape(x, [n_head, -1, s[1], s[2]]) \n",
    "                x = tf.transpose(x, [1, 2, 0, 3])\n",
    "                x = tf.reshape(x, [-1, s[1], n_head*d_v])  # [batch_size, len_v, n_head * d_v]\n",
    "                return x\n",
    "            head = Lambda(reshape2)(head)\n",
    "        elif self.mode == 1:\n",
    "            heads = []; attns = []\n",
    "            for i in range(n_head):\n",
    "                qs = self.qs_layers[i](q)   \n",
    "                ks = self.ks_layers[i](k) \n",
    "                vs = self.vs_layers[i](v) \n",
    "                head, attn = self.attention(qs, ks, vs, mask)\n",
    "                heads.append(head); attns.append(attn)\n",
    "            head = Concatenate()(heads) if n_head > 1 else heads[0]\n",
    "            attn = Concatenate()(attns) if n_head > 1 else attns[0]\n",
    "\n",
    "        outputs = self.w_o(head)\n",
    "        outputs = Dropout(self.dropout)(outputs)\n",
    "        if not self.layer_norm: return outputs, attn\n",
    "        # outputs = Add()([outputs, q]) # sl: fix\n",
    "        return self.layer_norm(outputs), attn\n",
    "\n",
    "class PositionwiseFeedForward():\n",
    "    def __init__(self, d_hid, d_inner_hid, dropout=0.1):\n",
    "        self.w_1 = Conv1D(d_inner_hid, 1, activation='tanh')\n",
    "        self.w_2 = Conv1D(d_hid, 1)\n",
    "        self.layer_norm = LayerNormalization()\n",
    "        self.dropout = Dropout(dropout)\n",
    "    def __call__(self, x):\n",
    "        output = self.w_1(x) \n",
    "        output = self.w_2(output)\n",
    "        output = self.dropout(output)\n",
    "        output = Add()([output, x])\n",
    "        return self.layer_norm(output)\n",
    "\n",
    "class EncoderLayer():\n",
    "    def __init__(self, d_model, d_inner_hid, n_head, d_k, d_v, dropout=0.1):\n",
    "        self.self_att_layer = MultiHeadAttention(n_head, d_model, d_k, d_v, dropout=dropout)\n",
    "        self.pos_ffn_layer  = PositionwiseFeedForward(d_model, d_inner_hid, dropout=dropout)\n",
    "    def __call__(self, enc_input, mask=None):\n",
    "        output, slf_attn = self.self_att_layer(enc_input, enc_input, enc_input, mask=mask)\n",
    "        output = self.pos_ffn_layer(output)\n",
    "        return output, slf_attn\n",
    "\n",
    "\n",
    "def GetPosEncodingMatrix(max_len, d_emb):\n",
    "    pos_enc = np.array([\n",
    "        [pos / np.power(10000, 2 * (j // 2) / d_emb) for j in range(d_emb)] \n",
    "        if pos != 0 else np.zeros(d_emb) \n",
    "            for pos in range(max_len)\n",
    "            ])\n",
    "    pos_enc[1:, 0::2] = np.sin(pos_enc[1:, 0::2]) # dim 2i\n",
    "    pos_enc[1:, 1::2] = np.cos(pos_enc[1:, 1::2]) # dim 2i+1\n",
    "    return pos_enc\n",
    "\n",
    "def GetPadMask(q, k):\n",
    "    ones = K.expand_dims(K.ones_like(q, 'float32'), -1)\n",
    "    mask = K.cast(K.expand_dims(K.not_equal(k, 0), 1), 'float32')\n",
    "    mask = K.batch_dot(ones, mask, axes=[2,1])\n",
    "    return mask\n",
    "\n",
    "def GetSubMask(s):\n",
    "    len_s = tf.shape(s)[1]\n",
    "    bs = tf.shape(s)[:1]\n",
    "    mask = K.cumsum(tf.eye(len_s, batch_shape=bs), 1)\n",
    "    return mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
    "def CnnTransformerModel():\n",
    "#    i = tf.compat.v2.keras.layers.Flatten(input_shape=(batch_size, amount_of_features))\n",
    "    i = tf.compat.v2.keras.layers.Input(shape = (seq_len, amount_of_features)#, batch_size=mini_batch_size\n",
    "                                       )\n",
    "    \n",
    "    x = tf.compat.v2.keras.layers.Convolution1D(64*2, kernel_size = 3, dilation_rate=2)(i)\n",
    "#     x = tf.compat.v2.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.compat.v2.keras.layers.Activation('tanh')(x)\n",
    "    x = tf.keras.layers.Dropout(rate=dropout_rate)(x)\n",
    "    x = tf.keras.layers.MaxPool1D(pool_size=2, strides=1)(x)\n",
    "    x = tf.compat.v2.keras.layers.Convolution1D(64, kernel_size = 3, dilation_rate=2)(x)\n",
    "    x = tf.compat.v2.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.compat.v2.keras.layers.Activation('tanh')(x)\n",
    "    x = tf.keras.layers.Dropout(rate=dropout_rate)(x)\n",
    "    x = tf.keras.layers.MaxPool1D(pool_size=2, strides=1)(x)    \n",
    "    x = tf.compat.v2.keras.layers.Convolution1D(32, kernel_size = 3, dilation_rate=2)(x)\n",
    "    x = tf.compat.v2.keras.layers.Activation('tanh')(x)\n",
    "    x = tf.keras.layers.Dropout(rate=dropout_rate)(x) \n",
    "    x = tf.compat.v2.keras.layers.Convolution1D(16, kernel_size = 3, dilation_rate=2)(x)\n",
    "    x = tf.compat.v2.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.compat.v2.keras.layers.Activation('tanh')(x)\n",
    "    x = tf.keras.layers.Dropout(rate=dropout_rate)(x)\n",
    "    x = tf.compat.v2.keras.layers.Convolution1D(8, kernel_size = 3, dilation_rate=2)(x)\n",
    "    x = tf.compat.v2.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.compat.v2.keras.layers.Activation('tanh')(x)\n",
    "    x = tf.keras.layers.Dropout(rate=dropout_rate)(x)\n",
    "    \n",
    "    x2 = tf.compat.v2.keras.layers.LocallyConnected1D(64*2, kernel_size = 3, strides=2)(i)\n",
    "    x2 = tf.keras.layers.MaxPool1D(pool_size=2, strides=1)(i)\n",
    "    x2 = tf.compat.v2.keras.layers.Activation('tanh')(x2)\n",
    "    x2 = tf.keras.layers.Dropout(rate=0.2)(x2)\n",
    "    x2 = tf.compat.v2.keras.layers.LocallyConnected1D(64, kernel_size = 3, strides=2)(i)\n",
    "    x2 = tf.keras.layers.MaxPool1D(pool_size=2, strides=1)(x2)\n",
    "    x2 = tf.compat.v2.keras.layers.BatchNormalization()(x2)\n",
    "    x2 = tf.compat.v2.keras.layers.Activation('tanh')(x2)\n",
    "    x2 = tf.keras.layers.Dropout(rate=dropout_rate)(x2)\n",
    "    x2 = tf.compat.v2.keras.layers.LocallyConnected1D(32, kernel_size = 3, strides=2)(x2)\n",
    "    x2 = tf.compat.v2.keras.layers.Activation('tanh')(x2)\n",
    "    x2 = tf.keras.layers.Dropout(rate=dropout_rate)(x2)\n",
    "    x2 = tf.compat.v2.keras.layers.LocallyConnected1D(16, kernel_size = 3, strides=2)(x2)\n",
    "    x2 = tf.compat.v2.keras.layers.Activation('tanh')(x2)\n",
    "    x2 = tf.keras.layers.Dropout(rate=dropout_rate)(x2)\n",
    "    x2 = tf.compat.v2.keras.layers.LocallyConnected1D(8, kernel_size = 3, strides=2)(x2)\n",
    "    x2 = tf.compat.v2.keras.layers.Activation('tanh')(x2)\n",
    "    x2 = tf.keras.layers.Dropout(rate=dropout_rate)(x2)\n",
    "    \n",
    "#     x2 = tf.compat.v2.keras.layers.Convolution1D(64, kernel_size = 3, strides=2)(x2)\n",
    "#     x2 = tf.keras.layers.MaxPool1D(pool_size=2, pool_size=1)(x2)\n",
    "#     x2 = tf.compat.v2.keras.layers.BatchNormalization()(x2)\n",
    "#     x2 = tf.compat.v2.keras.layers.Activation('tanh')(x2)\n",
    "#     x2 = tf.keras.layers.Dropout(rate=dropout_rate)(x2)\n",
    "\n",
    "#     x = tf.compat.v2.keras.layers.Convolution1D(32, kernel_size = 4, strides = 2)(x)\n",
    "#     x = tf.compat.v2.keras.layers.BatchNormalization()(x)\n",
    "#     x = tf.compat.v2.keras.layers.Activation('relu')(x)\n",
    "#     x = tf.keras.layers.Dropout(rate=0.2)(x)\n",
    "#     x = tf.keras.layers.MaxPool1D(pool_size=2)(x)\n",
    "#     x = tf.compat.v2.keras.layers.Convolution1D(32, kernel_size = 4, dilation_rate=5)(x)\n",
    "#     x = tf.compat.v2.keras.layers.BatchNormalization()(x)\n",
    "#     x = tf.compat.v2.keras.layers.Activation('relu')(x)\n",
    "#     x = (CuDNNLSTM(16, return_sequences = True, return_state = False))(x)\n",
    "#     x, slf_attn = MultiHeadAttention(n_head=int(80), d_model=300, d_k=64, d_v=64, dropout=0.1)(x, x, x)\n",
    "    \n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    avg_pool2 = GlobalAveragePooling1D()(x2)\n",
    "    max_pool2 = GlobalMaxPooling1D()(x2)\n",
    "    \n",
    "#     x = Dense(300)(concatenate([max_pool, avg_pool, max_pool2, avg_pool2]))\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = Activation('tanh')(x)\n",
    "#     x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "#     x = Dense(600)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = Activation('tanh')(x)\n",
    "#     x = Dropout(dropout_rate)(x)\n",
    "\n",
    "#     x = Dense(1200)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = Activation('tanh')(x)\n",
    "#     x = Dropout(dropout_rate)(x)\n",
    "\n",
    "#     x = Dense(600)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = Activation('tanh')(x)    \n",
    "#     x = Dropout(dropout_rate)(x)\n",
    "\n",
    "#     x = Dense(300)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = Activation('tanh')(x)    \n",
    "#     x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "#     x = Dense(130)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = Activation('tanh')(x)    \n",
    "#     x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    x = Dense(70)(concatenate([max_pool, avg_pool, max_pool2, avg_pool2]))\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('tanh')(x)    \n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    x = Dense(35)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('tanh')(x)    \n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    x = Dense(15)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('tanh')(x)    \n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    x = Dense(7)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('tanh')(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    tailInput = Input(shape=(input2Length,))\n",
    "    tailLayers = Dense(input2Length, activation='tanh')(tailInput)\n",
    "    tailLayers = Dense(input2Length*2, activation='tanh')(tailInput)\n",
    "    tailLayers = Dense(input2Length*2*2, activation='tanh')(tailInput)\n",
    "    tailLayers = BatchNormalization()(tailInput)\n",
    "    tailLayers = Dropout(0.2)(tailInput)\n",
    "    tailLayers = Dense(input2Length*2*2*2, activation='tanh')(tailInput)\n",
    "    tailLayers = BatchNormalization()(tailInput)\n",
    "    tailLayers = Dropout(0.2)(tailInput)\n",
    "    tailLayers = Dense(input2Length*2*2, activation='tanh')(tailInput)    \n",
    "    tailLayers = Dense(input2Length*2, activation='tanh')(tailInput)\n",
    "    tailLayers = Dense(3, activation='tanh')(tailInput)\n",
    "    \n",
    "#     concat = concatenate([avg_pool, max_pool, tailLayers])\n",
    "    concat = concatenate([x, tailLayers])\n",
    "\n",
    "    y = Dense(3,activation = 'softmax')(concat)\n",
    "    \n",
    "\n",
    "    return Model(inputs = [i, tailInput], outputs = [y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_28 (InputLayer)           [(None, 360, 4)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_99 (Conv1D)              (None, 356, 128)     1664        input_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 356, 128)     0           conv1d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_237 (Dropout)           (None, 356, 128)     0           activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling1D) (None, 355, 128)     0           dropout_237[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_100 (Conv1D)             (None, 351, 64)      24640       max_pooling1d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 351, 64)      256         conv1d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 351, 64)      0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_1 (LocallyC (None, 179, 64)      148928      input_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_238 (Dropout)           (None, 351, 64)      0           activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling1D) (None, 178, 64)      0           locally_connected1d_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling1D) (None, 350, 64)      0           dropout_238[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 178, 64)      256         max_pooling1d_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_101 (Conv1D)             (None, 346, 32)      6176        max_pooling1d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 178, 64)      0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 346, 32)      0           conv1d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_243 (Dropout)           (None, 178, 64)      0           activation_228[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_239 (Dropout)           (None, 346, 32)      0           activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_2 (LocallyC (None, 88, 32)       543488      dropout_243[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling1D) (None, 345, 32)      0           dropout_239[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling1D) (None, 87, 32)       0           locally_connected1d_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_102 (Conv1D)             (None, 341, 16)      1552        max_pooling1d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 87, 32)       0           max_pooling1d_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 341, 16)      64          conv1d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_244 (Dropout)           (None, 87, 32)       0           activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 341, 16)      0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_3 (LocallyC (None, 43, 16)       66736       dropout_244[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_240 (Dropout)           (None, 341, 16)      0           activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling1D) (None, 42, 16)       0           locally_connected1d_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling1D) (None, 340, 16)      0           dropout_240[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 42, 16)       0           max_pooling1d_30[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_103 (Conv1D)             (None, 336, 8)       392         max_pooling1d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_245 (Dropout)           (None, 42, 16)       0           activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 336, 8)       32          conv1d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_4 (LocallyC (None, 20, 8)        7840        dropout_245[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 336, 8)       0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling1D) (None, 19, 8)        0           locally_connected1d_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_241 (Dropout)           (None, 336, 8)       0           activation_226[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 19, 8)        0           max_pooling1d_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling1D) (None, 335, 8)       0           dropout_241[0][0]                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "dropout_246 (Dropout)           (None, 19, 8)        0           activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_24 (Global (None, 8)            0           max_pooling1d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_24 (Gl (None, 8)            0           max_pooling1d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_25 (Global (None, 8)            0           dropout_246[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_25 (Gl (None, 8)            0           dropout_246[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 32)           0           global_max_pooling1d_24[0][0]    \n",
      "                                                                 global_average_pooling1d_24[0][0]\n",
      "                                                                 global_max_pooling1d_25[0][0]    \n",
      "                                                                 global_average_pooling1d_25[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_216 (Dense)               (None, 300)          9900        concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 300)          1200        dense_216[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 300)          0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_247 (Dropout)           (None, 300)          0           activation_232[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_217 (Dense)               (None, 600)          180600      dropout_247[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 600)          2400        dense_217[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 600)          0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_248 (Dropout)           (None, 600)          0           activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_218 (Dense)               (None, 1200)         721200      dropout_248[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 1200)         4800        dense_218[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, 1200)         0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_249 (Dropout)           (None, 1200)         0           activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_219 (Dense)               (None, 600)          720600      dropout_249[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 600)          2400        dense_219[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, 600)          0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_250 (Dropout)           (None, 600)          0           activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_220 (Dense)               (None, 300)          180300      dropout_250[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 300)          1200        dense_220[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, 300)          0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_251 (Dropout)           (None, 300)          0           activation_236[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_221 (Dense)               (None, 130)          39130       dropout_251[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 130)          520         dense_221[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, 130)          0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_252 (Dropout)           (None, 130)          0           activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_222 (Dense)               (None, 70)           9170        dropout_252[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 70)           280         dense_222[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 70)           0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_253 (Dropout)           (None, 70)           0           activation_238[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_223 (Dense)               (None, 35)           2485        dropout_253[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 35)           140         dense_223[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 35)           0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_254 (Dropout)           (None, 35)           0           activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_224 (Dense)               (None, 15)           540         dropout_254[0][0]                \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_204 (BatchN (None, 15)           60          dense_224[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 15)           0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_255 (Dropout)           (None, 15)           0           activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_225 (Dense)               (None, 7)            112         dropout_255[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 7)            28          dense_225[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 7)            0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "input_29 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_256 (Dropout)           (None, 7)            0           activation_241[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_232 (Dense)               (None, 3)            18          input_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 10)           0           dropout_256[0][0]                \n",
      "                                                                 dense_232[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_233 (Dense)               (None, 3)            33          concatenate_25[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 2,679,140\n",
      "Trainable params: 2,672,322\n",
      "Non-trainable params: 6,818\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = CnnTransformerModel()\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.09, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer=optimizer, \n",
    "                          loss='categorical_crossentropy'\n",
    "#                           loss_weights=[1., 1.]\n",
    "#                           loss_weights=[1.]\n",
    "#                             , metrics=['accuracy']\n",
    "                           , metrics=['accuracy' \n",
    "#                                       , tfa.metrics.MultiLabelConfusionMatrix(num_classes=3)\n",
    "#                                       , Recall(class_id=0)\n",
    "#                                 , Recall(class_id=2)\n",
    "#                                   , Precision(class_id=0)\n",
    "#                                  , Precision(class_id=2)\n",
    "                                 ]\n",
    "             )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizing The Model Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"7488pt\" viewBox=\"0.00 0.00 1824.50 5616.00\" width=\"2433pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1.33333 1.33333) rotate(0) translate(4 5612)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-5612 1820.5,-5612 1820.5,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 2217943516552 -->\n",
       "<g class=\"node\" id=\"node1\"><title>2217943516552</title>\n",
       "<polygon fill=\"none\" points=\"751,-5561.5 751,-5607.5 1023,-5607.5 1023,-5561.5 751,-5561.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"817.5\" y=\"-5580.8\">input_28: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"884,-5561.5 884,-5607.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"912\" y=\"-5592.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"884,-5584.5 940,-5584.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"912\" y=\"-5569.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"940,-5561.5 940,-5607.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"981.5\" y=\"-5592.3\">[(?, 360, 4)]</text>\n",
       "<polyline fill=\"none\" points=\"940,-5584.5 1023,-5584.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"981.5\" y=\"-5569.3\">[(?, 360, 4)]</text>\n",
       "</g>\n",
       "<!-- 2217943468128 -->\n",
       "<g class=\"node\" id=\"node2\"><title>2217943468128</title>\n",
       "<polygon fill=\"none\" points=\"565.5,-5478.5 565.5,-5524.5 842.5,-5524.5 842.5,-5478.5 565.5,-5478.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"632.5\" y=\"-5497.8\">conv1d_99: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"699.5,-5478.5 699.5,-5524.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"727.5\" y=\"-5509.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"699.5,-5501.5 755.5,-5501.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"727.5\" y=\"-5486.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"755.5,-5478.5 755.5,-5524.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"799\" y=\"-5509.3\">(?, 360, 4)</text>\n",
       "<polyline fill=\"none\" points=\"755.5,-5501.5 842.5,-5501.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"799\" y=\"-5486.3\">(?, 356, 128)</text>\n",
       "</g>\n",
       "<!-- 2217943516552&#45;&gt;2217943468128 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>2217943516552-&gt;2217943468128</title>\n",
       "<path d=\"M836.994,-5561.37C814.199,-5551.28 787.044,-5539.26 763.233,-5528.72\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"764.506,-5525.45 753.945,-5524.61 761.673,-5531.85 764.506,-5525.45\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217964015856 -->\n",
       "<g class=\"node\" id=\"node9\"><title>2217964015856</title>\n",
       "<polygon fill=\"none\" points=\"866,-5478.5 866,-5524.5 1274,-5524.5 1274,-5478.5 866,-5478.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1002\" y=\"-5497.8\">locally_connected1d_1: LocallyConnected1D</text>\n",
       "<polyline fill=\"none\" points=\"1138,-5478.5 1138,-5524.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1166\" y=\"-5509.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1138,-5501.5 1194,-5501.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1166\" y=\"-5486.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1194,-5478.5 1194,-5524.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1234\" y=\"-5509.3\">(?, 360, 4)</text>\n",
       "<polyline fill=\"none\" points=\"1194,-5501.5 1274,-5501.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1234\" y=\"-5486.3\">(?, 179, 64)</text>\n",
       "</g>\n",
       "<!-- 2217943516552&#45;&gt;2217964015856 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>2217943516552-&gt;2217964015856</title>\n",
       "<path d=\"M937.006,-5561.37C959.801,-5551.28 986.956,-5539.26 1010.77,-5528.72\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1012.33,-5531.85 1020.05,-5524.61 1009.49,-5525.45 1012.33,-5531.85\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217943517560 -->\n",
       "<g class=\"node\" id=\"node3\"><title>2217943517560</title>\n",
       "<polygon fill=\"none\" points=\"543,-5395.5 543,-5441.5 847,-5441.5 847,-5395.5 543,-5395.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"623.5\" y=\"-5414.8\">activation_222: Activation</text>\n",
       "<polyline fill=\"none\" points=\"704,-5395.5 704,-5441.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"732\" y=\"-5426.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"704,-5418.5 760,-5418.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"732\" y=\"-5403.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"760,-5395.5 760,-5441.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"803.5\" y=\"-5426.3\">(?, 356, 128)</text>\n",
       "<polyline fill=\"none\" points=\"760,-5418.5 847,-5418.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"803.5\" y=\"-5403.3\">(?, 356, 128)</text>\n",
       "</g>\n",
       "<!-- 2217943468128&#45;&gt;2217943517560 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>2217943468128-&gt;2217943517560</title>\n",
       "<path d=\"M701.541,-5478.37C700.628,-5470.15 699.573,-5460.66 698.581,-5451.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"702.039,-5451.16 697.456,-5441.61 695.082,-5451.93 702.039,-5451.16\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217943515992 -->\n",
       "<g class=\"node\" id=\"node4\"><title>2217943515992</title>\n",
       "<polygon fill=\"none\" points=\"550,-5312.5 550,-5358.5 836,-5358.5 836,-5312.5 550,-5312.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"621.5\" y=\"-5331.8\">dropout_237: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"693,-5312.5 693,-5358.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"721\" y=\"-5343.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"693,-5335.5 749,-5335.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"721\" y=\"-5320.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"749,-5312.5 749,-5358.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"792.5\" y=\"-5343.3\">(?, 356, 128)</text>\n",
       "<polyline fill=\"none\" points=\"749,-5335.5 836,-5335.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"792.5\" y=\"-5320.3\">(?, 356, 128)</text>\n",
       "</g>\n",
       "<!-- 2217943517560&#45;&gt;2217943515992 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>2217943517560-&gt;2217943515992</title>\n",
       "<path d=\"M694.453,-5395.37C694.251,-5387.15 694.016,-5377.66 693.796,-5368.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"697.292,-5368.52 693.546,-5358.61 690.294,-5368.69 697.292,-5368.52\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2218045830648 -->\n",
       "<g class=\"node\" id=\"node5\"><title>2218045830648</title>\n",
       "<polygon fill=\"none\" points=\"513,-5229.5 513,-5275.5 871,-5275.5 871,-5229.5 513,-5229.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"620.5\" y=\"-5248.8\">max_pooling1d_22: MaxPooling1D</text>\n",
       "<polyline fill=\"none\" points=\"728,-5229.5 728,-5275.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"756\" y=\"-5260.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"728,-5252.5 784,-5252.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"756\" y=\"-5237.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"784,-5229.5 784,-5275.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"827.5\" y=\"-5260.3\">(?, 356, 128)</text>\n",
       "<polyline fill=\"none\" points=\"784,-5252.5 871,-5252.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"827.5\" y=\"-5237.3\">(?, 355, 128)</text>\n",
       "</g>\n",
       "<!-- 2217943515992&#45;&gt;2218045830648 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>2217943515992-&gt;2218045830648</title>\n",
       "<path d=\"M692.727,-5312.37C692.625,-5304.15 692.508,-5294.66 692.398,-5285.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"695.896,-5285.56 692.273,-5275.61 688.897,-5285.65 695.896,-5285.56\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217937151200 -->\n",
       "<g class=\"node\" id=\"node6\"><title>2217937151200</title>\n",
       "<polygon fill=\"none\" points=\"549.5,-5146.5 549.5,-5192.5 832.5,-5192.5 832.5,-5146.5 549.5,-5146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"619.5\" y=\"-5165.8\">conv1d_100: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"689.5,-5146.5 689.5,-5192.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"717.5\" y=\"-5177.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"689.5,-5169.5 745.5,-5169.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"717.5\" y=\"-5154.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"745.5,-5146.5 745.5,-5192.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"789\" y=\"-5177.3\">(?, 355, 128)</text>\n",
       "<polyline fill=\"none\" points=\"745.5,-5169.5 832.5,-5169.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"789\" y=\"-5154.3\">(?, 351, 64)</text>\n",
       "</g>\n",
       "<!-- 2218045830648&#45;&gt;2217937151200 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>2218045830648-&gt;2217937151200</title>\n",
       "<path d=\"M691.727,-5229.37C691.625,-5221.15 691.508,-5211.66 691.398,-5202.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"694.896,-5202.56 691.273,-5192.61 687.897,-5202.65 694.896,-5202.56\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217938183728 -->\n",
       "<g class=\"node\" id=\"node7\"><title>2217938183728</title>\n",
       "<polygon fill=\"none\" points=\"486.5,-5063.5 486.5,-5109.5 895.5,-5109.5 895.5,-5063.5 486.5,-5063.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"623\" y=\"-5082.8\">batch_normalization_192: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"759.5,-5063.5 759.5,-5109.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"787.5\" y=\"-5094.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"759.5,-5086.5 815.5,-5086.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"787.5\" y=\"-5071.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"815.5,-5063.5 815.5,-5109.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"855.5\" y=\"-5094.3\">(?, 351, 64)</text>\n",
       "<polyline fill=\"none\" points=\"815.5,-5086.5 895.5,-5086.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"855.5\" y=\"-5071.3\">(?, 351, 64)</text>\n",
       "</g>\n",
       "<!-- 2217937151200&#45;&gt;2217938183728 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>2217937151200-&gt;2217938183728</title>\n",
       "<path d=\"M691,-5146.37C691,-5138.15 691,-5128.66 691,-5119.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"694.5,-5119.61 691,-5109.61 687.5,-5119.61 694.5,-5119.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217937260496 -->\n",
       "<g class=\"node\" id=\"node8\"><title>2217937260496</title>\n",
       "<polygon fill=\"none\" points=\"542.5,-4980.5 542.5,-5026.5 839.5,-5026.5 839.5,-4980.5 542.5,-4980.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"623\" y=\"-4999.8\">activation_223: Activation</text>\n",
       "<polyline fill=\"none\" points=\"703.5,-4980.5 703.5,-5026.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"731.5\" y=\"-5011.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"703.5,-5003.5 759.5,-5003.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"731.5\" y=\"-4988.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"759.5,-4980.5 759.5,-5026.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"799.5\" y=\"-5011.3\">(?, 351, 64)</text>\n",
       "<polyline fill=\"none\" points=\"759.5,-5003.5 839.5,-5003.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"799.5\" y=\"-4988.3\">(?, 351, 64)</text>\n",
       "</g>\n",
       "<!-- 2217938183728&#45;&gt;2217937260496 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>2217938183728-&gt;2217937260496</title>\n",
       "<path d=\"M691,-5063.37C691,-5055.15 691,-5045.66 691,-5036.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"694.5,-5036.61 691,-5026.61 687.5,-5036.61 694.5,-5036.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217937260216 -->\n",
       "<g class=\"node\" id=\"node10\"><title>2217937260216</title>\n",
       "<polygon fill=\"none\" points=\"551.5,-4897.5 551.5,-4943.5 830.5,-4943.5 830.5,-4897.5 551.5,-4897.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"623\" y=\"-4916.8\">dropout_238: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"694.5,-4897.5 694.5,-4943.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"722.5\" y=\"-4928.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"694.5,-4920.5 750.5,-4920.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"722.5\" y=\"-4905.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"750.5,-4897.5 750.5,-4943.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"790.5\" y=\"-4928.3\">(?, 351, 64)</text>\n",
       "<polyline fill=\"none\" points=\"750.5,-4920.5 830.5,-4920.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"790.5\" y=\"-4905.3\">(?, 351, 64)</text>\n",
       "</g>\n",
       "<!-- 2217937260496&#45;&gt;2217937260216 -->\n",
       "<g class=\"edge\" id=\"edge9\"><title>2217937260496-&gt;2217937260216</title>\n",
       "<path d=\"M691,-4980.37C691,-4972.15 691,-4962.66 691,-4953.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"694.5,-4953.61 691,-4943.61 687.5,-4953.61 694.5,-4953.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217981357136 -->\n",
       "<g class=\"node\" id=\"node11\"><title>2217981357136</title>\n",
       "<polygon fill=\"none\" points=\"912.5,-4897.5 912.5,-4943.5 1263.5,-4943.5 1263.5,-4897.5 912.5,-4897.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1020\" y=\"-4916.8\">max_pooling1d_28: MaxPooling1D</text>\n",
       "<polyline fill=\"none\" points=\"1127.5,-4897.5 1127.5,-4943.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1155.5\" y=\"-4928.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1127.5,-4920.5 1183.5,-4920.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1155.5\" y=\"-4905.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1183.5,-4897.5 1183.5,-4943.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1223.5\" y=\"-4928.3\">(?, 179, 64)</text>\n",
       "<polyline fill=\"none\" points=\"1183.5,-4920.5 1263.5,-4920.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1223.5\" y=\"-4905.3\">(?, 178, 64)</text>\n",
       "</g>\n",
       "<!-- 2217964015856&#45;&gt;2217981357136 -->\n",
       "<g class=\"edge\" id=\"edge10\"><title>2217964015856-&gt;2217981357136</title>\n",
       "<path d=\"M1073.99,-5478.3C1079.3,-5446.86 1088,-5387.48 1088,-5336.5 1088,-5336.5 1088,-5336.5 1088,-5085.5 1088,-5039.84 1088,-4987.03 1088,-4953.94\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1091.5,-4953.52 1088,-4943.52 1084.5,-4953.52 1091.5,-4953.52\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2218035185088 -->\n",
       "<g class=\"node\" id=\"node12\"><title>2218035185088</title>\n",
       "<polygon fill=\"none\" points=\"515.5,-4814.5 515.5,-4860.5 866.5,-4860.5 866.5,-4814.5 515.5,-4814.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"623\" y=\"-4833.8\">max_pooling1d_23: MaxPooling1D</text>\n",
       "<polyline fill=\"none\" points=\"730.5,-4814.5 730.5,-4860.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"758.5\" y=\"-4845.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"730.5,-4837.5 786.5,-4837.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"758.5\" y=\"-4822.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"786.5,-4814.5 786.5,-4860.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"826.5\" y=\"-4845.3\">(?, 351, 64)</text>\n",
       "<polyline fill=\"none\" points=\"786.5,-4837.5 866.5,-4837.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"826.5\" y=\"-4822.3\">(?, 350, 64)</text>\n",
       "</g>\n",
       "<!-- 2217937260216&#45;&gt;2218035185088 -->\n",
       "<g class=\"edge\" id=\"edge11\"><title>2217937260216-&gt;2218035185088</title>\n",
       "<path d=\"M691,-4897.37C691,-4889.15 691,-4879.66 691,-4870.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"694.5,-4870.61 691,-4860.61 687.5,-4870.61 694.5,-4870.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217964944016 -->\n",
       "<g class=\"node\" id=\"node13\"><title>2217964944016</title>\n",
       "<polygon fill=\"none\" points=\"914.5,-4814.5 914.5,-4860.5 1323.5,-4860.5 1323.5,-4814.5 914.5,-4814.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1051\" y=\"-4833.8\">batch_normalization_195: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"1187.5,-4814.5 1187.5,-4860.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1215.5\" y=\"-4845.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1187.5,-4837.5 1243.5,-4837.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1215.5\" y=\"-4822.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1243.5,-4814.5 1243.5,-4860.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1283.5\" y=\"-4845.3\">(?, 178, 64)</text>\n",
       "<polyline fill=\"none\" points=\"1243.5,-4837.5 1323.5,-4837.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1283.5\" y=\"-4822.3\">(?, 178, 64)</text>\n",
       "</g>\n",
       "<!-- 2217981357136&#45;&gt;2217964944016 -->\n",
       "<g class=\"edge\" id=\"edge12\"><title>2217981357136-&gt;2217964944016</title>\n",
       "<path d=\"M1096.47,-4897.37C1099.68,-4888.97 1103.41,-4879.24 1106.89,-4870.14\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1110.23,-4871.2 1110.54,-4860.61 1103.7,-4868.7 1110.23,-4871.2\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2218035149512 -->\n",
       "<g class=\"node\" id=\"node14\"><title>2218035149512</title>\n",
       "<polygon fill=\"none\" points=\"538,-4731.5 538,-4777.5 814,-4777.5 814,-4731.5 538,-4731.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"608\" y=\"-4750.8\">conv1d_101: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"678,-4731.5 678,-4777.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"706\" y=\"-4762.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"678,-4754.5 734,-4754.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"706\" y=\"-4739.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"734,-4731.5 734,-4777.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"774\" y=\"-4762.3\">(?, 350, 64)</text>\n",
       "<polyline fill=\"none\" points=\"734,-4754.5 814,-4754.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"774\" y=\"-4739.3\">(?, 346, 32)</text>\n",
       "</g>\n",
       "<!-- 2218035185088&#45;&gt;2218035149512 -->\n",
       "<g class=\"edge\" id=\"edge13\"><title>2218035185088-&gt;2218035149512</title>\n",
       "<path d=\"M686.901,-4814.37C685.38,-4806.15 683.622,-4796.66 681.968,-4787.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"685.356,-4786.8 680.094,-4777.61 678.473,-4788.08 685.356,-4786.8\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217981402360 -->\n",
       "<g class=\"node\" id=\"node15\"><title>2217981402360</title>\n",
       "<polygon fill=\"none\" points=\"974.5,-4731.5 974.5,-4777.5 1271.5,-4777.5 1271.5,-4731.5 974.5,-4731.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1055\" y=\"-4750.8\">activation_228: Activation</text>\n",
       "<polyline fill=\"none\" points=\"1135.5,-4731.5 1135.5,-4777.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1163.5\" y=\"-4762.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1135.5,-4754.5 1191.5,-4754.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1163.5\" y=\"-4739.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1191.5,-4731.5 1191.5,-4777.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1231.5\" y=\"-4762.3\">(?, 178, 64)</text>\n",
       "<polyline fill=\"none\" points=\"1191.5,-4754.5 1271.5,-4754.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1231.5\" y=\"-4739.3\">(?, 178, 64)</text>\n",
       "</g>\n",
       "<!-- 2217964944016&#45;&gt;2217981402360 -->\n",
       "<g class=\"edge\" id=\"edge14\"><title>2217964944016-&gt;2217981402360</title>\n",
       "<path d=\"M1120.09,-4814.37C1120.5,-4806.15 1120.97,-4796.66 1121.41,-4787.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1124.91,-4787.77 1121.91,-4777.61 1117.92,-4787.42 1124.91,-4787.77\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2218035300112 -->\n",
       "<g class=\"node\" id=\"node16\"><title>2218035300112</title>\n",
       "<polygon fill=\"none\" points=\"525.5,-4648.5 525.5,-4694.5 822.5,-4694.5 822.5,-4648.5 525.5,-4648.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"606\" y=\"-4667.8\">activation_224: Activation</text>\n",
       "<polyline fill=\"none\" points=\"686.5,-4648.5 686.5,-4694.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"714.5\" y=\"-4679.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"686.5,-4671.5 742.5,-4671.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"714.5\" y=\"-4656.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"742.5,-4648.5 742.5,-4694.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"782.5\" y=\"-4679.3\">(?, 346, 32)</text>\n",
       "<polyline fill=\"none\" points=\"742.5,-4671.5 822.5,-4671.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"782.5\" y=\"-4656.3\">(?, 346, 32)</text>\n",
       "</g>\n",
       "<!-- 2218035149512&#45;&gt;2218035300112 -->\n",
       "<g class=\"edge\" id=\"edge15\"><title>2218035149512-&gt;2218035300112</title>\n",
       "<path d=\"M675.453,-4731.37C675.251,-4723.15 675.016,-4713.66 674.796,-4704.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"678.292,-4704.52 674.546,-4694.61 671.294,-4704.69 678.292,-4704.52\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217981401912 -->\n",
       "<g class=\"node\" id=\"node17\"><title>2217981401912</title>\n",
       "<polygon fill=\"none\" points=\"991.5,-4648.5 991.5,-4694.5 1270.5,-4694.5 1270.5,-4648.5 991.5,-4648.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1063\" y=\"-4667.8\">dropout_243: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"1134.5,-4648.5 1134.5,-4694.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1162.5\" y=\"-4679.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1134.5,-4671.5 1190.5,-4671.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1162.5\" y=\"-4656.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1190.5,-4648.5 1190.5,-4694.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1230.5\" y=\"-4679.3\">(?, 178, 64)</text>\n",
       "<polyline fill=\"none\" points=\"1190.5,-4671.5 1270.5,-4671.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1230.5\" y=\"-4656.3\">(?, 178, 64)</text>\n",
       "</g>\n",
       "<!-- 2217981402360&#45;&gt;2217981401912 -->\n",
       "<g class=\"edge\" id=\"edge16\"><title>2217981402360-&gt;2217981401912</title>\n",
       "<path d=\"M1125.19,-4731.37C1126,-4723.15 1126.94,-4713.66 1127.82,-4704.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1131.32,-4704.9 1128.82,-4694.61 1124.35,-4704.21 1131.32,-4704.9\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2218035300224 -->\n",
       "<g class=\"node\" id=\"node18\"><title>2218035300224</title>\n",
       "<polygon fill=\"none\" points=\"534.5,-4565.5 534.5,-4611.5 813.5,-4611.5 813.5,-4565.5 534.5,-4565.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"606\" y=\"-4584.8\">dropout_239: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"677.5,-4565.5 677.5,-4611.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"705.5\" y=\"-4596.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"677.5,-4588.5 733.5,-4588.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"705.5\" y=\"-4573.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"733.5,-4565.5 733.5,-4611.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"773.5\" y=\"-4596.3\">(?, 346, 32)</text>\n",
       "<polyline fill=\"none\" points=\"733.5,-4588.5 813.5,-4588.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"773.5\" y=\"-4573.3\">(?, 346, 32)</text>\n",
       "</g>\n",
       "<!-- 2218035300112&#45;&gt;2218035300224 -->\n",
       "<g class=\"edge\" id=\"edge17\"><title>2218035300112-&gt;2218035300224</title>\n",
       "<path d=\"M674,-4648.37C674,-4640.15 674,-4630.66 674,-4621.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"677.5,-4621.61 674,-4611.61 670.5,-4621.61 677.5,-4621.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217981773136 -->\n",
       "<g class=\"node\" id=\"node19\"><title>2217981773136</title>\n",
       "<polygon fill=\"none\" points=\"928,-4565.5 928,-4611.5 1336,-4611.5 1336,-4565.5 928,-4565.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1064\" y=\"-4584.8\">locally_connected1d_2: LocallyConnected1D</text>\n",
       "<polyline fill=\"none\" points=\"1200,-4565.5 1200,-4611.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1228\" y=\"-4596.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1200,-4588.5 1256,-4588.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1228\" y=\"-4573.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1256,-4565.5 1256,-4611.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1296\" y=\"-4596.3\">(?, 178, 64)</text>\n",
       "<polyline fill=\"none\" points=\"1256,-4588.5 1336,-4588.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1296\" y=\"-4573.3\">(?, 88, 32)</text>\n",
       "</g>\n",
       "<!-- 2217981401912&#45;&gt;2217981773136 -->\n",
       "<g class=\"edge\" id=\"edge18\"><title>2217981401912-&gt;2217981773136</title>\n",
       "<path d=\"M1131.27,-4648.37C1131.37,-4640.15 1131.49,-4630.66 1131.6,-4621.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1135.1,-4621.65 1131.73,-4611.61 1128.1,-4621.56 1135.1,-4621.65\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2218035354144 -->\n",
       "<g class=\"node\" id=\"node20\"><title>2218035354144</title>\n",
       "<polygon fill=\"none\" points=\"498.5,-4482.5 498.5,-4528.5 849.5,-4528.5 849.5,-4482.5 498.5,-4482.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"606\" y=\"-4501.8\">max_pooling1d_24: MaxPooling1D</text>\n",
       "<polyline fill=\"none\" points=\"713.5,-4482.5 713.5,-4528.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"741.5\" y=\"-4513.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"713.5,-4505.5 769.5,-4505.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"741.5\" y=\"-4490.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"769.5,-4482.5 769.5,-4528.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"809.5\" y=\"-4513.3\">(?, 346, 32)</text>\n",
       "<polyline fill=\"none\" points=\"769.5,-4505.5 849.5,-4505.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"809.5\" y=\"-4490.3\">(?, 345, 32)</text>\n",
       "</g>\n",
       "<!-- 2218035300224&#45;&gt;2218035354144 -->\n",
       "<g class=\"edge\" id=\"edge19\"><title>2218035300224-&gt;2218035354144</title>\n",
       "<path d=\"M674,-4565.37C674,-4557.15 674,-4547.66 674,-4538.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"677.5,-4538.61 674,-4528.61 670.5,-4538.61 677.5,-4538.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217981868464 -->\n",
       "<g class=\"node\" id=\"node21\"><title>2217981868464</title>\n",
       "<polygon fill=\"none\" points=\"959.5,-4482.5 959.5,-4528.5 1304.5,-4528.5 1304.5,-4482.5 959.5,-4482.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1067\" y=\"-4501.8\">max_pooling1d_29: MaxPooling1D</text>\n",
       "<polyline fill=\"none\" points=\"1174.5,-4482.5 1174.5,-4528.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1202.5\" y=\"-4513.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1174.5,-4505.5 1230.5,-4505.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1202.5\" y=\"-4490.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1230.5,-4482.5 1230.5,-4528.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1267.5\" y=\"-4513.3\">(?, 88, 32)</text>\n",
       "<polyline fill=\"none\" points=\"1230.5,-4505.5 1304.5,-4505.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1267.5\" y=\"-4490.3\">(?, 87, 32)</text>\n",
       "</g>\n",
       "<!-- 2217981773136&#45;&gt;2217981868464 -->\n",
       "<g class=\"edge\" id=\"edge20\"><title>2217981773136-&gt;2217981868464</title>\n",
       "<path d=\"M1132,-4565.37C1132,-4557.15 1132,-4547.66 1132,-4538.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1135.5,-4538.61 1132,-4528.61 1128.5,-4538.61 1135.5,-4538.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2218036987944 -->\n",
       "<g class=\"node\" id=\"node22\"><title>2218036987944</title>\n",
       "<polygon fill=\"none\" points=\"536,-4399.5 536,-4445.5 812,-4445.5 812,-4399.5 536,-4399.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"606\" y=\"-4418.8\">conv1d_102: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"676,-4399.5 676,-4445.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"704\" y=\"-4430.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"676,-4422.5 732,-4422.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"704\" y=\"-4407.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"732,-4399.5 732,-4445.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"772\" y=\"-4430.3\">(?, 345, 32)</text>\n",
       "<polyline fill=\"none\" points=\"732,-4422.5 812,-4422.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"772\" y=\"-4407.3\">(?, 341, 16)</text>\n",
       "</g>\n",
       "<!-- 2218035354144&#45;&gt;2218036987944 -->\n",
       "<g class=\"edge\" id=\"edge21\"><title>2218035354144-&gt;2218036987944</title>\n",
       "<path d=\"M674,-4482.37C674,-4474.15 674,-4464.66 674,-4455.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"677.5,-4455.61 674,-4445.61 670.5,-4455.61 677.5,-4455.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217981915936 -->\n",
       "<g class=\"node\" id=\"node23\"><title>2217981915936</title>\n",
       "<polygon fill=\"none\" points=\"986.5,-4399.5 986.5,-4445.5 1277.5,-4445.5 1277.5,-4399.5 986.5,-4399.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1067\" y=\"-4418.8\">activation_229: Activation</text>\n",
       "<polyline fill=\"none\" points=\"1147.5,-4399.5 1147.5,-4445.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1175.5\" y=\"-4430.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1147.5,-4422.5 1203.5,-4422.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1175.5\" y=\"-4407.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1203.5,-4399.5 1203.5,-4445.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1240.5\" y=\"-4430.3\">(?, 87, 32)</text>\n",
       "<polyline fill=\"none\" points=\"1203.5,-4422.5 1277.5,-4422.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1240.5\" y=\"-4407.3\">(?, 87, 32)</text>\n",
       "</g>\n",
       "<!-- 2217981868464&#45;&gt;2217981915936 -->\n",
       "<g class=\"edge\" id=\"edge22\"><title>2217981868464-&gt;2217981915936</title>\n",
       "<path d=\"M1132,-4482.37C1132,-4474.15 1132,-4464.66 1132,-4455.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1135.5,-4455.61 1132,-4445.61 1128.5,-4455.61 1135.5,-4455.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2218037108864 -->\n",
       "<g class=\"node\" id=\"node24\"><title>2218037108864</title>\n",
       "<polygon fill=\"none\" points=\"469.5,-4316.5 469.5,-4362.5 878.5,-4362.5 878.5,-4316.5 469.5,-4316.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"606\" y=\"-4335.8\">batch_normalization_193: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"742.5,-4316.5 742.5,-4362.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"770.5\" y=\"-4347.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"742.5,-4339.5 798.5,-4339.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"770.5\" y=\"-4324.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"798.5,-4316.5 798.5,-4362.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"838.5\" y=\"-4347.3\">(?, 341, 16)</text>\n",
       "<polyline fill=\"none\" points=\"798.5,-4339.5 878.5,-4339.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"838.5\" y=\"-4324.3\">(?, 341, 16)</text>\n",
       "</g>\n",
       "<!-- 2218036987944&#45;&gt;2218037108864 -->\n",
       "<g class=\"edge\" id=\"edge23\"><title>2218036987944-&gt;2218037108864</title>\n",
       "<path d=\"M674,-4399.37C674,-4391.15 674,-4381.66 674,-4372.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"677.5,-4372.61 674,-4362.61 670.5,-4372.61 677.5,-4372.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217984305080 -->\n",
       "<g class=\"node\" id=\"node25\"><title>2217984305080</title>\n",
       "<polygon fill=\"none\" points=\"995.5,-4316.5 995.5,-4362.5 1268.5,-4362.5 1268.5,-4316.5 995.5,-4316.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1067\" y=\"-4335.8\">dropout_244: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"1138.5,-4316.5 1138.5,-4362.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1166.5\" y=\"-4347.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1138.5,-4339.5 1194.5,-4339.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1166.5\" y=\"-4324.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1194.5,-4316.5 1194.5,-4362.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1231.5\" y=\"-4347.3\">(?, 87, 32)</text>\n",
       "<polyline fill=\"none\" points=\"1194.5,-4339.5 1268.5,-4339.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1231.5\" y=\"-4324.3\">(?, 87, 32)</text>\n",
       "</g>\n",
       "<!-- 2217981915936&#45;&gt;2217984305080 -->\n",
       "<g class=\"edge\" id=\"edge24\"><title>2217981915936-&gt;2217984305080</title>\n",
       "<path d=\"M1132,-4399.37C1132,-4391.15 1132,-4381.66 1132,-4372.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1135.5,-4372.61 1132,-4362.61 1128.5,-4372.61 1135.5,-4372.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2218037125360 -->\n",
       "<g class=\"node\" id=\"node26\"><title>2218037125360</title>\n",
       "<polygon fill=\"none\" points=\"525.5,-4233.5 525.5,-4279.5 822.5,-4279.5 822.5,-4233.5 525.5,-4233.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"606\" y=\"-4252.8\">activation_225: Activation</text>\n",
       "<polyline fill=\"none\" points=\"686.5,-4233.5 686.5,-4279.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"714.5\" y=\"-4264.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"686.5,-4256.5 742.5,-4256.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"714.5\" y=\"-4241.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"742.5,-4233.5 742.5,-4279.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"782.5\" y=\"-4264.3\">(?, 341, 16)</text>\n",
       "<polyline fill=\"none\" points=\"742.5,-4256.5 822.5,-4256.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"782.5\" y=\"-4241.3\">(?, 341, 16)</text>\n",
       "</g>\n",
       "<!-- 2218037108864&#45;&gt;2218037125360 -->\n",
       "<g class=\"edge\" id=\"edge25\"><title>2218037108864-&gt;2218037125360</title>\n",
       "<path d=\"M674,-4316.37C674,-4308.15 674,-4298.66 674,-4289.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"677.5,-4289.61 674,-4279.61 670.5,-4289.61 677.5,-4289.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217985048248 -->\n",
       "<g class=\"node\" id=\"node27\"><title>2217985048248</title>\n",
       "<polygon fill=\"none\" points=\"931,-4233.5 931,-4279.5 1333,-4279.5 1333,-4233.5 931,-4233.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1067\" y=\"-4252.8\">locally_connected1d_3: LocallyConnected1D</text>\n",
       "<polyline fill=\"none\" points=\"1203,-4233.5 1203,-4279.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1231\" y=\"-4264.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1203,-4256.5 1259,-4256.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1231\" y=\"-4241.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1259,-4233.5 1259,-4279.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1296\" y=\"-4264.3\">(?, 87, 32)</text>\n",
       "<polyline fill=\"none\" points=\"1259,-4256.5 1333,-4256.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1296\" y=\"-4241.3\">(?, 43, 16)</text>\n",
       "</g>\n",
       "<!-- 2217984305080&#45;&gt;2217985048248 -->\n",
       "<g class=\"edge\" id=\"edge26\"><title>2217984305080-&gt;2217985048248</title>\n",
       "<path d=\"M1132,-4316.37C1132,-4308.15 1132,-4298.66 1132,-4289.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1135.5,-4289.61 1132,-4279.61 1128.5,-4289.61 1135.5,-4289.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2218037126536 -->\n",
       "<g class=\"node\" id=\"node28\"><title>2218037126536</title>\n",
       "<polygon fill=\"none\" points=\"534.5,-4150.5 534.5,-4196.5 813.5,-4196.5 813.5,-4150.5 534.5,-4150.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"606\" y=\"-4169.8\">dropout_240: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"677.5,-4150.5 677.5,-4196.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"705.5\" y=\"-4181.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"677.5,-4173.5 733.5,-4173.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"705.5\" y=\"-4158.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"733.5,-4150.5 733.5,-4196.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"773.5\" y=\"-4181.3\">(?, 341, 16)</text>\n",
       "<polyline fill=\"none\" points=\"733.5,-4173.5 813.5,-4173.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"773.5\" y=\"-4158.3\">(?, 341, 16)</text>\n",
       "</g>\n",
       "<!-- 2218037125360&#45;&gt;2218037126536 -->\n",
       "<g class=\"edge\" id=\"edge27\"><title>2218037125360-&gt;2218037126536</title>\n",
       "<path d=\"M674,-4233.37C674,-4225.15 674,-4215.66 674,-4206.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"677.5,-4206.61 674,-4196.61 670.5,-4206.61 677.5,-4206.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217985204064 -->\n",
       "<g class=\"node\" id=\"node29\"><title>2217985204064</title>\n",
       "<polygon fill=\"none\" points=\"959.5,-4150.5 959.5,-4196.5 1304.5,-4196.5 1304.5,-4150.5 959.5,-4150.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1067\" y=\"-4169.8\">max_pooling1d_30: MaxPooling1D</text>\n",
       "<polyline fill=\"none\" points=\"1174.5,-4150.5 1174.5,-4196.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1202.5\" y=\"-4181.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1174.5,-4173.5 1230.5,-4173.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1202.5\" y=\"-4158.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1230.5,-4150.5 1230.5,-4196.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1267.5\" y=\"-4181.3\">(?, 43, 16)</text>\n",
       "<polyline fill=\"none\" points=\"1230.5,-4173.5 1304.5,-4173.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1267.5\" y=\"-4158.3\">(?, 42, 16)</text>\n",
       "</g>\n",
       "<!-- 2217985048248&#45;&gt;2217985204064 -->\n",
       "<g class=\"edge\" id=\"edge28\"><title>2217985048248-&gt;2217985204064</title>\n",
       "<path d=\"M1132,-4233.37C1132,-4225.15 1132,-4215.66 1132,-4206.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1135.5,-4206.61 1132,-4196.61 1128.5,-4206.61 1135.5,-4206.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2218057684136 -->\n",
       "<g class=\"node\" id=\"node30\"><title>2218057684136</title>\n",
       "<polygon fill=\"none\" points=\"498.5,-4067.5 498.5,-4113.5 849.5,-4113.5 849.5,-4067.5 498.5,-4067.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"606\" y=\"-4086.8\">max_pooling1d_25: MaxPooling1D</text>\n",
       "<polyline fill=\"none\" points=\"713.5,-4067.5 713.5,-4113.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"741.5\" y=\"-4098.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"713.5,-4090.5 769.5,-4090.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"741.5\" y=\"-4075.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"769.5,-4067.5 769.5,-4113.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"809.5\" y=\"-4098.3\">(?, 341, 16)</text>\n",
       "<polyline fill=\"none\" points=\"769.5,-4090.5 849.5,-4090.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"809.5\" y=\"-4075.3\">(?, 340, 16)</text>\n",
       "</g>\n",
       "<!-- 2218037126536&#45;&gt;2218057684136 -->\n",
       "<g class=\"edge\" id=\"edge29\"><title>2218037126536-&gt;2218057684136</title>\n",
       "<path d=\"M674,-4150.37C674,-4142.15 674,-4132.66 674,-4123.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"677.5,-4123.61 674,-4113.61 670.5,-4123.61 677.5,-4123.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217985104304 -->\n",
       "<g class=\"node\" id=\"node31\"><title>2217985104304</title>\n",
       "<polygon fill=\"none\" points=\"986.5,-4067.5 986.5,-4113.5 1277.5,-4113.5 1277.5,-4067.5 986.5,-4067.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1067\" y=\"-4086.8\">activation_230: Activation</text>\n",
       "<polyline fill=\"none\" points=\"1147.5,-4067.5 1147.5,-4113.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1175.5\" y=\"-4098.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1147.5,-4090.5 1203.5,-4090.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1175.5\" y=\"-4075.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1203.5,-4067.5 1203.5,-4113.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1240.5\" y=\"-4098.3\">(?, 42, 16)</text>\n",
       "<polyline fill=\"none\" points=\"1203.5,-4090.5 1277.5,-4090.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1240.5\" y=\"-4075.3\">(?, 42, 16)</text>\n",
       "</g>\n",
       "<!-- 2217985204064&#45;&gt;2217985104304 -->\n",
       "<g class=\"edge\" id=\"edge30\"><title>2217985204064-&gt;2217985104304</title>\n",
       "<path d=\"M1132,-4150.37C1132,-4142.15 1132,-4132.66 1132,-4123.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1135.5,-4123.61 1132,-4113.61 1128.5,-4123.61 1135.5,-4123.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2218057684080 -->\n",
       "<g class=\"node\" id=\"node32\"><title>2218057684080</title>\n",
       "<polygon fill=\"none\" points=\"536,-3984.5 536,-4030.5 812,-4030.5 812,-3984.5 536,-3984.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"606\" y=\"-4003.8\">conv1d_103: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"676,-3984.5 676,-4030.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"704\" y=\"-4015.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"676,-4007.5 732,-4007.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"704\" y=\"-3992.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"732,-3984.5 732,-4030.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"772\" y=\"-4015.3\">(?, 340, 16)</text>\n",
       "<polyline fill=\"none\" points=\"732,-4007.5 812,-4007.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"772\" y=\"-3992.3\">(?, 336, 8)</text>\n",
       "</g>\n",
       "<!-- 2218057684136&#45;&gt;2218057684080 -->\n",
       "<g class=\"edge\" id=\"edge31\"><title>2218057684136-&gt;2218057684080</title>\n",
       "<path d=\"M674,-4067.37C674,-4059.15 674,-4049.66 674,-4040.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"677.5,-4040.61 674,-4030.61 670.5,-4040.61 677.5,-4040.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217985724656 -->\n",
       "<g class=\"node\" id=\"node33\"><title>2217985724656</title>\n",
       "<polygon fill=\"none\" points=\"995.5,-3984.5 995.5,-4030.5 1268.5,-4030.5 1268.5,-3984.5 995.5,-3984.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1067\" y=\"-4003.8\">dropout_245: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"1138.5,-3984.5 1138.5,-4030.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1166.5\" y=\"-4015.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1138.5,-4007.5 1194.5,-4007.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1166.5\" y=\"-3992.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1194.5,-3984.5 1194.5,-4030.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1231.5\" y=\"-4015.3\">(?, 42, 16)</text>\n",
       "<polyline fill=\"none\" points=\"1194.5,-4007.5 1268.5,-4007.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1231.5\" y=\"-3992.3\">(?, 42, 16)</text>\n",
       "</g>\n",
       "<!-- 2217985104304&#45;&gt;2217985724656 -->\n",
       "<g class=\"edge\" id=\"edge32\"><title>2217985104304-&gt;2217985724656</title>\n",
       "<path d=\"M1132,-4067.37C1132,-4059.15 1132,-4049.66 1132,-4040.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1135.5,-4040.61 1132,-4030.61 1128.5,-4040.61 1135.5,-4040.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2218057876200 -->\n",
       "<g class=\"node\" id=\"node34\"><title>2218057876200</title>\n",
       "<polygon fill=\"none\" points=\"472.5,-3901.5 472.5,-3947.5 875.5,-3947.5 875.5,-3901.5 472.5,-3901.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"609\" y=\"-3920.8\">batch_normalization_194: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"745.5,-3901.5 745.5,-3947.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"773.5\" y=\"-3932.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"745.5,-3924.5 801.5,-3924.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"773.5\" y=\"-3909.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"801.5,-3901.5 801.5,-3947.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"838.5\" y=\"-3932.3\">(?, 336, 8)</text>\n",
       "<polyline fill=\"none\" points=\"801.5,-3924.5 875.5,-3924.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"838.5\" y=\"-3909.3\">(?, 336, 8)</text>\n",
       "</g>\n",
       "<!-- 2218057684080&#45;&gt;2218057876200 -->\n",
       "<g class=\"edge\" id=\"edge33\"><title>2218057684080-&gt;2218057876200</title>\n",
       "<path d=\"M674,-3984.37C674,-3976.15 674,-3966.66 674,-3957.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"677.5,-3957.61 674,-3947.61 670.5,-3957.61 677.5,-3957.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217985763760 -->\n",
       "<g class=\"node\" id=\"node35\"><title>2217985763760</title>\n",
       "<polygon fill=\"none\" points=\"932,-3901.5 932,-3947.5 1334,-3947.5 1334,-3901.5 932,-3901.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1068\" y=\"-3920.8\">locally_connected1d_4: LocallyConnected1D</text>\n",
       "<polyline fill=\"none\" points=\"1204,-3901.5 1204,-3947.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1232\" y=\"-3932.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1204,-3924.5 1260,-3924.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1232\" y=\"-3909.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1260,-3901.5 1260,-3947.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1297\" y=\"-3932.3\">(?, 42, 16)</text>\n",
       "<polyline fill=\"none\" points=\"1260,-3924.5 1334,-3924.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1297\" y=\"-3909.3\">(?, 20, 8)</text>\n",
       "</g>\n",
       "<!-- 2217985724656&#45;&gt;2217985763760 -->\n",
       "<g class=\"edge\" id=\"edge34\"><title>2217985724656-&gt;2217985763760</title>\n",
       "<path d=\"M1132.27,-3984.37C1132.37,-3976.15 1132.49,-3966.66 1132.6,-3957.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1136.1,-3957.65 1132.73,-3947.61 1129.1,-3957.56 1136.1,-3957.65\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2218057832544 -->\n",
       "<g class=\"node\" id=\"node36\"><title>2218057832544</title>\n",
       "<polygon fill=\"none\" points=\"528.5,-3818.5 528.5,-3864.5 819.5,-3864.5 819.5,-3818.5 528.5,-3818.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"609\" y=\"-3837.8\">activation_226: Activation</text>\n",
       "<polyline fill=\"none\" points=\"689.5,-3818.5 689.5,-3864.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"717.5\" y=\"-3849.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"689.5,-3841.5 745.5,-3841.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"717.5\" y=\"-3826.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"745.5,-3818.5 745.5,-3864.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"782.5\" y=\"-3849.3\">(?, 336, 8)</text>\n",
       "<polyline fill=\"none\" points=\"745.5,-3841.5 819.5,-3841.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"782.5\" y=\"-3826.3\">(?, 336, 8)</text>\n",
       "</g>\n",
       "<!-- 2218057876200&#45;&gt;2218057832544 -->\n",
       "<g class=\"edge\" id=\"edge35\"><title>2218057876200-&gt;2218057832544</title>\n",
       "<path d=\"M674,-3901.37C674,-3893.15 674,-3883.66 674,-3874.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"677.5,-3874.61 674,-3864.61 670.5,-3874.61 677.5,-3874.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217985919688 -->\n",
       "<g class=\"node\" id=\"node37\"><title>2217985919688</title>\n",
       "<polygon fill=\"none\" points=\"964,-3818.5 964,-3864.5 1302,-3864.5 1302,-3818.5 964,-3818.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1071.5\" y=\"-3837.8\">max_pooling1d_31: MaxPooling1D</text>\n",
       "<polyline fill=\"none\" points=\"1179,-3818.5 1179,-3864.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1207\" y=\"-3849.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1179,-3841.5 1235,-3841.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1207\" y=\"-3826.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1235,-3818.5 1235,-3864.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1268.5\" y=\"-3849.3\">(?, 20, 8)</text>\n",
       "<polyline fill=\"none\" points=\"1235,-3841.5 1302,-3841.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1268.5\" y=\"-3826.3\">(?, 19, 8)</text>\n",
       "</g>\n",
       "<!-- 2217985763760&#45;&gt;2217985919688 -->\n",
       "<g class=\"edge\" id=\"edge36\"><title>2217985763760-&gt;2217985919688</title>\n",
       "<path d=\"M1133,-3901.37C1133,-3893.15 1133,-3883.66 1133,-3874.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1136.5,-3874.61 1133,-3864.61 1129.5,-3874.61 1136.5,-3874.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2218057831256 -->\n",
       "<g class=\"node\" id=\"node38\"><title>2218057831256</title>\n",
       "<polygon fill=\"none\" points=\"537.5,-3735.5 537.5,-3781.5 810.5,-3781.5 810.5,-3735.5 537.5,-3735.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"609\" y=\"-3754.8\">dropout_241: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"680.5,-3735.5 680.5,-3781.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"708.5\" y=\"-3766.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"680.5,-3758.5 736.5,-3758.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"708.5\" y=\"-3743.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"736.5,-3735.5 736.5,-3781.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"773.5\" y=\"-3766.3\">(?, 336, 8)</text>\n",
       "<polyline fill=\"none\" points=\"736.5,-3758.5 810.5,-3758.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"773.5\" y=\"-3743.3\">(?, 336, 8)</text>\n",
       "</g>\n",
       "<!-- 2218057832544&#45;&gt;2218057831256 -->\n",
       "<g class=\"edge\" id=\"edge37\"><title>2218057832544-&gt;2218057831256</title>\n",
       "<path d=\"M674,-3818.37C674,-3810.15 674,-3800.66 674,-3791.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"677.5,-3791.61 674,-3781.61 670.5,-3791.61 677.5,-3791.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217985808760 -->\n",
       "<g class=\"node\" id=\"node39\"><title>2217985808760</title>\n",
       "<polygon fill=\"none\" points=\"991,-3735.5 991,-3781.5 1275,-3781.5 1275,-3735.5 991,-3735.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1071.5\" y=\"-3754.8\">activation_231: Activation</text>\n",
       "<polyline fill=\"none\" points=\"1152,-3735.5 1152,-3781.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1180\" y=\"-3766.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1152,-3758.5 1208,-3758.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1180\" y=\"-3743.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1208,-3735.5 1208,-3781.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1241.5\" y=\"-3766.3\">(?, 19, 8)</text>\n",
       "<polyline fill=\"none\" points=\"1208,-3758.5 1275,-3758.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1241.5\" y=\"-3743.3\">(?, 19, 8)</text>\n",
       "</g>\n",
       "<!-- 2217985919688&#45;&gt;2217985808760 -->\n",
       "<g class=\"edge\" id=\"edge38\"><title>2217985919688-&gt;2217985808760</title>\n",
       "<path d=\"M1133,-3818.37C1133,-3810.15 1133,-3800.66 1133,-3791.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1136.5,-3791.61 1133,-3781.61 1129.5,-3791.61 1136.5,-3791.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2234629094872 -->\n",
       "<g class=\"node\" id=\"node40\"><title>2234629094872</title>\n",
       "<polygon fill=\"none\" points=\"501.5,-3652.5 501.5,-3698.5 846.5,-3698.5 846.5,-3652.5 501.5,-3652.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"609\" y=\"-3671.8\">max_pooling1d_26: MaxPooling1D</text>\n",
       "<polyline fill=\"none\" points=\"716.5,-3652.5 716.5,-3698.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"744.5\" y=\"-3683.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"716.5,-3675.5 772.5,-3675.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"744.5\" y=\"-3660.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"772.5,-3652.5 772.5,-3698.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"809.5\" y=\"-3683.3\">(?, 336, 8)</text>\n",
       "<polyline fill=\"none\" points=\"772.5,-3675.5 846.5,-3675.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"809.5\" y=\"-3660.3\">(?, 335, 8)</text>\n",
       "</g>\n",
       "<!-- 2218057831256&#45;&gt;2234629094872 -->\n",
       "<g class=\"edge\" id=\"edge39\"><title>2218057831256-&gt;2234629094872</title>\n",
       "<path d=\"M674,-3735.37C674,-3727.15 674,-3717.66 674,-3708.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"677.5,-3708.61 674,-3698.61 670.5,-3708.61 677.5,-3708.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217986146880 -->\n",
       "<g class=\"node\" id=\"node41\"><title>2217986146880</title>\n",
       "<polygon fill=\"none\" points=\"1000,-3652.5 1000,-3698.5 1266,-3698.5 1266,-3652.5 1000,-3652.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1071.5\" y=\"-3671.8\">dropout_246: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"1143,-3652.5 1143,-3698.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1171\" y=\"-3683.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1143,-3675.5 1199,-3675.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1171\" y=\"-3660.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1199,-3652.5 1199,-3698.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1232.5\" y=\"-3683.3\">(?, 19, 8)</text>\n",
       "<polyline fill=\"none\" points=\"1199,-3675.5 1266,-3675.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1232.5\" y=\"-3660.3\">(?, 19, 8)</text>\n",
       "</g>\n",
       "<!-- 2217985808760&#45;&gt;2217986146880 -->\n",
       "<g class=\"edge\" id=\"edge40\"><title>2217985808760-&gt;2217986146880</title>\n",
       "<path d=\"M1133,-3735.37C1133,-3727.15 1133,-3717.66 1133,-3708.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1136.5,-3708.61 1133,-3698.61 1129.5,-3708.61 1136.5,-3708.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217986261232 -->\n",
       "<g class=\"node\" id=\"node42\"><title>2217986261232</title>\n",
       "<polygon fill=\"none\" points=\"0,-3569.5 0,-3615.5 424,-3615.5 424,-3569.5 0,-3569.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"147\" y=\"-3588.8\">global_max_pooling1d_24: GlobalMaxPooling1D</text>\n",
       "<polyline fill=\"none\" points=\"294,-3569.5 294,-3615.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"322\" y=\"-3600.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"294,-3592.5 350,-3592.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"322\" y=\"-3577.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"350,-3569.5 350,-3615.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"387\" y=\"-3600.3\">(?, 335, 8)</text>\n",
       "<polyline fill=\"none\" points=\"350,-3592.5 424,-3592.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"387\" y=\"-3577.3\">(?, 8)</text>\n",
       "</g>\n",
       "<!-- 2234629094872&#45;&gt;2217986261232 -->\n",
       "<g class=\"edge\" id=\"edge41\"><title>2234629094872-&gt;2217986261232</title>\n",
       "<path d=\"M548.367,-3652.47C486.227,-3641.58 411.14,-3628.41 347.688,-3617.29\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"348.062,-3613.8 337.608,-3615.52 346.854,-3620.7 348.062,-3613.8\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217986293888 -->\n",
       "<g class=\"node\" id=\"node43\"><title>2217986293888</title>\n",
       "<polygon fill=\"none\" points=\"442,-3569.5 442,-3615.5 906,-3615.5 906,-3569.5 442,-3569.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"609\" y=\"-3588.8\">global_average_pooling1d_24: GlobalAveragePooling1D</text>\n",
       "<polyline fill=\"none\" points=\"776,-3569.5 776,-3615.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"804\" y=\"-3600.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"776,-3592.5 832,-3592.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"804\" y=\"-3577.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"832,-3569.5 832,-3615.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"869\" y=\"-3600.3\">(?, 335, 8)</text>\n",
       "<polyline fill=\"none\" points=\"832,-3592.5 906,-3592.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"869\" y=\"-3577.3\">(?, 8)</text>\n",
       "</g>\n",
       "<!-- 2234629094872&#45;&gt;2217986293888 -->\n",
       "<g class=\"edge\" id=\"edge42\"><title>2234629094872-&gt;2217986293888</title>\n",
       "<path d=\"M674,-3652.37C674,-3644.15 674,-3634.66 674,-3625.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"677.5,-3625.61 674,-3615.61 670.5,-3625.61 677.5,-3625.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217986406272 -->\n",
       "<g class=\"node\" id=\"node44\"><title>2217986406272</title>\n",
       "<polygon fill=\"none\" points=\"924.5,-3569.5 924.5,-3615.5 1341.5,-3615.5 1341.5,-3569.5 924.5,-3569.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1071.5\" y=\"-3588.8\">global_max_pooling1d_25: GlobalMaxPooling1D</text>\n",
       "<polyline fill=\"none\" points=\"1218.5,-3569.5 1218.5,-3615.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1246.5\" y=\"-3600.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1218.5,-3592.5 1274.5,-3592.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1246.5\" y=\"-3577.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1274.5,-3569.5 1274.5,-3615.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1308\" y=\"-3600.3\">(?, 19, 8)</text>\n",
       "<polyline fill=\"none\" points=\"1274.5,-3592.5 1341.5,-3592.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1308\" y=\"-3577.3\">(?, 8)</text>\n",
       "</g>\n",
       "<!-- 2217986146880&#45;&gt;2217986406272 -->\n",
       "<g class=\"edge\" id=\"edge43\"><title>2217986146880-&gt;2217986406272</title>\n",
       "<path d=\"M1133,-3652.37C1133,-3644.15 1133,-3634.66 1133,-3625.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1136.5,-3625.61 1133,-3615.61 1129.5,-3625.61 1136.5,-3625.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217986406048 -->\n",
       "<g class=\"node\" id=\"node45\"><title>2217986406048</title>\n",
       "<polygon fill=\"none\" points=\"1359.5,-3569.5 1359.5,-3615.5 1816.5,-3615.5 1816.5,-3569.5 1359.5,-3569.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1526.5\" y=\"-3588.8\">global_average_pooling1d_25: GlobalAveragePooling1D</text>\n",
       "<polyline fill=\"none\" points=\"1693.5,-3569.5 1693.5,-3615.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1721.5\" y=\"-3600.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1693.5,-3592.5 1749.5,-3592.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1721.5\" y=\"-3577.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1749.5,-3569.5 1749.5,-3615.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1783\" y=\"-3600.3\">(?, 19, 8)</text>\n",
       "<polyline fill=\"none\" points=\"1749.5,-3592.5 1816.5,-3592.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1783\" y=\"-3577.3\">(?, 8)</text>\n",
       "</g>\n",
       "<!-- 2217986146880&#45;&gt;2217986406048 -->\n",
       "<g class=\"edge\" id=\"edge44\"><title>2217986146880-&gt;2217986406048</title>\n",
       "<path d=\"M1256.73,-3652.47C1317.93,-3641.58 1391.88,-3628.41 1454.37,-3617.29\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1455.06,-3620.72 1464.29,-3615.52 1453.84,-3613.83 1455.06,-3620.72\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217986435448 -->\n",
       "<g class=\"node\" id=\"node46\"><title>2217986435448</title>\n",
       "<polygon fill=\"none\" points=\"703,-3486.5 703,-3532.5 1103,-3532.5 1103,-3486.5 703,-3486.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"792.5\" y=\"-3505.8\">concatenate_24: Concatenate</text>\n",
       "<polyline fill=\"none\" points=\"882,-3486.5 882,-3532.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"910\" y=\"-3517.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"882,-3509.5 938,-3509.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"910\" y=\"-3494.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"938,-3486.5 938,-3532.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1020.5\" y=\"-3517.3\">[(?, 8), (?, 8), (?, 8), (?, 8)]</text>\n",
       "<polyline fill=\"none\" points=\"938,-3509.5 1103,-3509.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1020.5\" y=\"-3494.3\">(?, 32)</text>\n",
       "</g>\n",
       "<!-- 2217986261232&#45;&gt;2217986435448 -->\n",
       "<g class=\"edge\" id=\"edge45\"><title>2217986261232-&gt;2217986435448</title>\n",
       "<path d=\"M399.906,-3569.47C494.473,-3558.39 609.086,-3544.95 705.018,-3533.71\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"705.607,-3537.16 715.131,-3532.52 704.792,-3530.21 705.607,-3537.16\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217986293888&#45;&gt;2217986435448 -->\n",
       "<g class=\"edge\" id=\"edge46\"><title>2217986293888-&gt;2217986435448</title>\n",
       "<path d=\"M736.273,-3569.47C765.553,-3559.12 800.632,-3546.71 831.043,-3535.95\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"832.479,-3539.16 840.74,-3532.52 830.145,-3532.56 832.479,-3539.16\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217986406272&#45;&gt;2217986435448 -->\n",
       "<g class=\"edge\" id=\"edge47\"><title>2217986406272-&gt;2217986435448</title>\n",
       "<path d=\"M1070.46,-3569.47C1041.05,-3559.12 1005.82,-3546.71 975.271,-3535.95\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"976.127,-3532.54 965.532,-3532.52 973.802,-3539.15 976.127,-3532.54\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217986406048&#45;&gt;2217986435448 -->\n",
       "<g class=\"edge\" id=\"edge48\"><title>2217986406048-&gt;2217986435448</title>\n",
       "<path d=\"M1401.73,-3569.47C1307.98,-3558.39 1194.36,-3544.95 1099.26,-3533.71\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1099.58,-3530.22 1089.24,-3532.52 1098.76,-3537.17 1099.58,-3530.22\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217986406944 -->\n",
       "<g class=\"node\" id=\"node47\"><title>2217986406944</title>\n",
       "<polygon fill=\"none\" points=\"786.5,-3403.5 786.5,-3449.5 1019.5,-3449.5 1019.5,-3403.5 786.5,-3403.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"845.5\" y=\"-3422.8\">dense_216: Dense</text>\n",
       "<polyline fill=\"none\" points=\"904.5,-3403.5 904.5,-3449.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"932.5\" y=\"-3434.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"904.5,-3426.5 960.5,-3426.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"932.5\" y=\"-3411.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"960.5,-3403.5 960.5,-3449.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"990\" y=\"-3434.3\">(?, 32)</text>\n",
       "<polyline fill=\"none\" points=\"960.5,-3426.5 1019.5,-3426.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"990\" y=\"-3411.3\">(?, 300)</text>\n",
       "</g>\n",
       "<!-- 2217986435448&#45;&gt;2217986406944 -->\n",
       "<g class=\"edge\" id=\"edge49\"><title>2217986435448-&gt;2217986406944</title>\n",
       "<path d=\"M903,-3486.37C903,-3478.15 903,-3468.66 903,-3459.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"906.5,-3459.61 903,-3449.61 899.5,-3459.61 906.5,-3459.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217986436904 -->\n",
       "<g class=\"node\" id=\"node48\"><title>2217986436904</title>\n",
       "<polygon fill=\"none\" points=\"709,-3320.5 709,-3366.5 1097,-3366.5 1097,-3320.5 709,-3320.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"845.5\" y=\"-3339.8\">batch_normalization_196: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"982,-3320.5 982,-3366.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1010\" y=\"-3351.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"982,-3343.5 1038,-3343.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1010\" y=\"-3328.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1038,-3320.5 1038,-3366.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1067.5\" y=\"-3351.3\">(?, 300)</text>\n",
       "<polyline fill=\"none\" points=\"1038,-3343.5 1097,-3343.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1067.5\" y=\"-3328.3\">(?, 300)</text>\n",
       "</g>\n",
       "<!-- 2217986406944&#45;&gt;2217986436904 -->\n",
       "<g class=\"edge\" id=\"edge50\"><title>2217986406944-&gt;2217986436904</title>\n",
       "<path d=\"M903,-3403.37C903,-3395.15 903,-3385.66 903,-3376.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"906.5,-3376.61 903,-3366.61 899.5,-3376.61 906.5,-3376.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217986488696 -->\n",
       "<g class=\"node\" id=\"node49\"><title>2217986488696</title>\n",
       "<polygon fill=\"none\" points=\"765,-3237.5 765,-3283.5 1041,-3283.5 1041,-3237.5 765,-3237.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"845.5\" y=\"-3256.8\">activation_232: Activation</text>\n",
       "<polyline fill=\"none\" points=\"926,-3237.5 926,-3283.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"954\" y=\"-3268.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"926,-3260.5 982,-3260.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"954\" y=\"-3245.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"982,-3237.5 982,-3283.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1011.5\" y=\"-3268.3\">(?, 300)</text>\n",
       "<polyline fill=\"none\" points=\"982,-3260.5 1041,-3260.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1011.5\" y=\"-3245.3\">(?, 300)</text>\n",
       "</g>\n",
       "<!-- 2217986436904&#45;&gt;2217986488696 -->\n",
       "<g class=\"edge\" id=\"edge51\"><title>2217986436904-&gt;2217986488696</title>\n",
       "<path d=\"M903,-3320.37C903,-3312.15 903,-3302.66 903,-3293.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"906.5,-3293.61 903,-3283.61 899.5,-3293.61 906.5,-3293.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217986487352 -->\n",
       "<g class=\"node\" id=\"node50\"><title>2217986487352</title>\n",
       "<polygon fill=\"none\" points=\"774,-3154.5 774,-3200.5 1032,-3200.5 1032,-3154.5 774,-3154.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"845.5\" y=\"-3173.8\">dropout_247: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"917,-3154.5 917,-3200.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"945\" y=\"-3185.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"917,-3177.5 973,-3177.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"945\" y=\"-3162.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"973,-3154.5 973,-3200.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1002.5\" y=\"-3185.3\">(?, 300)</text>\n",
       "<polyline fill=\"none\" points=\"973,-3177.5 1032,-3177.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1002.5\" y=\"-3162.3\">(?, 300)</text>\n",
       "</g>\n",
       "<!-- 2217986488696&#45;&gt;2217986487352 -->\n",
       "<g class=\"edge\" id=\"edge52\"><title>2217986488696-&gt;2217986487352</title>\n",
       "<path d=\"M903,-3237.37C903,-3229.15 903,-3219.66 903,-3210.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"906.5,-3210.61 903,-3200.61 899.5,-3210.61 906.5,-3210.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217986807120 -->\n",
       "<g class=\"node\" id=\"node51\"><title>2217986807120</title>\n",
       "<polygon fill=\"none\" points=\"786.5,-3071.5 786.5,-3117.5 1019.5,-3117.5 1019.5,-3071.5 786.5,-3071.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"845.5\" y=\"-3090.8\">dense_217: Dense</text>\n",
       "<polyline fill=\"none\" points=\"904.5,-3071.5 904.5,-3117.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"932.5\" y=\"-3102.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"904.5,-3094.5 960.5,-3094.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"932.5\" y=\"-3079.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"960.5,-3071.5 960.5,-3117.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"990\" y=\"-3102.3\">(?, 300)</text>\n",
       "<polyline fill=\"none\" points=\"960.5,-3094.5 1019.5,-3094.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"990\" y=\"-3079.3\">(?, 600)</text>\n",
       "</g>\n",
       "<!-- 2217986487352&#45;&gt;2217986807120 -->\n",
       "<g class=\"edge\" id=\"edge53\"><title>2217986487352-&gt;2217986807120</title>\n",
       "<path d=\"M903,-3154.37C903,-3146.15 903,-3136.66 903,-3127.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"906.5,-3127.61 903,-3117.61 899.5,-3127.61 906.5,-3127.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217986807344 -->\n",
       "<g class=\"node\" id=\"node52\"><title>2217986807344</title>\n",
       "<polygon fill=\"none\" points=\"709,-2988.5 709,-3034.5 1097,-3034.5 1097,-2988.5 709,-2988.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"845.5\" y=\"-3007.8\">batch_normalization_197: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"982,-2988.5 982,-3034.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1010\" y=\"-3019.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"982,-3011.5 1038,-3011.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1010\" y=\"-2996.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1038,-2988.5 1038,-3034.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1067.5\" y=\"-3019.3\">(?, 600)</text>\n",
       "<polyline fill=\"none\" points=\"1038,-3011.5 1097,-3011.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1067.5\" y=\"-2996.3\">(?, 600)</text>\n",
       "</g>\n",
       "<!-- 2217986807120&#45;&gt;2217986807344 -->\n",
       "<g class=\"edge\" id=\"edge54\"><title>2217986807120-&gt;2217986807344</title>\n",
       "<path d=\"M903,-3071.37C903,-3063.15 903,-3053.66 903,-3044.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"906.5,-3044.61 903,-3034.61 899.5,-3044.61 906.5,-3044.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217986955248 -->\n",
       "<g class=\"node\" id=\"node53\"><title>2217986955248</title>\n",
       "<polygon fill=\"none\" points=\"765,-2905.5 765,-2951.5 1041,-2951.5 1041,-2905.5 765,-2905.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"845.5\" y=\"-2924.8\">activation_233: Activation</text>\n",
       "<polyline fill=\"none\" points=\"926,-2905.5 926,-2951.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"954\" y=\"-2936.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"926,-2928.5 982,-2928.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"954\" y=\"-2913.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"982,-2905.5 982,-2951.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1011.5\" y=\"-2936.3\">(?, 600)</text>\n",
       "<polyline fill=\"none\" points=\"982,-2928.5 1041,-2928.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1011.5\" y=\"-2913.3\">(?, 600)</text>\n",
       "</g>\n",
       "<!-- 2217986807344&#45;&gt;2217986955248 -->\n",
       "<g class=\"edge\" id=\"edge55\"><title>2217986807344-&gt;2217986955248</title>\n",
       "<path d=\"M903,-2988.37C903,-2980.15 903,-2970.66 903,-2961.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"906.5,-2961.61 903,-2951.61 899.5,-2961.61 906.5,-2961.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217987028080 -->\n",
       "<g class=\"node\" id=\"node54\"><title>2217987028080</title>\n",
       "<polygon fill=\"none\" points=\"774,-2822.5 774,-2868.5 1032,-2868.5 1032,-2822.5 774,-2822.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"845.5\" y=\"-2841.8\">dropout_248: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"917,-2822.5 917,-2868.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"945\" y=\"-2853.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"917,-2845.5 973,-2845.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"945\" y=\"-2830.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"973,-2822.5 973,-2868.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1002.5\" y=\"-2853.3\">(?, 600)</text>\n",
       "<polyline fill=\"none\" points=\"973,-2845.5 1032,-2845.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1002.5\" y=\"-2830.3\">(?, 600)</text>\n",
       "</g>\n",
       "<!-- 2217986955248&#45;&gt;2217987028080 -->\n",
       "<g class=\"edge\" id=\"edge56\"><title>2217986955248-&gt;2217987028080</title>\n",
       "<path d=\"M903,-2905.37C903,-2897.15 903,-2887.66 903,-2878.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"906.5,-2878.61 903,-2868.61 899.5,-2878.61 906.5,-2878.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217986514504 -->\n",
       "<g class=\"node\" id=\"node55\"><title>2217986514504</title>\n",
       "<polygon fill=\"none\" points=\"783,-2739.5 783,-2785.5 1023,-2785.5 1023,-2739.5 783,-2739.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"842\" y=\"-2758.8\">dense_218: Dense</text>\n",
       "<polyline fill=\"none\" points=\"901,-2739.5 901,-2785.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"929\" y=\"-2770.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"901,-2762.5 957,-2762.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"929\" y=\"-2747.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"957,-2739.5 957,-2785.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"990\" y=\"-2770.3\">(?, 600)</text>\n",
       "<polyline fill=\"none\" points=\"957,-2762.5 1023,-2762.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"990\" y=\"-2747.3\">(?, 1200)</text>\n",
       "</g>\n",
       "<!-- 2217987028080&#45;&gt;2217986514504 -->\n",
       "<g class=\"edge\" id=\"edge57\"><title>2217987028080-&gt;2217986514504</title>\n",
       "<path d=\"M903,-2822.37C903,-2814.15 903,-2804.66 903,-2795.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"906.5,-2795.61 903,-2785.61 899.5,-2795.61 906.5,-2795.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217987277824 -->\n",
       "<g class=\"node\" id=\"node56\"><title>2217987277824</title>\n",
       "<polygon fill=\"none\" points=\"705.5,-2656.5 705.5,-2702.5 1100.5,-2702.5 1100.5,-2656.5 705.5,-2656.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"842\" y=\"-2675.8\">batch_normalization_198: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"978.5,-2656.5 978.5,-2702.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1006.5\" y=\"-2687.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"978.5,-2679.5 1034.5,-2679.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1006.5\" y=\"-2664.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1034.5,-2656.5 1034.5,-2702.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1067.5\" y=\"-2687.3\">(?, 1200)</text>\n",
       "<polyline fill=\"none\" points=\"1034.5,-2679.5 1100.5,-2679.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1067.5\" y=\"-2664.3\">(?, 1200)</text>\n",
       "</g>\n",
       "<!-- 2217986514504&#45;&gt;2217987277824 -->\n",
       "<g class=\"edge\" id=\"edge58\"><title>2217986514504-&gt;2217987277824</title>\n",
       "<path d=\"M903,-2739.37C903,-2731.15 903,-2721.66 903,-2712.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"906.5,-2712.61 903,-2702.61 899.5,-2712.61 906.5,-2712.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217987430776 -->\n",
       "<g class=\"node\" id=\"node57\"><title>2217987430776</title>\n",
       "<polygon fill=\"none\" points=\"761.5,-2573.5 761.5,-2619.5 1044.5,-2619.5 1044.5,-2573.5 761.5,-2573.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"842\" y=\"-2592.8\">activation_234: Activation</text>\n",
       "<polyline fill=\"none\" points=\"922.5,-2573.5 922.5,-2619.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"950.5\" y=\"-2604.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"922.5,-2596.5 978.5,-2596.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"950.5\" y=\"-2581.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"978.5,-2573.5 978.5,-2619.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1011.5\" y=\"-2604.3\">(?, 1200)</text>\n",
       "<polyline fill=\"none\" points=\"978.5,-2596.5 1044.5,-2596.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1011.5\" y=\"-2581.3\">(?, 1200)</text>\n",
       "</g>\n",
       "<!-- 2217987277824&#45;&gt;2217987430776 -->\n",
       "<g class=\"edge\" id=\"edge59\"><title>2217987277824-&gt;2217987430776</title>\n",
       "<path d=\"M903,-2656.37C903,-2648.15 903,-2638.66 903,-2629.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"906.5,-2629.61 903,-2619.61 899.5,-2629.61 906.5,-2629.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217987429040 -->\n",
       "<g class=\"node\" id=\"node58\"><title>2217987429040</title>\n",
       "<polygon fill=\"none\" points=\"770.5,-2490.5 770.5,-2536.5 1035.5,-2536.5 1035.5,-2490.5 770.5,-2490.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"842\" y=\"-2509.8\">dropout_249: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"913.5,-2490.5 913.5,-2536.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"941.5\" y=\"-2521.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"913.5,-2513.5 969.5,-2513.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"941.5\" y=\"-2498.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"969.5,-2490.5 969.5,-2536.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1002.5\" y=\"-2521.3\">(?, 1200)</text>\n",
       "<polyline fill=\"none\" points=\"969.5,-2513.5 1035.5,-2513.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1002.5\" y=\"-2498.3\">(?, 1200)</text>\n",
       "</g>\n",
       "<!-- 2217987430776&#45;&gt;2217987429040 -->\n",
       "<g class=\"edge\" id=\"edge60\"><title>2217987430776-&gt;2217987429040</title>\n",
       "<path d=\"M903,-2573.37C903,-2565.15 903,-2555.66 903,-2546.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"906.5,-2546.61 903,-2536.61 899.5,-2546.61 906.5,-2546.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217987718784 -->\n",
       "<g class=\"node\" id=\"node59\"><title>2217987718784</title>\n",
       "<polygon fill=\"none\" points=\"783,-2407.5 783,-2453.5 1023,-2453.5 1023,-2407.5 783,-2407.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"842\" y=\"-2426.8\">dense_219: Dense</text>\n",
       "<polyline fill=\"none\" points=\"901,-2407.5 901,-2453.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"929\" y=\"-2438.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"901,-2430.5 957,-2430.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"929\" y=\"-2415.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"957,-2407.5 957,-2453.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"990\" y=\"-2438.3\">(?, 1200)</text>\n",
       "<polyline fill=\"none\" points=\"957,-2430.5 1023,-2430.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"990\" y=\"-2415.3\">(?, 600)</text>\n",
       "</g>\n",
       "<!-- 2217987429040&#45;&gt;2217987718784 -->\n",
       "<g class=\"edge\" id=\"edge61\"><title>2217987429040-&gt;2217987718784</title>\n",
       "<path d=\"M903,-2490.37C903,-2482.15 903,-2472.66 903,-2463.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"906.5,-2463.61 903,-2453.61 899.5,-2463.61 906.5,-2463.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217987850136 -->\n",
       "<g class=\"node\" id=\"node60\"><title>2217987850136</title>\n",
       "<polygon fill=\"none\" points=\"709,-2324.5 709,-2370.5 1097,-2370.5 1097,-2324.5 709,-2324.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"845.5\" y=\"-2343.8\">batch_normalization_199: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"982,-2324.5 982,-2370.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1010\" y=\"-2355.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"982,-2347.5 1038,-2347.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1010\" y=\"-2332.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1038,-2324.5 1038,-2370.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1067.5\" y=\"-2355.3\">(?, 600)</text>\n",
       "<polyline fill=\"none\" points=\"1038,-2347.5 1097,-2347.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1067.5\" y=\"-2332.3\">(?, 600)</text>\n",
       "</g>\n",
       "<!-- 2217987718784&#45;&gt;2217987850136 -->\n",
       "<g class=\"edge\" id=\"edge62\"><title>2217987718784-&gt;2217987850136</title>\n",
       "<path d=\"M903,-2407.37C903,-2399.15 903,-2389.66 903,-2380.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"906.5,-2380.61 903,-2370.61 899.5,-2380.61 906.5,-2380.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217987848232 -->\n",
       "<g class=\"node\" id=\"node61\"><title>2217987848232</title>\n",
       "<polygon fill=\"none\" points=\"765,-2241.5 765,-2287.5 1041,-2287.5 1041,-2241.5 765,-2241.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"845.5\" y=\"-2260.8\">activation_235: Activation</text>\n",
       "<polyline fill=\"none\" points=\"926,-2241.5 926,-2287.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"954\" y=\"-2272.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"926,-2264.5 982,-2264.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"954\" y=\"-2249.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"982,-2241.5 982,-2287.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1011.5\" y=\"-2272.3\">(?, 600)</text>\n",
       "<polyline fill=\"none\" points=\"982,-2264.5 1041,-2264.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1011.5\" y=\"-2249.3\">(?, 600)</text>\n",
       "</g>\n",
       "<!-- 2217987850136&#45;&gt;2217987848232 -->\n",
       "<g class=\"edge\" id=\"edge63\"><title>2217987850136-&gt;2217987848232</title>\n",
       "<path d=\"M903,-2324.37C903,-2316.15 903,-2306.66 903,-2297.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"906.5,-2297.61 903,-2287.61 899.5,-2297.61 906.5,-2297.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217987892224 -->\n",
       "<g class=\"node\" id=\"node62\"><title>2217987892224</title>\n",
       "<polygon fill=\"none\" points=\"774,-2158.5 774,-2204.5 1032,-2204.5 1032,-2158.5 774,-2158.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"845.5\" y=\"-2177.8\">dropout_250: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"917,-2158.5 917,-2204.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"945\" y=\"-2189.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"917,-2181.5 973,-2181.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"945\" y=\"-2166.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"973,-2158.5 973,-2204.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1002.5\" y=\"-2189.3\">(?, 600)</text>\n",
       "<polyline fill=\"none\" points=\"973,-2181.5 1032,-2181.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1002.5\" y=\"-2166.3\">(?, 600)</text>\n",
       "</g>\n",
       "<!-- 2217987848232&#45;&gt;2217987892224 -->\n",
       "<g class=\"edge\" id=\"edge64\"><title>2217987848232-&gt;2217987892224</title>\n",
       "<path d=\"M903,-2241.37C903,-2233.15 903,-2223.66 903,-2214.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"906.5,-2214.61 903,-2204.61 899.5,-2214.61 906.5,-2214.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217988181744 -->\n",
       "<g class=\"node\" id=\"node63\"><title>2217988181744</title>\n",
       "<polygon fill=\"none\" points=\"786.5,-2075.5 786.5,-2121.5 1019.5,-2121.5 1019.5,-2075.5 786.5,-2075.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"845.5\" y=\"-2094.8\">dense_220: Dense</text>\n",
       "<polyline fill=\"none\" points=\"904.5,-2075.5 904.5,-2121.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"932.5\" y=\"-2106.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"904.5,-2098.5 960.5,-2098.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"932.5\" y=\"-2083.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"960.5,-2075.5 960.5,-2121.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"990\" y=\"-2106.3\">(?, 600)</text>\n",
       "<polyline fill=\"none\" points=\"960.5,-2098.5 1019.5,-2098.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"990\" y=\"-2083.3\">(?, 300)</text>\n",
       "</g>\n",
       "<!-- 2217987892224&#45;&gt;2217988181744 -->\n",
       "<g class=\"edge\" id=\"edge65\"><title>2217987892224-&gt;2217988181744</title>\n",
       "<path d=\"M903,-2158.37C903,-2150.15 903,-2140.66 903,-2131.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"906.5,-2131.61 903,-2121.61 899.5,-2131.61 906.5,-2131.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217988325328 -->\n",
       "<g class=\"node\" id=\"node64\"><title>2217988325328</title>\n",
       "<polygon fill=\"none\" points=\"709,-1992.5 709,-2038.5 1097,-2038.5 1097,-1992.5 709,-1992.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"845.5\" y=\"-2011.8\">batch_normalization_200: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"982,-1992.5 982,-2038.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1010\" y=\"-2023.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"982,-2015.5 1038,-2015.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1010\" y=\"-2000.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1038,-1992.5 1038,-2038.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1067.5\" y=\"-2023.3\">(?, 300)</text>\n",
       "<polyline fill=\"none\" points=\"1038,-2015.5 1097,-2015.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1067.5\" y=\"-2000.3\">(?, 300)</text>\n",
       "</g>\n",
       "<!-- 2217988181744&#45;&gt;2217988325328 -->\n",
       "<g class=\"edge\" id=\"edge66\"><title>2217988181744-&gt;2217988325328</title>\n",
       "<path d=\"M903,-2075.37C903,-2067.15 903,-2057.66 903,-2048.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"906.5,-2048.61 903,-2038.61 899.5,-2048.61 906.5,-2048.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217988325104 -->\n",
       "<g class=\"node\" id=\"node65\"><title>2217988325104</title>\n",
       "<polygon fill=\"none\" points=\"765,-1909.5 765,-1955.5 1041,-1955.5 1041,-1909.5 765,-1909.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"845.5\" y=\"-1928.8\">activation_236: Activation</text>\n",
       "<polyline fill=\"none\" points=\"926,-1909.5 926,-1955.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"954\" y=\"-1940.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"926,-1932.5 982,-1932.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"954\" y=\"-1917.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"982,-1909.5 982,-1955.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1011.5\" y=\"-1940.3\">(?, 300)</text>\n",
       "<polyline fill=\"none\" points=\"982,-1932.5 1041,-1932.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1011.5\" y=\"-1917.3\">(?, 300)</text>\n",
       "</g>\n",
       "<!-- 2217988325328&#45;&gt;2217988325104 -->\n",
       "<g class=\"edge\" id=\"edge67\"><title>2217988325328-&gt;2217988325104</title>\n",
       "<path d=\"M903,-1992.37C903,-1984.15 903,-1974.66 903,-1965.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"906.5,-1965.61 903,-1955.61 899.5,-1965.61 906.5,-1965.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217988366968 -->\n",
       "<g class=\"node\" id=\"node66\"><title>2217988366968</title>\n",
       "<polygon fill=\"none\" points=\"774,-1826.5 774,-1872.5 1032,-1872.5 1032,-1826.5 774,-1826.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"845.5\" y=\"-1845.8\">dropout_251: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"917,-1826.5 917,-1872.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"945\" y=\"-1857.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"917,-1849.5 973,-1849.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"945\" y=\"-1834.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"973,-1826.5 973,-1872.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1002.5\" y=\"-1857.3\">(?, 300)</text>\n",
       "<polyline fill=\"none\" points=\"973,-1849.5 1032,-1849.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1002.5\" y=\"-1834.3\">(?, 300)</text>\n",
       "</g>\n",
       "<!-- 2217988325104&#45;&gt;2217988366968 -->\n",
       "<g class=\"edge\" id=\"edge68\"><title>2217988325104-&gt;2217988366968</title>\n",
       "<path d=\"M903,-1909.37C903,-1901.15 903,-1891.66 903,-1882.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"906.5,-1882.61 903,-1872.61 899.5,-1882.61 906.5,-1882.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217988691280 -->\n",
       "<g class=\"node\" id=\"node67\"><title>2217988691280</title>\n",
       "<polygon fill=\"none\" points=\"786.5,-1743.5 786.5,-1789.5 1019.5,-1789.5 1019.5,-1743.5 786.5,-1743.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"845.5\" y=\"-1762.8\">dense_221: Dense</text>\n",
       "<polyline fill=\"none\" points=\"904.5,-1743.5 904.5,-1789.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"932.5\" y=\"-1774.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"904.5,-1766.5 960.5,-1766.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"932.5\" y=\"-1751.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"960.5,-1743.5 960.5,-1789.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"990\" y=\"-1774.3\">(?, 300)</text>\n",
       "<polyline fill=\"none\" points=\"960.5,-1766.5 1019.5,-1766.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"990\" y=\"-1751.3\">(?, 130)</text>\n",
       "</g>\n",
       "<!-- 2217988366968&#45;&gt;2217988691280 -->\n",
       "<g class=\"edge\" id=\"edge69\"><title>2217988366968-&gt;2217988691280</title>\n",
       "<path d=\"M903,-1826.37C903,-1818.15 903,-1808.66 903,-1799.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"906.5,-1799.61 903,-1789.61 899.5,-1799.61 906.5,-1799.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217988800240 -->\n",
       "<g class=\"node\" id=\"node68\"><title>2217988800240</title>\n",
       "<polygon fill=\"none\" points=\"709,-1660.5 709,-1706.5 1097,-1706.5 1097,-1660.5 709,-1660.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"845.5\" y=\"-1679.8\">batch_normalization_201: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"982,-1660.5 982,-1706.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1010\" y=\"-1691.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"982,-1683.5 1038,-1683.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1010\" y=\"-1668.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1038,-1660.5 1038,-1706.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1067.5\" y=\"-1691.3\">(?, 130)</text>\n",
       "<polyline fill=\"none\" points=\"1038,-1683.5 1097,-1683.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1067.5\" y=\"-1668.3\">(?, 130)</text>\n",
       "</g>\n",
       "<!-- 2217988691280&#45;&gt;2217988800240 -->\n",
       "<g class=\"edge\" id=\"edge70\"><title>2217988691280-&gt;2217988800240</title>\n",
       "<path d=\"M903,-1743.37C903,-1735.15 903,-1725.66 903,-1716.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"906.5,-1716.61 903,-1706.61 899.5,-1716.61 906.5,-1716.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217988798056 -->\n",
       "<g class=\"node\" id=\"node69\"><title>2217988798056</title>\n",
       "<polygon fill=\"none\" points=\"765,-1577.5 765,-1623.5 1041,-1623.5 1041,-1577.5 765,-1577.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"845.5\" y=\"-1596.8\">activation_237: Activation</text>\n",
       "<polyline fill=\"none\" points=\"926,-1577.5 926,-1623.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"954\" y=\"-1608.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"926,-1600.5 982,-1600.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"954\" y=\"-1585.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"982,-1577.5 982,-1623.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1011.5\" y=\"-1608.3\">(?, 130)</text>\n",
       "<polyline fill=\"none\" points=\"982,-1600.5 1041,-1600.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1011.5\" y=\"-1585.3\">(?, 130)</text>\n",
       "</g>\n",
       "<!-- 2217988800240&#45;&gt;2217988798056 -->\n",
       "<g class=\"edge\" id=\"edge71\"><title>2217988800240-&gt;2217988798056</title>\n",
       "<path d=\"M903,-1660.37C903,-1652.15 903,-1642.66 903,-1633.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"906.5,-1633.61 903,-1623.61 899.5,-1633.61 906.5,-1633.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217988799736 -->\n",
       "<g class=\"node\" id=\"node70\"><title>2217988799736</title>\n",
       "<polygon fill=\"none\" points=\"774,-1494.5 774,-1540.5 1032,-1540.5 1032,-1494.5 774,-1494.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"845.5\" y=\"-1513.8\">dropout_252: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"917,-1494.5 917,-1540.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"945\" y=\"-1525.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"917,-1517.5 973,-1517.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"945\" y=\"-1502.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"973,-1494.5 973,-1540.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1002.5\" y=\"-1525.3\">(?, 130)</text>\n",
       "<polyline fill=\"none\" points=\"973,-1517.5 1032,-1517.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1002.5\" y=\"-1502.3\">(?, 130)</text>\n",
       "</g>\n",
       "<!-- 2217988798056&#45;&gt;2217988799736 -->\n",
       "<g class=\"edge\" id=\"edge72\"><title>2217988798056-&gt;2217988799736</title>\n",
       "<path d=\"M903,-1577.37C903,-1569.15 903,-1559.66 903,-1550.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"906.5,-1550.61 903,-1540.61 899.5,-1550.61 906.5,-1550.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217989222128 -->\n",
       "<g class=\"node\" id=\"node71\"><title>2217989222128</title>\n",
       "<polygon fill=\"none\" points=\"786.5,-1411.5 786.5,-1457.5 1019.5,-1457.5 1019.5,-1411.5 786.5,-1411.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"845.5\" y=\"-1430.8\">dense_222: Dense</text>\n",
       "<polyline fill=\"none\" points=\"904.5,-1411.5 904.5,-1457.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"932.5\" y=\"-1442.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"904.5,-1434.5 960.5,-1434.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"932.5\" y=\"-1419.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"960.5,-1411.5 960.5,-1457.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"990\" y=\"-1442.3\">(?, 130)</text>\n",
       "<polyline fill=\"none\" points=\"960.5,-1434.5 1019.5,-1434.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"990\" y=\"-1419.3\">(?, 70)</text>\n",
       "</g>\n",
       "<!-- 2217988799736&#45;&gt;2217989222128 -->\n",
       "<g class=\"edge\" id=\"edge73\"><title>2217988799736-&gt;2217989222128</title>\n",
       "<path d=\"M903,-1494.37C903,-1486.15 903,-1476.66 903,-1467.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"906.5,-1467.61 903,-1457.61 899.5,-1467.61 906.5,-1467.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217989271336 -->\n",
       "<g class=\"node\" id=\"node72\"><title>2217989271336</title>\n",
       "<polygon fill=\"none\" points=\"712,-1328.5 712,-1374.5 1094,-1374.5 1094,-1328.5 712,-1328.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"848.5\" y=\"-1347.8\">batch_normalization_202: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"985,-1328.5 985,-1374.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1013\" y=\"-1359.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"985,-1351.5 1041,-1351.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1013\" y=\"-1336.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1041,-1328.5 1041,-1374.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1067.5\" y=\"-1359.3\">(?, 70)</text>\n",
       "<polyline fill=\"none\" points=\"1041,-1351.5 1094,-1351.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1067.5\" y=\"-1336.3\">(?, 70)</text>\n",
       "</g>\n",
       "<!-- 2217989222128&#45;&gt;2217989271336 -->\n",
       "<g class=\"edge\" id=\"edge74\"><title>2217989222128-&gt;2217989271336</title>\n",
       "<path d=\"M903,-1411.37C903,-1403.15 903,-1393.66 903,-1384.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"906.5,-1384.61 903,-1374.61 899.5,-1384.61 906.5,-1384.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217989318416 -->\n",
       "<g class=\"node\" id=\"node73\"><title>2217989318416</title>\n",
       "<polygon fill=\"none\" points=\"768,-1245.5 768,-1291.5 1038,-1291.5 1038,-1245.5 768,-1245.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"848.5\" y=\"-1264.8\">activation_238: Activation</text>\n",
       "<polyline fill=\"none\" points=\"929,-1245.5 929,-1291.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"957\" y=\"-1276.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"929,-1268.5 985,-1268.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"957\" y=\"-1253.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"985,-1245.5 985,-1291.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1011.5\" y=\"-1276.3\">(?, 70)</text>\n",
       "<polyline fill=\"none\" points=\"985,-1268.5 1038,-1268.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1011.5\" y=\"-1253.3\">(?, 70)</text>\n",
       "</g>\n",
       "<!-- 2217989271336&#45;&gt;2217989318416 -->\n",
       "<g class=\"edge\" id=\"edge75\"><title>2217989271336-&gt;2217989318416</title>\n",
       "<path d=\"M903,-1328.37C903,-1320.15 903,-1310.66 903,-1301.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"906.5,-1301.61 903,-1291.61 899.5,-1301.61 906.5,-1301.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217989268536 -->\n",
       "<g class=\"node\" id=\"node74\"><title>2217989268536</title>\n",
       "<polygon fill=\"none\" points=\"777,-1162.5 777,-1208.5 1029,-1208.5 1029,-1162.5 777,-1162.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"848.5\" y=\"-1181.8\">dropout_253: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"920,-1162.5 920,-1208.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"948\" y=\"-1193.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"920,-1185.5 976,-1185.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"948\" y=\"-1170.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"976,-1162.5 976,-1208.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1002.5\" y=\"-1193.3\">(?, 70)</text>\n",
       "<polyline fill=\"none\" points=\"976,-1185.5 1029,-1185.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1002.5\" y=\"-1170.3\">(?, 70)</text>\n",
       "</g>\n",
       "<!-- 2217989318416&#45;&gt;2217989268536 -->\n",
       "<g class=\"edge\" id=\"edge76\"><title>2217989318416-&gt;2217989268536</title>\n",
       "<path d=\"M903,-1245.37C903,-1237.15 903,-1227.66 903,-1218.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"906.5,-1218.61 903,-1208.61 899.5,-1218.61 906.5,-1218.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217989640488 -->\n",
       "<g class=\"node\" id=\"node75\"><title>2217989640488</title>\n",
       "<polygon fill=\"none\" points=\"789.5,-1079.5 789.5,-1125.5 1016.5,-1125.5 1016.5,-1079.5 789.5,-1079.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"848.5\" y=\"-1098.8\">dense_223: Dense</text>\n",
       "<polyline fill=\"none\" points=\"907.5,-1079.5 907.5,-1125.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"935.5\" y=\"-1110.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"907.5,-1102.5 963.5,-1102.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"935.5\" y=\"-1087.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"963.5,-1079.5 963.5,-1125.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"990\" y=\"-1110.3\">(?, 70)</text>\n",
       "<polyline fill=\"none\" points=\"963.5,-1102.5 1016.5,-1102.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"990\" y=\"-1087.3\">(?, 35)</text>\n",
       "</g>\n",
       "<!-- 2217989268536&#45;&gt;2217989640488 -->\n",
       "<g class=\"edge\" id=\"edge77\"><title>2217989268536-&gt;2217989640488</title>\n",
       "<path d=\"M903,-1162.37C903,-1154.15 903,-1144.66 903,-1135.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"906.5,-1135.61 903,-1125.61 899.5,-1135.61 906.5,-1135.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217989701472 -->\n",
       "<g class=\"node\" id=\"node76\"><title>2217989701472</title>\n",
       "<polygon fill=\"none\" points=\"712,-996.5 712,-1042.5 1094,-1042.5 1094,-996.5 712,-996.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"848.5\" y=\"-1015.8\">batch_normalization_203: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"985,-996.5 985,-1042.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1013\" y=\"-1027.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"985,-1019.5 1041,-1019.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1013\" y=\"-1004.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1041,-996.5 1041,-1042.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1067.5\" y=\"-1027.3\">(?, 35)</text>\n",
       "<polyline fill=\"none\" points=\"1041,-1019.5 1094,-1019.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1067.5\" y=\"-1004.3\">(?, 35)</text>\n",
       "</g>\n",
       "<!-- 2217989640488&#45;&gt;2217989701472 -->\n",
       "<g class=\"edge\" id=\"edge78\"><title>2217989640488-&gt;2217989701472</title>\n",
       "<path d=\"M903,-1079.37C903,-1071.15 903,-1061.66 903,-1052.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"906.5,-1052.61 903,-1042.61 899.5,-1052.61 906.5,-1052.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217989749056 -->\n",
       "<g class=\"node\" id=\"node77\"><title>2217989749056</title>\n",
       "<polygon fill=\"none\" points=\"768,-913.5 768,-959.5 1038,-959.5 1038,-913.5 768,-913.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"848.5\" y=\"-932.8\">activation_239: Activation</text>\n",
       "<polyline fill=\"none\" points=\"929,-913.5 929,-959.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"957\" y=\"-944.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"929,-936.5 985,-936.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"957\" y=\"-921.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"985,-913.5 985,-959.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1011.5\" y=\"-944.3\">(?, 35)</text>\n",
       "<polyline fill=\"none\" points=\"985,-936.5 1038,-936.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1011.5\" y=\"-921.3\">(?, 35)</text>\n",
       "</g>\n",
       "<!-- 2217989701472&#45;&gt;2217989749056 -->\n",
       "<g class=\"edge\" id=\"edge79\"><title>2217989701472-&gt;2217989749056</title>\n",
       "<path d=\"M903,-996.366C903,-988.152 903,-978.658 903,-969.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"906.5,-969.607 903,-959.607 899.5,-969.607 906.5,-969.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217989750120 -->\n",
       "<g class=\"node\" id=\"node78\"><title>2217989750120</title>\n",
       "<polygon fill=\"none\" points=\"777,-830.5 777,-876.5 1029,-876.5 1029,-830.5 777,-830.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"848.5\" y=\"-849.8\">dropout_254: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"920,-830.5 920,-876.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"948\" y=\"-861.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"920,-853.5 976,-853.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"948\" y=\"-838.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"976,-830.5 976,-876.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1002.5\" y=\"-861.3\">(?, 35)</text>\n",
       "<polyline fill=\"none\" points=\"976,-853.5 1029,-853.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1002.5\" y=\"-838.3\">(?, 35)</text>\n",
       "</g>\n",
       "<!-- 2217989749056&#45;&gt;2217989750120 -->\n",
       "<g class=\"edge\" id=\"edge80\"><title>2217989749056-&gt;2217989750120</title>\n",
       "<path d=\"M903,-913.366C903,-905.152 903,-895.658 903,-886.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"906.5,-886.607 903,-876.607 899.5,-886.607 906.5,-886.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217990094920 -->\n",
       "<g class=\"node\" id=\"node79\"><title>2217990094920</title>\n",
       "<polygon fill=\"none\" points=\"789.5,-747.5 789.5,-793.5 1016.5,-793.5 1016.5,-747.5 789.5,-747.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"848.5\" y=\"-766.8\">dense_224: Dense</text>\n",
       "<polyline fill=\"none\" points=\"907.5,-747.5 907.5,-793.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"935.5\" y=\"-778.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"907.5,-770.5 963.5,-770.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"935.5\" y=\"-755.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"963.5,-747.5 963.5,-793.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"990\" y=\"-778.3\">(?, 35)</text>\n",
       "<polyline fill=\"none\" points=\"963.5,-770.5 1016.5,-770.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"990\" y=\"-755.3\">(?, 15)</text>\n",
       "</g>\n",
       "<!-- 2217989750120&#45;&gt;2217990094920 -->\n",
       "<g class=\"edge\" id=\"edge81\"><title>2217989750120-&gt;2217990094920</title>\n",
       "<path d=\"M903,-830.366C903,-822.152 903,-812.658 903,-803.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"906.5,-803.607 903,-793.607 899.5,-803.607 906.5,-803.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217990167296 -->\n",
       "<g class=\"node\" id=\"node80\"><title>2217990167296</title>\n",
       "<polygon fill=\"none\" points=\"712,-664.5 712,-710.5 1094,-710.5 1094,-664.5 712,-664.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"848.5\" y=\"-683.8\">batch_normalization_204: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"985,-664.5 985,-710.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1013\" y=\"-695.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"985,-687.5 1041,-687.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1013\" y=\"-672.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1041,-664.5 1041,-710.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1067.5\" y=\"-695.3\">(?, 15)</text>\n",
       "<polyline fill=\"none\" points=\"1041,-687.5 1094,-687.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1067.5\" y=\"-672.3\">(?, 15)</text>\n",
       "</g>\n",
       "<!-- 2217990094920&#45;&gt;2217990167296 -->\n",
       "<g class=\"edge\" id=\"edge82\"><title>2217990094920-&gt;2217990167296</title>\n",
       "<path d=\"M903,-747.366C903,-739.152 903,-729.658 903,-720.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"906.5,-720.607 903,-710.607 899.5,-720.607 906.5,-720.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217990220152 -->\n",
       "<g class=\"node\" id=\"node81\"><title>2217990220152</title>\n",
       "<polygon fill=\"none\" points=\"768,-581.5 768,-627.5 1038,-627.5 1038,-581.5 768,-581.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"848.5\" y=\"-600.8\">activation_240: Activation</text>\n",
       "<polyline fill=\"none\" points=\"929,-581.5 929,-627.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"957\" y=\"-612.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"929,-604.5 985,-604.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"957\" y=\"-589.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"985,-581.5 985,-627.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1011.5\" y=\"-612.3\">(?, 15)</text>\n",
       "<polyline fill=\"none\" points=\"985,-604.5 1038,-604.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1011.5\" y=\"-589.3\">(?, 15)</text>\n",
       "</g>\n",
       "<!-- 2217990167296&#45;&gt;2217990220152 -->\n",
       "<g class=\"edge\" id=\"edge83\"><title>2217990167296-&gt;2217990220152</title>\n",
       "<path d=\"M903,-664.366C903,-656.152 903,-646.658 903,-637.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"906.5,-637.607 903,-627.607 899.5,-637.607 906.5,-637.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217990217856 -->\n",
       "<g class=\"node\" id=\"node82\"><title>2217990217856</title>\n",
       "<polygon fill=\"none\" points=\"777,-498.5 777,-544.5 1029,-544.5 1029,-498.5 777,-498.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"848.5\" y=\"-517.8\">dropout_255: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"920,-498.5 920,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"948\" y=\"-529.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"920,-521.5 976,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"948\" y=\"-506.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"976,-498.5 976,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1002.5\" y=\"-529.3\">(?, 15)</text>\n",
       "<polyline fill=\"none\" points=\"976,-521.5 1029,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1002.5\" y=\"-506.3\">(?, 15)</text>\n",
       "</g>\n",
       "<!-- 2217990220152&#45;&gt;2217990217856 -->\n",
       "<g class=\"edge\" id=\"edge84\"><title>2217990220152-&gt;2217990217856</title>\n",
       "<path d=\"M903,-581.366C903,-573.152 903,-563.658 903,-554.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"906.5,-554.607 903,-544.607 899.5,-554.607 906.5,-554.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217990563320 -->\n",
       "<g class=\"node\" id=\"node83\"><title>2217990563320</title>\n",
       "<polygon fill=\"none\" points=\"789.5,-415.5 789.5,-461.5 1016.5,-461.5 1016.5,-415.5 789.5,-415.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"848.5\" y=\"-434.8\">dense_225: Dense</text>\n",
       "<polyline fill=\"none\" points=\"907.5,-415.5 907.5,-461.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"935.5\" y=\"-446.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"907.5,-438.5 963.5,-438.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"935.5\" y=\"-423.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"963.5,-415.5 963.5,-461.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"990\" y=\"-446.3\">(?, 15)</text>\n",
       "<polyline fill=\"none\" points=\"963.5,-438.5 1016.5,-438.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"990\" y=\"-423.3\">(?, 7)</text>\n",
       "</g>\n",
       "<!-- 2217990217856&#45;&gt;2217990563320 -->\n",
       "<g class=\"edge\" id=\"edge85\"><title>2217990217856-&gt;2217990563320</title>\n",
       "<path d=\"M903,-498.366C903,-490.152 903,-480.658 903,-471.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"906.5,-471.607 903,-461.607 899.5,-471.607 906.5,-471.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217990825632 -->\n",
       "<g class=\"node\" id=\"node84\"><title>2217990825632</title>\n",
       "<polygon fill=\"none\" points=\"715.5,-332.5 715.5,-378.5 1090.5,-378.5 1090.5,-332.5 715.5,-332.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"852\" y=\"-351.8\">batch_normalization_205: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"988.5,-332.5 988.5,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1016.5\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"988.5,-355.5 1044.5,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1016.5\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1044.5,-332.5 1044.5,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1067.5\" y=\"-363.3\">(?, 7)</text>\n",
       "<polyline fill=\"none\" points=\"1044.5,-355.5 1090.5,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1067.5\" y=\"-340.3\">(?, 7)</text>\n",
       "</g>\n",
       "<!-- 2217990563320&#45;&gt;2217990825632 -->\n",
       "<g class=\"edge\" id=\"edge86\"><title>2217990563320-&gt;2217990825632</title>\n",
       "<path d=\"M903,-415.366C903,-407.152 903,-397.658 903,-388.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"906.5,-388.607 903,-378.607 899.5,-388.607 906.5,-388.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217990960968 -->\n",
       "<g class=\"node\" id=\"node85\"><title>2217990960968</title>\n",
       "<polygon fill=\"none\" points=\"771.5,-249.5 771.5,-295.5 1034.5,-295.5 1034.5,-249.5 771.5,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"852\" y=\"-268.8\">activation_241: Activation</text>\n",
       "<polyline fill=\"none\" points=\"932.5,-249.5 932.5,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"960.5\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"932.5,-272.5 988.5,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"960.5\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"988.5,-249.5 988.5,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1011.5\" y=\"-280.3\">(?, 7)</text>\n",
       "<polyline fill=\"none\" points=\"988.5,-272.5 1034.5,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1011.5\" y=\"-257.3\">(?, 7)</text>\n",
       "</g>\n",
       "<!-- 2217990825632&#45;&gt;2217990960968 -->\n",
       "<g class=\"edge\" id=\"edge87\"><title>2217990825632-&gt;2217990960968</title>\n",
       "<path d=\"M903,-332.366C903,-324.152 903,-314.658 903,-305.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"906.5,-305.607 903,-295.607 899.5,-305.607 906.5,-305.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217990959512 -->\n",
       "<g class=\"node\" id=\"node87\"><title>2217990959512</title>\n",
       "<polygon fill=\"none\" points=\"790.5,-166.5 790.5,-212.5 1035.5,-212.5 1035.5,-166.5 790.5,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"862\" y=\"-185.8\">dropout_256: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"933.5,-166.5 933.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"961.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"933.5,-189.5 989.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"961.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"989.5,-166.5 989.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1012.5\" y=\"-197.3\">(?, 7)</text>\n",
       "<polyline fill=\"none\" points=\"989.5,-189.5 1035.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1012.5\" y=\"-174.3\">(?, 7)</text>\n",
       "</g>\n",
       "<!-- 2217990960968&#45;&gt;2217990959512 -->\n",
       "<g class=\"edge\" id=\"edge88\"><title>2217990960968-&gt;2217990959512</title>\n",
       "<path d=\"M905.733,-249.366C906.747,-241.152 907.919,-231.658 909.022,-222.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"912.519,-222.96 910.271,-212.607 905.572,-222.103 912.519,-222.96\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217990266328 -->\n",
       "<g class=\"node\" id=\"node86\"><title>2217990266328</title>\n",
       "<polygon fill=\"none\" points=\"1053,-249.5 1053,-295.5 1297,-295.5 1297,-249.5 1053,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1119.5\" y=\"-268.8\">input_29: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"1186,-249.5 1186,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1214\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1186,-272.5 1242,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1214\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1242,-249.5 1242,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1269.5\" y=\"-280.3\">[(?, 5)]</text>\n",
       "<polyline fill=\"none\" points=\"1242,-272.5 1297,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1269.5\" y=\"-257.3\">[(?, 5)]</text>\n",
       "</g>\n",
       "<!-- 2217992671696 -->\n",
       "<g class=\"node\" id=\"node88\"><title>2217992671696</title>\n",
       "<polygon fill=\"none\" points=\"1059,-166.5 1059,-212.5 1279,-212.5 1279,-166.5 1059,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1118\" y=\"-185.8\">dense_232: Dense</text>\n",
       "<polyline fill=\"none\" points=\"1177,-166.5 1177,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1205\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1177,-189.5 1233,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1205\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1233,-166.5 1233,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1256\" y=\"-197.3\">(?, 5)</text>\n",
       "<polyline fill=\"none\" points=\"1233,-189.5 1279,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1256\" y=\"-174.3\">(?, 3)</text>\n",
       "</g>\n",
       "<!-- 2217990266328&#45;&gt;2217992671696 -->\n",
       "<g class=\"edge\" id=\"edge89\"><title>2217990266328-&gt;2217992671696</title>\n",
       "<path d=\"M1173.36,-249.366C1172.75,-241.152 1172.05,-231.658 1171.39,-222.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1174.87,-222.321 1170.64,-212.607 1167.89,-222.838 1174.87,-222.321\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217992715176 -->\n",
       "<g class=\"node\" id=\"node89\"><title>2217992715176</title>\n",
       "<polygon fill=\"none\" points=\"877.5,-83.5 877.5,-129.5 1204.5,-129.5 1204.5,-83.5 877.5,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"967\" y=\"-102.8\">concatenate_25: Concatenate</text>\n",
       "<polyline fill=\"none\" points=\"1056.5,-83.5 1056.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1084.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1056.5,-106.5 1112.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1084.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1112.5,-83.5 1112.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1158.5\" y=\"-114.3\">[(?, 7), (?, 3)]</text>\n",
       "<polyline fill=\"none\" points=\"1112.5,-106.5 1204.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1158.5\" y=\"-91.3\">(?, 10)</text>\n",
       "</g>\n",
       "<!-- 2217990959512&#45;&gt;2217992715176 -->\n",
       "<g class=\"edge\" id=\"edge90\"><title>2217990959512-&gt;2217992715176</title>\n",
       "<path d=\"M947.977,-166.366C963.216,-156.723 981.24,-145.317 997.345,-135.125\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"999.487,-137.912 1006.07,-129.607 995.744,-131.997 999.487,-137.912\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217992671696&#45;&gt;2217992715176 -->\n",
       "<g class=\"edge\" id=\"edge91\"><title>2217992671696-&gt;2217992715176</title>\n",
       "<path d=\"M1134.02,-166.366C1118.78,-156.723 1100.76,-145.317 1084.65,-135.125\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1086.26,-131.997 1075.93,-129.607 1082.51,-137.912 1086.26,-131.997\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2217992747272 -->\n",
       "<g class=\"node\" id=\"node90\"><title>2217992747272</title>\n",
       "<polygon fill=\"none\" points=\"927.5,-0.5 927.5,-46.5 1154.5,-46.5 1154.5,-0.5 927.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"986.5\" y=\"-19.8\">dense_233: Dense</text>\n",
       "<polyline fill=\"none\" points=\"1045.5,-0.5 1045.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1073.5\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1045.5,-23.5 1101.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1073.5\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1101.5,-0.5 1101.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1128\" y=\"-31.3\">(?, 10)</text>\n",
       "<polyline fill=\"none\" points=\"1101.5,-23.5 1154.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1128\" y=\"-8.3\">(?, 3)</text>\n",
       "</g>\n",
       "<!-- 2217992715176&#45;&gt;2217992747272 -->\n",
       "<g class=\"edge\" id=\"edge92\"><title>2217992715176-&gt;2217992747272</title>\n",
       "<path d=\"M1041,-83.3664C1041,-75.1516 1041,-65.6579 1041,-56.7252\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1044.5,-56.6068 1041,-46.6068 1037.5,-56.6069 1044.5,-56.6068\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from tensorflow.python.keras.utils.vis_utils import model_to_dot\n",
    "SVG(model_to_dot(model,show_shapes = True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5bed51171db8bf8c5e1731119fd31205bfd80a82"
   },
   "source": [
    "Train the model with early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": false,
    "_uuid": "e1061c7cde0687450300f516735aad0cc5dbf08f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0613 23:44:42.706076  7492 callbacks.py:2207] `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "      2/Unknown - 0s 0s/step - loss: 1.3543 - accuracy: 0.30 - 8s 4s/step - loss: 1.2628 - accuracy: 0.3292"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0613 23:45:08.398110  7492 callbacks.py:307] Method (on_train_batch_end) is slow compared to the batch update (3.973660). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     19/Unknown - 8s 3s/step - loss: 1.1871 - accuracy: 0.39 - 8s 2s/step - loss: 1.1213 - accuracy: 0.45 - 8s 2s/step - loss: 1.0930 - accuracy: 0.48 - 8s 1s/step - loss: 1.0557 - accuracy: 0.51 - 8s 1s/step - loss: 1.0418 - accuracy: 0.53 - 8s 1s/step - loss: 1.0338 - accuracy: 0.54 - 9s 949ms/step - loss: 1.0279 - accuracy: 0.548 - 9s 862ms/step - loss: 1.0301 - accuracy: 0.545 - 9s 790ms/step - loss: 1.0215 - accuracy: 0.553 - 9s 730ms/step - loss: 1.0064 - accuracy: 0.567 - 9s 680ms/step - loss: 0.9832 - accuracy: 0.585 - 9s 636ms/step - loss: 0.9997 - accuracy: 0.578 - 9s 599ms/step - loss: 1.0298 - accuracy: 0.564 - 9s 566ms/step - loss: 1.0317 - accuracy: 0.564 - 9s 537ms/step - loss: 1.0361 - accuracy: 0.562 - 9s 511ms/step - loss: 1.0326 - accuracy: 0.564 - 9s 488ms/step - loss: 1.0307 - accuracy: 0.5644\n",
      "Epoch 00001: val_loss improved from inf to 1.03998, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 12s 611ms/step - loss: 1.0307 - accuracy: 0.5644 - val_loss: 1.0400 - val_accuracy: 0.4971 - lr: 0.0900\n",
      "Epoch 2/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0252 - accuracy: 0.52 - ETA: 0s - loss: 1.0345 - accuracy: 0.50 - ETA: 0s - loss: 1.0398 - accuracy: 0.50 - ETA: 0s - loss: 1.0219 - accuracy: 0.53 - ETA: 0s - loss: 1.0159 - accuracy: 0.54 - ETA: 0s - loss: 0.9952 - accuracy: 0.56 - ETA: 0s - loss: 0.9862 - accuracy: 0.57 - ETA: 0s - loss: 0.9810 - accuracy: 0.58 - ETA: 0s - loss: 0.9821 - accuracy: 0.58 - ETA: 0s - loss: 0.9963 - accuracy: 0.57 - ETA: 0s - loss: 0.9830 - accuracy: 0.58 - ETA: 0s - loss: 0.9662 - accuracy: 0.59 - ETA: 0s - loss: 0.9450 - accuracy: 0.61 - ETA: 0s - loss: 0.9576 - accuracy: 0.60 - ETA: 0s - loss: 0.9764 - accuracy: 0.58 - ETA: 0s - loss: 0.9774 - accuracy: 0.58 - ETA: 0s - loss: 0.9821 - accuracy: 0.58 - ETA: 0s - loss: 0.9831 - accuracy: 0.58 - ETA: 0s - loss: 0.9855 - accuracy: 0.5827\n",
      "Epoch 00002: val_loss did not improve from 1.03998\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9855 - accuracy: 0.5827 - val_loss: 1.0574 - val_accuracy: 0.4971 - lr: 0.0900\n",
      "Epoch 3/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0305 - accuracy: 0.51 - ETA: 0s - loss: 1.0366 - accuracy: 0.51 - ETA: 0s - loss: 1.0325 - accuracy: 0.52 - ETA: 0s - loss: 1.0087 - accuracy: 0.55 - ETA: 0s - loss: 0.9996 - accuracy: 0.56 - ETA: 0s - loss: 0.9818 - accuracy: 0.58 - ETA: 0s - loss: 0.9747 - accuracy: 0.58 - ETA: 0s - loss: 0.9708 - accuracy: 0.59 - ETA: 0s - loss: 0.9703 - accuracy: 0.59 - ETA: 0s - loss: 0.9800 - accuracy: 0.58 - ETA: 0s - loss: 0.9676 - accuracy: 0.59 - ETA: 0s - loss: 0.9524 - accuracy: 0.60 - ETA: 0s - loss: 0.9332 - accuracy: 0.62 - ETA: 0s - loss: 0.9468 - accuracy: 0.61 - ETA: 0s - loss: 0.9689 - accuracy: 0.59 - ETA: 0s - loss: 0.9703 - accuracy: 0.59 - ETA: 0s - loss: 0.9751 - accuracy: 0.58 - ETA: 0s - loss: 0.9757 - accuracy: 0.58 - ETA: 0s - loss: 0.9779 - accuracy: 0.5871\n",
      "Epoch 00003: val_loss did not improve from 1.03998\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9779 - accuracy: 0.5871 - val_loss: 1.0431 - val_accuracy: 0.4971 - lr: 0.0900\n",
      "Epoch 4/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0325 - accuracy: 0.49 - ETA: 0s - loss: 1.0451 - accuracy: 0.50 - ETA: 0s - loss: 1.0323 - accuracy: 0.51 - ETA: 0s - loss: 1.0089 - accuracy: 0.54 - ETA: 0s - loss: 0.9979 - accuracy: 0.56 - ETA: 0s - loss: 0.9786 - accuracy: 0.57 - ETA: 0s - loss: 0.9709 - accuracy: 0.58 - ETA: 0s - loss: 0.9665 - accuracy: 0.58 - ETA: 0s - loss: 0.9666 - accuracy: 0.58 - ETA: 0s - loss: 0.9772 - accuracy: 0.58 - ETA: 0s - loss: 0.9647 - accuracy: 0.59 - ETA: 0s - loss: 0.9482 - accuracy: 0.60 - ETA: 0s - loss: 0.9277 - accuracy: 0.61 - ETA: 0s - loss: 0.9414 - accuracy: 0.60 - ETA: 0s - loss: 0.9629 - accuracy: 0.59 - ETA: 0s - loss: 0.9639 - accuracy: 0.59 - ETA: 0s - loss: 0.9684 - accuracy: 0.58 - ETA: 0s - loss: 0.9685 - accuracy: 0.58 - ETA: 0s - loss: 0.9703 - accuracy: 0.5874\n",
      "Epoch 00004: val_loss improved from 1.03998 to 1.03671, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 2s 87ms/step - loss: 0.9703 - accuracy: 0.5874 - val_loss: 1.0367 - val_accuracy: 0.4971 - lr: 0.0900\n",
      "Epoch 5/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0197 - accuracy: 0.52 - ETA: 0s - loss: 1.0297 - accuracy: 0.51 - ETA: 0s - loss: 1.0247 - accuracy: 0.52 - ETA: 0s - loss: 1.0057 - accuracy: 0.55 - ETA: 0s - loss: 0.9973 - accuracy: 0.56 - ETA: 0s - loss: 0.9816 - accuracy: 0.58 - ETA: 0s - loss: 0.9743 - accuracy: 0.58 - ETA: 0s - loss: 0.9697 - accuracy: 0.59 - ETA: 0s - loss: 0.9687 - accuracy: 0.59 - ETA: 0s - loss: 0.9769 - accuracy: 0.58 - ETA: 0s - loss: 0.9645 - accuracy: 0.59 - ETA: 0s - loss: 0.9490 - accuracy: 0.60 - ETA: 0s - loss: 0.9289 - accuracy: 0.62 - ETA: 0s - loss: 0.9432 - accuracy: 0.61 - ETA: 0s - loss: 0.9670 - accuracy: 0.59 - ETA: 0s - loss: 0.9688 - accuracy: 0.59 - ETA: 0s - loss: 0.9743 - accuracy: 0.58 - ETA: 0s - loss: 0.9737 - accuracy: 0.59 - ETA: 0s - loss: 0.9750 - accuracy: 0.5889\n",
      "Epoch 00005: val_loss did not improve from 1.03671\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9750 - accuracy: 0.5889 - val_loss: 1.0485 - val_accuracy: 0.4971 - lr: 0.0900\n",
      "Epoch 6/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0168 - accuracy: 0.52 - ETA: 0s - loss: 1.0309 - accuracy: 0.51 - ETA: 0s - loss: 1.0220 - accuracy: 0.52 - ETA: 0s - loss: 1.0048 - accuracy: 0.55 - ETA: 0s - loss: 0.9962 - accuracy: 0.56 - ETA: 0s - loss: 0.9827 - accuracy: 0.58 - ETA: 0s - loss: 0.9759 - accuracy: 0.59 - ETA: 0s - loss: 0.9711 - accuracy: 0.59 - ETA: 0s - loss: 0.9697 - accuracy: 0.59 - ETA: 0s - loss: 0.9775 - accuracy: 0.58 - ETA: 0s - loss: 0.9655 - accuracy: 0.59 - ETA: 0s - loss: 0.9490 - accuracy: 0.60 - ETA: 0s - loss: 0.9281 - accuracy: 0.62 - ETA: 0s - loss: 0.9432 - accuracy: 0.61 - ETA: 0s - loss: 0.9675 - accuracy: 0.59 - ETA: 0s - loss: 0.9689 - accuracy: 0.59 - ETA: 0s - loss: 0.9735 - accuracy: 0.59 - ETA: 0s - loss: 0.9728 - accuracy: 0.59 - ETA: 0s - loss: 0.9735 - accuracy: 0.5894\n",
      "Epoch 00006: val_loss improved from 1.03671 to 1.03301, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 2s 87ms/step - loss: 0.9735 - accuracy: 0.5894 - val_loss: 1.0330 - val_accuracy: 0.4971 - lr: 0.0900\n",
      "Epoch 7/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0248 - accuracy: 0.52 - ETA: 0s - loss: 1.0325 - accuracy: 0.52 - ETA: 0s - loss: 1.0259 - accuracy: 0.53 - ETA: 0s - loss: 1.0074 - accuracy: 0.56 - ETA: 0s - loss: 0.9993 - accuracy: 0.57 - ETA: 0s - loss: 0.9840 - accuracy: 0.58 - ETA: 0s - loss: 0.9760 - accuracy: 0.59 - ETA: 0s - loss: 0.9705 - accuracy: 0.59 - ETA: 0s - loss: 0.9698 - accuracy: 0.59 - ETA: 0s - loss: 0.9784 - accuracy: 0.58 - ETA: 0s - loss: 0.9662 - accuracy: 0.59 - ETA: 0s - loss: 0.9512 - accuracy: 0.60 - ETA: 0s - loss: 0.9318 - accuracy: 0.62 - ETA: 0s - loss: 0.9462 - accuracy: 0.61 - ETA: 0s - loss: 0.9705 - accuracy: 0.59 - ETA: 0s - loss: 0.9722 - accuracy: 0.59 - ETA: 0s - loss: 0.9773 - accuracy: 0.59 - ETA: 0s - loss: 0.9770 - accuracy: 0.59 - ETA: 0s - loss: 0.9779 - accuracy: 0.5897\n",
      "Epoch 00007: val_loss did not improve from 1.03301\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9779 - accuracy: 0.5897 - val_loss: 1.0458 - val_accuracy: 0.4971 - lr: 0.0900\n",
      "Epoch 8/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0138 - accuracy: 0.52 - ETA: 0s - loss: 1.0269 - accuracy: 0.51 - ETA: 0s - loss: 1.0175 - accuracy: 0.52 - ETA: 0s - loss: 0.9946 - accuracy: 0.55 - ETA: 0s - loss: 0.9853 - accuracy: 0.56 - ETA: 0s - loss: 0.9687 - accuracy: 0.58 - ETA: 0s - loss: 0.9619 - accuracy: 0.59 - ETA: 0s - loss: 0.9582 - accuracy: 0.59 - ETA: 0s - loss: 0.9608 - accuracy: 0.59 - ETA: 0s - loss: 0.9732 - accuracy: 0.58 - ETA: 0s - loss: 0.9617 - accuracy: 0.59 - ETA: 0s - loss: 0.9451 - accuracy: 0.60 - ETA: 0s - loss: 0.9247 - accuracy: 0.62 - ETA: 0s - loss: 0.9390 - accuracy: 0.61 - ETA: 0s - loss: 0.9602 - accuracy: 0.59 - ETA: 0s - loss: 0.9614 - accuracy: 0.59 - ETA: 0s - loss: 0.9655 - accuracy: 0.59 - ETA: 0s - loss: 0.9660 - accuracy: 0.59 - ETA: 0s - loss: 0.9677 - accuracy: 0.5891\n",
      "Epoch 00008: val_loss did not improve from 1.03301\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9677 - accuracy: 0.5891 - val_loss: 1.0371 - val_accuracy: 0.4971 - lr: 0.0900\n",
      "Epoch 9/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0198 - accuracy: 0.52 - ETA: 0s - loss: 1.0295 - accuracy: 0.51 - ETA: 0s - loss: 1.0239 - accuracy: 0.52 - ETA: 0s - loss: 1.0075 - accuracy: 0.55 - ETA: 0s - loss: 1.0000 - accuracy: 0.56 - ETA: 0s - loss: 0.9853 - accuracy: 0.58 - ETA: 0s - loss: 0.9777 - accuracy: 0.59 - ETA: 0s - loss: 0.9723 - accuracy: 0.59 - ETA: 0s - loss: 0.9709 - accuracy: 0.59 - ETA: 0s - loss: 0.9799 - accuracy: 0.58 - ETA: 0s - loss: 0.9675 - accuracy: 0.59 - ETA: 0s - loss: 0.9513 - accuracy: 0.60 - ETA: 0s - loss: 0.9301 - accuracy: 0.62 - ETA: 0s - loss: 0.9469 - accuracy: 0.61 - ETA: 0s - loss: 0.9717 - accuracy: 0.59 - ETA: 0s - loss: 0.9729 - accuracy: 0.59 - ETA: 0s - loss: 0.9775 - accuracy: 0.59 - ETA: 0s - loss: 0.9768 - accuracy: 0.59 - ETA: 0s - loss: 0.9779 - accuracy: 0.5891\n",
      "Epoch 00009: val_loss did not improve from 1.03301\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9779 - accuracy: 0.5891 - val_loss: 1.0334 - val_accuracy: 0.4971 - lr: 0.0900\n",
      "Epoch 10/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0199 - accuracy: 0.53 - ETA: 0s - loss: 1.0288 - accuracy: 0.52 - ETA: 0s - loss: 1.0203 - accuracy: 0.53 - ETA: 0s - loss: 0.9981 - accuracy: 0.56 - ETA: 0s - loss: 0.9894 - accuracy: 0.57 - ETA: 0s - loss: 0.9722 - accuracy: 0.58 - ETA: 0s - loss: 0.9650 - accuracy: 0.59 - ETA: 0s - loss: 0.9636 - accuracy: 0.59 - ETA: 0s - loss: 0.9675 - accuracy: 0.59 - ETA: 0s - loss: 0.9806 - accuracy: 0.58 - ETA: 0s - loss: 0.9680 - accuracy: 0.59 - ETA: 0s - loss: 0.9521 - accuracy: 0.60 - ETA: 0s - loss: 0.9331 - accuracy: 0.62 - ETA: 0s - loss: 0.9446 - accuracy: 0.61 - ETA: 0s - loss: 0.9623 - accuracy: 0.59 - ETA: 0s - loss: 0.9633 - accuracy: 0.59 - ETA: 0s - loss: 0.9674 - accuracy: 0.59 - ETA: 0s - loss: 0.9680 - accuracy: 0.59 - ETA: 0s - loss: 0.9699 - accuracy: 0.5897\n",
      "Epoch 00010: val_loss did not improve from 1.03301\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9699 - accuracy: 0.5897 - val_loss: 1.0356 - val_accuracy: 0.4971 - lr: 0.0900\n",
      "Epoch 11/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0241 - accuracy: 0.52 - ETA: 0s - loss: 1.0311 - accuracy: 0.51 - ETA: 0s - loss: 1.0243 - accuracy: 0.52 - ETA: 0s - loss: 1.0017 - accuracy: 0.55 - ETA: 0s - loss: 0.9930 - accuracy: 0.56 - ETA: 0s - loss: 0.9760 - accuracy: 0.58 - ETA: 0s - loss: 0.9686 - accuracy: 0.59 - ETA: 0s - loss: 0.9641 - accuracy: 0.59 - ETA: 0s - loss: 0.9637 - accuracy: 0.59 - ETA: 0s - loss: 0.9736 - accuracy: 0.58 - ETA: 0s - loss: 0.9615 - accuracy: 0.59 - ETA: 0s - loss: 0.9455 - accuracy: 0.60 - ETA: 0s - loss: 0.9253 - accuracy: 0.62 - ETA: 0s - loss: 0.9400 - accuracy: 0.61 - ETA: 0s - loss: 0.9626 - accuracy: 0.59 - ETA: 0s - loss: 0.9643 - accuracy: 0.59 - ETA: 0s - loss: 0.9690 - accuracy: 0.59 - ETA: 0s - loss: 0.9695 - accuracy: 0.59 - ETA: 0s - loss: 0.9715 - accuracy: 0.5888\n",
      "Epoch 00011: val_loss did not improve from 1.03301\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9715 - accuracy: 0.5888 - val_loss: 1.0389 - val_accuracy: 0.4971 - lr: 0.0900\n",
      "Epoch 12/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0305 - accuracy: 0.51 - ETA: 0s - loss: 1.0401 - accuracy: 0.51 - ETA: 0s - loss: 1.0306 - accuracy: 0.52 - ETA: 0s - loss: 1.0050 - accuracy: 0.55 - ETA: 0s - loss: 0.9962 - accuracy: 0.56 - ETA: 0s - loss: 0.9767 - accuracy: 0.58 - ETA: 0s - loss: 0.9691 - accuracy: 0.59 - ETA: 0s - loss: 0.9649 - accuracy: 0.59 - ETA: 0s - loss: 0.9651 - accuracy: 0.59 - ETA: 0s - loss: 0.9756 - accuracy: 0.58 - ETA: 0s - loss: 0.9632 - accuracy: 0.59 - ETA: 0s - loss: 0.9466 - accuracy: 0.60 - ETA: 0s - loss: 0.9266 - accuracy: 0.62 - ETA: 0s - loss: 0.9398 - accuracy: 0.61 - ETA: 0s - loss: 0.9593 - accuracy: 0.59 - ETA: 0s - loss: 0.9614 - accuracy: 0.59 - ETA: 0s - loss: 0.9657 - accuracy: 0.59 - ETA: 0s - loss: 0.9668 - accuracy: 0.58 - ETA: 0s - loss: 0.9694 - accuracy: 0.5864\n",
      "Epoch 00012: val_loss improved from 1.03301 to 1.02982, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 2s 87ms/step - loss: 0.9694 - accuracy: 0.5864 - val_loss: 1.0298 - val_accuracy: 0.4971 - lr: 0.0900\n",
      "Epoch 13/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0364 - accuracy: 0.50 - ETA: 0s - loss: 1.0391 - accuracy: 0.50 - ETA: 0s - loss: 1.0280 - accuracy: 0.52 - ETA: 0s - loss: 0.9978 - accuracy: 0.55 - ETA: 0s - loss: 0.9881 - accuracy: 0.56 - ETA: 0s - loss: 0.9683 - accuracy: 0.58 - ETA: 0s - loss: 0.9612 - accuracy: 0.58 - ETA: 0s - loss: 0.9584 - accuracy: 0.59 - ETA: 0s - loss: 0.9598 - accuracy: 0.59 - ETA: 0s - loss: 0.9718 - accuracy: 0.58 - ETA: 0s - loss: 0.9600 - accuracy: 0.59 - ETA: 0s - loss: 0.9446 - accuracy: 0.60 - ETA: 0s - loss: 0.9250 - accuracy: 0.61 - ETA: 0s - loss: 0.9382 - accuracy: 0.61 - ETA: 0s - loss: 0.9586 - accuracy: 0.59 - ETA: 0s - loss: 0.9601 - accuracy: 0.59 - ETA: 0s - loss: 0.9649 - accuracy: 0.58 - ETA: 0s - loss: 0.9648 - accuracy: 0.58 - ETA: 0s - loss: 0.9660 - accuracy: 0.5881\n",
      "Epoch 00013: val_loss did not improve from 1.02982\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9660 - accuracy: 0.5881 - val_loss: 1.0375 - val_accuracy: 0.4971 - lr: 0.0900\n",
      "Epoch 14/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0120 - accuracy: 0.52 - ETA: 0s - loss: 1.0229 - accuracy: 0.51 - ETA: 0s - loss: 1.0169 - accuracy: 0.52 - ETA: 0s - loss: 0.9971 - accuracy: 0.55 - ETA: 0s - loss: 0.9899 - accuracy: 0.56 - ETA: 0s - loss: 0.9748 - accuracy: 0.58 - ETA: 0s - loss: 0.9683 - accuracy: 0.59 - ETA: 0s - loss: 0.9647 - accuracy: 0.59 - ETA: 0s - loss: 0.9642 - accuracy: 0.59 - ETA: 0s - loss: 0.9744 - accuracy: 0.58 - ETA: 0s - loss: 0.9620 - accuracy: 0.59 - ETA: 0s - loss: 0.9457 - accuracy: 0.60 - ETA: 0s - loss: 0.9248 - accuracy: 0.62 - ETA: 0s - loss: 0.9403 - accuracy: 0.61 - ETA: 0s - loss: 0.9635 - accuracy: 0.59 - ETA: 0s - loss: 0.9652 - accuracy: 0.59 - ETA: 0s - loss: 0.9697 - accuracy: 0.59 - ETA: 0s - loss: 0.9698 - accuracy: 0.59 - ETA: 0s - loss: 0.9714 - accuracy: 0.5898\n",
      "Epoch 00014: val_loss did not improve from 1.02982\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9714 - accuracy: 0.5898 - val_loss: 1.0393 - val_accuracy: 0.4971 - lr: 0.0900\n",
      "Epoch 15/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0231 - accuracy: 0.52 - ETA: 0s - loss: 1.0315 - accuracy: 0.51 - ETA: 0s - loss: 1.0268 - accuracy: 0.52 - ETA: 0s - loss: 1.0064 - accuracy: 0.55 - ETA: 0s - loss: 0.9966 - accuracy: 0.56 - ETA: 0s - loss: 0.9789 - accuracy: 0.58 - ETA: 0s - loss: 0.9710 - accuracy: 0.59 - ETA: 0s - loss: 0.9662 - accuracy: 0.59 - ETA: 0s - loss: 0.9662 - accuracy: 0.59 - ETA: 0s - loss: 0.9775 - accuracy: 0.58 - ETA: 0s - loss: 0.9648 - accuracy: 0.59 - ETA: 0s - loss: 0.9486 - accuracy: 0.60 - ETA: 0s - loss: 0.9280 - accuracy: 0.62 - ETA: 0s - loss: 0.9422 - accuracy: 0.61 - ETA: 0s - loss: 0.9634 - accuracy: 0.59 - ETA: 0s - loss: 0.9647 - accuracy: 0.59 - ETA: 0s - loss: 0.9687 - accuracy: 0.59 - ETA: 0s - loss: 0.9701 - accuracy: 0.58 - ETA: 0s - loss: 0.9731 - accuracy: 0.5869\n",
      "Epoch 00015: val_loss did not improve from 1.02982\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9731 - accuracy: 0.5869 - val_loss: 1.0370 - val_accuracy: 0.5049 - lr: 0.0900\n",
      "Epoch 16/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0321 - accuracy: 0.50 - ETA: 0s - loss: 1.0341 - accuracy: 0.51 - ETA: 0s - loss: 1.0231 - accuracy: 0.52 - ETA: 0s - loss: 0.9938 - accuracy: 0.55 - ETA: 0s - loss: 0.9833 - accuracy: 0.56 - ETA: 0s - loss: 0.9640 - accuracy: 0.58 - ETA: 0s - loss: 0.9567 - accuracy: 0.58 - ETA: 0s - loss: 0.9543 - accuracy: 0.59 - ETA: 0s - loss: 0.9569 - accuracy: 0.59 - ETA: 0s - loss: 0.9694 - accuracy: 0.58 - ETA: 0s - loss: 0.9575 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.60 - ETA: 0s - loss: 0.9223 - accuracy: 0.62 - ETA: 0s - loss: 0.9348 - accuracy: 0.61 - ETA: 0s - loss: 0.9537 - accuracy: 0.59 - ETA: 0s - loss: 0.9557 - accuracy: 0.59 - ETA: 0s - loss: 0.9608 - accuracy: 0.58 - ETA: 0s - loss: 0.9615 - accuracy: 0.58 - ETA: 0s - loss: 0.9636 - accuracy: 0.5873\n",
      "Epoch 00016: val_loss did not improve from 1.02982\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9636 - accuracy: 0.5873 - val_loss: 1.0369 - val_accuracy: 0.4971 - lr: 0.0900\n",
      "Epoch 17/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0143 - accuracy: 0.52 - ETA: 0s - loss: 1.0268 - accuracy: 0.51 - ETA: 0s - loss: 1.0187 - accuracy: 0.53 - ETA: 0s - loss: 0.9942 - accuracy: 0.55 - ETA: 0s - loss: 0.9869 - accuracy: 0.56 - ETA: 0s - loss: 0.9704 - accuracy: 0.58 - ETA: 0s - loss: 0.9643 - accuracy: 0.59 - ETA: 0s - loss: 0.9609 - accuracy: 0.59 - ETA: 0s - loss: 0.9606 - accuracy: 0.59 - ETA: 0s - loss: 0.9700 - accuracy: 0.58 - ETA: 0s - loss: 0.9587 - accuracy: 0.59 - ETA: 0s - loss: 0.9424 - accuracy: 0.60 - ETA: 0s - loss: 0.9217 - accuracy: 0.62 - ETA: 0s - loss: 0.9363 - accuracy: 0.61 - ETA: 0s - loss: 0.9586 - accuracy: 0.59 - ETA: 0s - loss: 0.9604 - accuracy: 0.59 - ETA: 0s - loss: 0.9653 - accuracy: 0.59 - ETA: 0s - loss: 0.9657 - accuracy: 0.59 - ETA: 0s - loss: 0.9671 - accuracy: 0.5894\n",
      "Epoch 00017: val_loss improved from 1.02982 to 1.02934, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 2s 87ms/step - loss: 0.9671 - accuracy: 0.5894 - val_loss: 1.0293 - val_accuracy: 0.4969 - lr: 0.0900\n",
      "Epoch 18/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0242 - accuracy: 0.51 - ETA: 0s - loss: 1.0316 - accuracy: 0.51 - ETA: 0s - loss: 1.0245 - accuracy: 0.52 - ETA: 0s - loss: 1.0023 - accuracy: 0.55 - ETA: 0s - loss: 0.9932 - accuracy: 0.56 - ETA: 0s - loss: 0.9746 - accuracy: 0.58 - ETA: 0s - loss: 0.9666 - accuracy: 0.58 - ETA: 0s - loss: 0.9624 - accuracy: 0.59 - ETA: 0s - loss: 0.9629 - accuracy: 0.59 - ETA: 0s - loss: 0.9744 - accuracy: 0.58 - ETA: 0s - loss: 0.9617 - accuracy: 0.59 - ETA: 0s - loss: 0.9455 - accuracy: 0.60 - ETA: 0s - loss: 0.9254 - accuracy: 0.62 - ETA: 0s - loss: 0.9394 - accuracy: 0.61 - ETA: 0s - loss: 0.9607 - accuracy: 0.59 - ETA: 0s - loss: 0.9623 - accuracy: 0.59 - ETA: 0s - loss: 0.9671 - accuracy: 0.58 - ETA: 0s - loss: 0.9676 - accuracy: 0.58 - ETA: 0s - loss: 0.9692 - accuracy: 0.5881\n",
      "Epoch 00018: val_loss did not improve from 1.02934\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9692 - accuracy: 0.5881 - val_loss: 1.0331 - val_accuracy: 0.4971 - lr: 0.0900\n",
      "Epoch 19/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0222 - accuracy: 0.51 - ETA: 0s - loss: 1.0285 - accuracy: 0.51 - ETA: 0s - loss: 1.0204 - accuracy: 0.52 - ETA: 0s - loss: 0.9985 - accuracy: 0.55 - ETA: 0s - loss: 0.9902 - accuracy: 0.56 - ETA: 0s - loss: 0.9734 - accuracy: 0.58 - ETA: 0s - loss: 0.9655 - accuracy: 0.58 - ETA: 0s - loss: 0.9610 - accuracy: 0.59 - ETA: 0s - loss: 0.9611 - accuracy: 0.59 - ETA: 0s - loss: 0.9718 - accuracy: 0.58 - ETA: 0s - loss: 0.9605 - accuracy: 0.59 - ETA: 0s - loss: 0.9439 - accuracy: 0.60 - ETA: 0s - loss: 0.9235 - accuracy: 0.62 - ETA: 0s - loss: 0.9382 - accuracy: 0.61 - ETA: 0s - loss: 0.9602 - accuracy: 0.59 - ETA: 0s - loss: 0.9621 - accuracy: 0.59 - ETA: 0s - loss: 0.9670 - accuracy: 0.58 - ETA: 0s - loss: 0.9674 - accuracy: 0.58 - ETA: 0s - loss: 0.9689 - accuracy: 0.5887\n",
      "Epoch 00019: val_loss did not improve from 1.02934\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9689 - accuracy: 0.5887 - val_loss: 1.0306 - val_accuracy: 0.4971 - lr: 0.0900\n",
      "Epoch 20/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0218 - accuracy: 0.52 - ETA: 0s - loss: 1.0301 - accuracy: 0.51 - ETA: 0s - loss: 1.0223 - accuracy: 0.52 - ETA: 0s - loss: 0.9966 - accuracy: 0.55 - ETA: 0s - loss: 0.9869 - accuracy: 0.56 - ETA: 0s - loss: 0.9680 - accuracy: 0.58 - ETA: 0s - loss: 0.9611 - accuracy: 0.59 - ETA: 0s - loss: 0.9578 - accuracy: 0.59 - ETA: 0s - loss: 0.9600 - accuracy: 0.59 - ETA: 0s - loss: 0.9732 - accuracy: 0.58 - ETA: 0s - loss: 0.9618 - accuracy: 0.59 - ETA: 0s - loss: 0.9460 - accuracy: 0.60 - ETA: 0s - loss: 0.9263 - accuracy: 0.62 - ETA: 0s - loss: 0.9389 - accuracy: 0.61 - ETA: 0s - loss: 0.9579 - accuracy: 0.59 - ETA: 0s - loss: 0.9591 - accuracy: 0.59 - ETA: 0s - loss: 0.9630 - accuracy: 0.59 - ETA: 0s - loss: 0.9637 - accuracy: 0.59 - ETA: 0s - loss: 0.9650 - accuracy: 0.5895\n",
      "Epoch 00020: val_loss improved from 1.02934 to 1.02803, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 2s 87ms/step - loss: 0.9650 - accuracy: 0.5895 - val_loss: 1.0280 - val_accuracy: 0.5018 - lr: 0.0900\n",
      "Epoch 21/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0217 - accuracy: 0.52 - ETA: 0s - loss: 1.0267 - accuracy: 0.51 - ETA: 0s - loss: 1.0201 - accuracy: 0.52 - ETA: 0s - loss: 0.9972 - accuracy: 0.55 - ETA: 0s - loss: 0.9888 - accuracy: 0.56 - ETA: 0s - loss: 0.9716 - accuracy: 0.58 - ETA: 0s - loss: 0.9633 - accuracy: 0.59 - ETA: 0s - loss: 0.9588 - accuracy: 0.59 - ETA: 0s - loss: 0.9597 - accuracy: 0.59 - ETA: 0s - loss: 0.9707 - accuracy: 0.58 - ETA: 0s - loss: 0.9584 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.60 - ETA: 0s - loss: 0.9228 - accuracy: 0.62 - ETA: 0s - loss: 0.9368 - accuracy: 0.61 - ETA: 0s - loss: 0.9584 - accuracy: 0.59 - ETA: 0s - loss: 0.9598 - accuracy: 0.59 - ETA: 0s - loss: 0.9643 - accuracy: 0.59 - ETA: 0s - loss: 0.9648 - accuracy: 0.59 - ETA: 0s - loss: 0.9664 - accuracy: 0.5893\n",
      "Epoch 00021: val_loss did not improve from 1.02803\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9664 - accuracy: 0.5893 - val_loss: 1.0355 - val_accuracy: 0.4969 - lr: 0.0900\n",
      "Epoch 22/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0195 - accuracy: 0.52 - ETA: 0s - loss: 1.0274 - accuracy: 0.51 - ETA: 0s - loss: 1.0225 - accuracy: 0.52 - ETA: 0s - loss: 0.9958 - accuracy: 0.55 - ETA: 0s - loss: 0.9864 - accuracy: 0.56 - ETA: 0s - loss: 0.9678 - accuracy: 0.58 - ETA: 0s - loss: 0.9613 - accuracy: 0.59 - ETA: 0s - loss: 0.9590 - accuracy: 0.59 - ETA: 0s - loss: 0.9606 - accuracy: 0.59 - ETA: 0s - loss: 0.9735 - accuracy: 0.58 - ETA: 0s - loss: 0.9615 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.60 - ETA: 0s - loss: 0.9239 - accuracy: 0.62 - ETA: 0s - loss: 0.9370 - accuracy: 0.61 - ETA: 0s - loss: 0.9559 - accuracy: 0.59 - ETA: 0s - loss: 0.9571 - accuracy: 0.59 - ETA: 0s - loss: 0.9612 - accuracy: 0.59 - ETA: 0s - loss: 0.9627 - accuracy: 0.59 - ETA: 0s - loss: 0.9645 - accuracy: 0.5892\n",
      "Epoch 00022: val_loss improved from 1.02803 to 1.02736, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 2s 87ms/step - loss: 0.9645 - accuracy: 0.5892 - val_loss: 1.0274 - val_accuracy: 0.5037 - lr: 0.0900\n",
      "Epoch 23/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0273 - accuracy: 0.52 - ETA: 0s - loss: 1.0289 - accuracy: 0.51 - ETA: 0s - loss: 1.0201 - accuracy: 0.52 - ETA: 0s - loss: 0.9970 - accuracy: 0.55 - ETA: 0s - loss: 0.9868 - accuracy: 0.56 - ETA: 0s - loss: 0.9699 - accuracy: 0.58 - ETA: 0s - loss: 0.9627 - accuracy: 0.59 - ETA: 0s - loss: 0.9584 - accuracy: 0.59 - ETA: 0s - loss: 0.9581 - accuracy: 0.59 - ETA: 0s - loss: 0.9682 - accuracy: 0.58 - ETA: 0s - loss: 0.9566 - accuracy: 0.59 - ETA: 0s - loss: 0.9408 - accuracy: 0.60 - ETA: 0s - loss: 0.9209 - accuracy: 0.62 - ETA: 0s - loss: 0.9354 - accuracy: 0.61 - ETA: 0s - loss: 0.9572 - accuracy: 0.59 - ETA: 0s - loss: 0.9589 - accuracy: 0.59 - ETA: 0s - loss: 0.9635 - accuracy: 0.59 - ETA: 0s - loss: 0.9644 - accuracy: 0.59 - ETA: 0s - loss: 0.9659 - accuracy: 0.5891\n",
      "Epoch 00023: val_loss did not improve from 1.02736\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9659 - accuracy: 0.5891 - val_loss: 1.0300 - val_accuracy: 0.4971 - lr: 0.0900\n",
      "Epoch 24/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0224 - accuracy: 0.52 - ETA: 0s - loss: 1.0293 - accuracy: 0.51 - ETA: 0s - loss: 1.0211 - accuracy: 0.52 - ETA: 0s - loss: 0.9948 - accuracy: 0.55 - ETA: 0s - loss: 0.9852 - accuracy: 0.56 - ETA: 0s - loss: 0.9659 - accuracy: 0.58 - ETA: 0s - loss: 0.9594 - accuracy: 0.58 - ETA: 0s - loss: 0.9569 - accuracy: 0.59 - ETA: 0s - loss: 0.9589 - accuracy: 0.59 - ETA: 0s - loss: 0.9719 - accuracy: 0.58 - ETA: 0s - loss: 0.9598 - accuracy: 0.59 - ETA: 0s - loss: 0.9440 - accuracy: 0.60 - ETA: 0s - loss: 0.9242 - accuracy: 0.62 - ETA: 0s - loss: 0.9364 - accuracy: 0.61 - ETA: 0s - loss: 0.9546 - accuracy: 0.59 - ETA: 0s - loss: 0.9560 - accuracy: 0.59 - ETA: 0s - loss: 0.9596 - accuracy: 0.58 - ETA: 0s - loss: 0.9604 - accuracy: 0.58 - ETA: 0s - loss: 0.9622 - accuracy: 0.5878\n",
      "Epoch 00024: val_loss improved from 1.02736 to 1.02311, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 2s 87ms/step - loss: 0.9622 - accuracy: 0.5878 - val_loss: 1.0231 - val_accuracy: 0.4972 - lr: 0.0900\n",
      "Epoch 25/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0227 - accuracy: 0.52 - ETA: 0s - loss: 1.0218 - accuracy: 0.51 - ETA: 0s - loss: 1.0153 - accuracy: 0.52 - ETA: 0s - loss: 0.9895 - accuracy: 0.55 - ETA: 0s - loss: 0.9804 - accuracy: 0.56 - ETA: 0s - loss: 0.9622 - accuracy: 0.58 - ETA: 0s - loss: 0.9564 - accuracy: 0.59 - ETA: 0s - loss: 0.9538 - accuracy: 0.59 - ETA: 0s - loss: 0.9557 - accuracy: 0.59 - ETA: 0s - loss: 0.9676 - accuracy: 0.58 - ETA: 0s - loss: 0.9560 - accuracy: 0.59 - ETA: 0s - loss: 0.9399 - accuracy: 0.60 - ETA: 0s - loss: 0.9198 - accuracy: 0.62 - ETA: 0s - loss: 0.9334 - accuracy: 0.61 - ETA: 0s - loss: 0.9531 - accuracy: 0.59 - ETA: 0s - loss: 0.9547 - accuracy: 0.59 - ETA: 0s - loss: 0.9596 - accuracy: 0.59 - ETA: 0s - loss: 0.9598 - accuracy: 0.59 - ETA: 0s - loss: 0.9612 - accuracy: 0.5893\n",
      "Epoch 00025: val_loss did not improve from 1.02311\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9612 - accuracy: 0.5893 - val_loss: 1.0280 - val_accuracy: 0.4971 - lr: 0.0900\n",
      "Epoch 26/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0096 - accuracy: 0.52 - ETA: 0s - loss: 1.0197 - accuracy: 0.51 - ETA: 0s - loss: 1.0130 - accuracy: 0.52 - ETA: 0s - loss: 0.9936 - accuracy: 0.55 - ETA: 0s - loss: 0.9866 - accuracy: 0.56 - ETA: 0s - loss: 0.9720 - accuracy: 0.58 - ETA: 0s - loss: 0.9647 - accuracy: 0.59 - ETA: 0s - loss: 0.9605 - accuracy: 0.59 - ETA: 0s - loss: 0.9605 - accuracy: 0.59 - ETA: 0s - loss: 0.9716 - accuracy: 0.58 - ETA: 0s - loss: 0.9595 - accuracy: 0.59 - ETA: 0s - loss: 0.9439 - accuracy: 0.60 - ETA: 0s - loss: 0.9235 - accuracy: 0.62 - ETA: 0s - loss: 0.9396 - accuracy: 0.61 - ETA: 0s - loss: 0.9611 - accuracy: 0.59 - ETA: 0s - loss: 0.9624 - accuracy: 0.59 - ETA: 0s - loss: 0.9664 - accuracy: 0.59 - ETA: 0s - loss: 0.9667 - accuracy: 0.59 - ETA: 0s - loss: 0.9679 - accuracy: 0.5895\n",
      "Epoch 00026: val_loss did not improve from 1.02311\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9679 - accuracy: 0.5895 - val_loss: 1.0269 - val_accuracy: 0.4976 - lr: 0.0900\n",
      "Epoch 27/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0213 - accuracy: 0.52 - ETA: 0s - loss: 1.0251 - accuracy: 0.51 - ETA: 0s - loss: 1.0197 - accuracy: 0.52 - ETA: 0s - loss: 0.9952 - accuracy: 0.55 - ETA: 0s - loss: 0.9863 - accuracy: 0.56 - ETA: 0s - loss: 0.9668 - accuracy: 0.58 - ETA: 0s - loss: 0.9606 - accuracy: 0.59 - ETA: 0s - loss: 0.9587 - accuracy: 0.59 - ETA: 0s - loss: 0.9616 - accuracy: 0.59 - ETA: 0s - loss: 0.9745 - accuracy: 0.58 - ETA: 0s - loss: 0.9624 - accuracy: 0.59 - ETA: 0s - loss: 0.9473 - accuracy: 0.60 - ETA: 0s - loss: 0.9288 - accuracy: 0.62 - ETA: 0s - loss: 0.9400 - accuracy: 0.61 - ETA: 0s - loss: 0.9568 - accuracy: 0.59 - ETA: 0s - loss: 0.9584 - accuracy: 0.59 - ETA: 0s - loss: 0.9628 - accuracy: 0.59 - ETA: 0s - loss: 0.9635 - accuracy: 0.59 - ETA: 0s - loss: 0.9648 - accuracy: 0.5890\n",
      "Epoch 00027: val_loss improved from 1.02311 to 1.01635, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 2s 87ms/step - loss: 0.9648 - accuracy: 0.5890 - val_loss: 1.0163 - val_accuracy: 0.5037 - lr: 0.0900\n",
      "Epoch 28/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0163 - accuracy: 0.52 - ETA: 0s - loss: 1.0216 - accuracy: 0.51 - ETA: 0s - loss: 1.0127 - accuracy: 0.52 - ETA: 0s - loss: 0.9855 - accuracy: 0.55 - ETA: 0s - loss: 0.9765 - accuracy: 0.56 - ETA: 0s - loss: 0.9582 - accuracy: 0.58 - ETA: 0s - loss: 0.9517 - accuracy: 0.59 - ETA: 0s - loss: 0.9496 - accuracy: 0.59 - ETA: 0s - loss: 0.9507 - accuracy: 0.59 - ETA: 0s - loss: 0.9627 - accuracy: 0.58 - ETA: 0s - loss: 0.9513 - accuracy: 0.59 - ETA: 0s - loss: 0.9359 - accuracy: 0.60 - ETA: 0s - loss: 0.9163 - accuracy: 0.62 - ETA: 0s - loss: 0.9301 - accuracy: 0.61 - ETA: 0s - loss: 0.9495 - accuracy: 0.59 - ETA: 0s - loss: 0.9514 - accuracy: 0.59 - ETA: 0s - loss: 0.9557 - accuracy: 0.59 - ETA: 0s - loss: 0.9580 - accuracy: 0.58 - ETA: 0s - loss: 0.9602 - accuracy: 0.5882\n",
      "Epoch 00028: val_loss did not improve from 1.01635\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9602 - accuracy: 0.5882 - val_loss: 1.0244 - val_accuracy: 0.5060 - lr: 0.0900\n",
      "Epoch 29/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0196 - accuracy: 0.51 - ETA: 0s - loss: 1.0215 - accuracy: 0.51 - ETA: 0s - loss: 1.0138 - accuracy: 0.52 - ETA: 0s - loss: 0.9873 - accuracy: 0.55 - ETA: 0s - loss: 0.9789 - accuracy: 0.56 - ETA: 0s - loss: 0.9607 - accuracy: 0.58 - ETA: 0s - loss: 0.9542 - accuracy: 0.58 - ETA: 0s - loss: 0.9513 - accuracy: 0.59 - ETA: 0s - loss: 0.9520 - accuracy: 0.59 - ETA: 0s - loss: 0.9632 - accuracy: 0.58 - ETA: 0s - loss: 0.9521 - accuracy: 0.59 - ETA: 0s - loss: 0.9360 - accuracy: 0.60 - ETA: 0s - loss: 0.9159 - accuracy: 0.62 - ETA: 0s - loss: 0.9303 - accuracy: 0.61 - ETA: 0s - loss: 0.9506 - accuracy: 0.59 - ETA: 0s - loss: 0.9529 - accuracy: 0.59 - ETA: 0s - loss: 0.9576 - accuracy: 0.59 - ETA: 0s - loss: 0.9593 - accuracy: 0.58 - ETA: 0s - loss: 0.9613 - accuracy: 0.5884\n",
      "Epoch 00029: val_loss did not improve from 1.01635\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9613 - accuracy: 0.5884 - val_loss: 1.0220 - val_accuracy: 0.5021 - lr: 0.0900\n",
      "Epoch 30/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0216 - accuracy: 0.52 - ETA: 0s - loss: 1.0253 - accuracy: 0.51 - ETA: 0s - loss: 1.0189 - accuracy: 0.52 - ETA: 0s - loss: 0.9920 - accuracy: 0.55 - ETA: 0s - loss: 0.9831 - accuracy: 0.56 - ETA: 0s - loss: 0.9644 - accuracy: 0.58 - ETA: 0s - loss: 0.9573 - accuracy: 0.59 - ETA: 0s - loss: 0.9536 - accuracy: 0.59 - ETA: 0s - loss: 0.9537 - accuracy: 0.59 - ETA: 0s - loss: 0.9643 - accuracy: 0.58 - ETA: 0s - loss: 0.9525 - accuracy: 0.59 - ETA: 0s - loss: 0.9373 - accuracy: 0.60 - ETA: 0s - loss: 0.9175 - accuracy: 0.62 - ETA: 0s - loss: 0.9318 - accuracy: 0.61 - ETA: 0s - loss: 0.9521 - accuracy: 0.59 - ETA: 0s - loss: 0.9542 - accuracy: 0.59 - ETA: 0s - loss: 0.9589 - accuracy: 0.59 - ETA: 0s - loss: 0.9613 - accuracy: 0.58 - ETA: 0s - loss: 0.9643 - accuracy: 0.5862\n",
      "Epoch 00030: val_loss did not improve from 1.01635\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9643 - accuracy: 0.5862 - val_loss: 1.0211 - val_accuracy: 0.5052 - lr: 0.0900\n",
      "Epoch 31/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0262 - accuracy: 0.51 - ETA: 0s - loss: 1.0236 - accuracy: 0.51 - ETA: 0s - loss: 1.0156 - accuracy: 0.52 - ETA: 0s - loss: 0.9857 - accuracy: 0.55 - ETA: 0s - loss: 0.9765 - accuracy: 0.56 - ETA: 0s - loss: 0.9579 - accuracy: 0.58 - ETA: 0s - loss: 0.9518 - accuracy: 0.58 - ETA: 0s - loss: 0.9493 - accuracy: 0.59 - ETA: 0s - loss: 0.9498 - accuracy: 0.59 - ETA: 0s - loss: 0.9607 - accuracy: 0.58 - ETA: 0s - loss: 0.9495 - accuracy: 0.59 - ETA: 0s - loss: 0.9339 - accuracy: 0.60 - ETA: 0s - loss: 0.9143 - accuracy: 0.62 - ETA: 0s - loss: 0.9286 - accuracy: 0.61 - ETA: 0s - loss: 0.9491 - accuracy: 0.59 - ETA: 0s - loss: 0.9516 - accuracy: 0.59 - ETA: 0s - loss: 0.9572 - accuracy: 0.59 - ETA: 0s - loss: 0.9587 - accuracy: 0.59 - ETA: 0s - loss: 0.9610 - accuracy: 0.5887\n",
      "Epoch 00031: val_loss did not improve from 1.01635\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9610 - accuracy: 0.5887 - val_loss: 1.0205 - val_accuracy: 0.4971 - lr: 0.0900\n",
      "Epoch 32/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0197 - accuracy: 0.52 - ETA: 0s - loss: 1.0240 - accuracy: 0.51 - ETA: 0s - loss: 1.0170 - accuracy: 0.52 - ETA: 0s - loss: 0.9890 - accuracy: 0.55 - ETA: 0s - loss: 0.9804 - accuracy: 0.56 - ETA: 0s - loss: 0.9621 - accuracy: 0.58 - ETA: 0s - loss: 0.9555 - accuracy: 0.58 - ETA: 0s - loss: 0.9528 - accuracy: 0.59 - ETA: 0s - loss: 0.9526 - accuracy: 0.59 - ETA: 0s - loss: 0.9629 - accuracy: 0.58 - ETA: 0s - loss: 0.9518 - accuracy: 0.59 - ETA: 0s - loss: 0.9363 - accuracy: 0.60 - ETA: 0s - loss: 0.9163 - accuracy: 0.62 - ETA: 0s - loss: 0.9310 - accuracy: 0.61 - ETA: 0s - loss: 0.9517 - accuracy: 0.59 - ETA: 0s - loss: 0.9534 - accuracy: 0.59 - ETA: 0s - loss: 0.9576 - accuracy: 0.59 - ETA: 0s - loss: 0.9587 - accuracy: 0.58 - ETA: 0s - loss: 0.9611 - accuracy: 0.5877\n",
      "Epoch 00032: val_loss did not improve from 1.01635\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9611 - accuracy: 0.5877 - val_loss: 1.0207 - val_accuracy: 0.5039 - lr: 0.0900\n",
      "Epoch 33/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0223 - accuracy: 0.50 - ETA: 0s - loss: 1.0279 - accuracy: 0.50 - ETA: 0s - loss: 1.0186 - accuracy: 0.51 - ETA: 0s - loss: 0.9930 - accuracy: 0.55 - ETA: 0s - loss: 0.9824 - accuracy: 0.56 - ETA: 0s - loss: 0.9639 - accuracy: 0.57 - ETA: 0s - loss: 0.9560 - accuracy: 0.58 - ETA: 0s - loss: 0.9528 - accuracy: 0.59 - ETA: 0s - loss: 0.9543 - accuracy: 0.59 - ETA: 0s - loss: 0.9665 - accuracy: 0.58 - ETA: 0s - loss: 0.9547 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.60 - ETA: 0s - loss: 0.9185 - accuracy: 0.61 - ETA: 0s - loss: 0.9316 - accuracy: 0.60 - ETA: 0s - loss: 0.9502 - accuracy: 0.59 - ETA: 0s - loss: 0.9520 - accuracy: 0.59 - ETA: 0s - loss: 0.9564 - accuracy: 0.58 - ETA: 0s - loss: 0.9573 - accuracy: 0.58 - ETA: 0s - loss: 0.9592 - accuracy: 0.5873\n",
      "Epoch 00033: val_loss did not improve from 1.01635\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9592 - accuracy: 0.5873 - val_loss: 1.0196 - val_accuracy: 0.4985 - lr: 0.0900\n",
      "Epoch 34/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0149 - accuracy: 0.52 - ETA: 0s - loss: 1.0184 - accuracy: 0.51 - ETA: 0s - loss: 1.0126 - accuracy: 0.52 - ETA: 0s - loss: 0.9917 - accuracy: 0.55 - ETA: 0s - loss: 0.9834 - accuracy: 0.56 - ETA: 0s - loss: 0.9657 - accuracy: 0.58 - ETA: 0s - loss: 0.9581 - accuracy: 0.59 - ETA: 0s - loss: 0.9539 - accuracy: 0.59 - ETA: 0s - loss: 0.9544 - accuracy: 0.59 - ETA: 0s - loss: 0.9658 - accuracy: 0.58 - ETA: 0s - loss: 0.9538 - accuracy: 0.59 - ETA: 0s - loss: 0.9373 - accuracy: 0.60 - ETA: 0s - loss: 0.9161 - accuracy: 0.62 - ETA: 0s - loss: 0.9315 - accuracy: 0.61 - ETA: 0s - loss: 0.9526 - accuracy: 0.59 - ETA: 0s - loss: 0.9545 - accuracy: 0.59 - ETA: 0s - loss: 0.9587 - accuracy: 0.59 - ETA: 0s - loss: 0.9592 - accuracy: 0.59 - ETA: 0s - loss: 0.9605 - accuracy: 0.5893\n",
      "Epoch 00034: val_loss did not improve from 1.01635\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9605 - accuracy: 0.5893 - val_loss: 1.0249 - val_accuracy: 0.4971 - lr: 0.0900\n",
      "Epoch 35/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0192 - accuracy: 0.52 - ETA: 0s - loss: 1.0234 - accuracy: 0.51 - ETA: 0s - loss: 1.0172 - accuracy: 0.52 - ETA: 0s - loss: 0.9947 - accuracy: 0.55 - ETA: 0s - loss: 0.9865 - accuracy: 0.56 - ETA: 0s - loss: 0.9696 - accuracy: 0.58 - ETA: 0s - loss: 0.9622 - accuracy: 0.59 - ETA: 0s - loss: 0.9607 - accuracy: 0.59 - ETA: 0s - loss: 0.9640 - accuracy: 0.59 - ETA: 0s - loss: 0.9772 - accuracy: 0.58 - ETA: 0s - loss: 0.9646 - accuracy: 0.59 - ETA: 0s - loss: 0.9490 - accuracy: 0.60 - ETA: 0s - loss: 0.9297 - accuracy: 0.62 - ETA: 0s - loss: 0.9413 - accuracy: 0.61 - ETA: 0s - loss: 0.9591 - accuracy: 0.59 - ETA: 0s - loss: 0.9605 - accuracy: 0.59 - ETA: 0s - loss: 0.9646 - accuracy: 0.59 - ETA: 0s - loss: 0.9655 - accuracy: 0.59 - ETA: 0s - loss: 0.9670 - accuracy: 0.5893\n",
      "Epoch 00035: val_loss did not improve from 1.01635\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9670 - accuracy: 0.5893 - val_loss: 1.0198 - val_accuracy: 0.4971 - lr: 0.0900\n",
      "Epoch 36/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0137 - accuracy: 0.52 - ETA: 0s - loss: 1.0211 - accuracy: 0.51 - ETA: 0s - loss: 1.0133 - accuracy: 0.53 - ETA: 0s - loss: 0.9887 - accuracy: 0.56 - ETA: 0s - loss: 0.9794 - accuracy: 0.57 - ETA: 0s - loss: 0.9601 - accuracy: 0.58 - ETA: 0s - loss: 0.9542 - accuracy: 0.59 - ETA: 0s - loss: 0.9530 - accuracy: 0.59 - ETA: 0s - loss: 0.9550 - accuracy: 0.59 - ETA: 0s - loss: 0.9672 - accuracy: 0.58 - ETA: 0s - loss: 0.9555 - accuracy: 0.59 - ETA: 0s - loss: 0.9395 - accuracy: 0.60 - ETA: 0s - loss: 0.9193 - accuracy: 0.62 - ETA: 0s - loss: 0.9329 - accuracy: 0.61 - ETA: 0s - loss: 0.9521 - accuracy: 0.59 - ETA: 0s - loss: 0.9535 - accuracy: 0.59 - ETA: 0s - loss: 0.9577 - accuracy: 0.59 - ETA: 0s - loss: 0.9582 - accuracy: 0.59 - ETA: 0s - loss: 0.9596 - accuracy: 0.5898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00036: val_loss did not improve from 1.01635\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9596 - accuracy: 0.5898 - val_loss: 1.0228 - val_accuracy: 0.4979 - lr: 0.0900\n",
      "Epoch 37/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0136 - accuracy: 0.52 - ETA: 0s - loss: 1.0189 - accuracy: 0.51 - ETA: 0s - loss: 1.0117 - accuracy: 0.52 - ETA: 0s - loss: 0.9888 - accuracy: 0.55 - ETA: 0s - loss: 0.9810 - accuracy: 0.56 - ETA: 0s - loss: 0.9636 - accuracy: 0.58 - ETA: 0s - loss: 0.9593 - accuracy: 0.59 - ETA: 0s - loss: 0.9578 - accuracy: 0.59 - ETA: 0s - loss: 0.9592 - accuracy: 0.59 - ETA: 0s - loss: 0.9704 - accuracy: 0.58 - ETA: 0s - loss: 0.9595 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.60 - ETA: 0s - loss: 0.9242 - accuracy: 0.62 - ETA: 0s - loss: 0.9364 - accuracy: 0.61 - ETA: 0s - loss: 0.9544 - accuracy: 0.59 - ETA: 0s - loss: 0.9559 - accuracy: 0.59 - ETA: 0s - loss: 0.9601 - accuracy: 0.59 - ETA: 0s - loss: 0.9607 - accuracy: 0.59 - ETA: 0s - loss: 0.9621 - accuracy: 0.5891\n",
      "Epoch 00037: val_loss did not improve from 1.01635\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.07200000286102295.\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9621 - accuracy: 0.5891 - val_loss: 1.0189 - val_accuracy: 0.5039 - lr: 0.0900\n",
      "Epoch 38/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0109 - accuracy: 0.52 - ETA: 0s - loss: 1.0183 - accuracy: 0.51 - ETA: 0s - loss: 1.0107 - accuracy: 0.52 - ETA: 0s - loss: 0.9887 - accuracy: 0.55 - ETA: 0s - loss: 0.9794 - accuracy: 0.56 - ETA: 0s - loss: 0.9622 - accuracy: 0.58 - ETA: 0s - loss: 0.9555 - accuracy: 0.59 - ETA: 0s - loss: 0.9526 - accuracy: 0.59 - ETA: 0s - loss: 0.9533 - accuracy: 0.59 - ETA: 0s - loss: 0.9654 - accuracy: 0.58 - ETA: 0s - loss: 0.9532 - accuracy: 0.59 - ETA: 0s - loss: 0.9371 - accuracy: 0.60 - ETA: 0s - loss: 0.9157 - accuracy: 0.62 - ETA: 0s - loss: 0.9311 - accuracy: 0.61 - ETA: 0s - loss: 0.9515 - accuracy: 0.59 - ETA: 0s - loss: 0.9533 - accuracy: 0.59 - ETA: 0s - loss: 0.9576 - accuracy: 0.59 - ETA: 0s - loss: 0.9581 - accuracy: 0.59 - ETA: 0s - loss: 0.9596 - accuracy: 0.5894\n",
      "Epoch 00038: val_loss did not improve from 1.01635\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9596 - accuracy: 0.5894 - val_loss: 1.0190 - val_accuracy: 0.4987 - lr: 0.0720\n",
      "Epoch 39/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0153 - accuracy: 0.52 - ETA: 0s - loss: 1.0195 - accuracy: 0.51 - ETA: 0s - loss: 1.0142 - accuracy: 0.52 - ETA: 0s - loss: 0.9958 - accuracy: 0.55 - ETA: 0s - loss: 0.9893 - accuracy: 0.56 - ETA: 0s - loss: 0.9749 - accuracy: 0.58 - ETA: 0s - loss: 0.9679 - accuracy: 0.58 - ETA: 0s - loss: 0.9630 - accuracy: 0.59 - ETA: 0s - loss: 0.9616 - accuracy: 0.59 - ETA: 0s - loss: 0.9701 - accuracy: 0.58 - ETA: 0s - loss: 0.9584 - accuracy: 0.59 - ETA: 0s - loss: 0.9418 - accuracy: 0.60 - ETA: 0s - loss: 0.9207 - accuracy: 0.62 - ETA: 0s - loss: 0.9369 - accuracy: 0.61 - ETA: 0s - loss: 0.9600 - accuracy: 0.59 - ETA: 0s - loss: 0.9617 - accuracy: 0.59 - ETA: 0s - loss: 0.9667 - accuracy: 0.58 - ETA: 0s - loss: 0.9664 - accuracy: 0.58 - ETA: 0s - loss: 0.9674 - accuracy: 0.5887\n",
      "Epoch 00039: val_loss did not improve from 1.01635\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9674 - accuracy: 0.5887 - val_loss: 1.0316 - val_accuracy: 0.4971 - lr: 0.0720\n",
      "Epoch 40/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0122 - accuracy: 0.52 - ETA: 0s - loss: 1.0209 - accuracy: 0.51 - ETA: 0s - loss: 1.0186 - accuracy: 0.52 - ETA: 0s - loss: 0.9996 - accuracy: 0.55 - ETA: 0s - loss: 0.9915 - accuracy: 0.56 - ETA: 0s - loss: 0.9744 - accuracy: 0.58 - ETA: 0s - loss: 0.9661 - accuracy: 0.58 - ETA: 0s - loss: 0.9616 - accuracy: 0.59 - ETA: 0s - loss: 0.9602 - accuracy: 0.59 - ETA: 0s - loss: 0.9709 - accuracy: 0.58 - ETA: 0s - loss: 0.9593 - accuracy: 0.59 - ETA: 0s - loss: 0.9421 - accuracy: 0.60 - ETA: 0s - loss: 0.9207 - accuracy: 0.62 - ETA: 0s - loss: 0.9359 - accuracy: 0.61 - ETA: 0s - loss: 0.9566 - accuracy: 0.59 - ETA: 0s - loss: 0.9588 - accuracy: 0.59 - ETA: 0s - loss: 0.9628 - accuracy: 0.59 - ETA: 0s - loss: 0.9637 - accuracy: 0.59 - ETA: 0s - loss: 0.9654 - accuracy: 0.5888\n",
      "Epoch 00040: val_loss improved from 1.01635 to 1.01564, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 2s 87ms/step - loss: 0.9654 - accuracy: 0.5888 - val_loss: 1.0156 - val_accuracy: 0.5060 - lr: 0.0720\n",
      "Epoch 41/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0297 - accuracy: 0.50 - ETA: 0s - loss: 1.0262 - accuracy: 0.50 - ETA: 0s - loss: 1.0193 - accuracy: 0.51 - ETA: 0s - loss: 0.9945 - accuracy: 0.55 - ETA: 0s - loss: 0.9843 - accuracy: 0.56 - ETA: 0s - loss: 0.9654 - accuracy: 0.57 - ETA: 0s - loss: 0.9572 - accuracy: 0.58 - ETA: 0s - loss: 0.9535 - accuracy: 0.58 - ETA: 0s - loss: 0.9542 - accuracy: 0.58 - ETA: 0s - loss: 0.9664 - accuracy: 0.58 - ETA: 0s - loss: 0.9539 - accuracy: 0.59 - ETA: 0s - loss: 0.9377 - accuracy: 0.60 - ETA: 0s - loss: 0.9170 - accuracy: 0.61 - ETA: 0s - loss: 0.9320 - accuracy: 0.60 - ETA: 0s - loss: 0.9525 - accuracy: 0.59 - ETA: 0s - loss: 0.9539 - accuracy: 0.59 - ETA: 0s - loss: 0.9580 - accuracy: 0.58 - ETA: 0s - loss: 0.9586 - accuracy: 0.58 - ETA: 0s - loss: 0.9607 - accuracy: 0.5868\n",
      "Epoch 00041: val_loss did not improve from 1.01564\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9607 - accuracy: 0.5868 - val_loss: 1.0196 - val_accuracy: 0.5000 - lr: 0.0720\n",
      "Epoch 42/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0241 - accuracy: 0.52 - ETA: 0s - loss: 1.0245 - accuracy: 0.51 - ETA: 0s - loss: 1.0181 - accuracy: 0.52 - ETA: 0s - loss: 0.9949 - accuracy: 0.55 - ETA: 0s - loss: 0.9855 - accuracy: 0.56 - ETA: 0s - loss: 0.9677 - accuracy: 0.58 - ETA: 0s - loss: 0.9601 - accuracy: 0.59 - ETA: 0s - loss: 0.9558 - accuracy: 0.59 - ETA: 0s - loss: 0.9549 - accuracy: 0.59 - ETA: 0s - loss: 0.9647 - accuracy: 0.58 - ETA: 0s - loss: 0.9531 - accuracy: 0.59 - ETA: 0s - loss: 0.9369 - accuracy: 0.60 - ETA: 0s - loss: 0.9159 - accuracy: 0.62 - ETA: 0s - loss: 0.9310 - accuracy: 0.61 - ETA: 0s - loss: 0.9521 - accuracy: 0.59 - ETA: 0s - loss: 0.9544 - accuracy: 0.59 - ETA: 0s - loss: 0.9594 - accuracy: 0.59 - ETA: 0s - loss: 0.9608 - accuracy: 0.59 - ETA: 0s - loss: 0.9630 - accuracy: 0.5885\n",
      "Epoch 00042: val_loss did not improve from 1.01564\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9630 - accuracy: 0.5885 - val_loss: 1.0226 - val_accuracy: 0.4974 - lr: 0.0720\n",
      "Epoch 43/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0214 - accuracy: 0.52 - ETA: 0s - loss: 1.0346 - accuracy: 0.51 - ETA: 0s - loss: 1.0221 - accuracy: 0.52 - ETA: 0s - loss: 0.9961 - accuracy: 0.55 - ETA: 0s - loss: 0.9863 - accuracy: 0.56 - ETA: 0s - loss: 0.9694 - accuracy: 0.58 - ETA: 0s - loss: 0.9616 - accuracy: 0.58 - ETA: 0s - loss: 0.9572 - accuracy: 0.59 - ETA: 0s - loss: 0.9555 - accuracy: 0.59 - ETA: 0s - loss: 0.9642 - accuracy: 0.58 - ETA: 0s - loss: 0.9530 - accuracy: 0.59 - ETA: 0s - loss: 0.9375 - accuracy: 0.60 - ETA: 0s - loss: 0.9168 - accuracy: 0.62 - ETA: 0s - loss: 0.9317 - accuracy: 0.61 - ETA: 0s - loss: 0.9532 - accuracy: 0.59 - ETA: 0s - loss: 0.9551 - accuracy: 0.59 - ETA: 0s - loss: 0.9597 - accuracy: 0.58 - ETA: 0s - loss: 0.9602 - accuracy: 0.58 - ETA: 0s - loss: 0.9618 - accuracy: 0.5877\n",
      "Epoch 00043: val_loss did not improve from 1.01564\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9618 - accuracy: 0.5877 - val_loss: 1.0162 - val_accuracy: 0.5047 - lr: 0.0720\n",
      "Epoch 44/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0279 - accuracy: 0.52 - ETA: 0s - loss: 1.0282 - accuracy: 0.51 - ETA: 0s - loss: 1.0202 - accuracy: 0.52 - ETA: 0s - loss: 0.9953 - accuracy: 0.55 - ETA: 0s - loss: 0.9852 - accuracy: 0.56 - ETA: 0s - loss: 0.9674 - accuracy: 0.58 - ETA: 0s - loss: 0.9603 - accuracy: 0.58 - ETA: 0s - loss: 0.9566 - accuracy: 0.59 - ETA: 0s - loss: 0.9559 - accuracy: 0.59 - ETA: 0s - loss: 0.9666 - accuracy: 0.58 - ETA: 0s - loss: 0.9545 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.60 - ETA: 0s - loss: 0.9166 - accuracy: 0.62 - ETA: 0s - loss: 0.9325 - accuracy: 0.61 - ETA: 0s - loss: 0.9547 - accuracy: 0.59 - ETA: 0s - loss: 0.9562 - accuracy: 0.59 - ETA: 0s - loss: 0.9604 - accuracy: 0.58 - ETA: 0s - loss: 0.9607 - accuracy: 0.58 - ETA: 0s - loss: 0.9628 - accuracy: 0.5885\n",
      "Epoch 00044: val_loss did not improve from 1.01564\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9628 - accuracy: 0.5885 - val_loss: 1.0180 - val_accuracy: 0.4971 - lr: 0.0720\n",
      "Epoch 45/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0160 - accuracy: 0.52 - ETA: 0s - loss: 1.0228 - accuracy: 0.52 - ETA: 0s - loss: 1.0145 - accuracy: 0.52 - ETA: 0s - loss: 0.9939 - accuracy: 0.55 - ETA: 0s - loss: 0.9859 - accuracy: 0.56 - ETA: 0s - loss: 0.9687 - accuracy: 0.58 - ETA: 0s - loss: 0.9608 - accuracy: 0.58 - ETA: 0s - loss: 0.9564 - accuracy: 0.59 - ETA: 0s - loss: 0.9559 - accuracy: 0.59 - ETA: 0s - loss: 0.9676 - accuracy: 0.58 - ETA: 0s - loss: 0.9553 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.60 - ETA: 0s - loss: 0.9174 - accuracy: 0.62 - ETA: 0s - loss: 0.9331 - accuracy: 0.61 - ETA: 0s - loss: 0.9553 - accuracy: 0.59 - ETA: 0s - loss: 0.9568 - accuracy: 0.59 - ETA: 0s - loss: 0.9607 - accuracy: 0.59 - ETA: 0s - loss: 0.9612 - accuracy: 0.58 - ETA: 0s - loss: 0.9628 - accuracy: 0.5888\n",
      "Epoch 00045: val_loss did not improve from 1.01564\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9628 - accuracy: 0.5888 - val_loss: 1.0223 - val_accuracy: 0.4980 - lr: 0.0720\n",
      "Epoch 46/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0127 - accuracy: 0.52 - ETA: 0s - loss: 1.0197 - accuracy: 0.51 - ETA: 0s - loss: 1.0143 - accuracy: 0.53 - ETA: 0s - loss: 0.9957 - accuracy: 0.55 - ETA: 0s - loss: 0.9883 - accuracy: 0.56 - ETA: 0s - loss: 0.9719 - accuracy: 0.58 - ETA: 0s - loss: 0.9638 - accuracy: 0.59 - ETA: 0s - loss: 0.9587 - accuracy: 0.59 - ETA: 0s - loss: 0.9587 - accuracy: 0.59 - ETA: 0s - loss: 0.9714 - accuracy: 0.58 - ETA: 0s - loss: 0.9593 - accuracy: 0.59 - ETA: 0s - loss: 0.9423 - accuracy: 0.60 - ETA: 0s - loss: 0.9205 - accuracy: 0.62 - ETA: 0s - loss: 0.9367 - accuracy: 0.61 - ETA: 0s - loss: 0.9596 - accuracy: 0.59 - ETA: 0s - loss: 0.9610 - accuracy: 0.59 - ETA: 0s - loss: 0.9649 - accuracy: 0.59 - ETA: 0s - loss: 0.9653 - accuracy: 0.59 - ETA: 0s - loss: 0.9666 - accuracy: 0.5894\n",
      "Epoch 00046: val_loss did not improve from 1.01564\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9666 - accuracy: 0.5894 - val_loss: 1.0228 - val_accuracy: 0.5068 - lr: 0.0720\n",
      "Epoch 47/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0197 - accuracy: 0.51 - ETA: 0s - loss: 1.0237 - accuracy: 0.51 - ETA: 0s - loss: 1.0165 - accuracy: 0.52 - ETA: 0s - loss: 0.9947 - accuracy: 0.55 - ETA: 0s - loss: 0.9867 - accuracy: 0.56 - ETA: 0s - loss: 0.9692 - accuracy: 0.58 - ETA: 0s - loss: 0.9612 - accuracy: 0.58 - ETA: 0s - loss: 0.9571 - accuracy: 0.59 - ETA: 0s - loss: 0.9572 - accuracy: 0.59 - ETA: 0s - loss: 0.9701 - accuracy: 0.58 - ETA: 0s - loss: 0.9576 - accuracy: 0.59 - ETA: 0s - loss: 0.9411 - accuracy: 0.60 - ETA: 0s - loss: 0.9202 - accuracy: 0.62 - ETA: 0s - loss: 0.9349 - accuracy: 0.61 - ETA: 0s - loss: 0.9550 - accuracy: 0.59 - ETA: 0s - loss: 0.9563 - accuracy: 0.59 - ETA: 0s - loss: 0.9600 - accuracy: 0.58 - ETA: 0s - loss: 0.9612 - accuracy: 0.58 - ETA: 0s - loss: 0.9634 - accuracy: 0.5883\n",
      "Epoch 00047: val_loss did not improve from 1.01564\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9634 - accuracy: 0.5883 - val_loss: 1.0240 - val_accuracy: 0.5036 - lr: 0.0720\n",
      "Epoch 48/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0187 - accuracy: 0.52 - ETA: 0s - loss: 1.0217 - accuracy: 0.51 - ETA: 0s - loss: 1.0142 - accuracy: 0.52 - ETA: 0s - loss: 0.9914 - accuracy: 0.55 - ETA: 0s - loss: 0.9824 - accuracy: 0.56 - ETA: 0s - loss: 0.9637 - accuracy: 0.58 - ETA: 0s - loss: 0.9568 - accuracy: 0.58 - ETA: 0s - loss: 0.9545 - accuracy: 0.59 - ETA: 0s - loss: 0.9564 - accuracy: 0.59 - ETA: 0s - loss: 0.9698 - accuracy: 0.58 - ETA: 0s - loss: 0.9584 - accuracy: 0.59 - ETA: 0s - loss: 0.9412 - accuracy: 0.60 - ETA: 0s - loss: 0.9197 - accuracy: 0.61 - ETA: 0s - loss: 0.9341 - accuracy: 0.61 - ETA: 0s - loss: 0.9535 - accuracy: 0.59 - ETA: 0s - loss: 0.9550 - accuracy: 0.59 - ETA: 0s - loss: 0.9593 - accuracy: 0.58 - ETA: 0s - loss: 0.9598 - accuracy: 0.58 - ETA: 0s - loss: 0.9613 - accuracy: 0.5884\n",
      "Epoch 00048: val_loss did not improve from 1.01564\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9613 - accuracy: 0.5884 - val_loss: 1.0269 - val_accuracy: 0.4971 - lr: 0.0720\n",
      "Epoch 49/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0119 - accuracy: 0.52 - ETA: 0s - loss: 1.0212 - accuracy: 0.51 - ETA: 0s - loss: 1.0130 - accuracy: 0.52 - ETA: 0s - loss: 0.9921 - accuracy: 0.55 - ETA: 0s - loss: 0.9829 - accuracy: 0.56 - ETA: 0s - loss: 0.9668 - accuracy: 0.58 - ETA: 0s - loss: 0.9597 - accuracy: 0.59 - ETA: 0s - loss: 0.9564 - accuracy: 0.59 - ETA: 0s - loss: 0.9562 - accuracy: 0.59 - ETA: 0s - loss: 0.9674 - accuracy: 0.58 - ETA: 0s - loss: 0.9552 - accuracy: 0.59 - ETA: 0s - loss: 0.9393 - accuracy: 0.60 - ETA: 0s - loss: 0.9178 - accuracy: 0.62 - ETA: 0s - loss: 0.9339 - accuracy: 0.61 - ETA: 0s - loss: 0.9549 - accuracy: 0.59 - ETA: 0s - loss: 0.9563 - accuracy: 0.59 - ETA: 0s - loss: 0.9598 - accuracy: 0.59 - ETA: 0s - loss: 0.9613 - accuracy: 0.59 - ETA: 0s - loss: 0.9635 - accuracy: 0.5878\n",
      "Epoch 00049: val_loss did not improve from 1.01564\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9635 - accuracy: 0.5878 - val_loss: 1.0160 - val_accuracy: 0.5086 - lr: 0.0720\n",
      "Epoch 50/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0223 - accuracy: 0.53 - ETA: 0s - loss: 1.0197 - accuracy: 0.51 - ETA: 0s - loss: 1.0128 - accuracy: 0.52 - ETA: 0s - loss: 0.9890 - accuracy: 0.55 - ETA: 0s - loss: 0.9800 - accuracy: 0.56 - ETA: 0s - loss: 0.9608 - accuracy: 0.58 - ETA: 0s - loss: 0.9552 - accuracy: 0.59 - ETA: 0s - loss: 0.9531 - accuracy: 0.59 - ETA: 0s - loss: 0.9546 - accuracy: 0.59 - ETA: 0s - loss: 0.9678 - accuracy: 0.58 - ETA: 0s - loss: 0.9554 - accuracy: 0.59 - ETA: 0s - loss: 0.9395 - accuracy: 0.60 - ETA: 0s - loss: 0.9194 - accuracy: 0.62 - ETA: 0s - loss: 0.9324 - accuracy: 0.61 - ETA: 0s - loss: 0.9508 - accuracy: 0.59 - ETA: 0s - loss: 0.9521 - accuracy: 0.59 - ETA: 0s - loss: 0.9561 - accuracy: 0.59 - ETA: 0s - loss: 0.9566 - accuracy: 0.59 - ETA: 0s - loss: 0.9582 - accuracy: 0.5894\n",
      "Epoch 00050: val_loss did not improve from 1.01564\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9582 - accuracy: 0.5894 - val_loss: 1.0208 - val_accuracy: 0.4974 - lr: 0.0720\n",
      "Epoch 51/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0120 - accuracy: 0.52 - ETA: 0s - loss: 1.0171 - accuracy: 0.51 - ETA: 0s - loss: 1.0095 - accuracy: 0.52 - ETA: 0s - loss: 0.9898 - accuracy: 0.55 - ETA: 0s - loss: 0.9825 - accuracy: 0.56 - ETA: 0s - loss: 0.9673 - accuracy: 0.58 - ETA: 0s - loss: 0.9603 - accuracy: 0.59 - ETA: 0s - loss: 0.9563 - accuracy: 0.59 - ETA: 0s - loss: 0.9548 - accuracy: 0.59 - ETA: 0s - loss: 0.9649 - accuracy: 0.58 - ETA: 0s - loss: 0.9537 - accuracy: 0.59 - ETA: 0s - loss: 0.9372 - accuracy: 0.60 - ETA: 0s - loss: 0.9151 - accuracy: 0.62 - ETA: 0s - loss: 0.9317 - accuracy: 0.61 - ETA: 0s - loss: 0.9548 - accuracy: 0.59 - ETA: 0s - loss: 0.9565 - accuracy: 0.59 - ETA: 0s - loss: 0.9608 - accuracy: 0.59 - ETA: 0s - loss: 0.9609 - accuracy: 0.59 - ETA: 0s - loss: 0.9621 - accuracy: 0.5897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00051: val_loss did not improve from 1.01564\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.05760000348091126.\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9621 - accuracy: 0.5897 - val_loss: 1.0171 - val_accuracy: 0.5064 - lr: 0.0720\n",
      "Epoch 52/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0104 - accuracy: 0.51 - ETA: 0s - loss: 1.0143 - accuracy: 0.51 - ETA: 0s - loss: 1.0089 - accuracy: 0.52 - ETA: 0s - loss: 0.9925 - accuracy: 0.55 - ETA: 0s - loss: 0.9859 - accuracy: 0.56 - ETA: 0s - loss: 0.9702 - accuracy: 0.58 - ETA: 0s - loss: 0.9624 - accuracy: 0.59 - ETA: 0s - loss: 0.9580 - accuracy: 0.59 - ETA: 0s - loss: 0.9570 - accuracy: 0.59 - ETA: 0s - loss: 0.9679 - accuracy: 0.58 - ETA: 0s - loss: 0.9556 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.60 - ETA: 0s - loss: 0.9171 - accuracy: 0.62 - ETA: 0s - loss: 0.9338 - accuracy: 0.61 - ETA: 0s - loss: 0.9567 - accuracy: 0.59 - ETA: 0s - loss: 0.9582 - accuracy: 0.59 - ETA: 0s - loss: 0.9628 - accuracy: 0.59 - ETA: 0s - loss: 0.9627 - accuracy: 0.59 - ETA: 0s - loss: 0.9638 - accuracy: 0.5891\n",
      "Epoch 00052: val_loss did not improve from 1.01564\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9638 - accuracy: 0.5891 - val_loss: 1.0189 - val_accuracy: 0.4971 - lr: 0.0576\n",
      "Epoch 53/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0071 - accuracy: 0.52 - ETA: 0s - loss: 1.0186 - accuracy: 0.51 - ETA: 0s - loss: 1.0106 - accuracy: 0.52 - ETA: 0s - loss: 0.9928 - accuracy: 0.55 - ETA: 0s - loss: 0.9866 - accuracy: 0.56 - ETA: 0s - loss: 0.9723 - accuracy: 0.58 - ETA: 0s - loss: 0.9657 - accuracy: 0.58 - ETA: 0s - loss: 0.9606 - accuracy: 0.59 - ETA: 0s - loss: 0.9584 - accuracy: 0.59 - ETA: 0s - loss: 0.9668 - accuracy: 0.58 - ETA: 0s - loss: 0.9549 - accuracy: 0.59 - ETA: 0s - loss: 0.9384 - accuracy: 0.60 - ETA: 0s - loss: 0.9169 - accuracy: 0.61 - ETA: 0s - loss: 0.9334 - accuracy: 0.61 - ETA: 0s - loss: 0.9562 - accuracy: 0.59 - ETA: 0s - loss: 0.9583 - accuracy: 0.59 - ETA: 0s - loss: 0.9628 - accuracy: 0.58 - ETA: 0s - loss: 0.9633 - accuracy: 0.58 - ETA: 0s - loss: 0.9649 - accuracy: 0.5868\n",
      "Epoch 00053: val_loss did not improve from 1.01564\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9649 - accuracy: 0.5868 - val_loss: 1.0159 - val_accuracy: 0.5064 - lr: 0.0576\n",
      "Epoch 54/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0203 - accuracy: 0.51 - ETA: 0s - loss: 1.0266 - accuracy: 0.50 - ETA: 0s - loss: 1.0179 - accuracy: 0.51 - ETA: 0s - loss: 0.9987 - accuracy: 0.54 - ETA: 0s - loss: 0.9905 - accuracy: 0.55 - ETA: 0s - loss: 0.9727 - accuracy: 0.57 - ETA: 0s - loss: 0.9648 - accuracy: 0.58 - ETA: 0s - loss: 0.9598 - accuracy: 0.58 - ETA: 0s - loss: 0.9580 - accuracy: 0.58 - ETA: 0s - loss: 0.9672 - accuracy: 0.58 - ETA: 0s - loss: 0.9552 - accuracy: 0.59 - ETA: 0s - loss: 0.9385 - accuracy: 0.60 - ETA: 0s - loss: 0.9170 - accuracy: 0.61 - ETA: 0s - loss: 0.9321 - accuracy: 0.60 - ETA: 0s - loss: 0.9537 - accuracy: 0.59 - ETA: 0s - loss: 0.9556 - accuracy: 0.59 - ETA: 0s - loss: 0.9605 - accuracy: 0.58 - ETA: 0s - loss: 0.9609 - accuracy: 0.58 - ETA: 0s - loss: 0.9622 - accuracy: 0.5869\n",
      "Epoch 00054: val_loss did not improve from 1.01564\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9622 - accuracy: 0.5869 - val_loss: 1.0191 - val_accuracy: 0.4971 - lr: 0.0576\n",
      "Epoch 55/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0126 - accuracy: 0.52 - ETA: 0s - loss: 1.0227 - accuracy: 0.51 - ETA: 0s - loss: 1.0179 - accuracy: 0.52 - ETA: 0s - loss: 0.9961 - accuracy: 0.55 - ETA: 0s - loss: 0.9885 - accuracy: 0.56 - ETA: 0s - loss: 0.9738 - accuracy: 0.57 - ETA: 0s - loss: 0.9666 - accuracy: 0.58 - ETA: 0s - loss: 0.9616 - accuracy: 0.58 - ETA: 0s - loss: 0.9594 - accuracy: 0.58 - ETA: 0s - loss: 0.9673 - accuracy: 0.58 - ETA: 0s - loss: 0.9555 - accuracy: 0.59 - ETA: 0s - loss: 0.9397 - accuracy: 0.60 - ETA: 0s - loss: 0.9189 - accuracy: 0.61 - ETA: 0s - loss: 0.9330 - accuracy: 0.60 - ETA: 0s - loss: 0.9539 - accuracy: 0.59 - ETA: 0s - loss: 0.9555 - accuracy: 0.59 - ETA: 0s - loss: 0.9603 - accuracy: 0.58 - ETA: 0s - loss: 0.9604 - accuracy: 0.58 - ETA: 0s - loss: 0.9616 - accuracy: 0.5875\n",
      "Epoch 00055: val_loss did not improve from 1.01564\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9616 - accuracy: 0.5875 - val_loss: 1.0210 - val_accuracy: 0.4976 - lr: 0.0576\n",
      "Epoch 56/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0169 - accuracy: 0.53 - ETA: 0s - loss: 1.0245 - accuracy: 0.52 - ETA: 0s - loss: 1.0124 - accuracy: 0.53 - ETA: 0s - loss: 0.9956 - accuracy: 0.56 - ETA: 0s - loss: 0.9880 - accuracy: 0.57 - ETA: 0s - loss: 0.9732 - accuracy: 0.58 - ETA: 0s - loss: 0.9658 - accuracy: 0.59 - ETA: 0s - loss: 0.9612 - accuracy: 0.59 - ETA: 0s - loss: 0.9589 - accuracy: 0.59 - ETA: 0s - loss: 0.9673 - accuracy: 0.58 - ETA: 0s - loss: 0.9555 - accuracy: 0.59 - ETA: 0s - loss: 0.9391 - accuracy: 0.60 - ETA: 0s - loss: 0.9176 - accuracy: 0.62 - ETA: 0s - loss: 0.9325 - accuracy: 0.61 - ETA: 0s - loss: 0.9543 - accuracy: 0.59 - ETA: 0s - loss: 0.9563 - accuracy: 0.59 - ETA: 0s - loss: 0.9614 - accuracy: 0.59 - ETA: 0s - loss: 0.9613 - accuracy: 0.59 - ETA: 0s - loss: 0.9622 - accuracy: 0.5901\n",
      "Epoch 00056: val_loss did not improve from 1.01564\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9622 - accuracy: 0.5901 - val_loss: 1.0234 - val_accuracy: 0.4971 - lr: 0.0576\n",
      "Epoch 57/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0162 - accuracy: 0.52 - ETA: 0s - loss: 1.0215 - accuracy: 0.51 - ETA: 0s - loss: 1.0127 - accuracy: 0.52 - ETA: 0s - loss: 0.9912 - accuracy: 0.55 - ETA: 0s - loss: 0.9841 - accuracy: 0.56 - ETA: 0s - loss: 0.9715 - accuracy: 0.58 - ETA: 0s - loss: 0.9654 - accuracy: 0.58 - ETA: 0s - loss: 0.9617 - accuracy: 0.59 - ETA: 0s - loss: 0.9595 - accuracy: 0.59 - ETA: 0s - loss: 0.9663 - accuracy: 0.58 - ETA: 0s - loss: 0.9552 - accuracy: 0.59 - ETA: 0s - loss: 0.9404 - accuracy: 0.60 - ETA: 0s - loss: 0.9203 - accuracy: 0.62 - ETA: 0s - loss: 0.9338 - accuracy: 0.61 - ETA: 0s - loss: 0.9546 - accuracy: 0.59 - ETA: 0s - loss: 0.9564 - accuracy: 0.59 - ETA: 0s - loss: 0.9618 - accuracy: 0.58 - ETA: 0s - loss: 0.9617 - accuracy: 0.59 - ETA: 0s - loss: 0.9629 - accuracy: 0.5889\n",
      "Epoch 00057: val_loss did not improve from 1.01564\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9629 - accuracy: 0.5889 - val_loss: 1.0290 - val_accuracy: 0.4971 - lr: 0.0576\n",
      "Epoch 58/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0121 - accuracy: 0.52 - ETA: 0s - loss: 1.0191 - accuracy: 0.51 - ETA: 0s - loss: 1.0109 - accuracy: 0.52 - ETA: 0s - loss: 0.9860 - accuracy: 0.55 - ETA: 0s - loss: 0.9800 - accuracy: 0.56 - ETA: 0s - loss: 0.9675 - accuracy: 0.58 - ETA: 0s - loss: 0.9626 - accuracy: 0.59 - ETA: 0s - loss: 0.9592 - accuracy: 0.59 - ETA: 0s - loss: 0.9571 - accuracy: 0.59 - ETA: 0s - loss: 0.9645 - accuracy: 0.58 - ETA: 0s - loss: 0.9540 - accuracy: 0.59 - ETA: 0s - loss: 0.9392 - accuracy: 0.60 - ETA: 0s - loss: 0.9191 - accuracy: 0.62 - ETA: 0s - loss: 0.9322 - accuracy: 0.61 - ETA: 0s - loss: 0.9527 - accuracy: 0.59 - ETA: 0s - loss: 0.9547 - accuracy: 0.59 - ETA: 0s - loss: 0.9604 - accuracy: 0.59 - ETA: 0s - loss: 0.9604 - accuracy: 0.59 - ETA: 0s - loss: 0.9617 - accuracy: 0.5898\n",
      "Epoch 00058: val_loss did not improve from 1.01564\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9617 - accuracy: 0.5898 - val_loss: 1.0389 - val_accuracy: 0.4971 - lr: 0.0576\n",
      "Epoch 59/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0165 - accuracy: 0.52 - ETA: 0s - loss: 1.0250 - accuracy: 0.51 - ETA: 0s - loss: 1.0126 - accuracy: 0.52 - ETA: 0s - loss: 0.9852 - accuracy: 0.55 - ETA: 0s - loss: 0.9774 - accuracy: 0.56 - ETA: 0s - loss: 0.9639 - accuracy: 0.58 - ETA: 0s - loss: 0.9590 - accuracy: 0.59 - ETA: 0s - loss: 0.9566 - accuracy: 0.59 - ETA: 0s - loss: 0.9557 - accuracy: 0.59 - ETA: 0s - loss: 0.9626 - accuracy: 0.58 - ETA: 0s - loss: 0.9527 - accuracy: 0.59 - ETA: 0s - loss: 0.9390 - accuracy: 0.60 - ETA: 0s - loss: 0.9198 - accuracy: 0.62 - ETA: 0s - loss: 0.9330 - accuracy: 0.61 - ETA: 0s - loss: 0.9536 - accuracy: 0.59 - ETA: 0s - loss: 0.9554 - accuracy: 0.59 - ETA: 0s - loss: 0.9608 - accuracy: 0.59 - ETA: 0s - loss: 0.9608 - accuracy: 0.59 - ETA: 0s - loss: 0.9620 - accuracy: 0.5895\n",
      "Epoch 00059: val_loss did not improve from 1.01564\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9620 - accuracy: 0.5895 - val_loss: 1.0248 - val_accuracy: 0.4971 - lr: 0.0576\n",
      "Epoch 60/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0084 - accuracy: 0.52 - ETA: 0s - loss: 1.0155 - accuracy: 0.51 - ETA: 0s - loss: 1.0064 - accuracy: 0.52 - ETA: 0s - loss: 0.9839 - accuracy: 0.55 - ETA: 0s - loss: 0.9780 - accuracy: 0.56 - ETA: 0s - loss: 0.9648 - accuracy: 0.58 - ETA: 0s - loss: 0.9594 - accuracy: 0.59 - ETA: 0s - loss: 0.9561 - accuracy: 0.59 - ETA: 0s - loss: 0.9542 - accuracy: 0.59 - ETA: 0s - loss: 0.9619 - accuracy: 0.58 - ETA: 0s - loss: 0.9510 - accuracy: 0.59 - ETA: 0s - loss: 0.9357 - accuracy: 0.60 - ETA: 0s - loss: 0.9149 - accuracy: 0.62 - ETA: 0s - loss: 0.9301 - accuracy: 0.61 - ETA: 0s - loss: 0.9528 - accuracy: 0.59 - ETA: 0s - loss: 0.9550 - accuracy: 0.59 - ETA: 0s - loss: 0.9607 - accuracy: 0.59 - ETA: 0s - loss: 0.9606 - accuracy: 0.59 - ETA: 0s - loss: 0.9617 - accuracy: 0.5893\n",
      "Epoch 00060: val_loss did not improve from 1.01564\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9617 - accuracy: 0.5893 - val_loss: 1.0312 - val_accuracy: 0.4971 - lr: 0.0576\n",
      "Epoch 61/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0094 - accuracy: 0.52 - ETA: 0s - loss: 1.0176 - accuracy: 0.51 - ETA: 0s - loss: 1.0077 - accuracy: 0.52 - ETA: 0s - loss: 0.9847 - accuracy: 0.55 - ETA: 0s - loss: 0.9782 - accuracy: 0.56 - ETA: 0s - loss: 0.9653 - accuracy: 0.58 - ETA: 0s - loss: 0.9602 - accuracy: 0.59 - ETA: 0s - loss: 0.9572 - accuracy: 0.59 - ETA: 0s - loss: 0.9559 - accuracy: 0.59 - ETA: 0s - loss: 0.9640 - accuracy: 0.58 - ETA: 0s - loss: 0.9535 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.60 - ETA: 0s - loss: 0.9173 - accuracy: 0.62 - ETA: 0s - loss: 0.9330 - accuracy: 0.61 - ETA: 0s - loss: 0.9560 - accuracy: 0.59 - ETA: 0s - loss: 0.9580 - accuracy: 0.59 - ETA: 0s - loss: 0.9635 - accuracy: 0.59 - ETA: 0s - loss: 0.9633 - accuracy: 0.59 - ETA: 0s - loss: 0.9641 - accuracy: 0.5895\n",
      "Epoch 00061: val_loss did not improve from 1.01564\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9641 - accuracy: 0.5895 - val_loss: 1.0202 - val_accuracy: 0.4971 - lr: 0.0576\n",
      "Epoch 62/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0092 - accuracy: 0.52 - ETA: 0s - loss: 1.0149 - accuracy: 0.51 - ETA: 0s - loss: 1.0067 - accuracy: 0.52 - ETA: 0s - loss: 0.9841 - accuracy: 0.55 - ETA: 0s - loss: 0.9774 - accuracy: 0.57 - ETA: 0s - loss: 0.9633 - accuracy: 0.58 - ETA: 0s - loss: 0.9577 - accuracy: 0.59 - ETA: 0s - loss: 0.9545 - accuracy: 0.59 - ETA: 0s - loss: 0.9532 - accuracy: 0.59 - ETA: 0s - loss: 0.9627 - accuracy: 0.58 - ETA: 0s - loss: 0.9508 - accuracy: 0.59 - ETA: 0s - loss: 0.9353 - accuracy: 0.60 - ETA: 0s - loss: 0.9136 - accuracy: 0.62 - ETA: 0s - loss: 0.9323 - accuracy: 0.61 - ETA: 0s - loss: 0.9563 - accuracy: 0.59 - ETA: 0s - loss: 0.9584 - accuracy: 0.59 - ETA: 0s - loss: 0.9629 - accuracy: 0.59 - ETA: 0s - loss: 0.9628 - accuracy: 0.59 - ETA: 0s - loss: 0.9636 - accuracy: 0.5896\n",
      "Epoch 00062: val_loss improved from 1.01564 to 1.01430, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 2s 87ms/step - loss: 0.9636 - accuracy: 0.5896 - val_loss: 1.0143 - val_accuracy: 0.4972 - lr: 0.0576\n",
      "Epoch 63/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0109 - accuracy: 0.52 - ETA: 0s - loss: 1.0143 - accuracy: 0.51 - ETA: 0s - loss: 1.0108 - accuracy: 0.52 - ETA: 0s - loss: 0.9883 - accuracy: 0.55 - ETA: 0s - loss: 0.9818 - accuracy: 0.56 - ETA: 0s - loss: 0.9658 - accuracy: 0.58 - ETA: 0s - loss: 0.9591 - accuracy: 0.59 - ETA: 0s - loss: 0.9565 - accuracy: 0.59 - ETA: 0s - loss: 0.9577 - accuracy: 0.59 - ETA: 0s - loss: 0.9697 - accuracy: 0.58 - ETA: 0s - loss: 0.9589 - accuracy: 0.59 - ETA: 0s - loss: 0.9429 - accuracy: 0.60 - ETA: 0s - loss: 0.9221 - accuracy: 0.62 - ETA: 0s - loss: 0.9379 - accuracy: 0.61 - ETA: 0s - loss: 0.9582 - accuracy: 0.59 - ETA: 0s - loss: 0.9597 - accuracy: 0.59 - ETA: 0s - loss: 0.9638 - accuracy: 0.59 - ETA: 0s - loss: 0.9642 - accuracy: 0.59 - ETA: 0s - loss: 0.9653 - accuracy: 0.5893\n",
      "Epoch 00063: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9653 - accuracy: 0.5893 - val_loss: 1.0177 - val_accuracy: 0.4993 - lr: 0.0576\n",
      "Epoch 64/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0064 - accuracy: 0.52 - ETA: 0s - loss: 1.0129 - accuracy: 0.51 - ETA: 0s - loss: 1.0052 - accuracy: 0.52 - ETA: 0s - loss: 0.9863 - accuracy: 0.55 - ETA: 0s - loss: 0.9795 - accuracy: 0.56 - ETA: 0s - loss: 0.9640 - accuracy: 0.58 - ETA: 0s - loss: 0.9566 - accuracy: 0.59 - ETA: 0s - loss: 0.9535 - accuracy: 0.59 - ETA: 0s - loss: 0.9533 - accuracy: 0.59 - ETA: 0s - loss: 0.9655 - accuracy: 0.58 - ETA: 0s - loss: 0.9539 - accuracy: 0.59 - ETA: 0s - loss: 0.9371 - accuracy: 0.60 - ETA: 0s - loss: 0.9148 - accuracy: 0.62 - ETA: 0s - loss: 0.9310 - accuracy: 0.61 - ETA: 0s - loss: 0.9532 - accuracy: 0.59 - ETA: 0s - loss: 0.9550 - accuracy: 0.59 - ETA: 0s - loss: 0.9594 - accuracy: 0.59 - ETA: 0s - loss: 0.9595 - accuracy: 0.59 - ETA: 0s - loss: 0.9604 - accuracy: 0.5892\n",
      "Epoch 00064: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9604 - accuracy: 0.5892 - val_loss: 1.0155 - val_accuracy: 0.4979 - lr: 0.0576\n",
      "Epoch 65/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0063 - accuracy: 0.52 - ETA: 0s - loss: 1.0125 - accuracy: 0.51 - ETA: 0s - loss: 1.0059 - accuracy: 0.52 - ETA: 0s - loss: 0.9869 - accuracy: 0.55 - ETA: 0s - loss: 0.9808 - accuracy: 0.56 - ETA: 0s - loss: 0.9678 - accuracy: 0.58 - ETA: 0s - loss: 0.9618 - accuracy: 0.59 - ETA: 0s - loss: 0.9577 - accuracy: 0.59 - ETA: 0s - loss: 0.9560 - accuracy: 0.59 - ETA: 0s - loss: 0.9651 - accuracy: 0.58 - ETA: 0s - loss: 0.9545 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.60 - ETA: 0s - loss: 0.9175 - accuracy: 0.62 - ETA: 0s - loss: 0.9345 - accuracy: 0.61 - ETA: 0s - loss: 0.9582 - accuracy: 0.59 - ETA: 0s - loss: 0.9602 - accuracy: 0.59 - ETA: 0s - loss: 0.9650 - accuracy: 0.59 - ETA: 0s - loss: 0.9646 - accuracy: 0.59 - ETA: 0s - loss: 0.9652 - accuracy: 0.5894\n",
      "Epoch 00065: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9652 - accuracy: 0.5894 - val_loss: 1.0163 - val_accuracy: 0.4971 - lr: 0.0576\n",
      "Epoch 66/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0095 - accuracy: 0.52 - ETA: 0s - loss: 1.0140 - accuracy: 0.51 - ETA: 0s - loss: 1.0068 - accuracy: 0.52 - ETA: 0s - loss: 0.9852 - accuracy: 0.55 - ETA: 0s - loss: 0.9791 - accuracy: 0.56 - ETA: 0s - loss: 0.9649 - accuracy: 0.58 - ETA: 0s - loss: 0.9589 - accuracy: 0.59 - ETA: 0s - loss: 0.9552 - accuracy: 0.59 - ETA: 0s - loss: 0.9535 - accuracy: 0.59 - ETA: 0s - loss: 0.9629 - accuracy: 0.58 - ETA: 0s - loss: 0.9513 - accuracy: 0.59 - ETA: 0s - loss: 0.9355 - accuracy: 0.60 - ETA: 0s - loss: 0.9136 - accuracy: 0.62 - ETA: 0s - loss: 0.9322 - accuracy: 0.61 - ETA: 0s - loss: 0.9571 - accuracy: 0.59 - ETA: 0s - loss: 0.9591 - accuracy: 0.59 - ETA: 0s - loss: 0.9635 - accuracy: 0.59 - ETA: 0s - loss: 0.9634 - accuracy: 0.59 - ETA: 0s - loss: 0.9641 - accuracy: 0.5894\n",
      "Epoch 00066: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9641 - accuracy: 0.5894 - val_loss: 1.0170 - val_accuracy: 0.4969 - lr: 0.0576\n",
      "Epoch 67/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0078 - accuracy: 0.52 - ETA: 0s - loss: 1.0126 - accuracy: 0.51 - ETA: 0s - loss: 1.0077 - accuracy: 0.52 - ETA: 0s - loss: 0.9882 - accuracy: 0.55 - ETA: 0s - loss: 0.9832 - accuracy: 0.56 - ETA: 0s - loss: 0.9698 - accuracy: 0.58 - ETA: 0s - loss: 0.9637 - accuracy: 0.59 - ETA: 0s - loss: 0.9600 - accuracy: 0.59 - ETA: 0s - loss: 0.9585 - accuracy: 0.59 - ETA: 0s - loss: 0.9684 - accuracy: 0.58 - ETA: 0s - loss: 0.9572 - accuracy: 0.59 - ETA: 0s - loss: 0.9412 - accuracy: 0.60 - ETA: 0s - loss: 0.9192 - accuracy: 0.62 - ETA: 0s - loss: 0.9360 - accuracy: 0.61 - ETA: 0s - loss: 0.9602 - accuracy: 0.59 - ETA: 0s - loss: 0.9623 - accuracy: 0.59 - ETA: 0s - loss: 0.9675 - accuracy: 0.59 - ETA: 0s - loss: 0.9670 - accuracy: 0.59 - ETA: 0s - loss: 0.9677 - accuracy: 0.5895\n",
      "Epoch 00067: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9677 - accuracy: 0.5895 - val_loss: 1.0197 - val_accuracy: 0.4971 - lr: 0.0576\n",
      "Epoch 68/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0068 - accuracy: 0.52 - ETA: 0s - loss: 1.0133 - accuracy: 0.51 - ETA: 0s - loss: 1.0055 - accuracy: 0.52 - ETA: 0s - loss: 0.9842 - accuracy: 0.55 - ETA: 0s - loss: 0.9774 - accuracy: 0.56 - ETA: 0s - loss: 0.9633 - accuracy: 0.58 - ETA: 0s - loss: 0.9569 - accuracy: 0.59 - ETA: 0s - loss: 0.9535 - accuracy: 0.59 - ETA: 0s - loss: 0.9522 - accuracy: 0.59 - ETA: 0s - loss: 0.9619 - accuracy: 0.58 - ETA: 0s - loss: 0.9505 - accuracy: 0.59 - ETA: 0s - loss: 0.9344 - accuracy: 0.60 - ETA: 0s - loss: 0.9120 - accuracy: 0.62 - ETA: 0s - loss: 0.9313 - accuracy: 0.61 - ETA: 0s - loss: 0.9560 - accuracy: 0.59 - ETA: 0s - loss: 0.9580 - accuracy: 0.59 - ETA: 0s - loss: 0.9621 - accuracy: 0.59 - ETA: 0s - loss: 0.9621 - accuracy: 0.59 - ETA: 0s - loss: 0.9632 - accuracy: 0.5894\n",
      "Epoch 00068: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9632 - accuracy: 0.5894 - val_loss: 1.0153 - val_accuracy: 0.5021 - lr: 0.0576\n",
      "Epoch 69/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0126 - accuracy: 0.53 - ETA: 0s - loss: 1.0160 - accuracy: 0.52 - ETA: 0s - loss: 1.0129 - accuracy: 0.53 - ETA: 0s - loss: 0.9969 - accuracy: 0.56 - ETA: 0s - loss: 0.9921 - accuracy: 0.57 - ETA: 0s - loss: 0.9795 - accuracy: 0.58 - ETA: 0s - loss: 0.9738 - accuracy: 0.59 - ETA: 0s - loss: 0.9687 - accuracy: 0.59 - ETA: 0s - loss: 0.9664 - accuracy: 0.59 - ETA: 0s - loss: 0.9738 - accuracy: 0.58 - ETA: 0s - loss: 0.9610 - accuracy: 0.59 - ETA: 0s - loss: 0.9451 - accuracy: 0.60 - ETA: 0s - loss: 0.9233 - accuracy: 0.62 - ETA: 0s - loss: 0.9413 - accuracy: 0.61 - ETA: 0s - loss: 0.9679 - accuracy: 0.59 - ETA: 0s - loss: 0.9700 - accuracy: 0.59 - ETA: 0s - loss: 0.9753 - accuracy: 0.59 - ETA: 0s - loss: 0.9746 - accuracy: 0.59 - ETA: 0s - loss: 0.9750 - accuracy: 0.5903\n",
      "Epoch 00069: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9750 - accuracy: 0.5903 - val_loss: 1.0264 - val_accuracy: 0.4971 - lr: 0.0576\n",
      "Epoch 70/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0085 - accuracy: 0.52 - ETA: 0s - loss: 1.0179 - accuracy: 0.51 - ETA: 0s - loss: 1.0077 - accuracy: 0.52 - ETA: 0s - loss: 0.9846 - accuracy: 0.55 - ETA: 0s - loss: 0.9777 - accuracy: 0.56 - ETA: 0s - loss: 0.9620 - accuracy: 0.58 - ETA: 0s - loss: 0.9561 - accuracy: 0.59 - ETA: 0s - loss: 0.9530 - accuracy: 0.59 - ETA: 0s - loss: 0.9523 - accuracy: 0.59 - ETA: 0s - loss: 0.9617 - accuracy: 0.58 - ETA: 0s - loss: 0.9505 - accuracy: 0.59 - ETA: 0s - loss: 0.9341 - accuracy: 0.60 - ETA: 0s - loss: 0.9130 - accuracy: 0.62 - ETA: 0s - loss: 0.9301 - accuracy: 0.61 - ETA: 0s - loss: 0.9540 - accuracy: 0.59 - ETA: 0s - loss: 0.9562 - accuracy: 0.59 - ETA: 0s - loss: 0.9609 - accuracy: 0.59 - ETA: 0s - loss: 0.9614 - accuracy: 0.59 - ETA: 0s - loss: 0.9629 - accuracy: 0.5894\n",
      "Epoch 00070: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9629 - accuracy: 0.5894 - val_loss: 1.0199 - val_accuracy: 0.5042 - lr: 0.0576\n",
      "Epoch 71/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0114 - accuracy: 0.52 - ETA: 0s - loss: 1.0177 - accuracy: 0.51 - ETA: 0s - loss: 1.0149 - accuracy: 0.52 - ETA: 0s - loss: 1.0022 - accuracy: 0.55 - ETA: 0s - loss: 0.9971 - accuracy: 0.56 - ETA: 0s - loss: 0.9827 - accuracy: 0.58 - ETA: 0s - loss: 0.9747 - accuracy: 0.58 - ETA: 0s - loss: 0.9690 - accuracy: 0.59 - ETA: 0s - loss: 0.9658 - accuracy: 0.59 - ETA: 0s - loss: 0.9734 - accuracy: 0.58 - ETA: 0s - loss: 0.9611 - accuracy: 0.59 - ETA: 0s - loss: 0.9436 - accuracy: 0.60 - ETA: 0s - loss: 0.9207 - accuracy: 0.61 - ETA: 0s - loss: 0.9381 - accuracy: 0.61 - ETA: 0s - loss: 0.9628 - accuracy: 0.59 - ETA: 0s - loss: 0.9650 - accuracy: 0.59 - ETA: 0s - loss: 0.9696 - accuracy: 0.58 - ETA: 0s - loss: 0.9692 - accuracy: 0.58 - ETA: 0s - loss: 0.9701 - accuracy: 0.5879\n",
      "Epoch 00071: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9701 - accuracy: 0.5879 - val_loss: 1.0238 - val_accuracy: 0.5052 - lr: 0.0576\n",
      "Epoch 72/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0280 - accuracy: 0.52 - ETA: 0s - loss: 1.0308 - accuracy: 0.51 - ETA: 0s - loss: 1.0299 - accuracy: 0.52 - ETA: 0s - loss: 1.0122 - accuracy: 0.55 - ETA: 0s - loss: 1.0050 - accuracy: 0.56 - ETA: 0s - loss: 0.9862 - accuracy: 0.57 - ETA: 0s - loss: 0.9766 - accuracy: 0.58 - ETA: 0s - loss: 0.9702 - accuracy: 0.59 - ETA: 0s - loss: 0.9671 - accuracy: 0.59 - ETA: 0s - loss: 0.9756 - accuracy: 0.58 - ETA: 0s - loss: 0.9625 - accuracy: 0.59 - ETA: 0s - loss: 0.9452 - accuracy: 0.60 - ETA: 0s - loss: 0.9228 - accuracy: 0.61 - ETA: 0s - loss: 0.9388 - accuracy: 0.61 - ETA: 0s - loss: 0.9602 - accuracy: 0.59 - ETA: 0s - loss: 0.9620 - accuracy: 0.59 - ETA: 0s - loss: 0.9663 - accuracy: 0.58 - ETA: 0s - loss: 0.9667 - accuracy: 0.58 - ETA: 0s - loss: 0.9683 - accuracy: 0.5871\n",
      "Epoch 00072: val_loss did not improve from 1.01430\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 0.04608000218868256.\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9683 - accuracy: 0.5871 - val_loss: 1.0162 - val_accuracy: 0.4993 - lr: 0.0576\n",
      "Epoch 73/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0243 - accuracy: 0.51 - ETA: 0s - loss: 1.0288 - accuracy: 0.51 - ETA: 0s - loss: 1.0222 - accuracy: 0.52 - ETA: 0s - loss: 1.0007 - accuracy: 0.54 - ETA: 0s - loss: 0.9915 - accuracy: 0.56 - ETA: 0s - loss: 0.9726 - accuracy: 0.57 - ETA: 0s - loss: 0.9645 - accuracy: 0.58 - ETA: 0s - loss: 0.9598 - accuracy: 0.58 - ETA: 0s - loss: 0.9578 - accuracy: 0.58 - ETA: 0s - loss: 0.9677 - accuracy: 0.58 - ETA: 0s - loss: 0.9556 - accuracy: 0.59 - ETA: 0s - loss: 0.9397 - accuracy: 0.60 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9339 - accuracy: 0.60 - ETA: 0s - loss: 0.9553 - accuracy: 0.59 - ETA: 0s - loss: 0.9571 - accuracy: 0.59 - ETA: 0s - loss: 0.9619 - accuracy: 0.58 - ETA: 0s - loss: 0.9617 - accuracy: 0.58 - ETA: 0s - loss: 0.9624 - accuracy: 0.5877\n",
      "Epoch 00073: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9624 - accuracy: 0.5877 - val_loss: 1.0172 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 74/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0171 - accuracy: 0.52 - ETA: 0s - loss: 1.0215 - accuracy: 0.51 - ETA: 0s - loss: 1.0110 - accuracy: 0.52 - ETA: 0s - loss: 0.9877 - accuracy: 0.55 - ETA: 0s - loss: 0.9807 - accuracy: 0.56 - ETA: 0s - loss: 0.9672 - accuracy: 0.58 - ETA: 0s - loss: 0.9621 - accuracy: 0.59 - ETA: 0s - loss: 0.9588 - accuracy: 0.59 - ETA: 0s - loss: 0.9568 - accuracy: 0.59 - ETA: 0s - loss: 0.9640 - accuracy: 0.58 - ETA: 0s - loss: 0.9532 - accuracy: 0.59 - ETA: 0s - loss: 0.9386 - accuracy: 0.60 - ETA: 0s - loss: 0.9182 - accuracy: 0.62 - ETA: 0s - loss: 0.9322 - accuracy: 0.61 - ETA: 0s - loss: 0.9537 - accuracy: 0.59 - ETA: 0s - loss: 0.9559 - accuracy: 0.59 - ETA: 0s - loss: 0.9618 - accuracy: 0.59 - ETA: 0s - loss: 0.9619 - accuracy: 0.59 - ETA: 0s - loss: 0.9634 - accuracy: 0.5891\n",
      "Epoch 00074: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9634 - accuracy: 0.5891 - val_loss: 1.0347 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 75/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0160 - accuracy: 0.52 - ETA: 0s - loss: 1.0239 - accuracy: 0.51 - ETA: 0s - loss: 1.0113 - accuracy: 0.52 - ETA: 0s - loss: 0.9836 - accuracy: 0.55 - ETA: 0s - loss: 0.9751 - accuracy: 0.56 - ETA: 0s - loss: 0.9612 - accuracy: 0.58 - ETA: 0s - loss: 0.9562 - accuracy: 0.59 - ETA: 0s - loss: 0.9538 - accuracy: 0.59 - ETA: 0s - loss: 0.9529 - accuracy: 0.59 - ETA: 0s - loss: 0.9599 - accuracy: 0.58 - ETA: 0s - loss: 0.9513 - accuracy: 0.59 - ETA: 0s - loss: 0.9390 - accuracy: 0.60 - ETA: 0s - loss: 0.9211 - accuracy: 0.62 - ETA: 0s - loss: 0.9323 - accuracy: 0.61 - ETA: 0s - loss: 0.9499 - accuracy: 0.59 - ETA: 0s - loss: 0.9515 - accuracy: 0.59 - ETA: 0s - loss: 0.9565 - accuracy: 0.59 - ETA: 0s - loss: 0.9567 - accuracy: 0.59 - ETA: 0s - loss: 0.9581 - accuracy: 0.5895\n",
      "Epoch 00075: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9581 - accuracy: 0.5895 - val_loss: 1.0387 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 76/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0198 - accuracy: 0.52 - ETA: 0s - loss: 1.0295 - accuracy: 0.51 - ETA: 0s - loss: 1.0170 - accuracy: 0.52 - ETA: 0s - loss: 0.9852 - accuracy: 0.55 - ETA: 0s - loss: 0.9749 - accuracy: 0.56 - ETA: 0s - loss: 0.9585 - accuracy: 0.58 - ETA: 0s - loss: 0.9522 - accuracy: 0.59 - ETA: 0s - loss: 0.9491 - accuracy: 0.59 - ETA: 0s - loss: 0.9484 - accuracy: 0.59 - ETA: 0s - loss: 0.9561 - accuracy: 0.58 - ETA: 0s - loss: 0.9469 - accuracy: 0.59 - ETA: 0s - loss: 0.9344 - accuracy: 0.60 - ETA: 0s - loss: 0.9168 - accuracy: 0.62 - ETA: 0s - loss: 0.9285 - accuracy: 0.61 - ETA: 0s - loss: 0.9463 - accuracy: 0.59 - ETA: 0s - loss: 0.9479 - accuracy: 0.59 - ETA: 0s - loss: 0.9526 - accuracy: 0.59 - ETA: 0s - loss: 0.9528 - accuracy: 0.59 - ETA: 0s - loss: 0.9542 - accuracy: 0.5895\n",
      "Epoch 00076: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9542 - accuracy: 0.5895 - val_loss: 1.0284 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 77/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0124 - accuracy: 0.52 - ETA: 0s - loss: 1.0198 - accuracy: 0.51 - ETA: 0s - loss: 1.0088 - accuracy: 0.52 - ETA: 0s - loss: 0.9798 - accuracy: 0.55 - ETA: 0s - loss: 0.9711 - accuracy: 0.56 - ETA: 0s - loss: 0.9558 - accuracy: 0.58 - ETA: 0s - loss: 0.9504 - accuracy: 0.59 - ETA: 0s - loss: 0.9480 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.59 - ETA: 0s - loss: 0.9549 - accuracy: 0.58 - ETA: 0s - loss: 0.9455 - accuracy: 0.59 - ETA: 0s - loss: 0.9324 - accuracy: 0.60 - ETA: 0s - loss: 0.9135 - accuracy: 0.62 - ETA: 0s - loss: 0.9264 - accuracy: 0.61 - ETA: 0s - loss: 0.9455 - accuracy: 0.59 - ETA: 0s - loss: 0.9475 - accuracy: 0.59 - ETA: 0s - loss: 0.9527 - accuracy: 0.59 - ETA: 0s - loss: 0.9531 - accuracy: 0.59 - ETA: 0s - loss: 0.9546 - accuracy: 0.5891\n",
      "Epoch 00077: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9546 - accuracy: 0.5891 - val_loss: 1.0301 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 78/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0123 - accuracy: 0.52 - ETA: 0s - loss: 1.0198 - accuracy: 0.51 - ETA: 0s - loss: 1.0085 - accuracy: 0.52 - ETA: 0s - loss: 0.9803 - accuracy: 0.55 - ETA: 0s - loss: 0.9718 - accuracy: 0.56 - ETA: 0s - loss: 0.9572 - accuracy: 0.58 - ETA: 0s - loss: 0.9521 - accuracy: 0.59 - ETA: 0s - loss: 0.9498 - accuracy: 0.59 - ETA: 0s - loss: 0.9489 - accuracy: 0.59 - ETA: 0s - loss: 0.9564 - accuracy: 0.58 - ETA: 0s - loss: 0.9475 - accuracy: 0.59 - ETA: 0s - loss: 0.9350 - accuracy: 0.60 - ETA: 0s - loss: 0.9168 - accuracy: 0.62 - ETA: 0s - loss: 0.9288 - accuracy: 0.61 - ETA: 0s - loss: 0.9470 - accuracy: 0.59 - ETA: 0s - loss: 0.9487 - accuracy: 0.59 - ETA: 0s - loss: 0.9538 - accuracy: 0.59 - ETA: 0s - loss: 0.9540 - accuracy: 0.59 - ETA: 0s - loss: 0.9554 - accuracy: 0.5895\n",
      "Epoch 00078: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9554 - accuracy: 0.5895 - val_loss: 1.0344 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 79/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0146 - accuracy: 0.52 - ETA: 0s - loss: 1.0233 - accuracy: 0.51 - ETA: 0s - loss: 1.0115 - accuracy: 0.52 - ETA: 0s - loss: 0.9815 - accuracy: 0.55 - ETA: 0s - loss: 0.9721 - accuracy: 0.56 - ETA: 0s - loss: 0.9566 - accuracy: 0.58 - ETA: 0s - loss: 0.9509 - accuracy: 0.59 - ETA: 0s - loss: 0.9483 - accuracy: 0.59 - ETA: 0s - loss: 0.9475 - accuracy: 0.59 - ETA: 0s - loss: 0.9553 - accuracy: 0.58 - ETA: 0s - loss: 0.9463 - accuracy: 0.59 - ETA: 0s - loss: 0.9336 - accuracy: 0.60 - ETA: 0s - loss: 0.9155 - accuracy: 0.62 - ETA: 0s - loss: 0.9275 - accuracy: 0.61 - ETA: 0s - loss: 0.9456 - accuracy: 0.59 - ETA: 0s - loss: 0.9474 - accuracy: 0.59 - ETA: 0s - loss: 0.9523 - accuracy: 0.59 - ETA: 0s - loss: 0.9526 - accuracy: 0.59 - ETA: 0s - loss: 0.9540 - accuracy: 0.5895\n",
      "Epoch 00079: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9540 - accuracy: 0.5895 - val_loss: 1.0300 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 80/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0126 - accuracy: 0.52 - ETA: 0s - loss: 1.0206 - accuracy: 0.51 - ETA: 0s - loss: 1.0093 - accuracy: 0.52 - ETA: 0s - loss: 0.9802 - accuracy: 0.55 - ETA: 0s - loss: 0.9712 - accuracy: 0.56 - ETA: 0s - loss: 0.9561 - accuracy: 0.58 - ETA: 0s - loss: 0.9506 - accuracy: 0.59 - ETA: 0s - loss: 0.9481 - accuracy: 0.59 - ETA: 0s - loss: 0.9472 - accuracy: 0.59 - ETA: 0s - loss: 0.9550 - accuracy: 0.58 - ETA: 0s - loss: 0.9459 - accuracy: 0.59 - ETA: 0s - loss: 0.9331 - accuracy: 0.60 - ETA: 0s - loss: 0.9146 - accuracy: 0.62 - ETA: 0s - loss: 0.9270 - accuracy: 0.61 - ETA: 0s - loss: 0.9457 - accuracy: 0.59 - ETA: 0s - loss: 0.9475 - accuracy: 0.59 - ETA: 0s - loss: 0.9526 - accuracy: 0.59 - ETA: 0s - loss: 0.9529 - accuracy: 0.59 - ETA: 0s - loss: 0.9544 - accuracy: 0.5894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00080: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9544 - accuracy: 0.5894 - val_loss: 1.0307 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 81/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0128 - accuracy: 0.52 - ETA: 0s - loss: 1.0207 - accuracy: 0.51 - ETA: 0s - loss: 1.0093 - accuracy: 0.52 - ETA: 0s - loss: 0.9804 - accuracy: 0.55 - ETA: 0s - loss: 0.9716 - accuracy: 0.56 - ETA: 0s - loss: 0.9566 - accuracy: 0.58 - ETA: 0s - loss: 0.9512 - accuracy: 0.59 - ETA: 0s - loss: 0.9488 - accuracy: 0.59 - ETA: 0s - loss: 0.9479 - accuracy: 0.59 - ETA: 0s - loss: 0.9556 - accuracy: 0.58 - ETA: 0s - loss: 0.9466 - accuracy: 0.59 - ETA: 0s - loss: 0.9340 - accuracy: 0.60 - ETA: 0s - loss: 0.9157 - accuracy: 0.62 - ETA: 0s - loss: 0.9279 - accuracy: 0.61 - ETA: 0s - loss: 0.9462 - accuracy: 0.59 - ETA: 0s - loss: 0.9479 - accuracy: 0.59 - ETA: 0s - loss: 0.9529 - accuracy: 0.59 - ETA: 0s - loss: 0.9532 - accuracy: 0.59 - ETA: 0s - loss: 0.9546 - accuracy: 0.5895\n",
      "Epoch 00081: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9546 - accuracy: 0.5895 - val_loss: 1.0317 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 82/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0133 - accuracy: 0.52 - ETA: 0s - loss: 1.0215 - accuracy: 0.51 - ETA: 0s - loss: 1.0100 - accuracy: 0.52 - ETA: 0s - loss: 0.9805 - accuracy: 0.55 - ETA: 0s - loss: 0.9714 - accuracy: 0.56 - ETA: 0s - loss: 0.9562 - accuracy: 0.58 - ETA: 0s - loss: 0.9508 - accuracy: 0.59 - ETA: 0s - loss: 0.9483 - accuracy: 0.59 - ETA: 0s - loss: 0.9475 - accuracy: 0.59 - ETA: 0s - loss: 0.9552 - accuracy: 0.58 - ETA: 0s - loss: 0.9462 - accuracy: 0.59 - ETA: 0s - loss: 0.9335 - accuracy: 0.60 - ETA: 0s - loss: 0.9152 - accuracy: 0.62 - ETA: 0s - loss: 0.9274 - accuracy: 0.61 - ETA: 0s - loss: 0.9458 - accuracy: 0.59 - ETA: 0s - loss: 0.9475 - accuracy: 0.59 - ETA: 0s - loss: 0.9525 - accuracy: 0.59 - ETA: 0s - loss: 0.9528 - accuracy: 0.59 - ETA: 0s - loss: 0.9543 - accuracy: 0.5894\n",
      "Epoch 00082: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9543 - accuracy: 0.5894 - val_loss: 1.0305 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 83/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0127 - accuracy: 0.52 - ETA: 0s - loss: 1.0206 - accuracy: 0.51 - ETA: 0s - loss: 1.0092 - accuracy: 0.52 - ETA: 0s - loss: 0.9802 - accuracy: 0.55 - ETA: 0s - loss: 0.9712 - accuracy: 0.56 - ETA: 0s - loss: 0.9561 - accuracy: 0.58 - ETA: 0s - loss: 0.9507 - accuracy: 0.59 - ETA: 0s - loss: 0.9482 - accuracy: 0.59 - ETA: 0s - loss: 0.9474 - accuracy: 0.59 - ETA: 0s - loss: 0.9551 - accuracy: 0.58 - ETA: 0s - loss: 0.9460 - accuracy: 0.59 - ETA: 0s - loss: 0.9333 - accuracy: 0.60 - ETA: 0s - loss: 0.9150 - accuracy: 0.62 - ETA: 0s - loss: 0.9272 - accuracy: 0.61 - ETA: 0s - loss: 0.9457 - accuracy: 0.59 - ETA: 0s - loss: 0.9475 - accuracy: 0.59 - ETA: 0s - loss: 0.9525 - accuracy: 0.59 - ETA: 0s - loss: 0.9528 - accuracy: 0.59 - ETA: 0s - loss: 0.9544 - accuracy: 0.5892\n",
      "Epoch 00083: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9544 - accuracy: 0.5892 - val_loss: 1.0311 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 84/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0138 - accuracy: 0.52 - ETA: 0s - loss: 1.0216 - accuracy: 0.51 - ETA: 0s - loss: 1.0096 - accuracy: 0.52 - ETA: 0s - loss: 0.9805 - accuracy: 0.55 - ETA: 0s - loss: 0.9715 - accuracy: 0.56 - ETA: 0s - loss: 0.9563 - accuracy: 0.58 - ETA: 0s - loss: 0.9509 - accuracy: 0.59 - ETA: 0s - loss: 0.9485 - accuracy: 0.59 - ETA: 0s - loss: 0.9477 - accuracy: 0.59 - ETA: 0s - loss: 0.9554 - accuracy: 0.58 - ETA: 0s - loss: 0.9464 - accuracy: 0.59 - ETA: 0s - loss: 0.9337 - accuracy: 0.60 - ETA: 0s - loss: 0.9154 - accuracy: 0.62 - ETA: 0s - loss: 0.9276 - accuracy: 0.61 - ETA: 0s - loss: 0.9460 - accuracy: 0.59 - ETA: 0s - loss: 0.9477 - accuracy: 0.59 - ETA: 0s - loss: 0.9527 - accuracy: 0.59 - ETA: 0s - loss: 0.9530 - accuracy: 0.59 - ETA: 0s - loss: 0.9545 - accuracy: 0.5894\n",
      "Epoch 00084: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9545 - accuracy: 0.5894 - val_loss: 1.0309 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 85/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0129 - accuracy: 0.52 - ETA: 0s - loss: 1.0209 - accuracy: 0.51 - ETA: 0s - loss: 1.0095 - accuracy: 0.52 - ETA: 0s - loss: 0.9804 - accuracy: 0.55 - ETA: 0s - loss: 0.9714 - accuracy: 0.56 - ETA: 0s - loss: 0.9562 - accuracy: 0.58 - ETA: 0s - loss: 0.9508 - accuracy: 0.59 - ETA: 0s - loss: 0.9483 - accuracy: 0.59 - ETA: 0s - loss: 0.9474 - accuracy: 0.59 - ETA: 0s - loss: 0.9552 - accuracy: 0.58 - ETA: 0s - loss: 0.9461 - accuracy: 0.59 - ETA: 0s - loss: 0.9334 - accuracy: 0.60 - ETA: 0s - loss: 0.9151 - accuracy: 0.62 - ETA: 0s - loss: 0.9274 - accuracy: 0.61 - ETA: 0s - loss: 0.9458 - accuracy: 0.59 - ETA: 0s - loss: 0.9476 - accuracy: 0.59 - ETA: 0s - loss: 0.9526 - accuracy: 0.59 - ETA: 0s - loss: 0.9529 - accuracy: 0.59 - ETA: 0s - loss: 0.9543 - accuracy: 0.5894\n",
      "Epoch 00085: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9543 - accuracy: 0.5894 - val_loss: 1.0307 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 86/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0126 - accuracy: 0.52 - ETA: 0s - loss: 1.0207 - accuracy: 0.51 - ETA: 0s - loss: 1.0093 - accuracy: 0.52 - ETA: 0s - loss: 0.9802 - accuracy: 0.55 - ETA: 0s - loss: 0.9713 - accuracy: 0.56 - ETA: 0s - loss: 0.9562 - accuracy: 0.58 - ETA: 0s - loss: 0.9508 - accuracy: 0.59 - ETA: 0s - loss: 0.9483 - accuracy: 0.59 - ETA: 0s - loss: 0.9475 - accuracy: 0.59 - ETA: 0s - loss: 0.9552 - accuracy: 0.58 - ETA: 0s - loss: 0.9462 - accuracy: 0.59 - ETA: 0s - loss: 0.9335 - accuracy: 0.60 - ETA: 0s - loss: 0.9152 - accuracy: 0.62 - ETA: 0s - loss: 0.9274 - accuracy: 0.61 - ETA: 0s - loss: 0.9458 - accuracy: 0.59 - ETA: 0s - loss: 0.9476 - accuracy: 0.59 - ETA: 0s - loss: 0.9526 - accuracy: 0.59 - ETA: 0s - loss: 0.9529 - accuracy: 0.59 - ETA: 0s - loss: 0.9544 - accuracy: 0.5894\n",
      "Epoch 00086: val_loss did not improve from 1.01430\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 0.03686400055885315.\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9544 - accuracy: 0.5894 - val_loss: 1.0309 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 87/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0126 - accuracy: 0.52 - ETA: 0s - loss: 1.0210 - accuracy: 0.51 - ETA: 0s - loss: 1.0097 - accuracy: 0.52 - ETA: 0s - loss: 0.9800 - accuracy: 0.55 - ETA: 0s - loss: 0.9707 - accuracy: 0.56 - ETA: 0s - loss: 0.9551 - accuracy: 0.58 - ETA: 0s - loss: 0.9495 - accuracy: 0.59 - ETA: 0s - loss: 0.9471 - accuracy: 0.59 - ETA: 0s - loss: 0.9462 - accuracy: 0.59 - ETA: 0s - loss: 0.9542 - accuracy: 0.58 - ETA: 0s - loss: 0.9452 - accuracy: 0.59 - ETA: 0s - loss: 0.9327 - accuracy: 0.60 - ETA: 0s - loss: 0.9148 - accuracy: 0.62 - ETA: 0s - loss: 0.9266 - accuracy: 0.61 - ETA: 0s - loss: 0.9441 - accuracy: 0.59 - ETA: 0s - loss: 0.9459 - accuracy: 0.59 - ETA: 0s - loss: 0.9507 - accuracy: 0.59 - ETA: 0s - loss: 0.9511 - accuracy: 0.59 - ETA: 0s - loss: 0.9525 - accuracy: 0.5891\n",
      "Epoch 00087: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9525 - accuracy: 0.5891 - val_loss: 1.0293 - val_accuracy: 0.4974 - lr: 0.0369\n",
      "Epoch 88/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0121 - accuracy: 0.52 - ETA: 0s - loss: 1.0201 - accuracy: 0.51 - ETA: 0s - loss: 1.0089 - accuracy: 0.52 - ETA: 0s - loss: 0.9792 - accuracy: 0.55 - ETA: 0s - loss: 0.9699 - accuracy: 0.56 - ETA: 0s - loss: 0.9541 - accuracy: 0.58 - ETA: 0s - loss: 0.9485 - accuracy: 0.59 - ETA: 0s - loss: 0.9462 - accuracy: 0.59 - ETA: 0s - loss: 0.9453 - accuracy: 0.59 - ETA: 0s - loss: 0.9534 - accuracy: 0.58 - ETA: 0s - loss: 0.9442 - accuracy: 0.59 - ETA: 0s - loss: 0.9315 - accuracy: 0.60 - ETA: 0s - loss: 0.9131 - accuracy: 0.62 - ETA: 0s - loss: 0.9254 - accuracy: 0.61 - ETA: 0s - loss: 0.9435 - accuracy: 0.59 - ETA: 0s - loss: 0.9454 - accuracy: 0.59 - ETA: 0s - loss: 0.9503 - accuracy: 0.59 - ETA: 0s - loss: 0.9507 - accuracy: 0.59 - ETA: 0s - loss: 0.9522 - accuracy: 0.5892\n",
      "Epoch 00088: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9522 - accuracy: 0.5892 - val_loss: 1.0284 - val_accuracy: 0.4972 - lr: 0.0369\n",
      "Epoch 89/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0116 - accuracy: 0.52 - ETA: 0s - loss: 1.0190 - accuracy: 0.51 - ETA: 0s - loss: 1.0080 - accuracy: 0.52 - ETA: 0s - loss: 0.9787 - accuracy: 0.55 - ETA: 0s - loss: 0.9697 - accuracy: 0.56 - ETA: 0s - loss: 0.9543 - accuracy: 0.58 - ETA: 0s - loss: 0.9490 - accuracy: 0.59 - ETA: 0s - loss: 0.9467 - accuracy: 0.59 - ETA: 0s - loss: 0.9459 - accuracy: 0.59 - ETA: 0s - loss: 0.9538 - accuracy: 0.58 - ETA: 0s - loss: 0.9448 - accuracy: 0.59 - ETA: 0s - loss: 0.9321 - accuracy: 0.60 - ETA: 0s - loss: 0.9137 - accuracy: 0.62 - ETA: 0s - loss: 0.9260 - accuracy: 0.61 - ETA: 0s - loss: 0.9441 - accuracy: 0.59 - ETA: 0s - loss: 0.9459 - accuracy: 0.59 - ETA: 0s - loss: 0.9509 - accuracy: 0.59 - ETA: 0s - loss: 0.9512 - accuracy: 0.59 - ETA: 0s - loss: 0.9527 - accuracy: 0.5893\n",
      "Epoch 00089: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9527 - accuracy: 0.5893 - val_loss: 1.0297 - val_accuracy: 0.4974 - lr: 0.0369\n",
      "Epoch 90/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0117 - accuracy: 0.52 - ETA: 0s - loss: 1.0196 - accuracy: 0.51 - ETA: 0s - loss: 1.0084 - accuracy: 0.52 - ETA: 0s - loss: 0.9790 - accuracy: 0.55 - ETA: 0s - loss: 0.9699 - accuracy: 0.56 - ETA: 0s - loss: 0.9543 - accuracy: 0.58 - ETA: 0s - loss: 0.9489 - accuracy: 0.59 - ETA: 0s - loss: 0.9467 - accuracy: 0.59 - ETA: 0s - loss: 0.9458 - accuracy: 0.59 - ETA: 0s - loss: 0.9538 - accuracy: 0.58 - ETA: 0s - loss: 0.9447 - accuracy: 0.59 - ETA: 0s - loss: 0.9321 - accuracy: 0.60 - ETA: 0s - loss: 0.9138 - accuracy: 0.62 - ETA: 0s - loss: 0.9260 - accuracy: 0.61 - ETA: 0s - loss: 0.9440 - accuracy: 0.59 - ETA: 0s - loss: 0.9458 - accuracy: 0.59 - ETA: 0s - loss: 0.9508 - accuracy: 0.59 - ETA: 0s - loss: 0.9511 - accuracy: 0.59 - ETA: 0s - loss: 0.9526 - accuracy: 0.5893\n",
      "Epoch 00090: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9526 - accuracy: 0.5893 - val_loss: 1.0292 - val_accuracy: 0.4972 - lr: 0.0369\n",
      "Epoch 91/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0114 - accuracy: 0.52 - ETA: 0s - loss: 1.0192 - accuracy: 0.51 - ETA: 0s - loss: 1.0080 - accuracy: 0.52 - ETA: 0s - loss: 0.9787 - accuracy: 0.55 - ETA: 0s - loss: 0.9696 - accuracy: 0.56 - ETA: 0s - loss: 0.9542 - accuracy: 0.58 - ETA: 0s - loss: 0.9488 - accuracy: 0.59 - ETA: 0s - loss: 0.9466 - accuracy: 0.59 - ETA: 0s - loss: 0.9457 - accuracy: 0.59 - ETA: 0s - loss: 0.9537 - accuracy: 0.58 - ETA: 0s - loss: 0.9446 - accuracy: 0.59 - ETA: 0s - loss: 0.9319 - accuracy: 0.60 - ETA: 0s - loss: 0.9135 - accuracy: 0.62 - ETA: 0s - loss: 0.9258 - accuracy: 0.61 - ETA: 0s - loss: 0.9439 - accuracy: 0.59 - ETA: 0s - loss: 0.9458 - accuracy: 0.59 - ETA: 0s - loss: 0.9508 - accuracy: 0.59 - ETA: 0s - loss: 0.9512 - accuracy: 0.59 - ETA: 0s - loss: 0.9527 - accuracy: 0.5893\n",
      "Epoch 00091: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9527 - accuracy: 0.5893 - val_loss: 1.0289 - val_accuracy: 0.4974 - lr: 0.0369\n",
      "Epoch 92/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0111 - accuracy: 0.52 - ETA: 0s - loss: 1.0188 - accuracy: 0.51 - ETA: 0s - loss: 1.0076 - accuracy: 0.52 - ETA: 0s - loss: 0.9785 - accuracy: 0.55 - ETA: 0s - loss: 0.9696 - accuracy: 0.56 - ETA: 0s - loss: 0.9542 - accuracy: 0.58 - ETA: 0s - loss: 0.9489 - accuracy: 0.59 - ETA: 0s - loss: 0.9467 - accuracy: 0.59 - ETA: 0s - loss: 0.9458 - accuracy: 0.59 - ETA: 0s - loss: 0.9538 - accuracy: 0.58 - ETA: 0s - loss: 0.9447 - accuracy: 0.59 - ETA: 0s - loss: 0.9321 - accuracy: 0.60 - ETA: 0s - loss: 0.9136 - accuracy: 0.62 - ETA: 0s - loss: 0.9259 - accuracy: 0.61 - ETA: 0s - loss: 0.9441 - accuracy: 0.59 - ETA: 0s - loss: 0.9459 - accuracy: 0.59 - ETA: 0s - loss: 0.9509 - accuracy: 0.59 - ETA: 0s - loss: 0.9513 - accuracy: 0.59 - ETA: 0s - loss: 0.9528 - accuracy: 0.5893\n",
      "Epoch 00092: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9528 - accuracy: 0.5893 - val_loss: 1.0293 - val_accuracy: 0.4976 - lr: 0.0369\n",
      "Epoch 93/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0111 - accuracy: 0.52 - ETA: 0s - loss: 1.0189 - accuracy: 0.51 - ETA: 0s - loss: 1.0077 - accuracy: 0.52 - ETA: 0s - loss: 0.9785 - accuracy: 0.55 - ETA: 0s - loss: 0.9695 - accuracy: 0.56 - ETA: 0s - loss: 0.9541 - accuracy: 0.58 - ETA: 0s - loss: 0.9488 - accuracy: 0.59 - ETA: 0s - loss: 0.9467 - accuracy: 0.59 - ETA: 0s - loss: 0.9458 - accuracy: 0.59 - ETA: 0s - loss: 0.9537 - accuracy: 0.58 - ETA: 0s - loss: 0.9447 - accuracy: 0.59 - ETA: 0s - loss: 0.9320 - accuracy: 0.60 - ETA: 0s - loss: 0.9136 - accuracy: 0.62 - ETA: 0s - loss: 0.9259 - accuracy: 0.61 - ETA: 0s - loss: 0.9440 - accuracy: 0.59 - ETA: 0s - loss: 0.9459 - accuracy: 0.59 - ETA: 0s - loss: 0.9509 - accuracy: 0.59 - ETA: 0s - loss: 0.9513 - accuracy: 0.59 - ETA: 0s - loss: 0.9527 - accuracy: 0.5892\n",
      "Epoch 00093: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9527 - accuracy: 0.5892 - val_loss: 1.0291 - val_accuracy: 0.4979 - lr: 0.0369\n",
      "Epoch 94/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0109 - accuracy: 0.52 - ETA: 0s - loss: 1.0186 - accuracy: 0.51 - ETA: 0s - loss: 1.0075 - accuracy: 0.52 - ETA: 0s - loss: 0.9783 - accuracy: 0.55 - ETA: 0s - loss: 0.9694 - accuracy: 0.56 - ETA: 0s - loss: 0.9540 - accuracy: 0.58 - ETA: 0s - loss: 0.9487 - accuracy: 0.59 - ETA: 0s - loss: 0.9466 - accuracy: 0.59 - ETA: 0s - loss: 0.9457 - accuracy: 0.59 - ETA: 0s - loss: 0.9537 - accuracy: 0.58 - ETA: 0s - loss: 0.9446 - accuracy: 0.59 - ETA: 0s - loss: 0.9320 - accuracy: 0.60 - ETA: 0s - loss: 0.9135 - accuracy: 0.62 - ETA: 0s - loss: 0.9259 - accuracy: 0.61 - ETA: 0s - loss: 0.9440 - accuracy: 0.59 - ETA: 0s - loss: 0.9459 - accuracy: 0.59 - ETA: 0s - loss: 0.9509 - accuracy: 0.59 - ETA: 0s - loss: 0.9513 - accuracy: 0.59 - ETA: 0s - loss: 0.9528 - accuracy: 0.5892\n",
      "Epoch 00094: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9528 - accuracy: 0.5892 - val_loss: 1.0291 - val_accuracy: 0.4979 - lr: 0.0369\n",
      "Epoch 95/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0108 - accuracy: 0.52 - ETA: 0s - loss: 1.0185 - accuracy: 0.51 - ETA: 0s - loss: 1.0073 - accuracy: 0.52 - ETA: 0s - loss: 0.9782 - accuracy: 0.55 - ETA: 0s - loss: 0.9693 - accuracy: 0.56 - ETA: 0s - loss: 0.9540 - accuracy: 0.58 - ETA: 0s - loss: 0.9487 - accuracy: 0.59 - ETA: 0s - loss: 0.9466 - accuracy: 0.59 - ETA: 0s - loss: 0.9458 - accuracy: 0.59 - ETA: 0s - loss: 0.9537 - accuracy: 0.58 - ETA: 0s - loss: 0.9447 - accuracy: 0.59 - ETA: 0s - loss: 0.9320 - accuracy: 0.60 - ETA: 0s - loss: 0.9135 - accuracy: 0.62 - ETA: 0s - loss: 0.9259 - accuracy: 0.61 - ETA: 0s - loss: 0.9440 - accuracy: 0.59 - ETA: 0s - loss: 0.9459 - accuracy: 0.59 - ETA: 0s - loss: 0.9509 - accuracy: 0.59 - ETA: 0s - loss: 0.9513 - accuracy: 0.59 - ETA: 0s - loss: 0.9528 - accuracy: 0.5893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00095: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9528 - accuracy: 0.5893 - val_loss: 1.0291 - val_accuracy: 0.4979 - lr: 0.0369\n",
      "Epoch 96/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0108 - accuracy: 0.52 - ETA: 0s - loss: 1.0184 - accuracy: 0.51 - ETA: 0s - loss: 1.0073 - accuracy: 0.52 - ETA: 0s - loss: 0.9782 - accuracy: 0.55 - ETA: 0s - loss: 0.9693 - accuracy: 0.56 - ETA: 0s - loss: 0.9539 - accuracy: 0.58 - ETA: 0s - loss: 0.9487 - accuracy: 0.59 - ETA: 0s - loss: 0.9466 - accuracy: 0.59 - ETA: 0s - loss: 0.9457 - accuracy: 0.59 - ETA: 0s - loss: 0.9537 - accuracy: 0.58 - ETA: 0s - loss: 0.9446 - accuracy: 0.59 - ETA: 0s - loss: 0.9320 - accuracy: 0.60 - ETA: 0s - loss: 0.9135 - accuracy: 0.62 - ETA: 0s - loss: 0.9259 - accuracy: 0.61 - ETA: 0s - loss: 0.9440 - accuracy: 0.59 - ETA: 0s - loss: 0.9459 - accuracy: 0.59 - ETA: 0s - loss: 0.9509 - accuracy: 0.59 - ETA: 0s - loss: 0.9513 - accuracy: 0.59 - ETA: 0s - loss: 0.9528 - accuracy: 0.5893\n",
      "Epoch 00096: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9528 - accuracy: 0.5893 - val_loss: 1.0290 - val_accuracy: 0.4979 - lr: 0.0369\n",
      "Epoch 97/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0106 - accuracy: 0.52 - ETA: 0s - loss: 1.0183 - accuracy: 0.51 - ETA: 0s - loss: 1.0071 - accuracy: 0.52 - ETA: 0s - loss: 0.9781 - accuracy: 0.55 - ETA: 0s - loss: 0.9692 - accuracy: 0.56 - ETA: 0s - loss: 0.9539 - accuracy: 0.58 - ETA: 0s - loss: 0.9486 - accuracy: 0.59 - ETA: 0s - loss: 0.9466 - accuracy: 0.59 - ETA: 0s - loss: 0.9457 - accuracy: 0.59 - ETA: 0s - loss: 0.9536 - accuracy: 0.58 - ETA: 0s - loss: 0.9446 - accuracy: 0.59 - ETA: 0s - loss: 0.9319 - accuracy: 0.60 - ETA: 0s - loss: 0.9134 - accuracy: 0.62 - ETA: 0s - loss: 0.9258 - accuracy: 0.61 - ETA: 0s - loss: 0.9440 - accuracy: 0.59 - ETA: 0s - loss: 0.9459 - accuracy: 0.59 - ETA: 0s - loss: 0.9509 - accuracy: 0.59 - ETA: 0s - loss: 0.9513 - accuracy: 0.59 - ETA: 0s - loss: 0.9528 - accuracy: 0.5893\n",
      "Epoch 00097: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9528 - accuracy: 0.5893 - val_loss: 1.0289 - val_accuracy: 0.4984 - lr: 0.0369\n",
      "Epoch 98/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0105 - accuracy: 0.52 - ETA: 0s - loss: 1.0181 - accuracy: 0.51 - ETA: 0s - loss: 1.0070 - accuracy: 0.52 - ETA: 0s - loss: 0.9780 - accuracy: 0.55 - ETA: 0s - loss: 0.9691 - accuracy: 0.56 - ETA: 0s - loss: 0.9538 - accuracy: 0.58 - ETA: 0s - loss: 0.9486 - accuracy: 0.59 - ETA: 0s - loss: 0.9466 - accuracy: 0.59 - ETA: 0s - loss: 0.9457 - accuracy: 0.59 - ETA: 0s - loss: 0.9536 - accuracy: 0.58 - ETA: 0s - loss: 0.9446 - accuracy: 0.59 - ETA: 0s - loss: 0.9319 - accuracy: 0.60 - ETA: 0s - loss: 0.9134 - accuracy: 0.62 - ETA: 0s - loss: 0.9258 - accuracy: 0.61 - ETA: 0s - loss: 0.9440 - accuracy: 0.59 - ETA: 0s - loss: 0.9459 - accuracy: 0.59 - ETA: 0s - loss: 0.9509 - accuracy: 0.59 - ETA: 0s - loss: 0.9514 - accuracy: 0.59 - ETA: 0s - loss: 0.9528 - accuracy: 0.5892\n",
      "Epoch 00098: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9528 - accuracy: 0.5892 - val_loss: 1.0289 - val_accuracy: 0.4985 - lr: 0.0369\n",
      "Epoch 99/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0104 - accuracy: 0.52 - ETA: 0s - loss: 1.0180 - accuracy: 0.51 - ETA: 0s - loss: 1.0069 - accuracy: 0.52 - ETA: 0s - loss: 0.9779 - accuracy: 0.55 - ETA: 0s - loss: 0.9690 - accuracy: 0.56 - ETA: 0s - loss: 0.9537 - accuracy: 0.58 - ETA: 0s - loss: 0.9486 - accuracy: 0.59 - ETA: 0s - loss: 0.9465 - accuracy: 0.59 - ETA: 0s - loss: 0.9457 - accuracy: 0.59 - ETA: 0s - loss: 0.9536 - accuracy: 0.58 - ETA: 0s - loss: 0.9446 - accuracy: 0.59 - ETA: 0s - loss: 0.9319 - accuracy: 0.60 - ETA: 0s - loss: 0.9133 - accuracy: 0.62 - ETA: 0s - loss: 0.9258 - accuracy: 0.61 - ETA: 0s - loss: 0.9440 - accuracy: 0.59 - ETA: 0s - loss: 0.9458 - accuracy: 0.59 - ETA: 0s - loss: 0.9509 - accuracy: 0.59 - ETA: 0s - loss: 0.9514 - accuracy: 0.59 - ETA: 0s - loss: 0.9528 - accuracy: 0.5892\n",
      "Epoch 00099: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9528 - accuracy: 0.5892 - val_loss: 1.0288 - val_accuracy: 0.4989 - lr: 0.0369\n",
      "Epoch 100/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0103 - accuracy: 0.52 - ETA: 0s - loss: 1.0178 - accuracy: 0.51 - ETA: 0s - loss: 1.0067 - accuracy: 0.52 - ETA: 0s - loss: 0.9778 - accuracy: 0.55 - ETA: 0s - loss: 0.9690 - accuracy: 0.56 - ETA: 0s - loss: 0.9537 - accuracy: 0.58 - ETA: 0s - loss: 0.9485 - accuracy: 0.59 - ETA: 0s - loss: 0.9465 - accuracy: 0.59 - ETA: 0s - loss: 0.9457 - accuracy: 0.59 - ETA: 0s - loss: 0.9536 - accuracy: 0.58 - ETA: 0s - loss: 0.9446 - accuracy: 0.59 - ETA: 0s - loss: 0.9319 - accuracy: 0.60 - ETA: 0s - loss: 0.9133 - accuracy: 0.62 - ETA: 0s - loss: 0.9258 - accuracy: 0.61 - ETA: 0s - loss: 0.9440 - accuracy: 0.59 - ETA: 0s - loss: 0.9458 - accuracy: 0.59 - ETA: 0s - loss: 0.9509 - accuracy: 0.59 - ETA: 0s - loss: 0.9514 - accuracy: 0.59 - ETA: 0s - loss: 0.9528 - accuracy: 0.5891\n",
      "Epoch 00100: val_loss did not improve from 1.01430\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 0.029491201043128967.\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9528 - accuracy: 0.5891 - val_loss: 1.0288 - val_accuracy: 0.4989 - lr: 0.0369\n",
      "Epoch 101/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0101 - accuracy: 0.52 - ETA: 0s - loss: 1.0180 - accuracy: 0.51 - ETA: 0s - loss: 1.0070 - accuracy: 0.52 - ETA: 0s - loss: 0.9775 - accuracy: 0.55 - ETA: 0s - loss: 0.9684 - accuracy: 0.56 - ETA: 0s - loss: 0.9527 - accuracy: 0.58 - ETA: 0s - loss: 0.9474 - accuracy: 0.59 - ETA: 0s - loss: 0.9454 - accuracy: 0.59 - ETA: 0s - loss: 0.9446 - accuracy: 0.59 - ETA: 0s - loss: 0.9527 - accuracy: 0.58 - ETA: 0s - loss: 0.9437 - accuracy: 0.59 - ETA: 0s - loss: 0.9312 - accuracy: 0.60 - ETA: 0s - loss: 0.9130 - accuracy: 0.62 - ETA: 0s - loss: 0.9250 - accuracy: 0.61 - ETA: 0s - loss: 0.9424 - accuracy: 0.59 - ETA: 0s - loss: 0.9443 - accuracy: 0.59 - ETA: 0s - loss: 0.9492 - accuracy: 0.59 - ETA: 0s - loss: 0.9497 - accuracy: 0.59 - ETA: 0s - loss: 0.9511 - accuracy: 0.5891\n",
      "Epoch 00101: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9511 - accuracy: 0.5891 - val_loss: 1.0277 - val_accuracy: 0.4992 - lr: 0.0295\n",
      "Epoch 102/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0097 - accuracy: 0.52 - ETA: 0s - loss: 1.0174 - accuracy: 0.51 - ETA: 0s - loss: 1.0065 - accuracy: 0.52 - ETA: 0s - loss: 0.9768 - accuracy: 0.55 - ETA: 0s - loss: 0.9677 - accuracy: 0.56 - ETA: 0s - loss: 0.9518 - accuracy: 0.58 - ETA: 0s - loss: 0.9465 - accuracy: 0.59 - ETA: 0s - loss: 0.9446 - accuracy: 0.59 - ETA: 0s - loss: 0.9438 - accuracy: 0.59 - ETA: 0s - loss: 0.9520 - accuracy: 0.58 - ETA: 0s - loss: 0.9429 - accuracy: 0.59 - ETA: 0s - loss: 0.9302 - accuracy: 0.60 - ETA: 0s - loss: 0.9116 - accuracy: 0.62 - ETA: 0s - loss: 0.9240 - accuracy: 0.61 - ETA: 0s - loss: 0.9418 - accuracy: 0.59 - ETA: 0s - loss: 0.9437 - accuracy: 0.59 - ETA: 0s - loss: 0.9488 - accuracy: 0.59 - ETA: 0s - loss: 0.9493 - accuracy: 0.59 - ETA: 0s - loss: 0.9508 - accuracy: 0.5890\n",
      "Epoch 00102: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9508 - accuracy: 0.5890 - val_loss: 1.0269 - val_accuracy: 0.4992 - lr: 0.0295\n",
      "Epoch 103/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0094 - accuracy: 0.52 - ETA: 0s - loss: 1.0166 - accuracy: 0.51 - ETA: 0s - loss: 1.0058 - accuracy: 0.53 - ETA: 0s - loss: 0.9764 - accuracy: 0.55 - ETA: 0s - loss: 0.9675 - accuracy: 0.56 - ETA: 0s - loss: 0.9518 - accuracy: 0.58 - ETA: 0s - loss: 0.9467 - accuracy: 0.59 - ETA: 0s - loss: 0.9449 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.59 - ETA: 0s - loss: 0.9522 - accuracy: 0.58 - ETA: 0s - loss: 0.9432 - accuracy: 0.59 - ETA: 0s - loss: 0.9305 - accuracy: 0.60 - ETA: 0s - loss: 0.9120 - accuracy: 0.62 - ETA: 0s - loss: 0.9243 - accuracy: 0.61 - ETA: 0s - loss: 0.9421 - accuracy: 0.59 - ETA: 0s - loss: 0.9440 - accuracy: 0.59 - ETA: 0s - loss: 0.9491 - accuracy: 0.59 - ETA: 0s - loss: 0.9496 - accuracy: 0.59 - ETA: 0s - loss: 0.9511 - accuracy: 0.5890\n",
      "Epoch 00103: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9511 - accuracy: 0.5890 - val_loss: 1.0276 - val_accuracy: 0.4993 - lr: 0.0295\n",
      "Epoch 104/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0095 - accuracy: 0.52 - ETA: 0s - loss: 1.0168 - accuracy: 0.51 - ETA: 0s - loss: 1.0059 - accuracy: 0.53 - ETA: 0s - loss: 0.9764 - accuracy: 0.55 - ETA: 0s - loss: 0.9674 - accuracy: 0.56 - ETA: 0s - loss: 0.9517 - accuracy: 0.58 - ETA: 0s - loss: 0.9466 - accuracy: 0.59 - ETA: 0s - loss: 0.9448 - accuracy: 0.59 - ETA: 0s - loss: 0.9440 - accuracy: 0.59 - ETA: 0s - loss: 0.9521 - accuracy: 0.58 - ETA: 0s - loss: 0.9431 - accuracy: 0.59 - ETA: 0s - loss: 0.9304 - accuracy: 0.60 - ETA: 0s - loss: 0.9119 - accuracy: 0.62 - ETA: 0s - loss: 0.9243 - accuracy: 0.61 - ETA: 0s - loss: 0.9421 - accuracy: 0.59 - ETA: 0s - loss: 0.9440 - accuracy: 0.59 - ETA: 0s - loss: 0.9490 - accuracy: 0.59 - ETA: 0s - loss: 0.9495 - accuracy: 0.59 - ETA: 0s - loss: 0.9510 - accuracy: 0.5890\n",
      "Epoch 00104: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9510 - accuracy: 0.5890 - val_loss: 1.0273 - val_accuracy: 0.4995 - lr: 0.0295\n",
      "Epoch 105/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0092 - accuracy: 0.52 - ETA: 0s - loss: 1.0164 - accuracy: 0.51 - ETA: 0s - loss: 1.0056 - accuracy: 0.53 - ETA: 0s - loss: 0.9762 - accuracy: 0.55 - ETA: 0s - loss: 0.9673 - accuracy: 0.56 - ETA: 0s - loss: 0.9516 - accuracy: 0.58 - ETA: 0s - loss: 0.9465 - accuracy: 0.59 - ETA: 0s - loss: 0.9448 - accuracy: 0.59 - ETA: 0s - loss: 0.9439 - accuracy: 0.59 - ETA: 0s - loss: 0.9521 - accuracy: 0.58 - ETA: 0s - loss: 0.9431 - accuracy: 0.59 - ETA: 0s - loss: 0.9304 - accuracy: 0.60 - ETA: 0s - loss: 0.9118 - accuracy: 0.62 - ETA: 0s - loss: 0.9242 - accuracy: 0.61 - ETA: 0s - loss: 0.9420 - accuracy: 0.59 - ETA: 0s - loss: 0.9439 - accuracy: 0.59 - ETA: 0s - loss: 0.9490 - accuracy: 0.59 - ETA: 0s - loss: 0.9496 - accuracy: 0.59 - ETA: 0s - loss: 0.9510 - accuracy: 0.5889\n",
      "Epoch 00105: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9510 - accuracy: 0.5889 - val_loss: 1.0272 - val_accuracy: 0.4997 - lr: 0.0295\n",
      "Epoch 106/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0091 - accuracy: 0.52 - ETA: 0s - loss: 1.0163 - accuracy: 0.51 - ETA: 0s - loss: 1.0054 - accuracy: 0.53 - ETA: 0s - loss: 0.9760 - accuracy: 0.55 - ETA: 0s - loss: 0.9672 - accuracy: 0.56 - ETA: 0s - loss: 0.9515 - accuracy: 0.58 - ETA: 0s - loss: 0.9464 - accuracy: 0.59 - ETA: 0s - loss: 0.9448 - accuracy: 0.59 - ETA: 0s - loss: 0.9439 - accuracy: 0.59 - ETA: 0s - loss: 0.9520 - accuracy: 0.58 - ETA: 0s - loss: 0.9431 - accuracy: 0.59 - ETA: 0s - loss: 0.9304 - accuracy: 0.60 - ETA: 0s - loss: 0.9117 - accuracy: 0.62 - ETA: 0s - loss: 0.9242 - accuracy: 0.61 - ETA: 0s - loss: 0.9420 - accuracy: 0.59 - ETA: 0s - loss: 0.9439 - accuracy: 0.59 - ETA: 0s - loss: 0.9490 - accuracy: 0.59 - ETA: 0s - loss: 0.9496 - accuracy: 0.59 - ETA: 0s - loss: 0.9511 - accuracy: 0.5891\n",
      "Epoch 00106: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9511 - accuracy: 0.5891 - val_loss: 1.0272 - val_accuracy: 0.4997 - lr: 0.0295\n",
      "Epoch 107/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0090 - accuracy: 0.52 - ETA: 0s - loss: 1.0161 - accuracy: 0.51 - ETA: 0s - loss: 1.0053 - accuracy: 0.53 - ETA: 0s - loss: 0.9759 - accuracy: 0.55 - ETA: 0s - loss: 0.9670 - accuracy: 0.57 - ETA: 0s - loss: 0.9514 - accuracy: 0.58 - ETA: 0s - loss: 0.9463 - accuracy: 0.59 - ETA: 0s - loss: 0.9447 - accuracy: 0.59 - ETA: 0s - loss: 0.9438 - accuracy: 0.59 - ETA: 0s - loss: 0.9520 - accuracy: 0.58 - ETA: 0s - loss: 0.9430 - accuracy: 0.59 - ETA: 0s - loss: 0.9303 - accuracy: 0.60 - ETA: 0s - loss: 0.9117 - accuracy: 0.62 - ETA: 0s - loss: 0.9241 - accuracy: 0.61 - ETA: 0s - loss: 0.9420 - accuracy: 0.59 - ETA: 0s - loss: 0.9439 - accuracy: 0.59 - ETA: 0s - loss: 0.9490 - accuracy: 0.59 - ETA: 0s - loss: 0.9496 - accuracy: 0.59 - ETA: 0s - loss: 0.9510 - accuracy: 0.5893\n",
      "Epoch 00107: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9510 - accuracy: 0.5893 - val_loss: 1.0271 - val_accuracy: 0.4998 - lr: 0.0295\n",
      "Epoch 108/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0088 - accuracy: 0.52 - ETA: 0s - loss: 1.0159 - accuracy: 0.51 - ETA: 0s - loss: 1.0051 - accuracy: 0.53 - ETA: 0s - loss: 0.9757 - accuracy: 0.55 - ETA: 0s - loss: 0.9669 - accuracy: 0.57 - ETA: 0s - loss: 0.9512 - accuracy: 0.58 - ETA: 0s - loss: 0.9462 - accuracy: 0.59 - ETA: 0s - loss: 0.9447 - accuracy: 0.59 - ETA: 0s - loss: 0.9438 - accuracy: 0.59 - ETA: 0s - loss: 0.9519 - accuracy: 0.58 - ETA: 0s - loss: 0.9430 - accuracy: 0.59 - ETA: 0s - loss: 0.9303 - accuracy: 0.60 - ETA: 0s - loss: 0.9116 - accuracy: 0.62 - ETA: 0s - loss: 0.9241 - accuracy: 0.61 - ETA: 0s - loss: 0.9419 - accuracy: 0.59 - ETA: 0s - loss: 0.9439 - accuracy: 0.59 - ETA: 0s - loss: 0.9490 - accuracy: 0.59 - ETA: 0s - loss: 0.9496 - accuracy: 0.59 - ETA: 0s - loss: 0.9510 - accuracy: 0.5893\n",
      "Epoch 00108: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9510 - accuracy: 0.5893 - val_loss: 1.0271 - val_accuracy: 0.4998 - lr: 0.0295\n",
      "Epoch 109/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0087 - accuracy: 0.52 - ETA: 0s - loss: 1.0158 - accuracy: 0.51 - ETA: 0s - loss: 1.0050 - accuracy: 0.53 - ETA: 0s - loss: 0.9756 - accuracy: 0.55 - ETA: 0s - loss: 0.9668 - accuracy: 0.57 - ETA: 0s - loss: 0.9511 - accuracy: 0.58 - ETA: 0s - loss: 0.9462 - accuracy: 0.59 - ETA: 0s - loss: 0.9447 - accuracy: 0.59 - ETA: 0s - loss: 0.9438 - accuracy: 0.59 - ETA: 0s - loss: 0.9519 - accuracy: 0.58 - ETA: 0s - loss: 0.9429 - accuracy: 0.59 - ETA: 0s - loss: 0.9303 - accuracy: 0.60 - ETA: 0s - loss: 0.9116 - accuracy: 0.62 - ETA: 0s - loss: 0.9240 - accuracy: 0.61 - ETA: 0s - loss: 0.9419 - accuracy: 0.59 - ETA: 0s - loss: 0.9438 - accuracy: 0.59 - ETA: 0s - loss: 0.9490 - accuracy: 0.59 - ETA: 0s - loss: 0.9496 - accuracy: 0.59 - ETA: 0s - loss: 0.9510 - accuracy: 0.5893\n",
      "Epoch 00109: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9510 - accuracy: 0.5893 - val_loss: 1.0270 - val_accuracy: 0.4997 - lr: 0.0295\n",
      "Epoch 110/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0086 - accuracy: 0.52 - ETA: 0s - loss: 1.0156 - accuracy: 0.51 - ETA: 0s - loss: 1.0048 - accuracy: 0.53 - ETA: 0s - loss: 0.9754 - accuracy: 0.55 - ETA: 0s - loss: 0.9667 - accuracy: 0.57 - ETA: 0s - loss: 0.9510 - accuracy: 0.58 - ETA: 0s - loss: 0.9461 - accuracy: 0.59 - ETA: 0s - loss: 0.9446 - accuracy: 0.59 - ETA: 0s - loss: 0.9437 - accuracy: 0.59 - ETA: 0s - loss: 0.9518 - accuracy: 0.58 - ETA: 0s - loss: 0.9429 - accuracy: 0.59 - ETA: 0s - loss: 0.9302 - accuracy: 0.60 - ETA: 0s - loss: 0.9115 - accuracy: 0.62 - ETA: 0s - loss: 0.9240 - accuracy: 0.61 - ETA: 0s - loss: 0.9419 - accuracy: 0.59 - ETA: 0s - loss: 0.9438 - accuracy: 0.59 - ETA: 0s - loss: 0.9489 - accuracy: 0.59 - ETA: 0s - loss: 0.9496 - accuracy: 0.59 - ETA: 0s - loss: 0.9510 - accuracy: 0.5892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00110: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9510 - accuracy: 0.5892 - val_loss: 1.0269 - val_accuracy: 0.4997 - lr: 0.0295\n",
      "Epoch 111/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0085 - accuracy: 0.52 - ETA: 0s - loss: 1.0155 - accuracy: 0.51 - ETA: 0s - loss: 1.0048 - accuracy: 0.53 - ETA: 0s - loss: 0.9753 - accuracy: 0.55 - ETA: 0s - loss: 0.9666 - accuracy: 0.57 - ETA: 0s - loss: 0.9509 - accuracy: 0.58 - ETA: 0s - loss: 0.9460 - accuracy: 0.59 - ETA: 0s - loss: 0.9446 - accuracy: 0.59 - ETA: 0s - loss: 0.9437 - accuracy: 0.59 - ETA: 0s - loss: 0.9518 - accuracy: 0.58 - ETA: 0s - loss: 0.9429 - accuracy: 0.59 - ETA: 0s - loss: 0.9302 - accuracy: 0.60 - ETA: 0s - loss: 0.9115 - accuracy: 0.62 - ETA: 0s - loss: 0.9240 - accuracy: 0.61 - ETA: 0s - loss: 0.9418 - accuracy: 0.59 - ETA: 0s - loss: 0.9438 - accuracy: 0.59 - ETA: 0s - loss: 0.9489 - accuracy: 0.59 - ETA: 0s - loss: 0.9495 - accuracy: 0.59 - ETA: 0s - loss: 0.9510 - accuracy: 0.5891\n",
      "Epoch 00111: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9510 - accuracy: 0.5891 - val_loss: 1.0268 - val_accuracy: 0.4997 - lr: 0.0295\n",
      "Epoch 112/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0084 - accuracy: 0.52 - ETA: 0s - loss: 1.0153 - accuracy: 0.51 - ETA: 0s - loss: 1.0046 - accuracy: 0.53 - ETA: 0s - loss: 0.9752 - accuracy: 0.55 - ETA: 0s - loss: 0.9665 - accuracy: 0.57 - ETA: 0s - loss: 0.9508 - accuracy: 0.58 - ETA: 0s - loss: 0.9459 - accuracy: 0.59 - ETA: 0s - loss: 0.9445 - accuracy: 0.59 - ETA: 0s - loss: 0.9436 - accuracy: 0.59 - ETA: 0s - loss: 0.9517 - accuracy: 0.58 - ETA: 0s - loss: 0.9428 - accuracy: 0.59 - ETA: 0s - loss: 0.9301 - accuracy: 0.60 - ETA: 0s - loss: 0.9114 - accuracy: 0.62 - ETA: 0s - loss: 0.9239 - accuracy: 0.61 - ETA: 0s - loss: 0.9418 - accuracy: 0.59 - ETA: 0s - loss: 0.9437 - accuracy: 0.59 - ETA: 0s - loss: 0.9489 - accuracy: 0.59 - ETA: 0s - loss: 0.9495 - accuracy: 0.59 - ETA: 0s - loss: 0.9509 - accuracy: 0.5891\n",
      "Epoch 00112: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9509 - accuracy: 0.5891 - val_loss: 1.0268 - val_accuracy: 0.4997 - lr: 0.0295\n",
      "Epoch 113/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0083 - accuracy: 0.52 - ETA: 0s - loss: 1.0152 - accuracy: 0.51 - ETA: 0s - loss: 1.0045 - accuracy: 0.53 - ETA: 0s - loss: 0.9751 - accuracy: 0.55 - ETA: 0s - loss: 0.9664 - accuracy: 0.57 - ETA: 0s - loss: 0.9507 - accuracy: 0.58 - ETA: 0s - loss: 0.9458 - accuracy: 0.59 - ETA: 0s - loss: 0.9445 - accuracy: 0.59 - ETA: 0s - loss: 0.9435 - accuracy: 0.59 - ETA: 0s - loss: 0.9517 - accuracy: 0.58 - ETA: 0s - loss: 0.9428 - accuracy: 0.59 - ETA: 0s - loss: 0.9301 - accuracy: 0.60 - ETA: 0s - loss: 0.9113 - accuracy: 0.62 - ETA: 0s - loss: 0.9239 - accuracy: 0.61 - ETA: 0s - loss: 0.9417 - accuracy: 0.59 - ETA: 0s - loss: 0.9437 - accuracy: 0.59 - ETA: 0s - loss: 0.9488 - accuracy: 0.59 - ETA: 0s - loss: 0.9495 - accuracy: 0.59 - ETA: 0s - loss: 0.9509 - accuracy: 0.5891\n",
      "Epoch 00113: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9509 - accuracy: 0.5891 - val_loss: 1.0267 - val_accuracy: 0.4997 - lr: 0.0295\n",
      "Epoch 114/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0082 - accuracy: 0.52 - ETA: 0s - loss: 1.0150 - accuracy: 0.51 - ETA: 0s - loss: 1.0044 - accuracy: 0.53 - ETA: 0s - loss: 0.9750 - accuracy: 0.55 - ETA: 0s - loss: 0.9663 - accuracy: 0.57 - ETA: 0s - loss: 0.9506 - accuracy: 0.58 - ETA: 0s - loss: 0.9457 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.59 - ETA: 0s - loss: 0.9435 - accuracy: 0.59 - ETA: 0s - loss: 0.9516 - accuracy: 0.58 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9300 - accuracy: 0.60 - ETA: 0s - loss: 0.9113 - accuracy: 0.62 - ETA: 0s - loss: 0.9238 - accuracy: 0.61 - ETA: 0s - loss: 0.9417 - accuracy: 0.59 - ETA: 0s - loss: 0.9436 - accuracy: 0.59 - ETA: 0s - loss: 0.9488 - accuracy: 0.59 - ETA: 0s - loss: 0.9494 - accuracy: 0.59 - ETA: 0s - loss: 0.9509 - accuracy: 0.5891\n",
      "Epoch 00114: val_loss did not improve from 1.01430\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 0.023592960834503175.\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9509 - accuracy: 0.5891 - val_loss: 1.0266 - val_accuracy: 0.4998 - lr: 0.0295\n",
      "Epoch 115/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0081 - accuracy: 0.52 - ETA: 0s - loss: 1.0152 - accuracy: 0.51 - ETA: 0s - loss: 1.0046 - accuracy: 0.53 - ETA: 0s - loss: 0.9747 - accuracy: 0.55 - ETA: 0s - loss: 0.9658 - accuracy: 0.56 - ETA: 0s - loss: 0.9497 - accuracy: 0.58 - ETA: 0s - loss: 0.9447 - accuracy: 0.59 - ETA: 0s - loss: 0.9434 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9508 - accuracy: 0.58 - ETA: 0s - loss: 0.9420 - accuracy: 0.59 - ETA: 0s - loss: 0.9294 - accuracy: 0.60 - ETA: 0s - loss: 0.9110 - accuracy: 0.62 - ETA: 0s - loss: 0.9231 - accuracy: 0.61 - ETA: 0s - loss: 0.9403 - accuracy: 0.59 - ETA: 0s - loss: 0.9422 - accuracy: 0.59 - ETA: 0s - loss: 0.9473 - accuracy: 0.59 - ETA: 0s - loss: 0.9479 - accuracy: 0.59 - ETA: 0s - loss: 0.9494 - accuracy: 0.5891\n",
      "Epoch 00115: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9494 - accuracy: 0.5891 - val_loss: 1.0251 - val_accuracy: 0.5000 - lr: 0.0236\n",
      "Epoch 116/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0075 - accuracy: 0.52 - ETA: 0s - loss: 1.0143 - accuracy: 0.51 - ETA: 0s - loss: 1.0040 - accuracy: 0.53 - ETA: 0s - loss: 0.9740 - accuracy: 0.56 - ETA: 0s - loss: 0.9652 - accuracy: 0.57 - ETA: 0s - loss: 0.9491 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.59 - ETA: 0s - loss: 0.9429 - accuracy: 0.59 - ETA: 0s - loss: 0.9420 - accuracy: 0.59 - ETA: 0s - loss: 0.9504 - accuracy: 0.58 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9287 - accuracy: 0.60 - ETA: 0s - loss: 0.9100 - accuracy: 0.62 - ETA: 0s - loss: 0.9224 - accuracy: 0.61 - ETA: 0s - loss: 0.9399 - accuracy: 0.59 - ETA: 0s - loss: 0.9419 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.59 - ETA: 0s - loss: 0.9477 - accuracy: 0.59 - ETA: 0s - loss: 0.9491 - accuracy: 0.5893\n",
      "Epoch 00116: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9491 - accuracy: 0.5893 - val_loss: 1.0250 - val_accuracy: 0.5002 - lr: 0.0236\n",
      "Epoch 117/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0075 - accuracy: 0.52 - ETA: 0s - loss: 1.0141 - accuracy: 0.51 - ETA: 0s - loss: 1.0038 - accuracy: 0.53 - ETA: 0s - loss: 0.9739 - accuracy: 0.56 - ETA: 0s - loss: 0.9651 - accuracy: 0.57 - ETA: 0s - loss: 0.9491 - accuracy: 0.58 - ETA: 0s - loss: 0.9442 - accuracy: 0.59 - ETA: 0s - loss: 0.9430 - accuracy: 0.59 - ETA: 0s - loss: 0.9421 - accuracy: 0.59 - ETA: 0s - loss: 0.9505 - accuracy: 0.58 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9289 - accuracy: 0.60 - ETA: 0s - loss: 0.9103 - accuracy: 0.62 - ETA: 0s - loss: 0.9226 - accuracy: 0.61 - ETA: 0s - loss: 0.9400 - accuracy: 0.59 - ETA: 0s - loss: 0.9420 - accuracy: 0.59 - ETA: 0s - loss: 0.9471 - accuracy: 0.59 - ETA: 0s - loss: 0.9478 - accuracy: 0.59 - ETA: 0s - loss: 0.9492 - accuracy: 0.5893\n",
      "Epoch 00117: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9492 - accuracy: 0.5893 - val_loss: 1.0251 - val_accuracy: 0.5002 - lr: 0.0236\n",
      "Epoch 118/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0074 - accuracy: 0.52 - ETA: 0s - loss: 1.0141 - accuracy: 0.51 - ETA: 0s - loss: 1.0038 - accuracy: 0.53 - ETA: 0s - loss: 0.9738 - accuracy: 0.56 - ETA: 0s - loss: 0.9651 - accuracy: 0.57 - ETA: 0s - loss: 0.9490 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.59 - ETA: 0s - loss: 0.9429 - accuracy: 0.59 - ETA: 0s - loss: 0.9420 - accuracy: 0.59 - ETA: 0s - loss: 0.9504 - accuracy: 0.58 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9288 - accuracy: 0.60 - ETA: 0s - loss: 0.9102 - accuracy: 0.62 - ETA: 0s - loss: 0.9225 - accuracy: 0.61 - ETA: 0s - loss: 0.9399 - accuracy: 0.59 - ETA: 0s - loss: 0.9419 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.59 - ETA: 0s - loss: 0.9477 - accuracy: 0.59 - ETA: 0s - loss: 0.9492 - accuracy: 0.5893\n",
      "Epoch 00118: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9492 - accuracy: 0.5893 - val_loss: 1.0250 - val_accuracy: 0.5002 - lr: 0.0236\n",
      "Epoch 119/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0073 - accuracy: 0.52 - ETA: 0s - loss: 1.0140 - accuracy: 0.51 - ETA: 0s - loss: 1.0037 - accuracy: 0.53 - ETA: 0s - loss: 0.9737 - accuracy: 0.56 - ETA: 0s - loss: 0.9650 - accuracy: 0.57 - ETA: 0s - loss: 0.9489 - accuracy: 0.58 - ETA: 0s - loss: 0.9440 - accuracy: 0.59 - ETA: 0s - loss: 0.9429 - accuracy: 0.59 - ETA: 0s - loss: 0.9420 - accuracy: 0.59 - ETA: 0s - loss: 0.9504 - accuracy: 0.58 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9288 - accuracy: 0.60 - ETA: 0s - loss: 0.9101 - accuracy: 0.62 - ETA: 0s - loss: 0.9225 - accuracy: 0.61 - ETA: 0s - loss: 0.9399 - accuracy: 0.59 - ETA: 0s - loss: 0.9419 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.59 - ETA: 0s - loss: 0.9477 - accuracy: 0.59 - ETA: 0s - loss: 0.9492 - accuracy: 0.5894\n",
      "Epoch 00119: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9492 - accuracy: 0.5894 - val_loss: 1.0250 - val_accuracy: 0.5000 - lr: 0.0236\n",
      "Epoch 120/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0073 - accuracy: 0.52 - ETA: 0s - loss: 1.0139 - accuracy: 0.51 - ETA: 0s - loss: 1.0036 - accuracy: 0.53 - ETA: 0s - loss: 0.9737 - accuracy: 0.56 - ETA: 0s - loss: 0.9649 - accuracy: 0.57 - ETA: 0s - loss: 0.9489 - accuracy: 0.58 - ETA: 0s - loss: 0.9440 - accuracy: 0.59 - ETA: 0s - loss: 0.9429 - accuracy: 0.59 - ETA: 0s - loss: 0.9420 - accuracy: 0.59 - ETA: 0s - loss: 0.9503 - accuracy: 0.58 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9288 - accuracy: 0.60 - ETA: 0s - loss: 0.9101 - accuracy: 0.62 - ETA: 0s - loss: 0.9225 - accuracy: 0.61 - ETA: 0s - loss: 0.9398 - accuracy: 0.59 - ETA: 0s - loss: 0.9418 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.59 - ETA: 0s - loss: 0.9477 - accuracy: 0.59 - ETA: 0s - loss: 0.9491 - accuracy: 0.5894\n",
      "Epoch 00120: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9491 - accuracy: 0.5894 - val_loss: 1.0249 - val_accuracy: 0.5002 - lr: 0.0236\n",
      "Epoch 121/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0072 - accuracy: 0.52 - ETA: 0s - loss: 1.0138 - accuracy: 0.51 - ETA: 0s - loss: 1.0036 - accuracy: 0.53 - ETA: 0s - loss: 0.9736 - accuracy: 0.55 - ETA: 0s - loss: 0.9648 - accuracy: 0.57 - ETA: 0s - loss: 0.9488 - accuracy: 0.58 - ETA: 0s - loss: 0.9439 - accuracy: 0.59 - ETA: 0s - loss: 0.9428 - accuracy: 0.59 - ETA: 0s - loss: 0.9419 - accuracy: 0.59 - ETA: 0s - loss: 0.9503 - accuracy: 0.58 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9287 - accuracy: 0.60 - ETA: 0s - loss: 0.9101 - accuracy: 0.62 - ETA: 0s - loss: 0.9224 - accuracy: 0.61 - ETA: 0s - loss: 0.9398 - accuracy: 0.59 - ETA: 0s - loss: 0.9418 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.59 - ETA: 0s - loss: 0.9477 - accuracy: 0.59 - ETA: 0s - loss: 0.9491 - accuracy: 0.5893\n",
      "Epoch 00121: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9491 - accuracy: 0.5893 - val_loss: 1.0248 - val_accuracy: 0.5000 - lr: 0.0236\n",
      "Epoch 122/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0072 - accuracy: 0.52 - ETA: 0s - loss: 1.0137 - accuracy: 0.51 - ETA: 0s - loss: 1.0035 - accuracy: 0.53 - ETA: 0s - loss: 0.9735 - accuracy: 0.55 - ETA: 0s - loss: 0.9648 - accuracy: 0.57 - ETA: 0s - loss: 0.9487 - accuracy: 0.58 - ETA: 0s - loss: 0.9439 - accuracy: 0.59 - ETA: 0s - loss: 0.9428 - accuracy: 0.59 - ETA: 0s - loss: 0.9419 - accuracy: 0.59 - ETA: 0s - loss: 0.9503 - accuracy: 0.58 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9287 - accuracy: 0.60 - ETA: 0s - loss: 0.9100 - accuracy: 0.62 - ETA: 0s - loss: 0.9224 - accuracy: 0.61 - ETA: 0s - loss: 0.9398 - accuracy: 0.59 - ETA: 0s - loss: 0.9418 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.59 - ETA: 0s - loss: 0.9477 - accuracy: 0.59 - ETA: 0s - loss: 0.9491 - accuracy: 0.5893\n",
      "Epoch 00122: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9491 - accuracy: 0.5893 - val_loss: 1.0248 - val_accuracy: 0.5000 - lr: 0.0236\n",
      "Epoch 123/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0071 - accuracy: 0.52 - ETA: 0s - loss: 1.0136 - accuracy: 0.51 - ETA: 0s - loss: 1.0034 - accuracy: 0.53 - ETA: 0s - loss: 0.9734 - accuracy: 0.55 - ETA: 0s - loss: 0.9647 - accuracy: 0.57 - ETA: 0s - loss: 0.9486 - accuracy: 0.58 - ETA: 0s - loss: 0.9438 - accuracy: 0.59 - ETA: 0s - loss: 0.9428 - accuracy: 0.59 - ETA: 0s - loss: 0.9419 - accuracy: 0.59 - ETA: 0s - loss: 0.9502 - accuracy: 0.58 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9287 - accuracy: 0.60 - ETA: 0s - loss: 0.9100 - accuracy: 0.62 - ETA: 0s - loss: 0.9224 - accuracy: 0.61 - ETA: 0s - loss: 0.9397 - accuracy: 0.59 - ETA: 0s - loss: 0.9417 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.59 - ETA: 0s - loss: 0.9476 - accuracy: 0.59 - ETA: 0s - loss: 0.9491 - accuracy: 0.5894\n",
      "Epoch 00123: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9491 - accuracy: 0.5894 - val_loss: 1.0247 - val_accuracy: 0.4998 - lr: 0.0236\n",
      "Epoch 124/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0071 - accuracy: 0.52 - ETA: 0s - loss: 1.0135 - accuracy: 0.51 - ETA: 0s - loss: 1.0034 - accuracy: 0.53 - ETA: 0s - loss: 0.9733 - accuracy: 0.55 - ETA: 0s - loss: 0.9647 - accuracy: 0.57 - ETA: 0s - loss: 0.9486 - accuracy: 0.58 - ETA: 0s - loss: 0.9437 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9418 - accuracy: 0.59 - ETA: 0s - loss: 0.9502 - accuracy: 0.58 - ETA: 0s - loss: 0.9413 - accuracy: 0.59 - ETA: 0s - loss: 0.9287 - accuracy: 0.60 - ETA: 0s - loss: 0.9100 - accuracy: 0.62 - ETA: 0s - loss: 0.9223 - accuracy: 0.61 - ETA: 0s - loss: 0.9397 - accuracy: 0.59 - ETA: 0s - loss: 0.9417 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.59 - ETA: 0s - loss: 0.9476 - accuracy: 0.59 - ETA: 0s - loss: 0.9490 - accuracy: 0.5894\n",
      "Epoch 00124: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9490 - accuracy: 0.5894 - val_loss: 1.0247 - val_accuracy: 0.4998 - lr: 0.0236\n",
      "Epoch 125/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0070 - accuracy: 0.52 - ETA: 0s - loss: 1.0135 - accuracy: 0.51 - ETA: 0s - loss: 1.0033 - accuracy: 0.53 - ETA: 0s - loss: 0.9733 - accuracy: 0.55 - ETA: 0s - loss: 0.9646 - accuracy: 0.57 - ETA: 0s - loss: 0.9485 - accuracy: 0.58 - ETA: 0s - loss: 0.9437 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9418 - accuracy: 0.59 - ETA: 0s - loss: 0.9502 - accuracy: 0.58 - ETA: 0s - loss: 0.9413 - accuracy: 0.59 - ETA: 0s - loss: 0.9286 - accuracy: 0.60 - ETA: 0s - loss: 0.9100 - accuracy: 0.62 - ETA: 0s - loss: 0.9223 - accuracy: 0.61 - ETA: 0s - loss: 0.9397 - accuracy: 0.59 - ETA: 0s - loss: 0.9417 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.59 - ETA: 0s - loss: 0.9476 - accuracy: 0.59 - ETA: 0s - loss: 0.9490 - accuracy: 0.5894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00125: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9490 - accuracy: 0.5894 - val_loss: 1.0246 - val_accuracy: 0.4997 - lr: 0.0236\n",
      "Epoch 126/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0070 - accuracy: 0.52 - ETA: 0s - loss: 1.0134 - accuracy: 0.51 - ETA: 0s - loss: 1.0033 - accuracy: 0.53 - ETA: 0s - loss: 0.9732 - accuracy: 0.55 - ETA: 0s - loss: 0.9645 - accuracy: 0.57 - ETA: 0s - loss: 0.9485 - accuracy: 0.58 - ETA: 0s - loss: 0.9437 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9418 - accuracy: 0.59 - ETA: 0s - loss: 0.9501 - accuracy: 0.58 - ETA: 0s - loss: 0.9413 - accuracy: 0.59 - ETA: 0s - loss: 0.9286 - accuracy: 0.60 - ETA: 0s - loss: 0.9099 - accuracy: 0.62 - ETA: 0s - loss: 0.9223 - accuracy: 0.61 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9417 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.59 - ETA: 0s - loss: 0.9476 - accuracy: 0.59 - ETA: 0s - loss: 0.9490 - accuracy: 0.5894\n",
      "Epoch 00126: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9490 - accuracy: 0.5894 - val_loss: 1.0246 - val_accuracy: 0.4997 - lr: 0.0236\n",
      "Epoch 127/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0069 - accuracy: 0.52 - ETA: 0s - loss: 1.0133 - accuracy: 0.51 - ETA: 0s - loss: 1.0032 - accuracy: 0.53 - ETA: 0s - loss: 0.9731 - accuracy: 0.55 - ETA: 0s - loss: 0.9645 - accuracy: 0.57 - ETA: 0s - loss: 0.9484 - accuracy: 0.58 - ETA: 0s - loss: 0.9436 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9417 - accuracy: 0.59 - ETA: 0s - loss: 0.9501 - accuracy: 0.58 - ETA: 0s - loss: 0.9413 - accuracy: 0.59 - ETA: 0s - loss: 0.9286 - accuracy: 0.60 - ETA: 0s - loss: 0.9099 - accuracy: 0.62 - ETA: 0s - loss: 0.9223 - accuracy: 0.61 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.59 - ETA: 0s - loss: 0.9476 - accuracy: 0.59 - ETA: 0s - loss: 0.9490 - accuracy: 0.5894\n",
      "Epoch 00127: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9490 - accuracy: 0.5894 - val_loss: 1.0245 - val_accuracy: 0.4998 - lr: 0.0236\n",
      "Epoch 128/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0069 - accuracy: 0.52 - ETA: 0s - loss: 1.0133 - accuracy: 0.51 - ETA: 0s - loss: 1.0032 - accuracy: 0.53 - ETA: 0s - loss: 0.9731 - accuracy: 0.55 - ETA: 0s - loss: 0.9645 - accuracy: 0.57 - ETA: 0s - loss: 0.9484 - accuracy: 0.58 - ETA: 0s - loss: 0.9436 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.59 - ETA: 0s - loss: 0.9417 - accuracy: 0.59 - ETA: 0s - loss: 0.9501 - accuracy: 0.58 - ETA: 0s - loss: 0.9413 - accuracy: 0.59 - ETA: 0s - loss: 0.9286 - accuracy: 0.60 - ETA: 0s - loss: 0.9099 - accuracy: 0.62 - ETA: 0s - loss: 0.9223 - accuracy: 0.61 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.59 - ETA: 0s - loss: 0.9475 - accuracy: 0.59 - ETA: 0s - loss: 0.9490 - accuracy: 0.5894\n",
      "Epoch 00128: val_loss did not improve from 1.01430\n",
      "\n",
      "Epoch 00128: ReduceLROnPlateau reducing learning rate to 0.018874368071556093.\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9490 - accuracy: 0.5894 - val_loss: 1.0245 - val_accuracy: 0.5000 - lr: 0.0236\n",
      "Epoch 129/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0069 - accuracy: 0.52 - ETA: 0s - loss: 1.0135 - accuracy: 0.51 - ETA: 0s - loss: 1.0035 - accuracy: 0.53 - ETA: 0s - loss: 0.9730 - accuracy: 0.55 - ETA: 0s - loss: 0.9642 - accuracy: 0.57 - ETA: 0s - loss: 0.9478 - accuracy: 0.58 - ETA: 0s - loss: 0.9429 - accuracy: 0.59 - ETA: 0s - loss: 0.9420 - accuracy: 0.59 - ETA: 0s - loss: 0.9411 - accuracy: 0.59 - ETA: 0s - loss: 0.9495 - accuracy: 0.58 - ETA: 0s - loss: 0.9407 - accuracy: 0.59 - ETA: 0s - loss: 0.9281 - accuracy: 0.60 - ETA: 0s - loss: 0.9096 - accuracy: 0.62 - ETA: 0s - loss: 0.9217 - accuracy: 0.61 - ETA: 0s - loss: 0.9386 - accuracy: 0.59 - ETA: 0s - loss: 0.9406 - accuracy: 0.59 - ETA: 0s - loss: 0.9456 - accuracy: 0.59 - ETA: 0s - loss: 0.9465 - accuracy: 0.59 - ETA: 0s - loss: 0.9479 - accuracy: 0.5894\n",
      "Epoch 00129: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9479 - accuracy: 0.5894 - val_loss: 1.0230 - val_accuracy: 0.5002 - lr: 0.0189\n",
      "Epoch 130/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0062 - accuracy: 0.52 - ETA: 0s - loss: 1.0125 - accuracy: 0.51 - ETA: 0s - loss: 1.0027 - accuracy: 0.53 - ETA: 0s - loss: 0.9724 - accuracy: 0.55 - ETA: 0s - loss: 0.9637 - accuracy: 0.57 - ETA: 0s - loss: 0.9474 - accuracy: 0.58 - ETA: 0s - loss: 0.9426 - accuracy: 0.59 - ETA: 0s - loss: 0.9417 - accuracy: 0.59 - ETA: 0s - loss: 0.9408 - accuracy: 0.59 - ETA: 0s - loss: 0.9493 - accuracy: 0.58 - ETA: 0s - loss: 0.9405 - accuracy: 0.59 - ETA: 0s - loss: 0.9277 - accuracy: 0.60 - ETA: 0s - loss: 0.9090 - accuracy: 0.62 - ETA: 0s - loss: 0.9213 - accuracy: 0.61 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9405 - accuracy: 0.59 - ETA: 0s - loss: 0.9455 - accuracy: 0.59 - ETA: 0s - loss: 0.9464 - accuracy: 0.59 - ETA: 0s - loss: 0.9478 - accuracy: 0.5893\n",
      "Epoch 00130: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9478 - accuracy: 0.5893 - val_loss: 1.0234 - val_accuracy: 0.5000 - lr: 0.0189\n",
      "Epoch 131/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0065 - accuracy: 0.52 - ETA: 0s - loss: 1.0127 - accuracy: 0.51 - ETA: 0s - loss: 1.0029 - accuracy: 0.53 - ETA: 0s - loss: 0.9724 - accuracy: 0.55 - ETA: 0s - loss: 0.9638 - accuracy: 0.57 - ETA: 0s - loss: 0.9475 - accuracy: 0.58 - ETA: 0s - loss: 0.9426 - accuracy: 0.59 - ETA: 0s - loss: 0.9417 - accuracy: 0.59 - ETA: 0s - loss: 0.9409 - accuracy: 0.59 - ETA: 0s - loss: 0.9494 - accuracy: 0.58 - ETA: 0s - loss: 0.9405 - accuracy: 0.59 - ETA: 0s - loss: 0.9278 - accuracy: 0.60 - ETA: 0s - loss: 0.9092 - accuracy: 0.62 - ETA: 0s - loss: 0.9215 - accuracy: 0.61 - ETA: 0s - loss: 0.9385 - accuracy: 0.59 - ETA: 0s - loss: 0.9405 - accuracy: 0.59 - ETA: 0s - loss: 0.9456 - accuracy: 0.59 - ETA: 0s - loss: 0.9464 - accuracy: 0.59 - ETA: 0s - loss: 0.9478 - accuracy: 0.5893\n",
      "Epoch 00131: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9478 - accuracy: 0.5893 - val_loss: 1.0232 - val_accuracy: 0.5002 - lr: 0.0189\n",
      "Epoch 132/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0063 - accuracy: 0.52 - ETA: 0s - loss: 1.0125 - accuracy: 0.51 - ETA: 0s - loss: 1.0027 - accuracy: 0.53 - ETA: 0s - loss: 0.9723 - accuracy: 0.55 - ETA: 0s - loss: 0.9637 - accuracy: 0.57 - ETA: 0s - loss: 0.9474 - accuracy: 0.58 - ETA: 0s - loss: 0.9426 - accuracy: 0.59 - ETA: 0s - loss: 0.9417 - accuracy: 0.59 - ETA: 0s - loss: 0.9408 - accuracy: 0.59 - ETA: 0s - loss: 0.9493 - accuracy: 0.58 - ETA: 0s - loss: 0.9405 - accuracy: 0.59 - ETA: 0s - loss: 0.9278 - accuracy: 0.60 - ETA: 0s - loss: 0.9091 - accuracy: 0.62 - ETA: 0s - loss: 0.9214 - accuracy: 0.61 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9405 - accuracy: 0.59 - ETA: 0s - loss: 0.9455 - accuracy: 0.59 - ETA: 0s - loss: 0.9464 - accuracy: 0.59 - ETA: 0s - loss: 0.9478 - accuracy: 0.5893\n",
      "Epoch 00132: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9478 - accuracy: 0.5893 - val_loss: 1.0233 - val_accuracy: 0.5000 - lr: 0.0189\n",
      "Epoch 133/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0063 - accuracy: 0.52 - ETA: 0s - loss: 1.0125 - accuracy: 0.51 - ETA: 0s - loss: 1.0027 - accuracy: 0.53 - ETA: 0s - loss: 0.9723 - accuracy: 0.55 - ETA: 0s - loss: 0.9637 - accuracy: 0.57 - ETA: 0s - loss: 0.9474 - accuracy: 0.58 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9417 - accuracy: 0.59 - ETA: 0s - loss: 0.9408 - accuracy: 0.59 - ETA: 0s - loss: 0.9493 - accuracy: 0.58 - ETA: 0s - loss: 0.9405 - accuracy: 0.59 - ETA: 0s - loss: 0.9278 - accuracy: 0.60 - ETA: 0s - loss: 0.9091 - accuracy: 0.62 - ETA: 0s - loss: 0.9214 - accuracy: 0.61 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9405 - accuracy: 0.59 - ETA: 0s - loss: 0.9455 - accuracy: 0.59 - ETA: 0s - loss: 0.9464 - accuracy: 0.59 - ETA: 0s - loss: 0.9478 - accuracy: 0.5894\n",
      "Epoch 00133: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9478 - accuracy: 0.5894 - val_loss: 1.0232 - val_accuracy: 0.4998 - lr: 0.0189\n",
      "Epoch 134/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0063 - accuracy: 0.52 - ETA: 0s - loss: 1.0125 - accuracy: 0.51 - ETA: 0s - loss: 1.0027 - accuracy: 0.53 - ETA: 0s - loss: 0.9723 - accuracy: 0.55 - ETA: 0s - loss: 0.9636 - accuracy: 0.57 - ETA: 0s - loss: 0.9473 - accuracy: 0.58 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9417 - accuracy: 0.59 - ETA: 0s - loss: 0.9408 - accuracy: 0.59 - ETA: 0s - loss: 0.9493 - accuracy: 0.58 - ETA: 0s - loss: 0.9405 - accuracy: 0.59 - ETA: 0s - loss: 0.9278 - accuracy: 0.60 - ETA: 0s - loss: 0.9091 - accuracy: 0.62 - ETA: 0s - loss: 0.9214 - accuracy: 0.61 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9405 - accuracy: 0.59 - ETA: 0s - loss: 0.9455 - accuracy: 0.59 - ETA: 0s - loss: 0.9464 - accuracy: 0.59 - ETA: 0s - loss: 0.9478 - accuracy: 0.5894\n",
      "Epoch 00134: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9478 - accuracy: 0.5894 - val_loss: 1.0232 - val_accuracy: 0.4998 - lr: 0.0189\n",
      "Epoch 135/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0063 - accuracy: 0.52 - ETA: 0s - loss: 1.0124 - accuracy: 0.51 - ETA: 0s - loss: 1.0027 - accuracy: 0.53 - ETA: 0s - loss: 0.9723 - accuracy: 0.55 - ETA: 0s - loss: 0.9636 - accuracy: 0.57 - ETA: 0s - loss: 0.9473 - accuracy: 0.58 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9417 - accuracy: 0.59 - ETA: 0s - loss: 0.9408 - accuracy: 0.59 - ETA: 0s - loss: 0.9493 - accuracy: 0.58 - ETA: 0s - loss: 0.9405 - accuracy: 0.59 - ETA: 0s - loss: 0.9277 - accuracy: 0.60 - ETA: 0s - loss: 0.9091 - accuracy: 0.62 - ETA: 0s - loss: 0.9214 - accuracy: 0.61 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9404 - accuracy: 0.59 - ETA: 0s - loss: 0.9455 - accuracy: 0.59 - ETA: 0s - loss: 0.9464 - accuracy: 0.59 - ETA: 0s - loss: 0.9478 - accuracy: 0.5894\n",
      "Epoch 00135: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9478 - accuracy: 0.5894 - val_loss: 1.0232 - val_accuracy: 0.4998 - lr: 0.0189\n",
      "Epoch 136/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0062 - accuracy: 0.52 - ETA: 0s - loss: 1.0124 - accuracy: 0.51 - ETA: 0s - loss: 1.0027 - accuracy: 0.53 - ETA: 0s - loss: 0.9722 - accuracy: 0.55 - ETA: 0s - loss: 0.9636 - accuracy: 0.57 - ETA: 0s - loss: 0.9473 - accuracy: 0.58 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9417 - accuracy: 0.59 - ETA: 0s - loss: 0.9408 - accuracy: 0.59 - ETA: 0s - loss: 0.9493 - accuracy: 0.58 - ETA: 0s - loss: 0.9404 - accuracy: 0.59 - ETA: 0s - loss: 0.9277 - accuracy: 0.60 - ETA: 0s - loss: 0.9091 - accuracy: 0.62 - ETA: 0s - loss: 0.9213 - accuracy: 0.61 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9404 - accuracy: 0.59 - ETA: 0s - loss: 0.9455 - accuracy: 0.59 - ETA: 0s - loss: 0.9464 - accuracy: 0.59 - ETA: 0s - loss: 0.9478 - accuracy: 0.5894\n",
      "Epoch 00136: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9478 - accuracy: 0.5894 - val_loss: 1.0232 - val_accuracy: 0.4998 - lr: 0.0189\n",
      "Epoch 137/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0062 - accuracy: 0.52 - ETA: 0s - loss: 1.0124 - accuracy: 0.51 - ETA: 0s - loss: 1.0027 - accuracy: 0.53 - ETA: 0s - loss: 0.9722 - accuracy: 0.55 - ETA: 0s - loss: 0.9636 - accuracy: 0.57 - ETA: 0s - loss: 0.9473 - accuracy: 0.58 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9407 - accuracy: 0.59 - ETA: 0s - loss: 0.9493 - accuracy: 0.58 - ETA: 0s - loss: 0.9404 - accuracy: 0.59 - ETA: 0s - loss: 0.9277 - accuracy: 0.60 - ETA: 0s - loss: 0.9091 - accuracy: 0.62 - ETA: 0s - loss: 0.9213 - accuracy: 0.61 - ETA: 0s - loss: 0.9383 - accuracy: 0.59 - ETA: 0s - loss: 0.9404 - accuracy: 0.59 - ETA: 0s - loss: 0.9455 - accuracy: 0.59 - ETA: 0s - loss: 0.9463 - accuracy: 0.59 - ETA: 0s - loss: 0.9478 - accuracy: 0.5894\n",
      "Epoch 00137: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9478 - accuracy: 0.5894 - val_loss: 1.0231 - val_accuracy: 0.4998 - lr: 0.0189\n",
      "Epoch 138/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0062 - accuracy: 0.52 - ETA: 0s - loss: 1.0123 - accuracy: 0.51 - ETA: 0s - loss: 1.0026 - accuracy: 0.53 - ETA: 0s - loss: 0.9722 - accuracy: 0.55 - ETA: 0s - loss: 0.9635 - accuracy: 0.57 - ETA: 0s - loss: 0.9472 - accuracy: 0.58 - ETA: 0s - loss: 0.9424 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9407 - accuracy: 0.59 - ETA: 0s - loss: 0.9492 - accuracy: 0.58 - ETA: 0s - loss: 0.9404 - accuracy: 0.59 - ETA: 0s - loss: 0.9277 - accuracy: 0.60 - ETA: 0s - loss: 0.9091 - accuracy: 0.62 - ETA: 0s - loss: 0.9213 - accuracy: 0.61 - ETA: 0s - loss: 0.9383 - accuracy: 0.59 - ETA: 0s - loss: 0.9404 - accuracy: 0.59 - ETA: 0s - loss: 0.9455 - accuracy: 0.59 - ETA: 0s - loss: 0.9463 - accuracy: 0.59 - ETA: 0s - loss: 0.9478 - accuracy: 0.5894\n",
      "Epoch 00138: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9478 - accuracy: 0.5894 - val_loss: 1.0231 - val_accuracy: 0.4998 - lr: 0.0189\n",
      "Epoch 139/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0062 - accuracy: 0.52 - ETA: 0s - loss: 1.0123 - accuracy: 0.51 - ETA: 0s - loss: 1.0026 - accuracy: 0.53 - ETA: 0s - loss: 0.9721 - accuracy: 0.55 - ETA: 0s - loss: 0.9635 - accuracy: 0.57 - ETA: 0s - loss: 0.9472 - accuracy: 0.58 - ETA: 0s - loss: 0.9424 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9407 - accuracy: 0.59 - ETA: 0s - loss: 0.9492 - accuracy: 0.58 - ETA: 0s - loss: 0.9404 - accuracy: 0.59 - ETA: 0s - loss: 0.9277 - accuracy: 0.60 - ETA: 0s - loss: 0.9090 - accuracy: 0.62 - ETA: 0s - loss: 0.9213 - accuracy: 0.61 - ETA: 0s - loss: 0.9383 - accuracy: 0.59 - ETA: 0s - loss: 0.9404 - accuracy: 0.59 - ETA: 0s - loss: 0.9455 - accuracy: 0.59 - ETA: 0s - loss: 0.9463 - accuracy: 0.59 - ETA: 0s - loss: 0.9478 - accuracy: 0.5894\n",
      "Epoch 00139: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9478 - accuracy: 0.5894 - val_loss: 1.0231 - val_accuracy: 0.4998 - lr: 0.0189\n",
      "Epoch 140/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0062 - accuracy: 0.52 - ETA: 0s - loss: 1.0123 - accuracy: 0.51 - ETA: 0s - loss: 1.0026 - accuracy: 0.53 - ETA: 0s - loss: 0.9721 - accuracy: 0.55 - ETA: 0s - loss: 0.9635 - accuracy: 0.57 - ETA: 0s - loss: 0.9472 - accuracy: 0.58 - ETA: 0s - loss: 0.9424 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9407 - accuracy: 0.59 - ETA: 0s - loss: 0.9492 - accuracy: 0.58 - ETA: 0s - loss: 0.9404 - accuracy: 0.59 - ETA: 0s - loss: 0.9277 - accuracy: 0.60 - ETA: 0s - loss: 0.9090 - accuracy: 0.62 - ETA: 0s - loss: 0.9213 - accuracy: 0.61 - ETA: 0s - loss: 0.9383 - accuracy: 0.59 - ETA: 0s - loss: 0.9404 - accuracy: 0.59 - ETA: 0s - loss: 0.9455 - accuracy: 0.59 - ETA: 0s - loss: 0.9463 - accuracy: 0.59 - ETA: 0s - loss: 0.9478 - accuracy: 0.5894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00140: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9478 - accuracy: 0.5894 - val_loss: 1.0231 - val_accuracy: 0.4997 - lr: 0.0189\n",
      "Epoch 141/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0062 - accuracy: 0.52 - ETA: 0s - loss: 1.0123 - accuracy: 0.51 - ETA: 0s - loss: 1.0026 - accuracy: 0.53 - ETA: 0s - loss: 0.9721 - accuracy: 0.55 - ETA: 0s - loss: 0.9635 - accuracy: 0.57 - ETA: 0s - loss: 0.9472 - accuracy: 0.58 - ETA: 0s - loss: 0.9424 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9407 - accuracy: 0.59 - ETA: 0s - loss: 0.9492 - accuracy: 0.58 - ETA: 0s - loss: 0.9404 - accuracy: 0.59 - ETA: 0s - loss: 0.9277 - accuracy: 0.60 - ETA: 0s - loss: 0.9090 - accuracy: 0.62 - ETA: 0s - loss: 0.9213 - accuracy: 0.61 - ETA: 0s - loss: 0.9383 - accuracy: 0.59 - ETA: 0s - loss: 0.9404 - accuracy: 0.59 - ETA: 0s - loss: 0.9454 - accuracy: 0.59 - ETA: 0s - loss: 0.9463 - accuracy: 0.59 - ETA: 0s - loss: 0.9477 - accuracy: 0.5894\n",
      "Epoch 00141: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9477 - accuracy: 0.5894 - val_loss: 1.0231 - val_accuracy: 0.4997 - lr: 0.0189\n",
      "Epoch 142/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0061 - accuracy: 0.52 - ETA: 0s - loss: 1.0122 - accuracy: 0.51 - ETA: 0s - loss: 1.0026 - accuracy: 0.53 - ETA: 0s - loss: 0.9721 - accuracy: 0.55 - ETA: 0s - loss: 0.9635 - accuracy: 0.57 - ETA: 0s - loss: 0.9471 - accuracy: 0.58 - ETA: 0s - loss: 0.9424 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9407 - accuracy: 0.59 - ETA: 0s - loss: 0.9492 - accuracy: 0.58 - ETA: 0s - loss: 0.9404 - accuracy: 0.59 - ETA: 0s - loss: 0.9277 - accuracy: 0.60 - ETA: 0s - loss: 0.9090 - accuracy: 0.62 - ETA: 0s - loss: 0.9213 - accuracy: 0.61 - ETA: 0s - loss: 0.9383 - accuracy: 0.59 - ETA: 0s - loss: 0.9403 - accuracy: 0.59 - ETA: 0s - loss: 0.9454 - accuracy: 0.59 - ETA: 0s - loss: 0.9463 - accuracy: 0.59 - ETA: 0s - loss: 0.9477 - accuracy: 0.5894\n",
      "Epoch 00142: val_loss did not improve from 1.01430\n",
      "\n",
      "Epoch 00142: ReduceLROnPlateau reducing learning rate to 0.01509949415922165.\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9477 - accuracy: 0.5894 - val_loss: 1.0231 - val_accuracy: 0.4998 - lr: 0.0189\n",
      "Epoch 143/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0061 - accuracy: 0.52 - ETA: 0s - loss: 1.0123 - accuracy: 0.51 - ETA: 0s - loss: 1.0028 - accuracy: 0.53 - ETA: 0s - loss: 0.9720 - accuracy: 0.55 - ETA: 0s - loss: 0.9633 - accuracy: 0.57 - ETA: 0s - loss: 0.9467 - accuracy: 0.58 - ETA: 0s - loss: 0.9419 - accuracy: 0.59 - ETA: 0s - loss: 0.9411 - accuracy: 0.59 - ETA: 0s - loss: 0.9402 - accuracy: 0.59 - ETA: 0s - loss: 0.9488 - accuracy: 0.58 - ETA: 0s - loss: 0.9400 - accuracy: 0.59 - ETA: 0s - loss: 0.9273 - accuracy: 0.60 - ETA: 0s - loss: 0.9087 - accuracy: 0.62 - ETA: 0s - loss: 0.9208 - accuracy: 0.61 - ETA: 0s - loss: 0.9375 - accuracy: 0.59 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9446 - accuracy: 0.59 - ETA: 0s - loss: 0.9455 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.5894\n",
      "Epoch 00143: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9470 - accuracy: 0.5894 - val_loss: 1.0219 - val_accuracy: 0.4998 - lr: 0.0151\n",
      "Epoch 144/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0056 - accuracy: 0.52 - ETA: 0s - loss: 1.0115 - accuracy: 0.51 - ETA: 0s - loss: 1.0021 - accuracy: 0.53 - ETA: 0s - loss: 0.9715 - accuracy: 0.55 - ETA: 0s - loss: 0.9629 - accuracy: 0.57 - ETA: 0s - loss: 0.9465 - accuracy: 0.58 - ETA: 0s - loss: 0.9417 - accuracy: 0.59 - ETA: 0s - loss: 0.9410 - accuracy: 0.59 - ETA: 0s - loss: 0.9401 - accuracy: 0.59 - ETA: 0s - loss: 0.9487 - accuracy: 0.58 - ETA: 0s - loss: 0.9399 - accuracy: 0.59 - ETA: 0s - loss: 0.9271 - accuracy: 0.60 - ETA: 0s - loss: 0.9085 - accuracy: 0.62 - ETA: 0s - loss: 0.9207 - accuracy: 0.61 - ETA: 0s - loss: 0.9375 - accuracy: 0.59 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9446 - accuracy: 0.59 - ETA: 0s - loss: 0.9455 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.5896\n",
      "Epoch 00144: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9470 - accuracy: 0.5896 - val_loss: 1.0222 - val_accuracy: 0.4998 - lr: 0.0151\n",
      "Epoch 145/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0058 - accuracy: 0.52 - ETA: 0s - loss: 1.0118 - accuracy: 0.51 - ETA: 0s - loss: 1.0023 - accuracy: 0.53 - ETA: 0s - loss: 0.9716 - accuracy: 0.55 - ETA: 0s - loss: 0.9630 - accuracy: 0.57 - ETA: 0s - loss: 0.9465 - accuracy: 0.58 - ETA: 0s - loss: 0.9417 - accuracy: 0.59 - ETA: 0s - loss: 0.9410 - accuracy: 0.59 - ETA: 0s - loss: 0.9401 - accuracy: 0.59 - ETA: 0s - loss: 0.9487 - accuracy: 0.58 - ETA: 0s - loss: 0.9399 - accuracy: 0.59 - ETA: 0s - loss: 0.9271 - accuracy: 0.60 - ETA: 0s - loss: 0.9085 - accuracy: 0.62 - ETA: 0s - loss: 0.9207 - accuracy: 0.61 - ETA: 0s - loss: 0.9375 - accuracy: 0.59 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9446 - accuracy: 0.59 - ETA: 0s - loss: 0.9455 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.5896\n",
      "Epoch 00145: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9470 - accuracy: 0.5896 - val_loss: 1.0221 - val_accuracy: 0.5000 - lr: 0.0151\n",
      "Epoch 146/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0057 - accuracy: 0.52 - ETA: 0s - loss: 1.0116 - accuracy: 0.51 - ETA: 0s - loss: 1.0022 - accuracy: 0.53 - ETA: 0s - loss: 0.9715 - accuracy: 0.55 - ETA: 0s - loss: 0.9629 - accuracy: 0.57 - ETA: 0s - loss: 0.9465 - accuracy: 0.58 - ETA: 0s - loss: 0.9417 - accuracy: 0.59 - ETA: 0s - loss: 0.9410 - accuracy: 0.59 - ETA: 0s - loss: 0.9401 - accuracy: 0.59 - ETA: 0s - loss: 0.9487 - accuracy: 0.58 - ETA: 0s - loss: 0.9399 - accuracy: 0.59 - ETA: 0s - loss: 0.9271 - accuracy: 0.60 - ETA: 0s - loss: 0.9085 - accuracy: 0.62 - ETA: 0s - loss: 0.9207 - accuracy: 0.61 - ETA: 0s - loss: 0.9375 - accuracy: 0.59 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9446 - accuracy: 0.59 - ETA: 0s - loss: 0.9455 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.5896\n",
      "Epoch 00146: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9470 - accuracy: 0.5896 - val_loss: 1.0221 - val_accuracy: 0.5000 - lr: 0.0151\n",
      "Epoch 147/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0057 - accuracy: 0.52 - ETA: 0s - loss: 1.0117 - accuracy: 0.51 - ETA: 0s - loss: 1.0022 - accuracy: 0.53 - ETA: 0s - loss: 0.9715 - accuracy: 0.55 - ETA: 0s - loss: 0.9629 - accuracy: 0.57 - ETA: 0s - loss: 0.9465 - accuracy: 0.58 - ETA: 0s - loss: 0.9417 - accuracy: 0.59 - ETA: 0s - loss: 0.9410 - accuracy: 0.59 - ETA: 0s - loss: 0.9401 - accuracy: 0.59 - ETA: 0s - loss: 0.9487 - accuracy: 0.58 - ETA: 0s - loss: 0.9399 - accuracy: 0.59 - ETA: 0s - loss: 0.9271 - accuracy: 0.60 - ETA: 0s - loss: 0.9085 - accuracy: 0.62 - ETA: 0s - loss: 0.9207 - accuracy: 0.61 - ETA: 0s - loss: 0.9375 - accuracy: 0.59 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9446 - accuracy: 0.59 - ETA: 0s - loss: 0.9455 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.5896\n",
      "Epoch 00147: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9470 - accuracy: 0.5896 - val_loss: 1.0221 - val_accuracy: 0.5000 - lr: 0.0151\n",
      "Epoch 148/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0057 - accuracy: 0.52 - ETA: 0s - loss: 1.0116 - accuracy: 0.51 - ETA: 0s - loss: 1.0022 - accuracy: 0.53 - ETA: 0s - loss: 0.9715 - accuracy: 0.55 - ETA: 0s - loss: 0.9629 - accuracy: 0.57 - ETA: 0s - loss: 0.9465 - accuracy: 0.58 - ETA: 0s - loss: 0.9417 - accuracy: 0.59 - ETA: 0s - loss: 0.9410 - accuracy: 0.59 - ETA: 0s - loss: 0.9401 - accuracy: 0.59 - ETA: 0s - loss: 0.9487 - accuracy: 0.58 - ETA: 0s - loss: 0.9399 - accuracy: 0.59 - ETA: 0s - loss: 0.9271 - accuracy: 0.60 - ETA: 0s - loss: 0.9085 - accuracy: 0.62 - ETA: 0s - loss: 0.9207 - accuracy: 0.61 - ETA: 0s - loss: 0.9375 - accuracy: 0.59 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9446 - accuracy: 0.59 - ETA: 0s - loss: 0.9455 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.5896\n",
      "Epoch 00148: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9470 - accuracy: 0.5896 - val_loss: 1.0221 - val_accuracy: 0.4998 - lr: 0.0151\n",
      "Epoch 149/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0057 - accuracy: 0.52 - ETA: 0s - loss: 1.0116 - accuracy: 0.51 - ETA: 0s - loss: 1.0022 - accuracy: 0.53 - ETA: 0s - loss: 0.9715 - accuracy: 0.55 - ETA: 0s - loss: 0.9629 - accuracy: 0.57 - ETA: 0s - loss: 0.9465 - accuracy: 0.58 - ETA: 0s - loss: 0.9417 - accuracy: 0.59 - ETA: 0s - loss: 0.9410 - accuracy: 0.59 - ETA: 0s - loss: 0.9401 - accuracy: 0.59 - ETA: 0s - loss: 0.9487 - accuracy: 0.58 - ETA: 0s - loss: 0.9399 - accuracy: 0.59 - ETA: 0s - loss: 0.9271 - accuracy: 0.60 - ETA: 0s - loss: 0.9085 - accuracy: 0.62 - ETA: 0s - loss: 0.9207 - accuracy: 0.61 - ETA: 0s - loss: 0.9375 - accuracy: 0.59 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9446 - accuracy: 0.59 - ETA: 0s - loss: 0.9455 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.5896\n",
      "Epoch 00149: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9470 - accuracy: 0.5896 - val_loss: 1.0221 - val_accuracy: 0.4998 - lr: 0.0151\n",
      "Epoch 150/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0057 - accuracy: 0.52 - ETA: 0s - loss: 1.0116 - accuracy: 0.51 - ETA: 0s - loss: 1.0022 - accuracy: 0.53 - ETA: 0s - loss: 0.9715 - accuracy: 0.55 - ETA: 0s - loss: 0.9629 - accuracy: 0.57 - ETA: 0s - loss: 0.9464 - accuracy: 0.58 - ETA: 0s - loss: 0.9417 - accuracy: 0.59 - ETA: 0s - loss: 0.9410 - accuracy: 0.59 - ETA: 0s - loss: 0.9401 - accuracy: 0.59 - ETA: 0s - loss: 0.9487 - accuracy: 0.58 - ETA: 0s - loss: 0.9399 - accuracy: 0.59 - ETA: 0s - loss: 0.9271 - accuracy: 0.60 - ETA: 0s - loss: 0.9085 - accuracy: 0.62 - ETA: 0s - loss: 0.9207 - accuracy: 0.61 - ETA: 0s - loss: 0.9374 - accuracy: 0.59 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9446 - accuracy: 0.59 - ETA: 0s - loss: 0.9455 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.5896\n",
      "Epoch 00150: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9470 - accuracy: 0.5896 - val_loss: 1.0221 - val_accuracy: 0.4998 - lr: 0.0151\n",
      "Epoch 151/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0057 - accuracy: 0.52 - ETA: 0s - loss: 1.0116 - accuracy: 0.51 - ETA: 0s - loss: 1.0022 - accuracy: 0.53 - ETA: 0s - loss: 0.9715 - accuracy: 0.55 - ETA: 0s - loss: 0.9629 - accuracy: 0.57 - ETA: 0s - loss: 0.9464 - accuracy: 0.58 - ETA: 0s - loss: 0.9417 - accuracy: 0.59 - ETA: 0s - loss: 0.9410 - accuracy: 0.59 - ETA: 0s - loss: 0.9401 - accuracy: 0.59 - ETA: 0s - loss: 0.9487 - accuracy: 0.58 - ETA: 0s - loss: 0.9399 - accuracy: 0.59 - ETA: 0s - loss: 0.9271 - accuracy: 0.60 - ETA: 0s - loss: 0.9084 - accuracy: 0.62 - ETA: 0s - loss: 0.9207 - accuracy: 0.61 - ETA: 0s - loss: 0.9374 - accuracy: 0.59 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9446 - accuracy: 0.59 - ETA: 0s - loss: 0.9455 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.5896\n",
      "Epoch 00151: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9469 - accuracy: 0.5896 - val_loss: 1.0221 - val_accuracy: 0.4998 - lr: 0.0151\n",
      "Epoch 152/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0057 - accuracy: 0.52 - ETA: 0s - loss: 1.0116 - accuracy: 0.51 - ETA: 0s - loss: 1.0022 - accuracy: 0.53 - ETA: 0s - loss: 0.9715 - accuracy: 0.55 - ETA: 0s - loss: 0.9629 - accuracy: 0.57 - ETA: 0s - loss: 0.9464 - accuracy: 0.58 - ETA: 0s - loss: 0.9417 - accuracy: 0.59 - ETA: 0s - loss: 0.9409 - accuracy: 0.59 - ETA: 0s - loss: 0.9400 - accuracy: 0.59 - ETA: 0s - loss: 0.9487 - accuracy: 0.58 - ETA: 0s - loss: 0.9398 - accuracy: 0.59 - ETA: 0s - loss: 0.9271 - accuracy: 0.60 - ETA: 0s - loss: 0.9084 - accuracy: 0.62 - ETA: 0s - loss: 0.9207 - accuracy: 0.61 - ETA: 0s - loss: 0.9374 - accuracy: 0.59 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9446 - accuracy: 0.59 - ETA: 0s - loss: 0.9455 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.5896\n",
      "Epoch 00152: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9469 - accuracy: 0.5896 - val_loss: 1.0221 - val_accuracy: 0.4998 - lr: 0.0151\n",
      "Epoch 153/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0057 - accuracy: 0.52 - ETA: 0s - loss: 1.0116 - accuracy: 0.51 - ETA: 0s - loss: 1.0022 - accuracy: 0.53 - ETA: 0s - loss: 0.9715 - accuracy: 0.55 - ETA: 0s - loss: 0.9629 - accuracy: 0.57 - ETA: 0s - loss: 0.9464 - accuracy: 0.58 - ETA: 0s - loss: 0.9417 - accuracy: 0.59 - ETA: 0s - loss: 0.9409 - accuracy: 0.59 - ETA: 0s - loss: 0.9400 - accuracy: 0.59 - ETA: 0s - loss: 0.9487 - accuracy: 0.58 - ETA: 0s - loss: 0.9398 - accuracy: 0.59 - ETA: 0s - loss: 0.9271 - accuracy: 0.60 - ETA: 0s - loss: 0.9084 - accuracy: 0.62 - ETA: 0s - loss: 0.9206 - accuracy: 0.61 - ETA: 0s - loss: 0.9374 - accuracy: 0.59 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9446 - accuracy: 0.59 - ETA: 0s - loss: 0.9455 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.5895\n",
      "Epoch 00153: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9469 - accuracy: 0.5895 - val_loss: 1.0220 - val_accuracy: 0.4998 - lr: 0.0151\n",
      "Epoch 154/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0057 - accuracy: 0.52 - ETA: 0s - loss: 1.0116 - accuracy: 0.51 - ETA: 0s - loss: 1.0022 - accuracy: 0.53 - ETA: 0s - loss: 0.9714 - accuracy: 0.55 - ETA: 0s - loss: 0.9629 - accuracy: 0.57 - ETA: 0s - loss: 0.9464 - accuracy: 0.58 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9409 - accuracy: 0.59 - ETA: 0s - loss: 0.9400 - accuracy: 0.59 - ETA: 0s - loss: 0.9487 - accuracy: 0.58 - ETA: 0s - loss: 0.9398 - accuracy: 0.59 - ETA: 0s - loss: 0.9271 - accuracy: 0.60 - ETA: 0s - loss: 0.9084 - accuracy: 0.62 - ETA: 0s - loss: 0.9206 - accuracy: 0.61 - ETA: 0s - loss: 0.9374 - accuracy: 0.59 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9446 - accuracy: 0.59 - ETA: 0s - loss: 0.9455 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.5895\n",
      "Epoch 00154: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9469 - accuracy: 0.5895 - val_loss: 1.0220 - val_accuracy: 0.4998 - lr: 0.0151\n",
      "Epoch 155/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0057 - accuracy: 0.52 - ETA: 0s - loss: 1.0115 - accuracy: 0.51 - ETA: 0s - loss: 1.0022 - accuracy: 0.53 - ETA: 0s - loss: 0.9714 - accuracy: 0.55 - ETA: 0s - loss: 0.9629 - accuracy: 0.57 - ETA: 0s - loss: 0.9464 - accuracy: 0.58 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9409 - accuracy: 0.59 - ETA: 0s - loss: 0.9400 - accuracy: 0.59 - ETA: 0s - loss: 0.9487 - accuracy: 0.58 - ETA: 0s - loss: 0.9398 - accuracy: 0.59 - ETA: 0s - loss: 0.9271 - accuracy: 0.60 - ETA: 0s - loss: 0.9084 - accuracy: 0.62 - ETA: 0s - loss: 0.9206 - accuracy: 0.61 - ETA: 0s - loss: 0.9374 - accuracy: 0.59 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9446 - accuracy: 0.59 - ETA: 0s - loss: 0.9455 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.5895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00155: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9469 - accuracy: 0.5895 - val_loss: 1.0220 - val_accuracy: 0.4998 - lr: 0.0151\n",
      "Epoch 156/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0057 - accuracy: 0.52 - ETA: 0s - loss: 1.0115 - accuracy: 0.51 - ETA: 0s - loss: 1.0022 - accuracy: 0.53 - ETA: 0s - loss: 0.9714 - accuracy: 0.55 - ETA: 0s - loss: 0.9628 - accuracy: 0.57 - ETA: 0s - loss: 0.9464 - accuracy: 0.58 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9409 - accuracy: 0.59 - ETA: 0s - loss: 0.9400 - accuracy: 0.59 - ETA: 0s - loss: 0.9487 - accuracy: 0.58 - ETA: 0s - loss: 0.9398 - accuracy: 0.59 - ETA: 0s - loss: 0.9271 - accuracy: 0.60 - ETA: 0s - loss: 0.9084 - accuracy: 0.62 - ETA: 0s - loss: 0.9206 - accuracy: 0.61 - ETA: 0s - loss: 0.9374 - accuracy: 0.59 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9446 - accuracy: 0.59 - ETA: 0s - loss: 0.9455 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.5895\n",
      "Epoch 00156: val_loss did not improve from 1.01430\n",
      "\n",
      "Epoch 00156: ReduceLROnPlateau reducing learning rate to 0.012079595029354096.\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9469 - accuracy: 0.5895 - val_loss: 1.0220 - val_accuracy: 0.4997 - lr: 0.0151\n",
      "Epoch 157/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0057 - accuracy: 0.52 - ETA: 0s - loss: 1.0116 - accuracy: 0.51 - ETA: 0s - loss: 1.0023 - accuracy: 0.53 - ETA: 0s - loss: 0.9713 - accuracy: 0.55 - ETA: 0s - loss: 0.9627 - accuracy: 0.57 - ETA: 0s - loss: 0.9461 - accuracy: 0.58 - ETA: 0s - loss: 0.9413 - accuracy: 0.59 - ETA: 0s - loss: 0.9406 - accuracy: 0.59 - ETA: 0s - loss: 0.9397 - accuracy: 0.59 - ETA: 0s - loss: 0.9484 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9267 - accuracy: 0.60 - ETA: 0s - loss: 0.9081 - accuracy: 0.62 - ETA: 0s - loss: 0.9202 - accuracy: 0.61 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9439 - accuracy: 0.59 - ETA: 0s - loss: 0.9449 - accuracy: 0.59 - ETA: 0s - loss: 0.9463 - accuracy: 0.5895\n",
      "Epoch 00157: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9463 - accuracy: 0.5895 - val_loss: 1.0211 - val_accuracy: 0.4997 - lr: 0.0121\n",
      "Epoch 158/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0053 - accuracy: 0.52 - ETA: 0s - loss: 1.0110 - accuracy: 0.51 - ETA: 0s - loss: 1.0018 - accuracy: 0.53 - ETA: 0s - loss: 0.9710 - accuracy: 0.55 - ETA: 0s - loss: 0.9625 - accuracy: 0.57 - ETA: 0s - loss: 0.9459 - accuracy: 0.58 - ETA: 0s - loss: 0.9412 - accuracy: 0.59 - ETA: 0s - loss: 0.9405 - accuracy: 0.59 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9483 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9267 - accuracy: 0.60 - ETA: 0s - loss: 0.9080 - accuracy: 0.62 - ETA: 0s - loss: 0.9202 - accuracy: 0.61 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9439 - accuracy: 0.59 - ETA: 0s - loss: 0.9449 - accuracy: 0.59 - ETA: 0s - loss: 0.9464 - accuracy: 0.5895\n",
      "Epoch 00158: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9464 - accuracy: 0.5895 - val_loss: 1.0214 - val_accuracy: 0.4997 - lr: 0.0121\n",
      "Epoch 159/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0054 - accuracy: 0.52 - ETA: 0s - loss: 1.0112 - accuracy: 0.51 - ETA: 0s - loss: 1.0020 - accuracy: 0.53 - ETA: 0s - loss: 0.9711 - accuracy: 0.55 - ETA: 0s - loss: 0.9625 - accuracy: 0.57 - ETA: 0s - loss: 0.9459 - accuracy: 0.58 - ETA: 0s - loss: 0.9412 - accuracy: 0.59 - ETA: 0s - loss: 0.9405 - accuracy: 0.59 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9483 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9266 - accuracy: 0.60 - ETA: 0s - loss: 0.9080 - accuracy: 0.62 - ETA: 0s - loss: 0.9202 - accuracy: 0.61 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9439 - accuracy: 0.59 - ETA: 0s - loss: 0.9449 - accuracy: 0.59 - ETA: 0s - loss: 0.9463 - accuracy: 0.5895\n",
      "Epoch 00159: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9463 - accuracy: 0.5895 - val_loss: 1.0213 - val_accuracy: 0.4997 - lr: 0.0121\n",
      "Epoch 160/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0054 - accuracy: 0.52 - ETA: 0s - loss: 1.0111 - accuracy: 0.51 - ETA: 0s - loss: 1.0019 - accuracy: 0.53 - ETA: 0s - loss: 0.9710 - accuracy: 0.55 - ETA: 0s - loss: 0.9625 - accuracy: 0.57 - ETA: 0s - loss: 0.9459 - accuracy: 0.58 - ETA: 0s - loss: 0.9412 - accuracy: 0.59 - ETA: 0s - loss: 0.9405 - accuracy: 0.59 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9483 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9267 - accuracy: 0.60 - ETA: 0s - loss: 0.9080 - accuracy: 0.62 - ETA: 0s - loss: 0.9202 - accuracy: 0.61 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9439 - accuracy: 0.59 - ETA: 0s - loss: 0.9449 - accuracy: 0.59 - ETA: 0s - loss: 0.9464 - accuracy: 0.5895\n",
      "Epoch 00160: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9464 - accuracy: 0.5895 - val_loss: 1.0213 - val_accuracy: 0.4997 - lr: 0.0121\n",
      "Epoch 161/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0054 - accuracy: 0.52 - ETA: 0s - loss: 1.0111 - accuracy: 0.51 - ETA: 0s - loss: 1.0019 - accuracy: 0.53 - ETA: 0s - loss: 0.9710 - accuracy: 0.55 - ETA: 0s - loss: 0.9625 - accuracy: 0.57 - ETA: 0s - loss: 0.9459 - accuracy: 0.58 - ETA: 0s - loss: 0.9411 - accuracy: 0.59 - ETA: 0s - loss: 0.9405 - accuracy: 0.59 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9483 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9266 - accuracy: 0.60 - ETA: 0s - loss: 0.9080 - accuracy: 0.62 - ETA: 0s - loss: 0.9202 - accuracy: 0.61 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9439 - accuracy: 0.59 - ETA: 0s - loss: 0.9449 - accuracy: 0.59 - ETA: 0s - loss: 0.9464 - accuracy: 0.5895\n",
      "Epoch 00161: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9464 - accuracy: 0.5895 - val_loss: 1.0213 - val_accuracy: 0.4997 - lr: 0.0121\n",
      "Epoch 162/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0054 - accuracy: 0.52 - ETA: 0s - loss: 1.0111 - accuracy: 0.51 - ETA: 0s - loss: 1.0019 - accuracy: 0.53 - ETA: 0s - loss: 0.9710 - accuracy: 0.55 - ETA: 0s - loss: 0.9625 - accuracy: 0.57 - ETA: 0s - loss: 0.9459 - accuracy: 0.58 - ETA: 0s - loss: 0.9411 - accuracy: 0.59 - ETA: 0s - loss: 0.9405 - accuracy: 0.59 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9483 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9266 - accuracy: 0.60 - ETA: 0s - loss: 0.9080 - accuracy: 0.62 - ETA: 0s - loss: 0.9202 - accuracy: 0.61 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9439 - accuracy: 0.59 - ETA: 0s - loss: 0.9449 - accuracy: 0.59 - ETA: 0s - loss: 0.9463 - accuracy: 0.5895\n",
      "Epoch 00162: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9463 - accuracy: 0.5895 - val_loss: 1.0213 - val_accuracy: 0.4997 - lr: 0.0121\n",
      "Epoch 163/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0054 - accuracy: 0.52 - ETA: 0s - loss: 1.0111 - accuracy: 0.51 - ETA: 0s - loss: 1.0019 - accuracy: 0.53 - ETA: 0s - loss: 0.9710 - accuracy: 0.55 - ETA: 0s - loss: 0.9624 - accuracy: 0.57 - ETA: 0s - loss: 0.9459 - accuracy: 0.58 - ETA: 0s - loss: 0.9411 - accuracy: 0.59 - ETA: 0s - loss: 0.9405 - accuracy: 0.59 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9483 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9266 - accuracy: 0.60 - ETA: 0s - loss: 0.9080 - accuracy: 0.62 - ETA: 0s - loss: 0.9202 - accuracy: 0.61 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9439 - accuracy: 0.59 - ETA: 0s - loss: 0.9449 - accuracy: 0.59 - ETA: 0s - loss: 0.9463 - accuracy: 0.5895\n",
      "Epoch 00163: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9463 - accuracy: 0.5895 - val_loss: 1.0213 - val_accuracy: 0.4997 - lr: 0.0121\n",
      "Epoch 164/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0054 - accuracy: 0.52 - ETA: 0s - loss: 1.0111 - accuracy: 0.51 - ETA: 0s - loss: 1.0019 - accuracy: 0.53 - ETA: 0s - loss: 0.9710 - accuracy: 0.55 - ETA: 0s - loss: 0.9624 - accuracy: 0.57 - ETA: 0s - loss: 0.9459 - accuracy: 0.58 - ETA: 0s - loss: 0.9411 - accuracy: 0.59 - ETA: 0s - loss: 0.9405 - accuracy: 0.59 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9483 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9266 - accuracy: 0.60 - ETA: 0s - loss: 0.9080 - accuracy: 0.62 - ETA: 0s - loss: 0.9202 - accuracy: 0.61 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9439 - accuracy: 0.59 - ETA: 0s - loss: 0.9449 - accuracy: 0.59 - ETA: 0s - loss: 0.9463 - accuracy: 0.5894\n",
      "Epoch 00164: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9463 - accuracy: 0.5894 - val_loss: 1.0213 - val_accuracy: 0.4997 - lr: 0.0121\n",
      "Epoch 165/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0054 - accuracy: 0.52 - ETA: 0s - loss: 1.0111 - accuracy: 0.51 - ETA: 0s - loss: 1.0019 - accuracy: 0.53 - ETA: 0s - loss: 0.9710 - accuracy: 0.55 - ETA: 0s - loss: 0.9624 - accuracy: 0.57 - ETA: 0s - loss: 0.9459 - accuracy: 0.58 - ETA: 0s - loss: 0.9411 - accuracy: 0.59 - ETA: 0s - loss: 0.9405 - accuracy: 0.59 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9483 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9266 - accuracy: 0.60 - ETA: 0s - loss: 0.9080 - accuracy: 0.62 - ETA: 0s - loss: 0.9202 - accuracy: 0.61 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9439 - accuracy: 0.59 - ETA: 0s - loss: 0.9449 - accuracy: 0.59 - ETA: 0s - loss: 0.9463 - accuracy: 0.5894\n",
      "Epoch 00165: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9463 - accuracy: 0.5894 - val_loss: 1.0212 - val_accuracy: 0.4997 - lr: 0.0121\n",
      "Epoch 166/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0054 - accuracy: 0.52 - ETA: 0s - loss: 1.0111 - accuracy: 0.51 - ETA: 0s - loss: 1.0019 - accuracy: 0.53 - ETA: 0s - loss: 0.9710 - accuracy: 0.55 - ETA: 0s - loss: 0.9624 - accuracy: 0.57 - ETA: 0s - loss: 0.9459 - accuracy: 0.58 - ETA: 0s - loss: 0.9411 - accuracy: 0.59 - ETA: 0s - loss: 0.9405 - accuracy: 0.59 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9483 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9266 - accuracy: 0.60 - ETA: 0s - loss: 0.9080 - accuracy: 0.62 - ETA: 0s - loss: 0.9202 - accuracy: 0.61 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9439 - accuracy: 0.59 - ETA: 0s - loss: 0.9449 - accuracy: 0.59 - ETA: 0s - loss: 0.9463 - accuracy: 0.5894\n",
      "Epoch 00166: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9463 - accuracy: 0.5894 - val_loss: 1.0212 - val_accuracy: 0.4997 - lr: 0.0121\n",
      "Epoch 167/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0054 - accuracy: 0.52 - ETA: 0s - loss: 1.0110 - accuracy: 0.51 - ETA: 0s - loss: 1.0019 - accuracy: 0.53 - ETA: 0s - loss: 0.9710 - accuracy: 0.55 - ETA: 0s - loss: 0.9624 - accuracy: 0.57 - ETA: 0s - loss: 0.9459 - accuracy: 0.58 - ETA: 0s - loss: 0.9411 - accuracy: 0.59 - ETA: 0s - loss: 0.9405 - accuracy: 0.59 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9483 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9266 - accuracy: 0.60 - ETA: 0s - loss: 0.9080 - accuracy: 0.62 - ETA: 0s - loss: 0.9201 - accuracy: 0.61 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9439 - accuracy: 0.59 - ETA: 0s - loss: 0.9449 - accuracy: 0.59 - ETA: 0s - loss: 0.9463 - accuracy: 0.5894\n",
      "Epoch 00167: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9463 - accuracy: 0.5894 - val_loss: 1.0212 - val_accuracy: 0.4997 - lr: 0.0121\n",
      "Epoch 168/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0054 - accuracy: 0.52 - ETA: 0s - loss: 1.0110 - accuracy: 0.51 - ETA: 0s - loss: 1.0019 - accuracy: 0.53 - ETA: 0s - loss: 0.9710 - accuracy: 0.55 - ETA: 0s - loss: 0.9624 - accuracy: 0.57 - ETA: 0s - loss: 0.9459 - accuracy: 0.58 - ETA: 0s - loss: 0.9411 - accuracy: 0.59 - ETA: 0s - loss: 0.9405 - accuracy: 0.59 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9483 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9266 - accuracy: 0.60 - ETA: 0s - loss: 0.9080 - accuracy: 0.62 - ETA: 0s - loss: 0.9201 - accuracy: 0.61 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9439 - accuracy: 0.59 - ETA: 0s - loss: 0.9449 - accuracy: 0.59 - ETA: 0s - loss: 0.9463 - accuracy: 0.5894\n",
      "Epoch 00168: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9463 - accuracy: 0.5894 - val_loss: 1.0212 - val_accuracy: 0.4997 - lr: 0.0121\n",
      "Epoch 169/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0054 - accuracy: 0.52 - ETA: 0s - loss: 1.0110 - accuracy: 0.51 - ETA: 0s - loss: 1.0019 - accuracy: 0.53 - ETA: 0s - loss: 0.9710 - accuracy: 0.55 - ETA: 0s - loss: 0.9624 - accuracy: 0.57 - ETA: 0s - loss: 0.9459 - accuracy: 0.58 - ETA: 0s - loss: 0.9411 - accuracy: 0.59 - ETA: 0s - loss: 0.9405 - accuracy: 0.59 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9483 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9266 - accuracy: 0.60 - ETA: 0s - loss: 0.9080 - accuracy: 0.62 - ETA: 0s - loss: 0.9201 - accuracy: 0.61 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9439 - accuracy: 0.59 - ETA: 0s - loss: 0.9449 - accuracy: 0.59 - ETA: 0s - loss: 0.9463 - accuracy: 0.5894\n",
      "Epoch 00169: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9463 - accuracy: 0.5894 - val_loss: 1.0212 - val_accuracy: 0.4997 - lr: 0.0121\n",
      "Epoch 170/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0054 - accuracy: 0.52 - ETA: 0s - loss: 1.0110 - accuracy: 0.51 - ETA: 0s - loss: 1.0019 - accuracy: 0.53 - ETA: 0s - loss: 0.9710 - accuracy: 0.55 - ETA: 0s - loss: 0.9624 - accuracy: 0.57 - ETA: 0s - loss: 0.9459 - accuracy: 0.58 - ETA: 0s - loss: 0.9411 - accuracy: 0.59 - ETA: 0s - loss: 0.9405 - accuracy: 0.59 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9482 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9266 - accuracy: 0.60 - ETA: 0s - loss: 0.9080 - accuracy: 0.62 - ETA: 0s - loss: 0.9201 - accuracy: 0.61 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9439 - accuracy: 0.59 - ETA: 0s - loss: 0.9449 - accuracy: 0.59 - ETA: 0s - loss: 0.9463 - accuracy: 0.5894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00170: val_loss did not improve from 1.01430\n",
      "\n",
      "Epoch 00170: ReduceLROnPlateau reducing learning rate to 0.009663675725460053.\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9463 - accuracy: 0.5894 - val_loss: 1.0212 - val_accuracy: 0.4997 - lr: 0.0121\n",
      "Epoch 171/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0054 - accuracy: 0.52 - ETA: 0s - loss: 1.0111 - accuracy: 0.51 - ETA: 0s - loss: 1.0020 - accuracy: 0.53 - ETA: 0s - loss: 0.9709 - accuracy: 0.55 - ETA: 0s - loss: 0.9623 - accuracy: 0.57 - ETA: 0s - loss: 0.9456 - accuracy: 0.58 - ETA: 0s - loss: 0.9408 - accuracy: 0.59 - ETA: 0s - loss: 0.9402 - accuracy: 0.59 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9480 - accuracy: 0.58 - ETA: 0s - loss: 0.9392 - accuracy: 0.59 - ETA: 0s - loss: 0.9263 - accuracy: 0.60 - ETA: 0s - loss: 0.9077 - accuracy: 0.62 - ETA: 0s - loss: 0.9198 - accuracy: 0.61 - ETA: 0s - loss: 0.9363 - accuracy: 0.59 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9434 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.59 - ETA: 0s - loss: 0.9459 - accuracy: 0.5894\n",
      "Epoch 00171: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9459 - accuracy: 0.5894 - val_loss: 1.0205 - val_accuracy: 0.4998 - lr: 0.0097\n",
      "Epoch 172/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0050 - accuracy: 0.52 - ETA: 0s - loss: 1.0106 - accuracy: 0.51 - ETA: 0s - loss: 1.0016 - accuracy: 0.53 - ETA: 0s - loss: 0.9707 - accuracy: 0.55 - ETA: 0s - loss: 0.9621 - accuracy: 0.57 - ETA: 0s - loss: 0.9455 - accuracy: 0.58 - ETA: 0s - loss: 0.9408 - accuracy: 0.59 - ETA: 0s - loss: 0.9401 - accuracy: 0.59 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9480 - accuracy: 0.58 - ETA: 0s - loss: 0.9392 - accuracy: 0.59 - ETA: 0s - loss: 0.9263 - accuracy: 0.60 - ETA: 0s - loss: 0.9077 - accuracy: 0.62 - ETA: 0s - loss: 0.9198 - accuracy: 0.61 - ETA: 0s - loss: 0.9363 - accuracy: 0.59 - ETA: 0s - loss: 0.9385 - accuracy: 0.59 - ETA: 0s - loss: 0.9434 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.59 - ETA: 0s - loss: 0.9459 - accuracy: 0.5894\n",
      "Epoch 00172: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9459 - accuracy: 0.5894 - val_loss: 1.0207 - val_accuracy: 0.4998 - lr: 0.0097\n",
      "Epoch 173/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0051 - accuracy: 0.52 - ETA: 0s - loss: 1.0107 - accuracy: 0.51 - ETA: 0s - loss: 1.0017 - accuracy: 0.53 - ETA: 0s - loss: 0.9707 - accuracy: 0.55 - ETA: 0s - loss: 0.9621 - accuracy: 0.57 - ETA: 0s - loss: 0.9455 - accuracy: 0.58 - ETA: 0s - loss: 0.9408 - accuracy: 0.59 - ETA: 0s - loss: 0.9401 - accuracy: 0.59 - ETA: 0s - loss: 0.9392 - accuracy: 0.59 - ETA: 0s - loss: 0.9480 - accuracy: 0.58 - ETA: 0s - loss: 0.9391 - accuracy: 0.59 - ETA: 0s - loss: 0.9263 - accuracy: 0.60 - ETA: 0s - loss: 0.9076 - accuracy: 0.62 - ETA: 0s - loss: 0.9198 - accuracy: 0.61 - ETA: 0s - loss: 0.9363 - accuracy: 0.59 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9434 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.59 - ETA: 0s - loss: 0.9459 - accuracy: 0.5894\n",
      "Epoch 00173: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9459 - accuracy: 0.5894 - val_loss: 1.0207 - val_accuracy: 0.4998 - lr: 0.0097\n",
      "Epoch 174/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0051 - accuracy: 0.52 - ETA: 0s - loss: 1.0107 - accuracy: 0.51 - ETA: 0s - loss: 1.0017 - accuracy: 0.53 - ETA: 0s - loss: 0.9707 - accuracy: 0.55 - ETA: 0s - loss: 0.9621 - accuracy: 0.57 - ETA: 0s - loss: 0.9455 - accuracy: 0.58 - ETA: 0s - loss: 0.9408 - accuracy: 0.59 - ETA: 0s - loss: 0.9401 - accuracy: 0.59 - ETA: 0s - loss: 0.9392 - accuracy: 0.59 - ETA: 0s - loss: 0.9480 - accuracy: 0.58 - ETA: 0s - loss: 0.9391 - accuracy: 0.59 - ETA: 0s - loss: 0.9263 - accuracy: 0.60 - ETA: 0s - loss: 0.9076 - accuracy: 0.62 - ETA: 0s - loss: 0.9198 - accuracy: 0.61 - ETA: 0s - loss: 0.9363 - accuracy: 0.59 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9434 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.59 - ETA: 0s - loss: 0.9459 - accuracy: 0.5894\n",
      "Epoch 00174: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9459 - accuracy: 0.5894 - val_loss: 1.0206 - val_accuracy: 0.4998 - lr: 0.0097\n",
      "Epoch 175/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0051 - accuracy: 0.52 - ETA: 0s - loss: 1.0107 - accuracy: 0.51 - ETA: 0s - loss: 1.0017 - accuracy: 0.53 - ETA: 0s - loss: 0.9707 - accuracy: 0.55 - ETA: 0s - loss: 0.9621 - accuracy: 0.57 - ETA: 0s - loss: 0.9455 - accuracy: 0.58 - ETA: 0s - loss: 0.9407 - accuracy: 0.59 - ETA: 0s - loss: 0.9401 - accuracy: 0.59 - ETA: 0s - loss: 0.9392 - accuracy: 0.59 - ETA: 0s - loss: 0.9480 - accuracy: 0.58 - ETA: 0s - loss: 0.9391 - accuracy: 0.59 - ETA: 0s - loss: 0.9263 - accuracy: 0.60 - ETA: 0s - loss: 0.9076 - accuracy: 0.62 - ETA: 0s - loss: 0.9198 - accuracy: 0.61 - ETA: 0s - loss: 0.9363 - accuracy: 0.59 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9434 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.59 - ETA: 0s - loss: 0.9459 - accuracy: 0.5894\n",
      "Epoch 00175: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9459 - accuracy: 0.5894 - val_loss: 1.0206 - val_accuracy: 0.4998 - lr: 0.0097\n",
      "Epoch 176/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0051 - accuracy: 0.52 - ETA: 0s - loss: 1.0107 - accuracy: 0.51 - ETA: 0s - loss: 1.0017 - accuracy: 0.53 - ETA: 0s - loss: 0.9707 - accuracy: 0.55 - ETA: 0s - loss: 0.9621 - accuracy: 0.57 - ETA: 0s - loss: 0.9455 - accuracy: 0.58 - ETA: 0s - loss: 0.9407 - accuracy: 0.59 - ETA: 0s - loss: 0.9401 - accuracy: 0.59 - ETA: 0s - loss: 0.9392 - accuracy: 0.59 - ETA: 0s - loss: 0.9480 - accuracy: 0.58 - ETA: 0s - loss: 0.9391 - accuracy: 0.59 - ETA: 0s - loss: 0.9263 - accuracy: 0.60 - ETA: 0s - loss: 0.9076 - accuracy: 0.62 - ETA: 0s - loss: 0.9198 - accuracy: 0.61 - ETA: 0s - loss: 0.9363 - accuracy: 0.59 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9434 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.59 - ETA: 0s - loss: 0.9459 - accuracy: 0.5894\n",
      "Epoch 00176: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9459 - accuracy: 0.5894 - val_loss: 1.0206 - val_accuracy: 0.4998 - lr: 0.0097\n",
      "Epoch 177/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0051 - accuracy: 0.52 - ETA: 0s - loss: 1.0107 - accuracy: 0.51 - ETA: 0s - loss: 1.0017 - accuracy: 0.53 - ETA: 0s - loss: 0.9707 - accuracy: 0.55 - ETA: 0s - loss: 0.9621 - accuracy: 0.57 - ETA: 0s - loss: 0.9455 - accuracy: 0.58 - ETA: 0s - loss: 0.9407 - accuracy: 0.59 - ETA: 0s - loss: 0.9401 - accuracy: 0.59 - ETA: 0s - loss: 0.9392 - accuracy: 0.59 - ETA: 0s - loss: 0.9480 - accuracy: 0.58 - ETA: 0s - loss: 0.9391 - accuracy: 0.59 - ETA: 0s - loss: 0.9263 - accuracy: 0.60 - ETA: 0s - loss: 0.9076 - accuracy: 0.62 - ETA: 0s - loss: 0.9198 - accuracy: 0.61 - ETA: 0s - loss: 0.9363 - accuracy: 0.59 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9434 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.59 - ETA: 0s - loss: 0.9459 - accuracy: 0.5894\n",
      "Epoch 00177: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9459 - accuracy: 0.5894 - val_loss: 1.0206 - val_accuracy: 0.4998 - lr: 0.0097\n",
      "Epoch 178/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0051 - accuracy: 0.52 - ETA: 0s - loss: 1.0107 - accuracy: 0.51 - ETA: 0s - loss: 1.0017 - accuracy: 0.53 - ETA: 0s - loss: 0.9706 - accuracy: 0.55 - ETA: 0s - loss: 0.9621 - accuracy: 0.57 - ETA: 0s - loss: 0.9455 - accuracy: 0.58 - ETA: 0s - loss: 0.9407 - accuracy: 0.59 - ETA: 0s - loss: 0.9401 - accuracy: 0.59 - ETA: 0s - loss: 0.9392 - accuracy: 0.59 - ETA: 0s - loss: 0.9480 - accuracy: 0.58 - ETA: 0s - loss: 0.9391 - accuracy: 0.59 - ETA: 0s - loss: 0.9263 - accuracy: 0.60 - ETA: 0s - loss: 0.9076 - accuracy: 0.62 - ETA: 0s - loss: 0.9198 - accuracy: 0.61 - ETA: 0s - loss: 0.9363 - accuracy: 0.59 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9434 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.59 - ETA: 0s - loss: 0.9459 - accuracy: 0.5894\n",
      "Epoch 00178: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9459 - accuracy: 0.5894 - val_loss: 1.0206 - val_accuracy: 0.4998 - lr: 0.0097\n",
      "Epoch 179/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0051 - accuracy: 0.52 - ETA: 0s - loss: 1.0107 - accuracy: 0.51 - ETA: 0s - loss: 1.0017 - accuracy: 0.53 - ETA: 0s - loss: 0.9706 - accuracy: 0.55 - ETA: 0s - loss: 0.9621 - accuracy: 0.57 - ETA: 0s - loss: 0.9455 - accuracy: 0.58 - ETA: 0s - loss: 0.9407 - accuracy: 0.59 - ETA: 0s - loss: 0.9401 - accuracy: 0.59 - ETA: 0s - loss: 0.9392 - accuracy: 0.59 - ETA: 0s - loss: 0.9480 - accuracy: 0.58 - ETA: 0s - loss: 0.9391 - accuracy: 0.59 - ETA: 0s - loss: 0.9263 - accuracy: 0.60 - ETA: 0s - loss: 0.9076 - accuracy: 0.62 - ETA: 0s - loss: 0.9198 - accuracy: 0.61 - ETA: 0s - loss: 0.9363 - accuracy: 0.59 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9434 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.59 - ETA: 0s - loss: 0.9459 - accuracy: 0.5894\n",
      "Epoch 00179: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9459 - accuracy: 0.5894 - val_loss: 1.0206 - val_accuracy: 0.4998 - lr: 0.0097\n",
      "Epoch 180/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0051 - accuracy: 0.52 - ETA: 0s - loss: 1.0107 - accuracy: 0.51 - ETA: 0s - loss: 1.0017 - accuracy: 0.53 - ETA: 0s - loss: 0.9706 - accuracy: 0.55 - ETA: 0s - loss: 0.9621 - accuracy: 0.57 - ETA: 0s - loss: 0.9455 - accuracy: 0.58 - ETA: 0s - loss: 0.9407 - accuracy: 0.59 - ETA: 0s - loss: 0.9401 - accuracy: 0.59 - ETA: 0s - loss: 0.9392 - accuracy: 0.59 - ETA: 0s - loss: 0.9479 - accuracy: 0.58 - ETA: 0s - loss: 0.9391 - accuracy: 0.59 - ETA: 0s - loss: 0.9263 - accuracy: 0.60 - ETA: 0s - loss: 0.9076 - accuracy: 0.62 - ETA: 0s - loss: 0.9198 - accuracy: 0.61 - ETA: 0s - loss: 0.9363 - accuracy: 0.59 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9434 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.59 - ETA: 0s - loss: 0.9459 - accuracy: 0.5894\n",
      "Epoch 00180: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9459 - accuracy: 0.5894 - val_loss: 1.0206 - val_accuracy: 0.4998 - lr: 0.0097\n",
      "Epoch 181/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0051 - accuracy: 0.52 - ETA: 0s - loss: 1.0107 - accuracy: 0.51 - ETA: 0s - loss: 1.0017 - accuracy: 0.53 - ETA: 0s - loss: 0.9706 - accuracy: 0.55 - ETA: 0s - loss: 0.9621 - accuracy: 0.57 - ETA: 0s - loss: 0.9455 - accuracy: 0.58 - ETA: 0s - loss: 0.9407 - accuracy: 0.59 - ETA: 0s - loss: 0.9401 - accuracy: 0.59 - ETA: 0s - loss: 0.9392 - accuracy: 0.59 - ETA: 0s - loss: 0.9479 - accuracy: 0.58 - ETA: 0s - loss: 0.9391 - accuracy: 0.59 - ETA: 0s - loss: 0.9263 - accuracy: 0.60 - ETA: 0s - loss: 0.9076 - accuracy: 0.62 - ETA: 0s - loss: 0.9198 - accuracy: 0.61 - ETA: 0s - loss: 0.9363 - accuracy: 0.59 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9434 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.59 - ETA: 0s - loss: 0.9459 - accuracy: 0.5894\n",
      "Epoch 00181: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9459 - accuracy: 0.5894 - val_loss: 1.0206 - val_accuracy: 0.4998 - lr: 0.0097\n",
      "Epoch 182/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0051 - accuracy: 0.52 - ETA: 0s - loss: 1.0107 - accuracy: 0.51 - ETA: 0s - loss: 1.0017 - accuracy: 0.53 - ETA: 0s - loss: 0.9706 - accuracy: 0.55 - ETA: 0s - loss: 0.9621 - accuracy: 0.57 - ETA: 0s - loss: 0.9455 - accuracy: 0.58 - ETA: 0s - loss: 0.9407 - accuracy: 0.59 - ETA: 0s - loss: 0.9401 - accuracy: 0.59 - ETA: 0s - loss: 0.9392 - accuracy: 0.59 - ETA: 0s - loss: 0.9479 - accuracy: 0.58 - ETA: 0s - loss: 0.9391 - accuracy: 0.59 - ETA: 0s - loss: 0.9263 - accuracy: 0.60 - ETA: 0s - loss: 0.9076 - accuracy: 0.62 - ETA: 0s - loss: 0.9198 - accuracy: 0.61 - ETA: 0s - loss: 0.9363 - accuracy: 0.59 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9434 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.59 - ETA: 0s - loss: 0.9459 - accuracy: 0.5894\n",
      "Epoch 00182: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9459 - accuracy: 0.5894 - val_loss: 1.0206 - val_accuracy: 0.4998 - lr: 0.0097\n",
      "Epoch 183/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0051 - accuracy: 0.52 - ETA: 0s - loss: 1.0107 - accuracy: 0.51 - ETA: 0s - loss: 1.0017 - accuracy: 0.53 - ETA: 0s - loss: 0.9706 - accuracy: 0.55 - ETA: 0s - loss: 0.9621 - accuracy: 0.57 - ETA: 0s - loss: 0.9455 - accuracy: 0.58 - ETA: 0s - loss: 0.9407 - accuracy: 0.59 - ETA: 0s - loss: 0.9401 - accuracy: 0.59 - ETA: 0s - loss: 0.9392 - accuracy: 0.59 - ETA: 0s - loss: 0.9479 - accuracy: 0.58 - ETA: 0s - loss: 0.9391 - accuracy: 0.59 - ETA: 0s - loss: 0.9263 - accuracy: 0.60 - ETA: 0s - loss: 0.9076 - accuracy: 0.62 - ETA: 0s - loss: 0.9197 - accuracy: 0.61 - ETA: 0s - loss: 0.9363 - accuracy: 0.59 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9434 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.59 - ETA: 0s - loss: 0.9459 - accuracy: 0.5894\n",
      "Epoch 00183: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9459 - accuracy: 0.5894 - val_loss: 1.0206 - val_accuracy: 0.4998 - lr: 0.0097\n",
      "Epoch 184/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0051 - accuracy: 0.52 - ETA: 0s - loss: 1.0106 - accuracy: 0.51 - ETA: 0s - loss: 1.0017 - accuracy: 0.53 - ETA: 0s - loss: 0.9706 - accuracy: 0.55 - ETA: 0s - loss: 0.9621 - accuracy: 0.57 - ETA: 0s - loss: 0.9455 - accuracy: 0.58 - ETA: 0s - loss: 0.9407 - accuracy: 0.59 - ETA: 0s - loss: 0.9401 - accuracy: 0.59 - ETA: 0s - loss: 0.9392 - accuracy: 0.59 - ETA: 0s - loss: 0.9479 - accuracy: 0.58 - ETA: 0s - loss: 0.9391 - accuracy: 0.59 - ETA: 0s - loss: 0.9263 - accuracy: 0.60 - ETA: 0s - loss: 0.9076 - accuracy: 0.62 - ETA: 0s - loss: 0.9197 - accuracy: 0.61 - ETA: 0s - loss: 0.9363 - accuracy: 0.59 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9434 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.59 - ETA: 0s - loss: 0.9459 - accuracy: 0.5894\n",
      "Epoch 00184: val_loss did not improve from 1.01430\n",
      "\n",
      "Epoch 00184: ReduceLROnPlateau reducing learning rate to 0.007730940729379654.\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9459 - accuracy: 0.5894 - val_loss: 1.0206 - val_accuracy: 0.4998 - lr: 0.0097\n",
      "Epoch 185/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0051 - accuracy: 0.52 - ETA: 0s - loss: 1.0107 - accuracy: 0.51 - ETA: 0s - loss: 1.0018 - accuracy: 0.53 - ETA: 0s - loss: 0.9706 - accuracy: 0.55 - ETA: 0s - loss: 0.9620 - accuracy: 0.57 - ETA: 0s - loss: 0.9453 - accuracy: 0.58 - ETA: 0s - loss: 0.9405 - accuracy: 0.59 - ETA: 0s - loss: 0.9399 - accuracy: 0.59 - ETA: 0s - loss: 0.9390 - accuracy: 0.59 - ETA: 0s - loss: 0.9478 - accuracy: 0.58 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9260 - accuracy: 0.60 - ETA: 0s - loss: 0.9074 - accuracy: 0.62 - ETA: 0s - loss: 0.9195 - accuracy: 0.61 - ETA: 0s - loss: 0.9359 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9430 - accuracy: 0.59 - ETA: 0s - loss: 0.9440 - accuracy: 0.59 - ETA: 0s - loss: 0.9455 - accuracy: 0.5893\n",
      "Epoch 00185: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9455 - accuracy: 0.5893 - val_loss: 1.0201 - val_accuracy: 0.4998 - lr: 0.0077\n",
      "Epoch 186/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0049 - accuracy: 0.52 - ETA: 0s - loss: 1.0103 - accuracy: 0.51 - ETA: 0s - loss: 1.0015 - accuracy: 0.53 - ETA: 0s - loss: 0.9704 - accuracy: 0.55 - ETA: 0s - loss: 0.9619 - accuracy: 0.57 - ETA: 0s - loss: 0.9452 - accuracy: 0.58 - ETA: 0s - loss: 0.9405 - accuracy: 0.59 - ETA: 0s - loss: 0.9398 - accuracy: 0.59 - ETA: 0s - loss: 0.9390 - accuracy: 0.59 - ETA: 0s - loss: 0.9478 - accuracy: 0.58 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9260 - accuracy: 0.60 - ETA: 0s - loss: 0.9074 - accuracy: 0.62 - ETA: 0s - loss: 0.9195 - accuracy: 0.61 - ETA: 0s - loss: 0.9359 - accuracy: 0.59 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9430 - accuracy: 0.59 - ETA: 0s - loss: 0.9440 - accuracy: 0.59 - ETA: 0s - loss: 0.9455 - accuracy: 0.5893\n",
      "Epoch 00186: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9455 - accuracy: 0.5893 - val_loss: 1.0201 - val_accuracy: 0.5000 - lr: 0.0077\n",
      "Epoch 187/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0049 - accuracy: 0.52 - ETA: 0s - loss: 1.0104 - accuracy: 0.51 - ETA: 0s - loss: 1.0015 - accuracy: 0.53 - ETA: 0s - loss: 0.9704 - accuracy: 0.55 - ETA: 0s - loss: 0.9619 - accuracy: 0.57 - ETA: 0s - loss: 0.9452 - accuracy: 0.58 - ETA: 0s - loss: 0.9404 - accuracy: 0.59 - ETA: 0s - loss: 0.9398 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9477 - accuracy: 0.58 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9260 - accuracy: 0.60 - ETA: 0s - loss: 0.9073 - accuracy: 0.62 - ETA: 0s - loss: 0.9195 - accuracy: 0.61 - ETA: 0s - loss: 0.9359 - accuracy: 0.59 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9430 - accuracy: 0.59 - ETA: 0s - loss: 0.9440 - accuracy: 0.59 - ETA: 0s - loss: 0.9455 - accuracy: 0.5893\n",
      "Epoch 00187: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9455 - accuracy: 0.5893 - val_loss: 1.0201 - val_accuracy: 0.5000 - lr: 0.0077\n",
      "Epoch 188/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0049 - accuracy: 0.52 - ETA: 0s - loss: 1.0104 - accuracy: 0.51 - ETA: 0s - loss: 1.0015 - accuracy: 0.53 - ETA: 0s - loss: 0.9704 - accuracy: 0.55 - ETA: 0s - loss: 0.9619 - accuracy: 0.57 - ETA: 0s - loss: 0.9452 - accuracy: 0.58 - ETA: 0s - loss: 0.9404 - accuracy: 0.59 - ETA: 0s - loss: 0.9398 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9477 - accuracy: 0.58 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9260 - accuracy: 0.60 - ETA: 0s - loss: 0.9073 - accuracy: 0.62 - ETA: 0s - loss: 0.9195 - accuracy: 0.61 - ETA: 0s - loss: 0.9359 - accuracy: 0.59 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9430 - accuracy: 0.59 - ETA: 0s - loss: 0.9440 - accuracy: 0.59 - ETA: 0s - loss: 0.9455 - accuracy: 0.5893\n",
      "Epoch 00188: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9455 - accuracy: 0.5893 - val_loss: 1.0201 - val_accuracy: 0.5000 - lr: 0.0077\n",
      "Epoch 189/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0049 - accuracy: 0.52 - ETA: 0s - loss: 1.0104 - accuracy: 0.51 - ETA: 0s - loss: 1.0015 - accuracy: 0.53 - ETA: 0s - loss: 0.9704 - accuracy: 0.55 - ETA: 0s - loss: 0.9619 - accuracy: 0.57 - ETA: 0s - loss: 0.9452 - accuracy: 0.58 - ETA: 0s - loss: 0.9404 - accuracy: 0.59 - ETA: 0s - loss: 0.9398 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9477 - accuracy: 0.58 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9260 - accuracy: 0.60 - ETA: 0s - loss: 0.9073 - accuracy: 0.62 - ETA: 0s - loss: 0.9195 - accuracy: 0.61 - ETA: 0s - loss: 0.9359 - accuracy: 0.59 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9430 - accuracy: 0.59 - ETA: 0s - loss: 0.9440 - accuracy: 0.59 - ETA: 0s - loss: 0.9455 - accuracy: 0.5893\n",
      "Epoch 00189: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9455 - accuracy: 0.5893 - val_loss: 1.0201 - val_accuracy: 0.5000 - lr: 0.0077\n",
      "Epoch 190/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0049 - accuracy: 0.52 - ETA: 0s - loss: 1.0104 - accuracy: 0.51 - ETA: 0s - loss: 1.0015 - accuracy: 0.53 - ETA: 0s - loss: 0.9704 - accuracy: 0.55 - ETA: 0s - loss: 0.9619 - accuracy: 0.57 - ETA: 0s - loss: 0.9452 - accuracy: 0.58 - ETA: 0s - loss: 0.9404 - accuracy: 0.59 - ETA: 0s - loss: 0.9398 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9477 - accuracy: 0.58 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9260 - accuracy: 0.60 - ETA: 0s - loss: 0.9073 - accuracy: 0.62 - ETA: 0s - loss: 0.9195 - accuracy: 0.61 - ETA: 0s - loss: 0.9359 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9430 - accuracy: 0.59 - ETA: 0s - loss: 0.9440 - accuracy: 0.59 - ETA: 0s - loss: 0.9455 - accuracy: 0.5893\n",
      "Epoch 00190: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9455 - accuracy: 0.5893 - val_loss: 1.0201 - val_accuracy: 0.5000 - lr: 0.0077\n",
      "Epoch 191/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0049 - accuracy: 0.52 - ETA: 0s - loss: 1.0104 - accuracy: 0.51 - ETA: 0s - loss: 1.0015 - accuracy: 0.53 - ETA: 0s - loss: 0.9704 - accuracy: 0.55 - ETA: 0s - loss: 0.9619 - accuracy: 0.57 - ETA: 0s - loss: 0.9452 - accuracy: 0.58 - ETA: 0s - loss: 0.9404 - accuracy: 0.59 - ETA: 0s - loss: 0.9398 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9477 - accuracy: 0.58 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9260 - accuracy: 0.60 - ETA: 0s - loss: 0.9073 - accuracy: 0.62 - ETA: 0s - loss: 0.9195 - accuracy: 0.61 - ETA: 0s - loss: 0.9359 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9430 - accuracy: 0.59 - ETA: 0s - loss: 0.9440 - accuracy: 0.59 - ETA: 0s - loss: 0.9455 - accuracy: 0.5892\n",
      "Epoch 00191: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9455 - accuracy: 0.5892 - val_loss: 1.0201 - val_accuracy: 0.5000 - lr: 0.0077\n",
      "Epoch 192/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0049 - accuracy: 0.52 - ETA: 0s - loss: 1.0104 - accuracy: 0.51 - ETA: 0s - loss: 1.0015 - accuracy: 0.53 - ETA: 0s - loss: 0.9704 - accuracy: 0.55 - ETA: 0s - loss: 0.9619 - accuracy: 0.57 - ETA: 0s - loss: 0.9452 - accuracy: 0.58 - ETA: 0s - loss: 0.9404 - accuracy: 0.59 - ETA: 0s - loss: 0.9398 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9477 - accuracy: 0.58 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9260 - accuracy: 0.60 - ETA: 0s - loss: 0.9073 - accuracy: 0.62 - ETA: 0s - loss: 0.9194 - accuracy: 0.61 - ETA: 0s - loss: 0.9359 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9430 - accuracy: 0.59 - ETA: 0s - loss: 0.9440 - accuracy: 0.59 - ETA: 0s - loss: 0.9455 - accuracy: 0.5892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00192: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9455 - accuracy: 0.5892 - val_loss: 1.0201 - val_accuracy: 0.5000 - lr: 0.0077\n",
      "Epoch 193/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0049 - accuracy: 0.52 - ETA: 0s - loss: 1.0104 - accuracy: 0.51 - ETA: 0s - loss: 1.0015 - accuracy: 0.53 - ETA: 0s - loss: 0.9704 - accuracy: 0.55 - ETA: 0s - loss: 0.9619 - accuracy: 0.57 - ETA: 0s - loss: 0.9452 - accuracy: 0.58 - ETA: 0s - loss: 0.9404 - accuracy: 0.59 - ETA: 0s - loss: 0.9398 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9477 - accuracy: 0.58 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9260 - accuracy: 0.60 - ETA: 0s - loss: 0.9073 - accuracy: 0.62 - ETA: 0s - loss: 0.9194 - accuracy: 0.61 - ETA: 0s - loss: 0.9359 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9430 - accuracy: 0.59 - ETA: 0s - loss: 0.9440 - accuracy: 0.59 - ETA: 0s - loss: 0.9455 - accuracy: 0.5892\n",
      "Epoch 00193: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9455 - accuracy: 0.5892 - val_loss: 1.0201 - val_accuracy: 0.5000 - lr: 0.0077\n",
      "Epoch 194/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0049 - accuracy: 0.52 - ETA: 0s - loss: 1.0104 - accuracy: 0.51 - ETA: 0s - loss: 1.0015 - accuracy: 0.53 - ETA: 0s - loss: 0.9704 - accuracy: 0.55 - ETA: 0s - loss: 0.9619 - accuracy: 0.57 - ETA: 0s - loss: 0.9451 - accuracy: 0.58 - ETA: 0s - loss: 0.9404 - accuracy: 0.59 - ETA: 0s - loss: 0.9398 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9477 - accuracy: 0.58 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9260 - accuracy: 0.60 - ETA: 0s - loss: 0.9073 - accuracy: 0.62 - ETA: 0s - loss: 0.9194 - accuracy: 0.61 - ETA: 0s - loss: 0.9359 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9430 - accuracy: 0.59 - ETA: 0s - loss: 0.9440 - accuracy: 0.59 - ETA: 0s - loss: 0.9455 - accuracy: 0.5892\n",
      "Epoch 00194: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9455 - accuracy: 0.5892 - val_loss: 1.0201 - val_accuracy: 0.4998 - lr: 0.0077\n",
      "Epoch 195/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0049 - accuracy: 0.52 - ETA: 0s - loss: 1.0104 - accuracy: 0.51 - ETA: 0s - loss: 1.0015 - accuracy: 0.53 - ETA: 0s - loss: 0.9704 - accuracy: 0.55 - ETA: 0s - loss: 0.9619 - accuracy: 0.57 - ETA: 0s - loss: 0.9451 - accuracy: 0.58 - ETA: 0s - loss: 0.9404 - accuracy: 0.59 - ETA: 0s - loss: 0.9398 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9477 - accuracy: 0.58 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9260 - accuracy: 0.60 - ETA: 0s - loss: 0.9073 - accuracy: 0.62 - ETA: 0s - loss: 0.9194 - accuracy: 0.61 - ETA: 0s - loss: 0.9359 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9430 - accuracy: 0.59 - ETA: 0s - loss: 0.9440 - accuracy: 0.59 - ETA: 0s - loss: 0.9455 - accuracy: 0.5892\n",
      "Epoch 00195: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9455 - accuracy: 0.5892 - val_loss: 1.0200 - val_accuracy: 0.4998 - lr: 0.0077\n",
      "Epoch 196/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0049 - accuracy: 0.52 - ETA: 0s - loss: 1.0104 - accuracy: 0.51 - ETA: 0s - loss: 1.0015 - accuracy: 0.53 - ETA: 0s - loss: 0.9704 - accuracy: 0.55 - ETA: 0s - loss: 0.9619 - accuracy: 0.57 - ETA: 0s - loss: 0.9451 - accuracy: 0.58 - ETA: 0s - loss: 0.9404 - accuracy: 0.59 - ETA: 0s - loss: 0.9398 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9477 - accuracy: 0.58 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9260 - accuracy: 0.60 - ETA: 0s - loss: 0.9073 - accuracy: 0.62 - ETA: 0s - loss: 0.9194 - accuracy: 0.61 - ETA: 0s - loss: 0.9359 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9430 - accuracy: 0.59 - ETA: 0s - loss: 0.9440 - accuracy: 0.59 - ETA: 0s - loss: 0.9455 - accuracy: 0.5892\n",
      "Epoch 00196: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9455 - accuracy: 0.5892 - val_loss: 1.0200 - val_accuracy: 0.4998 - lr: 0.0077\n",
      "Epoch 197/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0049 - accuracy: 0.52 - ETA: 0s - loss: 1.0103 - accuracy: 0.51 - ETA: 0s - loss: 1.0015 - accuracy: 0.53 - ETA: 0s - loss: 0.9704 - accuracy: 0.55 - ETA: 0s - loss: 0.9619 - accuracy: 0.57 - ETA: 0s - loss: 0.9451 - accuracy: 0.58 - ETA: 0s - loss: 0.9404 - accuracy: 0.59 - ETA: 0s - loss: 0.9398 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9477 - accuracy: 0.58 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9260 - accuracy: 0.60 - ETA: 0s - loss: 0.9073 - accuracy: 0.62 - ETA: 0s - loss: 0.9194 - accuracy: 0.61 - ETA: 0s - loss: 0.9359 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9430 - accuracy: 0.59 - ETA: 0s - loss: 0.9440 - accuracy: 0.59 - ETA: 0s - loss: 0.9455 - accuracy: 0.5892\n",
      "Epoch 00197: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9455 - accuracy: 0.5892 - val_loss: 1.0200 - val_accuracy: 0.4998 - lr: 0.0077\n",
      "Epoch 198/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0049 - accuracy: 0.52 - ETA: 0s - loss: 1.0103 - accuracy: 0.51 - ETA: 0s - loss: 1.0015 - accuracy: 0.53 - ETA: 0s - loss: 0.9704 - accuracy: 0.55 - ETA: 0s - loss: 0.9618 - accuracy: 0.57 - ETA: 0s - loss: 0.9451 - accuracy: 0.58 - ETA: 0s - loss: 0.9404 - accuracy: 0.59 - ETA: 0s - loss: 0.9398 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9477 - accuracy: 0.58 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9260 - accuracy: 0.60 - ETA: 0s - loss: 0.9073 - accuracy: 0.62 - ETA: 0s - loss: 0.9194 - accuracy: 0.61 - ETA: 0s - loss: 0.9359 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9430 - accuracy: 0.59 - ETA: 0s - loss: 0.9440 - accuracy: 0.59 - ETA: 0s - loss: 0.9455 - accuracy: 0.5892\n",
      "Epoch 00198: val_loss did not improve from 1.01430\n",
      "\n",
      "Epoch 00198: ReduceLROnPlateau reducing learning rate to 0.00618475265800953.\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9455 - accuracy: 0.5892 - val_loss: 1.0200 - val_accuracy: 0.4998 - lr: 0.0077\n",
      "Epoch 199/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0049 - accuracy: 0.52 - ETA: 0s - loss: 1.0104 - accuracy: 0.51 - ETA: 0s - loss: 1.0016 - accuracy: 0.53 - ETA: 0s - loss: 0.9703 - accuracy: 0.55 - ETA: 0s - loss: 0.9618 - accuracy: 0.57 - ETA: 0s - loss: 0.9450 - accuracy: 0.58 - ETA: 0s - loss: 0.9402 - accuracy: 0.59 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9476 - accuracy: 0.58 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9258 - accuracy: 0.60 - ETA: 0s - loss: 0.9071 - accuracy: 0.62 - ETA: 0s - loss: 0.9192 - accuracy: 0.61 - ETA: 0s - loss: 0.9355 - accuracy: 0.59 - ETA: 0s - loss: 0.9377 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9437 - accuracy: 0.59 - ETA: 0s - loss: 0.9452 - accuracy: 0.5893\n",
      "Epoch 00199: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9452 - accuracy: 0.5893 - val_loss: 1.0197 - val_accuracy: 0.5000 - lr: 0.0062\n",
      "Epoch 200/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0048 - accuracy: 0.52 - ETA: 0s - loss: 1.0101 - accuracy: 0.51 - ETA: 0s - loss: 1.0014 - accuracy: 0.53 - ETA: 0s - loss: 0.9702 - accuracy: 0.55 - ETA: 0s - loss: 0.9617 - accuracy: 0.57 - ETA: 0s - loss: 0.9450 - accuracy: 0.58 - ETA: 0s - loss: 0.9402 - accuracy: 0.59 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9475 - accuracy: 0.58 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9258 - accuracy: 0.60 - ETA: 0s - loss: 0.9071 - accuracy: 0.62 - ETA: 0s - loss: 0.9192 - accuracy: 0.61 - ETA: 0s - loss: 0.9356 - accuracy: 0.59 - ETA: 0s - loss: 0.9378 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9437 - accuracy: 0.59 - ETA: 0s - loss: 0.9452 - accuracy: 0.5892\n",
      "Epoch 00200: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9452 - accuracy: 0.5892 - val_loss: 1.0196 - val_accuracy: 0.5000 - lr: 0.0062\n",
      "Epoch 201/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0048 - accuracy: 0.52 - ETA: 0s - loss: 1.0101 - accuracy: 0.51 - ETA: 0s - loss: 1.0014 - accuracy: 0.53 - ETA: 0s - loss: 0.9702 - accuracy: 0.55 - ETA: 0s - loss: 0.9617 - accuracy: 0.57 - ETA: 0s - loss: 0.9449 - accuracy: 0.58 - ETA: 0s - loss: 0.9402 - accuracy: 0.59 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9475 - accuracy: 0.58 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9258 - accuracy: 0.60 - ETA: 0s - loss: 0.9071 - accuracy: 0.62 - ETA: 0s - loss: 0.9192 - accuracy: 0.61 - ETA: 0s - loss: 0.9356 - accuracy: 0.59 - ETA: 0s - loss: 0.9377 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9437 - accuracy: 0.59 - ETA: 0s - loss: 0.9452 - accuracy: 0.5892\n",
      "Epoch 00201: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9452 - accuracy: 0.5892 - val_loss: 1.0197 - val_accuracy: 0.5000 - lr: 0.0062\n",
      "Epoch 202/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0048 - accuracy: 0.52 - ETA: 0s - loss: 1.0101 - accuracy: 0.51 - ETA: 0s - loss: 1.0014 - accuracy: 0.53 - ETA: 0s - loss: 0.9702 - accuracy: 0.55 - ETA: 0s - loss: 0.9617 - accuracy: 0.57 - ETA: 0s - loss: 0.9449 - accuracy: 0.58 - ETA: 0s - loss: 0.9402 - accuracy: 0.59 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9475 - accuracy: 0.58 - ETA: 0s - loss: 0.9386 - accuracy: 0.59 - ETA: 0s - loss: 0.9258 - accuracy: 0.60 - ETA: 0s - loss: 0.9071 - accuracy: 0.62 - ETA: 0s - loss: 0.9192 - accuracy: 0.61 - ETA: 0s - loss: 0.9355 - accuracy: 0.59 - ETA: 0s - loss: 0.9377 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9437 - accuracy: 0.59 - ETA: 0s - loss: 0.9452 - accuracy: 0.5892\n",
      "Epoch 00202: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9452 - accuracy: 0.5892 - val_loss: 1.0197 - val_accuracy: 0.5000 - lr: 0.0062\n",
      "Epoch 203/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0048 - accuracy: 0.52 - ETA: 0s - loss: 1.0101 - accuracy: 0.51 - ETA: 0s - loss: 1.0014 - accuracy: 0.53 - ETA: 0s - loss: 0.9702 - accuracy: 0.55 - ETA: 0s - loss: 0.9617 - accuracy: 0.57 - ETA: 0s - loss: 0.9449 - accuracy: 0.58 - ETA: 0s - loss: 0.9402 - accuracy: 0.59 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9475 - accuracy: 0.58 - ETA: 0s - loss: 0.9386 - accuracy: 0.59 - ETA: 0s - loss: 0.9258 - accuracy: 0.60 - ETA: 0s - loss: 0.9071 - accuracy: 0.62 - ETA: 0s - loss: 0.9192 - accuracy: 0.61 - ETA: 0s - loss: 0.9355 - accuracy: 0.59 - ETA: 0s - loss: 0.9377 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9437 - accuracy: 0.59 - ETA: 0s - loss: 0.9452 - accuracy: 0.5892\n",
      "Epoch 00203: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9452 - accuracy: 0.5892 - val_loss: 1.0196 - val_accuracy: 0.5000 - lr: 0.0062\n",
      "Epoch 204/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0048 - accuracy: 0.52 - ETA: 0s - loss: 1.0101 - accuracy: 0.51 - ETA: 0s - loss: 1.0014 - accuracy: 0.53 - ETA: 0s - loss: 0.9702 - accuracy: 0.55 - ETA: 0s - loss: 0.9617 - accuracy: 0.57 - ETA: 0s - loss: 0.9449 - accuracy: 0.58 - ETA: 0s - loss: 0.9402 - accuracy: 0.59 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9475 - accuracy: 0.58 - ETA: 0s - loss: 0.9386 - accuracy: 0.59 - ETA: 0s - loss: 0.9258 - accuracy: 0.60 - ETA: 0s - loss: 0.9071 - accuracy: 0.62 - ETA: 0s - loss: 0.9192 - accuracy: 0.61 - ETA: 0s - loss: 0.9355 - accuracy: 0.59 - ETA: 0s - loss: 0.9377 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9437 - accuracy: 0.59 - ETA: 0s - loss: 0.9452 - accuracy: 0.5892\n",
      "Epoch 00204: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9452 - accuracy: 0.5892 - val_loss: 1.0196 - val_accuracy: 0.5000 - lr: 0.0062\n",
      "Epoch 205/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0048 - accuracy: 0.52 - ETA: 0s - loss: 1.0101 - accuracy: 0.51 - ETA: 0s - loss: 1.0014 - accuracy: 0.53 - ETA: 0s - loss: 0.9702 - accuracy: 0.55 - ETA: 0s - loss: 0.9617 - accuracy: 0.57 - ETA: 0s - loss: 0.9449 - accuracy: 0.58 - ETA: 0s - loss: 0.9402 - accuracy: 0.59 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9475 - accuracy: 0.58 - ETA: 0s - loss: 0.9386 - accuracy: 0.59 - ETA: 0s - loss: 0.9257 - accuracy: 0.60 - ETA: 0s - loss: 0.9071 - accuracy: 0.62 - ETA: 0s - loss: 0.9192 - accuracy: 0.61 - ETA: 0s - loss: 0.9355 - accuracy: 0.59 - ETA: 0s - loss: 0.9377 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9437 - accuracy: 0.59 - ETA: 0s - loss: 0.9452 - accuracy: 0.5892\n",
      "Epoch 00205: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9452 - accuracy: 0.5892 - val_loss: 1.0196 - val_accuracy: 0.5000 - lr: 0.0062\n",
      "Epoch 206/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0048 - accuracy: 0.52 - ETA: 0s - loss: 1.0101 - accuracy: 0.51 - ETA: 0s - loss: 1.0014 - accuracy: 0.53 - ETA: 0s - loss: 0.9702 - accuracy: 0.55 - ETA: 0s - loss: 0.9617 - accuracy: 0.57 - ETA: 0s - loss: 0.9449 - accuracy: 0.58 - ETA: 0s - loss: 0.9402 - accuracy: 0.59 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9475 - accuracy: 0.58 - ETA: 0s - loss: 0.9386 - accuracy: 0.59 - ETA: 0s - loss: 0.9257 - accuracy: 0.60 - ETA: 0s - loss: 0.9071 - accuracy: 0.62 - ETA: 0s - loss: 0.9192 - accuracy: 0.61 - ETA: 0s - loss: 0.9355 - accuracy: 0.59 - ETA: 0s - loss: 0.9377 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9437 - accuracy: 0.59 - ETA: 0s - loss: 0.9452 - accuracy: 0.5892\n",
      "Epoch 00206: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9452 - accuracy: 0.5892 - val_loss: 1.0196 - val_accuracy: 0.5000 - lr: 0.0062\n",
      "Epoch 207/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0048 - accuracy: 0.52 - ETA: 0s - loss: 1.0101 - accuracy: 0.51 - ETA: 0s - loss: 1.0014 - accuracy: 0.53 - ETA: 0s - loss: 0.9702 - accuracy: 0.55 - ETA: 0s - loss: 0.9617 - accuracy: 0.57 - ETA: 0s - loss: 0.9449 - accuracy: 0.58 - ETA: 0s - loss: 0.9402 - accuracy: 0.59 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9475 - accuracy: 0.58 - ETA: 0s - loss: 0.9386 - accuracy: 0.59 - ETA: 0s - loss: 0.9257 - accuracy: 0.60 - ETA: 0s - loss: 0.9071 - accuracy: 0.62 - ETA: 0s - loss: 0.9192 - accuracy: 0.61 - ETA: 0s - loss: 0.9355 - accuracy: 0.59 - ETA: 0s - loss: 0.9377 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9437 - accuracy: 0.59 - ETA: 0s - loss: 0.9452 - accuracy: 0.5892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00207: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9452 - accuracy: 0.5892 - val_loss: 1.0196 - val_accuracy: 0.5000 - lr: 0.0062\n",
      "Epoch 208/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0048 - accuracy: 0.52 - ETA: 0s - loss: 1.0101 - accuracy: 0.51 - ETA: 0s - loss: 1.0014 - accuracy: 0.53 - ETA: 0s - loss: 0.9702 - accuracy: 0.55 - ETA: 0s - loss: 0.9617 - accuracy: 0.57 - ETA: 0s - loss: 0.9449 - accuracy: 0.58 - ETA: 0s - loss: 0.9402 - accuracy: 0.59 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9475 - accuracy: 0.58 - ETA: 0s - loss: 0.9386 - accuracy: 0.59 - ETA: 0s - loss: 0.9257 - accuracy: 0.60 - ETA: 0s - loss: 0.9071 - accuracy: 0.62 - ETA: 0s - loss: 0.9192 - accuracy: 0.61 - ETA: 0s - loss: 0.9355 - accuracy: 0.59 - ETA: 0s - loss: 0.9377 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9437 - accuracy: 0.59 - ETA: 0s - loss: 0.9452 - accuracy: 0.5892\n",
      "Epoch 00208: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9452 - accuracy: 0.5892 - val_loss: 1.0196 - val_accuracy: 0.5000 - lr: 0.0062\n",
      "Epoch 209/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0048 - accuracy: 0.52 - ETA: 0s - loss: 1.0101 - accuracy: 0.51 - ETA: 0s - loss: 1.0014 - accuracy: 0.53 - ETA: 0s - loss: 0.9702 - accuracy: 0.55 - ETA: 0s - loss: 0.9617 - accuracy: 0.57 - ETA: 0s - loss: 0.9449 - accuracy: 0.58 - ETA: 0s - loss: 0.9402 - accuracy: 0.59 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9475 - accuracy: 0.58 - ETA: 0s - loss: 0.9386 - accuracy: 0.59 - ETA: 0s - loss: 0.9257 - accuracy: 0.60 - ETA: 0s - loss: 0.9071 - accuracy: 0.62 - ETA: 0s - loss: 0.9192 - accuracy: 0.61 - ETA: 0s - loss: 0.9355 - accuracy: 0.59 - ETA: 0s - loss: 0.9377 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9437 - accuracy: 0.59 - ETA: 0s - loss: 0.9452 - accuracy: 0.5892\n",
      "Epoch 00209: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9452 - accuracy: 0.5892 - val_loss: 1.0196 - val_accuracy: 0.5000 - lr: 0.0062\n",
      "Epoch 210/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0048 - accuracy: 0.52 - ETA: 0s - loss: 1.0101 - accuracy: 0.51 - ETA: 0s - loss: 1.0014 - accuracy: 0.53 - ETA: 0s - loss: 0.9702 - accuracy: 0.55 - ETA: 0s - loss: 0.9617 - accuracy: 0.57 - ETA: 0s - loss: 0.9449 - accuracy: 0.58 - ETA: 0s - loss: 0.9402 - accuracy: 0.59 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9475 - accuracy: 0.58 - ETA: 0s - loss: 0.9386 - accuracy: 0.59 - ETA: 0s - loss: 0.9257 - accuracy: 0.60 - ETA: 0s - loss: 0.9071 - accuracy: 0.62 - ETA: 0s - loss: 0.9192 - accuracy: 0.61 - ETA: 0s - loss: 0.9355 - accuracy: 0.59 - ETA: 0s - loss: 0.9377 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9437 - accuracy: 0.59 - ETA: 0s - loss: 0.9452 - accuracy: 0.5892\n",
      "Epoch 00210: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9452 - accuracy: 0.5892 - val_loss: 1.0196 - val_accuracy: 0.5000 - lr: 0.0062\n",
      "Epoch 211/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0048 - accuracy: 0.52 - ETA: 0s - loss: 1.0101 - accuracy: 0.51 - ETA: 0s - loss: 1.0014 - accuracy: 0.53 - ETA: 0s - loss: 0.9702 - accuracy: 0.55 - ETA: 0s - loss: 0.9617 - accuracy: 0.57 - ETA: 0s - loss: 0.9449 - accuracy: 0.58 - ETA: 0s - loss: 0.9402 - accuracy: 0.59 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9475 - accuracy: 0.58 - ETA: 0s - loss: 0.9386 - accuracy: 0.59 - ETA: 0s - loss: 0.9257 - accuracy: 0.60 - ETA: 0s - loss: 0.9071 - accuracy: 0.62 - ETA: 0s - loss: 0.9192 - accuracy: 0.61 - ETA: 0s - loss: 0.9355 - accuracy: 0.59 - ETA: 0s - loss: 0.9377 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.59 - ETA: 0s - loss: 0.9437 - accuracy: 0.59 - ETA: 0s - loss: 0.9452 - accuracy: 0.5892\n",
      "Epoch 00211: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9452 - accuracy: 0.5892 - val_loss: 1.0196 - val_accuracy: 0.5000 - lr: 0.0062\n",
      "Epoch 212/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0048 - accuracy: 0.52 - ETA: 0s - loss: 1.0101 - accuracy: 0.51 - ETA: 0s - loss: 1.0014 - accuracy: 0.53 - ETA: 0s - loss: 0.9702 - accuracy: 0.55 - ETA: 0s - loss: 0.9617 - accuracy: 0.57 - ETA: 0s - loss: 0.9449 - accuracy: 0.58 - ETA: 0s - loss: 0.9402 - accuracy: 0.59 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9475 - accuracy: 0.58 - ETA: 0s - loss: 0.9386 - accuracy: 0.59 - ETA: 0s - loss: 0.9257 - accuracy: 0.60 - ETA: 0s - loss: 0.9071 - accuracy: 0.62 - ETA: 0s - loss: 0.9192 - accuracy: 0.61 - ETA: 0s - loss: 0.9355 - accuracy: 0.59 - ETA: 0s - loss: 0.9377 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.59 - ETA: 0s - loss: 0.9437 - accuracy: 0.59 - ETA: 0s - loss: 0.9452 - accuracy: 0.5892\n",
      "Epoch 00212: val_loss did not improve from 1.01430\n",
      "\n",
      "Epoch 00212: ReduceLROnPlateau reducing learning rate to 0.004947802051901817.\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9452 - accuracy: 0.5892 - val_loss: 1.0196 - val_accuracy: 0.5000 - lr: 0.0062\n",
      "Epoch 213/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0048 - accuracy: 0.52 - ETA: 0s - loss: 1.0102 - accuracy: 0.51 - ETA: 0s - loss: 1.0015 - accuracy: 0.53 - ETA: 0s - loss: 0.9702 - accuracy: 0.55 - ETA: 0s - loss: 0.9616 - accuracy: 0.57 - ETA: 0s - loss: 0.9448 - accuracy: 0.58 - ETA: 0s - loss: 0.9400 - accuracy: 0.59 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9385 - accuracy: 0.59 - ETA: 0s - loss: 0.9474 - accuracy: 0.58 - ETA: 0s - loss: 0.9385 - accuracy: 0.59 - ETA: 0s - loss: 0.9256 - accuracy: 0.60 - ETA: 0s - loss: 0.9069 - accuracy: 0.62 - ETA: 0s - loss: 0.9190 - accuracy: 0.61 - ETA: 0s - loss: 0.9353 - accuracy: 0.59 - ETA: 0s - loss: 0.9375 - accuracy: 0.59 - ETA: 0s - loss: 0.9424 - accuracy: 0.59 - ETA: 0s - loss: 0.9434 - accuracy: 0.59 - ETA: 0s - loss: 0.9450 - accuracy: 0.5892\n",
      "Epoch 00213: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9450 - accuracy: 0.5892 - val_loss: 1.0193 - val_accuracy: 0.5002 - lr: 0.0049\n",
      "Epoch 214/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0047 - accuracy: 0.52 - ETA: 0s - loss: 1.0100 - accuracy: 0.51 - ETA: 0s - loss: 1.0013 - accuracy: 0.53 - ETA: 0s - loss: 0.9701 - accuracy: 0.55 - ETA: 0s - loss: 0.9616 - accuracy: 0.57 - ETA: 0s - loss: 0.9448 - accuracy: 0.58 - ETA: 0s - loss: 0.9400 - accuracy: 0.59 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9386 - accuracy: 0.59 - ETA: 0s - loss: 0.9474 - accuracy: 0.58 - ETA: 0s - loss: 0.9385 - accuracy: 0.59 - ETA: 0s - loss: 0.9256 - accuracy: 0.60 - ETA: 0s - loss: 0.9069 - accuracy: 0.62 - ETA: 0s - loss: 0.9190 - accuracy: 0.61 - ETA: 0s - loss: 0.9353 - accuracy: 0.59 - ETA: 0s - loss: 0.9375 - accuracy: 0.59 - ETA: 0s - loss: 0.9424 - accuracy: 0.59 - ETA: 0s - loss: 0.9434 - accuracy: 0.59 - ETA: 0s - loss: 0.9450 - accuracy: 0.5891\n",
      "Epoch 00214: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9450 - accuracy: 0.5891 - val_loss: 1.0193 - val_accuracy: 0.5002 - lr: 0.0049\n",
      "Epoch 215/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0046 - accuracy: 0.52 - ETA: 0s - loss: 1.0099 - accuracy: 0.51 - ETA: 0s - loss: 1.0013 - accuracy: 0.53 - ETA: 0s - loss: 0.9700 - accuracy: 0.55 - ETA: 0s - loss: 0.9615 - accuracy: 0.57 - ETA: 0s - loss: 0.9447 - accuracy: 0.58 - ETA: 0s - loss: 0.9400 - accuracy: 0.59 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9385 - accuracy: 0.59 - ETA: 0s - loss: 0.9474 - accuracy: 0.58 - ETA: 0s - loss: 0.9385 - accuracy: 0.59 - ETA: 0s - loss: 0.9256 - accuracy: 0.60 - ETA: 0s - loss: 0.9069 - accuracy: 0.62 - ETA: 0s - loss: 0.9190 - accuracy: 0.61 - ETA: 0s - loss: 0.9353 - accuracy: 0.59 - ETA: 0s - loss: 0.9375 - accuracy: 0.59 - ETA: 0s - loss: 0.9424 - accuracy: 0.59 - ETA: 0s - loss: 0.9434 - accuracy: 0.59 - ETA: 0s - loss: 0.9450 - accuracy: 0.5891\n",
      "Epoch 00215: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9450 - accuracy: 0.5891 - val_loss: 1.0193 - val_accuracy: 0.5002 - lr: 0.0049\n",
      "Epoch 216/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0047 - accuracy: 0.52 - ETA: 0s - loss: 1.0099 - accuracy: 0.51 - ETA: 0s - loss: 1.0013 - accuracy: 0.53 - ETA: 0s - loss: 0.9701 - accuracy: 0.55 - ETA: 0s - loss: 0.9615 - accuracy: 0.57 - ETA: 0s - loss: 0.9447 - accuracy: 0.58 - ETA: 0s - loss: 0.9400 - accuracy: 0.59 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9385 - accuracy: 0.59 - ETA: 0s - loss: 0.9474 - accuracy: 0.58 - ETA: 0s - loss: 0.9385 - accuracy: 0.59 - ETA: 0s - loss: 0.9256 - accuracy: 0.60 - ETA: 0s - loss: 0.9069 - accuracy: 0.62 - ETA: 0s - loss: 0.9190 - accuracy: 0.61 - ETA: 0s - loss: 0.9353 - accuracy: 0.59 - ETA: 0s - loss: 0.9375 - accuracy: 0.59 - ETA: 0s - loss: 0.9424 - accuracy: 0.59 - ETA: 0s - loss: 0.9434 - accuracy: 0.59 - ETA: 0s - loss: 0.9450 - accuracy: 0.5891\n",
      "Epoch 00216: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9450 - accuracy: 0.5891 - val_loss: 1.0193 - val_accuracy: 0.5002 - lr: 0.0049\n",
      "Epoch 217/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0047 - accuracy: 0.52 - ETA: 0s - loss: 1.0099 - accuracy: 0.51 - ETA: 0s - loss: 1.0013 - accuracy: 0.53 - ETA: 0s - loss: 0.9700 - accuracy: 0.55 - ETA: 0s - loss: 0.9615 - accuracy: 0.57 - ETA: 0s - loss: 0.9447 - accuracy: 0.58 - ETA: 0s - loss: 0.9400 - accuracy: 0.59 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9385 - accuracy: 0.59 - ETA: 0s - loss: 0.9474 - accuracy: 0.58 - ETA: 0s - loss: 0.9385 - accuracy: 0.59 - ETA: 0s - loss: 0.9256 - accuracy: 0.60 - ETA: 0s - loss: 0.9069 - accuracy: 0.62 - ETA: 0s - loss: 0.9190 - accuracy: 0.61 - ETA: 0s - loss: 0.9353 - accuracy: 0.59 - ETA: 0s - loss: 0.9375 - accuracy: 0.59 - ETA: 0s - loss: 0.9424 - accuracy: 0.59 - ETA: 0s - loss: 0.9434 - accuracy: 0.59 - ETA: 0s - loss: 0.9450 - accuracy: 0.5891\n",
      "Epoch 00217: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9450 - accuracy: 0.5891 - val_loss: 1.0193 - val_accuracy: 0.5002 - lr: 0.0049\n",
      "Epoch 218/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0047 - accuracy: 0.52 - ETA: 0s - loss: 1.0099 - accuracy: 0.51 - ETA: 0s - loss: 1.0013 - accuracy: 0.53 - ETA: 0s - loss: 0.9700 - accuracy: 0.55 - ETA: 0s - loss: 0.9615 - accuracy: 0.57 - ETA: 0s - loss: 0.9447 - accuracy: 0.58 - ETA: 0s - loss: 0.9400 - accuracy: 0.59 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9385 - accuracy: 0.59 - ETA: 0s - loss: 0.9474 - accuracy: 0.58 - ETA: 0s - loss: 0.9385 - accuracy: 0.59 - ETA: 0s - loss: 0.9256 - accuracy: 0.60 - ETA: 0s - loss: 0.9069 - accuracy: 0.62 - ETA: 0s - loss: 0.9190 - accuracy: 0.61 - ETA: 0s - loss: 0.9353 - accuracy: 0.59 - ETA: 0s - loss: 0.9375 - accuracy: 0.59 - ETA: 0s - loss: 0.9424 - accuracy: 0.59 - ETA: 0s - loss: 0.9434 - accuracy: 0.59 - ETA: 0s - loss: 0.9450 - accuracy: 0.5891\n",
      "Epoch 00218: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9450 - accuracy: 0.5891 - val_loss: 1.0193 - val_accuracy: 0.5002 - lr: 0.0049\n",
      "Epoch 219/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0047 - accuracy: 0.52 - ETA: 0s - loss: 1.0099 - accuracy: 0.51 - ETA: 0s - loss: 1.0013 - accuracy: 0.53 - ETA: 0s - loss: 0.9700 - accuracy: 0.55 - ETA: 0s - loss: 0.9615 - accuracy: 0.57 - ETA: 0s - loss: 0.9447 - accuracy: 0.58 - ETA: 0s - loss: 0.9400 - accuracy: 0.59 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9385 - accuracy: 0.59 - ETA: 0s - loss: 0.9474 - accuracy: 0.58 - ETA: 0s - loss: 0.9385 - accuracy: 0.59 - ETA: 0s - loss: 0.9256 - accuracy: 0.60 - ETA: 0s - loss: 0.9069 - accuracy: 0.62 - ETA: 0s - loss: 0.9190 - accuracy: 0.61 - ETA: 0s - loss: 0.9353 - accuracy: 0.59 - ETA: 0s - loss: 0.9375 - accuracy: 0.59 - ETA: 0s - loss: 0.9424 - accuracy: 0.59 - ETA: 0s - loss: 0.9434 - accuracy: 0.59 - ETA: 0s - loss: 0.9450 - accuracy: 0.5891\n",
      "Epoch 00219: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9450 - accuracy: 0.5891 - val_loss: 1.0193 - val_accuracy: 0.5002 - lr: 0.0049\n",
      "Epoch 220/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0047 - accuracy: 0.52 - ETA: 0s - loss: 1.0099 - accuracy: 0.51 - ETA: 0s - loss: 1.0013 - accuracy: 0.53 - ETA: 0s - loss: 0.9700 - accuracy: 0.55 - ETA: 0s - loss: 0.9615 - accuracy: 0.57 - ETA: 0s - loss: 0.9447 - accuracy: 0.58 - ETA: 0s - loss: 0.9400 - accuracy: 0.59 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9385 - accuracy: 0.59 - ETA: 0s - loss: 0.9473 - accuracy: 0.58 - ETA: 0s - loss: 0.9385 - accuracy: 0.59 - ETA: 0s - loss: 0.9256 - accuracy: 0.60 - ETA: 0s - loss: 0.9069 - accuracy: 0.62 - ETA: 0s - loss: 0.9190 - accuracy: 0.61 - ETA: 0s - loss: 0.9353 - accuracy: 0.59 - ETA: 0s - loss: 0.9375 - accuracy: 0.59 - ETA: 0s - loss: 0.9424 - accuracy: 0.59 - ETA: 0s - loss: 0.9434 - accuracy: 0.59 - ETA: 0s - loss: 0.9450 - accuracy: 0.5891\n",
      "Epoch 00220: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9450 - accuracy: 0.5891 - val_loss: 1.0193 - val_accuracy: 0.5002 - lr: 0.0049\n",
      "Epoch 221/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0047 - accuracy: 0.52 - ETA: 0s - loss: 1.0099 - accuracy: 0.51 - ETA: 0s - loss: 1.0013 - accuracy: 0.53 - ETA: 0s - loss: 0.9700 - accuracy: 0.55 - ETA: 0s - loss: 0.9615 - accuracy: 0.57 - ETA: 0s - loss: 0.9447 - accuracy: 0.58 - ETA: 0s - loss: 0.9400 - accuracy: 0.59 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9385 - accuracy: 0.59 - ETA: 0s - loss: 0.9473 - accuracy: 0.58 - ETA: 0s - loss: 0.9385 - accuracy: 0.59 - ETA: 0s - loss: 0.9256 - accuracy: 0.60 - ETA: 0s - loss: 0.9069 - accuracy: 0.62 - ETA: 0s - loss: 0.9190 - accuracy: 0.61 - ETA: 0s - loss: 0.9353 - accuracy: 0.59 - ETA: 0s - loss: 0.9375 - accuracy: 0.59 - ETA: 0s - loss: 0.9424 - accuracy: 0.59 - ETA: 0s - loss: 0.9434 - accuracy: 0.59 - ETA: 0s - loss: 0.9450 - accuracy: 0.5891\n",
      "Epoch 00221: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9450 - accuracy: 0.5891 - val_loss: 1.0193 - val_accuracy: 0.5002 - lr: 0.0049\n",
      "Epoch 222/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0047 - accuracy: 0.52 - ETA: 0s - loss: 1.0099 - accuracy: 0.51 - ETA: 0s - loss: 1.0013 - accuracy: 0.53 - ETA: 0s - loss: 0.9700 - accuracy: 0.55 - ETA: 0s - loss: 0.9615 - accuracy: 0.57 - ETA: 0s - loss: 0.9447 - accuracy: 0.58 - ETA: 0s - loss: 0.9400 - accuracy: 0.59 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9385 - accuracy: 0.59 - ETA: 0s - loss: 0.9473 - accuracy: 0.58 - ETA: 0s - loss: 0.9385 - accuracy: 0.59 - ETA: 0s - loss: 0.9256 - accuracy: 0.60 - ETA: 0s - loss: 0.9069 - accuracy: 0.62 - ETA: 0s - loss: 0.9190 - accuracy: 0.61 - ETA: 0s - loss: 0.9353 - accuracy: 0.59 - ETA: 0s - loss: 0.9375 - accuracy: 0.59 - ETA: 0s - loss: 0.9424 - accuracy: 0.59 - ETA: 0s - loss: 0.9434 - accuracy: 0.59 - ETA: 0s - loss: 0.9450 - accuracy: 0.5891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00222: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9450 - accuracy: 0.5891 - val_loss: 1.0193 - val_accuracy: 0.5002 - lr: 0.0049\n",
      "Epoch 223/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0047 - accuracy: 0.52 - ETA: 0s - loss: 1.0099 - accuracy: 0.51 - ETA: 0s - loss: 1.0013 - accuracy: 0.53 - ETA: 0s - loss: 0.9700 - accuracy: 0.55 - ETA: 0s - loss: 0.9615 - accuracy: 0.57 - ETA: 0s - loss: 0.9447 - accuracy: 0.58 - ETA: 0s - loss: 0.9400 - accuracy: 0.59 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9385 - accuracy: 0.59 - ETA: 0s - loss: 0.9473 - accuracy: 0.58 - ETA: 0s - loss: 0.9385 - accuracy: 0.59 - ETA: 0s - loss: 0.9255 - accuracy: 0.60 - ETA: 0s - loss: 0.9069 - accuracy: 0.62 - ETA: 0s - loss: 0.9190 - accuracy: 0.61 - ETA: 0s - loss: 0.9353 - accuracy: 0.59 - ETA: 0s - loss: 0.9375 - accuracy: 0.59 - ETA: 0s - loss: 0.9424 - accuracy: 0.59 - ETA: 0s - loss: 0.9434 - accuracy: 0.59 - ETA: 0s - loss: 0.9450 - accuracy: 0.5889\n",
      "Epoch 00223: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9450 - accuracy: 0.5889 - val_loss: 1.0193 - val_accuracy: 0.5002 - lr: 0.0049\n",
      "Epoch 224/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0047 - accuracy: 0.52 - ETA: 0s - loss: 1.0099 - accuracy: 0.51 - ETA: 0s - loss: 1.0013 - accuracy: 0.53 - ETA: 0s - loss: 0.9700 - accuracy: 0.55 - ETA: 0s - loss: 0.9615 - accuracy: 0.57 - ETA: 0s - loss: 0.9447 - accuracy: 0.58 - ETA: 0s - loss: 0.9400 - accuracy: 0.59 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9385 - accuracy: 0.59 - ETA: 0s - loss: 0.9473 - accuracy: 0.58 - ETA: 0s - loss: 0.9385 - accuracy: 0.59 - ETA: 0s - loss: 0.9255 - accuracy: 0.60 - ETA: 0s - loss: 0.9069 - accuracy: 0.62 - ETA: 0s - loss: 0.9190 - accuracy: 0.61 - ETA: 0s - loss: 0.9353 - accuracy: 0.59 - ETA: 0s - loss: 0.9375 - accuracy: 0.59 - ETA: 0s - loss: 0.9424 - accuracy: 0.59 - ETA: 0s - loss: 0.9434 - accuracy: 0.59 - ETA: 0s - loss: 0.9450 - accuracy: 0.5889\n",
      "Epoch 00224: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9450 - accuracy: 0.5889 - val_loss: 1.0193 - val_accuracy: 0.5002 - lr: 0.0049\n",
      "Epoch 225/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0047 - accuracy: 0.52 - ETA: 0s - loss: 1.0099 - accuracy: 0.51 - ETA: 0s - loss: 1.0013 - accuracy: 0.53 - ETA: 0s - loss: 0.9700 - accuracy: 0.55 - ETA: 0s - loss: 0.9615 - accuracy: 0.57 - ETA: 0s - loss: 0.9447 - accuracy: 0.58 - ETA: 0s - loss: 0.9400 - accuracy: 0.59 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9385 - accuracy: 0.59 - ETA: 0s - loss: 0.9473 - accuracy: 0.58 - ETA: 0s - loss: 0.9385 - accuracy: 0.59 - ETA: 0s - loss: 0.9255 - accuracy: 0.60 - ETA: 0s - loss: 0.9069 - accuracy: 0.62 - ETA: 0s - loss: 0.9190 - accuracy: 0.61 - ETA: 0s - loss: 0.9353 - accuracy: 0.59 - ETA: 0s - loss: 0.9375 - accuracy: 0.59 - ETA: 0s - loss: 0.9424 - accuracy: 0.59 - ETA: 0s - loss: 0.9434 - accuracy: 0.59 - ETA: 0s - loss: 0.9450 - accuracy: 0.5889\n",
      "Epoch 00225: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9450 - accuracy: 0.5889 - val_loss: 1.0193 - val_accuracy: 0.5002 - lr: 0.0049\n",
      "Epoch 226/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0047 - accuracy: 0.52 - ETA: 0s - loss: 1.0099 - accuracy: 0.51 - ETA: 0s - loss: 1.0013 - accuracy: 0.53 - ETA: 0s - loss: 0.9700 - accuracy: 0.55 - ETA: 0s - loss: 0.9615 - accuracy: 0.57 - ETA: 0s - loss: 0.9447 - accuracy: 0.58 - ETA: 0s - loss: 0.9400 - accuracy: 0.59 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9385 - accuracy: 0.59 - ETA: 0s - loss: 0.9473 - accuracy: 0.58 - ETA: 0s - loss: 0.9385 - accuracy: 0.59 - ETA: 0s - loss: 0.9255 - accuracy: 0.60 - ETA: 0s - loss: 0.9069 - accuracy: 0.62 - ETA: 0s - loss: 0.9190 - accuracy: 0.61 - ETA: 0s - loss: 0.9353 - accuracy: 0.59 - ETA: 0s - loss: 0.9375 - accuracy: 0.59 - ETA: 0s - loss: 0.9424 - accuracy: 0.59 - ETA: 0s - loss: 0.9434 - accuracy: 0.59 - ETA: 0s - loss: 0.9450 - accuracy: 0.5889\n",
      "Epoch 00226: val_loss did not improve from 1.01430\n",
      "\n",
      "Epoch 00226: ReduceLROnPlateau reducing learning rate to 0.003958241641521454.\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9450 - accuracy: 0.5889 - val_loss: 1.0192 - val_accuracy: 0.5002 - lr: 0.0049\n",
      "Epoch 227/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0047 - accuracy: 0.52 - ETA: 0s - loss: 1.0100 - accuracy: 0.51 - ETA: 0s - loss: 1.0013 - accuracy: 0.53 - ETA: 0s - loss: 0.9700 - accuracy: 0.55 - ETA: 0s - loss: 0.9615 - accuracy: 0.57 - ETA: 0s - loss: 0.9446 - accuracy: 0.58 - ETA: 0s - loss: 0.9399 - accuracy: 0.59 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9473 - accuracy: 0.58 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9254 - accuracy: 0.60 - ETA: 0s - loss: 0.9067 - accuracy: 0.62 - ETA: 0s - loss: 0.9188 - accuracy: 0.61 - ETA: 0s - loss: 0.9351 - accuracy: 0.59 - ETA: 0s - loss: 0.9373 - accuracy: 0.59 - ETA: 0s - loss: 0.9422 - accuracy: 0.59 - ETA: 0s - loss: 0.9432 - accuracy: 0.59 - ETA: 0s - loss: 0.9448 - accuracy: 0.5891\n",
      "Epoch 00227: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9448 - accuracy: 0.5891 - val_loss: 1.0191 - val_accuracy: 0.5002 - lr: 0.0040\n",
      "Epoch 228/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0046 - accuracy: 0.52 - ETA: 0s - loss: 1.0098 - accuracy: 0.51 - ETA: 0s - loss: 1.0012 - accuracy: 0.53 - ETA: 0s - loss: 0.9700 - accuracy: 0.55 - ETA: 0s - loss: 0.9614 - accuracy: 0.57 - ETA: 0s - loss: 0.9446 - accuracy: 0.58 - ETA: 0s - loss: 0.9399 - accuracy: 0.59 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9473 - accuracy: 0.58 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9254 - accuracy: 0.60 - ETA: 0s - loss: 0.9068 - accuracy: 0.62 - ETA: 0s - loss: 0.9188 - accuracy: 0.61 - ETA: 0s - loss: 0.9351 - accuracy: 0.59 - ETA: 0s - loss: 0.9373 - accuracy: 0.59 - ETA: 0s - loss: 0.9422 - accuracy: 0.59 - ETA: 0s - loss: 0.9432 - accuracy: 0.59 - ETA: 0s - loss: 0.9448 - accuracy: 0.5890\n",
      "Epoch 00228: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9448 - accuracy: 0.5890 - val_loss: 1.0190 - val_accuracy: 0.5002 - lr: 0.0040\n",
      "Epoch 229/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0045 - accuracy: 0.52 - ETA: 0s - loss: 1.0098 - accuracy: 0.51 - ETA: 0s - loss: 1.0012 - accuracy: 0.53 - ETA: 0s - loss: 0.9699 - accuracy: 0.55 - ETA: 0s - loss: 0.9614 - accuracy: 0.57 - ETA: 0s - loss: 0.9446 - accuracy: 0.58 - ETA: 0s - loss: 0.9399 - accuracy: 0.59 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9472 - accuracy: 0.58 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9254 - accuracy: 0.60 - ETA: 0s - loss: 0.9068 - accuracy: 0.62 - ETA: 0s - loss: 0.9188 - accuracy: 0.61 - ETA: 0s - loss: 0.9351 - accuracy: 0.59 - ETA: 0s - loss: 0.9373 - accuracy: 0.59 - ETA: 0s - loss: 0.9422 - accuracy: 0.59 - ETA: 0s - loss: 0.9432 - accuracy: 0.59 - ETA: 0s - loss: 0.9448 - accuracy: 0.5890\n",
      "Epoch 00229: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9448 - accuracy: 0.5890 - val_loss: 1.0190 - val_accuracy: 0.5002 - lr: 0.0040\n",
      "Epoch 230/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0046 - accuracy: 0.52 - ETA: 0s - loss: 1.0098 - accuracy: 0.51 - ETA: 0s - loss: 1.0012 - accuracy: 0.53 - ETA: 0s - loss: 0.9699 - accuracy: 0.55 - ETA: 0s - loss: 0.9614 - accuracy: 0.57 - ETA: 0s - loss: 0.9446 - accuracy: 0.58 - ETA: 0s - loss: 0.9399 - accuracy: 0.59 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9472 - accuracy: 0.58 - ETA: 0s - loss: 0.9383 - accuracy: 0.59 - ETA: 0s - loss: 0.9254 - accuracy: 0.60 - ETA: 0s - loss: 0.9068 - accuracy: 0.62 - ETA: 0s - loss: 0.9188 - accuracy: 0.61 - ETA: 0s - loss: 0.9351 - accuracy: 0.59 - ETA: 0s - loss: 0.9373 - accuracy: 0.59 - ETA: 0s - loss: 0.9422 - accuracy: 0.59 - ETA: 0s - loss: 0.9432 - accuracy: 0.59 - ETA: 0s - loss: 0.9448 - accuracy: 0.5890\n",
      "Epoch 00230: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9448 - accuracy: 0.5890 - val_loss: 1.0190 - val_accuracy: 0.5002 - lr: 0.0040\n",
      "Epoch 231/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0046 - accuracy: 0.52 - ETA: 0s - loss: 1.0098 - accuracy: 0.51 - ETA: 0s - loss: 1.0012 - accuracy: 0.53 - ETA: 0s - loss: 0.9699 - accuracy: 0.55 - ETA: 0s - loss: 0.9614 - accuracy: 0.57 - ETA: 0s - loss: 0.9446 - accuracy: 0.58 - ETA: 0s - loss: 0.9399 - accuracy: 0.59 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9472 - accuracy: 0.58 - ETA: 0s - loss: 0.9383 - accuracy: 0.59 - ETA: 0s - loss: 0.9254 - accuracy: 0.60 - ETA: 0s - loss: 0.9068 - accuracy: 0.62 - ETA: 0s - loss: 0.9188 - accuracy: 0.61 - ETA: 0s - loss: 0.9351 - accuracy: 0.59 - ETA: 0s - loss: 0.9373 - accuracy: 0.59 - ETA: 0s - loss: 0.9422 - accuracy: 0.59 - ETA: 0s - loss: 0.9432 - accuracy: 0.59 - ETA: 0s - loss: 0.9448 - accuracy: 0.5890\n",
      "Epoch 00231: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9448 - accuracy: 0.5890 - val_loss: 1.0190 - val_accuracy: 0.5002 - lr: 0.0040\n",
      "Epoch 232/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0046 - accuracy: 0.52 - ETA: 0s - loss: 1.0098 - accuracy: 0.51 - ETA: 0s - loss: 1.0012 - accuracy: 0.53 - ETA: 0s - loss: 0.9699 - accuracy: 0.55 - ETA: 0s - loss: 0.9614 - accuracy: 0.57 - ETA: 0s - loss: 0.9446 - accuracy: 0.58 - ETA: 0s - loss: 0.9399 - accuracy: 0.59 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9472 - accuracy: 0.58 - ETA: 0s - loss: 0.9383 - accuracy: 0.59 - ETA: 0s - loss: 0.9254 - accuracy: 0.60 - ETA: 0s - loss: 0.9068 - accuracy: 0.62 - ETA: 0s - loss: 0.9188 - accuracy: 0.61 - ETA: 0s - loss: 0.9351 - accuracy: 0.59 - ETA: 0s - loss: 0.9373 - accuracy: 0.59 - ETA: 0s - loss: 0.9422 - accuracy: 0.59 - ETA: 0s - loss: 0.9432 - accuracy: 0.59 - ETA: 0s - loss: 0.9448 - accuracy: 0.5890\n",
      "Epoch 00232: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9448 - accuracy: 0.5890 - val_loss: 1.0190 - val_accuracy: 0.5002 - lr: 0.0040\n",
      "Epoch 233/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0046 - accuracy: 0.52 - ETA: 0s - loss: 1.0098 - accuracy: 0.51 - ETA: 0s - loss: 1.0012 - accuracy: 0.53 - ETA: 0s - loss: 0.9699 - accuracy: 0.55 - ETA: 0s - loss: 0.9614 - accuracy: 0.57 - ETA: 0s - loss: 0.9446 - accuracy: 0.58 - ETA: 0s - loss: 0.9399 - accuracy: 0.59 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9472 - accuracy: 0.58 - ETA: 0s - loss: 0.9383 - accuracy: 0.59 - ETA: 0s - loss: 0.9254 - accuracy: 0.60 - ETA: 0s - loss: 0.9068 - accuracy: 0.62 - ETA: 0s - loss: 0.9188 - accuracy: 0.61 - ETA: 0s - loss: 0.9351 - accuracy: 0.59 - ETA: 0s - loss: 0.9373 - accuracy: 0.59 - ETA: 0s - loss: 0.9422 - accuracy: 0.59 - ETA: 0s - loss: 0.9432 - accuracy: 0.59 - ETA: 0s - loss: 0.9448 - accuracy: 0.5890\n",
      "Epoch 00233: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9448 - accuracy: 0.5890 - val_loss: 1.0190 - val_accuracy: 0.5002 - lr: 0.0040\n",
      "Epoch 234/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0046 - accuracy: 0.52 - ETA: 0s - loss: 1.0098 - accuracy: 0.51 - ETA: 0s - loss: 1.0012 - accuracy: 0.53 - ETA: 0s - loss: 0.9699 - accuracy: 0.55 - ETA: 0s - loss: 0.9614 - accuracy: 0.57 - ETA: 0s - loss: 0.9446 - accuracy: 0.58 - ETA: 0s - loss: 0.9399 - accuracy: 0.59 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9472 - accuracy: 0.58 - ETA: 0s - loss: 0.9383 - accuracy: 0.59 - ETA: 0s - loss: 0.9254 - accuracy: 0.60 - ETA: 0s - loss: 0.9068 - accuracy: 0.62 - ETA: 0s - loss: 0.9188 - accuracy: 0.61 - ETA: 0s - loss: 0.9351 - accuracy: 0.59 - ETA: 0s - loss: 0.9373 - accuracy: 0.59 - ETA: 0s - loss: 0.9422 - accuracy: 0.59 - ETA: 0s - loss: 0.9432 - accuracy: 0.59 - ETA: 0s - loss: 0.9448 - accuracy: 0.5890\n",
      "Epoch 00234: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9448 - accuracy: 0.5890 - val_loss: 1.0190 - val_accuracy: 0.5002 - lr: 0.0040\n",
      "Epoch 235/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0046 - accuracy: 0.52 - ETA: 0s - loss: 1.0098 - accuracy: 0.51 - ETA: 0s - loss: 1.0012 - accuracy: 0.53 - ETA: 0s - loss: 0.9699 - accuracy: 0.55 - ETA: 0s - loss: 0.9614 - accuracy: 0.57 - ETA: 0s - loss: 0.9446 - accuracy: 0.58 - ETA: 0s - loss: 0.9399 - accuracy: 0.59 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9472 - accuracy: 0.58 - ETA: 0s - loss: 0.9383 - accuracy: 0.59 - ETA: 0s - loss: 0.9254 - accuracy: 0.60 - ETA: 0s - loss: 0.9067 - accuracy: 0.62 - ETA: 0s - loss: 0.9188 - accuracy: 0.61 - ETA: 0s - loss: 0.9351 - accuracy: 0.59 - ETA: 0s - loss: 0.9373 - accuracy: 0.59 - ETA: 0s - loss: 0.9422 - accuracy: 0.59 - ETA: 0s - loss: 0.9432 - accuracy: 0.59 - ETA: 0s - loss: 0.9448 - accuracy: 0.5889\n",
      "Epoch 00235: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9448 - accuracy: 0.5889 - val_loss: 1.0190 - val_accuracy: 0.5002 - lr: 0.0040\n",
      "Epoch 236/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0046 - accuracy: 0.52 - ETA: 0s - loss: 1.0098 - accuracy: 0.51 - ETA: 0s - loss: 1.0012 - accuracy: 0.53 - ETA: 0s - loss: 0.9699 - accuracy: 0.55 - ETA: 0s - loss: 0.9614 - accuracy: 0.57 - ETA: 0s - loss: 0.9446 - accuracy: 0.58 - ETA: 0s - loss: 0.9399 - accuracy: 0.59 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9472 - accuracy: 0.58 - ETA: 0s - loss: 0.9383 - accuracy: 0.59 - ETA: 0s - loss: 0.9254 - accuracy: 0.60 - ETA: 0s - loss: 0.9067 - accuracy: 0.62 - ETA: 0s - loss: 0.9188 - accuracy: 0.61 - ETA: 0s - loss: 0.9351 - accuracy: 0.59 - ETA: 0s - loss: 0.9373 - accuracy: 0.59 - ETA: 0s - loss: 0.9422 - accuracy: 0.59 - ETA: 0s - loss: 0.9432 - accuracy: 0.59 - ETA: 0s - loss: 0.9448 - accuracy: 0.5889\n",
      "Epoch 00236: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9448 - accuracy: 0.5889 - val_loss: 1.0190 - val_accuracy: 0.5002 - lr: 0.0040\n",
      "Epoch 237/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0046 - accuracy: 0.52 - ETA: 0s - loss: 1.0098 - accuracy: 0.51 - ETA: 0s - loss: 1.0012 - accuracy: 0.53 - ETA: 0s - loss: 0.9699 - accuracy: 0.55 - ETA: 0s - loss: 0.9614 - accuracy: 0.57 - ETA: 0s - loss: 0.9446 - accuracy: 0.58 - ETA: 0s - loss: 0.9399 - accuracy: 0.59 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9472 - accuracy: 0.58 - ETA: 0s - loss: 0.9383 - accuracy: 0.59 - ETA: 0s - loss: 0.9254 - accuracy: 0.60 - ETA: 0s - loss: 0.9067 - accuracy: 0.62 - ETA: 0s - loss: 0.9188 - accuracy: 0.61 - ETA: 0s - loss: 0.9351 - accuracy: 0.59 - ETA: 0s - loss: 0.9373 - accuracy: 0.59 - ETA: 0s - loss: 0.9422 - accuracy: 0.59 - ETA: 0s - loss: 0.9432 - accuracy: 0.59 - ETA: 0s - loss: 0.9448 - accuracy: 0.5889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00237: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9448 - accuracy: 0.5889 - val_loss: 1.0190 - val_accuracy: 0.5002 - lr: 0.0040\n",
      "Epoch 238/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0046 - accuracy: 0.52 - ETA: 0s - loss: 1.0098 - accuracy: 0.51 - ETA: 0s - loss: 1.0012 - accuracy: 0.53 - ETA: 0s - loss: 0.9699 - accuracy: 0.55 - ETA: 0s - loss: 0.9614 - accuracy: 0.57 - ETA: 0s - loss: 0.9446 - accuracy: 0.58 - ETA: 0s - loss: 0.9399 - accuracy: 0.59 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9472 - accuracy: 0.58 - ETA: 0s - loss: 0.9383 - accuracy: 0.59 - ETA: 0s - loss: 0.9254 - accuracy: 0.60 - ETA: 0s - loss: 0.9067 - accuracy: 0.62 - ETA: 0s - loss: 0.9188 - accuracy: 0.61 - ETA: 0s - loss: 0.9351 - accuracy: 0.59 - ETA: 0s - loss: 0.9373 - accuracy: 0.59 - ETA: 0s - loss: 0.9422 - accuracy: 0.59 - ETA: 0s - loss: 0.9432 - accuracy: 0.59 - ETA: 0s - loss: 0.9448 - accuracy: 0.5889\n",
      "Epoch 00238: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9448 - accuracy: 0.5889 - val_loss: 1.0190 - val_accuracy: 0.5002 - lr: 0.0040\n",
      "Epoch 239/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0046 - accuracy: 0.52 - ETA: 0s - loss: 1.0098 - accuracy: 0.51 - ETA: 0s - loss: 1.0012 - accuracy: 0.53 - ETA: 0s - loss: 0.9699 - accuracy: 0.55 - ETA: 0s - loss: 0.9614 - accuracy: 0.57 - ETA: 0s - loss: 0.9446 - accuracy: 0.58 - ETA: 0s - loss: 0.9399 - accuracy: 0.59 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9472 - accuracy: 0.58 - ETA: 0s - loss: 0.9383 - accuracy: 0.59 - ETA: 0s - loss: 0.9254 - accuracy: 0.60 - ETA: 0s - loss: 0.9067 - accuracy: 0.62 - ETA: 0s - loss: 0.9188 - accuracy: 0.61 - ETA: 0s - loss: 0.9351 - accuracy: 0.59 - ETA: 0s - loss: 0.9373 - accuracy: 0.59 - ETA: 0s - loss: 0.9422 - accuracy: 0.59 - ETA: 0s - loss: 0.9432 - accuracy: 0.59 - ETA: 0s - loss: 0.9448 - accuracy: 0.5889\n",
      "Epoch 00239: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9448 - accuracy: 0.5889 - val_loss: 1.0190 - val_accuracy: 0.5002 - lr: 0.0040\n",
      "Epoch 240/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0046 - accuracy: 0.52 - ETA: 0s - loss: 1.0098 - accuracy: 0.51 - ETA: 0s - loss: 1.0012 - accuracy: 0.53 - ETA: 0s - loss: 0.9699 - accuracy: 0.55 - ETA: 0s - loss: 0.9614 - accuracy: 0.57 - ETA: 0s - loss: 0.9446 - accuracy: 0.58 - ETA: 0s - loss: 0.9399 - accuracy: 0.59 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9472 - accuracy: 0.58 - ETA: 0s - loss: 0.9383 - accuracy: 0.59 - ETA: 0s - loss: 0.9254 - accuracy: 0.60 - ETA: 0s - loss: 0.9067 - accuracy: 0.62 - ETA: 0s - loss: 0.9188 - accuracy: 0.61 - ETA: 0s - loss: 0.9351 - accuracy: 0.59 - ETA: 0s - loss: 0.9373 - accuracy: 0.59 - ETA: 0s - loss: 0.9422 - accuracy: 0.59 - ETA: 0s - loss: 0.9432 - accuracy: 0.59 - ETA: 0s - loss: 0.9448 - accuracy: 0.5889\n",
      "Epoch 00240: val_loss did not improve from 1.01430\n",
      "\n",
      "Epoch 00240: ReduceLROnPlateau reducing learning rate to 0.003166593238711357.\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9448 - accuracy: 0.5889 - val_loss: 1.0190 - val_accuracy: 0.5002 - lr: 0.0040\n",
      "Epoch 241/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0046 - accuracy: 0.52 - ETA: 0s - loss: 1.0098 - accuracy: 0.51 - ETA: 0s - loss: 1.0013 - accuracy: 0.53 - ETA: 0s - loss: 0.9699 - accuracy: 0.55 - ETA: 0s - loss: 0.9614 - accuracy: 0.57 - ETA: 0s - loss: 0.9445 - accuracy: 0.58 - ETA: 0s - loss: 0.9398 - accuracy: 0.59 - ETA: 0s - loss: 0.9392 - accuracy: 0.59 - ETA: 0s - loss: 0.9383 - accuracy: 0.59 - ETA: 0s - loss: 0.9472 - accuracy: 0.58 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9253 - accuracy: 0.60 - ETA: 0s - loss: 0.9066 - accuracy: 0.62 - ETA: 0s - loss: 0.9187 - accuracy: 0.61 - ETA: 0s - loss: 0.9349 - accuracy: 0.59 - ETA: 0s - loss: 0.9371 - accuracy: 0.59 - ETA: 0s - loss: 0.9420 - accuracy: 0.59 - ETA: 0s - loss: 0.9431 - accuracy: 0.59 - ETA: 0s - loss: 0.9446 - accuracy: 0.5890\n",
      "Epoch 00241: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9446 - accuracy: 0.5890 - val_loss: 1.0189 - val_accuracy: 0.5002 - lr: 0.0032\n",
      "Epoch 242/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0045 - accuracy: 0.52 - ETA: 0s - loss: 1.0097 - accuracy: 0.51 - ETA: 0s - loss: 1.0012 - accuracy: 0.53 - ETA: 0s - loss: 0.9699 - accuracy: 0.55 - ETA: 0s - loss: 0.9613 - accuracy: 0.57 - ETA: 0s - loss: 0.9445 - accuracy: 0.58 - ETA: 0s - loss: 0.9398 - accuracy: 0.59 - ETA: 0s - loss: 0.9392 - accuracy: 0.59 - ETA: 0s - loss: 0.9383 - accuracy: 0.59 - ETA: 0s - loss: 0.9472 - accuracy: 0.58 - ETA: 0s - loss: 0.9383 - accuracy: 0.59 - ETA: 0s - loss: 0.9253 - accuracy: 0.60 - ETA: 0s - loss: 0.9066 - accuracy: 0.62 - ETA: 0s - loss: 0.9187 - accuracy: 0.61 - ETA: 0s - loss: 0.9349 - accuracy: 0.59 - ETA: 0s - loss: 0.9371 - accuracy: 0.59 - ETA: 0s - loss: 0.9420 - accuracy: 0.59 - ETA: 0s - loss: 0.9431 - accuracy: 0.59 - ETA: 0s - loss: 0.9446 - accuracy: 0.5889\n",
      "Epoch 00242: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9446 - accuracy: 0.5889 - val_loss: 1.0188 - val_accuracy: 0.5002 - lr: 0.0032\n",
      "Epoch 243/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0045 - accuracy: 0.52 - ETA: 0s - loss: 1.0097 - accuracy: 0.51 - ETA: 0s - loss: 1.0012 - accuracy: 0.53 - ETA: 0s - loss: 0.9698 - accuracy: 0.55 - ETA: 0s - loss: 0.9613 - accuracy: 0.57 - ETA: 0s - loss: 0.9445 - accuracy: 0.58 - ETA: 0s - loss: 0.9398 - accuracy: 0.59 - ETA: 0s - loss: 0.9392 - accuracy: 0.59 - ETA: 0s - loss: 0.9383 - accuracy: 0.59 - ETA: 0s - loss: 0.9471 - accuracy: 0.58 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9253 - accuracy: 0.60 - ETA: 0s - loss: 0.9066 - accuracy: 0.62 - ETA: 0s - loss: 0.9187 - accuracy: 0.61 - ETA: 0s - loss: 0.9349 - accuracy: 0.59 - ETA: 0s - loss: 0.9371 - accuracy: 0.59 - ETA: 0s - loss: 0.9420 - accuracy: 0.59 - ETA: 0s - loss: 0.9431 - accuracy: 0.59 - ETA: 0s - loss: 0.9446 - accuracy: 0.5889\n",
      "Epoch 00243: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9446 - accuracy: 0.5889 - val_loss: 1.0188 - val_accuracy: 0.5002 - lr: 0.0032\n",
      "Epoch 244/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0045 - accuracy: 0.52 - ETA: 0s - loss: 1.0097 - accuracy: 0.51 - ETA: 0s - loss: 1.0011 - accuracy: 0.53 - ETA: 0s - loss: 0.9698 - accuracy: 0.55 - ETA: 0s - loss: 0.9613 - accuracy: 0.57 - ETA: 0s - loss: 0.9445 - accuracy: 0.58 - ETA: 0s - loss: 0.9398 - accuracy: 0.59 - ETA: 0s - loss: 0.9392 - accuracy: 0.59 - ETA: 0s - loss: 0.9383 - accuracy: 0.59 - ETA: 0s - loss: 0.9471 - accuracy: 0.58 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9253 - accuracy: 0.60 - ETA: 0s - loss: 0.9066 - accuracy: 0.62 - ETA: 0s - loss: 0.9187 - accuracy: 0.61 - ETA: 0s - loss: 0.9349 - accuracy: 0.59 - ETA: 0s - loss: 0.9371 - accuracy: 0.59 - ETA: 0s - loss: 0.9420 - accuracy: 0.59 - ETA: 0s - loss: 0.9431 - accuracy: 0.59 - ETA: 0s - loss: 0.9446 - accuracy: 0.5889\n",
      "Epoch 00244: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9446 - accuracy: 0.5889 - val_loss: 1.0188 - val_accuracy: 0.5002 - lr: 0.0032\n",
      "Epoch 245/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0045 - accuracy: 0.52 - ETA: 0s - loss: 1.0097 - accuracy: 0.51 - ETA: 0s - loss: 1.0012 - accuracy: 0.53 - ETA: 0s - loss: 0.9698 - accuracy: 0.55 - ETA: 0s - loss: 0.9613 - accuracy: 0.57 - ETA: 0s - loss: 0.9445 - accuracy: 0.58 - ETA: 0s - loss: 0.9398 - accuracy: 0.59 - ETA: 0s - loss: 0.9392 - accuracy: 0.59 - ETA: 0s - loss: 0.9383 - accuracy: 0.59 - ETA: 0s - loss: 0.9471 - accuracy: 0.58 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9253 - accuracy: 0.60 - ETA: 0s - loss: 0.9066 - accuracy: 0.62 - ETA: 0s - loss: 0.9187 - accuracy: 0.61 - ETA: 0s - loss: 0.9349 - accuracy: 0.59 - ETA: 0s - loss: 0.9371 - accuracy: 0.59 - ETA: 0s - loss: 0.9420 - accuracy: 0.59 - ETA: 0s - loss: 0.9431 - accuracy: 0.59 - ETA: 0s - loss: 0.9446 - accuracy: 0.5889\n",
      "Epoch 00245: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9446 - accuracy: 0.5889 - val_loss: 1.0188 - val_accuracy: 0.5002 - lr: 0.0032\n",
      "Epoch 246/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0045 - accuracy: 0.52 - ETA: 0s - loss: 1.0097 - accuracy: 0.51 - ETA: 0s - loss: 1.0012 - accuracy: 0.53 - ETA: 0s - loss: 0.9698 - accuracy: 0.55 - ETA: 0s - loss: 0.9613 - accuracy: 0.57 - ETA: 0s - loss: 0.9445 - accuracy: 0.58 - ETA: 0s - loss: 0.9398 - accuracy: 0.59 - ETA: 0s - loss: 0.9392 - accuracy: 0.59 - ETA: 0s - loss: 0.9383 - accuracy: 0.59 - ETA: 0s - loss: 0.9471 - accuracy: 0.58 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9253 - accuracy: 0.60 - ETA: 0s - loss: 0.9066 - accuracy: 0.62 - ETA: 0s - loss: 0.9187 - accuracy: 0.61 - ETA: 0s - loss: 0.9349 - accuracy: 0.59 - ETA: 0s - loss: 0.9371 - accuracy: 0.59 - ETA: 0s - loss: 0.9420 - accuracy: 0.59 - ETA: 0s - loss: 0.9431 - accuracy: 0.59 - ETA: 0s - loss: 0.9446 - accuracy: 0.5889\n",
      "Epoch 00246: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9446 - accuracy: 0.5889 - val_loss: 1.0188 - val_accuracy: 0.5002 - lr: 0.0032\n",
      "Epoch 247/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0045 - accuracy: 0.52 - ETA: 0s - loss: 1.0097 - accuracy: 0.51 - ETA: 0s - loss: 1.0012 - accuracy: 0.53 - ETA: 0s - loss: 0.9698 - accuracy: 0.55 - ETA: 0s - loss: 0.9613 - accuracy: 0.57 - ETA: 0s - loss: 0.9445 - accuracy: 0.58 - ETA: 0s - loss: 0.9398 - accuracy: 0.59 - ETA: 0s - loss: 0.9392 - accuracy: 0.59 - ETA: 0s - loss: 0.9383 - accuracy: 0.59 - ETA: 0s - loss: 0.9471 - accuracy: 0.58 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9253 - accuracy: 0.60 - ETA: 0s - loss: 0.9066 - accuracy: 0.62 - ETA: 0s - loss: 0.9187 - accuracy: 0.61 - ETA: 0s - loss: 0.9349 - accuracy: 0.59 - ETA: 0s - loss: 0.9371 - accuracy: 0.59 - ETA: 0s - loss: 0.9420 - accuracy: 0.59 - ETA: 0s - loss: 0.9431 - accuracy: 0.59 - ETA: 0s - loss: 0.9446 - accuracy: 0.5889\n",
      "Epoch 00247: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9446 - accuracy: 0.5889 - val_loss: 1.0188 - val_accuracy: 0.5002 - lr: 0.0032\n",
      "Epoch 248/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0045 - accuracy: 0.52 - ETA: 0s - loss: 1.0097 - accuracy: 0.51 - ETA: 0s - loss: 1.0012 - accuracy: 0.53 - ETA: 0s - loss: 0.9698 - accuracy: 0.55 - ETA: 0s - loss: 0.9613 - accuracy: 0.57 - ETA: 0s - loss: 0.9445 - accuracy: 0.58 - ETA: 0s - loss: 0.9398 - accuracy: 0.59 - ETA: 0s - loss: 0.9392 - accuracy: 0.59 - ETA: 0s - loss: 0.9383 - accuracy: 0.59 - ETA: 0s - loss: 0.9471 - accuracy: 0.58 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9253 - accuracy: 0.60 - ETA: 0s - loss: 0.9066 - accuracy: 0.62 - ETA: 0s - loss: 0.9187 - accuracy: 0.61 - ETA: 0s - loss: 0.9349 - accuracy: 0.59 - ETA: 0s - loss: 0.9371 - accuracy: 0.59 - ETA: 0s - loss: 0.9420 - accuracy: 0.59 - ETA: 0s - loss: 0.9431 - accuracy: 0.59 - ETA: 0s - loss: 0.9446 - accuracy: 0.5888\n",
      "Epoch 00248: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9446 - accuracy: 0.5888 - val_loss: 1.0188 - val_accuracy: 0.5002 - lr: 0.0032\n",
      "Epoch 249/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0045 - accuracy: 0.52 - ETA: 0s - loss: 1.0097 - accuracy: 0.51 - ETA: 0s - loss: 1.0012 - accuracy: 0.53 - ETA: 0s - loss: 0.9698 - accuracy: 0.55 - ETA: 0s - loss: 0.9613 - accuracy: 0.57 - ETA: 0s - loss: 0.9445 - accuracy: 0.58 - ETA: 0s - loss: 0.9397 - accuracy: 0.59 - ETA: 0s - loss: 0.9392 - accuracy: 0.59 - ETA: 0s - loss: 0.9383 - accuracy: 0.59 - ETA: 0s - loss: 0.9471 - accuracy: 0.58 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9253 - accuracy: 0.60 - ETA: 0s - loss: 0.9066 - accuracy: 0.62 - ETA: 0s - loss: 0.9187 - accuracy: 0.61 - ETA: 0s - loss: 0.9349 - accuracy: 0.59 - ETA: 0s - loss: 0.9371 - accuracy: 0.59 - ETA: 0s - loss: 0.9420 - accuracy: 0.59 - ETA: 0s - loss: 0.9431 - accuracy: 0.59 - ETA: 0s - loss: 0.9446 - accuracy: 0.5888\n",
      "Epoch 00249: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9446 - accuracy: 0.5888 - val_loss: 1.0188 - val_accuracy: 0.5002 - lr: 0.0032\n",
      "Epoch 250/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0045 - accuracy: 0.52 - ETA: 0s - loss: 1.0097 - accuracy: 0.51 - ETA: 0s - loss: 1.0012 - accuracy: 0.53 - ETA: 0s - loss: 0.9698 - accuracy: 0.55 - ETA: 0s - loss: 0.9613 - accuracy: 0.57 - ETA: 0s - loss: 0.9445 - accuracy: 0.58 - ETA: 0s - loss: 0.9397 - accuracy: 0.59 - ETA: 0s - loss: 0.9392 - accuracy: 0.59 - ETA: 0s - loss: 0.9383 - accuracy: 0.59 - ETA: 0s - loss: 0.9471 - accuracy: 0.58 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9253 - accuracy: 0.60 - ETA: 0s - loss: 0.9066 - accuracy: 0.62 - ETA: 0s - loss: 0.9187 - accuracy: 0.61 - ETA: 0s - loss: 0.9349 - accuracy: 0.59 - ETA: 0s - loss: 0.9371 - accuracy: 0.59 - ETA: 0s - loss: 0.9420 - accuracy: 0.59 - ETA: 0s - loss: 0.9431 - accuracy: 0.59 - ETA: 0s - loss: 0.9446 - accuracy: 0.5888\n",
      "Epoch 00250: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9446 - accuracy: 0.5888 - val_loss: 1.0188 - val_accuracy: 0.5002 - lr: 0.0032\n",
      "Epoch 251/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0045 - accuracy: 0.52 - ETA: 0s - loss: 1.0097 - accuracy: 0.51 - ETA: 0s - loss: 1.0012 - accuracy: 0.53 - ETA: 0s - loss: 0.9698 - accuracy: 0.55 - ETA: 0s - loss: 0.9613 - accuracy: 0.57 - ETA: 0s - loss: 0.9445 - accuracy: 0.58 - ETA: 0s - loss: 0.9397 - accuracy: 0.59 - ETA: 0s - loss: 0.9391 - accuracy: 0.59 - ETA: 0s - loss: 0.9383 - accuracy: 0.59 - ETA: 0s - loss: 0.9471 - accuracy: 0.58 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9253 - accuracy: 0.60 - ETA: 0s - loss: 0.9066 - accuracy: 0.62 - ETA: 0s - loss: 0.9187 - accuracy: 0.61 - ETA: 0s - loss: 0.9349 - accuracy: 0.59 - ETA: 0s - loss: 0.9371 - accuracy: 0.59 - ETA: 0s - loss: 0.9420 - accuracy: 0.59 - ETA: 0s - loss: 0.9431 - accuracy: 0.59 - ETA: 0s - loss: 0.9446 - accuracy: 0.5888\n",
      "Epoch 00251: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 84ms/step - loss: 0.9446 - accuracy: 0.5888 - val_loss: 1.0188 - val_accuracy: 0.5002 - lr: 0.0032\n",
      "Epoch 252/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0045 - accuracy: 0.52 - ETA: 0s - loss: 1.0097 - accuracy: 0.51 - ETA: 0s - loss: 1.0012 - accuracy: 0.53 - ETA: 0s - loss: 0.9698 - accuracy: 0.55 - ETA: 0s - loss: 0.9613 - accuracy: 0.57 - ETA: 0s - loss: 0.9445 - accuracy: 0.58 - ETA: 0s - loss: 0.9397 - accuracy: 0.59 - ETA: 0s - loss: 0.9391 - accuracy: 0.59 - ETA: 0s - loss: 0.9383 - accuracy: 0.59 - ETA: 0s - loss: 0.9471 - accuracy: 0.58 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9253 - accuracy: 0.60 - ETA: 0s - loss: 0.9066 - accuracy: 0.62 - ETA: 0s - loss: 0.9187 - accuracy: 0.61 - ETA: 0s - loss: 0.9349 - accuracy: 0.59 - ETA: 0s - loss: 0.9371 - accuracy: 0.59 - ETA: 0s - loss: 0.9420 - accuracy: 0.59 - ETA: 0s - loss: 0.9431 - accuracy: 0.59 - ETA: 0s - loss: 0.9446 - accuracy: 0.5889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00252: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9446 - accuracy: 0.5889 - val_loss: 1.0188 - val_accuracy: 0.5002 - lr: 0.0032\n",
      "Epoch 253/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0045 - accuracy: 0.52 - ETA: 0s - loss: 1.0097 - accuracy: 0.51 - ETA: 0s - loss: 1.0012 - accuracy: 0.53 - ETA: 0s - loss: 0.9698 - accuracy: 0.55 - ETA: 0s - loss: 0.9613 - accuracy: 0.57 - ETA: 0s - loss: 0.9445 - accuracy: 0.58 - ETA: 0s - loss: 0.9397 - accuracy: 0.59 - ETA: 0s - loss: 0.9391 - accuracy: 0.59 - ETA: 0s - loss: 0.9383 - accuracy: 0.59 - ETA: 0s - loss: 0.9471 - accuracy: 0.58 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9253 - accuracy: 0.60 - ETA: 0s - loss: 0.9066 - accuracy: 0.62 - ETA: 0s - loss: 0.9187 - accuracy: 0.61 - ETA: 0s - loss: 0.9349 - accuracy: 0.59 - ETA: 0s - loss: 0.9371 - accuracy: 0.59 - ETA: 0s - loss: 0.9420 - accuracy: 0.59 - ETA: 0s - loss: 0.9431 - accuracy: 0.59 - ETA: 0s - loss: 0.9446 - accuracy: 0.5889\n",
      "Epoch 00253: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9446 - accuracy: 0.5889 - val_loss: 1.0188 - val_accuracy: 0.5002 - lr: 0.0032\n",
      "Epoch 254/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0045 - accuracy: 0.52 - ETA: 0s - loss: 1.0097 - accuracy: 0.51 - ETA: 0s - loss: 1.0012 - accuracy: 0.53 - ETA: 0s - loss: 0.9698 - accuracy: 0.55 - ETA: 0s - loss: 0.9613 - accuracy: 0.57 - ETA: 0s - loss: 0.9445 - accuracy: 0.58 - ETA: 0s - loss: 0.9397 - accuracy: 0.59 - ETA: 0s - loss: 0.9391 - accuracy: 0.59 - ETA: 0s - loss: 0.9383 - accuracy: 0.59 - ETA: 0s - loss: 0.9471 - accuracy: 0.58 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9253 - accuracy: 0.60 - ETA: 0s - loss: 0.9066 - accuracy: 0.62 - ETA: 0s - loss: 0.9187 - accuracy: 0.61 - ETA: 0s - loss: 0.9349 - accuracy: 0.59 - ETA: 0s - loss: 0.9371 - accuracy: 0.59 - ETA: 0s - loss: 0.9420 - accuracy: 0.59 - ETA: 0s - loss: 0.9431 - accuracy: 0.59 - ETA: 0s - loss: 0.9446 - accuracy: 0.5889\n",
      "Epoch 00254: val_loss did not improve from 1.01430\n",
      "\n",
      "Epoch 00254: ReduceLROnPlateau reducing learning rate to 0.00253327451646328.\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9446 - accuracy: 0.5889 - val_loss: 1.0188 - val_accuracy: 0.5002 - lr: 0.0032\n",
      "Epoch 255/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0045 - accuracy: 0.52 - ETA: 0s - loss: 1.0097 - accuracy: 0.51 - ETA: 0s - loss: 1.0012 - accuracy: 0.53 - ETA: 0s - loss: 0.9698 - accuracy: 0.55 - ETA: 0s - loss: 0.9613 - accuracy: 0.57 - ETA: 0s - loss: 0.9444 - accuracy: 0.58 - ETA: 0s - loss: 0.9397 - accuracy: 0.59 - ETA: 0s - loss: 0.9391 - accuracy: 0.59 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9471 - accuracy: 0.58 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9252 - accuracy: 0.60 - ETA: 0s - loss: 0.9065 - accuracy: 0.62 - ETA: 0s - loss: 0.9186 - accuracy: 0.61 - ETA: 0s - loss: 0.9348 - accuracy: 0.59 - ETA: 0s - loss: 0.9370 - accuracy: 0.59 - ETA: 0s - loss: 0.9419 - accuracy: 0.59 - ETA: 0s - loss: 0.9429 - accuracy: 0.59 - ETA: 0s - loss: 0.9445 - accuracy: 0.5889\n",
      "Epoch 00255: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9445 - accuracy: 0.5889 - val_loss: 1.0187 - val_accuracy: 0.5002 - lr: 0.0025\n",
      "Epoch 256/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0045 - accuracy: 0.52 - ETA: 0s - loss: 1.0096 - accuracy: 0.51 - ETA: 0s - loss: 1.0011 - accuracy: 0.53 - ETA: 0s - loss: 0.9698 - accuracy: 0.55 - ETA: 0s - loss: 0.9613 - accuracy: 0.57 - ETA: 0s - loss: 0.9444 - accuracy: 0.58 - ETA: 0s - loss: 0.9397 - accuracy: 0.59 - ETA: 0s - loss: 0.9391 - accuracy: 0.59 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9471 - accuracy: 0.58 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9252 - accuracy: 0.60 - ETA: 0s - loss: 0.9065 - accuracy: 0.62 - ETA: 0s - loss: 0.9186 - accuracy: 0.61 - ETA: 0s - loss: 0.9348 - accuracy: 0.59 - ETA: 0s - loss: 0.9370 - accuracy: 0.59 - ETA: 0s - loss: 0.9419 - accuracy: 0.59 - ETA: 0s - loss: 0.9430 - accuracy: 0.59 - ETA: 0s - loss: 0.9445 - accuracy: 0.5889\n",
      "Epoch 00256: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9445 - accuracy: 0.5889 - val_loss: 1.0186 - val_accuracy: 0.5002 - lr: 0.0025\n",
      "Epoch 257/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0096 - accuracy: 0.51 - ETA: 0s - loss: 1.0011 - accuracy: 0.53 - ETA: 0s - loss: 0.9698 - accuracy: 0.55 - ETA: 0s - loss: 0.9613 - accuracy: 0.57 - ETA: 0s - loss: 0.9444 - accuracy: 0.58 - ETA: 0s - loss: 0.9397 - accuracy: 0.59 - ETA: 0s - loss: 0.9391 - accuracy: 0.59 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9471 - accuracy: 0.58 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9252 - accuracy: 0.60 - ETA: 0s - loss: 0.9065 - accuracy: 0.62 - ETA: 0s - loss: 0.9186 - accuracy: 0.61 - ETA: 0s - loss: 0.9348 - accuracy: 0.59 - ETA: 0s - loss: 0.9370 - accuracy: 0.59 - ETA: 0s - loss: 0.9419 - accuracy: 0.59 - ETA: 0s - loss: 0.9430 - accuracy: 0.59 - ETA: 0s - loss: 0.9445 - accuracy: 0.5889\n",
      "Epoch 00257: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9445 - accuracy: 0.5889 - val_loss: 1.0186 - val_accuracy: 0.5002 - lr: 0.0025\n",
      "Epoch 258/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0096 - accuracy: 0.51 - ETA: 0s - loss: 1.0011 - accuracy: 0.53 - ETA: 0s - loss: 0.9698 - accuracy: 0.55 - ETA: 0s - loss: 0.9613 - accuracy: 0.57 - ETA: 0s - loss: 0.9444 - accuracy: 0.58 - ETA: 0s - loss: 0.9397 - accuracy: 0.59 - ETA: 0s - loss: 0.9391 - accuracy: 0.59 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9471 - accuracy: 0.58 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9252 - accuracy: 0.60 - ETA: 0s - loss: 0.9065 - accuracy: 0.62 - ETA: 0s - loss: 0.9186 - accuracy: 0.61 - ETA: 0s - loss: 0.9348 - accuracy: 0.59 - ETA: 0s - loss: 0.9370 - accuracy: 0.59 - ETA: 0s - loss: 0.9419 - accuracy: 0.59 - ETA: 0s - loss: 0.9429 - accuracy: 0.59 - ETA: 0s - loss: 0.9445 - accuracy: 0.5889\n",
      "Epoch 00258: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9445 - accuracy: 0.5889 - val_loss: 1.0186 - val_accuracy: 0.5002 - lr: 0.0025\n",
      "Epoch 259/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0096 - accuracy: 0.51 - ETA: 0s - loss: 1.0011 - accuracy: 0.53 - ETA: 0s - loss: 0.9698 - accuracy: 0.55 - ETA: 0s - loss: 0.9613 - accuracy: 0.57 - ETA: 0s - loss: 0.9444 - accuracy: 0.58 - ETA: 0s - loss: 0.9397 - accuracy: 0.59 - ETA: 0s - loss: 0.9391 - accuracy: 0.59 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9471 - accuracy: 0.58 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9252 - accuracy: 0.60 - ETA: 0s - loss: 0.9065 - accuracy: 0.62 - ETA: 0s - loss: 0.9186 - accuracy: 0.61 - ETA: 0s - loss: 0.9348 - accuracy: 0.59 - ETA: 0s - loss: 0.9370 - accuracy: 0.59 - ETA: 0s - loss: 0.9419 - accuracy: 0.59 - ETA: 0s - loss: 0.9429 - accuracy: 0.59 - ETA: 0s - loss: 0.9445 - accuracy: 0.5889\n",
      "Epoch 00259: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9445 - accuracy: 0.5889 - val_loss: 1.0186 - val_accuracy: 0.5002 - lr: 0.0025\n",
      "Epoch 260/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0096 - accuracy: 0.51 - ETA: 0s - loss: 1.0011 - accuracy: 0.53 - ETA: 0s - loss: 0.9698 - accuracy: 0.55 - ETA: 0s - loss: 0.9613 - accuracy: 0.57 - ETA: 0s - loss: 0.9444 - accuracy: 0.58 - ETA: 0s - loss: 0.9397 - accuracy: 0.59 - ETA: 0s - loss: 0.9391 - accuracy: 0.59 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9471 - accuracy: 0.58 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9252 - accuracy: 0.60 - ETA: 0s - loss: 0.9065 - accuracy: 0.62 - ETA: 0s - loss: 0.9186 - accuracy: 0.61 - ETA: 0s - loss: 0.9348 - accuracy: 0.59 - ETA: 0s - loss: 0.9370 - accuracy: 0.59 - ETA: 0s - loss: 0.9419 - accuracy: 0.59 - ETA: 0s - loss: 0.9429 - accuracy: 0.59 - ETA: 0s - loss: 0.9445 - accuracy: 0.5889\n",
      "Epoch 00260: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9445 - accuracy: 0.5889 - val_loss: 1.0186 - val_accuracy: 0.5002 - lr: 0.0025\n",
      "Epoch 261/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0096 - accuracy: 0.51 - ETA: 0s - loss: 1.0011 - accuracy: 0.53 - ETA: 0s - loss: 0.9698 - accuracy: 0.55 - ETA: 0s - loss: 0.9612 - accuracy: 0.57 - ETA: 0s - loss: 0.9444 - accuracy: 0.58 - ETA: 0s - loss: 0.9397 - accuracy: 0.59 - ETA: 0s - loss: 0.9391 - accuracy: 0.59 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9471 - accuracy: 0.58 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9252 - accuracy: 0.60 - ETA: 0s - loss: 0.9065 - accuracy: 0.62 - ETA: 0s - loss: 0.9186 - accuracy: 0.61 - ETA: 0s - loss: 0.9348 - accuracy: 0.59 - ETA: 0s - loss: 0.9370 - accuracy: 0.59 - ETA: 0s - loss: 0.9419 - accuracy: 0.59 - ETA: 0s - loss: 0.9429 - accuracy: 0.59 - ETA: 0s - loss: 0.9445 - accuracy: 0.5889\n",
      "Epoch 00261: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9445 - accuracy: 0.5889 - val_loss: 1.0186 - val_accuracy: 0.5002 - lr: 0.0025\n",
      "Epoch 262/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0096 - accuracy: 0.51 - ETA: 0s - loss: 1.0011 - accuracy: 0.53 - ETA: 0s - loss: 0.9698 - accuracy: 0.55 - ETA: 0s - loss: 0.9612 - accuracy: 0.57 - ETA: 0s - loss: 0.9444 - accuracy: 0.58 - ETA: 0s - loss: 0.9397 - accuracy: 0.59 - ETA: 0s - loss: 0.9391 - accuracy: 0.59 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9471 - accuracy: 0.58 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9252 - accuracy: 0.60 - ETA: 0s - loss: 0.9065 - accuracy: 0.62 - ETA: 0s - loss: 0.9186 - accuracy: 0.61 - ETA: 0s - loss: 0.9348 - accuracy: 0.59 - ETA: 0s - loss: 0.9370 - accuracy: 0.59 - ETA: 0s - loss: 0.9419 - accuracy: 0.59 - ETA: 0s - loss: 0.9429 - accuracy: 0.59 - ETA: 0s - loss: 0.9445 - accuracy: 0.5889\n",
      "Epoch 00262: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9445 - accuracy: 0.5889 - val_loss: 1.0186 - val_accuracy: 0.5002 - lr: 0.0025\n",
      "Epoch 263/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0096 - accuracy: 0.51 - ETA: 0s - loss: 1.0011 - accuracy: 0.53 - ETA: 0s - loss: 0.9698 - accuracy: 0.55 - ETA: 0s - loss: 0.9612 - accuracy: 0.57 - ETA: 0s - loss: 0.9444 - accuracy: 0.58 - ETA: 0s - loss: 0.9397 - accuracy: 0.59 - ETA: 0s - loss: 0.9391 - accuracy: 0.59 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9471 - accuracy: 0.58 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9252 - accuracy: 0.60 - ETA: 0s - loss: 0.9065 - accuracy: 0.62 - ETA: 0s - loss: 0.9186 - accuracy: 0.61 - ETA: 0s - loss: 0.9348 - accuracy: 0.59 - ETA: 0s - loss: 0.9370 - accuracy: 0.59 - ETA: 0s - loss: 0.9419 - accuracy: 0.59 - ETA: 0s - loss: 0.9429 - accuracy: 0.59 - ETA: 0s - loss: 0.9445 - accuracy: 0.5889\n",
      "Epoch 00263: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9445 - accuracy: 0.5889 - val_loss: 1.0186 - val_accuracy: 0.5002 - lr: 0.0025\n",
      "Epoch 264/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0096 - accuracy: 0.51 - ETA: 0s - loss: 1.0011 - accuracy: 0.53 - ETA: 0s - loss: 0.9698 - accuracy: 0.55 - ETA: 0s - loss: 0.9612 - accuracy: 0.56 - ETA: 0s - loss: 0.9444 - accuracy: 0.58 - ETA: 0s - loss: 0.9397 - accuracy: 0.59 - ETA: 0s - loss: 0.9391 - accuracy: 0.59 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9471 - accuracy: 0.58 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9252 - accuracy: 0.60 - ETA: 0s - loss: 0.9065 - accuracy: 0.62 - ETA: 0s - loss: 0.9186 - accuracy: 0.61 - ETA: 0s - loss: 0.9348 - accuracy: 0.59 - ETA: 0s - loss: 0.9370 - accuracy: 0.59 - ETA: 0s - loss: 0.9419 - accuracy: 0.59 - ETA: 0s - loss: 0.9429 - accuracy: 0.59 - ETA: 0s - loss: 0.9445 - accuracy: 0.5887\n",
      "Epoch 00264: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9445 - accuracy: 0.5887 - val_loss: 1.0186 - val_accuracy: 0.5002 - lr: 0.0025\n",
      "Epoch 265/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0096 - accuracy: 0.51 - ETA: 0s - loss: 1.0011 - accuracy: 0.53 - ETA: 0s - loss: 0.9698 - accuracy: 0.55 - ETA: 0s - loss: 0.9612 - accuracy: 0.56 - ETA: 0s - loss: 0.9444 - accuracy: 0.58 - ETA: 0s - loss: 0.9397 - accuracy: 0.59 - ETA: 0s - loss: 0.9391 - accuracy: 0.59 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9471 - accuracy: 0.58 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9252 - accuracy: 0.60 - ETA: 0s - loss: 0.9065 - accuracy: 0.62 - ETA: 0s - loss: 0.9186 - accuracy: 0.61 - ETA: 0s - loss: 0.9348 - accuracy: 0.59 - ETA: 0s - loss: 0.9370 - accuracy: 0.59 - ETA: 0s - loss: 0.9419 - accuracy: 0.59 - ETA: 0s - loss: 0.9429 - accuracy: 0.59 - ETA: 0s - loss: 0.9445 - accuracy: 0.5887\n",
      "Epoch 00265: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9445 - accuracy: 0.5887 - val_loss: 1.0186 - val_accuracy: 0.5002 - lr: 0.0025\n",
      "Epoch 266/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0096 - accuracy: 0.51 - ETA: 0s - loss: 1.0011 - accuracy: 0.53 - ETA: 0s - loss: 0.9698 - accuracy: 0.55 - ETA: 0s - loss: 0.9612 - accuracy: 0.56 - ETA: 0s - loss: 0.9444 - accuracy: 0.58 - ETA: 0s - loss: 0.9397 - accuracy: 0.59 - ETA: 0s - loss: 0.9391 - accuracy: 0.59 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9471 - accuracy: 0.58 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9252 - accuracy: 0.60 - ETA: 0s - loss: 0.9065 - accuracy: 0.62 - ETA: 0s - loss: 0.9186 - accuracy: 0.61 - ETA: 0s - loss: 0.9348 - accuracy: 0.59 - ETA: 0s - loss: 0.9370 - accuracy: 0.59 - ETA: 0s - loss: 0.9419 - accuracy: 0.59 - ETA: 0s - loss: 0.9429 - accuracy: 0.59 - ETA: 0s - loss: 0.9445 - accuracy: 0.5887\n",
      "Epoch 00266: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9445 - accuracy: 0.5887 - val_loss: 1.0186 - val_accuracy: 0.5002 - lr: 0.0025\n",
      "Epoch 267/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0096 - accuracy: 0.51 - ETA: 0s - loss: 1.0011 - accuracy: 0.53 - ETA: 0s - loss: 0.9698 - accuracy: 0.55 - ETA: 0s - loss: 0.9612 - accuracy: 0.56 - ETA: 0s - loss: 0.9444 - accuracy: 0.58 - ETA: 0s - loss: 0.9397 - accuracy: 0.59 - ETA: 0s - loss: 0.9391 - accuracy: 0.59 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9471 - accuracy: 0.58 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9252 - accuracy: 0.60 - ETA: 0s - loss: 0.9065 - accuracy: 0.62 - ETA: 0s - loss: 0.9186 - accuracy: 0.61 - ETA: 0s - loss: 0.9348 - accuracy: 0.59 - ETA: 0s - loss: 0.9370 - accuracy: 0.59 - ETA: 0s - loss: 0.9419 - accuracy: 0.59 - ETA: 0s - loss: 0.9429 - accuracy: 0.59 - ETA: 0s - loss: 0.9445 - accuracy: 0.5887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00267: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9445 - accuracy: 0.5887 - val_loss: 1.0186 - val_accuracy: 0.5002 - lr: 0.0025\n",
      "Epoch 268/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0096 - accuracy: 0.51 - ETA: 0s - loss: 1.0011 - accuracy: 0.53 - ETA: 0s - loss: 0.9698 - accuracy: 0.55 - ETA: 0s - loss: 0.9612 - accuracy: 0.56 - ETA: 0s - loss: 0.9444 - accuracy: 0.58 - ETA: 0s - loss: 0.9397 - accuracy: 0.59 - ETA: 0s - loss: 0.9391 - accuracy: 0.59 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9471 - accuracy: 0.58 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9252 - accuracy: 0.60 - ETA: 0s - loss: 0.9065 - accuracy: 0.62 - ETA: 0s - loss: 0.9186 - accuracy: 0.61 - ETA: 0s - loss: 0.9348 - accuracy: 0.59 - ETA: 0s - loss: 0.9370 - accuracy: 0.59 - ETA: 0s - loss: 0.9419 - accuracy: 0.59 - ETA: 0s - loss: 0.9429 - accuracy: 0.59 - ETA: 0s - loss: 0.9445 - accuracy: 0.5887\n",
      "Epoch 00268: val_loss did not improve from 1.01430\n",
      "\n",
      "Epoch 00268: ReduceLROnPlateau reducing learning rate to 0.002026619575917721.\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9445 - accuracy: 0.5887 - val_loss: 1.0186 - val_accuracy: 0.5002 - lr: 0.0025\n",
      "Epoch 269/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0096 - accuracy: 0.51 - ETA: 0s - loss: 1.0011 - accuracy: 0.53 - ETA: 0s - loss: 0.9697 - accuracy: 0.55 - ETA: 0s - loss: 0.9612 - accuracy: 0.56 - ETA: 0s - loss: 0.9443 - accuracy: 0.58 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9390 - accuracy: 0.59 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.58 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9251 - accuracy: 0.60 - ETA: 0s - loss: 0.9064 - accuracy: 0.62 - ETA: 0s - loss: 0.9185 - accuracy: 0.61 - ETA: 0s - loss: 0.9347 - accuracy: 0.59 - ETA: 0s - loss: 0.9369 - accuracy: 0.59 - ETA: 0s - loss: 0.9418 - accuracy: 0.59 - ETA: 0s - loss: 0.9429 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.5888\n",
      "Epoch 00269: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9444 - accuracy: 0.5888 - val_loss: 1.0185 - val_accuracy: 0.5003 - lr: 0.0020\n",
      "Epoch 270/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0096 - accuracy: 0.51 - ETA: 0s - loss: 1.0011 - accuracy: 0.53 - ETA: 0s - loss: 0.9697 - accuracy: 0.55 - ETA: 0s - loss: 0.9612 - accuracy: 0.56 - ETA: 0s - loss: 0.9443 - accuracy: 0.58 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9390 - accuracy: 0.59 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.58 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9251 - accuracy: 0.60 - ETA: 0s - loss: 0.9065 - accuracy: 0.62 - ETA: 0s - loss: 0.9185 - accuracy: 0.61 - ETA: 0s - loss: 0.9347 - accuracy: 0.59 - ETA: 0s - loss: 0.9369 - accuracy: 0.59 - ETA: 0s - loss: 0.9418 - accuracy: 0.59 - ETA: 0s - loss: 0.9429 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.5888\n",
      "Epoch 00270: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9444 - accuracy: 0.5888 - val_loss: 1.0185 - val_accuracy: 0.5003 - lr: 0.0020\n",
      "Epoch 271/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0095 - accuracy: 0.51 - ETA: 0s - loss: 1.0011 - accuracy: 0.53 - ETA: 0s - loss: 0.9697 - accuracy: 0.55 - ETA: 0s - loss: 0.9612 - accuracy: 0.56 - ETA: 0s - loss: 0.9443 - accuracy: 0.58 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9390 - accuracy: 0.59 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.58 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9251 - accuracy: 0.60 - ETA: 0s - loss: 0.9065 - accuracy: 0.62 - ETA: 0s - loss: 0.9185 - accuracy: 0.61 - ETA: 0s - loss: 0.9347 - accuracy: 0.59 - ETA: 0s - loss: 0.9369 - accuracy: 0.59 - ETA: 0s - loss: 0.9418 - accuracy: 0.59 - ETA: 0s - loss: 0.9429 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.5888\n",
      "Epoch 00271: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9444 - accuracy: 0.5888 - val_loss: 1.0185 - val_accuracy: 0.5003 - lr: 0.0020\n",
      "Epoch 272/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0095 - accuracy: 0.51 - ETA: 0s - loss: 1.0011 - accuracy: 0.53 - ETA: 0s - loss: 0.9697 - accuracy: 0.55 - ETA: 0s - loss: 0.9612 - accuracy: 0.56 - ETA: 0s - loss: 0.9443 - accuracy: 0.58 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9390 - accuracy: 0.59 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.58 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9251 - accuracy: 0.60 - ETA: 0s - loss: 0.9065 - accuracy: 0.62 - ETA: 0s - loss: 0.9185 - accuracy: 0.61 - ETA: 0s - loss: 0.9347 - accuracy: 0.59 - ETA: 0s - loss: 0.9369 - accuracy: 0.59 - ETA: 0s - loss: 0.9418 - accuracy: 0.59 - ETA: 0s - loss: 0.9429 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.5888\n",
      "Epoch 00272: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9444 - accuracy: 0.5888 - val_loss: 1.0185 - val_accuracy: 0.5003 - lr: 0.0020\n",
      "Epoch 273/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0095 - accuracy: 0.51 - ETA: 0s - loss: 1.0011 - accuracy: 0.53 - ETA: 0s - loss: 0.9697 - accuracy: 0.55 - ETA: 0s - loss: 0.9612 - accuracy: 0.56 - ETA: 0s - loss: 0.9443 - accuracy: 0.58 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9390 - accuracy: 0.59 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.58 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9251 - accuracy: 0.60 - ETA: 0s - loss: 0.9065 - accuracy: 0.62 - ETA: 0s - loss: 0.9185 - accuracy: 0.61 - ETA: 0s - loss: 0.9347 - accuracy: 0.59 - ETA: 0s - loss: 0.9369 - accuracy: 0.59 - ETA: 0s - loss: 0.9418 - accuracy: 0.59 - ETA: 0s - loss: 0.9428 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.5888\n",
      "Epoch 00273: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9444 - accuracy: 0.5888 - val_loss: 1.0185 - val_accuracy: 0.5003 - lr: 0.0020\n",
      "Epoch 274/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0095 - accuracy: 0.51 - ETA: 0s - loss: 1.0011 - accuracy: 0.53 - ETA: 0s - loss: 0.9697 - accuracy: 0.55 - ETA: 0s - loss: 0.9612 - accuracy: 0.56 - ETA: 0s - loss: 0.9443 - accuracy: 0.58 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9390 - accuracy: 0.59 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.58 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9251 - accuracy: 0.60 - ETA: 0s - loss: 0.9065 - accuracy: 0.62 - ETA: 0s - loss: 0.9185 - accuracy: 0.61 - ETA: 0s - loss: 0.9347 - accuracy: 0.59 - ETA: 0s - loss: 0.9369 - accuracy: 0.59 - ETA: 0s - loss: 0.9418 - accuracy: 0.59 - ETA: 0s - loss: 0.9428 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.5888\n",
      "Epoch 00274: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9444 - accuracy: 0.5888 - val_loss: 1.0185 - val_accuracy: 0.5003 - lr: 0.0020\n",
      "Epoch 275/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0095 - accuracy: 0.51 - ETA: 0s - loss: 1.0011 - accuracy: 0.53 - ETA: 0s - loss: 0.9697 - accuracy: 0.55 - ETA: 0s - loss: 0.9612 - accuracy: 0.56 - ETA: 0s - loss: 0.9443 - accuracy: 0.58 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9390 - accuracy: 0.59 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.58 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9251 - accuracy: 0.60 - ETA: 0s - loss: 0.9065 - accuracy: 0.62 - ETA: 0s - loss: 0.9185 - accuracy: 0.61 - ETA: 0s - loss: 0.9347 - accuracy: 0.59 - ETA: 0s - loss: 0.9369 - accuracy: 0.59 - ETA: 0s - loss: 0.9418 - accuracy: 0.59 - ETA: 0s - loss: 0.9428 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.5888\n",
      "Epoch 00275: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9444 - accuracy: 0.5888 - val_loss: 1.0185 - val_accuracy: 0.5003 - lr: 0.0020\n",
      "Epoch 276/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0095 - accuracy: 0.51 - ETA: 0s - loss: 1.0011 - accuracy: 0.53 - ETA: 0s - loss: 0.9697 - accuracy: 0.55 - ETA: 0s - loss: 0.9612 - accuracy: 0.56 - ETA: 0s - loss: 0.9443 - accuracy: 0.58 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9390 - accuracy: 0.59 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.58 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9251 - accuracy: 0.60 - ETA: 0s - loss: 0.9065 - accuracy: 0.62 - ETA: 0s - loss: 0.9185 - accuracy: 0.61 - ETA: 0s - loss: 0.9347 - accuracy: 0.59 - ETA: 0s - loss: 0.9369 - accuracy: 0.59 - ETA: 0s - loss: 0.9418 - accuracy: 0.59 - ETA: 0s - loss: 0.9428 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.5888\n",
      "Epoch 00276: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9444 - accuracy: 0.5888 - val_loss: 1.0185 - val_accuracy: 0.5003 - lr: 0.0020\n",
      "Epoch 277/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0095 - accuracy: 0.51 - ETA: 0s - loss: 1.0011 - accuracy: 0.53 - ETA: 0s - loss: 0.9697 - accuracy: 0.55 - ETA: 0s - loss: 0.9612 - accuracy: 0.56 - ETA: 0s - loss: 0.9443 - accuracy: 0.58 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9390 - accuracy: 0.59 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.58 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9251 - accuracy: 0.60 - ETA: 0s - loss: 0.9065 - accuracy: 0.62 - ETA: 0s - loss: 0.9185 - accuracy: 0.61 - ETA: 0s - loss: 0.9347 - accuracy: 0.59 - ETA: 0s - loss: 0.9369 - accuracy: 0.59 - ETA: 0s - loss: 0.9418 - accuracy: 0.59 - ETA: 0s - loss: 0.9428 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.5888\n",
      "Epoch 00277: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9444 - accuracy: 0.5888 - val_loss: 1.0185 - val_accuracy: 0.5002 - lr: 0.0020\n",
      "Epoch 278/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0095 - accuracy: 0.51 - ETA: 0s - loss: 1.0011 - accuracy: 0.53 - ETA: 0s - loss: 0.9697 - accuracy: 0.55 - ETA: 0s - loss: 0.9612 - accuracy: 0.56 - ETA: 0s - loss: 0.9443 - accuracy: 0.58 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9390 - accuracy: 0.59 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.58 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9251 - accuracy: 0.60 - ETA: 0s - loss: 0.9065 - accuracy: 0.62 - ETA: 0s - loss: 0.9185 - accuracy: 0.61 - ETA: 0s - loss: 0.9347 - accuracy: 0.59 - ETA: 0s - loss: 0.9369 - accuracy: 0.59 - ETA: 0s - loss: 0.9418 - accuracy: 0.59 - ETA: 0s - loss: 0.9428 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.5888\n",
      "Epoch 00278: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9444 - accuracy: 0.5888 - val_loss: 1.0185 - val_accuracy: 0.5002 - lr: 0.0020\n",
      "Epoch 279/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0095 - accuracy: 0.51 - ETA: 0s - loss: 1.0011 - accuracy: 0.53 - ETA: 0s - loss: 0.9697 - accuracy: 0.55 - ETA: 0s - loss: 0.9612 - accuracy: 0.56 - ETA: 0s - loss: 0.9443 - accuracy: 0.58 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9390 - accuracy: 0.59 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.58 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9251 - accuracy: 0.60 - ETA: 0s - loss: 0.9065 - accuracy: 0.62 - ETA: 0s - loss: 0.9185 - accuracy: 0.61 - ETA: 0s - loss: 0.9347 - accuracy: 0.59 - ETA: 0s - loss: 0.9369 - accuracy: 0.59 - ETA: 0s - loss: 0.9418 - accuracy: 0.59 - ETA: 0s - loss: 0.9428 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.5888\n",
      "Epoch 00279: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9444 - accuracy: 0.5888 - val_loss: 1.0185 - val_accuracy: 0.5002 - lr: 0.0020\n",
      "Epoch 280/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0095 - accuracy: 0.51 - ETA: 0s - loss: 1.0011 - accuracy: 0.53 - ETA: 0s - loss: 0.9697 - accuracy: 0.55 - ETA: 0s - loss: 0.9612 - accuracy: 0.56 - ETA: 0s - loss: 0.9443 - accuracy: 0.58 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9390 - accuracy: 0.59 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.58 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9251 - accuracy: 0.60 - ETA: 0s - loss: 0.9065 - accuracy: 0.62 - ETA: 0s - loss: 0.9185 - accuracy: 0.61 - ETA: 0s - loss: 0.9347 - accuracy: 0.59 - ETA: 0s - loss: 0.9369 - accuracy: 0.59 - ETA: 0s - loss: 0.9418 - accuracy: 0.59 - ETA: 0s - loss: 0.9428 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.5888\n",
      "Epoch 00280: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9444 - accuracy: 0.5888 - val_loss: 1.0185 - val_accuracy: 0.5002 - lr: 0.0020\n",
      "Epoch 281/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0095 - accuracy: 0.51 - ETA: 0s - loss: 1.0011 - accuracy: 0.53 - ETA: 0s - loss: 0.9697 - accuracy: 0.55 - ETA: 0s - loss: 0.9612 - accuracy: 0.56 - ETA: 0s - loss: 0.9443 - accuracy: 0.58 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9390 - accuracy: 0.59 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.58 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9251 - accuracy: 0.60 - ETA: 0s - loss: 0.9065 - accuracy: 0.62 - ETA: 0s - loss: 0.9185 - accuracy: 0.61 - ETA: 0s - loss: 0.9347 - accuracy: 0.59 - ETA: 0s - loss: 0.9369 - accuracy: 0.59 - ETA: 0s - loss: 0.9418 - accuracy: 0.59 - ETA: 0s - loss: 0.9428 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.5888\n",
      "Epoch 00281: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9444 - accuracy: 0.5888 - val_loss: 1.0185 - val_accuracy: 0.5002 - lr: 0.0020\n",
      "Epoch 282/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0095 - accuracy: 0.51 - ETA: 0s - loss: 1.0011 - accuracy: 0.53 - ETA: 0s - loss: 0.9697 - accuracy: 0.55 - ETA: 0s - loss: 0.9612 - accuracy: 0.56 - ETA: 0s - loss: 0.9443 - accuracy: 0.58 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9390 - accuracy: 0.59 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.58 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9251 - accuracy: 0.60 - ETA: 0s - loss: 0.9065 - accuracy: 0.62 - ETA: 0s - loss: 0.9185 - accuracy: 0.61 - ETA: 0s - loss: 0.9347 - accuracy: 0.59 - ETA: 0s - loss: 0.9369 - accuracy: 0.59 - ETA: 0s - loss: 0.9418 - accuracy: 0.59 - ETA: 0s - loss: 0.9428 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.5888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00282: val_loss did not improve from 1.01430\n",
      "\n",
      "Epoch 00282: ReduceLROnPlateau reducing learning rate to 0.0016212956979870796.\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9444 - accuracy: 0.5888 - val_loss: 1.0185 - val_accuracy: 0.5002 - lr: 0.0020\n",
      "Epoch 283/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0095 - accuracy: 0.51 - ETA: 0s - loss: 1.0011 - accuracy: 0.53 - ETA: 0s - loss: 0.9697 - accuracy: 0.55 - ETA: 0s - loss: 0.9612 - accuracy: 0.56 - ETA: 0s - loss: 0.9443 - accuracy: 0.58 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9390 - accuracy: 0.59 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9251 - accuracy: 0.60 - ETA: 0s - loss: 0.9064 - accuracy: 0.62 - ETA: 0s - loss: 0.9184 - accuracy: 0.61 - ETA: 0s - loss: 0.9346 - accuracy: 0.59 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9417 - accuracy: 0.59 - ETA: 0s - loss: 0.9428 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.5888\n",
      "Epoch 00283: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9444 - accuracy: 0.5888 - val_loss: 1.0184 - val_accuracy: 0.5002 - lr: 0.0016\n",
      "Epoch 284/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0095 - accuracy: 0.51 - ETA: 0s - loss: 1.0011 - accuracy: 0.53 - ETA: 0s - loss: 0.9697 - accuracy: 0.55 - ETA: 0s - loss: 0.9612 - accuracy: 0.56 - ETA: 0s - loss: 0.9443 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9390 - accuracy: 0.59 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.58 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9251 - accuracy: 0.60 - ETA: 0s - loss: 0.9064 - accuracy: 0.62 - ETA: 0s - loss: 0.9184 - accuracy: 0.61 - ETA: 0s - loss: 0.9346 - accuracy: 0.59 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9417 - accuracy: 0.59 - ETA: 0s - loss: 0.9428 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.5888\n",
      "Epoch 00284: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9444 - accuracy: 0.5888 - val_loss: 1.0184 - val_accuracy: 0.5002 - lr: 0.0016\n",
      "Epoch 285/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0095 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9697 - accuracy: 0.55 - ETA: 0s - loss: 0.9612 - accuracy: 0.56 - ETA: 0s - loss: 0.9443 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9390 - accuracy: 0.59 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.58 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9251 - accuracy: 0.60 - ETA: 0s - loss: 0.9064 - accuracy: 0.62 - ETA: 0s - loss: 0.9185 - accuracy: 0.61 - ETA: 0s - loss: 0.9346 - accuracy: 0.59 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9417 - accuracy: 0.59 - ETA: 0s - loss: 0.9428 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.5888\n",
      "Epoch 00285: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9444 - accuracy: 0.5888 - val_loss: 1.0184 - val_accuracy: 0.5002 - lr: 0.0016\n",
      "Epoch 286/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0095 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9697 - accuracy: 0.55 - ETA: 0s - loss: 0.9612 - accuracy: 0.56 - ETA: 0s - loss: 0.9443 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9390 - accuracy: 0.59 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.58 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9251 - accuracy: 0.60 - ETA: 0s - loss: 0.9064 - accuracy: 0.62 - ETA: 0s - loss: 0.9185 - accuracy: 0.61 - ETA: 0s - loss: 0.9346 - accuracy: 0.59 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9417 - accuracy: 0.59 - ETA: 0s - loss: 0.9428 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.5888\n",
      "Epoch 00286: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9444 - accuracy: 0.5888 - val_loss: 1.0184 - val_accuracy: 0.5002 - lr: 0.0016\n",
      "Epoch 287/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0095 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9697 - accuracy: 0.55 - ETA: 0s - loss: 0.9612 - accuracy: 0.56 - ETA: 0s - loss: 0.9443 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9390 - accuracy: 0.59 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.58 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9251 - accuracy: 0.60 - ETA: 0s - loss: 0.9064 - accuracy: 0.62 - ETA: 0s - loss: 0.9185 - accuracy: 0.61 - ETA: 0s - loss: 0.9346 - accuracy: 0.59 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9417 - accuracy: 0.59 - ETA: 0s - loss: 0.9428 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.5888\n",
      "Epoch 00287: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9444 - accuracy: 0.5888 - val_loss: 1.0184 - val_accuracy: 0.5002 - lr: 0.0016\n",
      "Epoch 288/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0095 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9697 - accuracy: 0.55 - ETA: 0s - loss: 0.9612 - accuracy: 0.56 - ETA: 0s - loss: 0.9443 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9251 - accuracy: 0.60 - ETA: 0s - loss: 0.9064 - accuracy: 0.62 - ETA: 0s - loss: 0.9185 - accuracy: 0.61 - ETA: 0s - loss: 0.9346 - accuracy: 0.59 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9417 - accuracy: 0.59 - ETA: 0s - loss: 0.9428 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.5888\n",
      "Epoch 00288: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9444 - accuracy: 0.5888 - val_loss: 1.0184 - val_accuracy: 0.5002 - lr: 0.0016\n",
      "Epoch 289/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0095 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9697 - accuracy: 0.55 - ETA: 0s - loss: 0.9612 - accuracy: 0.56 - ETA: 0s - loss: 0.9443 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9251 - accuracy: 0.60 - ETA: 0s - loss: 0.9064 - accuracy: 0.62 - ETA: 0s - loss: 0.9185 - accuracy: 0.61 - ETA: 0s - loss: 0.9346 - accuracy: 0.59 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9417 - accuracy: 0.59 - ETA: 0s - loss: 0.9428 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.5888\n",
      "Epoch 00289: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9444 - accuracy: 0.5888 - val_loss: 1.0184 - val_accuracy: 0.5002 - lr: 0.0016\n",
      "Epoch 290/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0095 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9697 - accuracy: 0.55 - ETA: 0s - loss: 0.9612 - accuracy: 0.56 - ETA: 0s - loss: 0.9442 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9251 - accuracy: 0.60 - ETA: 0s - loss: 0.9064 - accuracy: 0.62 - ETA: 0s - loss: 0.9185 - accuracy: 0.61 - ETA: 0s - loss: 0.9346 - accuracy: 0.59 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9417 - accuracy: 0.59 - ETA: 0s - loss: 0.9428 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.5888\n",
      "Epoch 00290: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9444 - accuracy: 0.5888 - val_loss: 1.0184 - val_accuracy: 0.5002 - lr: 0.0016\n",
      "Epoch 291/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0095 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9697 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9442 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9251 - accuracy: 0.60 - ETA: 0s - loss: 0.9064 - accuracy: 0.62 - ETA: 0s - loss: 0.9185 - accuracy: 0.61 - ETA: 0s - loss: 0.9346 - accuracy: 0.59 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9417 - accuracy: 0.59 - ETA: 0s - loss: 0.9428 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.5887\n",
      "Epoch 00291: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9444 - accuracy: 0.5887 - val_loss: 1.0184 - val_accuracy: 0.5002 - lr: 0.0016\n",
      "Epoch 292/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0095 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9697 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9442 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9251 - accuracy: 0.60 - ETA: 0s - loss: 0.9064 - accuracy: 0.62 - ETA: 0s - loss: 0.9185 - accuracy: 0.61 - ETA: 0s - loss: 0.9346 - accuracy: 0.59 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9417 - accuracy: 0.59 - ETA: 0s - loss: 0.9428 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.5887\n",
      "Epoch 00292: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9444 - accuracy: 0.5887 - val_loss: 1.0184 - val_accuracy: 0.5002 - lr: 0.0016\n",
      "Epoch 293/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0095 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9697 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9442 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9251 - accuracy: 0.60 - ETA: 0s - loss: 0.9064 - accuracy: 0.62 - ETA: 0s - loss: 0.9184 - accuracy: 0.61 - ETA: 0s - loss: 0.9346 - accuracy: 0.59 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9417 - accuracy: 0.59 - ETA: 0s - loss: 0.9428 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.5887\n",
      "Epoch 00293: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9444 - accuracy: 0.5887 - val_loss: 1.0184 - val_accuracy: 0.5002 - lr: 0.0016\n",
      "Epoch 294/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0095 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9697 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9442 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9251 - accuracy: 0.60 - ETA: 0s - loss: 0.9064 - accuracy: 0.62 - ETA: 0s - loss: 0.9184 - accuracy: 0.61 - ETA: 0s - loss: 0.9346 - accuracy: 0.59 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9417 - accuracy: 0.59 - ETA: 0s - loss: 0.9428 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.5887\n",
      "Epoch 00294: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9444 - accuracy: 0.5887 - val_loss: 1.0184 - val_accuracy: 0.5002 - lr: 0.0016\n",
      "Epoch 295/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0094 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9697 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9442 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9251 - accuracy: 0.60 - ETA: 0s - loss: 0.9064 - accuracy: 0.62 - ETA: 0s - loss: 0.9184 - accuracy: 0.61 - ETA: 0s - loss: 0.9346 - accuracy: 0.59 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9417 - accuracy: 0.59 - ETA: 0s - loss: 0.9428 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.5887\n",
      "Epoch 00295: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9444 - accuracy: 0.5887 - val_loss: 1.0184 - val_accuracy: 0.5002 - lr: 0.0016\n",
      "Epoch 296/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0094 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9697 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9442 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9251 - accuracy: 0.60 - ETA: 0s - loss: 0.9064 - accuracy: 0.62 - ETA: 0s - loss: 0.9184 - accuracy: 0.61 - ETA: 0s - loss: 0.9346 - accuracy: 0.59 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9417 - accuracy: 0.59 - ETA: 0s - loss: 0.9428 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.5887\n",
      "Epoch 00296: val_loss did not improve from 1.01430\n",
      "\n",
      "Epoch 00296: ReduceLROnPlateau reducing learning rate to 0.0012970365583896638.\n",
      "19/19 [==============================] - 2s 84ms/step - loss: 0.9444 - accuracy: 0.5887 - val_loss: 1.0184 - val_accuracy: 0.5002 - lr: 0.0016\n",
      "Epoch 297/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0095 - accuracy: 0.51 - ETA: 0s - loss: 1.0011 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9442 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9184 - accuracy: 0.61 - ETA: 0s - loss: 0.9345 - accuracy: 0.59 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9443 - accuracy: 0.5887\n",
      "Epoch 00297: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9443 - accuracy: 0.5887 - val_loss: 1.0183 - val_accuracy: 0.5002 - lr: 0.0013\n",
      "Epoch 298/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0094 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9442 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9184 - accuracy: 0.61 - ETA: 0s - loss: 0.9345 - accuracy: 0.59 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9443 - accuracy: 0.5887\n",
      "Epoch 00298: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9443 - accuracy: 0.5887 - val_loss: 1.0183 - val_accuracy: 0.5002 - lr: 0.0013\n",
      "Epoch 299/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0094 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9442 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9064 - accuracy: 0.62 - ETA: 0s - loss: 0.9184 - accuracy: 0.61 - ETA: 0s - loss: 0.9345 - accuracy: 0.59 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9443 - accuracy: 0.5887\n",
      "Epoch 00299: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9443 - accuracy: 0.5887 - val_loss: 1.0183 - val_accuracy: 0.5002 - lr: 0.0013\n",
      "Epoch 300/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0094 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9442 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9064 - accuracy: 0.62 - ETA: 0s - loss: 0.9184 - accuracy: 0.61 - ETA: 0s - loss: 0.9345 - accuracy: 0.59 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9443 - accuracy: 0.5887\n",
      "Epoch 00300: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9443 - accuracy: 0.5887 - val_loss: 1.0183 - val_accuracy: 0.5002 - lr: 0.0013\n",
      "Epoch 301/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0094 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9442 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9064 - accuracy: 0.62 - ETA: 0s - loss: 0.9184 - accuracy: 0.61 - ETA: 0s - loss: 0.9345 - accuracy: 0.59 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9443 - accuracy: 0.5887\n",
      "Epoch 00301: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9443 - accuracy: 0.5887 - val_loss: 1.0183 - val_accuracy: 0.5002 - lr: 0.0013\n",
      "Epoch 302/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0094 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9442 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9064 - accuracy: 0.62 - ETA: 0s - loss: 0.9184 - accuracy: 0.61 - ETA: 0s - loss: 0.9345 - accuracy: 0.59 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9443 - accuracy: 0.5887\n",
      "Epoch 00302: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9443 - accuracy: 0.5887 - val_loss: 1.0183 - val_accuracy: 0.5002 - lr: 0.0013\n",
      "Epoch 303/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0094 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9442 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9064 - accuracy: 0.62 - ETA: 0s - loss: 0.9184 - accuracy: 0.61 - ETA: 0s - loss: 0.9345 - accuracy: 0.59 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9443 - accuracy: 0.5887\n",
      "Epoch 00303: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9443 - accuracy: 0.5887 - val_loss: 1.0183 - val_accuracy: 0.5002 - lr: 0.0013\n",
      "Epoch 304/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0094 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9442 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9064 - accuracy: 0.62 - ETA: 0s - loss: 0.9184 - accuracy: 0.61 - ETA: 0s - loss: 0.9345 - accuracy: 0.59 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9443 - accuracy: 0.5887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00304: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9443 - accuracy: 0.5887 - val_loss: 1.0183 - val_accuracy: 0.5002 - lr: 0.0013\n",
      "Epoch 305/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0094 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9442 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9064 - accuracy: 0.62 - ETA: 0s - loss: 0.9184 - accuracy: 0.61 - ETA: 0s - loss: 0.9345 - accuracy: 0.59 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9443 - accuracy: 0.5887\n",
      "Epoch 00305: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9443 - accuracy: 0.5887 - val_loss: 1.0183 - val_accuracy: 0.5002 - lr: 0.0013\n",
      "Epoch 306/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0094 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9442 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9064 - accuracy: 0.62 - ETA: 0s - loss: 0.9184 - accuracy: 0.61 - ETA: 0s - loss: 0.9345 - accuracy: 0.59 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9443 - accuracy: 0.5887\n",
      "Epoch 00306: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9443 - accuracy: 0.5887 - val_loss: 1.0183 - val_accuracy: 0.5002 - lr: 0.0013\n",
      "Epoch 307/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0094 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9442 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9064 - accuracy: 0.62 - ETA: 0s - loss: 0.9184 - accuracy: 0.61 - ETA: 0s - loss: 0.9345 - accuracy: 0.59 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9443 - accuracy: 0.5887\n",
      "Epoch 00307: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9443 - accuracy: 0.5887 - val_loss: 1.0183 - val_accuracy: 0.5002 - lr: 0.0013\n",
      "Epoch 308/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0094 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9442 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9064 - accuracy: 0.62 - ETA: 0s - loss: 0.9184 - accuracy: 0.61 - ETA: 0s - loss: 0.9345 - accuracy: 0.59 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9443 - accuracy: 0.5887\n",
      "Epoch 00308: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9443 - accuracy: 0.5887 - val_loss: 1.0183 - val_accuracy: 0.5002 - lr: 0.0013\n",
      "Epoch 309/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0094 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9442 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9064 - accuracy: 0.62 - ETA: 0s - loss: 0.9184 - accuracy: 0.61 - ETA: 0s - loss: 0.9345 - accuracy: 0.59 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9443 - accuracy: 0.5887\n",
      "Epoch 00309: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9443 - accuracy: 0.5887 - val_loss: 1.0183 - val_accuracy: 0.5002 - lr: 0.0013\n",
      "Epoch 310/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0094 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9442 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9064 - accuracy: 0.62 - ETA: 0s - loss: 0.9184 - accuracy: 0.61 - ETA: 0s - loss: 0.9345 - accuracy: 0.59 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9443 - accuracy: 0.5887\n",
      "Epoch 00310: val_loss did not improve from 1.01430\n",
      "\n",
      "Epoch 00310: ReduceLROnPlateau reducing learning rate to 0.0010376292280852796.\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9443 - accuracy: 0.5887 - val_loss: 1.0183 - val_accuracy: 0.5002 - lr: 0.0013\n",
      "Epoch 311/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0094 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9442 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9184 - accuracy: 0.61 - ETA: 0s - loss: 0.9345 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9443 - accuracy: 0.5887\n",
      "Epoch 00311: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9443 - accuracy: 0.5887 - val_loss: 1.0183 - val_accuracy: 0.5002 - lr: 0.0010\n",
      "Epoch 312/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0094 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9442 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9184 - accuracy: 0.61 - ETA: 0s - loss: 0.9345 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9443 - accuracy: 0.5887\n",
      "Epoch 00312: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9443 - accuracy: 0.5887 - val_loss: 1.0182 - val_accuracy: 0.5002 - lr: 0.0010\n",
      "Epoch 313/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0094 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9442 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9184 - accuracy: 0.61 - ETA: 0s - loss: 0.9345 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9443 - accuracy: 0.5887\n",
      "Epoch 00313: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9443 - accuracy: 0.5887 - val_loss: 1.0182 - val_accuracy: 0.5002 - lr: 0.0010\n",
      "Epoch 314/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0094 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9442 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9184 - accuracy: 0.61 - ETA: 0s - loss: 0.9345 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9443 - accuracy: 0.5887\n",
      "Epoch 00314: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9443 - accuracy: 0.5887 - val_loss: 1.0182 - val_accuracy: 0.5002 - lr: 0.0010\n",
      "Epoch 315/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0094 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9442 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9184 - accuracy: 0.61 - ETA: 0s - loss: 0.9345 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9443 - accuracy: 0.5887\n",
      "Epoch 00315: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9443 - accuracy: 0.5887 - val_loss: 1.0182 - val_accuracy: 0.5002 - lr: 0.0010\n",
      "Epoch 316/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0094 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9442 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9184 - accuracy: 0.61 - ETA: 0s - loss: 0.9345 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9443 - accuracy: 0.5887\n",
      "Epoch 00316: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9443 - accuracy: 0.5887 - val_loss: 1.0182 - val_accuracy: 0.5002 - lr: 0.0010\n",
      "Epoch 317/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0094 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9442 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9184 - accuracy: 0.61 - ETA: 0s - loss: 0.9345 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9443 - accuracy: 0.5887\n",
      "Epoch 00317: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9443 - accuracy: 0.5887 - val_loss: 1.0182 - val_accuracy: 0.5002 - lr: 0.0010\n",
      "Epoch 318/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0094 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9442 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9184 - accuracy: 0.61 - ETA: 0s - loss: 0.9345 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9443 - accuracy: 0.5887\n",
      "Epoch 00318: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9443 - accuracy: 0.5887 - val_loss: 1.0182 - val_accuracy: 0.5002 - lr: 0.0010\n",
      "Epoch 319/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0094 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9442 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9184 - accuracy: 0.61 - ETA: 0s - loss: 0.9345 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9443 - accuracy: 0.5887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00319: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9443 - accuracy: 0.5887 - val_loss: 1.0182 - val_accuracy: 0.5002 - lr: 0.0010\n",
      "Epoch 320/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0094 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9442 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9184 - accuracy: 0.61 - ETA: 0s - loss: 0.9345 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9443 - accuracy: 0.5887\n",
      "Epoch 00320: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9443 - accuracy: 0.5887 - val_loss: 1.0182 - val_accuracy: 0.5002 - lr: 0.0010\n",
      "Epoch 321/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0094 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9442 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9184 - accuracy: 0.61 - ETA: 0s - loss: 0.9345 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9443 - accuracy: 0.5887\n",
      "Epoch 00321: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9443 - accuracy: 0.5887 - val_loss: 1.0182 - val_accuracy: 0.5002 - lr: 0.0010\n",
      "Epoch 322/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0094 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9442 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9184 - accuracy: 0.61 - ETA: 0s - loss: 0.9345 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9443 - accuracy: 0.5887\n",
      "Epoch 00322: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9443 - accuracy: 0.5887 - val_loss: 1.0182 - val_accuracy: 0.5002 - lr: 0.0010\n",
      "Epoch 323/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0094 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9442 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9184 - accuracy: 0.61 - ETA: 0s - loss: 0.9345 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9443 - accuracy: 0.5887\n",
      "Epoch 00323: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9443 - accuracy: 0.5887 - val_loss: 1.0182 - val_accuracy: 0.5002 - lr: 0.0010\n",
      "Epoch 324/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0094 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9442 - accuracy: 0.58 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9184 - accuracy: 0.61 - ETA: 0s - loss: 0.9345 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9443 - accuracy: 0.5887\n",
      "Epoch 00324: val_loss did not improve from 1.01430\n",
      "\n",
      "Epoch 00324: ReduceLROnPlateau reducing learning rate to 0.0008301033638417721.\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9443 - accuracy: 0.5887 - val_loss: 1.0182 - val_accuracy: 0.5002 - lr: 0.0010\n",
      "Epoch 325/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0094 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.59 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00325: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0182 - val_accuracy: 0.5002 - lr: 8.3010e-04\n",
      "Epoch 326/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0094 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.59 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00326: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0182 - val_accuracy: 0.5002 - lr: 8.3010e-04\n",
      "Epoch 327/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0094 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.59 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00327: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0182 - val_accuracy: 0.5002 - lr: 8.3010e-04\n",
      "Epoch 328/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0094 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.59 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00328: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0182 - val_accuracy: 0.5002 - lr: 8.3010e-04\n",
      "Epoch 329/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.59 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00329: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0182 - val_accuracy: 0.5002 - lr: 8.3010e-04\n",
      "Epoch 330/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.59 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00330: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0182 - val_accuracy: 0.5002 - lr: 8.3010e-04\n",
      "Epoch 331/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.59 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00331: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0182 - val_accuracy: 0.5002 - lr: 8.3010e-04\n",
      "Epoch 332/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.59 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00332: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0182 - val_accuracy: 0.5002 - lr: 8.3010e-04\n",
      "Epoch 333/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.59 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00333: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0182 - val_accuracy: 0.5002 - lr: 8.3010e-04\n",
      "Epoch 334/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.59 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00334: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0182 - val_accuracy: 0.5002 - lr: 8.3010e-04\n",
      "Epoch 335/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.59 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00335: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0182 - val_accuracy: 0.5002 - lr: 8.3010e-04\n",
      "Epoch 336/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.59 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00336: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0182 - val_accuracy: 0.5002 - lr: 8.3010e-04\n",
      "Epoch 337/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.59 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00337: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0182 - val_accuracy: 0.5002 - lr: 8.3010e-04\n",
      "Epoch 338/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.59 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00338: val_loss did not improve from 1.01430\n",
      "\n",
      "Epoch 00338: ReduceLROnPlateau reducing learning rate to 0.000664082681760192.\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0182 - val_accuracy: 0.5002 - lr: 8.3010e-04\n",
      "Epoch 339/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.59 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00339: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5002 - lr: 6.6408e-04\n",
      "Epoch 340/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.59 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00340: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5002 - lr: 6.6408e-04\n",
      "Epoch 341/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.59 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00341: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5002 - lr: 6.6408e-04\n",
      "Epoch 342/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.59 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00342: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5002 - lr: 6.6408e-04\n",
      "Epoch 343/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.59 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00343: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5002 - lr: 6.6408e-04\n",
      "Epoch 344/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.59 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00344: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5002 - lr: 6.6408e-04\n",
      "Epoch 345/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9611 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.59 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00345: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5002 - lr: 6.6408e-04\n",
      "Epoch 346/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.59 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00346: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5002 - lr: 6.6408e-04\n",
      "Epoch 347/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.59 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00347: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5002 - lr: 6.6408e-04\n",
      "Epoch 348/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.59 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00348: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5002 - lr: 6.6408e-04\n",
      "Epoch 349/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.59 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00349: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5002 - lr: 6.6408e-04\n",
      "Epoch 350/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.59 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00350: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5002 - lr: 6.6408e-04\n",
      "Epoch 351/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.59 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00351: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5002 - lr: 6.6408e-04\n",
      "Epoch 352/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.59 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00352: val_loss did not improve from 1.01430\n",
      "\n",
      "Epoch 00352: ReduceLROnPlateau reducing learning rate to 0.0005312661640346051.\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5002 - lr: 6.6408e-04\n",
      "Epoch 353/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.58 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00353: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5002 - lr: 5.3127e-04\n",
      "Epoch 354/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.58 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00354: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5002 - lr: 5.3127e-04\n",
      "Epoch 355/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.58 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00355: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5002 - lr: 5.3127e-04\n",
      "Epoch 356/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.58 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00356: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5002 - lr: 5.3127e-04\n",
      "Epoch 357/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.58 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00357: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5002 - lr: 5.3127e-04\n",
      "Epoch 358/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.58 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00358: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5002 - lr: 5.3127e-04\n",
      "Epoch 359/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.58 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00359: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5002 - lr: 5.3127e-04\n",
      "Epoch 360/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.58 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00360: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5002 - lr: 5.3127e-04\n",
      "Epoch 361/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.58 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00361: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5000 - lr: 5.3127e-04\n",
      "Epoch 362/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.58 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00362: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5000 - lr: 5.3127e-04\n",
      "Epoch 363/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.58 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00363: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5000 - lr: 5.3127e-04\n",
      "Epoch 364/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.58 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00364: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5000 - lr: 5.3127e-04\n",
      "Epoch 365/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.58 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00365: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5000 - lr: 5.3127e-04\n",
      "Epoch 366/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.58 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00366: val_loss did not improve from 1.01430\n",
      "\n",
      "Epoch 00366: ReduceLROnPlateau reducing learning rate to 0.0004250129219144583.\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5000 - lr: 5.3127e-04\n",
      "Epoch 367/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00367: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5000 - lr: 4.2501e-04\n",
      "Epoch 368/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00368: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5000 - lr: 4.2501e-04\n",
      "Epoch 369/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00369: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5000 - lr: 4.2501e-04\n",
      "Epoch 370/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00370: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5000 - lr: 4.2501e-04\n",
      "Epoch 371/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00371: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5000 - lr: 4.2501e-04\n",
      "Epoch 372/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00372: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5000 - lr: 4.2501e-04\n",
      "Epoch 373/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00373: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5000 - lr: 4.2501e-04\n",
      "Epoch 374/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00374: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5000 - lr: 4.2501e-04\n",
      "Epoch 375/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00375: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5000 - lr: 4.2501e-04\n",
      "Epoch 376/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00376: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5000 - lr: 4.2501e-04\n",
      "Epoch 377/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00377: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5000 - lr: 4.2501e-04\n",
      "Epoch 378/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00378: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5000 - lr: 4.2501e-04\n",
      "Epoch 379/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00379: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5000 - lr: 4.2501e-04\n",
      "Epoch 380/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9442 - accuracy: 0.5887\n",
      "Epoch 00380: val_loss did not improve from 1.01430\n",
      "\n",
      "Epoch 00380: ReduceLROnPlateau reducing learning rate to 0.0003400103421881795.\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9442 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5000 - lr: 4.2501e-04\n",
      "Epoch 381/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00381: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0181 - val_accuracy: 0.5000 - lr: 3.4001e-04\n",
      "Epoch 382/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00382: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 3.4001e-04\n",
      "Epoch 383/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00383: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 3.4001e-04\n",
      "Epoch 384/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00384: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 3.4001e-04\n",
      "Epoch 385/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00385: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 3.4001e-04\n",
      "Epoch 386/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00386: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 3.4001e-04\n",
      "Epoch 387/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00387: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 3.4001e-04\n",
      "Epoch 388/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00388: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 3.4001e-04\n",
      "Epoch 389/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00389: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 3.4001e-04\n",
      "Epoch 390/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00390: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 3.4001e-04\n",
      "Epoch 391/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00391: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 3.4001e-04\n",
      "Epoch 392/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00392: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 3.4001e-04\n",
      "Epoch 393/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00393: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 3.4001e-04\n",
      "Epoch 394/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00394: val_loss did not improve from 1.01430\n",
      "\n",
      "Epoch 00394: ReduceLROnPlateau reducing learning rate to 0.00027200826443731787.\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 3.4001e-04\n",
      "Epoch 395/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00395: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 2.7201e-04\n",
      "Epoch 396/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00396: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 2.7201e-04\n",
      "Epoch 397/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00397: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 2.7201e-04\n",
      "Epoch 398/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00398: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 2.7201e-04\n",
      "Epoch 399/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00399: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 2.7201e-04\n",
      "Epoch 400/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00400: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 2.7201e-04\n",
      "Epoch 401/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00401: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 2.7201e-04\n",
      "Epoch 402/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00402: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 2.7201e-04\n",
      "Epoch 403/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00403: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 2.7201e-04\n",
      "Epoch 404/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00404: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 2.7201e-04\n",
      "Epoch 405/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00405: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 2.7201e-04\n",
      "Epoch 406/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00406: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 2.7201e-04\n",
      "Epoch 407/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00407: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 2.7201e-04\n",
      "Epoch 408/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00408: val_loss did not improve from 1.01430\n",
      "\n",
      "Epoch 00408: ReduceLROnPlateau reducing learning rate to 0.00021760661620646716.\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 2.7201e-04\n",
      "Epoch 409/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00409: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 2.1761e-04\n",
      "Epoch 410/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00410: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 2.1761e-04\n",
      "Epoch 411/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00411: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 2.1761e-04\n",
      "Epoch 412/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00412: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 2.1761e-04\n",
      "Epoch 413/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00413: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 2.1761e-04\n",
      "Epoch 414/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00414: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 2.1761e-04\n",
      "Epoch 415/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00415: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 2.1761e-04\n",
      "Epoch 416/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00416: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 2.1761e-04\n",
      "Epoch 417/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00417: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 2.1761e-04\n",
      "Epoch 418/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00418: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 2.1761e-04\n",
      "Epoch 419/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00419: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 2.1761e-04\n",
      "Epoch 420/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00420: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 2.1761e-04\n",
      "Epoch 421/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00421: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 2.1761e-04\n",
      "Epoch 422/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00422: val_loss did not improve from 1.01430\n",
      "\n",
      "Epoch 00422: ReduceLROnPlateau reducing learning rate to 0.00017408529529348016.\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 2.1761e-04\n",
      "Epoch 423/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00423: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.7409e-04\n",
      "Epoch 424/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00424: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.7409e-04\n",
      "Epoch 425/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00425: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.7409e-04\n",
      "Epoch 426/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00426: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.7409e-04\n",
      "Epoch 427/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00427: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.7409e-04\n",
      "Epoch 428/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00428: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.7409e-04\n",
      "Epoch 429/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00429: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 84ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.7409e-04\n",
      "Epoch 430/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00430: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.7409e-04\n",
      "Epoch 431/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00431: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.7409e-04\n",
      "Epoch 432/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00432: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.7409e-04\n",
      "Epoch 433/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00433: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.7409e-04\n",
      "Epoch 434/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00434: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.7409e-04\n",
      "Epoch 435/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00435: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.7409e-04\n",
      "Epoch 436/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00436: val_loss did not improve from 1.01430\n",
      "\n",
      "Epoch 00436: ReduceLROnPlateau reducing learning rate to 0.00013926823157817125.\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.7409e-04\n",
      "Epoch 437/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00437: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.3927e-04\n",
      "Epoch 438/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00438: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.3927e-04\n",
      "Epoch 439/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00439: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.3927e-04\n",
      "Epoch 440/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00440: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.3927e-04\n",
      "Epoch 441/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00441: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.3927e-04\n",
      "Epoch 442/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00442: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.3927e-04\n",
      "Epoch 443/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00443: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.3927e-04\n",
      "Epoch 444/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00444: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.3927e-04\n",
      "Epoch 445/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00445: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.3927e-04\n",
      "Epoch 446/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00446: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.3927e-04\n",
      "Epoch 447/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00447: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.3927e-04\n",
      "Epoch 448/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00448: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.3927e-04\n",
      "Epoch 449/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00449: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.3927e-04\n",
      "Epoch 450/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9441 - accuracy: 0.58 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00450: val_loss did not improve from 1.01430\n",
      "\n",
      "Epoch 00450: ReduceLROnPlateau reducing learning rate to 0.000111414585262537.\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.3927e-04\n",
      "Epoch 451/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00451: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.1141e-04\n",
      "Epoch 452/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00452: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.1141e-04\n",
      "Epoch 453/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00453: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.1141e-04\n",
      "Epoch 454/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00454: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.1141e-04\n",
      "Epoch 455/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00455: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.1141e-04\n",
      "Epoch 456/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00456: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.1141e-04\n",
      "Epoch 457/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00457: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.1141e-04\n",
      "Epoch 458/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00458: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.1141e-04\n",
      "Epoch 459/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00459: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.1141e-04\n",
      "Epoch 460/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00460: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.1141e-04\n",
      "Epoch 461/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00461: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.1141e-04\n",
      "Epoch 462/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00462: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.1141e-04\n",
      "Epoch 463/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00463: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.1141e-04\n",
      "Epoch 464/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00464: val_loss did not improve from 1.01430\n",
      "\n",
      "Epoch 00464: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.1141e-04\n",
      "Epoch 465/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00465: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 466/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00466: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 467/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00467: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 468/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00468: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 469/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00469: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 470/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00470: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 471/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00471: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 472/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00472: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 473/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00473: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 474/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00474: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 475/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00475: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 476/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00476: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 477/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00477: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 478/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00478: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 479/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00479: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 480/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00480: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 481/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00481: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 482/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00482: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 483/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00483: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 484/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00484: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 84ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 485/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00485: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 486/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00486: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 487/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00487: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 488/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00488: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 489/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00489: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 490/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00490: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 491/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00491: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 492/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00492: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 493/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00493: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 494/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00494: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 495/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00495: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 496/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00496: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 497/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00497: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 498/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00498: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 499/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00499: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 500/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00500: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 501/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00501: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 502/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00502: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 503/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00503: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 504/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00504: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 505/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00505: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 506/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00506: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 507/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00507: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 508/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00508: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 509/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00509: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 510/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00510: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 511/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00511: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 512/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00512: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 513/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00513: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 514/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00514: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 515/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00515: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 516/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00516: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 517/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00517: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 518/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00518: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 519/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00519: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 520/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00520: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 521/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00521: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 522/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00522: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 523/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00523: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 524/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00524: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 525/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00525: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 526/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00526: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 527/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00527: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 528/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00528: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 529/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00529: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 530/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00530: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 84ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 531/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00531: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 85ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 532/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00532: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 533/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00533: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 534/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00534: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 535/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00535: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 536/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00536: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 537/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00537: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 538/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00538: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 539/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00539: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 540/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00540: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 541/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00541: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 542/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00542: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 543/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00543: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 544/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00544: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 545/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00545: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 546/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00546: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 547/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00547: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 548/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00548: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 549/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00549: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 550/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00550: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 551/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00551: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 552/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00552: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 553/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00553: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 554/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00554: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 555/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00555: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 556/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00556: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 557/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00557: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 558/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00558: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 559/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00559: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 560/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00560: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 561/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00561: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 562/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00562: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 563/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00563: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 564/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00564: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 565/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00565: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 566/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00566: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 567/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00567: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 568/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00568: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 569/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00569: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 570/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00570: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 571/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00571: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 572/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00572: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 573/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00573: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 574/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00574: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 575/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00575: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 576/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00576: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 577/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00577: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 578/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00578: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 579/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00579: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 580/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00580: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 581/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00581: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 582/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00582: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 583/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00583: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 584/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00584: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 585/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00585: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 586/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00586: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 587/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00587: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 588/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00588: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 589/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00589: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 590/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00590: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 591/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00591: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 592/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00592: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 593/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00593: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 594/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00594: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 595/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00595: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 596/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00596: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 597/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00597: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 598/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00598: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 599/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00599: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 600/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00600: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 601/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00601: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 602/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00602: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 603/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00603: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 604/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00604: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 605/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00605: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 606/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00606: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 607/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00607: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 608/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00608: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 609/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00609: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 610/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00610: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 611/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00611: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 612/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00612: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 613/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00613: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 614/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00614: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 615/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00615: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 616/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00616: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 617/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00617: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 618/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00618: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 619/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00619: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 620/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00620: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 621/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00621: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 622/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00622: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 623/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00623: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 624/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00624: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 625/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00625: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 626/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00626: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 627/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00627: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 628/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00628: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 629/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00629: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 630/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00630: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 631/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00631: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 632/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00632: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 633/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00633: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 634/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00634: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 635/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00635: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 636/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00636: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 637/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00637: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 638/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00638: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 639/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00639: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 640/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00640: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 641/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00641: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 642/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00642: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 643/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00643: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 644/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00644: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 645/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00645: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 646/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00646: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 647/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00647: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 648/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00648: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 649/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00649: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 650/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00650: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 651/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00651: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 652/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00652: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 653/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00653: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 654/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00654: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 655/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00655: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 656/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00656: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 657/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00657: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 658/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00658: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 659/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00659: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 660/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00660: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 661/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00661: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 662/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00662: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 663/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00663: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 664/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00664: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 665/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00665: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 666/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00666: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 667/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00667: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 668/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00668: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 669/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00669: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 670/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00670: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 671/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00671: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 672/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00672: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 673/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00673: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 674/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00674: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 675/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00675: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 676/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00676: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 677/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00677: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 678/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00678: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 679/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00679: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 680/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00680: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 681/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00681: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 682/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00682: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 683/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00683: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 684/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00684: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 685/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00685: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 686/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00686: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 687/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00687: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 688/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00688: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 689/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00689: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 690/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00690: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 691/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00691: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 692/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00692: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 693/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00693: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 694/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00694: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 695/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00695: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 696/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00696: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 697/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00697: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 698/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00698: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 699/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00699: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 700/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00700: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 701/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00701: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 702/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00702: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 703/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00703: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 704/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00704: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 705/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00705: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 706/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00706: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 707/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00707: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 708/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00708: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 709/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00709: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 710/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00710: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 711/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00711: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 712/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00712: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 713/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00713: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 714/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00714: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 715/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00715: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 716/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00716: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 717/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00717: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 718/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00718: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 719/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00719: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 720/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00720: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 721/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00721: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 722/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00722: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 723/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00723: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 724/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00724: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 725/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00725: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 726/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00726: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 727/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00727: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 728/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00728: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 729/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00729: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 730/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00730: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 731/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00731: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 732/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00732: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 733/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00733: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 734/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00734: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 735/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00735: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 736/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00736: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 737/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00737: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 738/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00738: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 739/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00739: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 740/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00740: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 741/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00741: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 742/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00742: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 743/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00743: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 744/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00744: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 745/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00745: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 746/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00746: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 747/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00747: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 748/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00748: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 749/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00749: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 750/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00750: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 751/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00751: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 752/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00752: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 753/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00753: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 754/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00754: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 755/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00755: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 756/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00756: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 757/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00757: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 758/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00758: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 759/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00759: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 760/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00760: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 761/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00761: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 762/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00762: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 763/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00763: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 764/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00764: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 765/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00765: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 766/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00766: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 767/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00767: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 768/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00768: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 769/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00769: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 770/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00770: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 771/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00771: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 772/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00772: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 773/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00773: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 774/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00774: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 775/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00775: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 776/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00776: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 777/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00777: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 778/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00778: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 779/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00779: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 780/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00780: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 781/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00781: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 782/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00782: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 783/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00783: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 784/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00784: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 785/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00785: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 786/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00786: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 787/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00787: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 788/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00788: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 789/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00789: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 790/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00790: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 791/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00791: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 792/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00792: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 793/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00793: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 794/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00794: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 795/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00795: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 796/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00796: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 797/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00797: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 798/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00798: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 799/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00799: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 800/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00800: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 801/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00801: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 802/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00802: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 803/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00803: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 804/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00804: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 805/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00805: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 806/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00806: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 807/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00807: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 808/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00808: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 809/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00809: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 810/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00810: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 811/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00811: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 812/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00812: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 813/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00813: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 814/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00814: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 815/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00815: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 816/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00816: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 817/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00817: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 818/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00818: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 819/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00819: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 820/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00820: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 821/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00821: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 822/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00822: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 84ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 823/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00823: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 824/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00824: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 825/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00825: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 826/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00826: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 827/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00827: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 828/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00828: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 829/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00829: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 830/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00830: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 831/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00831: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 832/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00832: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 833/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00833: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 834/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00834: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 835/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00835: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 836/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00836: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 837/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00837: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 838/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00838: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 839/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00839: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 840/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00840: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 841/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00841: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 842/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00842: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 843/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00843: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 844/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00844: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 845/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00845: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 846/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00846: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 847/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00847: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 848/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9378 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9365 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00848: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 849/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9378 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9365 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00849: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 850/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00850: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 851/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00851: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 852/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00852: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 853/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00853: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 854/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00854: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 855/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00855: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 856/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00856: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 857/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00857: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 858/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00858: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 859/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00859: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 860/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00860: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 861/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00861: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 862/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00862: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 863/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00863: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 864/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00864: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 865/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9365 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00865: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 866/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00866: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 867/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00867: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 868/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00868: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 869/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00869: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 870/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00870: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 871/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00871: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 872/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00872: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0180 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 873/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00873: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 874/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00874: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 875/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00875: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 876/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00876: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 877/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9378 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00877: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 878/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00878: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 879/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00879: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 880/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00880: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 881/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00881: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 882/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00882: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 883/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00883: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 884/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00884: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 885/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00885: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 886/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00886: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 887/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00887: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 888/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00888: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 889/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00889: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 890/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00890: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 891/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00891: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 892/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00892: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 893/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00893: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 894/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00894: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 895/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00895: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 896/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00896: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 897/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00897: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 898/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00898: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 899/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00899: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 900/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00900: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 901/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00901: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 902/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00902: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 903/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00903: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 904/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00904: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 905/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00905: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 906/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00906: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 907/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00907: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 908/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9365 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00908: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 909/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00909: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 910/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00910: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 911/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00911: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 912/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9365 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00912: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 913/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00913: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 914/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00914: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 915/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00915: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 916/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0092 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5887\n",
      "Epoch 00916: val_loss did not improve from 1.01430\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.9441 - accuracy: 0.5887 - val_loss: 1.0179 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 917/1000\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 1.0043 - accuracy: 0.5279"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-3cb6a2175d5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     69\u001b[0m                       \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m                       \u001b[0muse_multiprocessing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m                       callbacks = callbacks_list)\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;31m# model.fit([train_X, train_X2], [train_y, train_y],\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    853\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    387\u001b[0m     \"\"\"\n\u001b[0;32m    388\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_process_logs\u001b[1;34m(self, logs)\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;34m\"\"\"Turns tensors into numpy arrays or Python scalars.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 523\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 617\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 617\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    517\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    959\u001b[0m     \"\"\"\n\u001b[0;32m    960\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 961\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    962\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    925\u001b[0m     \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 927\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    928\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from datetime import datetime\n",
    "# import os\n",
    "\n",
    "# from tensorflow.keras.callbacks import Callback\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from scikitplot.metrics import plot_confusion_matrix, plot_roc\n",
    "\n",
    "\n",
    "# class PerformanceVisualizationCallback(Callback):\n",
    "#     def __init__(self, model, validation_data, image_dir):\n",
    "#         super().__init__()\n",
    "#         self.model = model\n",
    "#         self.validation_data = validation_data\n",
    "        \n",
    "#         os.makedirs(image_dir, exist_ok=True)\n",
    "#         self.image_dir = image_dir\n",
    "\n",
    "#     def on_epoch_end(self, epoch, logs={}):\n",
    "#         y_pred = np.asarray(self.model.predict(self.validation_data[0]))\n",
    "#         y_true = self.validation_data[1]             \n",
    "#         y_pred_class = np.argmax(y_pred, axis=1)\n",
    "\n",
    "#         # plot and save confusion matrix\n",
    "#         fig, ax = plt.subplots(figsize=(16,12))\n",
    "#         chart = plot_confusion_matrix(y_true, y_pred_class, ax=ax)\n",
    "#         fig.savefig(os.path.join(self.image_dir, f'confusion_matrix_epoch_{epoch}'))\n",
    "#         plt.display(chart)\n",
    "#         plt.show()\n",
    "        \n",
    "#        # plot and save roc curve\n",
    "#         fig, ax = plt.subplots(figsize=(16,12))\n",
    "#         plot_roc(y_true, y_pred, ax=ax)\n",
    "#         chart = fig.savefig(os.path.join(self.image_dir, f'roc_curve_epoch_{epoch}'))\n",
    "#         plt.display(chart)\n",
    "#         plt.show()\n",
    "        \n",
    "# logdir = \"logs\\\\scalars\\\\\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "# weight_path=\"{}_weights.best.hdf5\".format('stroke_lstm_model')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=10, verbose=1, mode='auto', \n",
    "                                   epsilon=0.0001, cooldown=5, min_lr=0.0001)\n",
    "early = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=100) \n",
    "performance_cbk = PerformanceVisualizationCallback(\n",
    "                      model=model,\n",
    "                      validation_data=v_dataset,\n",
    "                      image_dir='performance_vizualizations')\n",
    "\n",
    "callbacks_list = [checkpoint\n",
    "#                   , early\n",
    "                  , reduceLROnPlat\n",
    "                  , tensorboard_callback\n",
    "                  \n",
    "                 ]\n",
    "\n",
    "\n",
    "from IPython.display import clear_output\n",
    "model.fit(train_dataset,\n",
    "                      validation_data = v_dataset, \n",
    "#                       batch_size = 10,\n",
    "                      epochs = 1000,\n",
    "                      use_multiprocessing = True,\n",
    "                      callbacks = callbacks_list)\n",
    "\n",
    "# model.fit([train_X, train_X2], [train_y, train_y],\n",
    "#                       validation_data = ([valid_X, valid_X2], [valid_y, valid_y]), \n",
    "#                       batch_size = batch_size,\n",
    "#                       epochs = 500,\n",
    "#                       callbacks = callbacks_list)\n",
    "\n",
    "#clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9b4790925984514e64ca5a9b46de8b309062e0cf",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(weight_path)\n",
    "lstm_results = model.evaluate(test_dataset, return_dict=True)\n",
    "print(lstm_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lstm_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./trained_model.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c3340d6d6ce75585f90c98f1728b1cd664d7f33f"
   },
   "source": [
    "Load and normalize the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test(ts_length = 150000):\n",
    "    base_dir = 'input/test/'\n",
    "    test_files = [f for f in listdir(base_dir) if isfile(join(base_dir, f))]\n",
    "\n",
    "    ts = np.empty([len(test_files), ts_length])\n",
    "    ids = []\n",
    "    \n",
    "    i = 0\n",
    "    for f in tqdm_notebook(test_files):\n",
    "        ids.append(splitext(f)[0])\n",
    "        t_df = pd.read_csv(base_dir + f, dtype={\"acoustic_data\": np.int8})\n",
    "        ts[i, :] = t_df['acoustic_data'].values\n",
    "        i = i + 1\n",
    "\n",
    "    return ts, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "0f005579ea08913f4f68a3749bd761df6cef2b1b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92feb967c8204b0c87aa92ee4c5d250e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2624), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_data, test_ids = load_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "0c3b7a864a9f53af142a08883def46c3866c5464"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2624, 150000, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test_data\n",
    "X_test = np.expand_dims(X_test, 2)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bf9b36929e5228d4d94b3b7ad1b9011bf088ac44"
   },
   "source": [
    "Load best model and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "435449fda2bf96635e67d69f56227e140c4cea99"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0613 16:55:21.078702  7492 network.py:957] Model was constructed with shape (None, 360, 4) for input Tensor(\"input_1:0\", shape=(None, 360, 4), dtype=float32), but it was called on an input with incompatible shape (32, 150000, 1).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\Admin\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1147 predict_function  *\n        outputs = self.distribute_strategy.run(\n    C:\\Users\\Admin\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\Admin\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\Admin\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\Admin\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1122 predict_step  **\n        return self(x, training=False)\n    C:\\Users\\Admin\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:927 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    C:\\Users\\Admin\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py:719 call\n        convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n    C:\\Users\\Admin\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py:888 _run_internal_graph\n        output_tensors = layer(computed_tensors, **kwargs)\n    C:\\Users\\Admin\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:886 __call__\n        self.name)\n    C:\\Users\\Admin\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:216 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer conv1d_4 is incompatible with the layer: expected axis -1 of input shape to have value 4 but received input with shape [32, 150000, 1]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-33f45f2977c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[0;32m     87\u001b[0m           method.__name__))\n\u001b[1;32m---> 88\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1266\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1267\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1268\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1269\u001b[0m             \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1270\u001b[0m             \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    625\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 627\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    628\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    505\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 506\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2445\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2446\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2447\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2775\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2777\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2779\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2667\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2669\u001b[0m         \u001b[1;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 981\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    982\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    983\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    966\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 968\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    969\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\Admin\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1147 predict_function  *\n        outputs = self.distribute_strategy.run(\n    C:\\Users\\Admin\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\Admin\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\Admin\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\Admin\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1122 predict_step  **\n        return self(x, training=False)\n    C:\\Users\\Admin\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:927 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    C:\\Users\\Admin\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py:719 call\n        convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n    C:\\Users\\Admin\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py:888 _run_internal_graph\n        output_tensors = layer(computed_tensors, **kwargs)\n    C:\\Users\\Admin\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:886 __call__\n        self.name)\n    C:\\Users\\Admin\\Anaconda3\\envs\\Transformer_1D-CNN_Feature_Extraction_tf2.2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:216 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer conv1d_4 is incompatible with the layer: expected axis -1 of input shape to have value 4 but received input with shape [32, 150000, 1]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9aaf9fb44edba5879a75c68820527d9180d2b3c6"
   },
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({'seg_id': test_ids, 'time_to_failure': y_pred[:, 0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9b9d5c63161f637de2e39b59e8e4d7c2f3049581"
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"submission.csv\"> Download File </a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb.transform([-1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "nn = np.array([[1., 0.,2], [2., 1.,3], [0., 0.,4]])\n",
    "print(nn[1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "print(valid_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(valid_X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset.take(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, \n",
    "                          loss='categorical_crossentropy',\n",
    "                          loss_weights=[1., 1.]\n",
    "#                           loss_weights=[1.]\n",
    "#               \n",
    "                            , metrics=[Recall(thresholds=0.5, class_id=0, top_k=1)\n",
    "                                 , Recall(thresholds=0.5, class_id=2, top_k=1)\n",
    "                                   , Precision(thresholds=0.5, class_id=0, top_k=1)\n",
    "                                  , Precision(thresholds=0.5, class_id=2, top_k=1)\n",
    "                                  ]\n",
    "             )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
