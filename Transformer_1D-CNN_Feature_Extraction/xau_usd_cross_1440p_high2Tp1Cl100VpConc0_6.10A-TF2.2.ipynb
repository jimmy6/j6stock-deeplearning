{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": false,
    "_uuid": "e1baa7518f18a7ff1f2767df1b29c051955502ff"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from os import listdir, makedirs\n",
    "from os.path import isfile, join, basename, splitext, isfile, exists\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.metrics import top_k_categorical_accuracy, CategoricalHinge, Recall, Precision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "# from tensorflow.keras import metrics\n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.compat.v2.keras.layers import Input\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import random, os, sys\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.initializers import *\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.layers import Layer\n",
    "tf.compat.v1.disable_eager_execution\n",
    "pd.set_option('precision', 30)\n",
    "np.set_printoptions(precision = 30)\n",
    "\n",
    "\n",
    "#np.random.seed(368)\n",
    "#tf.random.set_seed(368)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Size : <TensorSliceDataset shapes: (((3,), (5,)), (3,)), types: ((tf.float64, tf.float64), tf.int32)>\n",
      "Total Filtered Size : <TensorSliceDataset shapes: (((3,), (5,)), (3,)), types: ((tf.float64, tf.float64), tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "xfile='C:\\\\workspace\\\\j6stock\\\\xau_usd_OHLC2.0Tp1.0Cl100Vp.txt'\n",
    "\n",
    "seq_len = 60*6 #60*10 # 3 days + 2 features is enough memory\n",
    "batch_size = int(2048/3)       # Batch size\n",
    "# mini_batch_size = 64       # Batch size\n",
    "\n",
    "learning_rate = 0.001  #0.0001  # Learning rate (default is 0.001)\n",
    "epochs = 500\n",
    "\n",
    "\n",
    "y_column = 6\n",
    "compute_val_at = 0\n",
    "acc_filtered_r = 0.8\n",
    "\n",
    "\n",
    "upperTailFilter = 0.4\n",
    "lowerTailFilter = 0.4\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import debug as tf_debug\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt2\n",
    "import pandas as pd\n",
    "from pandas import datetime\n",
    "import math, time\n",
    "import itertools\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers.core import Dense, Dropout, Activation\n",
    "#from keras.layers.recurrent import LSTM\n",
    "#from keras.models import load_model\n",
    "#import keras\n",
    "import pandas as pd ## can be remove once pandas_datareader 0.7 using\n",
    "pd.core.common.is_list_like = pd.api.types.is_list_like ## can be remove once pandas_datareader 0.7 using\n",
    "import pandas_datareader.data as web\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def get_stock_data(normalize=True, ma=[]):\n",
    "    \"\"\"\n",
    "    Return a dataframe of that stock and normalize all the values. \n",
    "    (Optional: create moving average)\n",
    "    \"\"\"\n",
    "    global upperTailFilter, lowerTailFilter\n",
    "    \n",
    "    df = pd.read_csv(filepath_or_buffer  = xfile )\n",
    "    #TODO Use previous close instead of open\n",
    "    df['change'] = df['close'] - df['open']\n",
    "    df['tail_upper'] = df['high'].copy()\n",
    "    df['tail_lower'] = df['low'].copy()\n",
    "    for i, row in df.iterrows():\n",
    "        df.at[i, 'tail_upper'] = df.at[i, 'high'] - (df.at[i, 'open'] if df.at[i, 'open'] > df.at[i, 'close'] else df.at[i, 'close'])\n",
    "        df.at[i, 'tail_lower'] = (df.at[i, 'close'] if df.at[i, 'close'] < df.at[i, 'open'] else df.at[i, 'open']) - df.at[i, 'low']\n",
    "    \n",
    "    df.dropna(inplace=True)\n",
    "    df.drop('open', axis=1, inplace=True)\n",
    "    df.drop('high', axis=1, inplace=True)\n",
    "    df.drop('low', axis=1, inplace=True)\n",
    "    # Moving Average    \n",
    "    if ma != []:\n",
    "        for moving in ma:\n",
    "            df['{}ma'.format(moving)] = df['close'].rolling(window=moving).mean() \n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    if normalize:\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        #df['open'] = min_max_scaler.fit_transform(df.open.values.reshape(-1,1))\n",
    "        #df['high'] = min_max_scaler.fit_transform(df.high.values.reshape(-1,1))\n",
    "        #df['low'] = min_max_scaler.fit_transform(df.low.values.reshape(-1,1))\n",
    "        #df['vol'] = min_max_scaler.fit_transform(df.vol.values.reshape(-1,1))\n",
    "        df['close'] = min_max_scaler.fit_transform(df['close'].values.reshape(-1,1))\n",
    "#         df['change'] = min_max_scaler.fit_transform(df['change'].values.reshape(-1,1)) # no rescale for keep the negative value\n",
    "        df['tail_upper'] = min_max_scaler.fit_transform(df['tail_upper'].values.reshape(-1,1))\n",
    "        upperTailFilter = min_max_scaler.transform([[upperTailFilter]])[0][0] \n",
    "        df['tail_lower'] = min_max_scaler.fit_transform(df['tail_lower'].values.reshape(-1,1))\n",
    "        lowerTailFilter = min_max_scaler.transform([[lowerTailFilter]])[0][0] \n",
    "        \n",
    "        if ma != []:\n",
    "            for moving in ma:\n",
    "                df['{}ma'.format(moving)] = min_max_scaler.fit_transform(df['{}ma'.format(moving)].values.reshape(-1,1))   \n",
    "                #pd.concat([min_max_scaler.fit_transform(df['{}ma'.format(moving)].values.reshape(-1,1)), df], axis=1)\n",
    "                ma_data = df['{}ma'.format(moving)]\n",
    "                df.drop(labels=['{}ma'.format(moving)], axis=1, inplace=True)\n",
    "                df = pd.concat([ma_data, df], axis=1)\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    \n",
    "    # Move y_result to the rightmost for the ease of training\n",
    "    adj_close = df['y_result']\n",
    "    df.drop(labels=['y_result'], axis=1, inplace=True)\n",
    "    df = pd.concat([df, adj_close], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "#df = get_stock_data( ma=[50, 100, 200])\n",
    "df = get_stock_data(ma=[240])\n",
    "\n",
    "# amount_of_features = len(df.columns)-1+(input2Length*-1)\n",
    "\n",
    "# def load_data(stock, seq_len):\n",
    "#     print (\"Amount of features = {}\".format(amount_of_features))\n",
    "#     data = stock.as_matrix()\n",
    "#     sequence_length = seq_len + 1 # index starting from 0\n",
    "#     x_result = []\n",
    "#     x_result2 = []\n",
    "#     y_result = []\n",
    "#     for index in range(seq_len, len(data) ): # maxmimum date = lastest date - sequence length\n",
    "#         x_result.append(data[index-seq_len: index,\n",
    "#                              :-1 + (input2Length*-1) # -2 is ignore Input2 features\n",
    "#                             ]) # index : index + 22days\n",
    "#         x_result2.append(data[index, -1 + (input2Length*-1):-1])\n",
    "#         y_result.append(data[index ,-1]);\n",
    "\n",
    "#     x_result, x_result2, y_result = shuffle(x_result, x_result2, y_result , random_state=2)\n",
    "\n",
    "#     #print('---', data[0])\n",
    "#     #print('---', x_result[0])\n",
    "#     #print('---', y_result[0])\n",
    "#     x_result = np.array(x_result)\n",
    "#     x_result2 = np.array(x_result2)\n",
    "#     y_result = np.array(y_result)\n",
    "#     print (\"Amount of data = {}\".format(y_result.shape[0]))\n",
    "\n",
    "#     percentageSplit = 0.5 # 60% split\n",
    "#     row = round(percentageSplit * y_result.shape[0]) \n",
    "#     print (\"Split = {}\".format(row))\n",
    " \n",
    "#     X_train = x_result[:int(row), :] \n",
    "#     X_train2 = x_result2[:int(row), :] \n",
    "#     y_train = y_result[:int(row)] \n",
    "#     print (\"Amount of training data = {}\".format(y_train.shape[0]))\n",
    "#     X_test = x_result[int(row):, :]\n",
    "#     X_test2 = x_result2[int(row):, :]\n",
    "#     y_test = y_result[int(row):]\n",
    "#     # filter for 1 and -1 for validation only\n",
    "#     X_test = X_test[y_test[:]!=0,:]\n",
    "#     X_test2 = X_test2[y_test[:]!=0,:]\n",
    "#     y_test = y_test[y_test[:]!=0]\n",
    "    \n",
    "#     # split 50% again for test and validation set\n",
    "#     row = round(percentageSplit * y_test.shape[0]) \n",
    "#     X_val = X_test[int(row):, :]\n",
    "#     X_val2 = X_test2[int(row):, :]\n",
    "#     y_val = y_test[int(row):]\n",
    "#     print (\"Amount of validation data = {}\".format(y_val.shape[0]))\n",
    "#     X_test = X_test[:int(row), :]\n",
    "#     X_test2 = X_test2[:int(row), :]\n",
    "#     y_test = y_test[:int(row)]\n",
    "#     print (\"Amount of testing data = {}\".format(y_test.shape[0]))\n",
    "#     #print(result.shape[0], len(y_result), int(row), y_result[int(row):])\n",
    "#     #X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], amount_of_features-1))\n",
    "#     #X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], amount_of_features-1))    \n",
    "#     return [X_train, X_train2, y_train, X_test, X_test2, y_test, X_val, X_val2, y_val]\n",
    "\n",
    "\n",
    "\n",
    "classes = [1, 0, -1]\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(classes)\n",
    "lb.transform([-1, 0, 1])\n",
    "\n",
    "df_to_dataset = df[['close', 'change', '240ma'\n",
    "                   ]].copy()\n",
    "df_to_dataset_input2 = df[[ 'tail_upper', 'tail_lower', 'change' ,'cross_360p_high', 'cross_1440p_high'\n",
    "                          ]].copy()\n",
    "\n",
    "amount_of_features = len(df_to_dataset.columns)\n",
    "input2Length = len(df_to_dataset_input2.columns)\n",
    "\n",
    "df.drop(labels=['close'], axis=1, inplace=True)\n",
    "df.drop(labels=['change'], axis=1, inplace=True)\n",
    "df.drop(labels=['tail_upper'], axis=1, inplace=True)\n",
    "df.drop(labels=['tail_lower'], axis=1, inplace=True)\n",
    "df.drop(labels=['cross_360p_high'], axis=1, inplace=True)\n",
    "df.drop(labels=['cross_1440p_high'], axis=1, inplace=True)\n",
    "\n",
    "df_to_dataset_y = lb.transform(df[['y_result']].copy())\n",
    "df.drop(labels=['y_result'], axis=1, inplace=True)\n",
    "\n",
    "train_data_no = int(len(df_to_dataset_y)/2)\n",
    "test_data_no = int(train_data_no/2)\n",
    "v_data_no = test_data_no\n",
    "\n",
    "train_x_1 = df_to_dataset.iloc[:train_data_no].values\n",
    "train_x_2 = df_to_dataset_input2.iloc[:train_data_no].values\n",
    "train_y = df_to_dataset_y[:train_data_no]                                                   \n",
    "\n",
    "test_x_1 = df_to_dataset.iloc[train_data_no:train_data_no+test_data_no].values\n",
    "test_x_2 = df_to_dataset_input2.iloc[train_data_no:train_data_no+test_data_no].values\n",
    "test_y = df_to_dataset_y[train_data_no:train_data_no+test_data_no]                                                   \n",
    "\n",
    "v_x_1 = df_to_dataset.iloc[train_data_no+test_data_no:].values\n",
    "v_x_2 = df_to_dataset_input2.iloc[train_data_no+test_data_no:].values\n",
    "v_y = df_to_dataset_y[train_data_no+test_data_no:]                                                   \n",
    "\n",
    "\n",
    "def make_window_dataset(ds, window_size=seq_len, shift=1, stride=1):\n",
    "  windows = ds.window(window_size, shift=shift, stride=stride)\n",
    "\n",
    "  def batch(sub):\n",
    "    ret = ()\n",
    "    for index in range(2):\n",
    "      ret = ret + ( sub[index].batch(window_size, drop_remainder=True), )\n",
    "    return ret\n",
    "  def sub_to_batch(sub, sub2): \n",
    "    return tf.data.Dataset.zip((batch(sub), (sub2.batch(window_size, drop_remainder=True))))\n",
    "  \n",
    "  windows = windows.flat_map(sub_to_batch)\n",
    "  windows = windows.map(lambda sub1, sub2: ((sub1[0], sub1[1][-1:][0]), (sub2[-1:][0] #, sub2[-1:][0]\n",
    "                                                                        )))\n",
    "  return windows\n",
    "\n",
    "def filter_fn(a, b):\n",
    "#   return a[1][0]>=upperTailFilter or a[1][1]>=lowerTailFilter or a[1][3]==1 or a[1][4]==1\n",
    "  return a[1][4]==1\n",
    "\n",
    "train_dataset_x = tf.data.Dataset.from_tensor_slices(((train_x_1, train_x_2),(train_y)))\n",
    "train_dataset = make_window_dataset(train_dataset_x).filter(filter_fn).cache().batch(batch_size, drop_remainder=True) \n",
    "\n",
    "test_dataset_x = tf.data.Dataset.from_tensor_slices(((test_x_1, test_x_2),(test_y)))\n",
    "test_dataset = make_window_dataset(test_dataset_x).filter(filter_fn).cache().batch(batch_size, drop_remainder=True)\n",
    "\n",
    "v_dataset_x = tf.data.Dataset.from_tensor_slices(((v_x_1, v_x_2),(v_y)))\n",
    "v_dataset = make_window_dataset(v_dataset_x).filter(filter_fn).cache().batch(batch_size, drop_remainder=True)\n",
    "\n",
    "\n",
    "print('Total Size : {}'.format(train_dataset_x))\n",
    "print('Total Filtered Size : {}'.format(v_dataset_x))\n",
    "\n",
    "\n",
    "# X_tr, X_tr2, lab_tr, X_test, X_test2, lab_test, X_vld, X_vld2, lab_vld = load_data(df, seq_len)\n",
    "# y_tr = lb.transform(lab_tr)\n",
    "# y_vld = lb.transform(lab_vld)\n",
    "# y_test = lb.transform(lab_test)\n",
    "\n",
    "\n",
    "# train_X = X_tr\n",
    "# train_X2 = X_tr2\n",
    "# train_y = y_tr\n",
    "# valid_X = X_vld\n",
    "# valid_X2 = X_vld2\n",
    "# valid_y = y_vld\n",
    "# test_X = X_test\n",
    "# test_X2 = X_test2\n",
    "# test_y = y_test\n",
    "\n",
    "# print(train_X.shape)\n",
    "# print(train_y[0])\n",
    "# print(train_y[1])\n",
    "# print(train_y[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/shujian/transformer-with-lstm\n",
    "\n",
    "try:\n",
    "    from dataloader import TokenList, pad_to_longest\n",
    "    # for transformer\n",
    "except: pass\n",
    "\n",
    "\n",
    "\n",
    "embed_size = 60\n",
    "\n",
    "class LayerNormalization(Layer):\n",
    "    def __init__(self, eps=1e-6, **kwargs):\n",
    "        self.eps = eps\n",
    "        super(LayerNormalization, self).__init__(**kwargs)\n",
    "    def build(self, input_shape):\n",
    "        self.gamma = self.add_weight(name='gamma', shape=input_shape[-1:],\n",
    "                                     initializer=Ones(), trainable=True)\n",
    "        self.beta = self.add_weight(name='beta', shape=input_shape[-1:],\n",
    "                                    initializer=Zeros(), trainable=True)\n",
    "        super(LayerNormalization, self).build(input_shape)\n",
    "    def call(self, x):\n",
    "        mean = K.mean(x, axis=-1, keepdims=True)\n",
    "        std = K.std(x, axis=-1, keepdims=True)\n",
    "        return self.gamma * (x - mean) / (std + self.eps) + self.beta\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "class ScaledDotProductAttention():\n",
    "    def __init__(self, d_model, attn_dropout=0.1):\n",
    "        self.temper = np.sqrt(d_model)\n",
    "        self.dropout = Dropout(attn_dropout)\n",
    "    def __call__(self, q, k, v, mask):\n",
    "        attn = Lambda(lambda x:K.batch_dot(x[0],x[1],axes=[2,2])/self.temper)([q, k])\n",
    "        if mask is not None:\n",
    "            mmask = Lambda(lambda x:(-1e+10)*(1-x))(mask)\n",
    "            attn = Add()([attn, mmask])\n",
    "        attn = Activation('softmax')(attn)\n",
    "        attn = self.dropout(attn)\n",
    "        output = Lambda(lambda x:K.batch_dot(x[0], x[1]))([attn, v])\n",
    "        return output, attn\n",
    "\n",
    "class MultiHeadAttention():\n",
    "    # mode 0 - big martixes, faster; mode 1 - more clear implementation\n",
    "    def __init__(self, n_head, d_model, d_k, d_v, dropout, mode=0, use_norm=True):\n",
    "        self.mode = mode\n",
    "        self.n_head = n_head\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        self.dropout = dropout\n",
    "        if mode == 0:\n",
    "            self.qs_layer = Dense(n_head*d_k, use_bias=False)\n",
    "            self.ks_layer = Dense(n_head*d_k, use_bias=False)\n",
    "            self.vs_layer = Dense(n_head*d_v, use_bias=False)\n",
    "        elif mode == 1:\n",
    "            self.qs_layers = []\n",
    "            self.ks_layers = []\n",
    "            self.vs_layers = []\n",
    "            for _ in range(n_head):\n",
    "                self.qs_layers.append(TimeDistributed(Dense(d_k, use_bias=False)))\n",
    "                self.ks_layers.append(TimeDistributed(Dense(d_k, use_bias=False)))\n",
    "                self.vs_layers.append(TimeDistributed(Dense(d_v, use_bias=False)))\n",
    "        self.attention = ScaledDotProductAttention(d_model)\n",
    "        self.layer_norm = LayerNormalization() if use_norm else None\n",
    "        self.w_o = TimeDistributed(Dense(d_model))\n",
    "\n",
    "    def __call__(self, q, k, v, mask=None):\n",
    "        d_k, d_v = self.d_k, self.d_v\n",
    "        n_head = self.n_head\n",
    "\n",
    "        if self.mode == 0:\n",
    "            qs = self.qs_layer(q)  # [batch_size, len_q, n_head*d_k]\n",
    "            ks = self.ks_layer(k)\n",
    "            vs = self.vs_layer(v)\n",
    "\n",
    "            def reshape1(x):\n",
    "                s = tf.shape(x)   # [batch_size, len_q, n_head * d_k]\n",
    "                x = tf.reshape(x, [s[0], s[1], n_head, d_k])\n",
    "                x = tf.transpose(x, [2, 0, 1, 3])  \n",
    "                x = tf.reshape(x, [-1, s[1], d_k])  # [n_head * batch_size, len_q, d_k]\n",
    "                return x\n",
    "            qs = Lambda(reshape1)(qs)\n",
    "            ks = Lambda(reshape1)(ks)\n",
    "            vs = Lambda(reshape1)(vs)\n",
    "\n",
    "            if mask is not None:\n",
    "                mask = Lambda(lambda x:K.repeat_elements(x, n_head, 0))(mask)\n",
    "            head, attn = self.attention(qs, ks, vs, mask=mask)  \n",
    "                \n",
    "            def reshape2(x):\n",
    "                s = tf.shape(x)   # [n_head * batch_size, len_v, d_v]\n",
    "                x = tf.reshape(x, [n_head, -1, s[1], s[2]]) \n",
    "                x = tf.transpose(x, [1, 2, 0, 3])\n",
    "                x = tf.reshape(x, [-1, s[1], n_head*d_v])  # [batch_size, len_v, n_head * d_v]\n",
    "                return x\n",
    "            head = Lambda(reshape2)(head)\n",
    "        elif self.mode == 1:\n",
    "            heads = []; attns = []\n",
    "            for i in range(n_head):\n",
    "                qs = self.qs_layers[i](q)   \n",
    "                ks = self.ks_layers[i](k) \n",
    "                vs = self.vs_layers[i](v) \n",
    "                head, attn = self.attention(qs, ks, vs, mask)\n",
    "                heads.append(head); attns.append(attn)\n",
    "            head = Concatenate()(heads) if n_head > 1 else heads[0]\n",
    "            attn = Concatenate()(attns) if n_head > 1 else attns[0]\n",
    "\n",
    "        outputs = self.w_o(head)\n",
    "        outputs = Dropout(self.dropout)(outputs)\n",
    "        if not self.layer_norm: return outputs, attn\n",
    "        # outputs = Add()([outputs, q]) # sl: fix\n",
    "        return self.layer_norm(outputs), attn\n",
    "\n",
    "class PositionwiseFeedForward():\n",
    "    def __init__(self, d_hid, d_inner_hid, dropout=0.1):\n",
    "        self.w_1 = Conv1D(d_inner_hid, 1, activation='tanh')\n",
    "        self.w_2 = Conv1D(d_hid, 1)\n",
    "        self.layer_norm = LayerNormalization()\n",
    "        self.dropout = Dropout(dropout)\n",
    "    def __call__(self, x):\n",
    "        output = self.w_1(x) \n",
    "        output = self.w_2(output)\n",
    "        output = self.dropout(output)\n",
    "        output = Add()([output, x])\n",
    "        return self.layer_norm(output)\n",
    "\n",
    "class EncoderLayer():\n",
    "    def __init__(self, d_model, d_inner_hid, n_head, d_k, d_v, dropout=0.1):\n",
    "        self.self_att_layer = MultiHeadAttention(n_head, d_model, d_k, d_v, dropout=dropout)\n",
    "        self.pos_ffn_layer  = PositionwiseFeedForward(d_model, d_inner_hid, dropout=dropout)\n",
    "    def __call__(self, enc_input, mask=None):\n",
    "        output, slf_attn = self.self_att_layer(enc_input, enc_input, enc_input, mask=mask)\n",
    "        output = self.pos_ffn_layer(output)\n",
    "        return output, slf_attn\n",
    "\n",
    "\n",
    "def GetPosEncodingMatrix(max_len, d_emb):\n",
    "    pos_enc = np.array([\n",
    "        [pos / np.power(10000, 2 * (j // 2) / d_emb) for j in range(d_emb)] \n",
    "        if pos != 0 else np.zeros(d_emb) \n",
    "            for pos in range(max_len)\n",
    "            ])\n",
    "    pos_enc[1:, 0::2] = np.sin(pos_enc[1:, 0::2]) # dim 2i\n",
    "    pos_enc[1:, 1::2] = np.cos(pos_enc[1:, 1::2]) # dim 2i+1\n",
    "    return pos_enc\n",
    "\n",
    "def GetPadMask(q, k):\n",
    "    ones = K.expand_dims(K.ones_like(q, 'float32'), -1)\n",
    "    mask = K.cast(K.expand_dims(K.not_equal(k, 0), 1), 'float32')\n",
    "    mask = K.batch_dot(ones, mask, axes=[2,1])\n",
    "    return mask\n",
    "\n",
    "def GetSubMask(s):\n",
    "    len_s = tf.shape(s)[1]\n",
    "    bs = tf.shape(s)[:1]\n",
    "    mask = K.cumsum(tf.eye(len_s, batch_shape=bs), 1)\n",
    "    return mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
    "def CnnTransformerModel():\n",
    "#    i = tf.compat.v2.keras.layers.Flatten(input_shape=(batch_size, amount_of_features))\n",
    "    i = tf.compat.v2.keras.layers.Input(shape = (seq_len, amount_of_features)#, batch_size=mini_batch_size\n",
    "                                       )\n",
    "    \n",
    "    x = tf.compat.v2.keras.layers.Convolution1D(64*2, kernel_size = 4, strides=2)(i)\n",
    "    x = tf.compat.v2.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.compat.v2.keras.layers.Activation('tanh')(x)\n",
    "    x = tf.keras.layers.Dropout(rate=0.2)(x)\n",
    "    x = tf.keras.layers.MaxPool1D(pool_size=2)(x)\n",
    "    x = tf.compat.v2.keras.layers.Convolution1D(64, kernel_size = 2, dilation_rate=2)(x)\n",
    "    x = tf.compat.v2.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.compat.v2.keras.layers.Activation('tanh')(x)\n",
    "    x = tf.keras.layers.Dropout(rate=0.2)(x)\n",
    "    x = tf.keras.layers.MaxPool1D(pool_size=2)(x)\n",
    "    x = tf.compat.v2.keras.layers.Convolution1D(32, kernel_size = 2, dilation_rate=2)(x)\n",
    "    x = tf.compat.v2.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.compat.v2.keras.layers.Activation('tanh')(x)\n",
    "    x = tf.keras.layers.Dropout(rate=0.2)(x)\n",
    "    x = tf.compat.v2.keras.layers.Convolution1D(32, kernel_size = 2, dilation_rate=2)(x)\n",
    "    x = tf.compat.v2.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.compat.v2.keras.layers.Activation('tanh')(x)\n",
    "    x = tf.keras.layers.Dropout(rate=0.2)(x)\n",
    "#     x = tf.compat.v2.keras.layers.Convolution1D(32, kernel_size = 4, strides = 2)(x)\n",
    "#     x = tf.compat.v2.keras.layers.BatchNormalization()(x)\n",
    "#     x = tf.compat.v2.keras.layers.Activation('relu')(x)\n",
    "#     x = tf.keras.layers.Dropout(rate=0.2)(x)\n",
    "#     x = tf.keras.layers.MaxPool1D(pool_size=2)(x)\n",
    "#     x = tf.compat.v2.keras.layers.Convolution1D(32, kernel_size = 4, dilation_rate=5)(x)\n",
    "#     x = tf.compat.v2.keras.layers.BatchNormalization()(x)\n",
    "#     x = tf.compat.v2.keras.layers.Activation('relu')(x)\n",
    "    x = (CuDNNLSTM(16, return_sequences = True, return_state = False))(x)\n",
    "#     x, slf_attn = MultiHeadAttention(n_head=int(80), d_model=300, d_k=64, d_v=64, dropout=0.1)(x, x, x)\n",
    "    \n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    concat2 = concatenate([avg_pool, max_pool])\n",
    "    x = Dense(600)(concat2)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('tanh')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = Dense(300)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('tanh')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = Dense(150)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('tanh')(x)    \n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = Dense(70)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('tanh')(x)    \n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = Dense(35, activation='tanh')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('tanh')(x)    \n",
    "    \n",
    "    x = Dense(15)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('tanh')(x)    \n",
    "    \n",
    "    x = Dense(7)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('tanh')(x)\n",
    "    \n",
    "    tailInput = Input(shape=(input2Length,))\n",
    "    tailLayers = Dense(input2Length, activation='tanh')(tailInput)\n",
    "    tailLayers = Dense(input2Length*2, activation='tanh')(tailInput)\n",
    "    tailLayers = Dense(input2Length*2*2, activation='tanh')(tailInput)\n",
    "    tailLayers = BatchNormalization()(tailInput)\n",
    "    tailLayers = Dropout(0.2)(tailInput)\n",
    "    tailLayers = Dense(input2Length*2, activation='tanh')(tailInput)\n",
    "    tailLayers = Dense(3, activation='tanh')(tailInput)\n",
    "    \n",
    "#     concat = concatenate([avg_pool, max_pool, tailLayers])\n",
    "    concat = concatenate([x, tailLayers])\n",
    "\n",
    "    y = Dense(3,activation = 'softmax')(concat)\n",
    "    \n",
    "\n",
    "    return Model(inputs = [i, tailInput], outputs = [y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_35 (InputLayer)           [(None, 360, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_70 (Conv1D)              (None, 179, 128)     1664        input_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 179, 128)     512         conv1d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 179, 128)     0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_171 (Dropout)           (None, 179, 128)     0           activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling1D) (None, 89, 128)      0           dropout_171[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_71 (Conv1D)              (None, 87, 64)       16448       max_pooling1d_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 87, 64)       256         conv1d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 87, 64)       0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_172 (Dropout)           (None, 87, 64)       0           activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling1D) (None, 43, 64)       0           dropout_172[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_72 (Conv1D)              (None, 41, 32)       4128        max_pooling1d_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 41, 32)       128         conv1d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 41, 32)       0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_173 (Dropout)           (None, 41, 32)       0           activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_73 (Conv1D)              (None, 39, 32)       2080        dropout_173[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 39, 32)       128         conv1d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 39, 32)       0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_174 (Dropout)           (None, 39, 32)       0           activation_195[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm (CuDNNLSTM)          (None, 39, 16)       3200        dropout_174[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_16 (Gl (None, 16)           0           cu_dnnlstm[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_16 (Global (None, 16)           0           cu_dnnlstm[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 32)           0           global_average_pooling1d_16[0][0]\n",
      "                                                                 global_max_pooling1d_16[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_252 (Dense)               (None, 600)          19800       concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 600)          2400        dense_252[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 600)          0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_175 (Dropout)           (None, 600)          0           activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_253 (Dense)               (None, 300)          180300      dropout_175[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 300)          1200        dense_253[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 300)          0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_176 (Dropout)           (None, 300)          0           activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_254 (Dense)               (None, 150)          45150       dropout_176[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 150)          600         dense_254[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 150)          0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_177 (Dropout)           (None, 150)          0           activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_255 (Dense)               (None, 70)           10570       dropout_177[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 70)           280         dense_255[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 70)           0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_178 (Dropout)           (None, 70)           0           activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_256 (Dense)               (None, 35)           2485        dropout_178[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 35)           140         dense_256[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 35)           0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_257 (Dense)               (None, 15)           540         activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 15)           60          dense_257[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 15)           0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_258 (Dense)               (None, 7)            112         activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 7)            28          dense_258[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_36 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 7)            0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_263 (Dense)               (None, 3)            18          input_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 10)           0           activation_202[0][0]             \n",
      "                                                                 dense_263[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_264 (Dense)               (None, 3)            33          concatenate_33[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 292,260\n",
      "Trainable params: 289,394\n",
      "Non-trainable params: 2,866\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = CnnTransformerModel()\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.090, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer=optimizer, \n",
    "                          loss='categorical_crossentropy'\n",
    "#                           loss_weights=[1., 1.]\n",
    "#                           loss_weights=[1.]\n",
    "#                             , metrics=['accuracy']\n",
    "                           , metrics=['accuracy', Recall(thresholds=0.1, class_id=0, top_k=1)\n",
    "                                , Recall(thresholds=0.1, class_id=2, top_k=1)\n",
    "                                  , Precision(thresholds=0.1, class_id=0, top_k=1)\n",
    "                                 , Precision(thresholds=0.1, class_id=2, top_k=1)\n",
    "                                 ]\n",
    "             )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizing The Model Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"5385pt\" viewBox=\"0.00 0.00 921.00 4039.00\" width=\"1228pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1.33333 1.33333) rotate(0) translate(4 4035)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-4035 917,-4035 917,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 1579318753096 -->\n",
       "<g class=\"node\" id=\"node1\"><title>1579318753096</title>\n",
       "<polygon fill=\"none\" points=\"327,-3984.5 327,-4030.5 599,-4030.5 599,-3984.5 327,-3984.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"393.5\" y=\"-4003.8\">input_35: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"460,-3984.5 460,-4030.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"488\" y=\"-4015.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"460,-4007.5 516,-4007.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"488\" y=\"-3992.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"516,-3984.5 516,-4030.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"557.5\" y=\"-4015.3\">[(?, 360, 3)]</text>\n",
       "<polyline fill=\"none\" points=\"516,-4007.5 599,-4007.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"557.5\" y=\"-3992.3\">[(?, 360, 3)]</text>\n",
       "</g>\n",
       "<!-- 1565912200584 -->\n",
       "<g class=\"node\" id=\"node2\"><title>1565912200584</title>\n",
       "<polygon fill=\"none\" points=\"324.5,-3901.5 324.5,-3947.5 601.5,-3947.5 601.5,-3901.5 324.5,-3901.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"391.5\" y=\"-3920.8\">conv1d_70: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"458.5,-3901.5 458.5,-3947.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"486.5\" y=\"-3932.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"458.5,-3924.5 514.5,-3924.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"486.5\" y=\"-3909.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"514.5,-3901.5 514.5,-3947.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"558\" y=\"-3932.3\">(?, 360, 3)</text>\n",
       "<polyline fill=\"none\" points=\"514.5,-3924.5 601.5,-3924.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"558\" y=\"-3909.3\">(?, 179, 128)</text>\n",
       "</g>\n",
       "<!-- 1579318753096&#45;&gt;1565912200584 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>1579318753096-&gt;1565912200584</title>\n",
       "<path d=\"M463,-3984.37C463,-3976.15 463,-3966.66 463,-3957.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-3957.61 463,-3947.61 459.5,-3957.61 466.5,-3957.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1565912200808 -->\n",
       "<g class=\"node\" id=\"node3\"><title>1565912200808</title>\n",
       "<polygon fill=\"none\" points=\"255,-3818.5 255,-3864.5 671,-3864.5 671,-3818.5 255,-3818.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"391.5\" y=\"-3837.8\">batch_normalization_197: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"528,-3818.5 528,-3864.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"556\" y=\"-3849.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"528,-3841.5 584,-3841.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"556\" y=\"-3826.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"584,-3818.5 584,-3864.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"627.5\" y=\"-3849.3\">(?, 179, 128)</text>\n",
       "<polyline fill=\"none\" points=\"584,-3841.5 671,-3841.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"627.5\" y=\"-3826.3\">(?, 179, 128)</text>\n",
       "</g>\n",
       "<!-- 1565912200584&#45;&gt;1565912200808 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>1565912200584-&gt;1565912200808</title>\n",
       "<path d=\"M463,-3901.37C463,-3893.15 463,-3883.66 463,-3874.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-3874.61 463,-3864.61 459.5,-3874.61 466.5,-3874.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1565912199408 -->\n",
       "<g class=\"node\" id=\"node4\"><title>1565912199408</title>\n",
       "<polygon fill=\"none\" points=\"311,-3735.5 311,-3781.5 615,-3781.5 615,-3735.5 311,-3735.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"391.5\" y=\"-3754.8\">activation_192: Activation</text>\n",
       "<polyline fill=\"none\" points=\"472,-3735.5 472,-3781.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"500\" y=\"-3766.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"472,-3758.5 528,-3758.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"500\" y=\"-3743.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"528,-3735.5 528,-3781.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"571.5\" y=\"-3766.3\">(?, 179, 128)</text>\n",
       "<polyline fill=\"none\" points=\"528,-3758.5 615,-3758.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"571.5\" y=\"-3743.3\">(?, 179, 128)</text>\n",
       "</g>\n",
       "<!-- 1565912200808&#45;&gt;1565912199408 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>1565912200808-&gt;1565912199408</title>\n",
       "<path d=\"M463,-3818.37C463,-3810.15 463,-3800.66 463,-3791.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-3791.61 463,-3781.61 459.5,-3791.61 466.5,-3791.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579319565952 -->\n",
       "<g class=\"node\" id=\"node5\"><title>1579319565952</title>\n",
       "<polygon fill=\"none\" points=\"320,-3652.5 320,-3698.5 606,-3698.5 606,-3652.5 320,-3652.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"391.5\" y=\"-3671.8\">dropout_171: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"463,-3652.5 463,-3698.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"491\" y=\"-3683.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"463,-3675.5 519,-3675.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"491\" y=\"-3660.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"519,-3652.5 519,-3698.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"562.5\" y=\"-3683.3\">(?, 179, 128)</text>\n",
       "<polyline fill=\"none\" points=\"519,-3675.5 606,-3675.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"562.5\" y=\"-3660.3\">(?, 179, 128)</text>\n",
       "</g>\n",
       "<!-- 1565912199408&#45;&gt;1579319565952 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>1565912199408-&gt;1579319565952</title>\n",
       "<path d=\"M463,-3735.37C463,-3727.15 463,-3717.66 463,-3708.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-3708.61 463,-3698.61 459.5,-3708.61 466.5,-3708.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579319659656 -->\n",
       "<g class=\"node\" id=\"node6\"><title>1579319659656</title>\n",
       "<polygon fill=\"none\" points=\"284,-3569.5 284,-3615.5 642,-3615.5 642,-3569.5 284,-3569.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"391.5\" y=\"-3588.8\">max_pooling1d_37: MaxPooling1D</text>\n",
       "<polyline fill=\"none\" points=\"499,-3569.5 499,-3615.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"527\" y=\"-3600.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"499,-3592.5 555,-3592.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"527\" y=\"-3577.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"555,-3569.5 555,-3615.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"598.5\" y=\"-3600.3\">(?, 179, 128)</text>\n",
       "<polyline fill=\"none\" points=\"555,-3592.5 642,-3592.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"598.5\" y=\"-3577.3\">(?, 89, 128)</text>\n",
       "</g>\n",
       "<!-- 1579319565952&#45;&gt;1579319659656 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>1579319565952-&gt;1579319659656</title>\n",
       "<path d=\"M463,-3652.37C463,-3644.15 463,-3634.66 463,-3625.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-3625.61 463,-3615.61 459.5,-3625.61 466.5,-3625.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579319693496 -->\n",
       "<g class=\"node\" id=\"node7\"><title>1579319693496</title>\n",
       "<polygon fill=\"none\" points=\"328,-3486.5 328,-3532.5 598,-3532.5 598,-3486.5 328,-3486.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"395\" y=\"-3505.8\">conv1d_71: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"462,-3486.5 462,-3532.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"490\" y=\"-3517.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"462,-3509.5 518,-3509.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"490\" y=\"-3494.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"518,-3486.5 518,-3532.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"558\" y=\"-3517.3\">(?, 89, 128)</text>\n",
       "<polyline fill=\"none\" points=\"518,-3509.5 598,-3509.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"558\" y=\"-3494.3\">(?, 87, 64)</text>\n",
       "</g>\n",
       "<!-- 1579319659656&#45;&gt;1579319693496 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>1579319659656-&gt;1579319693496</title>\n",
       "<path d=\"M463,-3569.37C463,-3561.15 463,-3551.66 463,-3542.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-3542.61 463,-3532.61 459.5,-3542.61 466.5,-3542.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579319793144 -->\n",
       "<g class=\"node\" id=\"node8\"><title>1579319793144</title>\n",
       "<polygon fill=\"none\" points=\"261.5,-3403.5 261.5,-3449.5 664.5,-3449.5 664.5,-3403.5 261.5,-3403.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"398\" y=\"-3422.8\">batch_normalization_198: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"534.5,-3403.5 534.5,-3449.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"562.5\" y=\"-3434.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"534.5,-3426.5 590.5,-3426.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"562.5\" y=\"-3411.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"590.5,-3403.5 590.5,-3449.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"627.5\" y=\"-3434.3\">(?, 87, 64)</text>\n",
       "<polyline fill=\"none\" points=\"590.5,-3426.5 664.5,-3426.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"627.5\" y=\"-3411.3\">(?, 87, 64)</text>\n",
       "</g>\n",
       "<!-- 1579319693496&#45;&gt;1579319793144 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>1579319693496-&gt;1579319793144</title>\n",
       "<path d=\"M463,-3486.37C463,-3478.15 463,-3468.66 463,-3459.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-3459.61 463,-3449.61 459.5,-3459.61 466.5,-3459.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579320178952 -->\n",
       "<g class=\"node\" id=\"node9\"><title>1579320178952</title>\n",
       "<polygon fill=\"none\" points=\"317.5,-3320.5 317.5,-3366.5 608.5,-3366.5 608.5,-3320.5 317.5,-3320.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"398\" y=\"-3339.8\">activation_193: Activation</text>\n",
       "<polyline fill=\"none\" points=\"478.5,-3320.5 478.5,-3366.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"506.5\" y=\"-3351.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"478.5,-3343.5 534.5,-3343.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"506.5\" y=\"-3328.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"534.5,-3320.5 534.5,-3366.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"571.5\" y=\"-3351.3\">(?, 87, 64)</text>\n",
       "<polyline fill=\"none\" points=\"534.5,-3343.5 608.5,-3343.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"571.5\" y=\"-3328.3\">(?, 87, 64)</text>\n",
       "</g>\n",
       "<!-- 1579319793144&#45;&gt;1579320178952 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>1579319793144-&gt;1579320178952</title>\n",
       "<path d=\"M463,-3403.37C463,-3395.15 463,-3385.66 463,-3376.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-3376.61 463,-3366.61 459.5,-3376.61 466.5,-3376.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579320102584 -->\n",
       "<g class=\"node\" id=\"node10\"><title>1579320102584</title>\n",
       "<polygon fill=\"none\" points=\"326.5,-3237.5 326.5,-3283.5 599.5,-3283.5 599.5,-3237.5 326.5,-3237.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"398\" y=\"-3256.8\">dropout_172: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"469.5,-3237.5 469.5,-3283.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"497.5\" y=\"-3268.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"469.5,-3260.5 525.5,-3260.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"497.5\" y=\"-3245.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"525.5,-3237.5 525.5,-3283.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"562.5\" y=\"-3268.3\">(?, 87, 64)</text>\n",
       "<polyline fill=\"none\" points=\"525.5,-3260.5 599.5,-3260.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"562.5\" y=\"-3245.3\">(?, 87, 64)</text>\n",
       "</g>\n",
       "<!-- 1579320178952&#45;&gt;1579320102584 -->\n",
       "<g class=\"edge\" id=\"edge9\"><title>1579320178952-&gt;1579320102584</title>\n",
       "<path d=\"M463,-3320.37C463,-3312.15 463,-3302.66 463,-3293.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-3293.61 463,-3283.61 459.5,-3293.61 466.5,-3293.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579320360408 -->\n",
       "<g class=\"node\" id=\"node11\"><title>1579320360408</title>\n",
       "<polygon fill=\"none\" points=\"290.5,-3154.5 290.5,-3200.5 635.5,-3200.5 635.5,-3154.5 290.5,-3154.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"398\" y=\"-3173.8\">max_pooling1d_38: MaxPooling1D</text>\n",
       "<polyline fill=\"none\" points=\"505.5,-3154.5 505.5,-3200.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"533.5\" y=\"-3185.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"505.5,-3177.5 561.5,-3177.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"533.5\" y=\"-3162.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"561.5,-3154.5 561.5,-3200.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"598.5\" y=\"-3185.3\">(?, 87, 64)</text>\n",
       "<polyline fill=\"none\" points=\"561.5,-3177.5 635.5,-3177.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"598.5\" y=\"-3162.3\">(?, 43, 64)</text>\n",
       "</g>\n",
       "<!-- 1579320102584&#45;&gt;1579320360408 -->\n",
       "<g class=\"edge\" id=\"edge10\"><title>1579320102584-&gt;1579320360408</title>\n",
       "<path d=\"M463,-3237.37C463,-3229.15 463,-3219.66 463,-3210.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-3210.61 463,-3200.61 459.5,-3210.61 466.5,-3210.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579320445360 -->\n",
       "<g class=\"node\" id=\"node12\"><title>1579320445360</title>\n",
       "<polygon fill=\"none\" points=\"331,-3071.5 331,-3117.5 595,-3117.5 595,-3071.5 331,-3071.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"398\" y=\"-3090.8\">conv1d_72: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"465,-3071.5 465,-3117.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"493\" y=\"-3102.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"465,-3094.5 521,-3094.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"493\" y=\"-3079.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"521,-3071.5 521,-3117.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"558\" y=\"-3102.3\">(?, 43, 64)</text>\n",
       "<polyline fill=\"none\" points=\"521,-3094.5 595,-3094.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"558\" y=\"-3079.3\">(?, 41, 32)</text>\n",
       "</g>\n",
       "<!-- 1579320360408&#45;&gt;1579320445360 -->\n",
       "<g class=\"edge\" id=\"edge11\"><title>1579320360408-&gt;1579320445360</title>\n",
       "<path d=\"M463,-3154.37C463,-3146.15 463,-3136.66 463,-3127.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-3127.61 463,-3117.61 459.5,-3127.61 466.5,-3127.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579320597752 -->\n",
       "<g class=\"node\" id=\"node13\"><title>1579320597752</title>\n",
       "<polygon fill=\"none\" points=\"261.5,-2988.5 261.5,-3034.5 664.5,-3034.5 664.5,-2988.5 261.5,-2988.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"398\" y=\"-3007.8\">batch_normalization_199: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"534.5,-2988.5 534.5,-3034.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"562.5\" y=\"-3019.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"534.5,-3011.5 590.5,-3011.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"562.5\" y=\"-2996.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"590.5,-2988.5 590.5,-3034.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"627.5\" y=\"-3019.3\">(?, 41, 32)</text>\n",
       "<polyline fill=\"none\" points=\"590.5,-3011.5 664.5,-3011.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"627.5\" y=\"-2996.3\">(?, 41, 32)</text>\n",
       "</g>\n",
       "<!-- 1579320445360&#45;&gt;1579320597752 -->\n",
       "<g class=\"edge\" id=\"edge12\"><title>1579320445360-&gt;1579320597752</title>\n",
       "<path d=\"M463,-3071.37C463,-3063.15 463,-3053.66 463,-3044.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-3044.61 463,-3034.61 459.5,-3044.61 466.5,-3044.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579320637984 -->\n",
       "<g class=\"node\" id=\"node14\"><title>1579320637984</title>\n",
       "<polygon fill=\"none\" points=\"317.5,-2905.5 317.5,-2951.5 608.5,-2951.5 608.5,-2905.5 317.5,-2905.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"398\" y=\"-2924.8\">activation_194: Activation</text>\n",
       "<polyline fill=\"none\" points=\"478.5,-2905.5 478.5,-2951.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"506.5\" y=\"-2936.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"478.5,-2928.5 534.5,-2928.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"506.5\" y=\"-2913.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"534.5,-2905.5 534.5,-2951.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"571.5\" y=\"-2936.3\">(?, 41, 32)</text>\n",
       "<polyline fill=\"none\" points=\"534.5,-2928.5 608.5,-2928.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"571.5\" y=\"-2913.3\">(?, 41, 32)</text>\n",
       "</g>\n",
       "<!-- 1579320597752&#45;&gt;1579320637984 -->\n",
       "<g class=\"edge\" id=\"edge13\"><title>1579320597752-&gt;1579320637984</title>\n",
       "<path d=\"M463,-2988.37C463,-2980.15 463,-2970.66 463,-2961.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-2961.61 463,-2951.61 459.5,-2961.61 466.5,-2961.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579320637200 -->\n",
       "<g class=\"node\" id=\"node15\"><title>1579320637200</title>\n",
       "<polygon fill=\"none\" points=\"326.5,-2822.5 326.5,-2868.5 599.5,-2868.5 599.5,-2822.5 326.5,-2822.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"398\" y=\"-2841.8\">dropout_173: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"469.5,-2822.5 469.5,-2868.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"497.5\" y=\"-2853.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"469.5,-2845.5 525.5,-2845.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"497.5\" y=\"-2830.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"525.5,-2822.5 525.5,-2868.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"562.5\" y=\"-2853.3\">(?, 41, 32)</text>\n",
       "<polyline fill=\"none\" points=\"525.5,-2845.5 599.5,-2845.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"562.5\" y=\"-2830.3\">(?, 41, 32)</text>\n",
       "</g>\n",
       "<!-- 1579320637984&#45;&gt;1579320637200 -->\n",
       "<g class=\"edge\" id=\"edge14\"><title>1579320637984-&gt;1579320637200</title>\n",
       "<path d=\"M463,-2905.37C463,-2897.15 463,-2887.66 463,-2878.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-2878.61 463,-2868.61 459.5,-2878.61 466.5,-2878.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579320968416 -->\n",
       "<g class=\"node\" id=\"node16\"><title>1579320968416</title>\n",
       "<polygon fill=\"none\" points=\"331,-2739.5 331,-2785.5 595,-2785.5 595,-2739.5 331,-2739.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"398\" y=\"-2758.8\">conv1d_73: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"465,-2739.5 465,-2785.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"493\" y=\"-2770.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"465,-2762.5 521,-2762.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"493\" y=\"-2747.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"521,-2739.5 521,-2785.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"558\" y=\"-2770.3\">(?, 41, 32)</text>\n",
       "<polyline fill=\"none\" points=\"521,-2762.5 595,-2762.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"558\" y=\"-2747.3\">(?, 39, 32)</text>\n",
       "</g>\n",
       "<!-- 1579320637200&#45;&gt;1579320968416 -->\n",
       "<g class=\"edge\" id=\"edge15\"><title>1579320637200-&gt;1579320968416</title>\n",
       "<path d=\"M463,-2822.37C463,-2814.15 463,-2804.66 463,-2795.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-2795.61 463,-2785.61 459.5,-2795.61 466.5,-2795.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579321068904 -->\n",
       "<g class=\"node\" id=\"node17\"><title>1579321068904</title>\n",
       "<polygon fill=\"none\" points=\"261.5,-2656.5 261.5,-2702.5 664.5,-2702.5 664.5,-2656.5 261.5,-2656.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"398\" y=\"-2675.8\">batch_normalization_200: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"534.5,-2656.5 534.5,-2702.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"562.5\" y=\"-2687.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"534.5,-2679.5 590.5,-2679.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"562.5\" y=\"-2664.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"590.5,-2656.5 590.5,-2702.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"627.5\" y=\"-2687.3\">(?, 39, 32)</text>\n",
       "<polyline fill=\"none\" points=\"590.5,-2679.5 664.5,-2679.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"627.5\" y=\"-2664.3\">(?, 39, 32)</text>\n",
       "</g>\n",
       "<!-- 1579320968416&#45;&gt;1579321068904 -->\n",
       "<g class=\"edge\" id=\"edge16\"><title>1579320968416-&gt;1579321068904</title>\n",
       "<path d=\"M463,-2739.37C463,-2731.15 463,-2721.66 463,-2712.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-2712.61 463,-2702.61 459.5,-2712.61 466.5,-2712.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579321118280 -->\n",
       "<g class=\"node\" id=\"node18\"><title>1579321118280</title>\n",
       "<polygon fill=\"none\" points=\"317.5,-2573.5 317.5,-2619.5 608.5,-2619.5 608.5,-2573.5 317.5,-2573.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"398\" y=\"-2592.8\">activation_195: Activation</text>\n",
       "<polyline fill=\"none\" points=\"478.5,-2573.5 478.5,-2619.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"506.5\" y=\"-2604.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"478.5,-2596.5 534.5,-2596.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"506.5\" y=\"-2581.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"534.5,-2573.5 534.5,-2619.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"571.5\" y=\"-2604.3\">(?, 39, 32)</text>\n",
       "<polyline fill=\"none\" points=\"534.5,-2596.5 608.5,-2596.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"571.5\" y=\"-2581.3\">(?, 39, 32)</text>\n",
       "</g>\n",
       "<!-- 1579321068904&#45;&gt;1579321118280 -->\n",
       "<g class=\"edge\" id=\"edge17\"><title>1579321068904-&gt;1579321118280</title>\n",
       "<path d=\"M463,-2656.37C463,-2648.15 463,-2638.66 463,-2629.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-2629.61 463,-2619.61 459.5,-2629.61 466.5,-2629.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579321116432 -->\n",
       "<g class=\"node\" id=\"node19\"><title>1579321116432</title>\n",
       "<polygon fill=\"none\" points=\"326.5,-2490.5 326.5,-2536.5 599.5,-2536.5 599.5,-2490.5 326.5,-2490.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"398\" y=\"-2509.8\">dropout_174: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"469.5,-2490.5 469.5,-2536.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"497.5\" y=\"-2521.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"469.5,-2513.5 525.5,-2513.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"497.5\" y=\"-2498.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"525.5,-2490.5 525.5,-2536.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"562.5\" y=\"-2521.3\">(?, 39, 32)</text>\n",
       "<polyline fill=\"none\" points=\"525.5,-2513.5 599.5,-2513.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"562.5\" y=\"-2498.3\">(?, 39, 32)</text>\n",
       "</g>\n",
       "<!-- 1579321118280&#45;&gt;1579321116432 -->\n",
       "<g class=\"edge\" id=\"edge18\"><title>1579321118280-&gt;1579321116432</title>\n",
       "<path d=\"M463,-2573.37C463,-2565.15 463,-2555.66 463,-2546.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-2546.61 463,-2536.61 459.5,-2546.61 466.5,-2546.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579322013848 -->\n",
       "<g class=\"node\" id=\"node20\"><title>1579322013848</title>\n",
       "<polygon fill=\"none\" points=\"312,-2407.5 312,-2453.5 614,-2453.5 614,-2407.5 312,-2407.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"398\" y=\"-2426.8\">cu_dnnlstm: CuDNNLSTM</text>\n",
       "<polyline fill=\"none\" points=\"484,-2407.5 484,-2453.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"512\" y=\"-2438.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"484,-2430.5 540,-2430.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"512\" y=\"-2415.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"540,-2407.5 540,-2453.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"577\" y=\"-2438.3\">(?, 39, 32)</text>\n",
       "<polyline fill=\"none\" points=\"540,-2430.5 614,-2430.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"577\" y=\"-2415.3\">(?, 39, 16)</text>\n",
       "</g>\n",
       "<!-- 1579321116432&#45;&gt;1579322013848 -->\n",
       "<g class=\"edge\" id=\"edge19\"><title>1579321116432-&gt;1579322013848</title>\n",
       "<path d=\"M463,-2490.37C463,-2482.15 463,-2472.66 463,-2463.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-2463.61 463,-2453.61 459.5,-2463.61 466.5,-2463.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579322147728 -->\n",
       "<g class=\"node\" id=\"node21\"><title>1579322147728</title>\n",
       "<polygon fill=\"none\" points=\"0,-2324.5 0,-2370.5 464,-2370.5 464,-2324.5 0,-2324.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"167\" y=\"-2343.8\">global_average_pooling1d_16: GlobalAveragePooling1D</text>\n",
       "<polyline fill=\"none\" points=\"334,-2324.5 334,-2370.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"362\" y=\"-2355.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"334,-2347.5 390,-2347.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"362\" y=\"-2332.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"390,-2324.5 390,-2370.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"427\" y=\"-2355.3\">(?, 39, 16)</text>\n",
       "<polyline fill=\"none\" points=\"390,-2347.5 464,-2347.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"427\" y=\"-2332.3\">(?, 16)</text>\n",
       "</g>\n",
       "<!-- 1579322013848&#45;&gt;1579322147728 -->\n",
       "<g class=\"edge\" id=\"edge20\"><title>1579322013848-&gt;1579322147728</title>\n",
       "<path d=\"M400.183,-2407.47C370.648,-2397.12 335.262,-2384.71 304.585,-2373.95\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"305.399,-2370.53 294.804,-2370.52 303.083,-2377.13 305.399,-2370.53\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579322367952 -->\n",
       "<g class=\"node\" id=\"node22\"><title>1579322367952</title>\n",
       "<polygon fill=\"none\" points=\"482,-2324.5 482,-2370.5 906,-2370.5 906,-2324.5 482,-2324.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"629\" y=\"-2343.8\">global_max_pooling1d_16: GlobalMaxPooling1D</text>\n",
       "<polyline fill=\"none\" points=\"776,-2324.5 776,-2370.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"804\" y=\"-2355.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"776,-2347.5 832,-2347.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"804\" y=\"-2332.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"832,-2324.5 832,-2370.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"869\" y=\"-2355.3\">(?, 39, 16)</text>\n",
       "<polyline fill=\"none\" points=\"832,-2347.5 906,-2347.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"869\" y=\"-2332.3\">(?, 16)</text>\n",
       "</g>\n",
       "<!-- 1579322013848&#45;&gt;1579322367952 -->\n",
       "<g class=\"edge\" id=\"edge21\"><title>1579322013848-&gt;1579322367952</title>\n",
       "<path d=\"M525.817,-2407.47C555.352,-2397.12 590.738,-2384.71 621.415,-2373.95\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"622.917,-2377.13 631.196,-2370.52 620.601,-2370.53 622.917,-2377.13\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579322492856 -->\n",
       "<g class=\"node\" id=\"node23\"><title>1579322492856</title>\n",
       "<polygon fill=\"none\" points=\"293,-2241.5 293,-2287.5 633,-2287.5 633,-2241.5 293,-2241.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"382.5\" y=\"-2260.8\">concatenate_32: Concatenate</text>\n",
       "<polyline fill=\"none\" points=\"472,-2241.5 472,-2287.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"500\" y=\"-2272.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"472,-2264.5 528,-2264.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"500\" y=\"-2249.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"528,-2241.5 528,-2287.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"580.5\" y=\"-2272.3\">[(?, 16), (?, 16)]</text>\n",
       "<polyline fill=\"none\" points=\"528,-2264.5 633,-2264.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"580.5\" y=\"-2249.3\">(?, 32)</text>\n",
       "</g>\n",
       "<!-- 1579322147728&#45;&gt;1579322492856 -->\n",
       "<g class=\"edge\" id=\"edge22\"><title>1579322147728-&gt;1579322492856</title>\n",
       "<path d=\"M294.817,-2324.47C324.352,-2314.12 359.738,-2301.71 390.415,-2290.95\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"391.917,-2294.13 400.196,-2287.52 389.601,-2287.53 391.917,-2294.13\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579322367952&#45;&gt;1579322492856 -->\n",
       "<g class=\"edge\" id=\"edge23\"><title>1579322367952-&gt;1579322492856</title>\n",
       "<path d=\"M631.183,-2324.47C601.648,-2314.12 566.262,-2301.71 535.585,-2290.95\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"536.399,-2287.53 525.804,-2287.52 534.083,-2294.13 536.399,-2287.53\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579322493192 -->\n",
       "<g class=\"node\" id=\"node24\"><title>1579322493192</title>\n",
       "<polygon fill=\"none\" points=\"346.5,-2158.5 346.5,-2204.5 579.5,-2204.5 579.5,-2158.5 346.5,-2158.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"405.5\" y=\"-2177.8\">dense_252: Dense</text>\n",
       "<polyline fill=\"none\" points=\"464.5,-2158.5 464.5,-2204.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"492.5\" y=\"-2189.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"464.5,-2181.5 520.5,-2181.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"492.5\" y=\"-2166.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"520.5,-2158.5 520.5,-2204.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"550\" y=\"-2189.3\">(?, 32)</text>\n",
       "<polyline fill=\"none\" points=\"520.5,-2181.5 579.5,-2181.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"550\" y=\"-2166.3\">(?, 600)</text>\n",
       "</g>\n",
       "<!-- 1579322492856&#45;&gt;1579322493192 -->\n",
       "<g class=\"edge\" id=\"edge24\"><title>1579322492856-&gt;1579322493192</title>\n",
       "<path d=\"M463,-2241.37C463,-2233.15 463,-2223.66 463,-2214.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-2214.61 463,-2204.61 459.5,-2214.61 466.5,-2214.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579322531912 -->\n",
       "<g class=\"node\" id=\"node25\"><title>1579322531912</title>\n",
       "<polygon fill=\"none\" points=\"269,-2075.5 269,-2121.5 657,-2121.5 657,-2075.5 269,-2075.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"405.5\" y=\"-2094.8\">batch_normalization_201: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"542,-2075.5 542,-2121.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"570\" y=\"-2106.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"542,-2098.5 598,-2098.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"570\" y=\"-2083.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"598,-2075.5 598,-2121.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"627.5\" y=\"-2106.3\">(?, 600)</text>\n",
       "<polyline fill=\"none\" points=\"598,-2098.5 657,-2098.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"627.5\" y=\"-2083.3\">(?, 600)</text>\n",
       "</g>\n",
       "<!-- 1579322493192&#45;&gt;1579322531912 -->\n",
       "<g class=\"edge\" id=\"edge25\"><title>1579322493192-&gt;1579322531912</title>\n",
       "<path d=\"M463,-2158.37C463,-2150.15 463,-2140.66 463,-2131.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-2131.61 463,-2121.61 459.5,-2131.61 466.5,-2131.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579322535664 -->\n",
       "<g class=\"node\" id=\"node26\"><title>1579322535664</title>\n",
       "<polygon fill=\"none\" points=\"325,-1992.5 325,-2038.5 601,-2038.5 601,-1992.5 325,-1992.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"405.5\" y=\"-2011.8\">activation_196: Activation</text>\n",
       "<polyline fill=\"none\" points=\"486,-1992.5 486,-2038.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"514\" y=\"-2023.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"486,-2015.5 542,-2015.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"514\" y=\"-2000.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"542,-1992.5 542,-2038.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"571.5\" y=\"-2023.3\">(?, 600)</text>\n",
       "<polyline fill=\"none\" points=\"542,-2015.5 601,-2015.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"571.5\" y=\"-2000.3\">(?, 600)</text>\n",
       "</g>\n",
       "<!-- 1579322531912&#45;&gt;1579322535664 -->\n",
       "<g class=\"edge\" id=\"edge26\"><title>1579322531912-&gt;1579322535664</title>\n",
       "<path d=\"M463,-2075.37C463,-2067.15 463,-2057.66 463,-2048.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-2048.61 463,-2038.61 459.5,-2048.61 466.5,-2048.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579321233760 -->\n",
       "<g class=\"node\" id=\"node27\"><title>1579321233760</title>\n",
       "<polygon fill=\"none\" points=\"334,-1909.5 334,-1955.5 592,-1955.5 592,-1909.5 334,-1909.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"405.5\" y=\"-1928.8\">dropout_175: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"477,-1909.5 477,-1955.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"505\" y=\"-1940.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"477,-1932.5 533,-1932.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"505\" y=\"-1917.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"533,-1909.5 533,-1955.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"562.5\" y=\"-1940.3\">(?, 600)</text>\n",
       "<polyline fill=\"none\" points=\"533,-1932.5 592,-1932.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"562.5\" y=\"-1917.3\">(?, 600)</text>\n",
       "</g>\n",
       "<!-- 1579322535664&#45;&gt;1579321233760 -->\n",
       "<g class=\"edge\" id=\"edge27\"><title>1579322535664-&gt;1579321233760</title>\n",
       "<path d=\"M463,-1992.37C463,-1984.15 463,-1974.66 463,-1965.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-1965.61 463,-1955.61 459.5,-1965.61 466.5,-1965.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579322764984 -->\n",
       "<g class=\"node\" id=\"node28\"><title>1579322764984</title>\n",
       "<polygon fill=\"none\" points=\"346.5,-1826.5 346.5,-1872.5 579.5,-1872.5 579.5,-1826.5 346.5,-1826.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"405.5\" y=\"-1845.8\">dense_253: Dense</text>\n",
       "<polyline fill=\"none\" points=\"464.5,-1826.5 464.5,-1872.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"492.5\" y=\"-1857.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"464.5,-1849.5 520.5,-1849.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"492.5\" y=\"-1834.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"520.5,-1826.5 520.5,-1872.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"550\" y=\"-1857.3\">(?, 600)</text>\n",
       "<polyline fill=\"none\" points=\"520.5,-1849.5 579.5,-1849.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"550\" y=\"-1834.3\">(?, 300)</text>\n",
       "</g>\n",
       "<!-- 1579321233760&#45;&gt;1579322764984 -->\n",
       "<g class=\"edge\" id=\"edge28\"><title>1579321233760-&gt;1579322764984</title>\n",
       "<path d=\"M463,-1909.37C463,-1901.15 463,-1891.66 463,-1882.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-1882.61 463,-1872.61 459.5,-1882.61 466.5,-1882.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579322988584 -->\n",
       "<g class=\"node\" id=\"node29\"><title>1579322988584</title>\n",
       "<polygon fill=\"none\" points=\"269,-1743.5 269,-1789.5 657,-1789.5 657,-1743.5 269,-1743.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"405.5\" y=\"-1762.8\">batch_normalization_202: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"542,-1743.5 542,-1789.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"570\" y=\"-1774.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"542,-1766.5 598,-1766.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"570\" y=\"-1751.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"598,-1743.5 598,-1789.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"627.5\" y=\"-1774.3\">(?, 300)</text>\n",
       "<polyline fill=\"none\" points=\"598,-1766.5 657,-1766.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"627.5\" y=\"-1751.3\">(?, 300)</text>\n",
       "</g>\n",
       "<!-- 1579322764984&#45;&gt;1579322988584 -->\n",
       "<g class=\"edge\" id=\"edge29\"><title>1579322764984-&gt;1579322988584</title>\n",
       "<path d=\"M463,-1826.37C463,-1818.15 463,-1808.66 463,-1799.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-1799.61 463,-1789.61 459.5,-1799.61 466.5,-1799.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579322987016 -->\n",
       "<g class=\"node\" id=\"node30\"><title>1579322987016</title>\n",
       "<polygon fill=\"none\" points=\"325,-1660.5 325,-1706.5 601,-1706.5 601,-1660.5 325,-1660.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"405.5\" y=\"-1679.8\">activation_197: Activation</text>\n",
       "<polyline fill=\"none\" points=\"486,-1660.5 486,-1706.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"514\" y=\"-1691.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"486,-1683.5 542,-1683.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"514\" y=\"-1668.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"542,-1660.5 542,-1706.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"571.5\" y=\"-1691.3\">(?, 300)</text>\n",
       "<polyline fill=\"none\" points=\"542,-1683.5 601,-1683.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"571.5\" y=\"-1668.3\">(?, 300)</text>\n",
       "</g>\n",
       "<!-- 1579322988584&#45;&gt;1579322987016 -->\n",
       "<g class=\"edge\" id=\"edge30\"><title>1579322988584-&gt;1579322987016</title>\n",
       "<path d=\"M463,-1743.37C463,-1735.15 463,-1725.66 463,-1716.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-1716.61 463,-1706.61 459.5,-1716.61 466.5,-1716.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579322989088 -->\n",
       "<g class=\"node\" id=\"node31\"><title>1579322989088</title>\n",
       "<polygon fill=\"none\" points=\"334,-1577.5 334,-1623.5 592,-1623.5 592,-1577.5 334,-1577.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"405.5\" y=\"-1596.8\">dropout_176: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"477,-1577.5 477,-1623.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"505\" y=\"-1608.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"477,-1600.5 533,-1600.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"505\" y=\"-1585.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"533,-1577.5 533,-1623.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"562.5\" y=\"-1608.3\">(?, 300)</text>\n",
       "<polyline fill=\"none\" points=\"533,-1600.5 592,-1600.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"562.5\" y=\"-1585.3\">(?, 300)</text>\n",
       "</g>\n",
       "<!-- 1579322987016&#45;&gt;1579322989088 -->\n",
       "<g class=\"edge\" id=\"edge31\"><title>1579322987016-&gt;1579322989088</title>\n",
       "<path d=\"M463,-1660.37C463,-1652.15 463,-1642.66 463,-1633.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-1633.61 463,-1623.61 459.5,-1633.61 466.5,-1633.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579323045480 -->\n",
       "<g class=\"node\" id=\"node32\"><title>1579323045480</title>\n",
       "<polygon fill=\"none\" points=\"346.5,-1494.5 346.5,-1540.5 579.5,-1540.5 579.5,-1494.5 346.5,-1494.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"405.5\" y=\"-1513.8\">dense_254: Dense</text>\n",
       "<polyline fill=\"none\" points=\"464.5,-1494.5 464.5,-1540.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"492.5\" y=\"-1525.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"464.5,-1517.5 520.5,-1517.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"492.5\" y=\"-1502.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"520.5,-1494.5 520.5,-1540.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"550\" y=\"-1525.3\">(?, 300)</text>\n",
       "<polyline fill=\"none\" points=\"520.5,-1517.5 579.5,-1517.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"550\" y=\"-1502.3\">(?, 150)</text>\n",
       "</g>\n",
       "<!-- 1579322989088&#45;&gt;1579323045480 -->\n",
       "<g class=\"edge\" id=\"edge32\"><title>1579322989088-&gt;1579323045480</title>\n",
       "<path d=\"M463,-1577.37C463,-1569.15 463,-1559.66 463,-1550.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-1550.61 463,-1540.61 459.5,-1550.61 466.5,-1550.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579323420456 -->\n",
       "<g class=\"node\" id=\"node33\"><title>1579323420456</title>\n",
       "<polygon fill=\"none\" points=\"269,-1411.5 269,-1457.5 657,-1457.5 657,-1411.5 269,-1411.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"405.5\" y=\"-1430.8\">batch_normalization_203: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"542,-1411.5 542,-1457.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"570\" y=\"-1442.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"542,-1434.5 598,-1434.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"570\" y=\"-1419.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"598,-1411.5 598,-1457.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"627.5\" y=\"-1442.3\">(?, 150)</text>\n",
       "<polyline fill=\"none\" points=\"598,-1434.5 657,-1434.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"627.5\" y=\"-1419.3\">(?, 150)</text>\n",
       "</g>\n",
       "<!-- 1579323045480&#45;&gt;1579323420456 -->\n",
       "<g class=\"edge\" id=\"edge33\"><title>1579323045480-&gt;1579323420456</title>\n",
       "<path d=\"M463,-1494.37C463,-1486.15 463,-1476.66 463,-1467.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-1467.61 463,-1457.61 459.5,-1467.61 466.5,-1467.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579323470568 -->\n",
       "<g class=\"node\" id=\"node34\"><title>1579323470568</title>\n",
       "<polygon fill=\"none\" points=\"325,-1328.5 325,-1374.5 601,-1374.5 601,-1328.5 325,-1328.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"405.5\" y=\"-1347.8\">activation_198: Activation</text>\n",
       "<polyline fill=\"none\" points=\"486,-1328.5 486,-1374.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"514\" y=\"-1359.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"486,-1351.5 542,-1351.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"514\" y=\"-1336.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"542,-1328.5 542,-1374.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"571.5\" y=\"-1359.3\">(?, 150)</text>\n",
       "<polyline fill=\"none\" points=\"542,-1351.5 601,-1351.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"571.5\" y=\"-1336.3\">(?, 150)</text>\n",
       "</g>\n",
       "<!-- 1579323420456&#45;&gt;1579323470568 -->\n",
       "<g class=\"edge\" id=\"edge34\"><title>1579323420456-&gt;1579323470568</title>\n",
       "<path d=\"M463,-1411.37C463,-1403.15 463,-1393.66 463,-1384.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-1384.61 463,-1374.61 459.5,-1384.61 466.5,-1384.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579323470400 -->\n",
       "<g class=\"node\" id=\"node35\"><title>1579323470400</title>\n",
       "<polygon fill=\"none\" points=\"334,-1245.5 334,-1291.5 592,-1291.5 592,-1245.5 334,-1245.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"405.5\" y=\"-1264.8\">dropout_177: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"477,-1245.5 477,-1291.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"505\" y=\"-1276.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"477,-1268.5 533,-1268.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"505\" y=\"-1253.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"533,-1245.5 533,-1291.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"562.5\" y=\"-1276.3\">(?, 150)</text>\n",
       "<polyline fill=\"none\" points=\"533,-1268.5 592,-1268.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"562.5\" y=\"-1253.3\">(?, 150)</text>\n",
       "</g>\n",
       "<!-- 1579323470568&#45;&gt;1579323470400 -->\n",
       "<g class=\"edge\" id=\"edge35\"><title>1579323470568-&gt;1579323470400</title>\n",
       "<path d=\"M463,-1328.37C463,-1320.15 463,-1310.66 463,-1301.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-1301.61 463,-1291.61 459.5,-1301.61 466.5,-1301.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579323929936 -->\n",
       "<g class=\"node\" id=\"node36\"><title>1579323929936</title>\n",
       "<polygon fill=\"none\" points=\"346.5,-1162.5 346.5,-1208.5 579.5,-1208.5 579.5,-1162.5 346.5,-1162.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"405.5\" y=\"-1181.8\">dense_255: Dense</text>\n",
       "<polyline fill=\"none\" points=\"464.5,-1162.5 464.5,-1208.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"492.5\" y=\"-1193.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"464.5,-1185.5 520.5,-1185.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"492.5\" y=\"-1170.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"520.5,-1162.5 520.5,-1208.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"550\" y=\"-1193.3\">(?, 150)</text>\n",
       "<polyline fill=\"none\" points=\"520.5,-1185.5 579.5,-1185.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"550\" y=\"-1170.3\">(?, 70)</text>\n",
       "</g>\n",
       "<!-- 1579323470400&#45;&gt;1579323929936 -->\n",
       "<g class=\"edge\" id=\"edge36\"><title>1579323470400-&gt;1579323929936</title>\n",
       "<path d=\"M463,-1245.37C463,-1237.15 463,-1227.66 463,-1218.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-1218.61 463,-1208.61 459.5,-1218.61 466.5,-1218.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579324149544 -->\n",
       "<g class=\"node\" id=\"node37\"><title>1579324149544</title>\n",
       "<polygon fill=\"none\" points=\"272,-1079.5 272,-1125.5 654,-1125.5 654,-1079.5 272,-1079.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"408.5\" y=\"-1098.8\">batch_normalization_204: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"545,-1079.5 545,-1125.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"573\" y=\"-1110.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"545,-1102.5 601,-1102.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"573\" y=\"-1087.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"601,-1079.5 601,-1125.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"627.5\" y=\"-1110.3\">(?, 70)</text>\n",
       "<polyline fill=\"none\" points=\"601,-1102.5 654,-1102.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"627.5\" y=\"-1087.3\">(?, 70)</text>\n",
       "</g>\n",
       "<!-- 1579323929936&#45;&gt;1579324149544 -->\n",
       "<g class=\"edge\" id=\"edge37\"><title>1579323929936-&gt;1579324149544</title>\n",
       "<path d=\"M463,-1162.37C463,-1154.15 463,-1144.66 463,-1135.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-1135.61 463,-1125.61 459.5,-1135.61 466.5,-1135.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579324209360 -->\n",
       "<g class=\"node\" id=\"node38\"><title>1579324209360</title>\n",
       "<polygon fill=\"none\" points=\"328,-996.5 328,-1042.5 598,-1042.5 598,-996.5 328,-996.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"408.5\" y=\"-1015.8\">activation_199: Activation</text>\n",
       "<polyline fill=\"none\" points=\"489,-996.5 489,-1042.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"517\" y=\"-1027.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"489,-1019.5 545,-1019.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"517\" y=\"-1004.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"545,-996.5 545,-1042.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"571.5\" y=\"-1027.3\">(?, 70)</text>\n",
       "<polyline fill=\"none\" points=\"545,-1019.5 598,-1019.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"571.5\" y=\"-1004.3\">(?, 70)</text>\n",
       "</g>\n",
       "<!-- 1579324149544&#45;&gt;1579324209360 -->\n",
       "<g class=\"edge\" id=\"edge38\"><title>1579324149544-&gt;1579324209360</title>\n",
       "<path d=\"M463,-1079.37C463,-1071.15 463,-1061.66 463,-1052.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-1052.61 463,-1042.61 459.5,-1052.61 466.5,-1052.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579324209584 -->\n",
       "<g class=\"node\" id=\"node39\"><title>1579324209584</title>\n",
       "<polygon fill=\"none\" points=\"337,-913.5 337,-959.5 589,-959.5 589,-913.5 337,-913.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"408.5\" y=\"-932.8\">dropout_178: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"480,-913.5 480,-959.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"508\" y=\"-944.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"480,-936.5 536,-936.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"508\" y=\"-921.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"536,-913.5 536,-959.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"562.5\" y=\"-944.3\">(?, 70)</text>\n",
       "<polyline fill=\"none\" points=\"536,-936.5 589,-936.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"562.5\" y=\"-921.3\">(?, 70)</text>\n",
       "</g>\n",
       "<!-- 1579324209360&#45;&gt;1579324209584 -->\n",
       "<g class=\"edge\" id=\"edge39\"><title>1579324209360-&gt;1579324209584</title>\n",
       "<path d=\"M463,-996.366C463,-988.152 463,-978.658 463,-969.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-969.607 463,-959.607 459.5,-969.607 466.5,-969.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579324207344 -->\n",
       "<g class=\"node\" id=\"node40\"><title>1579324207344</title>\n",
       "<polygon fill=\"none\" points=\"349.5,-830.5 349.5,-876.5 576.5,-876.5 576.5,-830.5 349.5,-830.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"408.5\" y=\"-849.8\">dense_256: Dense</text>\n",
       "<polyline fill=\"none\" points=\"467.5,-830.5 467.5,-876.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"495.5\" y=\"-861.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"467.5,-853.5 523.5,-853.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"495.5\" y=\"-838.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"523.5,-830.5 523.5,-876.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"550\" y=\"-861.3\">(?, 70)</text>\n",
       "<polyline fill=\"none\" points=\"523.5,-853.5 576.5,-853.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"550\" y=\"-838.3\">(?, 35)</text>\n",
       "</g>\n",
       "<!-- 1579324209584&#45;&gt;1579324207344 -->\n",
       "<g class=\"edge\" id=\"edge40\"><title>1579324209584-&gt;1579324207344</title>\n",
       "<path d=\"M463,-913.366C463,-905.152 463,-895.658 463,-886.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-886.607 463,-876.607 459.5,-886.607 466.5,-886.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579324561224 -->\n",
       "<g class=\"node\" id=\"node41\"><title>1579324561224</title>\n",
       "<polygon fill=\"none\" points=\"272,-747.5 272,-793.5 654,-793.5 654,-747.5 272,-747.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"408.5\" y=\"-766.8\">batch_normalization_205: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"545,-747.5 545,-793.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"573\" y=\"-778.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"545,-770.5 601,-770.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"573\" y=\"-755.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"601,-747.5 601,-793.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"627.5\" y=\"-778.3\">(?, 35)</text>\n",
       "<polyline fill=\"none\" points=\"601,-770.5 654,-770.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"627.5\" y=\"-755.3\">(?, 35)</text>\n",
       "</g>\n",
       "<!-- 1579324207344&#45;&gt;1579324561224 -->\n",
       "<g class=\"edge\" id=\"edge41\"><title>1579324207344-&gt;1579324561224</title>\n",
       "<path d=\"M463,-830.366C463,-822.152 463,-812.658 463,-803.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-803.607 463,-793.607 459.5,-803.607 466.5,-803.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579324681296 -->\n",
       "<g class=\"node\" id=\"node42\"><title>1579324681296</title>\n",
       "<polygon fill=\"none\" points=\"328,-664.5 328,-710.5 598,-710.5 598,-664.5 328,-664.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"408.5\" y=\"-683.8\">activation_200: Activation</text>\n",
       "<polyline fill=\"none\" points=\"489,-664.5 489,-710.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"517\" y=\"-695.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"489,-687.5 545,-687.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"517\" y=\"-672.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"545,-664.5 545,-710.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"571.5\" y=\"-695.3\">(?, 35)</text>\n",
       "<polyline fill=\"none\" points=\"545,-687.5 598,-687.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"571.5\" y=\"-672.3\">(?, 35)</text>\n",
       "</g>\n",
       "<!-- 1579324561224&#45;&gt;1579324681296 -->\n",
       "<g class=\"edge\" id=\"edge42\"><title>1579324561224-&gt;1579324681296</title>\n",
       "<path d=\"M463,-747.366C463,-739.152 463,-729.658 463,-720.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-720.607 463,-710.607 459.5,-720.607 466.5,-720.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579324680512 -->\n",
       "<g class=\"node\" id=\"node43\"><title>1579324680512</title>\n",
       "<polygon fill=\"none\" points=\"349.5,-581.5 349.5,-627.5 576.5,-627.5 576.5,-581.5 349.5,-581.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"408.5\" y=\"-600.8\">dense_257: Dense</text>\n",
       "<polyline fill=\"none\" points=\"467.5,-581.5 467.5,-627.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"495.5\" y=\"-612.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"467.5,-604.5 523.5,-604.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"495.5\" y=\"-589.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"523.5,-581.5 523.5,-627.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"550\" y=\"-612.3\">(?, 35)</text>\n",
       "<polyline fill=\"none\" points=\"523.5,-604.5 576.5,-604.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"550\" y=\"-589.3\">(?, 15)</text>\n",
       "</g>\n",
       "<!-- 1579324681296&#45;&gt;1579324680512 -->\n",
       "<g class=\"edge\" id=\"edge43\"><title>1579324681296-&gt;1579324680512</title>\n",
       "<path d=\"M463,-664.366C463,-656.152 463,-646.658 463,-637.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-637.607 463,-627.607 459.5,-637.607 466.5,-637.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579325002584 -->\n",
       "<g class=\"node\" id=\"node44\"><title>1579325002584</title>\n",
       "<polygon fill=\"none\" points=\"272,-498.5 272,-544.5 654,-544.5 654,-498.5 272,-498.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"408.5\" y=\"-517.8\">batch_normalization_206: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"545,-498.5 545,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"573\" y=\"-529.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"545,-521.5 601,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"573\" y=\"-506.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"601,-498.5 601,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"627.5\" y=\"-529.3\">(?, 15)</text>\n",
       "<polyline fill=\"none\" points=\"601,-521.5 654,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"627.5\" y=\"-506.3\">(?, 15)</text>\n",
       "</g>\n",
       "<!-- 1579324680512&#45;&gt;1579325002584 -->\n",
       "<g class=\"edge\" id=\"edge44\"><title>1579324680512-&gt;1579325002584</title>\n",
       "<path d=\"M463,-581.366C463,-573.152 463,-563.658 463,-554.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-554.607 463,-544.607 459.5,-554.607 466.5,-554.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579325004208 -->\n",
       "<g class=\"node\" id=\"node45\"><title>1579325004208</title>\n",
       "<polygon fill=\"none\" points=\"328,-415.5 328,-461.5 598,-461.5 598,-415.5 328,-415.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"408.5\" y=\"-434.8\">activation_201: Activation</text>\n",
       "<polyline fill=\"none\" points=\"489,-415.5 489,-461.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"517\" y=\"-446.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"489,-438.5 545,-438.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"517\" y=\"-423.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"545,-415.5 545,-461.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"571.5\" y=\"-446.3\">(?, 15)</text>\n",
       "<polyline fill=\"none\" points=\"545,-438.5 598,-438.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"571.5\" y=\"-423.3\">(?, 15)</text>\n",
       "</g>\n",
       "<!-- 1579325002584&#45;&gt;1579325004208 -->\n",
       "<g class=\"edge\" id=\"edge45\"><title>1579325002584-&gt;1579325004208</title>\n",
       "<path d=\"M463,-498.366C463,-490.152 463,-480.658 463,-471.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-471.607 463,-461.607 459.5,-471.607 466.5,-471.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579325005496 -->\n",
       "<g class=\"node\" id=\"node46\"><title>1579325005496</title>\n",
       "<polygon fill=\"none\" points=\"349.5,-332.5 349.5,-378.5 576.5,-378.5 576.5,-332.5 349.5,-332.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"408.5\" y=\"-351.8\">dense_258: Dense</text>\n",
       "<polyline fill=\"none\" points=\"467.5,-332.5 467.5,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"495.5\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"467.5,-355.5 523.5,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"495.5\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"523.5,-332.5 523.5,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"550\" y=\"-363.3\">(?, 15)</text>\n",
       "<polyline fill=\"none\" points=\"523.5,-355.5 576.5,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"550\" y=\"-340.3\">(?, 7)</text>\n",
       "</g>\n",
       "<!-- 1579325004208&#45;&gt;1579325005496 -->\n",
       "<g class=\"edge\" id=\"edge46\"><title>1579325004208-&gt;1579325005496</title>\n",
       "<path d=\"M463,-415.366C463,-407.152 463,-397.658 463,-388.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-388.607 463,-378.607 459.5,-388.607 466.5,-388.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579325323136 -->\n",
       "<g class=\"node\" id=\"node47\"><title>1579325323136</title>\n",
       "<polygon fill=\"none\" points=\"275.5,-249.5 275.5,-295.5 650.5,-295.5 650.5,-249.5 275.5,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"412\" y=\"-268.8\">batch_normalization_207: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"548.5,-249.5 548.5,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"576.5\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"548.5,-272.5 604.5,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"576.5\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"604.5,-249.5 604.5,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"627.5\" y=\"-280.3\">(?, 7)</text>\n",
       "<polyline fill=\"none\" points=\"604.5,-272.5 650.5,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"627.5\" y=\"-257.3\">(?, 7)</text>\n",
       "</g>\n",
       "<!-- 1579325005496&#45;&gt;1579325323136 -->\n",
       "<g class=\"edge\" id=\"edge47\"><title>1579325005496-&gt;1579325323136</title>\n",
       "<path d=\"M463,-332.366C463,-324.152 463,-314.658 463,-305.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"466.5,-305.607 463,-295.607 459.5,-305.607 466.5,-305.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579325324536 -->\n",
       "<g class=\"node\" id=\"node49\"><title>1579325324536</title>\n",
       "<polygon fill=\"none\" points=\"365.5,-166.5 365.5,-212.5 628.5,-212.5 628.5,-166.5 365.5,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"446\" y=\"-185.8\">activation_202: Activation</text>\n",
       "<polyline fill=\"none\" points=\"526.5,-166.5 526.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"554.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"526.5,-189.5 582.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"554.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"582.5,-166.5 582.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"605.5\" y=\"-197.3\">(?, 7)</text>\n",
       "<polyline fill=\"none\" points=\"582.5,-189.5 628.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"605.5\" y=\"-174.3\">(?, 7)</text>\n",
       "</g>\n",
       "<!-- 1579325323136&#45;&gt;1579325324536 -->\n",
       "<g class=\"edge\" id=\"edge48\"><title>1579325323136-&gt;1579325324536</title>\n",
       "<path d=\"M472.291,-249.366C475.851,-240.884 479.984,-231.037 483.839,-221.853\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"487.077,-223.182 487.721,-212.607 480.623,-220.473 487.077,-223.182\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579325347040 -->\n",
       "<g class=\"node\" id=\"node48\"><title>1579325347040</title>\n",
       "<polygon fill=\"none\" points=\"669,-249.5 669,-295.5 913,-295.5 913,-249.5 669,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"735.5\" y=\"-268.8\">input_36: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"802,-249.5 802,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"830\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"802,-272.5 858,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"830\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"858,-249.5 858,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"885.5\" y=\"-280.3\">[(?, 5)]</text>\n",
       "<polyline fill=\"none\" points=\"858,-272.5 913,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"885.5\" y=\"-257.3\">[(?, 5)]</text>\n",
       "</g>\n",
       "<!-- 1579326051384 -->\n",
       "<g class=\"node\" id=\"node50\"><title>1579326051384</title>\n",
       "<polygon fill=\"none\" points=\"664,-166.5 664,-212.5 884,-212.5 884,-166.5 664,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"723\" y=\"-185.8\">dense_263: Dense</text>\n",
       "<polyline fill=\"none\" points=\"782,-166.5 782,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"810\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"782,-189.5 838,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"810\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"838,-166.5 838,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"861\" y=\"-197.3\">(?, 5)</text>\n",
       "<polyline fill=\"none\" points=\"838,-189.5 884,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"861\" y=\"-174.3\">(?, 3)</text>\n",
       "</g>\n",
       "<!-- 1579325347040&#45;&gt;1579326051384 -->\n",
       "<g class=\"edge\" id=\"edge49\"><title>1579325347040-&gt;1579326051384</title>\n",
       "<path d=\"M786.355,-249.366C784.612,-241.062 782.595,-231.451 780.702,-222.434\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"784.119,-221.675 778.64,-212.607 777.268,-223.113 784.119,-221.675\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579326193224 -->\n",
       "<g class=\"node\" id=\"node51\"><title>1579326193224</title>\n",
       "<polygon fill=\"none\" points=\"471.5,-83.5 471.5,-129.5 798.5,-129.5 798.5,-83.5 471.5,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"561\" y=\"-102.8\">concatenate_33: Concatenate</text>\n",
       "<polyline fill=\"none\" points=\"650.5,-83.5 650.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"678.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"650.5,-106.5 706.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"678.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"706.5,-83.5 706.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"752.5\" y=\"-114.3\">[(?, 7), (?, 3)]</text>\n",
       "<polyline fill=\"none\" points=\"706.5,-106.5 798.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"752.5\" y=\"-91.3\">(?, 10)</text>\n",
       "</g>\n",
       "<!-- 1579325324536&#45;&gt;1579326193224 -->\n",
       "<g class=\"edge\" id=\"edge50\"><title>1579325324536-&gt;1579326193224</title>\n",
       "<path d=\"M534.709,-166.366C551.291,-156.634 570.931,-145.106 588.417,-134.842\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"590.484,-137.687 597.336,-129.607 586.941,-131.65 590.484,-137.687\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579326051384&#45;&gt;1579326193224 -->\n",
       "<g class=\"edge\" id=\"edge51\"><title>1579326051384-&gt;1579326193224</title>\n",
       "<path d=\"M736.018,-166.366C719.316,-156.634 699.533,-145.106 681.921,-134.842\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"683.339,-131.618 672.936,-129.607 679.814,-137.666 683.339,-131.618\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1579326190088 -->\n",
       "<g class=\"node\" id=\"node52\"><title>1579326190088</title>\n",
       "<polygon fill=\"none\" points=\"521.5,-0.5 521.5,-46.5 748.5,-46.5 748.5,-0.5 521.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"580.5\" y=\"-19.8\">dense_264: Dense</text>\n",
       "<polyline fill=\"none\" points=\"639.5,-0.5 639.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"667.5\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"639.5,-23.5 695.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"667.5\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"695.5,-0.5 695.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"722\" y=\"-31.3\">(?, 10)</text>\n",
       "<polyline fill=\"none\" points=\"695.5,-23.5 748.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"722\" y=\"-8.3\">(?, 3)</text>\n",
       "</g>\n",
       "<!-- 1579326193224&#45;&gt;1579326190088 -->\n",
       "<g class=\"edge\" id=\"edge52\"><title>1579326193224-&gt;1579326190088</title>\n",
       "<path d=\"M635,-83.3664C635,-75.1516 635,-65.6579 635,-56.7252\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"638.5,-56.6068 635,-46.6068 631.5,-56.6069 638.5,-56.6068\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from tensorflow.python.keras.utils.vis_utils import model_to_dot\n",
    "SVG(model_to_dot(model,show_shapes = True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5bed51171db8bf8c5e1731119fd31205bfd80a82"
   },
   "source": [
    "Train the model with early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": false,
    "_uuid": "e1061c7cde0687450300f516735aad0cc5dbf08f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0607 23:49:21.092264 12736 callbacks.py:2207] `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "      2/Unknown - 0s 0s/step - loss: 1.2070 - accuracy: 0.2977 - recall_26: 0.4839 - recall_27: 0.0859 - precision_26: 0.1705 - precision_27: 0.22 - 4s 2s/step - loss: 1.1524 - accuracy: 0.3358 - recall_26: 0.2167 - recall_27: 0.2331 - precision_26: 0.1711 - precision_27: 0.2134"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0607 23:49:37.863744 12736 callbacks.py:307] Method (on_train_batch_end) is slow compared to the batch update (2.033191). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     19/Unknown - 4s 1s/step - loss: 1.0766 - accuracy: 0.4483 - recall_26: 0.1285 - recall_27: 0.1990 - precision_26: 0.1847 - precision_27: 0.21 - 4s 701ms/step - loss: 1.0206 - accuracy: 0.5112 - recall_26: 0.0893 - recall_27: 0.1447 - precision_26: 0.1847 - precision_27: 0.218 - 4s 533ms/step - loss: 1.0132 - accuracy: 0.5390 - recall_26: 0.0721 - recall_27: 0.1057 - precision_26: 0.1847 - precision_27: 0.218 - 4s 433ms/step - loss: 1.0155 - accuracy: 0.5425 - recall_26: 0.0562 - recall_27: 0.0836 - precision_26: 0.1847 - precision_27: 0.218 - 4s 339ms/step - loss: 0.9822 - accuracy: 0.5771 - recall_26: 0.0614 - recall_27: 0.0695 - precision_26: 0.1701 - precision_27: 0.218 - 4s 297ms/step - loss: 1.0124 - accuracy: 0.5572 - recall_26: 0.0519 - recall_27: 0.0543 - precision_26: 0.1701 - precision_27: 0.218 - 5s 265ms/step - loss: 1.0166 - accuracy: 0.5564 - recall_26: 0.0442 - recall_27: 0.0482 - precision_26: 0.1701 - precision_27: 0.218 - 5s 240ms/step - loss: 1.0147 - accuracy: 0.5590 - recall_26: 0.0388 - recall_27: 0.0437 - precision_26: 0.1701 - precision_27: 0.2180\n",
      "Epoch 00001: val_loss improved from inf to 1.04043, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 6s 291ms/step - loss: 1.0147 - accuracy: 0.5590 - recall_26: 0.0388 - recall_27: 0.0437 - precision_26: 0.1701 - precision_27: 0.2180 - val_loss: 1.0404 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0900\n",
      "Epoch 2/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0220 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9960 - accuracy: 0.5594 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9733 - accuracy: 0.5850 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9713 - accuracy: 0.5940 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9689 - accuracy: 0.5960 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9338 - accuracy: 0.6217 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9691 - accuracy: 0.5947 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9746 - accuracy: 0.5908 - recall_26: 0.0000e+00 - recall_27: 7.5844e-04 - precision_26: 0.0000e+00 - precision_27: 0.6667    \n",
      "Epoch 00002: val_loss improved from 1.04043 to 1.03905, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.9767 - accuracy: 0.5897 - recall_26: 0.0000e+00 - recall_27: 7.2202e-04 - precision_26: 0.0000e+00 - precision_27: 0.6667 - val_loss: 1.0390 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0900\n",
      "Epoch 3/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0268 - accuracy: 0.5264 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0176 - accuracy: 0.5293 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9708 - accuracy: 0.5848 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9651 - accuracy: 0.5942 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9653 - accuracy: 0.5958 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9275 - accuracy: 0.6216 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9687 - accuracy: 0.5957 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9729 - accuracy: 0.5904 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9759 - accuracy: 0.5894 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 00003: val_loss did not improve from 1.03905\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9759 - accuracy: 0.5894 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00 - val_loss: 1.0833 - val_accuracy: 0.5047 - val_recall_26: 0.1083 - val_recall_27: 0.0000e+00 - val_precision_26: 0.3917 - val_precision_27: 0.0000e+00 - lr: 0.0900\n",
      "Epoch 4/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0299 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0233 - accuracy: 0.5288 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9820 - accuracy: 0.5853 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9724 - accuracy: 0.5946 - recall_26: 0.0066 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9802 - accuracy: 0.5870 - recall_26: 0.0051 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9509 - accuracy: 0.6075 - recall_26: 0.0045 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9478 - accuracy: 0.6122 - recall_26: 0.0040 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9759 - accuracy: 0.5948 - recall_26: 0.0034 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9807 - accuracy: 0.5896 - recall_26: 0.0027 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00\n",
      "Epoch 00004: val_loss improved from 1.03905 to 1.03706, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.9807 - accuracy: 0.5896 - recall_26: 0.0027 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00 - val_loss: 1.0371 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0900\n",
      "Epoch 5/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0126 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0213 - accuracy: 0.5293 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.2000 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9947 - accuracy: 0.5695 - recall_26: 0.0056 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9755 - accuracy: 0.5911 - recall_26: 0.0041 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9696 - accuracy: 0.5940 - recall_26: 0.0033 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9677 - accuracy: 0.5960 - recall_26: 0.0027 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9293 - accuracy: 0.6217 - recall_26: 0.0025 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9689 - accuracy: 0.5947 - recall_26: 0.0019 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9733 - accuracy: 0.5907 - recall_26: 0.0017 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00\n",
      "Epoch 00005: val_loss improved from 1.03706 to 1.03045, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.9743 - accuracy: 0.5896 - recall_26: 0.0020 - recall_27: 0.0000e+00 - precision_26: 0.3846 - precision_27: 0.0000e+00 - val_loss: 1.0304 - val_accuracy: 0.5007 - val_recall_26: 0.0178 - val_recall_27: 0.0000e+00 - val_precision_26: 0.5714 - val_precision_27: 0.0000e+00 - lr: 0.0900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0240 - accuracy: 0.5293 - recall_26: 0.0242 - recall_27: 0.0000e+00 - precision_26: 0.4286 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0174 - accuracy: 0.5274 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.2000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9869 - accuracy: 0.5683 - recall_26: 0.0111 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9611 - accuracy: 0.5937 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9752 - accuracy: 0.5862 - recall_26: 0.0058 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9447 - accuracy: 0.6069 - recall_26: 0.0052 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9625 - accuracy: 0.5954 - recall_26: 0.0042 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9671 - accuracy: 0.5901 - recall_26: 0.0036 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+00\n",
      "Epoch 00006: val_loss did not improve from 1.03045\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9690 - accuracy: 0.5890 - recall_26: 0.0031 - recall_27: 7.2202e-04 - precision_26: 0.2500 - precision_27: 0.2857 - val_loss: 1.0351 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0900\n",
      "Epoch 7/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0114 - accuracy: 0.5279 - recall_26: 0.0161 - recall_27: 0.0051 - precision_26: 0.2500 - precision_27: 1.00 - ETA: 0s - loss: 0.9975 - accuracy: 0.5576 - recall_26: 0.0200 - recall_27: 0.0017 - precision_26: 0.2400 - precision_27: 1.00 - ETA: 0s - loss: 0.9744 - accuracy: 0.5838 - recall_26: 0.0139 - recall_27: 0.0012 - precision_26: 0.2400 - precision_27: 1.00 - ETA: 0s - loss: 0.9632 - accuracy: 0.5932 - recall_26: 0.0099 - recall_27: 7.7882e-04 - precision_26: 0.2400 - precision_27: 1.00 - ETA: 0s - loss: 0.9441 - accuracy: 0.6068 - recall_26: 0.0077 - recall_27: 6.0241e-04 - precision_26: 0.2400 - precision_27: 1.00 - ETA: 0s - loss: 0.9409 - accuracy: 0.6115 - recall_26: 0.0068 - recall_27: 5.1387e-04 - precision_26: 0.2400 - precision_27: 1.00 - ETA: 0s - loss: 0.9713 - accuracy: 0.5900 - recall_26: 0.0054 - recall_27: 3.9872e-04 - precision_26: 0.2400 - precision_27: 1.00 - ETA: 0s - loss: 0.9735 - accuracy: 0.5891 - recall_26: 0.0047 - recall_27: 3.6101e-04 - precision_26: 0.2400 - precision_27: 1.0000\n",
      "Epoch 00007: val_loss did not improve from 1.03045\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9735 - accuracy: 0.5891 - recall_26: 0.0047 - recall_27: 3.6101e-04 - precision_26: 0.2400 - precision_27: 1.0000 - val_loss: 1.0534 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0900\n",
      "Epoch 8/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0205 - accuracy: 0.5293 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0277 - accuracy: 0.5269 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.1786 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9702 - accuracy: 0.5802 - recall_26: 0.0162 - recall_27: 0.0000e+00 - precision_26: 0.2059 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9644 - accuracy: 0.5902 - recall_26: 0.0131 - recall_27: 0.0000e+00 - precision_26: 0.1918 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9647 - accuracy: 0.5929 - recall_26: 0.0095 - recall_27: 0.0000e+00 - precision_26: 0.1892 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9258 - accuracy: 0.6191 - recall_26: 0.0087 - recall_27: 0.0000e+00 - precision_26: 0.1892 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9604 - accuracy: 0.5926 - recall_26: 0.0068 - recall_27: 0.0000e+00 - precision_26: 0.1892 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9670 - accuracy: 0.5886 - recall_26: 0.0059 - recall_27: 7.5844e-04 - precision_26: 0.1892 - precision_27: 0.1818    \n",
      "Epoch 00008: val_loss did not improve from 1.03045\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9709 - accuracy: 0.5877 - recall_26: 0.0055 - recall_27: 0.0022 - precision_26: 0.1892 - precision_27: 0.3158 - val_loss: 1.0415 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0900\n",
      "Epoch 9/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0115 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0144 - accuracy: 0.5288 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.1429 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9781 - accuracy: 0.5846 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.2222 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9697 - accuracy: 0.5937 - recall_26: 0.0017 - recall_27: 0.0000e+00 - precision_26: 0.2222 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9673 - accuracy: 0.5957 - recall_26: 0.0014 - recall_27: 0.0000e+00 - precision_26: 0.2222 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9453 - accuracy: 0.6119 - recall_26: 0.0011 - recall_27: 0.0000e+00 - precision_26: 0.2222 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9702 - accuracy: 0.5945 - recall_26: 9.7040e-04 - recall_27: 0.0000e+00 - precision_26: 0.2222 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9759 - accuracy: 0.5905 - recall_26: 8.3752e-04 - recall_27: 0.0000e+00 - precision_26: 0.2222 - precision_27: 0.0000e+00\n",
      "Epoch 00009: val_loss did not improve from 1.03045\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9777 - accuracy: 0.5894 - recall_26: 7.8462e-04 - recall_27: 3.6101e-04 - precision_26: 0.2222 - precision_27: 0.3333 - val_loss: 1.0316 - val_accuracy: 0.5031 - val_recall_26: 0.0694 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4007 - val_precision_27: 0.0000e+00 - lr: 0.0900\n",
      "Epoch 10/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0171 - accuracy: 0.5264 - recall_26: 0.0081 - recall_27: 0.0051 - precision_26: 0.3333 - precision_27: 0.25 - ETA: 0s - loss: 1.0208 - accuracy: 0.5254 - recall_26: 0.0442 - recall_27: 0.0169 - precision_26: 0.2714 - precision_27: 0.47 - ETA: 0s - loss: 0.9952 - accuracy: 0.5622 - recall_26: 0.0627 - recall_27: 0.0133 - precision_26: 0.3061 - precision_27: 0.43 - ETA: 0s - loss: 0.9661 - accuracy: 0.5898 - recall_26: 0.0468 - recall_27: 0.0087 - precision_26: 0.3086 - precision_27: 0.43 - ETA: 0s - loss: 0.9761 - accuracy: 0.5831 - recall_26: 0.0365 - recall_27: 0.0069 - precision_26: 0.3086 - precision_27: 0.43 - ETA: 0s - loss: 0.9477 - accuracy: 0.6043 - recall_26: 0.0322 - recall_27: 0.0060 - precision_26: 0.3086 - precision_27: 0.43 - ETA: 0s - loss: 0.9421 - accuracy: 0.6094 - recall_26: 0.0284 - recall_27: 0.0051 - precision_26: 0.3086 - precision_27: 0.43 - ETA: 0s - loss: 0.9668 - accuracy: 0.5924 - recall_26: 0.0243 - recall_27: 0.0042 - precision_26: 0.3086 - precision_27: 0.43 - ETA: 0s - loss: 0.9724 - accuracy: 0.5876 - recall_26: 0.0196 - recall_27: 0.0036 - precision_26: 0.3086 - precision_27: 0.4348\n",
      "Epoch 00010: val_loss did not improve from 1.03045\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9724 - accuracy: 0.5876 - recall_26: 0.0196 - recall_27: 0.0036 - precision_26: 0.3086 - precision_27: 0.4348 - val_loss: 1.0439 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0900\n",
      "Epoch 11/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0159 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0177 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9734 - accuracy: 0.5850 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9622 - accuracy: 0.5944 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9720 - accuracy: 0.5868 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9230 - accuracy: 0.6217 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9626 - accuracy: 0.5958 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9685 - accuracy: 0.5905 - recall_26: 0.0000e+00 - recall_27: 3.7922e-04 - precision_26: 0.0000e+00 - precision_27: 0.2500    \n",
      "Epoch 00011: val_loss did not improve from 1.03045\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9705 - accuracy: 0.5888 - recall_26: 3.9231e-04 - recall_27: 3.6101e-04 - precision_26: 0.1000 - precision_27: 0.1111 - val_loss: 1.0404 - val_accuracy: 0.5028 - val_recall_26: 0.2045 - val_recall_27: 0.0000e+00 - val_precision_26: 0.3715 - val_precision_27: 0.0000e+00 - lr: 0.0900\n",
      "Epoch 12/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0275 - accuracy: 0.5264 - recall_26: 0.0323 - recall_27: 0.0202 - precision_26: 0.2222 - precision_27: 0.50 - ETA: 0s - loss: 1.0269 - accuracy: 0.5264 - recall_26: 0.0558 - recall_27: 0.0075 - precision_26: 0.2667 - precision_27: 0.50 - ETA: 0s - loss: 0.9873 - accuracy: 0.5826 - recall_26: 0.0499 - recall_27: 0.0048 - precision_26: 0.3094 - precision_27: 0.50 - ETA: 0s - loss: 0.9728 - accuracy: 0.5924 - recall_26: 0.0356 - recall_27: 0.0031 - precision_26: 0.3094 - precision_27: 0.50 - ETA: 0s - loss: 0.9708 - accuracy: 0.5946 - recall_26: 0.0293 - recall_27: 0.0026 - precision_26: 0.3094 - precision_27: 0.50 - ETA: 0s - loss: 0.9516 - accuracy: 0.6110 - recall_26: 0.0245 - recall_27: 0.0021 - precision_26: 0.3094 - precision_27: 0.50 - ETA: 0s - loss: 0.9781 - accuracy: 0.5938 - recall_26: 0.0209 - recall_27: 0.0017 - precision_26: 0.3094 - precision_27: 0.50 - ETA: 0s - loss: 0.9815 - accuracy: 0.5887 - recall_26: 0.0169 - recall_27: 0.0014 - precision_26: 0.3094 - precision_27: 0.5000\n",
      "Epoch 00012: val_loss did not improve from 1.03045\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9815 - accuracy: 0.5887 - recall_26: 0.0169 - recall_27: 0.0014 - precision_26: 0.3094 - precision_27: 0.5000 - val_loss: 1.0364 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0900\n",
      "Epoch 13/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0117 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0168 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9659 - accuracy: 0.5853 - recall_26: 0.0012 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9624 - accuracy: 0.5940 - recall_26: 0.0025 - recall_27: 7.7882e-04 - precision_26: 0.5000 - precision_27: 0.2500   - ETA: 0s - loss: 0.9652 - accuracy: 0.5957 - recall_26: 0.0041 - recall_27: 6.3980e-04 - precision_26: 0.4286 - precision_27: 0.14 - ETA: 0s - loss: 0.9285 - accuracy: 0.6217 - recall_26: 0.0050 - recall_27: 5.7438e-04 - precision_26: 0.4706 - precision_27: 0.14 - ETA: 0s - loss: 0.9605 - accuracy: 0.5960 - recall_26: 0.0058 - recall_27: 4.4903e-04 - precision_26: 0.4583 - precision_27: 0.12 - ETA: 0s - loss: 0.9653 - accuracy: 0.5911 - recall_26: 0.0089 - recall_27: 3.9872e-04 - precision_26: 0.4651 - precision_27: 0.12 - ETA: 0s - loss: 0.9680 - accuracy: 0.5897 - recall_26: 0.0118 - recall_27: 3.6101e-04 - precision_26: 0.3797 - precision_27: 0.1250\n",
      "Epoch 00013: val_loss did not improve from 1.03045\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9680 - accuracy: 0.5897 - recall_26: 0.0118 - recall_27: 3.6101e-04 - precision_26: 0.3797 - precision_27: 0.1250 - val_loss: 1.0342 - val_accuracy: 0.5073 - val_recall_26: 0.1624 - val_recall_27: 0.0000e+00 - val_precision_26: 0.3923 - val_precision_27: 0.0000e+00 - lr: 0.0900\n",
      "Epoch 14/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0271 - accuracy: 0.5249 - recall_26: 0.0403 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0305 - accuracy: 0.5279 - recall_26: 0.0326 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9932 - accuracy: 0.5686 - recall_26: 0.0251 - recall_27: 0.0000e+00 - precision_26: 0.2812 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9613 - accuracy: 0.5937 - recall_26: 0.0178 - recall_27: 0.0000e+00 - precision_26: 0.2836 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9719 - accuracy: 0.5861 - recall_26: 0.0139 - recall_27: 0.0000e+00 - precision_26: 0.2794 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9237 - accuracy: 0.6212 - recall_26: 0.0124 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9584 - accuracy: 0.5958 - recall_26: 0.0115 - recall_27: 8.9807e-04 - precision_26: 0.2973 - precision_27: 1.0000   - ETA: 0s - loss: 0.9660 - accuracy: 0.5904 - recall_26: 0.0105 - recall_27: 0.0072 - precision_26: 0.2809 - precision_27: 0.3725    \n",
      "Epoch 00014: val_loss did not improve from 1.03045\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9677 - accuracy: 0.5892 - recall_26: 0.0102 - recall_27: 0.0137 - precision_26: 0.2737 - precision_27: 0.3918 - val_loss: 1.0476 - val_accuracy: 0.5036 - val_recall_26: 0.0433 - val_recall_27: 0.1009 - val_precision_26: 0.3908 - val_precision_27: 0.3326 - lr: 0.0900\n",
      "Epoch 15/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0308 - accuracy: 0.5176 - recall_26: 0.0242 - recall_27: 0.0657 - precision_26: 0.4286 - precision_27: 0.27 - ETA: 0s - loss: 1.0001 - accuracy: 0.5546 - recall_26: 0.0100 - recall_27: 0.0415 - precision_26: 0.2857 - precision_27: 0.25 - ETA: 0s - loss: 0.9632 - accuracy: 0.5884 - recall_26: 0.0062 - recall_27: 0.0254 - precision_26: 0.2857 - precision_27: 0.25 - ETA: 0s - loss: 0.9613 - accuracy: 0.5919 - recall_26: 0.0050 - recall_27: 0.0195 - precision_26: 0.2857 - precision_27: 0.25 - ETA: 0s - loss: 0.9447 - accuracy: 0.6058 - recall_26: 0.0039 - recall_27: 0.0151 - precision_26: 0.2857 - precision_27: 0.25 - ETA: 0s - loss: 0.9384 - accuracy: 0.6107 - recall_26: 0.0034 - recall_27: 0.0128 - precision_26: 0.2857 - precision_27: 0.25 - ETA: 0s - loss: 0.9649 - accuracy: 0.5894 - recall_26: 0.0027 - recall_27: 0.0100 - precision_26: 0.2857 - precision_27: 0.2525\n",
      "Epoch 00015: val_loss improved from 1.03045 to 1.02288, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.9660 - accuracy: 0.5885 - recall_26: 0.0024 - recall_27: 0.0090 - precision_26: 0.2857 - precision_27: 0.2525 - val_loss: 1.0229 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0900\n",
      "Epoch 16/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0221 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0008 - accuracy: 0.5554 - recall_26: 0.0518 - recall_27: 0.0000e+00 - precision_26: 0.3131 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9764 - accuracy: 0.5816 - recall_26: 0.0383 - recall_27: 0.0000e+00 - precision_26: 0.3056 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9645 - accuracy: 0.5917 - recall_26: 0.0273 - recall_27: 0.0000e+00 - precision_26: 0.3056 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9627 - accuracy: 0.5941 - recall_26: 0.0225 - recall_27: 0.0000e+00 - precision_26: 0.3056 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9249 - accuracy: 0.6201 - recall_26: 0.0205 - recall_27: 0.0000e+00 - precision_26: 0.3056 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9603 - accuracy: 0.5944 - recall_26: 0.0173 - recall_27: 0.0000e+00 - precision_26: 0.3056 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9654 - accuracy: 0.5893 - recall_26: 0.0147 - recall_27: 0.0000e+00 - precision_26: 0.3056 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9690 - accuracy: 0.5884 - recall_26: 0.0129 - recall_27: 7.2202e-04 - precision_26: 0.3056 - precision_27: 0.2222    \n",
      "Epoch 00016: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9690 - accuracy: 0.5884 - recall_26: 0.0129 - recall_27: 7.2202e-04 - precision_26: 0.3056 - precision_27: 0.2222 - val_loss: 1.0310 - val_accuracy: 0.4979 - val_recall_26: 0.0102 - val_recall_27: 0.0000e+00 - val_precision_26: 0.3556 - val_precision_27: 0.0000e+00 - lr: 0.0900\n",
      "Epoch 17/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0190 - accuracy: 0.5279 - recall_26: 0.0081 - recall_27: 0.0051 - precision_26: 0.5000 - precision_27: 0.20 - ETA: 0s - loss: 1.0006 - accuracy: 0.5587 - recall_26: 0.0017 - recall_27: 0.0017 - precision_26: 0.2000 - precision_27: 0.20 - ETA: 0s - loss: 0.9757 - accuracy: 0.5846 - recall_26: 0.0012 - recall_27: 0.0012 - precision_26: 0.2000 - precision_27: 0.20 - ETA: 0s - loss: 0.9642 - accuracy: 0.5937 - recall_26: 8.2781e-04 - recall_27: 7.7882e-04 - precision_26: 0.2000 - precision_27: 0.20 - ETA: 0s - loss: 0.9623 - accuracy: 0.5957 - recall_26: 6.8120e-04 - recall_27: 6.3980e-04 - precision_26: 0.2000 - precision_27: 0.20 - ETA: 0s - loss: 0.9260 - accuracy: 0.6215 - recall_26: 6.1996e-04 - recall_27: 5.7438e-04 - precision_26: 0.2000 - precision_27: 0.20 - ETA: 0s - loss: 0.9633 - accuracy: 0.5956 - recall_26: 5.2411e-04 - recall_27: 4.4903e-04 - precision_26: 0.2000 - precision_27: 0.20 - ETA: 0s - loss: 0.9684 - accuracy: 0.5905 - recall_26: 4.1876e-04 - recall_27: 3.7922e-04 - precision_26: 0.2000 - precision_27: 0.2000\n",
      "Epoch 00017: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9691 - accuracy: 0.5894 - recall_26: 3.9231e-04 - recall_27: 3.6101e-04 - precision_26: 0.2000 - precision_27: 0.2000 - val_loss: 1.0382 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0900\n",
      "Epoch 18/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0154 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0231 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9748 - accuracy: 0.5850 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9641 - accuracy: 0.5944 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9816 - accuracy: 0.5868 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9498 - accuracy: 0.6074 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9423 - accuracy: 0.6121 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9623 - accuracy: 0.5947 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9665 - accuracy: 0.5906 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 00018: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9679 - accuracy: 0.5894 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00 - val_loss: 1.0355 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0900\n",
      "Epoch 19/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0301 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0188 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9904 - accuracy: 0.5695 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9655 - accuracy: 0.5944 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9742 - accuracy: 0.5868 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9458 - accuracy: 0.6074 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9400 - accuracy: 0.6121 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9639 - accuracy: 0.5947 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9718 - accuracy: 0.5891 - recall_26: 0.0000e+00 - recall_27: 0.0014 - precision_26: 0.0000e+00 - precision_27: 0.2500        \n",
      "Epoch 00019: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9718 - accuracy: 0.5891 - recall_26: 0.0000e+00 - recall_27: 0.0014 - precision_26: 0.0000e+00 - precision_27: 0.2500 - val_loss: 1.0324 - val_accuracy: 0.5041 - val_recall_26: 0.0713 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4148 - val_precision_27: 0.0000e+00 - lr: 0.0900\n",
      "Epoch 20/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0186 - accuracy: 0.5293 - recall_26: 0.0242 - recall_27: 0.0354 - precision_26: 0.4286 - precision_27: 0.43 - ETA: 0s - loss: 1.0206 - accuracy: 0.5274 - recall_26: 0.0349 - recall_27: 0.0132 - precision_26: 0.2830 - precision_27: 0.36 - ETA: 0s - loss: 0.9891 - accuracy: 0.5680 - recall_26: 0.0292 - recall_27: 0.0093 - precision_26: 0.3043 - precision_27: 0.36 - ETA: 0s - loss: 0.9647 - accuracy: 0.5907 - recall_26: 0.0248 - recall_27: 0.0071 - precision_26: 0.3288 - precision_27: 0.36 - ETA: 0s - loss: 0.9622 - accuracy: 0.5937 - recall_26: 0.0199 - recall_27: 0.0055 - precision_26: 0.3288 - precision_27: 0.36 - ETA: 0s - loss: 0.9451 - accuracy: 0.6072 - recall_26: 0.0155 - recall_27: 0.0042 - precision_26: 0.3288 - precision_27: 0.36 - ETA: 0s - loss: 0.9387 - accuracy: 0.6119 - recall_26: 0.0137 - recall_27: 0.0036 - precision_26: 0.3288 - precision_27: 0.36 - ETA: 0s - loss: 0.9613 - accuracy: 0.5945 - recall_26: 0.0116 - recall_27: 0.0030 - precision_26: 0.3288 - precision_27: 0.36 - ETA: 0s - loss: 0.9668 - accuracy: 0.5894 - recall_26: 0.0094 - recall_27: 0.0025 - precision_26: 0.3288 - precision_27: 0.3684\n",
      "Epoch 00020: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9668 - accuracy: 0.5894 - recall_26: 0.0094 - recall_27: 0.0025 - precision_26: 0.3288 - precision_27: 0.3684 - val_loss: 1.0434 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0265 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0184 - accuracy: 0.5279 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.0909 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9943 - accuracy: 0.5683 - recall_26: 0.0014 - recall_27: 0.0000e+00 - precision_26: 0.0909 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9678 - accuracy: 0.5937 - recall_26: 9.3633e-04 - recall_27: 0.0000e+00 - precision_26: 0.0909 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9659 - accuracy: 0.5954 - recall_26: 6.8120e-04 - recall_27: 0.0000e+00 - precision_26: 0.0909 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9286 - accuracy: 0.6212 - recall_26: 6.1996e-04 - recall_27: 0.0000e+00 - precision_26: 0.0909 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9677 - accuracy: 0.5943 - recall_26: 4.8520e-04 - recall_27: 0.0000e+00 - precision_26: 0.0909 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9738 - accuracy: 0.5900 - recall_26: 0.0038 - recall_27: 0.0000e+00 - precision_26: 0.2045 - precision_27: 0.0000e+00    \n",
      "Epoch 00021: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9754 - accuracy: 0.5885 - recall_26: 0.0043 - recall_27: 0.0000e+00 - precision_26: 0.2037 - precision_27: 0.0000e+00 - val_loss: 1.0353 - val_accuracy: 0.5046 - val_recall_26: 0.0917 - val_recall_27: 0.0000e+00 - val_precision_26: 0.3902 - val_precision_27: 0.0000e+00 - lr: 0.0900\n",
      "Epoch 22/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0308 - accuracy: 0.5249 - recall_26: 0.0484 - recall_27: 0.0000e+00 - precision_26: 0.2727 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0274 - accuracy: 0.5288 - recall_26: 0.0233 - recall_27: 0.0000e+00 - precision_26: 0.2632 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9736 - accuracy: 0.5843 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.2564 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9628 - accuracy: 0.5935 - recall_26: 0.0083 - recall_27: 0.0000e+00 - precision_26: 0.2564 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9639 - accuracy: 0.5956 - recall_26: 0.0068 - recall_27: 0.0000e+00 - precision_26: 0.2564 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9283 - accuracy: 0.6214 - recall_26: 0.0062 - recall_27: 0.0000e+00 - precision_26: 0.2564 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9599 - accuracy: 0.5955 - recall_26: 0.0052 - recall_27: 0.0000e+00 - precision_26: 0.2564 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9649 - accuracy: 0.5904 - recall_26: 0.0042 - recall_27: 0.0000e+00 - precision_26: 0.2564 - precision_27: 0.0000e+00\n",
      "Epoch 00022: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9659 - accuracy: 0.5893 - recall_26: 0.0039 - recall_27: 0.0000e+00 - precision_26: 0.2564 - precision_27: 0.0000e+00 - val_loss: 1.0393 - val_accuracy: 0.5018 - val_recall_26: 0.0420 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4342 - val_precision_27: 0.0000e+00 - lr: 0.0900\n",
      "Epoch 23/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0329 - accuracy: 0.5264 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0215 - accuracy: 0.5298 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9751 - accuracy: 0.5850 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9640 - accuracy: 0.5940 - recall_26: 0.0017 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9450 - accuracy: 0.6074 - recall_26: 0.0013 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9393 - accuracy: 0.6121 - recall_26: 0.0011 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9659 - accuracy: 0.5905 - recall_26: 8.9286e-04 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9668 - accuracy: 0.5895 - recall_26: 0.0016 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00    \n",
      "Epoch 00023: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9668 - accuracy: 0.5895 - recall_26: 0.0016 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00 - val_loss: 1.0372 - val_accuracy: 0.5049 - val_recall_26: 0.1764 - val_recall_27: 0.0000e+00 - val_precision_26: 0.3723 - val_precision_27: 0.0000e+00 - lr: 0.0900\n",
      "Epoch 24/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0384 - accuracy: 0.5205 - recall_26: 0.0242 - recall_27: 0.0000e+00 - precision_26: 0.1667 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0249 - accuracy: 0.5254 - recall_26: 0.0326 - recall_27: 0.0000e+00 - precision_26: 0.2545 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9929 - accuracy: 0.5669 - recall_26: 0.0195 - recall_27: 0.0000e+00 - precision_26: 0.2545 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9687 - accuracy: 0.5892 - recall_26: 0.0145 - recall_27: 0.0000e+00 - precision_26: 0.2545 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9777 - accuracy: 0.5855 - recall_26: 0.0102 - recall_27: 0.0000e+00 - precision_26: 0.2545 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9485 - accuracy: 0.6063 - recall_26: 0.0090 - recall_27: 0.0000e+00 - precision_26: 0.2545 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9622 - accuracy: 0.5949 - recall_26: 0.0073 - recall_27: 0.0000e+00 - precision_26: 0.2545 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9665 - accuracy: 0.5897 - recall_26: 0.0063 - recall_27: 0.0000e+00 - precision_26: 0.2545 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9682 - accuracy: 0.5888 - recall_26: 0.0063 - recall_27: 0.0000e+00 - precision_26: 0.2712 - precision_27: 0.0000e+00\n",
      "Epoch 00024: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9682 - accuracy: 0.5888 - recall_26: 0.0063 - recall_27: 0.0000e+00 - precision_26: 0.2712 - precision_27: 0.0000e+00 - val_loss: 1.0348 - val_accuracy: 0.5034 - val_recall_26: 0.0624 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4224 - val_precision_27: 0.0000e+00 - lr: 0.0900\n",
      "Epoch 25/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0300 - accuracy: 0.5293 - recall_26: 0.0323 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0218 - accuracy: 0.5308 - recall_26: 0.0140 - recall_27: 0.0000e+00 - precision_26: 0.3158 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9871 - accuracy: 0.5701 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.3158 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9587 - accuracy: 0.5948 - recall_26: 0.0056 - recall_27: 0.0000e+00 - precision_26: 0.3158 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9743 - accuracy: 0.5871 - recall_26: 0.0044 - recall_27: 0.0000e+00 - precision_26: 0.3158 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9237 - accuracy: 0.6219 - recall_26: 0.0037 - recall_27: 0.0000e+00 - precision_26: 0.3158 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9565 - accuracy: 0.5960 - recall_26: 0.0031 - recall_27: 0.0000e+00 - precision_26: 0.3158 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9609 - accuracy: 0.5907 - recall_26: 0.0027 - recall_27: 0.0000e+00 - precision_26: 0.3158 - precision_27: 0.0000e+00\n",
      "Epoch 00025: val_loss did not improve from 1.02288\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.07200000286102295.\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9628 - accuracy: 0.5897 - recall_26: 0.0027 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00 - val_loss: 1.0264 - val_accuracy: 0.5034 - val_recall_26: 0.0618 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4236 - val_precision_27: 0.0000e+00 - lr: 0.0900\n",
      "Epoch 26/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0215 - accuracy: 0.5279 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0159 - accuracy: 0.5288 - recall_26: 0.0093 - recall_27: 0.0019 - precision_26: 0.2500 - precision_27: 0.1667       - ETA: 0s - loss: 0.9879 - accuracy: 0.5692 - recall_26: 0.0084 - recall_27: 0.0013 - precision_26: 0.2857 - precision_27: 0.16 - ETA: 0s - loss: 0.9621 - accuracy: 0.5942 - recall_26: 0.0056 - recall_27: 8.7336e-04 - precision_26: 0.2857 - precision_27: 0.16 - ETA: 0s - loss: 0.9586 - accuracy: 0.5958 - recall_26: 0.0041 - recall_27: 6.3980e-04 - precision_26: 0.2857 - precision_27: 0.16 - ETA: 0s - loss: 0.9218 - accuracy: 0.6216 - recall_26: 0.0037 - recall_27: 5.7438e-04 - precision_26: 0.2857 - precision_27: 0.16 - ETA: 0s - loss: 0.9624 - accuracy: 0.5957 - recall_26: 0.0031 - recall_27: 4.4903e-04 - precision_26: 0.2857 - precision_27: 0.16 - ETA: 0s - loss: 0.9686 - accuracy: 0.5906 - recall_26: 0.0025 - recall_27: 3.7922e-04 - precision_26: 0.2857 - precision_27: 0.1667\n",
      "Epoch 00026: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9690 - accuracy: 0.5894 - recall_26: 0.0024 - recall_27: 3.6101e-04 - precision_26: 0.2857 - precision_27: 0.1667 - val_loss: 1.0361 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0720\n",
      "Epoch 27/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0174 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0140 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9845 - accuracy: 0.5695 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9628 - accuracy: 0.5944 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9703 - accuracy: 0.5868 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9202 - accuracy: 0.6217 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9619 - accuracy: 0.5958 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9669 - accuracy: 0.5905 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9683 - accuracy: 0.5884 - recall_26: 0.0047 - recall_27: 3.6101e-04 - precision_26: 0.2449 - precision_27: 0.1667            \n",
      "Epoch 00027: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9683 - accuracy: 0.5884 - recall_26: 0.0047 - recall_27: 3.6101e-04 - precision_26: 0.2449 - precision_27: 0.1667 - val_loss: 1.0322 - val_accuracy: 0.5033 - val_recall_26: 0.2567 - val_recall_27: 0.0000e+00 - val_precision_26: 0.3637 - val_precision_27: 0.0000e+00 - lr: 0.0720\n",
      "Epoch 28/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0377 - accuracy: 0.5059 - recall_26: 0.1048 - recall_27: 0.0253 - precision_26: 0.2281 - precision_27: 0.33 - ETA: 0s - loss: 1.0285 - accuracy: 0.5191 - recall_26: 0.1209 - recall_27: 0.0244 - precision_26: 0.2842 - precision_27: 0.41 - ETA: 0s - loss: 0.9877 - accuracy: 0.5775 - recall_26: 0.0777 - recall_27: 0.0179 - precision_26: 0.2926 - precision_27: 0.41 - ETA: 0s - loss: 0.9707 - accuracy: 0.5890 - recall_26: 0.0555 - recall_27: 0.0117 - precision_26: 0.2926 - precision_27: 0.41 - ETA: 0s - loss: 0.9499 - accuracy: 0.6036 - recall_26: 0.0431 - recall_27: 0.0090 - precision_26: 0.2926 - precision_27: 0.41 - ETA: 0s - loss: 0.9454 - accuracy: 0.6088 - recall_26: 0.0381 - recall_27: 0.0077 - precision_26: 0.2926 - precision_27: 0.41 - ETA: 0s - loss: 0.9717 - accuracy: 0.5918 - recall_26: 0.0325 - recall_27: 0.0064 - precision_26: 0.2926 - precision_27: 0.41 - ETA: 0s - loss: 0.9754 - accuracy: 0.5881 - recall_26: 0.0281 - recall_27: 0.0057 - precision_26: 0.2926 - precision_27: 0.4167\n",
      "Epoch 00028: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9759 - accuracy: 0.5871 - recall_26: 0.0263 - recall_27: 0.0054 - precision_26: 0.2926 - precision_27: 0.4167 - val_loss: 1.0460 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0720\n",
      "Epoch 29/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0285 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0232 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9773 - accuracy: 0.5850 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9650 - accuracy: 0.5944 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9824 - accuracy: 0.5868 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9513 - accuracy: 0.6072 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9430 - accuracy: 0.6119 - recall_26: 5.6883e-04 - recall_27: 0.0000e+00 - precision_26: 0.2000 - precision_27: 0.0000e+00   - ETA: 0s - loss: 0.9670 - accuracy: 0.5907 - recall_26: 0.0054 - recall_27: 0.0000e+00 - precision_26: 0.3429 - precision_27: 0.0000e+00   - ETA: 0s - loss: 0.9688 - accuracy: 0.5894 - recall_26: 0.0098 - recall_27: 0.0000e+00 - precision_26: 0.3125 - precision_27: 0.0000e+00\n",
      "Epoch 00029: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9688 - accuracy: 0.5894 - recall_26: 0.0098 - recall_27: 0.0000e+00 - precision_26: 0.3125 - precision_27: 0.0000e+00 - val_loss: 1.0359 - val_accuracy: 0.5055 - val_recall_26: 0.1541 - val_recall_27: 0.0000e+00 - val_precision_26: 0.3841 - val_precision_27: 0.0000e+00 - lr: 0.0720\n",
      "Epoch 30/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0402 - accuracy: 0.5132 - recall_26: 0.0403 - recall_27: 0.0000e+00 - precision_26: 0.1562 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0284 - accuracy: 0.5215 - recall_26: 0.0465 - recall_27: 0.0000e+00 - precision_26: 0.2273 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9994 - accuracy: 0.5645 - recall_26: 0.0279 - recall_27: 0.0000e+00 - precision_26: 0.2273 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9765 - accuracy: 0.5876 - recall_26: 0.0207 - recall_27: 0.0000e+00 - precision_26: 0.2273 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9686 - accuracy: 0.5912 - recall_26: 0.0166 - recall_27: 0.0000e+00 - precision_26: 0.2273 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9635 - accuracy: 0.5937 - recall_26: 0.0136 - recall_27: 0.0000e+00 - precision_26: 0.2273 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9270 - accuracy: 0.6198 - recall_26: 0.0124 - recall_27: 0.0000e+00 - precision_26: 0.2273 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9644 - accuracy: 0.5931 - recall_26: 0.0097 - recall_27: 0.0000e+00 - precision_26: 0.2273 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9692 - accuracy: 0.5882 - recall_26: 0.0078 - recall_27: 0.0000e+00 - precision_26: 0.2273 - precision_27: 0.0000e+00\n",
      "Epoch 00030: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9692 - accuracy: 0.5882 - recall_26: 0.0078 - recall_27: 0.0000e+00 - precision_26: 0.2273 - precision_27: 0.0000e+00 - val_loss: 1.0296 - val_accuracy: 0.5005 - val_recall_26: 0.0274 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4725 - val_precision_27: 0.0000e+00 - lr: 0.0720\n",
      "Epoch 31/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0196 - accuracy: 0.5279 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.1667 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0239 - accuracy: 0.5303 - recall_26: 0.0093 - recall_27: 0.0019 - precision_26: 0.1905 - precision_27: 0.5000       - ETA: 0s - loss: 1.0008 - accuracy: 0.5686 - recall_26: 0.0070 - recall_27: 0.0013 - precision_26: 0.1667 - precision_27: 0.25 - ETA: 0s - loss: 0.9742 - accuracy: 0.5905 - recall_26: 0.0052 - recall_27: 0.0010 - precision_26: 0.1667 - precision_27: 0.25 - ETA: 0s - loss: 0.9672 - accuracy: 0.5935 - recall_26: 0.0041 - recall_27: 7.7882e-04 - precision_26: 0.1667 - precision_27: 0.25 - ETA: 0s - loss: 0.9663 - accuracy: 0.5956 - recall_26: 0.0034 - recall_27: 6.3980e-04 - precision_26: 0.1667 - precision_27: 0.25 - ETA: 0s - loss: 0.9421 - accuracy: 0.6118 - recall_26: 0.0028 - recall_27: 5.1387e-04 - precision_26: 0.1667 - precision_27: 0.25 - ETA: 0s - loss: 0.9723 - accuracy: 0.5902 - recall_26: 0.0022 - recall_27: 3.9872e-04 - precision_26: 0.1667 - precision_27: 0.25 - ETA: 0s - loss: 0.9716 - accuracy: 0.5893 - recall_26: 0.0020 - recall_27: 3.6101e-04 - precision_26: 0.1667 - precision_27: 0.2500\n",
      "Epoch 00031: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9716 - accuracy: 0.5893 - recall_26: 0.0020 - recall_27: 3.6101e-04 - precision_26: 0.1667 - precision_27: 0.2500 - val_loss: 1.0262 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0720\n",
      "Epoch 32/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0199 - accuracy: 0.5308 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0159 - accuracy: 0.5298 - recall_26: 0.0372 - recall_27: 0.0000e+00 - precision_26: 0.3200 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9919 - accuracy: 0.5683 - recall_26: 0.0279 - recall_27: 0.0000e+00 - precision_26: 0.2985 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9730 - accuracy: 0.5903 - recall_26: 0.0207 - recall_27: 0.0000e+00 - precision_26: 0.2985 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9775 - accuracy: 0.5862 - recall_26: 0.0146 - recall_27: 0.0000e+00 - precision_26: 0.2985 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9491 - accuracy: 0.6069 - recall_26: 0.0129 - recall_27: 0.0000e+00 - precision_26: 0.2985 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9680 - accuracy: 0.5954 - recall_26: 0.0105 - recall_27: 0.0000e+00 - precision_26: 0.2985 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9730 - accuracy: 0.5901 - recall_26: 0.0089 - recall_27: 0.0000e+00 - precision_26: 0.2985 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9724 - accuracy: 0.5892 - recall_26: 0.0078 - recall_27: 0.0000e+00 - precision_26: 0.2985 - precision_27: 0.0000e+00\n",
      "Epoch 00032: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9724 - accuracy: 0.5892 - recall_26: 0.0078 - recall_27: 0.0000e+00 - precision_26: 0.2985 - precision_27: 0.0000e+00 - val_loss: 1.0298 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0720\n",
      "Epoch 33/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0206 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0159 - accuracy: 0.5279 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.2105 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9914 - accuracy: 0.5663 - recall_26: 0.0209 - recall_27: 0.0000e+00 - precision_26: 0.2632 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9644 - accuracy: 0.5929 - recall_26: 0.0197 - recall_27: 0.0000e+00 - precision_26: 0.3088 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9608 - accuracy: 0.5949 - recall_26: 0.0143 - recall_27: 0.0000e+00 - precision_26: 0.3088 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9209 - accuracy: 0.6208 - recall_26: 0.0130 - recall_27: 0.0000e+00 - precision_26: 0.3088 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9619 - accuracy: 0.5950 - recall_26: 0.0110 - recall_27: 0.0000e+00 - precision_26: 0.3088 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9668 - accuracy: 0.5900 - recall_26: 0.0088 - recall_27: 0.0000e+00 - precision_26: 0.3088 - precision_27: 0.0000e+00\n",
      "Epoch 00033: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9671 - accuracy: 0.5889 - recall_26: 0.0082 - recall_27: 0.0000e+00 - precision_26: 0.3088 - precision_27: 0.0000e+00 - val_loss: 1.0338 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0720\n",
      "Epoch 34/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0127 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0103 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9771 - accuracy: 0.5848 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9674 - accuracy: 0.5942 - recall_26: 0.0056 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9723 - accuracy: 0.5867 - recall_26: 0.0044 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9217 - accuracy: 0.6216 - recall_26: 0.0037 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9638 - accuracy: 0.5957 - recall_26: 0.0031 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9693 - accuracy: 0.5906 - recall_26: 0.0029 - recall_27: 0.0011 - precision_26: 0.3182 - precision_27: 0.3000        \n",
      "Epoch 00034: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9706 - accuracy: 0.5893 - recall_26: 0.0031 - recall_27: 0.0011 - precision_26: 0.3200 - precision_27: 0.2000 - val_loss: 1.0262 - val_accuracy: 0.5055 - val_recall_26: 0.0605 - val_recall_27: 0.0244 - val_precision_26: 0.4378 - val_precision_27: 0.3895 - lr: 0.0720\n",
      "Epoch 35/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0209 - accuracy: 0.5191 - recall_26: 0.0161 - recall_27: 0.0303 - precision_26: 0.2000 - precision_27: 0.28 - ETA: 0s - loss: 1.0201 - accuracy: 0.5239 - recall_26: 0.0628 - recall_27: 0.0357 - precision_26: 0.2842 - precision_27: 0.34 - ETA: 0s - loss: 1.0004 - accuracy: 0.5607 - recall_26: 0.0850 - recall_27: 0.0307 - precision_26: 0.3096 - precision_27: 0.33 - ETA: 0s - loss: 0.9729 - accuracy: 0.5885 - recall_26: 0.0655 - recall_27: 0.0201 - precision_26: 0.3153 - precision_27: 0.33 - ETA: 0s - loss: 0.9804 - accuracy: 0.5820 - recall_26: 0.0511 - recall_27: 0.0159 - precision_26: 0.3139 - precision_27: 0.33 - ETA: 0s - loss: 0.9280 - accuracy: 0.6180 - recall_26: 0.0434 - recall_27: 0.0132 - precision_26: 0.3139 - precision_27: 0.33 - ETA: 0s - loss: 0.9674 - accuracy: 0.5926 - recall_26: 0.0367 - recall_27: 0.0103 - precision_26: 0.3139 - precision_27: 0.33 - ETA: 0s - loss: 0.9730 - accuracy: 0.5876 - recall_26: 0.0312 - recall_27: 0.0092 - precision_26: 0.3139 - precision_27: 0.33 - ETA: 0s - loss: 0.9736 - accuracy: 0.5870 - recall_26: 0.0275 - recall_27: 0.0083 - precision_26: 0.3139 - precision_27: 0.3382\n",
      "Epoch 00035: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9736 - accuracy: 0.5870 - recall_26: 0.0275 - recall_27: 0.0083 - precision_26: 0.3139 - precision_27: 0.3382 - val_loss: 1.0415 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0720\n",
      "Epoch 36/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0153 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0235 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9851 - accuracy: 0.5850 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9698 - accuracy: 0.5944 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9778 - accuracy: 0.5868 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9465 - accuracy: 0.6074 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9401 - accuracy: 0.6121 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9644 - accuracy: 0.5947 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9680 - accuracy: 0.5879 - recall_26: 0.0082 - recall_27: 3.6101e-04 - precision_26: 0.2471 - precision_27: 0.1429            \n",
      "Epoch 00036: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9680 - accuracy: 0.5879 - recall_26: 0.0082 - recall_27: 3.6101e-04 - precision_26: 0.2471 - precision_27: 0.1429 - val_loss: 1.0445 - val_accuracy: 0.4941 - val_recall_26: 0.4159 - val_recall_27: 0.0000e+00 - val_precision_26: 0.3424 - val_precision_27: 0.0000e+00 - lr: 0.0720\n",
      "Epoch 37/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0481 - accuracy: 0.5059 - recall_26: 0.1210 - recall_27: 0.0455 - precision_26: 0.2239 - precision_27: 0.45 - ETA: 0s - loss: 1.0289 - accuracy: 0.5171 - recall_26: 0.1233 - recall_27: 0.0376 - precision_26: 0.2746 - precision_27: 0.44 - ETA: 0s - loss: 0.9828 - accuracy: 0.5794 - recall_26: 0.0684 - recall_27: 0.0251 - precision_26: 0.2906 - precision_27: 0.44 - ETA: 0s - loss: 0.9663 - accuracy: 0.5903 - recall_26: 0.0488 - recall_27: 0.0164 - precision_26: 0.2906 - precision_27: 0.44 - ETA: 0s - loss: 0.9626 - accuracy: 0.5929 - recall_26: 0.0402 - recall_27: 0.0134 - precision_26: 0.2906 - precision_27: 0.44 - ETA: 0s - loss: 0.9267 - accuracy: 0.6191 - recall_26: 0.0366 - recall_27: 0.0121 - precision_26: 0.2906 - precision_27: 0.44 - ETA: 0s - loss: 0.9643 - accuracy: 0.5935 - recall_26: 0.0309 - recall_27: 0.0094 - precision_26: 0.2906 - precision_27: 0.44 - ETA: 0s - loss: 0.9691 - accuracy: 0.5888 - recall_26: 0.0247 - recall_27: 0.0080 - precision_26: 0.2906 - precision_27: 0.4468\n",
      "Epoch 00037: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9689 - accuracy: 0.5877 - recall_26: 0.0231 - recall_27: 0.0076 - precision_26: 0.2906 - precision_27: 0.4468 - val_loss: 1.0350 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0720\n",
      "Epoch 38/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0317 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0005 - accuracy: 0.5583 - recall_26: 0.0217 - recall_27: 0.0000e+00 - precision_26: 0.3421 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9786 - accuracy: 0.5848 - recall_26: 0.0220 - recall_27: 0.0000e+00 - precision_26: 0.3725 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9646 - accuracy: 0.5942 - recall_26: 0.0178 - recall_27: 8.7336e-04 - precision_26: 0.3725 - precision_27: 0.3333   - ETA: 0s - loss: 0.9789 - accuracy: 0.5867 - recall_26: 0.0139 - recall_27: 6.9061e-04 - precision_26: 0.3725 - precision_27: 0.33 - ETA: 0s - loss: 0.9251 - accuracy: 0.6216 - recall_26: 0.0118 - recall_27: 5.7438e-04 - precision_26: 0.3725 - precision_27: 0.33 - ETA: 0s - loss: 0.9630 - accuracy: 0.5946 - recall_26: 0.0092 - recall_27: 4.2337e-04 - precision_26: 0.3725 - precision_27: 0.33 - ETA: 0s - loss: 0.9665 - accuracy: 0.5906 - recall_26: 0.0088 - recall_27: 3.7922e-04 - precision_26: 0.3818 - precision_27: 0.3333\n",
      "Epoch 00038: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9671 - accuracy: 0.5894 - recall_26: 0.0082 - recall_27: 3.6101e-04 - precision_26: 0.3818 - precision_27: 0.3333 - val_loss: 1.0247 - val_accuracy: 0.5020 - val_recall_26: 0.0414 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4305 - val_precision_27: 0.0000e+00 - lr: 0.0720\n",
      "Epoch 39/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0187 - accuracy: 0.5264 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0134 - accuracy: 0.5293 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9878 - accuracy: 0.5692 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9689 - accuracy: 0.5909 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9638 - accuracy: 0.5938 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9617 - accuracy: 0.5958 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9418 - accuracy: 0.6120 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9706 - accuracy: 0.5904 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9702 - accuracy: 0.5894 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 00039: val_loss did not improve from 1.02288\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.05760000348091126.\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9702 - accuracy: 0.5894 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00 - val_loss: 1.0272 - val_accuracy: 0.5064 - val_recall_26: 0.1541 - val_recall_27: 0.0000e+00 - val_precision_26: 0.3799 - val_precision_27: 0.0000e+00 - lr: 0.0720\n",
      "Epoch 40/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0193 - accuracy: 0.5308 - recall_26: 0.0242 - recall_27: 0.0000e+00 - precision_26: 0.6000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0134 - accuracy: 0.5283 - recall_26: 0.0279 - recall_27: 0.0075 - precision_26: 0.2609 - precision_27: 0.5000       - ETA: 0s - loss: 0.9868 - accuracy: 0.5663 - recall_26: 0.0418 - recall_27: 0.0093 - precision_26: 0.2885 - precision_27: 0.46 - ETA: 0s - loss: 0.9616 - accuracy: 0.5922 - recall_26: 0.0365 - recall_27: 0.0070 - precision_26: 0.3023 - precision_27: 0.42 - ETA: 0s - loss: 0.9696 - accuracy: 0.5850 - recall_26: 0.0307 - recall_27: 0.0055 - precision_26: 0.3066 - precision_27: 0.42 - ETA: 0s - loss: 0.9396 - accuracy: 0.6059 - recall_26: 0.0270 - recall_27: 0.0048 - precision_26: 0.3066 - precision_27: 0.42 - ETA: 0s - loss: 0.9603 - accuracy: 0.5947 - recall_26: 0.0231 - recall_27: 0.0036 - precision_26: 0.3143 - precision_27: 0.42 - ETA: 0s - loss: 0.9666 - accuracy: 0.5894 - recall_26: 0.0196 - recall_27: 0.0032 - precision_26: 0.3077 - precision_27: 0.42 - ETA: 0s - loss: 0.9658 - accuracy: 0.5884 - recall_26: 0.0173 - recall_27: 0.0029 - precision_26: 0.3034 - precision_27: 0.4211\n",
      "Epoch 00040: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9658 - accuracy: 0.5884 - recall_26: 0.0173 - recall_27: 0.0029 - precision_26: 0.3034 - precision_27: 0.4211 - val_loss: 1.0286 - val_accuracy: 0.4980 - val_recall_26: 0.0089 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4828 - val_precision_27: 0.0000e+00 - lr: 0.0576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0271 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0158 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9888 - accuracy: 0.5695 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9728 - accuracy: 0.5944 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9772 - accuracy: 0.5868 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9330 - accuracy: 0.6217 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9674 - accuracy: 0.5958 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9747 - accuracy: 0.5905 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 00041: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9743 - accuracy: 0.5895 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00 - val_loss: 1.0299 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0576\n",
      "Epoch 42/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0129 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0092 - accuracy: 0.5303 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 1.0000 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9745 - accuracy: 0.5858 - recall_26: 0.0197 - recall_27: 0.0000e+00 - precision_26: 0.4359 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9652 - accuracy: 0.5948 - recall_26: 0.0178 - recall_27: 0.0000e+00 - precision_26: 0.3958 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9692 - accuracy: 0.5871 - recall_26: 0.0139 - recall_27: 0.0000e+00 - precision_26: 0.3878 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9212 - accuracy: 0.6219 - recall_26: 0.0118 - recall_27: 0.0000e+00 - precision_26: 0.3878 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9583 - accuracy: 0.5960 - recall_26: 0.0100 - recall_27: 0.0000e+00 - precision_26: 0.3878 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9663 - accuracy: 0.5907 - recall_26: 0.0085 - recall_27: 0.0000e+00 - precision_26: 0.3878 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9663 - accuracy: 0.5897 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.3878 - precision_27: 0.0000e+00\n",
      "Epoch 00042: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9663 - accuracy: 0.5897 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.3878 - precision_27: 0.0000e+00 - val_loss: 1.0341 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0576\n",
      "Epoch 43/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0312 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0163 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9810 - accuracy: 0.5695 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9663 - accuracy: 0.5944 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9704 - accuracy: 0.5868 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9299 - accuracy: 0.6217 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9593 - accuracy: 0.5958 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9657 - accuracy: 0.5905 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 00043: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9663 - accuracy: 0.5895 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00 - val_loss: 1.0357 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0576\n",
      "Epoch 44/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0144 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0117 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9802 - accuracy: 0.5695 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9580 - accuracy: 0.5946 - recall_26: 9.3633e-04 - recall_27: 0.0000e+00 - precision_26: 1.0000 - precision_27: 0.0000e+00   - ETA: 0s - loss: 0.9632 - accuracy: 0.5870 - recall_26: 7.2993e-04 - recall_27: 0.0000e+00 - precision_26: 1.0000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9372 - accuracy: 0.6075 - recall_26: 6.4392e-04 - recall_27: 0.0000e+00 - precision_26: 1.0000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9317 - accuracy: 0.6122 - recall_26: 5.6883e-04 - recall_27: 0.0000e+00 - precision_26: 1.0000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9559 - accuracy: 0.5948 - recall_26: 4.8520e-04 - recall_27: 0.0000e+00 - precision_26: 1.0000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9613 - accuracy: 0.5907 - recall_26: 4.1876e-04 - recall_27: 0.0000e+00 - precision_26: 1.0000 - precision_27: 0.0000e+00\n",
      "Epoch 00044: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9621 - accuracy: 0.5896 - recall_26: 3.9231e-04 - recall_27: 0.0000e+00 - precision_26: 1.0000 - precision_27: 0.0000e+00 - val_loss: 1.0353 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0576\n",
      "Epoch 45/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0225 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0132 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9774 - accuracy: 0.5695 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9612 - accuracy: 0.5944 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9659 - accuracy: 0.5868 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9275 - accuracy: 0.6217 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9562 - accuracy: 0.5958 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9624 - accuracy: 0.5905 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9633 - accuracy: 0.5895 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 00045: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9633 - accuracy: 0.5895 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00 - val_loss: 1.0484 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0219 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0168 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9770 - accuracy: 0.5695 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9578 - accuracy: 0.5911 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9523 - accuracy: 0.5940 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9353 - accuracy: 0.6074 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9498 - accuracy: 0.5958 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9560 - accuracy: 0.5905 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9569 - accuracy: 0.5894 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 00046: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9569 - accuracy: 0.5894 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00 - val_loss: 1.0264 - val_accuracy: 0.4982 - val_recall_26: 0.0083 - val_recall_27: 0.0000e+00 - val_precision_26: 0.5000 - val_precision_27: 0.0000e+00 - lr: 0.0576\n",
      "Epoch 47/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0171 - accuracy: 0.5264 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0081 - accuracy: 0.5293 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9772 - accuracy: 0.5689 - recall_26: 0.0139 - recall_27: 0.0000e+00 - precision_26: 0.3030 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9640 - accuracy: 0.5905 - recall_26: 0.0155 - recall_27: 0.0000e+00 - precision_26: 0.3191 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9651 - accuracy: 0.5862 - recall_26: 0.0109 - recall_27: 0.0000e+00 - precision_26: 0.3125 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9412 - accuracy: 0.6069 - recall_26: 0.0097 - recall_27: 0.0000e+00 - precision_26: 0.3125 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9541 - accuracy: 0.5954 - recall_26: 0.0079 - recall_27: 0.0000e+00 - precision_26: 0.3125 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9613 - accuracy: 0.5901 - recall_26: 0.0067 - recall_27: 0.0000e+00 - precision_26: 0.3125 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9628 - accuracy: 0.5892 - recall_26: 0.0059 - recall_27: 0.0000e+00 - precision_26: 0.3125 - precision_27: 0.0000e+00\n",
      "Epoch 00047: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9628 - accuracy: 0.5892 - recall_26: 0.0059 - recall_27: 0.0000e+00 - precision_26: 0.3125 - precision_27: 0.0000e+00 - val_loss: 1.0483 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0576\n",
      "Epoch 48/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0184 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0166 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9655 - accuracy: 0.5850 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9568 - accuracy: 0.5944 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9625 - accuracy: 0.5868 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9227 - accuracy: 0.6217 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9533 - accuracy: 0.5958 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9595 - accuracy: 0.5907 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 00048: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9608 - accuracy: 0.5895 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00 - val_loss: 1.0382 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0576\n",
      "Epoch 49/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0182 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9863 - accuracy: 0.5594 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9636 - accuracy: 0.5850 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9548 - accuracy: 0.5944 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9603 - accuracy: 0.5868 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9377 - accuracy: 0.6074 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9515 - accuracy: 0.5958 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9584 - accuracy: 0.5905 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 00049: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9596 - accuracy: 0.5895 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00 - val_loss: 1.0426 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0576\n",
      "Epoch 50/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0205 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0157 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9769 - accuracy: 0.5695 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9549 - accuracy: 0.5944 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9610 - accuracy: 0.5868 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9225 - accuracy: 0.6217 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9518 - accuracy: 0.5958 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9582 - accuracy: 0.5907 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 00050: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9596 - accuracy: 0.5895 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00 - val_loss: 1.0427 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0184 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0155 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9767 - accuracy: 0.5695 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9523 - accuracy: 0.5944 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9587 - accuracy: 0.5868 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9182 - accuracy: 0.6217 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9499 - accuracy: 0.5958 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9569 - accuracy: 0.5905 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9584 - accuracy: 0.5895 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 00051: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9584 - accuracy: 0.5895 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00 - val_loss: 1.0353 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0576\n",
      "Epoch 52/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0150 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0117 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9767 - accuracy: 0.5695 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9577 - accuracy: 0.5911 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9537 - accuracy: 0.5940 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9513 - accuracy: 0.5960 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9318 - accuracy: 0.6121 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9590 - accuracy: 0.5905 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9604 - accuracy: 0.5895 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 00052: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9604 - accuracy: 0.5895 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00 - val_loss: 1.0429 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0576\n",
      "Epoch 53/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0197 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0159 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9629 - accuracy: 0.5850 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9540 - accuracy: 0.5944 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9515 - accuracy: 0.5960 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9216 - accuracy: 0.6217 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9514 - accuracy: 0.5958 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9579 - accuracy: 0.5905 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 00053: val_loss did not improve from 1.02288\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.04608000218868256.\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9591 - accuracy: 0.5895 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00 - val_loss: 1.0373 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0576\n",
      "Epoch 54/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0173 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0139 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9752 - accuracy: 0.5695 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9512 - accuracy: 0.5944 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9576 - accuracy: 0.5868 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9358 - accuracy: 0.6074 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9296 - accuracy: 0.6121 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9547 - accuracy: 0.5905 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9563 - accuracy: 0.5895 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 00054: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9563 - accuracy: 0.5895 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00 - val_loss: 1.0364 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0461\n",
      "Epoch 55/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0192 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0145 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9600 - accuracy: 0.5850 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9512 - accuracy: 0.5944 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9576 - accuracy: 0.5868 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9358 - accuracy: 0.6074 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9296 - accuracy: 0.6121 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9546 - accuracy: 0.5905 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9562 - accuracy: 0.5895 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 00055: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9562 - accuracy: 0.5895 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00 - val_loss: 1.0358 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0461\n",
      "Epoch 56/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0172 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0132 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9743 - accuracy: 0.5695 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9505 - accuracy: 0.5944 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9569 - accuracy: 0.5868 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9175 - accuracy: 0.6217 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9491 - accuracy: 0.5947 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9553 - accuracy: 0.5895 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 00056: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9553 - accuracy: 0.5895 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00 - val_loss: 1.0301 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0461\n",
      "Epoch 57/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0194 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0124 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9733 - accuracy: 0.5695 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9509 - accuracy: 0.5949 - recall_26: 0.0028 - recall_27: 0.0000e+00 - precision_26: 0.7500 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9566 - accuracy: 0.5872 - recall_26: 0.0022 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9347 - accuracy: 0.6078 - recall_26: 0.0019 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9288 - accuracy: 0.6125 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.5714 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9544 - accuracy: 0.5908 - recall_26: 0.0018 - recall_27: 0.0000e+00 - precision_26: 0.5714 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9561 - accuracy: 0.5898 - recall_26: 0.0016 - recall_27: 0.0000e+00 - precision_26: 0.5714 - precision_27: 0.0000e+00\n",
      "Epoch 00057: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9561 - accuracy: 0.5898 - recall_26: 0.0016 - recall_27: 0.0000e+00 - precision_26: 0.5714 - precision_27: 0.0000e+00 - val_loss: 1.0332 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0461\n",
      "Epoch 58/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0150 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0117 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9734 - accuracy: 0.5695 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9504 - accuracy: 0.5944 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9565 - accuracy: 0.5868 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9351 - accuracy: 0.6074 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9292 - accuracy: 0.6121 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9492 - accuracy: 0.5947 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9541 - accuracy: 0.5907 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 00058: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9557 - accuracy: 0.5895 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00 - val_loss: 1.0299 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0461\n",
      "Epoch 59/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0204 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0128 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9735 - accuracy: 0.5695 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9537 - accuracy: 0.5911 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9569 - accuracy: 0.5868 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9353 - accuracy: 0.6074 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9294 - accuracy: 0.6121 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9498 - accuracy: 0.5947 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9562 - accuracy: 0.5895 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 00059: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9562 - accuracy: 0.5895 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00 - val_loss: 1.0314 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0461\n",
      "Epoch 60/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0174 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0127 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9744 - accuracy: 0.5695 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9508 - accuracy: 0.5944 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9572 - accuracy: 0.5868 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9355 - accuracy: 0.6074 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9479 - accuracy: 0.5958 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9545 - accuracy: 0.5907 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 00060: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9560 - accuracy: 0.5895 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00 - val_loss: 1.0294 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0461\n",
      "Epoch 61/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0187 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0127 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9589 - accuracy: 0.5850 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9511 - accuracy: 0.5944 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9483 - accuracy: 0.5960 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9175 - accuracy: 0.6217 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9479 - accuracy: 0.5958 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9543 - accuracy: 0.5905 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9560 - accuracy: 0.5895 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 00061: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9560 - accuracy: 0.5895 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00 - val_loss: 1.0307 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0461\n",
      "Epoch 62/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0178 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0129 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9738 - accuracy: 0.5695 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9503 - accuracy: 0.5944 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9477 - accuracy: 0.5960 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9172 - accuracy: 0.6217 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9492 - accuracy: 0.5947 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9540 - accuracy: 0.5907 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 00062: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9555 - accuracy: 0.5895 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00 - val_loss: 1.0332 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0461\n",
      "Epoch 63/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0168 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0118 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9730 - accuracy: 0.5695 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9502 - accuracy: 0.5944 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9485 - accuracy: 0.5960 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9177 - accuracy: 0.6217 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9481 - accuracy: 0.5958 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9548 - accuracy: 0.5905 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 00063: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9563 - accuracy: 0.5895 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00 - val_loss: 1.0351 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0168 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0122 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9738 - accuracy: 0.5695 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9532 - accuracy: 0.5911 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9565 - accuracy: 0.5868 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9347 - accuracy: 0.6074 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9287 - accuracy: 0.6121 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9539 - accuracy: 0.5905 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9556 - accuracy: 0.5895 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 00064: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9556 - accuracy: 0.5895 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00 - val_loss: 1.0461 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0461\n",
      "Epoch 65/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0181 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0111 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9722 - accuracy: 0.5695 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9543 - accuracy: 0.5913 - recall_26: 0.0010 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9569 - accuracy: 0.5871 - recall_26: 0.0015 - recall_27: 0.0000e+00 - precision_26: 0.6667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9354 - accuracy: 0.6076 - recall_26: 0.0013 - recall_27: 0.0000e+00 - precision_26: 0.6667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9295 - accuracy: 0.6123 - recall_26: 0.0011 - recall_27: 0.0000e+00 - precision_26: 0.6667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9542 - accuracy: 0.5907 - recall_26: 8.9286e-04 - recall_27: 0.0000e+00 - precision_26: 0.6667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9555 - accuracy: 0.5897 - recall_26: 7.8462e-04 - recall_27: 0.0000e+00 - precision_26: 0.6667 - precision_27: 0.0000e+00\n",
      "Epoch 00065: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9555 - accuracy: 0.5897 - recall_26: 7.8462e-04 - recall_27: 0.0000e+00 - precision_26: 0.6667 - precision_27: 0.0000e+00 - val_loss: 1.0308 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0461\n",
      "Epoch 66/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0196 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0105 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9588 - accuracy: 0.5850 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9498 - accuracy: 0.5940 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9472 - accuracy: 0.5960 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9165 - accuracy: 0.6217 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9487 - accuracy: 0.5947 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9535 - accuracy: 0.5907 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 00066: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9548 - accuracy: 0.5895 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00 - val_loss: 1.0281 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0461\n",
      "Epoch 67/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0185 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0101 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9721 - accuracy: 0.5695 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9512 - accuracy: 0.5944 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9569 - accuracy: 0.5868 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9172 - accuracy: 0.6217 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9476 - accuracy: 0.5958 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9539 - accuracy: 0.5905 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9554 - accuracy: 0.5895 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 00067: val_loss did not improve from 1.02288\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 0.03686400055885315.\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9554 - accuracy: 0.5895 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00 - val_loss: 1.0318 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0461\n",
      "Epoch 68/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0186 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0129 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9585 - accuracy: 0.5850 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9497 - accuracy: 0.5944 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9560 - accuracy: 0.5868 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9170 - accuracy: 0.6217 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9458 - accuracy: 0.5958 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9522 - accuracy: 0.5907 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 00068: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9537 - accuracy: 0.5895 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00 - val_loss: 1.0382 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0369\n",
      "Epoch 69/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0155 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0114 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9566 - accuracy: 0.5850 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9481 - accuracy: 0.5944 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9458 - accuracy: 0.5960 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9149 - accuracy: 0.6217 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9468 - accuracy: 0.5947 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9517 - accuracy: 0.5907 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 00069: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9532 - accuracy: 0.5895 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00 - val_loss: 1.0352 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0369\n",
      "Epoch 70/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0164 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0117 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9573 - accuracy: 0.5853 - recall_26: 0.0012 - recall_27: 0.0000e+00 - precision_26: 1.0000 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9487 - accuracy: 0.5946 - recall_26: 0.0019 - recall_27: 0.0000e+00 - precision_26: 0.6667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9551 - accuracy: 0.5870 - recall_26: 0.0015 - recall_27: 0.0000e+00 - precision_26: 0.6667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9157 - accuracy: 0.6218 - recall_26: 0.0012 - recall_27: 0.0000e+00 - precision_26: 0.6667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9456 - accuracy: 0.5959 - recall_26: 0.0010 - recall_27: 0.0000e+00 - precision_26: 0.6667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9519 - accuracy: 0.5907 - recall_26: 8.3752e-04 - recall_27: 0.0000e+00 - precision_26: 0.6667 - precision_27: 0.0000e+00\n",
      "Epoch 00070: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9534 - accuracy: 0.5896 - recall_26: 7.8462e-04 - recall_27: 0.0000e+00 - precision_26: 0.6667 - precision_27: 0.0000e+00 - val_loss: 1.0269 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0369\n",
      "Epoch 71/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0175 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0121 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9731 - accuracy: 0.5695 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9520 - accuracy: 0.5911 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9482 - accuracy: 0.5940 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9467 - accuracy: 0.5960 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9279 - accuracy: 0.6121 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9518 - accuracy: 0.5905 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9535 - accuracy: 0.5895 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 00071: val_loss did not improve from 1.02288\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9535 - accuracy: 0.5895 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00 - val_loss: 1.0305 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0369\n",
      "Epoch 72/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0155 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0113 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9716 - accuracy: 0.5695 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9483 - accuracy: 0.5944 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9545 - accuracy: 0.5868 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9149 - accuracy: 0.6217 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9450 - accuracy: 0.5958 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9509 - accuracy: 0.5905 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9524 - accuracy: 0.5895 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 00072: val_loss improved from 1.02288 to 1.02258, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.9524 - accuracy: 0.5895 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00 - val_loss: 1.0226 - val_accuracy: 0.4997 - val_recall_26: 0.0166 - val_recall_27: 0.0000e+00 - val_precision_26: 0.5000 - val_precision_27: 0.0000e+00 - lr: 0.0369\n",
      "Epoch 73/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0199 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9814 - accuracy: 0.5594 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9579 - accuracy: 0.5855 - recall_26: 0.0035 - recall_27: 0.0000e+00 - precision_26: 0.4286 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9501 - accuracy: 0.5948 - recall_26: 0.0037 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9557 - accuracy: 0.5871 - recall_26: 0.0029 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9340 - accuracy: 0.6076 - recall_26: 0.0026 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9278 - accuracy: 0.6123 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9521 - accuracy: 0.5907 - recall_26: 0.0018 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9537 - accuracy: 0.5897 - recall_26: 0.0016 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+00\n",
      "Epoch 00073: val_loss did not improve from 1.02258\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9537 - accuracy: 0.5897 - recall_26: 0.0016 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+00 - val_loss: 1.0299 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0369\n",
      "Epoch 74/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0168 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9815 - accuracy: 0.5594 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9568 - accuracy: 0.5850 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9473 - accuracy: 0.5940 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9453 - accuracy: 0.5960 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9269 - accuracy: 0.6121 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9464 - accuracy: 0.5947 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9508 - accuracy: 0.5907 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 00074: val_loss improved from 1.02258 to 1.02197, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.9522 - accuracy: 0.5895 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00 - val_loss: 1.0220 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0369\n",
      "Epoch 75/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0185 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9789 - accuracy: 0.5605 - recall_26: 0.0050 - recall_27: 0.0000e+00 - precision_26: 1.0000 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9556 - accuracy: 0.5868 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.7778 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9477 - accuracy: 0.5950 - recall_26: 0.0091 - recall_27: 0.0000e+00 - precision_26: 0.4783 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9461 - accuracy: 0.5966 - recall_26: 0.0082 - recall_27: 0.0000e+00 - precision_26: 0.4286 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9275 - accuracy: 0.6126 - recall_26: 0.0068 - recall_27: 0.0000e+00 - precision_26: 0.4286 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9522 - accuracy: 0.5909 - recall_26: 0.0054 - recall_27: 0.0000e+00 - precision_26: 0.4286 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9539 - accuracy: 0.5899 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.4286 - precision_27: 0.0000e+00\n",
      "Epoch 00075: val_loss did not improve from 1.02197\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9539 - accuracy: 0.5899 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.4286 - precision_27: 0.0000e+00 - val_loss: 1.0317 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0369\n",
      "Epoch 76/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0152 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0114 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9722 - accuracy: 0.5692 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9480 - accuracy: 0.5942 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9458 - accuracy: 0.5958 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9153 - accuracy: 0.6216 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9451 - accuracy: 0.5957 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9515 - accuracy: 0.5906 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 00076: val_loss did not improve from 1.02197\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9531 - accuracy: 0.5894 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00 - val_loss: 1.0248 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0369\n",
      "Epoch 77/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0154 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9795 - accuracy: 0.5594 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9557 - accuracy: 0.5850 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9468 - accuracy: 0.5940 - recall_26: 0.0000e+00 - recall_27: 0.0016 - precision_26: 0.0000e+00 - precision_27: 0.2857       - ETA: 0s - loss: 0.9452 - accuracy: 0.5958 - recall_26: 0.0000e+00 - recall_27: 0.0013 - precision_26: 0.0000e+00 - precision_27: 0.20 - ETA: 0s - loss: 0.9145 - accuracy: 0.6216 - recall_26: 0.0000e+00 - recall_27: 0.0011 - precision_26: 0.0000e+00 - precision_27: 0.20 - ETA: 0s - loss: 0.9453 - accuracy: 0.5957 - recall_26: 0.0000e+00 - recall_27: 8.9807e-04 - precision_26: 0.0000e+00 - precision_27: 0.20 - ETA: 0s - loss: 0.9513 - accuracy: 0.5904 - recall_26: 0.0000e+00 - recall_27: 7.9745e-04 - precision_26: 0.0000e+00 - precision_27: 0.20 - ETA: 0s - loss: 0.9530 - accuracy: 0.5894 - recall_26: 0.0000e+00 - recall_27: 7.2202e-04 - precision_26: 0.0000e+00 - precision_27: 0.2000\n",
      "Epoch 00077: val_loss did not improve from 1.02197\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9530 - accuracy: 0.5894 - recall_26: 0.0000e+00 - recall_27: 7.2202e-04 - precision_26: 0.0000e+00 - precision_27: 0.2000 - val_loss: 1.0246 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0186 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0088 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9565 - accuracy: 0.5850 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9481 - accuracy: 0.5944 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9457 - accuracy: 0.5960 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9154 - accuracy: 0.6217 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9462 - accuracy: 0.5947 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9508 - accuracy: 0.5907 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 00078: val_loss did not improve from 1.02197\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9527 - accuracy: 0.5895 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00 - val_loss: 1.0372 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0369\n",
      "Epoch 79/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0200 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9803 - accuracy: 0.5594 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9557 - accuracy: 0.5853 - recall_26: 0.0012 - recall_27: 0.0000e+00 - precision_26: 1.0000 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9477 - accuracy: 0.5944 - recall_26: 9.3633e-04 - recall_27: 0.0000e+00 - precision_26: 1.0000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9451 - accuracy: 0.5960 - recall_26: 6.8120e-04 - recall_27: 0.0000e+00 - precision_26: 1.0000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9147 - accuracy: 0.6217 - recall_26: 6.1996e-04 - recall_27: 0.0000e+00 - precision_26: 1.0000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9460 - accuracy: 0.5947 - recall_26: 4.8520e-04 - recall_27: 0.0000e+00 - precision_26: 1.0000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9505 - accuracy: 0.5907 - recall_26: 4.1876e-04 - recall_27: 0.0000e+00 - precision_26: 1.0000 - precision_27: 0.0000e+00\n",
      "Epoch 00079: val_loss did not improve from 1.02197\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9522 - accuracy: 0.5895 - recall_26: 3.9231e-04 - recall_27: 0.0000e+00 - precision_26: 1.0000 - precision_27: 0.0000e+00 - val_loss: 1.0267 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0369\n",
      "Epoch 80/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0178 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0076 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9684 - accuracy: 0.5695 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9467 - accuracy: 0.5944 - recall_26: 0.0028 - recall_27: 0.0000e+00 - precision_26: 0.2727 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9528 - accuracy: 0.5867 - recall_26: 0.0051 - recall_27: 0.0000e+00 - precision_26: 0.2800 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9314 - accuracy: 0.6073 - recall_26: 0.0045 - recall_27: 0.0000e+00 - precision_26: 0.2692 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9446 - accuracy: 0.5958 - recall_26: 0.0042 - recall_27: 0.0000e+00 - precision_26: 0.2963 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9500 - accuracy: 0.5907 - recall_26: 0.0034 - recall_27: 0.0000e+00 - precision_26: 0.2963 - precision_27: 0.0000e+00\n",
      "Epoch 00080: val_loss improved from 1.02197 to 1.01748, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.9516 - accuracy: 0.5895 - recall_26: 0.0031 - recall_27: 0.0000e+00 - precision_26: 0.2963 - precision_27: 0.0000e+00 - val_loss: 1.0175 - val_accuracy: 0.5005 - val_recall_26: 0.0299 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4159 - val_precision_27: 0.0000e+00 - lr: 0.0369\n",
      "Epoch 81/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0214 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0075 - accuracy: 0.5303 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9560 - accuracy: 0.5860 - recall_26: 0.0046 - recall_27: 0.0000e+00 - precision_26: 0.5714 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9481 - accuracy: 0.5949 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.4167 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9535 - accuracy: 0.5871 - recall_26: 0.0058 - recall_27: 0.0000e+00 - precision_26: 0.3636 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9320 - accuracy: 0.6076 - recall_26: 0.0052 - recall_27: 0.0000e+00 - precision_26: 0.3478 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9449 - accuracy: 0.5960 - recall_26: 0.0042 - recall_27: 0.0000e+00 - precision_26: 0.3478 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9504 - accuracy: 0.5907 - recall_26: 0.0036 - recall_27: 0.0000e+00 - precision_26: 0.3478 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9517 - accuracy: 0.5897 - recall_26: 0.0031 - recall_27: 0.0000e+00 - precision_26: 0.3478 - precision_27: 0.0000e+00\n",
      "Epoch 00081: val_loss did not improve from 1.01748\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9517 - accuracy: 0.5897 - recall_26: 0.0031 - recall_27: 0.0000e+00 - precision_26: 0.3478 - precision_27: 0.0000e+00 - val_loss: 1.0189 - val_accuracy: 0.4993 - val_recall_26: 0.0159 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4717 - val_precision_27: 0.0000e+00 - lr: 0.0369\n",
      "Epoch 82/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0194 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0073 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9678 - accuracy: 0.5695 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9469 - accuracy: 0.5946 - recall_26: 0.0028 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9527 - accuracy: 0.5865 - recall_26: 0.0044 - recall_27: 0.0000e+00 - precision_26: 0.2727 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9137 - accuracy: 0.6215 - recall_26: 0.0037 - recall_27: 0.0000e+00 - precision_26: 0.2609 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9445 - accuracy: 0.5956 - recall_26: 0.0031 - recall_27: 0.0000e+00 - precision_26: 0.2609 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9500 - accuracy: 0.5905 - recall_26: 0.0025 - recall_27: 0.0000e+00 - precision_26: 0.2609 - precision_27: 0.0000e+00\n",
      "Epoch 00082: val_loss did not improve from 1.01748\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9513 - accuracy: 0.5894 - recall_26: 0.0024 - recall_27: 0.0000e+00 - precision_26: 0.2609 - precision_27: 0.0000e+00 - val_loss: 1.0184 - val_accuracy: 0.4998 - val_recall_26: 0.0268 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4118 - val_precision_27: 0.0000e+00 - lr: 0.0369\n",
      "Epoch 83/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0199 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9774 - accuracy: 0.5594 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9545 - accuracy: 0.5858 - recall_26: 0.0035 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9457 - accuracy: 0.5935 - recall_26: 0.0033 - recall_27: 0.0000e+00 - precision_26: 0.1905 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9436 - accuracy: 0.5956 - recall_26: 0.0048 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9134 - accuracy: 0.6215 - recall_26: 0.0050 - recall_27: 0.0000e+00 - precision_26: 0.2667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9450 - accuracy: 0.5945 - recall_26: 0.0039 - recall_27: 0.0000e+00 - precision_26: 0.2667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9508 - accuracy: 0.5894 - recall_26: 0.0031 - recall_27: 0.0000e+00 - precision_26: 0.2667 - precision_27: 0.0000e+00\n",
      "Epoch 00083: val_loss did not improve from 1.01748\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9508 - accuracy: 0.5894 - recall_26: 0.0031 - recall_27: 0.0000e+00 - precision_26: 0.2667 - precision_27: 0.0000e+00 - val_loss: 1.0188 - val_accuracy: 0.5020 - val_recall_26: 0.0401 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4172 - val_precision_27: 0.0000e+00 - lr: 0.0369\n",
      "Epoch 84/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0211 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0065 - accuracy: 0.5298 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9677 - accuracy: 0.5695 - recall_26: 0.0014 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9474 - accuracy: 0.5946 - recall_26: 0.0037 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9534 - accuracy: 0.5865 - recall_26: 0.0051 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9146 - accuracy: 0.6215 - recall_26: 0.0043 - recall_27: 0.0000e+00 - precision_26: 0.2414 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9456 - accuracy: 0.5945 - recall_26: 0.0034 - recall_27: 0.0000e+00 - precision_26: 0.2414 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9498 - accuracy: 0.5905 - recall_26: 0.0029 - recall_27: 0.0000e+00 - precision_26: 0.2414 - precision_27: 0.0000e+00\n",
      "Epoch 00084: val_loss did not improve from 1.01748\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9514 - accuracy: 0.5894 - recall_26: 0.0027 - recall_27: 0.0000e+00 - precision_26: 0.2414 - precision_27: 0.0000e+00 - val_loss: 1.0206 - val_accuracy: 0.4980 - val_recall_26: 0.0083 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4643 - val_precision_27: 0.0000e+00 - lr: 0.0369\n",
      "Epoch 85/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0190 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0070 - accuracy: 0.5303 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9680 - accuracy: 0.5698 - recall_26: 0.0014 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9500 - accuracy: 0.5915 - recall_26: 0.0031 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9526 - accuracy: 0.5868 - recall_26: 0.0058 - recall_27: 0.0000e+00 - precision_26: 0.3200 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9308 - accuracy: 0.6074 - recall_26: 0.0052 - recall_27: 0.0000e+00 - precision_26: 0.2963 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9255 - accuracy: 0.6122 - recall_26: 0.0051 - recall_27: 0.0000e+00 - precision_26: 0.3214 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9493 - accuracy: 0.5906 - recall_26: 0.0040 - recall_27: 0.0000e+00 - precision_26: 0.3214 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9507 - accuracy: 0.5896 - recall_26: 0.0035 - recall_27: 0.0000e+00 - precision_26: 0.3214 - precision_27: 0.0000e+00\n",
      "Epoch 00085: val_loss did not improve from 1.01748\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9507 - accuracy: 0.5896 - recall_26: 0.0035 - recall_27: 0.0000e+00 - precision_26: 0.3214 - precision_27: 0.0000e+00 - val_loss: 1.0177 - val_accuracy: 0.5007 - val_recall_26: 0.0331 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4031 - val_precision_27: 0.0000e+00 - lr: 0.0369\n",
      "Epoch 86/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0212 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0061 - accuracy: 0.5308 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.6667 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9544 - accuracy: 0.5863 - recall_26: 0.0058 - recall_27: 0.0000e+00 - precision_26: 0.6250 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9461 - accuracy: 0.5938 - recall_26: 0.0058 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9439 - accuracy: 0.5960 - recall_26: 0.0068 - recall_27: 0.0000e+00 - precision_26: 0.2941 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9138 - accuracy: 0.6217 - recall_26: 0.0062 - recall_27: 0.0000e+00 - precision_26: 0.2941 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9442 - accuracy: 0.5958 - recall_26: 0.0052 - recall_27: 0.0000e+00 - precision_26: 0.2941 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9496 - accuracy: 0.5907 - recall_26: 0.0042 - recall_27: 0.0000e+00 - precision_26: 0.2941 - precision_27: 0.0000e+00\n",
      "Epoch 00086: val_loss did not improve from 1.01748\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9510 - accuracy: 0.5895 - recall_26: 0.0039 - recall_27: 0.0000e+00 - precision_26: 0.2941 - precision_27: 0.0000e+00 - val_loss: 1.0205 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0369\n",
      "Epoch 87/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0205 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0072 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9547 - accuracy: 0.5858 - recall_26: 0.0035 - recall_27: 0.0000e+00 - precision_26: 0.7500 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9466 - accuracy: 0.5948 - recall_26: 0.0037 - recall_27: 0.0000e+00 - precision_26: 0.4444 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9435 - accuracy: 0.5961 - recall_26: 0.0048 - recall_27: 0.0000e+00 - precision_26: 0.3500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9134 - accuracy: 0.6218 - recall_26: 0.0043 - recall_27: 0.0000e+00 - precision_26: 0.3500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9439 - accuracy: 0.5959 - recall_26: 0.0037 - recall_27: 0.0000e+00 - precision_26: 0.3500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9490 - accuracy: 0.5907 - recall_26: 0.0029 - recall_27: 0.0000e+00 - precision_26: 0.3500 - precision_27: 0.0000e+00\n",
      "Epoch 00087: val_loss did not improve from 1.01748\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9505 - accuracy: 0.5896 - recall_26: 0.0027 - recall_27: 0.0000e+00 - precision_26: 0.3500 - precision_27: 0.0000e+00 - val_loss: 1.0187 - val_accuracy: 0.4997 - val_recall_26: 0.0255 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4167 - val_precision_27: 0.0000e+00 - lr: 0.0369\n",
      "Epoch 88/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0207 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0056 - accuracy: 0.5303 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9667 - accuracy: 0.5698 - recall_26: 0.0014 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9497 - accuracy: 0.5915 - recall_26: 0.0041 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9521 - accuracy: 0.5867 - recall_26: 0.0066 - recall_27: 0.0000e+00 - precision_26: 0.2727 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9133 - accuracy: 0.6215 - recall_26: 0.0056 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9438 - accuracy: 0.5956 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9492 - accuracy: 0.5905 - recall_26: 0.0038 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+00\n",
      "Epoch 00088: val_loss did not improve from 1.01748\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9506 - accuracy: 0.5894 - recall_26: 0.0035 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+00 - val_loss: 1.0198 - val_accuracy: 0.4982 - val_recall_26: 0.0083 - val_recall_27: 0.0000e+00 - val_precision_26: 0.5000 - val_precision_27: 0.0000e+00 - lr: 0.0369\n",
      "Epoch 89/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0205 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0067 - accuracy: 0.5303 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9673 - accuracy: 0.5698 - recall_26: 0.0014 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9463 - accuracy: 0.5949 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.4167 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9522 - accuracy: 0.5868 - recall_26: 0.0058 - recall_27: 0.0000e+00 - precision_26: 0.3200 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9135 - accuracy: 0.6217 - recall_26: 0.0050 - recall_27: 0.0000e+00 - precision_26: 0.3077 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9440 - accuracy: 0.5958 - recall_26: 0.0042 - recall_27: 0.0000e+00 - precision_26: 0.3077 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9495 - accuracy: 0.5907 - recall_26: 0.0034 - recall_27: 0.0000e+00 - precision_26: 0.3077 - precision_27: 0.0000e+00\n",
      "Epoch 00089: val_loss did not improve from 1.01748\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9508 - accuracy: 0.5895 - recall_26: 0.0031 - recall_27: 0.0000e+00 - precision_26: 0.3077 - precision_27: 0.0000e+00 - val_loss: 1.0199 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0369\n",
      "Epoch 90/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0204 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0080 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9553 - accuracy: 0.5858 - recall_26: 0.0035 - recall_27: 0.0000e+00 - precision_26: 0.6000 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9474 - accuracy: 0.5948 - recall_26: 0.0037 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9527 - accuracy: 0.5871 - recall_26: 0.0029 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9136 - accuracy: 0.6219 - recall_26: 0.0025 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9440 - accuracy: 0.5960 - recall_26: 0.0021 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9497 - accuracy: 0.5908 - recall_26: 0.0017 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+00\n",
      "Epoch 00090: val_loss did not improve from 1.01748\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 0.029491201043128967.\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9511 - accuracy: 0.5897 - recall_26: 0.0016 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+00 - val_loss: 1.0215 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0369\n",
      "Epoch 91/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0193 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0078 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9539 - accuracy: 0.5855 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 1.0000 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9458 - accuracy: 0.5948 - recall_26: 0.0028 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9513 - accuracy: 0.5872 - recall_26: 0.0044 - recall_27: 0.0000e+00 - precision_26: 0.4615 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9297 - accuracy: 0.6076 - recall_26: 0.0039 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9425 - accuracy: 0.5960 - recall_26: 0.0031 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9480 - accuracy: 0.5907 - recall_26: 0.0027 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+00\n",
      "Epoch 00091: val_loss did not improve from 1.01748\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9492 - accuracy: 0.5897 - recall_26: 0.0024 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+00 - val_loss: 1.0178 - val_accuracy: 0.5000 - val_recall_26: 0.0248 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4333 - val_precision_27: 0.0000e+00 - lr: 0.0295\n",
      "Epoch 92/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0181 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0059 - accuracy: 0.5303 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9530 - accuracy: 0.5860 - recall_26: 0.0046 - recall_27: 0.0000e+00 - precision_26: 0.5714 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9451 - accuracy: 0.5946 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9507 - accuracy: 0.5868 - recall_26: 0.0073 - recall_27: 0.0000e+00 - precision_26: 0.3125 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9117 - accuracy: 0.6216 - recall_26: 0.0062 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9420 - accuracy: 0.5956 - recall_26: 0.0052 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9476 - accuracy: 0.5903 - recall_26: 0.0045 - recall_27: 3.9872e-04 - precision_26: 0.2857 - precision_27: 0.2500    \n",
      "Epoch 00092: val_loss did not improve from 1.01748\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9490 - accuracy: 0.5892 - recall_26: 0.0039 - recall_27: 3.6101e-04 - precision_26: 0.2632 - precision_27: 0.2500 - val_loss: 1.0185 - val_accuracy: 0.4990 - val_recall_26: 0.0217 - val_recall_27: 0.0000e+00 - val_precision_26: 0.3908 - val_precision_27: 0.0000e+00 - lr: 0.0295\n",
      "Epoch 93/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0175 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0061 - accuracy: 0.5303 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9529 - accuracy: 0.5860 - recall_26: 0.0046 - recall_27: 0.0000e+00 - precision_26: 0.5714 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9441 - accuracy: 0.5940 - recall_26: 0.0050 - recall_27: 0.0000e+00 - precision_26: 0.2727 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9431 - accuracy: 0.5961 - recall_26: 0.0068 - recall_27: 0.0000e+00 - precision_26: 0.3226 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9128 - accuracy: 0.6219 - recall_26: 0.0068 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9425 - accuracy: 0.5960 - recall_26: 0.0058 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9480 - accuracy: 0.5907 - recall_26: 0.0049 - recall_27: 3.9872e-04 - precision_26: 0.3333 - precision_27: 0.5000   - ETA: 0s - loss: 0.9493 - accuracy: 0.5897 - recall_26: 0.0043 - recall_27: 3.6101e-04 - precision_26: 0.3235 - precision_27: 0.5000\n",
      "Epoch 00093: val_loss did not improve from 1.01748\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9493 - accuracy: 0.5897 - recall_26: 0.0043 - recall_27: 3.6101e-04 - precision_26: 0.3235 - precision_27: 0.5000 - val_loss: 1.0178 - val_accuracy: 0.4984 - val_recall_26: 0.0096 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4688 - val_precision_27: 0.0000e+00 - lr: 0.0295\n",
      "Epoch 94/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0170 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0069 - accuracy: 0.5298 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9533 - accuracy: 0.5858 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.5455 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9454 - accuracy: 0.5948 - recall_26: 0.0066 - recall_27: 0.0000e+00 - precision_26: 0.4375 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9515 - accuracy: 0.5864 - recall_26: 0.0051 - recall_27: 0.0000e+00 - precision_26: 0.3182 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9303 - accuracy: 0.6068 - recall_26: 0.0052 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9426 - accuracy: 0.5953 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.3103 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9480 - accuracy: 0.5900 - recall_26: 0.0040 - recall_27: 3.9872e-04 - precision_26: 0.3103 - precision_27: 0.1250    \n",
      "Epoch 00094: val_loss improved from 1.01748 to 1.01648, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.9493 - accuracy: 0.5890 - recall_26: 0.0035 - recall_27: 3.6101e-04 - precision_26: 0.2903 - precision_27: 0.1250 - val_loss: 1.0165 - val_accuracy: 0.5005 - val_recall_26: 0.0287 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4167 - val_precision_27: 0.0000e+00 - lr: 0.0295\n",
      "Epoch 95/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0180 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0072 - accuracy: 0.5298 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9534 - accuracy: 0.5855 - recall_26: 0.0035 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9454 - accuracy: 0.5946 - recall_26: 0.0037 - recall_27: 0.0000e+00 - precision_26: 0.3077 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9434 - accuracy: 0.5958 - recall_26: 0.0061 - recall_27: 0.0000e+00 - precision_26: 0.2812 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9129 - accuracy: 0.6216 - recall_26: 0.0056 - recall_27: 0.0000e+00 - precision_26: 0.2647 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9428 - accuracy: 0.5957 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2647 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9483 - accuracy: 0.5906 - recall_26: 0.0038 - recall_27: 3.7922e-04 - precision_26: 0.2647 - precision_27: 0.5000    \n",
      "Epoch 00095: val_loss did not improve from 1.01648\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9499 - accuracy: 0.5894 - recall_26: 0.0035 - recall_27: 3.6101e-04 - precision_26: 0.2647 - precision_27: 0.5000 - val_loss: 1.0179 - val_accuracy: 0.4990 - val_recall_26: 0.0153 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4615 - val_precision_27: 0.0000e+00 - lr: 0.0295\n",
      "Epoch 96/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0165 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0082 - accuracy: 0.5303 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9538 - accuracy: 0.5858 - recall_26: 0.0046 - recall_27: 0.0000e+00 - precision_26: 0.5714 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9449 - accuracy: 0.5940 - recall_26: 0.0041 - recall_27: 0.0000e+00 - precision_26: 0.3125 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9308 - accuracy: 0.6072 - recall_26: 0.0032 - recall_27: 0.0000e+00 - precision_26: 0.2941 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9250 - accuracy: 0.6119 - recall_26: 0.0028 - recall_27: 0.0000e+00 - precision_26: 0.2941 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9440 - accuracy: 0.5945 - recall_26: 0.0024 - recall_27: 0.0000e+00 - precision_26: 0.2941 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9482 - accuracy: 0.5905 - recall_26: 0.0021 - recall_27: 0.0000e+00 - precision_26: 0.2941 - precision_27: 0.0000e+00\n",
      "Epoch 00096: val_loss did not improve from 1.01648\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9497 - accuracy: 0.5894 - recall_26: 0.0020 - recall_27: 0.0000e+00 - precision_26: 0.2941 - precision_27: 0.0000e+00 - val_loss: 1.0190 - val_accuracy: 0.4989 - val_recall_26: 0.0134 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4884 - val_precision_27: 0.0000e+00 - lr: 0.0295\n",
      "Epoch 97/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0152 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9770 - accuracy: 0.5598 - recall_26: 0.0017 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9530 - accuracy: 0.5860 - recall_26: 0.0046 - recall_27: 0.0000e+00 - precision_26: 0.6667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9444 - accuracy: 0.5938 - recall_26: 0.0050 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9435 - accuracy: 0.5960 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.3143 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9130 - accuracy: 0.6217 - recall_26: 0.0074 - recall_27: 0.0000e+00 - precision_26: 0.3077 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9439 - accuracy: 0.5947 - recall_26: 0.0058 - recall_27: 0.0000e+00 - precision_26: 0.3077 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9480 - accuracy: 0.5905 - recall_26: 0.0050 - recall_27: 0.0000e+00 - precision_26: 0.2927 - precision_27: 0.0000e+00\n",
      "Epoch 00097: val_loss did not improve from 1.01648\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9495 - accuracy: 0.5894 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2927 - precision_27: 0.0000e+00 - val_loss: 1.0176 - val_accuracy: 0.4995 - val_recall_26: 0.0217 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4198 - val_precision_27: 0.0000e+00 - lr: 0.0295\n",
      "Epoch 98/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0149 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0064 - accuracy: 0.5298 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9661 - accuracy: 0.5695 - recall_26: 0.0014 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9451 - accuracy: 0.5948 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.3571 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9513 - accuracy: 0.5868 - recall_26: 0.0066 - recall_27: 0.0000e+00 - precision_26: 0.3103 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9128 - accuracy: 0.6218 - recall_26: 0.0074 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9437 - accuracy: 0.5948 - recall_26: 0.0058 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9493 - accuracy: 0.5896 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00\n",
      "Epoch 00098: val_loss did not improve from 1.01648\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9493 - accuracy: 0.5896 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00 - val_loss: 1.0182 - val_accuracy: 0.4987 - val_recall_26: 0.0153 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4444 - val_precision_27: 0.0000e+00 - lr: 0.0295\n",
      "Epoch 99/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0154 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0071 - accuracy: 0.5303 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9665 - accuracy: 0.5698 - recall_26: 0.0014 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9454 - accuracy: 0.5949 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.4167 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9515 - accuracy: 0.5870 - recall_26: 0.0066 - recall_27: 0.0000e+00 - precision_26: 0.3462 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9128 - accuracy: 0.6218 - recall_26: 0.0062 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9424 - accuracy: 0.5959 - recall_26: 0.0052 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9479 - accuracy: 0.5906 - recall_26: 0.0045 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00\n",
      "Epoch 00099: val_loss did not improve from 1.01648\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9495 - accuracy: 0.5896 - recall_26: 0.0039 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00 - val_loss: 1.0179 - val_accuracy: 0.4987 - val_recall_26: 0.0140 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4583 - val_precision_27: 0.0000e+00 - lr: 0.0295\n",
      "Epoch 100/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0150 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0066 - accuracy: 0.5303 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9667 - accuracy: 0.5698 - recall_26: 0.0014 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9454 - accuracy: 0.5948 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.3846 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9517 - accuracy: 0.5868 - recall_26: 0.0066 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9304 - accuracy: 0.6074 - recall_26: 0.0058 - recall_27: 0.0000e+00 - precision_26: 0.3103 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9247 - accuracy: 0.6121 - recall_26: 0.0051 - recall_27: 0.0000e+00 - precision_26: 0.3103 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9435 - accuracy: 0.5947 - recall_26: 0.0044 - recall_27: 0.0000e+00 - precision_26: 0.3103 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9494 - accuracy: 0.5895 - recall_26: 0.0035 - recall_27: 0.0000e+00 - precision_26: 0.3103 - precision_27: 0.0000e+00\n",
      "Epoch 00100: val_loss did not improve from 1.01648\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9494 - accuracy: 0.5895 - recall_26: 0.0035 - recall_27: 0.0000e+00 - precision_26: 0.3103 - precision_27: 0.0000e+00 - val_loss: 1.0177 - val_accuracy: 0.4989 - val_recall_26: 0.0166 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4483 - val_precision_27: 0.0000e+00 - lr: 0.0295\n",
      "Epoch 101/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0137 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0067 - accuracy: 0.5293 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9538 - accuracy: 0.5850 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9462 - accuracy: 0.5942 - recall_26: 0.0028 - recall_27: 0.0000e+00 - precision_26: 0.1875 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9443 - accuracy: 0.5953 - recall_26: 0.0048 - recall_27: 0.0000e+00 - precision_26: 0.2059 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9137 - accuracy: 0.6212 - recall_26: 0.0050 - recall_27: 0.0000e+00 - precision_26: 0.2222 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9444 - accuracy: 0.5943 - recall_26: 0.0039 - recall_27: 0.0000e+00 - precision_26: 0.2222 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9504 - accuracy: 0.5892 - recall_26: 0.0031 - recall_27: 0.0000e+00 - precision_26: 0.2222 - precision_27: 0.0000e+00\n",
      "Epoch 00101: val_loss did not improve from 1.01648\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9504 - accuracy: 0.5892 - recall_26: 0.0031 - recall_27: 0.0000e+00 - precision_26: 0.2222 - precision_27: 0.0000e+00 - val_loss: 1.0197 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0295\n",
      "Epoch 102/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0145 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0078 - accuracy: 0.5303 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9540 - accuracy: 0.5858 - recall_26: 0.0035 - recall_27: 0.0000e+00 - precision_26: 0.6000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9460 - accuracy: 0.5948 - recall_26: 0.0037 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9439 - accuracy: 0.5960 - recall_26: 0.0027 - recall_27: 0.0000e+00 - precision_26: 0.2667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9132 - accuracy: 0.6217 - recall_26: 0.0025 - recall_27: 0.0000e+00 - precision_26: 0.2667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9439 - accuracy: 0.5947 - recall_26: 0.0019 - recall_27: 0.0000e+00 - precision_26: 0.2667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9496 - accuracy: 0.5895 - recall_26: 0.0016 - recall_27: 0.0000e+00 - precision_26: 0.2667 - precision_27: 0.0000e+00\n",
      "Epoch 00102: val_loss did not improve from 1.01648\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9496 - accuracy: 0.5895 - recall_26: 0.0016 - recall_27: 0.0000e+00 - precision_26: 0.2667 - precision_27: 0.0000e+00 - val_loss: 1.0195 - val_accuracy: 0.4987 - val_recall_26: 0.0140 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4681 - val_precision_27: 0.0000e+00 - lr: 0.0295\n",
      "Epoch 103/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0144 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0068 - accuracy: 0.5303 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9677 - accuracy: 0.5698 - recall_26: 0.0014 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9464 - accuracy: 0.5948 - recall_26: 0.0037 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9523 - accuracy: 0.5868 - recall_26: 0.0058 - recall_27: 0.0000e+00 - precision_26: 0.3077 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9309 - accuracy: 0.6074 - recall_26: 0.0064 - recall_27: 0.0000e+00 - precision_26: 0.3030 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9429 - accuracy: 0.5958 - recall_26: 0.0052 - recall_27: 0.0000e+00 - precision_26: 0.3030 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9479 - accuracy: 0.5905 - recall_26: 0.0045 - recall_27: 0.0000e+00 - precision_26: 0.3030 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9495 - accuracy: 0.5895 - recall_26: 0.0039 - recall_27: 0.0000e+00 - precision_26: 0.3030 - precision_27: 0.0000e+00\n",
      "Epoch 00103: val_loss did not improve from 1.01648\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9495 - accuracy: 0.5895 - recall_26: 0.0039 - recall_27: 0.0000e+00 - precision_26: 0.3030 - precision_27: 0.0000e+00 - val_loss: 1.0190 - val_accuracy: 0.4997 - val_recall_26: 0.0197 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4493 - val_precision_27: 0.0000e+00 - lr: 0.0295\n",
      "Epoch 104/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0145 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0069 - accuracy: 0.5298 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9669 - accuracy: 0.5695 - recall_26: 0.0014 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9460 - accuracy: 0.5946 - recall_26: 0.0037 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9521 - accuracy: 0.5867 - recall_26: 0.0058 - recall_27: 0.0000e+00 - precision_26: 0.3077 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9134 - accuracy: 0.6215 - recall_26: 0.0050 - recall_27: 0.0000e+00 - precision_26: 0.2759 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9428 - accuracy: 0.5956 - recall_26: 0.0042 - recall_27: 0.0000e+00 - precision_26: 0.2759 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9480 - accuracy: 0.5903 - recall_26: 0.0036 - recall_27: 0.0000e+00 - precision_26: 0.2759 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9495 - accuracy: 0.5894 - recall_26: 0.0031 - recall_27: 0.0000e+00 - precision_26: 0.2759 - precision_27: 0.0000e+00\n",
      "Epoch 00104: val_loss did not improve from 1.01648\n",
      "\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 0.023592960834503175.\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9495 - accuracy: 0.5894 - recall_26: 0.0031 - recall_27: 0.0000e+00 - precision_26: 0.2759 - precision_27: 0.0000e+00 - val_loss: 1.0183 - val_accuracy: 0.4993 - val_recall_26: 0.0191 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4478 - val_precision_27: 0.0000e+00 - lr: 0.0295\n",
      "Epoch 105/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0157 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0071 - accuracy: 0.5298 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9529 - accuracy: 0.5858 - recall_26: 0.0046 - recall_27: 0.0000e+00 - precision_26: 0.5714 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9449 - accuracy: 0.5948 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.4167 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9510 - accuracy: 0.5868 - recall_26: 0.0058 - recall_27: 0.0000e+00 - precision_26: 0.3200 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9124 - accuracy: 0.6217 - recall_26: 0.0050 - recall_27: 0.0000e+00 - precision_26: 0.2963 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9414 - accuracy: 0.5958 - recall_26: 0.0042 - recall_27: 0.0000e+00 - precision_26: 0.2963 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9466 - accuracy: 0.5905 - recall_26: 0.0036 - recall_27: 0.0000e+00 - precision_26: 0.2963 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9482 - accuracy: 0.5895 - recall_26: 0.0031 - recall_27: 0.0000e+00 - precision_26: 0.2963 - precision_27: 0.0000e+00\n",
      "Epoch 00105: val_loss did not improve from 1.01648\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9482 - accuracy: 0.5895 - recall_26: 0.0031 - recall_27: 0.0000e+00 - precision_26: 0.2963 - precision_27: 0.0000e+00 - val_loss: 1.0172 - val_accuracy: 0.5008 - val_recall_26: 0.0318 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4202 - val_precision_27: 0.0000e+00 - lr: 0.0236\n",
      "Epoch 106/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0158 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0070 - accuracy: 0.5303 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9526 - accuracy: 0.5858 - recall_26: 0.0035 - recall_27: 0.0000e+00 - precision_26: 0.6000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9448 - accuracy: 0.5946 - recall_26: 0.0037 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9507 - accuracy: 0.5867 - recall_26: 0.0029 - recall_27: 0.0021 - precision_26: 0.2353 - precision_27: 0.3000       - ETA: 0s - loss: 0.9116 - accuracy: 0.6214 - recall_26: 0.0025 - recall_27: 0.0017 - precision_26: 0.2000 - precision_27: 0.25 - ETA: 0s - loss: 0.9410 - accuracy: 0.5954 - recall_26: 0.0021 - recall_27: 0.0013 - precision_26: 0.2000 - precision_27: 0.23 - ETA: 0s - loss: 0.9467 - accuracy: 0.5901 - recall_26: 0.0018 - recall_27: 0.0016 - precision_26: 0.2000 - precision_27: 0.26 - ETA: 0s - loss: 0.9482 - accuracy: 0.5892 - recall_26: 0.0016 - recall_27: 0.0014 - precision_26: 0.2000 - precision_27: 0.2667\n",
      "Epoch 00106: val_loss did not improve from 1.01648\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9482 - accuracy: 0.5892 - recall_26: 0.0016 - recall_27: 0.0014 - precision_26: 0.2000 - precision_27: 0.2667 - val_loss: 1.0190 - val_accuracy: 0.5007 - val_recall_26: 0.0293 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4381 - val_precision_27: 0.0000e+00 - lr: 0.0236\n",
      "Epoch 107/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0163 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0075 - accuracy: 0.5303 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9528 - accuracy: 0.5855 - recall_26: 0.0035 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9448 - accuracy: 0.5946 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.3846 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9418 - accuracy: 0.5957 - recall_26: 0.0041 - recall_27: 0.0013 - precision_26: 0.2609 - precision_27: 0.2857       - ETA: 0s - loss: 0.9115 - accuracy: 0.6214 - recall_26: 0.0037 - recall_27: 0.0011 - precision_26: 0.2500 - precision_27: 0.22 - ETA: 0s - loss: 0.9419 - accuracy: 0.5942 - recall_26: 0.0029 - recall_27: 8.4674e-04 - precision_26: 0.2500 - precision_27: 0.18 - ETA: 0s - loss: 0.9462 - accuracy: 0.5901 - recall_26: 0.0025 - recall_27: 7.5844e-04 - precision_26: 0.2222 - precision_27: 0.1818\n",
      "Epoch 00107: val_loss did not improve from 1.01648\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9476 - accuracy: 0.5890 - recall_26: 0.0024 - recall_27: 7.2202e-04 - precision_26: 0.2222 - precision_27: 0.1818 - val_loss: 1.0181 - val_accuracy: 0.5008 - val_recall_26: 0.0318 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4202 - val_precision_27: 0.0000e+00 - lr: 0.0236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0175 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0059 - accuracy: 0.5298 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9651 - accuracy: 0.5692 - recall_26: 0.0014 - recall_27: 0.0000e+00 - precision_26: 0.2000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9438 - accuracy: 0.5944 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2941 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9500 - accuracy: 0.5868 - recall_26: 0.0088 - recall_27: 0.0000e+00 - precision_26: 0.3077 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9114 - accuracy: 0.6218 - recall_26: 0.0087 - recall_27: 0.0000e+00 - precision_26: 0.3182 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9421 - accuracy: 0.5948 - recall_26: 0.0068 - recall_27: 8.4674e-04 - precision_26: 0.3182 - precision_27: 0.5000   - ETA: 0s - loss: 0.9464 - accuracy: 0.5906 - recall_26: 0.0059 - recall_27: 7.5844e-04 - precision_26: 0.2979 - precision_27: 0.5000\n",
      "Epoch 00108: val_loss did not improve from 1.01648\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9476 - accuracy: 0.5894 - recall_26: 0.0055 - recall_27: 7.2202e-04 - precision_26: 0.2979 - precision_27: 0.5000 - val_loss: 1.0174 - val_accuracy: 0.5002 - val_recall_26: 0.0293 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4182 - val_precision_27: 0.0000e+00 - lr: 0.0236\n",
      "Epoch 109/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0194 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0084 - accuracy: 0.5298 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9673 - accuracy: 0.5695 - recall_26: 0.0014 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9455 - accuracy: 0.5944 - recall_26: 0.0037 - recall_27: 0.0000e+00 - precision_26: 0.3077 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9424 - accuracy: 0.5956 - recall_26: 0.0027 - recall_27: 0.0019 - precision_26: 0.2105 - precision_27: 0.3333       - ETA: 0s - loss: 0.9238 - accuracy: 0.6118 - recall_26: 0.0023 - recall_27: 0.0015 - precision_26: 0.2000 - precision_27: 0.30 - ETA: 0s - loss: 0.9427 - accuracy: 0.5943 - recall_26: 0.0019 - recall_27: 0.0017 - precision_26: 0.2000 - precision_27: 0.30 - ETA: 0s - loss: 0.9470 - accuracy: 0.5902 - recall_26: 0.0017 - recall_27: 0.0015 - precision_26: 0.2000 - precision_27: 0.2667\n",
      "Epoch 00109: val_loss did not improve from 1.01648\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9484 - accuracy: 0.5891 - recall_26: 0.0016 - recall_27: 0.0014 - precision_26: 0.2000 - precision_27: 0.2667 - val_loss: 1.0179 - val_accuracy: 0.4987 - val_recall_26: 0.0159 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4630 - val_precision_27: 0.0000e+00 - lr: 0.0236\n",
      "Epoch 110/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0182 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0059 - accuracy: 0.5298 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9520 - accuracy: 0.5850 - recall_26: 0.0012 - recall_27: 0.0000e+00 - precision_26: 0.2000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9434 - accuracy: 0.5937 - recall_26: 0.0025 - recall_27: 0.0016 - precision_26: 0.1579 - precision_27: 0.4000       - ETA: 0s - loss: 0.9421 - accuracy: 0.5956 - recall_26: 0.0020 - recall_27: 0.0013 - precision_26: 0.1364 - precision_27: 0.25 - ETA: 0s - loss: 0.9237 - accuracy: 0.6119 - recall_26: 0.0023 - recall_27: 0.0010 - precision_26: 0.1739 - precision_27: 0.25 - ETA: 0s - loss: 0.9427 - accuracy: 0.5945 - recall_26: 0.0019 - recall_27: 8.4674e-04 - precision_26: 0.1739 - precision_27: 0.25 - ETA: 0s - loss: 0.9483 - accuracy: 0.5894 - recall_26: 0.0016 - recall_27: 7.2202e-04 - precision_26: 0.1739 - precision_27: 0.2500\n",
      "Epoch 00110: val_loss did not improve from 1.01648\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9483 - accuracy: 0.5894 - recall_26: 0.0016 - recall_27: 7.2202e-04 - precision_26: 0.1739 - precision_27: 0.2500 - val_loss: 1.0200 - val_accuracy: 0.4971 - val_recall_26: 0.0000e+00 - val_recall_27: 0.0000e+00 - val_precision_26: 0.0000e+00 - val_precision_27: 0.0000e+00 - lr: 0.0236\n",
      "Epoch 111/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0170 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0072 - accuracy: 0.5303 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9672 - accuracy: 0.5698 - recall_26: 0.0014 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9448 - accuracy: 0.5944 - recall_26: 0.0019 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9506 - accuracy: 0.5868 - recall_26: 0.0015 - recall_27: 0.0021 - precision_26: 0.2000 - precision_27: 0.2727       - ETA: 0s - loss: 0.9117 - accuracy: 0.6216 - recall_26: 0.0012 - recall_27: 0.0017 - precision_26: 0.1818 - precision_27: 0.23 - ETA: 0s - loss: 0.9411 - accuracy: 0.5956 - recall_26: 0.0010 - recall_27: 0.0013 - precision_26: 0.1818 - precision_27: 0.21 - ETA: 0s - loss: 0.9470 - accuracy: 0.5905 - recall_26: 8.3752e-04 - recall_27: 0.0011 - precision_26: 0.1818 - precision_27: 0.2143\n",
      "Epoch 00111: val_loss did not improve from 1.01648\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9483 - accuracy: 0.5894 - recall_26: 7.8462e-04 - recall_27: 0.0011 - precision_26: 0.1818 - precision_27: 0.2143 - val_loss: 1.0185 - val_accuracy: 0.4985 - val_recall_26: 0.0102 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4848 - val_precision_27: 0.0000e+00 - lr: 0.0236\n",
      "Epoch 112/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0170 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0062 - accuracy: 0.5303 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9516 - accuracy: 0.5853 - recall_26: 0.0012 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9439 - accuracy: 0.5942 - recall_26: 0.0019 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9498 - accuracy: 0.5868 - recall_26: 0.0029 - recall_27: 0.0021 - precision_26: 0.3077 - precision_27: 0.2500       - ETA: 0s - loss: 0.9282 - accuracy: 0.6073 - recall_26: 0.0026 - recall_27: 0.0018 - precision_26: 0.2667 - precision_27: 0.25 - ETA: 0s - loss: 0.9403 - accuracy: 0.5956 - recall_26: 0.0021 - recall_27: 0.0013 - precision_26: 0.2667 - precision_27: 0.21 - ETA: 0s - loss: 0.9461 - accuracy: 0.5903 - recall_26: 0.0017 - recall_27: 0.0011 - precision_26: 0.2222 - precision_27: 0.2143\n",
      "Epoch 00112: val_loss did not improve from 1.01648\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9474 - accuracy: 0.5892 - recall_26: 0.0016 - recall_27: 0.0011 - precision_26: 0.2222 - precision_27: 0.2143 - val_loss: 1.0178 - val_accuracy: 0.5000 - val_recall_26: 0.0217 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4416 - val_precision_27: 0.0000e+00 - lr: 0.0236\n",
      "Epoch 113/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0168 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0061 - accuracy: 0.5298 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9528 - accuracy: 0.5855 - recall_26: 0.0046 - recall_27: 0.0000e+00 - precision_26: 0.4444 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9448 - accuracy: 0.5942 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2778 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9425 - accuracy: 0.5954 - recall_26: 0.0068 - recall_27: 0.0000e+00 - precision_26: 0.2703 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9120 - accuracy: 0.6212 - recall_26: 0.0074 - recall_27: 0.0000e+00 - precision_26: 0.2791 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9414 - accuracy: 0.5954 - recall_26: 0.0063 - recall_27: 0.0000e+00 - precision_26: 0.2791 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9468 - accuracy: 0.5901 - recall_26: 0.0050 - recall_27: 0.0000e+00 - precision_26: 0.2553 - precision_27: 0.0000e+00\n",
      "Epoch 00113: val_loss did not improve from 1.01648\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9483 - accuracy: 0.5890 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2553 - precision_27: 0.0000e+00 - val_loss: 1.0182 - val_accuracy: 0.4982 - val_recall_26: 0.0096 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4545 - val_precision_27: 0.0000e+00 - lr: 0.0236\n",
      "Epoch 114/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0158 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0057 - accuracy: 0.5298 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9522 - accuracy: 0.5858 - recall_26: 0.0046 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9434 - accuracy: 0.5940 - recall_26: 0.0050 - recall_27: 0.0000e+00 - precision_26: 0.2727 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9421 - accuracy: 0.5960 - recall_26: 0.0061 - recall_27: 0.0000e+00 - precision_26: 0.3103 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9235 - accuracy: 0.6122 - recall_26: 0.0057 - recall_27: 0.0000e+00 - precision_26: 0.3125 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9462 - accuracy: 0.5905 - recall_26: 0.0045 - recall_27: 0.0000e+00 - precision_26: 0.2941 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9477 - accuracy: 0.5894 - recall_26: 0.0039 - recall_27: 0.0000e+00 - precision_26: 0.2703 - precision_27: 0.0000e+00\n",
      "Epoch 00114: val_loss did not improve from 1.01648\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9477 - accuracy: 0.5894 - recall_26: 0.0039 - recall_27: 0.0000e+00 - precision_26: 0.2703 - precision_27: 0.0000e+00 - val_loss: 1.0179 - val_accuracy: 0.4995 - val_recall_26: 0.0197 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4366 - val_precision_27: 0.0000e+00 - lr: 0.0236\n",
      "Epoch 115/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0167 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0071 - accuracy: 0.5298 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9529 - accuracy: 0.5853 - recall_26: 0.0046 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9452 - accuracy: 0.5946 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2941 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9431 - accuracy: 0.5956 - recall_26: 0.0061 - recall_27: 0.0000e+00 - precision_26: 0.2571 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9125 - accuracy: 0.6215 - recall_26: 0.0062 - recall_27: 0.0000e+00 - precision_26: 0.2703 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9418 - accuracy: 0.5956 - recall_26: 0.0052 - recall_27: 0.0000e+00 - precision_26: 0.2703 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9471 - accuracy: 0.5903 - recall_26: 0.0045 - recall_27: 0.0000e+00 - precision_26: 0.2703 - precision_27: 0.0000e+00\n",
      "Epoch 00115: val_loss did not improve from 1.01648\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9485 - accuracy: 0.5892 - recall_26: 0.0039 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+00 - val_loss: 1.0185 - val_accuracy: 0.4985 - val_recall_26: 0.0115 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4737 - val_precision_27: 0.0000e+00 - lr: 0.0236\n",
      "Epoch 116/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0160 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0070 - accuracy: 0.5298 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9526 - accuracy: 0.5855 - recall_26: 0.0035 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9435 - accuracy: 0.5935 - recall_26: 0.0033 - recall_27: 0.0000e+00 - precision_26: 0.2000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9292 - accuracy: 0.6072 - recall_26: 0.0045 - recall_27: 0.0000e+00 - precision_26: 0.2593 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9239 - accuracy: 0.6119 - recall_26: 0.0040 - recall_27: 0.0000e+00 - precision_26: 0.2593 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9426 - accuracy: 0.5945 - recall_26: 0.0034 - recall_27: 0.0000e+00 - precision_26: 0.2593 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9484 - accuracy: 0.5894 - recall_26: 0.0027 - recall_27: 0.0000e+00 - precision_26: 0.2593 - precision_27: 0.0000e+00\n",
      "Epoch 00116: val_loss did not improve from 1.01648\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9484 - accuracy: 0.5894 - recall_26: 0.0027 - recall_27: 0.0000e+00 - precision_26: 0.2593 - precision_27: 0.0000e+00 - val_loss: 1.0187 - val_accuracy: 0.4987 - val_recall_26: 0.0140 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4681 - val_precision_27: 0.0000e+00 - lr: 0.0236\n",
      "Epoch 117/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0168 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0063 - accuracy: 0.5298 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9517 - accuracy: 0.5858 - recall_26: 0.0046 - recall_27: 0.0000e+00 - precision_26: 0.5714 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9440 - accuracy: 0.5946 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.3846 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9414 - accuracy: 0.5957 - recall_26: 0.0054 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9112 - accuracy: 0.6217 - recall_26: 0.0062 - recall_27: 0.0000e+00 - precision_26: 0.3226 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9420 - accuracy: 0.5945 - recall_26: 0.0049 - recall_27: 0.0000e+00 - precision_26: 0.3030 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9476 - accuracy: 0.5892 - recall_26: 0.0039 - recall_27: 0.0000e+00 - precision_26: 0.2778 - precision_27: 0.0000e+00\n",
      "Epoch 00117: val_loss did not improve from 1.01648\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9476 - accuracy: 0.5892 - recall_26: 0.0039 - recall_27: 0.0000e+00 - precision_26: 0.2778 - precision_27: 0.0000e+00 - val_loss: 1.0180 - val_accuracy: 0.5007 - val_recall_26: 0.0274 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4343 - val_precision_27: 0.0000e+00 - lr: 0.0236\n",
      "Epoch 118/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0146 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0050 - accuracy: 0.5298 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9648 - accuracy: 0.5695 - recall_26: 0.0014 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9439 - accuracy: 0.5944 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.3125 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9496 - accuracy: 0.5867 - recall_26: 0.0073 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9111 - accuracy: 0.6216 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.2955 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9408 - accuracy: 0.5957 - recall_26: 0.0068 - recall_27: 0.0000e+00 - precision_26: 0.2955 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9462 - accuracy: 0.5903 - recall_26: 0.0058 - recall_27: 0.0000e+00 - precision_26: 0.2826 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9475 - accuracy: 0.5892 - recall_26: 0.0051 - recall_27: 0.0000e+00 - precision_26: 0.2653 - precision_27: 0.0000e+00\n",
      "Epoch 00118: val_loss did not improve from 1.01648\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 0.018874368071556093.\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9475 - accuracy: 0.5892 - recall_26: 0.0051 - recall_27: 0.0000e+00 - precision_26: 0.2653 - precision_27: 0.0000e+00 - val_loss: 1.0181 - val_accuracy: 0.5008 - val_recall_26: 0.0274 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4433 - val_precision_27: 0.0000e+00 - lr: 0.0236\n",
      "Epoch 119/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0186 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0058 - accuracy: 0.5298 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9656 - accuracy: 0.5695 - recall_26: 0.0014 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9438 - accuracy: 0.5946 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.3571 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9496 - accuracy: 0.5868 - recall_26: 0.0066 - recall_27: 0.0000e+00 - precision_26: 0.3214 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9109 - accuracy: 0.6218 - recall_26: 0.0068 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9400 - accuracy: 0.5959 - recall_26: 0.0058 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9454 - accuracy: 0.5906 - recall_26: 0.0050 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+00\n",
      "Epoch 00119: val_loss did not improve from 1.01648\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9467 - accuracy: 0.5894 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+00 - val_loss: 1.0168 - val_accuracy: 0.5015 - val_recall_26: 0.0382 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4196 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 120/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0164 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0057 - accuracy: 0.5293 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9656 - accuracy: 0.5689 - recall_26: 0.0028 - recall_27: 0.0000e+00 - precision_26: 0.2222 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9435 - accuracy: 0.5942 - recall_26: 0.0056 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9495 - accuracy: 0.5865 - recall_26: 0.0080 - recall_27: 0.0000e+00 - precision_26: 0.2973 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9107 - accuracy: 0.6217 - recall_26: 0.0099 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9397 - accuracy: 0.5957 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.3137 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9450 - accuracy: 0.5903 - recall_26: 0.0076 - recall_27: 0.0000e+00 - precision_26: 0.3036 - precision_27: 0.0000e+00\n",
      "Epoch 00120: val_loss improved from 1.01648 to 1.01605, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.9465 - accuracy: 0.5892 - recall_26: 0.0067 - recall_27: 0.0000e+00 - precision_26: 0.2881 - precision_27: 0.0000e+00 - val_loss: 1.0160 - val_accuracy: 0.5021 - val_recall_26: 0.0427 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4187 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 121/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0181 - accuracy: 0.5279 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0062 - accuracy: 0.5293 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9518 - accuracy: 0.5853 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.3750 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9443 - accuracy: 0.5942 - recall_26: 0.0066 - recall_27: 0.0000e+00 - precision_26: 0.2917 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9416 - accuracy: 0.5956 - recall_26: 0.0095 - recall_27: 0.0000e+00 - precision_26: 0.3043 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9232 - accuracy: 0.6119 - recall_26: 0.0091 - recall_27: 0.0000e+00 - precision_26: 0.3137 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9419 - accuracy: 0.5945 - recall_26: 0.0082 - recall_27: 0.0000e+00 - precision_26: 0.3036 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9473 - accuracy: 0.5892 - recall_26: 0.0067 - recall_27: 0.0000e+00 - precision_26: 0.2881 - precision_27: 0.0000e+00\n",
      "Epoch 00121: val_loss did not improve from 1.01605\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9473 - accuracy: 0.5892 - recall_26: 0.0067 - recall_27: 0.0000e+00 - precision_26: 0.2881 - precision_27: 0.0000e+00 - val_loss: 1.0163 - val_accuracy: 0.5007 - val_recall_26: 0.0299 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4273 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 122/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0139 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0056 - accuracy: 0.5298 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9513 - accuracy: 0.5855 - recall_26: 0.0058 - recall_27: 0.0000e+00 - precision_26: 0.4167 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9436 - accuracy: 0.5944 - recall_26: 0.0056 - recall_27: 0.0000e+00 - precision_26: 0.3158 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9413 - accuracy: 0.5956 - recall_26: 0.0068 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9228 - accuracy: 0.6120 - recall_26: 0.0068 - recall_27: 0.0000e+00 - precision_26: 0.3158 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9413 - accuracy: 0.5946 - recall_26: 0.0063 - recall_27: 0.0000e+00 - precision_26: 0.3095 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9469 - accuracy: 0.5893 - recall_26: 0.0051 - recall_27: 0.0000e+00 - precision_26: 0.2889 - precision_27: 0.0000e+00\n",
      "Epoch 00122: val_loss did not improve from 1.01605\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9469 - accuracy: 0.5893 - recall_26: 0.0051 - recall_27: 0.0000e+00 - precision_26: 0.2889 - precision_27: 0.0000e+00 - val_loss: 1.0168 - val_accuracy: 0.5007 - val_recall_26: 0.0306 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4248 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 123/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0158 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0056 - accuracy: 0.5298 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9651 - accuracy: 0.5692 - recall_26: 0.0014 - recall_27: 0.0000e+00 - precision_26: 0.2000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9439 - accuracy: 0.5944 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.3125 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9499 - accuracy: 0.5867 - recall_26: 0.0073 - recall_27: 0.0000e+00 - precision_26: 0.3125 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9281 - accuracy: 0.6070 - recall_26: 0.0071 - recall_27: 0.0000e+00 - precision_26: 0.2821 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9398 - accuracy: 0.5954 - recall_26: 0.0058 - recall_27: 0.0000e+00 - precision_26: 0.2683 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9451 - accuracy: 0.5901 - recall_26: 0.0054 - recall_27: 0.0000e+00 - precision_26: 0.2667 - precision_27: 0.0000e+00\n",
      "Epoch 00123: val_loss did not improve from 1.01605\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9466 - accuracy: 0.5891 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+00 - val_loss: 1.0163 - val_accuracy: 0.5011 - val_recall_26: 0.0357 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4148 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 124/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0160 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0055 - accuracy: 0.5293 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9653 - accuracy: 0.5692 - recall_26: 0.0042 - recall_27: 0.0000e+00 - precision_26: 0.2727 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9474 - accuracy: 0.5911 - recall_26: 0.0052 - recall_27: 0.0000e+00 - precision_26: 0.3125 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9500 - accuracy: 0.5864 - recall_26: 0.0080 - recall_27: 0.0000e+00 - precision_26: 0.2750 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9113 - accuracy: 0.6214 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.2941 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9402 - accuracy: 0.5955 - recall_26: 0.0079 - recall_27: 0.0000e+00 - precision_26: 0.2885 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9455 - accuracy: 0.5902 - recall_26: 0.0071 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+00\n",
      "Epoch 00124: val_loss improved from 1.01605 to 1.01603, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.9472 - accuracy: 0.5891 - recall_26: 0.0063 - recall_27: 0.0000e+00 - precision_26: 0.2712 - precision_27: 0.0000e+00 - val_loss: 1.0160 - val_accuracy: 0.5015 - val_recall_26: 0.0338 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4173 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 125/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0160 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0062 - accuracy: 0.5298 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9660 - accuracy: 0.5692 - recall_26: 0.0014 - recall_27: 0.0000e+00 - precision_26: 0.1667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9443 - accuracy: 0.5946 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9500 - accuracy: 0.5867 - recall_26: 0.0066 - recall_27: 0.0000e+00 - precision_26: 0.3103 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9109 - accuracy: 0.6217 - recall_26: 0.0062 - recall_27: 0.0000e+00 - precision_26: 0.3125 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9412 - accuracy: 0.5947 - recall_26: 0.0053 - recall_27: 0.0000e+00 - precision_26: 0.3056 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9454 - accuracy: 0.5905 - recall_26: 0.0046 - recall_27: 0.0000e+00 - precision_26: 0.2821 - precision_27: 0.0000e+00\n",
      "Epoch 00125: val_loss did not improve from 1.01603\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9468 - accuracy: 0.5894 - recall_26: 0.0043 - recall_27: 0.0000e+00 - precision_26: 0.2821 - precision_27: 0.0000e+00 - val_loss: 1.0169 - val_accuracy: 0.5008 - val_recall_26: 0.0312 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4153 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 126/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0158 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0068 - accuracy: 0.5298 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9663 - accuracy: 0.5692 - recall_26: 0.0014 - recall_27: 0.0000e+00 - precision_26: 0.2000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9446 - accuracy: 0.5946 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9505 - accuracy: 0.5867 - recall_26: 0.0058 - recall_27: 0.0000e+00 - precision_26: 0.2963 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9115 - accuracy: 0.6216 - recall_26: 0.0056 - recall_27: 0.0000e+00 - precision_26: 0.2903 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9403 - accuracy: 0.5957 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2903 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9456 - accuracy: 0.5904 - recall_26: 0.0045 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+00\n",
      "Epoch 00126: val_loss did not improve from 1.01603\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9472 - accuracy: 0.5893 - recall_26: 0.0039 - recall_27: 0.0000e+00 - precision_26: 0.2632 - precision_27: 0.0000e+00 - val_loss: 1.0166 - val_accuracy: 0.5003 - val_recall_26: 0.0274 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4216 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 127/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0166 - accuracy: 0.5264 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0064 - accuracy: 0.5293 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9657 - accuracy: 0.5689 - recall_26: 0.0014 - recall_27: 0.0000e+00 - precision_26: 0.1667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9474 - accuracy: 0.5911 - recall_26: 0.0041 - recall_27: 0.0000e+00 - precision_26: 0.3636 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9428 - accuracy: 0.5935 - recall_26: 0.0050 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9283 - accuracy: 0.6072 - recall_26: 0.0071 - recall_27: 0.0000e+00 - precision_26: 0.3056 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9230 - accuracy: 0.6119 - recall_26: 0.0063 - recall_27: 0.0000e+00 - precision_26: 0.3056 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9456 - accuracy: 0.5903 - recall_26: 0.0054 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9472 - accuracy: 0.5892 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2791 - precision_27: 0.0000e+00\n",
      "Epoch 00127: val_loss did not improve from 1.01603\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9472 - accuracy: 0.5892 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2791 - precision_27: 0.0000e+00 - val_loss: 1.0165 - val_accuracy: 0.5003 - val_recall_26: 0.0248 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4239 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 128/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0125 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0048 - accuracy: 0.5298 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9507 - accuracy: 0.5853 - recall_26: 0.0035 - recall_27: 0.0000e+00 - precision_26: 0.3750 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9422 - accuracy: 0.5935 - recall_26: 0.0050 - recall_27: 0.0000e+00 - precision_26: 0.2400 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9409 - accuracy: 0.5956 - recall_26: 0.0068 - recall_27: 0.0000e+00 - precision_26: 0.2941 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9107 - accuracy: 0.6214 - recall_26: 0.0068 - recall_27: 0.0000e+00 - precision_26: 0.2895 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9412 - accuracy: 0.5944 - recall_26: 0.0058 - recall_27: 0.0000e+00 - precision_26: 0.2791 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9454 - accuracy: 0.5903 - recall_26: 0.0050 - recall_27: 0.0000e+00 - precision_26: 0.2609 - precision_27: 0.0000e+00\n",
      "Epoch 00128: val_loss improved from 1.01603 to 1.01573, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.9467 - accuracy: 0.5891 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2609 - precision_27: 0.0000e+00 - val_loss: 1.0157 - val_accuracy: 0.5003 - val_recall_26: 0.0280 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4074 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 129/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0156 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9751 - accuracy: 0.5590 - recall_26: 0.0033 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9507 - accuracy: 0.5853 - recall_26: 0.0046 - recall_27: 0.0000e+00 - precision_26: 0.3636 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9418 - accuracy: 0.5934 - recall_26: 0.0050 - recall_27: 0.0000e+00 - precision_26: 0.2222 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9407 - accuracy: 0.5956 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.2973 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9102 - accuracy: 0.6215 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.3095 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9409 - accuracy: 0.5943 - recall_26: 0.0068 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9452 - accuracy: 0.5902 - recall_26: 0.0059 - recall_27: 0.0000e+00 - precision_26: 0.2692 - precision_27: 0.0000e+00\n",
      "Epoch 00129: val_loss improved from 1.01573 to 1.01502, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.9464 - accuracy: 0.5891 - recall_26: 0.0055 - recall_27: 0.0000e+00 - precision_26: 0.2692 - precision_27: 0.0000e+00 - val_loss: 1.0150 - val_accuracy: 0.5010 - val_recall_26: 0.0344 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4091 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 130/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0150 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0053 - accuracy: 0.5293 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9649 - accuracy: 0.5692 - recall_26: 0.0042 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9435 - accuracy: 0.5944 - recall_26: 0.0066 - recall_27: 0.0000e+00 - precision_26: 0.3182 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9497 - accuracy: 0.5865 - recall_26: 0.0088 - recall_27: 0.0000e+00 - precision_26: 0.3077 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9282 - accuracy: 0.6072 - recall_26: 0.0097 - recall_27: 0.0000e+00 - precision_26: 0.3125 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9229 - accuracy: 0.6118 - recall_26: 0.0085 - recall_27: 0.0000e+00 - precision_26: 0.3061 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9415 - accuracy: 0.5944 - recall_26: 0.0078 - recall_27: 0.0000e+00 - precision_26: 0.2963 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9470 - accuracy: 0.5891 - recall_26: 0.0063 - recall_27: 0.0000e+00 - precision_26: 0.2807 - precision_27: 0.0000e+00\n",
      "Epoch 00130: val_loss did not improve from 1.01502\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9470 - accuracy: 0.5891 - recall_26: 0.0063 - recall_27: 0.0000e+00 - precision_26: 0.2807 - precision_27: 0.0000e+00 - val_loss: 1.0150 - val_accuracy: 0.5002 - val_recall_26: 0.0274 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4057 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 131/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0136 - accuracy: 0.5264 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0041 - accuracy: 0.5293 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9504 - accuracy: 0.5855 - recall_26: 0.0058 - recall_27: 0.0000e+00 - precision_26: 0.4167 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9430 - accuracy: 0.5944 - recall_26: 0.0056 - recall_27: 0.0000e+00 - precision_26: 0.3158 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9410 - accuracy: 0.5957 - recall_26: 0.0082 - recall_27: 0.0000e+00 - precision_26: 0.3158 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9107 - accuracy: 0.6216 - recall_26: 0.0087 - recall_27: 0.0000e+00 - precision_26: 0.3256 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9411 - accuracy: 0.5946 - recall_26: 0.0073 - recall_27: 0.0000e+00 - precision_26: 0.3191 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9454 - accuracy: 0.5904 - recall_26: 0.0063 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+00\n",
      "Epoch 00131: val_loss improved from 1.01502 to 1.01433, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.9467 - accuracy: 0.5893 - recall_26: 0.0059 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+00 - val_loss: 1.0143 - val_accuracy: 0.5000 - val_recall_26: 0.0268 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4038 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 132/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0130 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0054 - accuracy: 0.5293 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9649 - accuracy: 0.5689 - recall_26: 0.0014 - recall_27: 0.0000e+00 - precision_26: 0.1667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9433 - accuracy: 0.5942 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2941 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9413 - accuracy: 0.5954 - recall_26: 0.0068 - recall_27: 0.0000e+00 - precision_26: 0.2778 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9228 - accuracy: 0.6118 - recall_26: 0.0068 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9413 - accuracy: 0.5943 - recall_26: 0.0063 - recall_27: 0.0000e+00 - precision_26: 0.2826 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9471 - accuracy: 0.5891 - recall_26: 0.0051 - recall_27: 0.0000e+00 - precision_26: 0.2653 - precision_27: 0.0000e+00\n",
      "Epoch 00132: val_loss did not improve from 1.01433\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9471 - accuracy: 0.5891 - recall_26: 0.0051 - recall_27: 0.0000e+00 - precision_26: 0.2653 - precision_27: 0.0000e+00 - val_loss: 1.0155 - val_accuracy: 0.5003 - val_recall_26: 0.0242 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4318 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 133/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0120 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0052 - accuracy: 0.5298 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9646 - accuracy: 0.5695 - recall_26: 0.0014 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9462 - accuracy: 0.5913 - recall_26: 0.0031 - recall_27: 0.0000e+00 - precision_26: 0.3750 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9420 - accuracy: 0.5935 - recall_26: 0.0041 - recall_27: 0.0000e+00 - precision_26: 0.2174 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9282 - accuracy: 0.6070 - recall_26: 0.0064 - recall_27: 0.0000e+00 - precision_26: 0.2778 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9229 - accuracy: 0.6118 - recall_26: 0.0057 - recall_27: 0.0000e+00 - precision_26: 0.2778 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9455 - accuracy: 0.5903 - recall_26: 0.0049 - recall_27: 0.0000e+00 - precision_26: 0.2821 - precision_27: 0.0000e+00\n",
      "Epoch 00133: val_loss did not improve from 1.01433\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9470 - accuracy: 0.5892 - recall_26: 0.0043 - recall_27: 0.0000e+00 - precision_26: 0.2619 - precision_27: 0.0000e+00 - val_loss: 1.0145 - val_accuracy: 0.5003 - val_recall_26: 0.0255 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4255 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 134/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0121 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0052 - accuracy: 0.5303 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.4286 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9650 - accuracy: 0.5695 - recall_26: 0.0042 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9433 - accuracy: 0.5946 - recall_26: 0.0066 - recall_27: 0.0000e+00 - precision_26: 0.3500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9495 - accuracy: 0.5868 - recall_26: 0.0088 - recall_27: 0.0000e+00 - precision_26: 0.3429 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9109 - accuracy: 0.6215 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.3095 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9401 - accuracy: 0.5956 - recall_26: 0.0068 - recall_27: 0.0000e+00 - precision_26: 0.3023 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9456 - accuracy: 0.5903 - recall_26: 0.0063 - recall_27: 0.0000e+00 - precision_26: 0.2979 - precision_27: 0.0000e+00\n",
      "Epoch 00134: val_loss did not improve from 1.01433\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9472 - accuracy: 0.5892 - recall_26: 0.0055 - recall_27: 0.0000e+00 - precision_26: 0.2800 - precision_27: 0.0000e+00 - val_loss: 1.0149 - val_accuracy: 0.5002 - val_recall_26: 0.0242 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4176 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 135/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0120 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0052 - accuracy: 0.5298 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9647 - accuracy: 0.5692 - recall_26: 0.0014 - recall_27: 0.0000e+00 - precision_26: 0.2000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9428 - accuracy: 0.5944 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.3125 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9491 - accuracy: 0.5867 - recall_26: 0.0073 - recall_27: 0.0000e+00 - precision_26: 0.3226 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9105 - accuracy: 0.6215 - recall_26: 0.0068 - recall_27: 0.0000e+00 - precision_26: 0.2973 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9398 - accuracy: 0.5955 - recall_26: 0.0058 - recall_27: 0.0000e+00 - precision_26: 0.2895 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9452 - accuracy: 0.5903 - recall_26: 0.0050 - recall_27: 0.0000e+00 - precision_26: 0.2667 - precision_27: 0.0000e+00\n",
      "Epoch 00135: val_loss did not improve from 1.01433\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9467 - accuracy: 0.5891 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2667 - precision_27: 0.0000e+00 - val_loss: 1.0154 - val_accuracy: 0.5010 - val_recall_26: 0.0318 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4065 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 136/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0134 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0046 - accuracy: 0.5293 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9644 - accuracy: 0.5692 - recall_26: 0.0042 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9464 - accuracy: 0.5913 - recall_26: 0.0062 - recall_27: 0.0000e+00 - precision_26: 0.3750 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9494 - accuracy: 0.5868 - recall_26: 0.0095 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9283 - accuracy: 0.6074 - recall_26: 0.0103 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9402 - accuracy: 0.5958 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.3265 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9455 - accuracy: 0.5905 - recall_26: 0.0076 - recall_27: 0.0000e+00 - precision_26: 0.3208 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9472 - accuracy: 0.5894 - recall_26: 0.0067 - recall_27: 0.0000e+00 - precision_26: 0.3036 - precision_27: 0.0000e+00\n",
      "Epoch 00136: val_loss did not improve from 1.01433\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9472 - accuracy: 0.5894 - recall_26: 0.0067 - recall_27: 0.0000e+00 - precision_26: 0.3036 - precision_27: 0.0000e+00 - val_loss: 1.0156 - val_accuracy: 0.5003 - val_recall_26: 0.0280 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4151 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 137/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0129 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0052 - accuracy: 0.5298 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9504 - accuracy: 0.5855 - recall_26: 0.0058 - recall_27: 0.0000e+00 - precision_26: 0.4167 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9433 - accuracy: 0.5944 - recall_26: 0.0056 - recall_27: 0.0000e+00 - precision_26: 0.3158 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9415 - accuracy: 0.5956 - recall_26: 0.0068 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9109 - accuracy: 0.6216 - recall_26: 0.0074 - recall_27: 0.0000e+00 - precision_26: 0.3158 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9417 - accuracy: 0.5945 - recall_26: 0.0063 - recall_27: 0.0000e+00 - precision_26: 0.3023 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9460 - accuracy: 0.5903 - recall_26: 0.0054 - recall_27: 0.0000e+00 - precision_26: 0.2826 - precision_27: 0.0000e+00\n",
      "Epoch 00137: val_loss did not improve from 1.01433\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9475 - accuracy: 0.5892 - recall_26: 0.0051 - recall_27: 0.0000e+00 - precision_26: 0.2826 - precision_27: 0.0000e+00 - val_loss: 1.0149 - val_accuracy: 0.5003 - val_recall_26: 0.0229 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4444 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 138/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0131 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0058 - accuracy: 0.5298 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9652 - accuracy: 0.5695 - recall_26: 0.0014 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9433 - accuracy: 0.5946 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.3846 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9496 - accuracy: 0.5868 - recall_26: 0.0066 - recall_27: 0.0000e+00 - precision_26: 0.3462 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9110 - accuracy: 0.6218 - recall_26: 0.0068 - recall_27: 0.0000e+00 - precision_26: 0.3548 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9401 - accuracy: 0.5959 - recall_26: 0.0058 - recall_27: 0.0000e+00 - precision_26: 0.3548 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9457 - accuracy: 0.5905 - recall_26: 0.0049 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00\n",
      "Epoch 00138: val_loss did not improve from 1.01433\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9474 - accuracy: 0.5894 - recall_26: 0.0043 - recall_27: 0.0000e+00 - precision_26: 0.3056 - precision_27: 0.0000e+00 - val_loss: 1.0152 - val_accuracy: 0.4998 - val_recall_26: 0.0191 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4615 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 139/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0118 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0050 - accuracy: 0.5288 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9499 - accuracy: 0.5853 - recall_26: 0.0035 - recall_27: 0.0000e+00 - precision_26: 0.4286 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9429 - accuracy: 0.5944 - recall_26: 0.0037 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9494 - accuracy: 0.5865 - recall_26: 0.0051 - recall_27: 0.0000e+00 - precision_26: 0.2917 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9107 - accuracy: 0.6216 - recall_26: 0.0056 - recall_27: 0.0000e+00 - precision_26: 0.3103 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9398 - accuracy: 0.5956 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2903 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9453 - accuracy: 0.5903 - recall_26: 0.0042 - recall_27: 0.0000e+00 - precision_26: 0.2632 - precision_27: 0.0000e+00\n",
      "Epoch 00139: val_loss did not improve from 1.01433\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9469 - accuracy: 0.5892 - recall_26: 0.0039 - recall_27: 0.0000e+00 - precision_26: 0.2632 - precision_27: 0.0000e+00 - val_loss: 1.0144 - val_accuracy: 0.5000 - val_recall_26: 0.0261 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4059 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 140/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0127 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0051 - accuracy: 0.5298 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9645 - accuracy: 0.5695 - recall_26: 0.0028 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9460 - accuracy: 0.5915 - recall_26: 0.0052 - recall_27: 0.0000e+00 - precision_26: 0.4167 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9420 - accuracy: 0.5940 - recall_26: 0.0066 - recall_27: 0.0000e+00 - precision_26: 0.2963 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9283 - accuracy: 0.6076 - recall_26: 0.0090 - recall_27: 0.0000e+00 - precision_26: 0.3500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9401 - accuracy: 0.5959 - recall_26: 0.0073 - recall_27: 0.0000e+00 - precision_26: 0.3415 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9458 - accuracy: 0.5906 - recall_26: 0.0063 - recall_27: 0.0000e+00 - precision_26: 0.3125 - precision_27: 0.0000e+00\n",
      "Epoch 00140: val_loss did not improve from 1.01433\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9473 - accuracy: 0.5894 - recall_26: 0.0059 - recall_27: 0.0000e+00 - precision_26: 0.3125 - precision_27: 0.0000e+00 - val_loss: 1.0149 - val_accuracy: 0.5007 - val_recall_26: 0.0242 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4368 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 141/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0102 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0042 - accuracy: 0.5298 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9638 - accuracy: 0.5692 - recall_26: 0.0014 - recall_27: 0.0000e+00 - precision_26: 0.1667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9423 - accuracy: 0.5944 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.3125 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9406 - accuracy: 0.5957 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.3143 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9105 - accuracy: 0.6216 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.3250 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9396 - accuracy: 0.5957 - recall_26: 0.0068 - recall_27: 0.0000e+00 - precision_26: 0.3171 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9453 - accuracy: 0.5903 - recall_26: 0.0059 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+00\n",
      "Epoch 00141: val_loss improved from 1.01433 to 1.01397, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.9468 - accuracy: 0.5892 - recall_26: 0.0055 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+00 - val_loss: 1.0140 - val_accuracy: 0.5000 - val_recall_26: 0.0261 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4059 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 142/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0106 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9751 - accuracy: 0.5590 - recall_26: 0.0050 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9455 - accuracy: 0.5911 - recall_26: 0.0052 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9415 - accuracy: 0.5934 - recall_26: 0.0058 - recall_27: 0.0000e+00 - precision_26: 0.2333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9408 - accuracy: 0.5957 - recall_26: 0.0089 - recall_27: 0.0000e+00 - precision_26: 0.3095 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9107 - accuracy: 0.6215 - recall_26: 0.0087 - recall_27: 0.0000e+00 - precision_26: 0.3043 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9413 - accuracy: 0.5943 - recall_26: 0.0073 - recall_27: 0.0000e+00 - precision_26: 0.2778 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9456 - accuracy: 0.5902 - recall_26: 0.0063 - recall_27: 0.0000e+00 - precision_26: 0.2632 - precision_27: 0.0000e+00\n",
      "Epoch 00142: val_loss improved from 1.01397 to 1.01341, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.9470 - accuracy: 0.5891 - recall_26: 0.0059 - recall_27: 0.0000e+00 - precision_26: 0.2632 - precision_27: 0.0000e+00 - val_loss: 1.0134 - val_accuracy: 0.5003 - val_recall_26: 0.0274 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4135 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 143/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0106 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0040 - accuracy: 0.5298 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9490 - accuracy: 0.5858 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.4615 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9422 - accuracy: 0.5948 - recall_26: 0.0066 - recall_27: 0.0000e+00 - precision_26: 0.3500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9407 - accuracy: 0.5962 - recall_26: 0.0102 - recall_27: 0.0000e+00 - precision_26: 0.3488 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9105 - accuracy: 0.6219 - recall_26: 0.0099 - recall_27: 0.0000e+00 - precision_26: 0.3404 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9409 - accuracy: 0.5946 - recall_26: 0.0082 - recall_27: 0.0000e+00 - precision_26: 0.3091 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9468 - accuracy: 0.5893 - recall_26: 0.0067 - recall_27: 0.0000e+00 - precision_26: 0.2881 - precision_27: 0.0000e+00\n",
      "Epoch 00143: val_loss improved from 1.01341 to 1.01339, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.9468 - accuracy: 0.5893 - recall_26: 0.0067 - recall_27: 0.0000e+00 - precision_26: 0.2881 - precision_27: 0.0000e+00 - val_loss: 1.0134 - val_accuracy: 0.5007 - val_recall_26: 0.0293 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4000 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 144/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0106 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0043 - accuracy: 0.5293 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.2000 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9641 - accuracy: 0.5695 - recall_26: 0.0042 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9426 - accuracy: 0.5948 - recall_26: 0.0066 - recall_27: 0.0000e+00 - precision_26: 0.3500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9489 - accuracy: 0.5868 - recall_26: 0.0088 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9104 - accuracy: 0.6215 - recall_26: 0.0087 - recall_27: 0.0000e+00 - precision_26: 0.3111 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9395 - accuracy: 0.5956 - recall_26: 0.0073 - recall_27: 0.0000e+00 - precision_26: 0.3043 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9450 - accuracy: 0.5902 - recall_26: 0.0063 - recall_27: 0.0000e+00 - precision_26: 0.2679 - precision_27: 0.0000e+00\n",
      "Epoch 00144: val_loss improved from 1.01339 to 1.01316, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.9466 - accuracy: 0.5891 - recall_26: 0.0063 - recall_27: 0.0000e+00 - precision_26: 0.2807 - precision_27: 0.0000e+00 - val_loss: 1.0132 - val_accuracy: 0.5010 - val_recall_26: 0.0344 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4060 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 145/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0089 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0039 - accuracy: 0.5303 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.4286 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9628 - accuracy: 0.5698 - recall_26: 0.0056 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9446 - accuracy: 0.5917 - recall_26: 0.0072 - recall_27: 0.0000e+00 - precision_26: 0.4375 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9487 - accuracy: 0.5870 - recall_26: 0.0102 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9277 - accuracy: 0.6074 - recall_26: 0.0109 - recall_27: 0.0000e+00 - precision_26: 0.3269 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9224 - accuracy: 0.6121 - recall_26: 0.0102 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9410 - accuracy: 0.5946 - recall_26: 0.0092 - recall_27: 0.0000e+00 - precision_26: 0.3220 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9454 - accuracy: 0.5904 - recall_26: 0.0080 - recall_27: 0.0000e+00 - precision_26: 0.3065 - precision_27: 0.0000e+00\n",
      "Epoch 00145: val_loss did not improve from 1.01316\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9467 - accuracy: 0.5893 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.3065 - precision_27: 0.0000e+00 - val_loss: 1.0139 - val_accuracy: 0.5010 - val_recall_26: 0.0331 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4094 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 146/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0116 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9752 - accuracy: 0.5590 - recall_26: 0.0017 - recall_27: 0.0000e+00 - precision_26: 0.2000 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9496 - accuracy: 0.5853 - recall_26: 0.0035 - recall_27: 0.0000e+00 - precision_26: 0.3750 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9418 - accuracy: 0.5932 - recall_26: 0.0033 - recall_27: 0.0000e+00 - precision_26: 0.1739 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9410 - accuracy: 0.5954 - recall_26: 0.0054 - recall_27: 0.0000e+00 - precision_26: 0.2581 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9108 - accuracy: 0.6214 - recall_26: 0.0056 - recall_27: 0.0000e+00 - precision_26: 0.2727 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9411 - accuracy: 0.5944 - recall_26: 0.0049 - recall_27: 0.0000e+00 - precision_26: 0.2703 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9455 - accuracy: 0.5903 - recall_26: 0.0042 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+00\n",
      "Epoch 00146: val_loss did not improve from 1.01316\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9468 - accuracy: 0.5891 - recall_26: 0.0039 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+00 - val_loss: 1.0144 - val_accuracy: 0.5002 - val_recall_26: 0.0274 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4057 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 147/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0131 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0059 - accuracy: 0.5298 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9648 - accuracy: 0.5692 - recall_26: 0.0014 - recall_27: 0.0000e+00 - precision_26: 0.2000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9458 - accuracy: 0.5913 - recall_26: 0.0041 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9492 - accuracy: 0.5867 - recall_26: 0.0066 - recall_27: 0.0000e+00 - precision_26: 0.3214 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9279 - accuracy: 0.6072 - recall_26: 0.0064 - recall_27: 0.0000e+00 - precision_26: 0.3030 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9397 - accuracy: 0.5958 - recall_26: 0.0063 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9454 - accuracy: 0.5907 - recall_26: 0.0063 - recall_27: 0.0000e+00 - precision_26: 0.3500 - precision_27: 0.0000e+00\n",
      "Epoch 00147: val_loss did not improve from 1.01316\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9471 - accuracy: 0.5895 - recall_26: 0.0055 - recall_27: 0.0000e+00 - precision_26: 0.3256 - precision_27: 0.0000e+00 - val_loss: 1.0142 - val_accuracy: 0.5010 - val_recall_26: 0.0312 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4083 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 148/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0126 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9751 - accuracy: 0.5594 - recall_26: 0.0033 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9491 - accuracy: 0.5855 - recall_26: 0.0046 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9413 - accuracy: 0.5935 - recall_26: 0.0050 - recall_27: 0.0000e+00 - precision_26: 0.2308 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9406 - accuracy: 0.5954 - recall_26: 0.0068 - recall_27: 0.0000e+00 - precision_26: 0.2778 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9106 - accuracy: 0.6212 - recall_26: 0.0068 - recall_27: 0.0000e+00 - precision_26: 0.2750 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9411 - accuracy: 0.5944 - recall_26: 0.0058 - recall_27: 0.0000e+00 - precision_26: 0.2727 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9470 - accuracy: 0.5892 - recall_26: 0.0051 - recall_27: 0.0000e+00 - precision_26: 0.2708 - precision_27: 0.0000e+00\n",
      "Epoch 00148: val_loss did not improve from 1.01316\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9470 - accuracy: 0.5892 - recall_26: 0.0051 - recall_27: 0.0000e+00 - precision_26: 0.2708 - precision_27: 0.0000e+00 - val_loss: 1.0144 - val_accuracy: 0.5005 - val_recall_26: 0.0274 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4175 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 149/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0100 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0049 - accuracy: 0.5293 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.2000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9646 - accuracy: 0.5692 - recall_26: 0.0028 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9451 - accuracy: 0.5911 - recall_26: 0.0041 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9489 - accuracy: 0.5865 - recall_26: 0.0073 - recall_27: 0.0000e+00 - precision_26: 0.3125 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9279 - accuracy: 0.6072 - recall_26: 0.0077 - recall_27: 0.0000e+00 - precision_26: 0.3077 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9397 - accuracy: 0.5957 - recall_26: 0.0068 - recall_27: 0.0000e+00 - precision_26: 0.3250 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9450 - accuracy: 0.5907 - recall_26: 0.0076 - recall_27: 0.0000e+00 - precision_26: 0.3778 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9468 - accuracy: 0.5896 - recall_26: 0.0067 - recall_27: 0.0000e+00 - precision_26: 0.3542 - precision_27: 0.0000e+00\n",
      "Epoch 00149: val_loss did not improve from 1.01316\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9468 - accuracy: 0.5896 - recall_26: 0.0067 - recall_27: 0.0000e+00 - precision_26: 0.3542 - precision_27: 0.0000e+00 - val_loss: 1.0140 - val_accuracy: 0.5013 - val_recall_26: 0.0312 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4153 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 150/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0112 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0046 - accuracy: 0.5293 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.2000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9488 - accuracy: 0.5858 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.4615 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9408 - accuracy: 0.5940 - recall_26: 0.0066 - recall_27: 0.0000e+00 - precision_26: 0.3077 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9403 - accuracy: 0.5966 - recall_26: 0.0109 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9101 - accuracy: 0.6223 - recall_26: 0.0105 - recall_27: 0.0000e+00 - precision_26: 0.3778 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9406 - accuracy: 0.5951 - recall_26: 0.0087 - recall_27: 0.0000e+00 - precision_26: 0.3529 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9451 - accuracy: 0.5911 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.3571 - precision_27: 0.0000e+00\n",
      "Epoch 00150: val_loss improved from 1.01316 to 1.01286, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.9466 - accuracy: 0.5899 - recall_26: 0.0082 - recall_27: 0.0000e+00 - precision_26: 0.3621 - precision_27: 0.0000e+00 - val_loss: 1.0129 - val_accuracy: 0.5003 - val_recall_26: 0.0261 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4184 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 151/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0112 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9758 - accuracy: 0.5598 - recall_26: 0.0067 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9494 - accuracy: 0.5863 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.5333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9422 - accuracy: 0.5951 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.4286 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9484 - accuracy: 0.5874 - recall_26: 0.0109 - recall_27: 0.0000e+00 - precision_26: 0.3947 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9280 - accuracy: 0.6079 - recall_26: 0.0109 - recall_27: 0.0000e+00 - precision_26: 0.3778 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9400 - accuracy: 0.5962 - recall_26: 0.0089 - recall_27: 0.0000e+00 - precision_26: 0.3696 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9456 - accuracy: 0.5908 - recall_26: 0.0080 - recall_27: 0.0000e+00 - precision_26: 0.3600 - precision_27: 0.0000e+00\n",
      "Epoch 00151: val_loss did not improve from 1.01286\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9471 - accuracy: 0.5897 - recall_26: 0.0071 - recall_27: 0.0000e+00 - precision_26: 0.3396 - precision_27: 0.0000e+00 - val_loss: 1.0137 - val_accuracy: 0.5003 - val_recall_26: 0.0223 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4605 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 152/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0105 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0046 - accuracy: 0.5293 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9648 - accuracy: 0.5695 - recall_26: 0.0028 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9426 - accuracy: 0.5949 - recall_26: 0.0056 - recall_27: 0.0000e+00 - precision_26: 0.3750 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9490 - accuracy: 0.5871 - recall_26: 0.0073 - recall_27: 0.0000e+00 - precision_26: 0.3448 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9107 - accuracy: 0.6217 - recall_26: 0.0068 - recall_27: 0.0000e+00 - precision_26: 0.3143 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9398 - accuracy: 0.5958 - recall_26: 0.0058 - recall_27: 0.0000e+00 - precision_26: 0.3056 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9449 - accuracy: 0.5905 - recall_26: 0.0054 - recall_27: 0.0000e+00 - precision_26: 0.2927 - precision_27: 0.0000e+00\n",
      "Epoch 00152: val_loss did not improve from 1.01286\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9467 - accuracy: 0.5894 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2727 - precision_27: 0.0000e+00 - val_loss: 1.0169 - val_accuracy: 0.5011 - val_recall_26: 0.0338 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4141 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 153/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0089 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0044 - accuracy: 0.5293 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9497 - accuracy: 0.5860 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9429 - accuracy: 0.5949 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.3600 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9417 - accuracy: 0.5961 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.3400 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9113 - accuracy: 0.6218 - recall_26: 0.0112 - recall_27: 0.0000e+00 - precision_26: 0.3396 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9400 - accuracy: 0.5958 - recall_26: 0.0094 - recall_27: 0.0000e+00 - precision_26: 0.3273 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9452 - accuracy: 0.5903 - recall_26: 0.0080 - recall_27: 0.0000e+00 - precision_26: 0.2923 - precision_27: 0.0000e+00\n",
      "Epoch 00153: val_loss did not improve from 1.01286\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9470 - accuracy: 0.5893 - recall_26: 0.0078 - recall_27: 0.0000e+00 - precision_26: 0.3030 - precision_27: 0.0000e+00 - val_loss: 1.0170 - val_accuracy: 0.5008 - val_recall_26: 0.0350 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4104 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 154/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0110 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0052 - accuracy: 0.5293 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9500 - accuracy: 0.5858 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.4667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9430 - accuracy: 0.5946 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.3200 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9416 - accuracy: 0.5958 - recall_26: 0.0102 - recall_27: 0.0000e+00 - precision_26: 0.3125 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9113 - accuracy: 0.6216 - recall_26: 0.0099 - recall_27: 0.0000e+00 - precision_26: 0.3077 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9403 - accuracy: 0.5955 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.2909 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9455 - accuracy: 0.5901 - recall_26: 0.0071 - recall_27: 0.0000e+00 - precision_26: 0.2615 - precision_27: 0.0000e+00\n",
      "Epoch 00154: val_loss did not improve from 1.01286\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9472 - accuracy: 0.5891 - recall_26: 0.0071 - recall_27: 0.0000e+00 - precision_26: 0.2727 - precision_27: 0.0000e+00 - val_loss: 1.0160 - val_accuracy: 0.5013 - val_recall_26: 0.0357 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4211 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 155/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0092 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0043 - accuracy: 0.5293 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9641 - accuracy: 0.5695 - recall_26: 0.0056 - recall_27: 0.0000e+00 - precision_26: 0.3636 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9426 - accuracy: 0.5948 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.3478 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9412 - accuracy: 0.5961 - recall_26: 0.0109 - recall_27: 0.0000e+00 - precision_26: 0.3478 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9225 - accuracy: 0.6121 - recall_26: 0.0097 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9411 - accuracy: 0.5945 - recall_26: 0.0087 - recall_27: 0.0000e+00 - precision_26: 0.3103 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9453 - accuracy: 0.5903 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.2903 - precision_27: 0.0000e+00\n",
      "Epoch 00155: val_loss did not improve from 1.01286\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9469 - accuracy: 0.5893 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.3016 - precision_27: 0.0000e+00 - val_loss: 1.0152 - val_accuracy: 0.5011 - val_recall_26: 0.0357 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4148 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 156/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0131 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0053 - accuracy: 0.5298 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9499 - accuracy: 0.5858 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.4615 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9422 - accuracy: 0.5940 - recall_26: 0.0066 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9415 - accuracy: 0.5960 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.3056 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9111 - accuracy: 0.6217 - recall_26: 0.0074 - recall_27: 0.0000e+00 - precision_26: 0.3077 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9400 - accuracy: 0.5958 - recall_26: 0.0063 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9451 - accuracy: 0.5905 - recall_26: 0.0058 - recall_27: 0.0000e+00 - precision_26: 0.2889 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9469 - accuracy: 0.5894 - recall_26: 0.0055 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+00\n",
      "Epoch 00156: val_loss did not improve from 1.01286\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9469 - accuracy: 0.5894 - recall_26: 0.0055 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+00 - val_loss: 1.0142 - val_accuracy: 0.5011 - val_recall_26: 0.0350 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4135 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 157/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0121 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0056 - accuracy: 0.5293 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9505 - accuracy: 0.5860 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9435 - accuracy: 0.5949 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.3478 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9502 - accuracy: 0.5871 - recall_26: 0.0088 - recall_27: 0.0000e+00 - precision_26: 0.3158 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9292 - accuracy: 0.6074 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.2955 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9236 - accuracy: 0.6121 - recall_26: 0.0074 - recall_27: 0.0000e+00 - precision_26: 0.2955 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9458 - accuracy: 0.5904 - recall_26: 0.0063 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9476 - accuracy: 0.5893 - recall_26: 0.0055 - recall_27: 0.0000e+00 - precision_26: 0.2692 - precision_27: 0.0000e+00\n",
      "Epoch 00157: val_loss did not improve from 1.01286\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9476 - accuracy: 0.5893 - recall_26: 0.0055 - recall_27: 0.0000e+00 - precision_26: 0.2692 - precision_27: 0.0000e+00 - val_loss: 1.0165 - val_accuracy: 0.5008 - val_recall_26: 0.0261 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4316 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 158/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0112 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0057 - accuracy: 0.5293 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9652 - accuracy: 0.5692 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9458 - accuracy: 0.5913 - recall_26: 0.0031 - recall_27: 0.0000e+00 - precision_26: 0.3750 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9488 - accuracy: 0.5868 - recall_26: 0.0051 - recall_27: 0.0000e+00 - precision_26: 0.3182 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9278 - accuracy: 0.6074 - recall_26: 0.0052 - recall_27: 0.0000e+00 - precision_26: 0.3077 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9223 - accuracy: 0.6121 - recall_26: 0.0046 - recall_27: 0.0000e+00 - precision_26: 0.3077 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9447 - accuracy: 0.5906 - recall_26: 0.0040 - recall_27: 0.0000e+00 - precision_26: 0.3103 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9466 - accuracy: 0.5894 - recall_26: 0.0035 - recall_27: 0.0000e+00 - precision_26: 0.2812 - precision_27: 0.0000e+00\n",
      "Epoch 00158: val_loss did not improve from 1.01286\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9466 - accuracy: 0.5894 - recall_26: 0.0035 - recall_27: 0.0000e+00 - precision_26: 0.2812 - precision_27: 0.0000e+00 - val_loss: 1.0148 - val_accuracy: 0.5013 - val_recall_26: 0.0331 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4194 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 159/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0107 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0053 - accuracy: 0.5293 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9485 - accuracy: 0.5855 - recall_26: 0.0035 - recall_27: 0.0000e+00 - precision_26: 0.3750 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9419 - accuracy: 0.5948 - recall_26: 0.0037 - recall_27: 0.0000e+00 - precision_26: 0.3077 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9476 - accuracy: 0.5870 - recall_26: 0.0066 - recall_27: 0.0000e+00 - precision_26: 0.3214 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9272 - accuracy: 0.6074 - recall_26: 0.0071 - recall_27: 0.0000e+00 - precision_26: 0.3056 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9221 - accuracy: 0.6121 - recall_26: 0.0063 - recall_27: 0.0000e+00 - precision_26: 0.2973 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9405 - accuracy: 0.5947 - recall_26: 0.0053 - recall_27: 0.0000e+00 - precision_26: 0.2895 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9467 - accuracy: 0.5894 - recall_26: 0.0043 - recall_27: 0.0000e+00 - precision_26: 0.2683 - precision_27: 0.0000e+00\n",
      "Epoch 00159: val_loss did not improve from 1.01286\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9467 - accuracy: 0.5894 - recall_26: 0.0043 - recall_27: 0.0000e+00 - precision_26: 0.2683 - precision_27: 0.0000e+00 - val_loss: 1.0134 - val_accuracy: 0.5010 - val_recall_26: 0.0331 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4094 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 160/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0107 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0059 - accuracy: 0.5298 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9655 - accuracy: 0.5695 - recall_26: 0.0014 - recall_27: 0.0000e+00 - precision_26: 0.2000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9450 - accuracy: 0.5911 - recall_26: 0.0031 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9410 - accuracy: 0.5938 - recall_26: 0.0033 - recall_27: 0.0000e+00 - precision_26: 0.2222 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9283 - accuracy: 0.6074 - recall_26: 0.0039 - recall_27: 0.0000e+00 - precision_26: 0.2727 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9226 - accuracy: 0.6121 - recall_26: 0.0034 - recall_27: 0.0000e+00 - precision_26: 0.2727 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9454 - accuracy: 0.5905 - recall_26: 0.0027 - recall_27: 0.0000e+00 - precision_26: 0.2727 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9471 - accuracy: 0.5895 - recall_26: 0.0024 - recall_27: 0.0000e+00 - precision_26: 0.2727 - precision_27: 0.0000e+00\n",
      "Epoch 00160: val_loss did not improve from 1.01286\n",
      "\n",
      "Epoch 00160: ReduceLROnPlateau reducing learning rate to 0.01509949415922165.\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9471 - accuracy: 0.5895 - recall_26: 0.0024 - recall_27: 0.0000e+00 - precision_26: 0.2727 - precision_27: 0.0000e+00 - val_loss: 1.0167 - val_accuracy: 0.4980 - val_recall_26: 0.0070 - val_recall_27: 0.0000e+00 - val_precision_26: 0.3929 - val_precision_27: 0.0000e+00 - lr: 0.0189\n",
      "Epoch 161/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0127 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0070 - accuracy: 0.5298 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9504 - accuracy: 0.5855 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.6667 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9425 - accuracy: 0.5949 - recall_26: 0.0028 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9490 - accuracy: 0.5872 - recall_26: 0.0036 - recall_27: 0.0000e+00 - precision_26: 0.4545 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9280 - accuracy: 0.6078 - recall_26: 0.0032 - recall_27: 0.0000e+00 - precision_26: 0.4167 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9392 - accuracy: 0.5961 - recall_26: 0.0026 - recall_27: 0.0000e+00 - precision_26: 0.4167 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9446 - accuracy: 0.5907 - recall_26: 0.0021 - recall_27: 0.0000e+00 - precision_26: 0.2941 - precision_27: 0.0000e+00\n",
      "Epoch 00161: val_loss did not improve from 1.01286\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9462 - accuracy: 0.5895 - recall_26: 0.0020 - recall_27: 0.0000e+00 - precision_26: 0.2941 - precision_27: 0.0000e+00 - val_loss: 1.0145 - val_accuracy: 0.5010 - val_recall_26: 0.0344 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4091 - val_precision_27: 0.0000e+00 - lr: 0.0151\n",
      "Epoch 162/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0109 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0047 - accuracy: 0.5293 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9643 - accuracy: 0.5698 - recall_26: 0.0028 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9416 - accuracy: 0.5949 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9399 - accuracy: 0.5961 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.3143 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9098 - accuracy: 0.6219 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.3250 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9399 - accuracy: 0.5947 - recall_26: 0.0073 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9443 - accuracy: 0.5905 - recall_26: 0.0063 - recall_27: 0.0000e+00 - precision_26: 0.2778 - precision_27: 0.0000e+00\n",
      "Epoch 00162: val_loss improved from 1.01286 to 1.01104, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.9459 - accuracy: 0.5894 - recall_26: 0.0063 - recall_27: 0.0000e+00 - precision_26: 0.2909 - precision_27: 0.0000e+00 - val_loss: 1.0110 - val_accuracy: 0.5021 - val_recall_26: 0.0446 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4142 - val_precision_27: 0.0000e+00 - lr: 0.0151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0140 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0052 - accuracy: 0.5293 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2222 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9646 - accuracy: 0.5701 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.3846 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9422 - accuracy: 0.5951 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.3636 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9486 - accuracy: 0.5875 - recall_26: 0.0102 - recall_27: 0.0000e+00 - precision_26: 0.3684 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9277 - accuracy: 0.6078 - recall_26: 0.0097 - recall_27: 0.0000e+00 - precision_26: 0.3409 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9393 - accuracy: 0.5960 - recall_26: 0.0079 - recall_27: 0.0000e+00 - precision_26: 0.3261 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9445 - accuracy: 0.5907 - recall_26: 0.0071 - recall_27: 0.0000e+00 - precision_26: 0.3265 - precision_27: 0.0000e+00\n",
      "Epoch 00163: val_loss did not improve from 1.01104\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9461 - accuracy: 0.5897 - recall_26: 0.0063 - recall_27: 0.0000e+00 - precision_26: 0.3137 - precision_27: 0.0000e+00 - val_loss: 1.0130 - val_accuracy: 0.5011 - val_recall_26: 0.0350 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4135 - val_precision_27: 0.0000e+00 - lr: 0.0151\n",
      "Epoch 164/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0139 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0063 - accuracy: 0.5293 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9490 - accuracy: 0.5858 - recall_26: 0.0046 - recall_27: 0.0000e+00 - precision_26: 0.4444 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9408 - accuracy: 0.5940 - recall_26: 0.0050 - recall_27: 0.0000e+00 - precision_26: 0.2727 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9403 - accuracy: 0.5960 - recall_26: 0.0068 - recall_27: 0.0000e+00 - precision_26: 0.3226 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9101 - accuracy: 0.6217 - recall_26: 0.0068 - recall_27: 0.0000e+00 - precision_26: 0.3235 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9402 - accuracy: 0.5947 - recall_26: 0.0058 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9445 - accuracy: 0.5905 - recall_26: 0.0050 - recall_27: 0.0000e+00 - precision_26: 0.2791 - precision_27: 0.0000e+00\n",
      "Epoch 00164: val_loss did not improve from 1.01104\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9460 - accuracy: 0.5894 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2791 - precision_27: 0.0000e+00 - val_loss: 1.0135 - val_accuracy: 0.5010 - val_recall_26: 0.0344 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4060 - val_precision_27: 0.0000e+00 - lr: 0.0151\n",
      "Epoch 165/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0133 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0056 - accuracy: 0.5288 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9635 - accuracy: 0.5692 - recall_26: 0.0028 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9443 - accuracy: 0.5911 - recall_26: 0.0041 - recall_27: 0.0000e+00 - precision_26: 0.3077 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9403 - accuracy: 0.5937 - recall_26: 0.0050 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9274 - accuracy: 0.6073 - recall_26: 0.0071 - recall_27: 0.0000e+00 - precision_26: 0.2973 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9388 - accuracy: 0.5955 - recall_26: 0.0058 - recall_27: 0.0000e+00 - precision_26: 0.2683 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9441 - accuracy: 0.5900 - recall_26: 0.0054 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+00\n",
      "Epoch 00165: val_loss did not improve from 1.01104\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9459 - accuracy: 0.5891 - recall_26: 0.0051 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+00 - val_loss: 1.0131 - val_accuracy: 0.5016 - val_recall_26: 0.0369 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4173 - val_precision_27: 0.0000e+00 - lr: 0.0151\n",
      "Epoch 166/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0128 - accuracy: 0.5308 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.6667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9748 - accuracy: 0.5601 - recall_26: 0.0083 - recall_27: 0.0000e+00 - precision_26: 0.4545 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9483 - accuracy: 0.5860 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9401 - accuracy: 0.5942 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9396 - accuracy: 0.5960 - recall_26: 0.0089 - recall_27: 0.0000e+00 - precision_26: 0.3421 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9216 - accuracy: 0.6120 - recall_26: 0.0080 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9397 - accuracy: 0.5944 - recall_26: 0.0073 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9441 - accuracy: 0.5903 - recall_26: 0.0063 - recall_27: 0.0000e+00 - precision_26: 0.2778 - precision_27: 0.0000e+00\n",
      "Epoch 00166: val_loss did not improve from 1.01104\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9456 - accuracy: 0.5892 - recall_26: 0.0063 - recall_27: 0.0000e+00 - precision_26: 0.2909 - precision_27: 0.0000e+00 - val_loss: 1.0128 - val_accuracy: 0.5020 - val_recall_26: 0.0389 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4207 - val_precision_27: 0.0000e+00 - lr: 0.0151\n",
      "Epoch 167/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0104 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0032 - accuracy: 0.5298 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9635 - accuracy: 0.5698 - recall_26: 0.0056 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9447 - accuracy: 0.5913 - recall_26: 0.0062 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9406 - accuracy: 0.5938 - recall_26: 0.0066 - recall_27: 0.0000e+00 - precision_26: 0.2581 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9275 - accuracy: 0.6074 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.3023 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9220 - accuracy: 0.6120 - recall_26: 0.0074 - recall_27: 0.0000e+00 - precision_26: 0.2955 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9402 - accuracy: 0.5946 - recall_26: 0.0068 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9459 - accuracy: 0.5893 - recall_26: 0.0055 - recall_27: 0.0000e+00 - precision_26: 0.2642 - precision_27: 0.0000e+00\n",
      "Epoch 00167: val_loss did not improve from 1.01104\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9459 - accuracy: 0.5893 - recall_26: 0.0055 - recall_27: 0.0000e+00 - precision_26: 0.2642 - precision_27: 0.0000e+00 - val_loss: 1.0130 - val_accuracy: 0.5013 - val_recall_26: 0.0357 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4148 - val_precision_27: 0.0000e+00 - lr: 0.0151\n",
      "Epoch 168/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0117 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9749 - accuracy: 0.5598 - recall_26: 0.0033 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9490 - accuracy: 0.5858 - recall_26: 0.0046 - recall_27: 0.0000e+00 - precision_26: 0.4444 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9408 - accuracy: 0.5940 - recall_26: 0.0050 - recall_27: 0.0000e+00 - precision_26: 0.2727 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9403 - accuracy: 0.5960 - recall_26: 0.0068 - recall_27: 0.0000e+00 - precision_26: 0.3125 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9220 - accuracy: 0.6120 - recall_26: 0.0063 - recall_27: 0.0000e+00 - precision_26: 0.3056 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9401 - accuracy: 0.5946 - recall_26: 0.0058 - recall_27: 0.0000e+00 - precision_26: 0.2927 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9445 - accuracy: 0.5904 - recall_26: 0.0050 - recall_27: 0.0000e+00 - precision_26: 0.2667 - precision_27: 0.0000e+00\n",
      "Epoch 00168: val_loss did not improve from 1.01104\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9462 - accuracy: 0.5893 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2667 - precision_27: 0.0000e+00 - val_loss: 1.0130 - val_accuracy: 0.5015 - val_recall_26: 0.0363 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4161 - val_precision_27: 0.0000e+00 - lr: 0.0151\n",
      "Epoch 169/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0121 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0045 - accuracy: 0.5298 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9634 - accuracy: 0.5704 - recall_26: 0.0056 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9412 - accuracy: 0.5953 - recall_26: 0.0066 - recall_27: 0.0000e+00 - precision_26: 0.4118 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9480 - accuracy: 0.5874 - recall_26: 0.0080 - recall_27: 0.0000e+00 - precision_26: 0.3667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9273 - accuracy: 0.6076 - recall_26: 0.0077 - recall_27: 0.0000e+00 - precision_26: 0.3243 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9219 - accuracy: 0.6122 - recall_26: 0.0068 - recall_27: 0.0000e+00 - precision_26: 0.3158 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9399 - accuracy: 0.5948 - recall_26: 0.0063 - recall_27: 0.0000e+00 - precision_26: 0.3023 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9442 - accuracy: 0.5906 - recall_26: 0.0054 - recall_27: 0.0000e+00 - precision_26: 0.2766 - precision_27: 0.0000e+00\n",
      "Epoch 00169: val_loss did not improve from 1.01104\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9456 - accuracy: 0.5894 - recall_26: 0.0051 - recall_27: 0.0000e+00 - precision_26: 0.2766 - precision_27: 0.0000e+00 - val_loss: 1.0125 - val_accuracy: 0.5020 - val_recall_26: 0.0389 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4236 - val_precision_27: 0.0000e+00 - lr: 0.0151\n",
      "Epoch 170/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0098 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0049 - accuracy: 0.5293 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.2000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9637 - accuracy: 0.5695 - recall_26: 0.0042 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9419 - accuracy: 0.5948 - recall_26: 0.0056 - recall_27: 0.0000e+00 - precision_26: 0.3529 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9405 - accuracy: 0.5957 - recall_26: 0.0068 - recall_27: 0.0000e+00 - precision_26: 0.2941 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9104 - accuracy: 0.6215 - recall_26: 0.0068 - recall_27: 0.0000e+00 - precision_26: 0.2895 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9393 - accuracy: 0.5954 - recall_26: 0.0058 - recall_27: 0.0000e+00 - precision_26: 0.2750 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9447 - accuracy: 0.5902 - recall_26: 0.0050 - recall_27: 0.0000e+00 - precision_26: 0.2553 - precision_27: 0.0000e+00\n",
      "Epoch 00170: val_loss did not improve from 1.01104\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9463 - accuracy: 0.5891 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2553 - precision_27: 0.0000e+00 - val_loss: 1.0132 - val_accuracy: 0.5010 - val_recall_26: 0.0344 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4091 - val_precision_27: 0.0000e+00 - lr: 0.0151\n",
      "Epoch 171/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0105 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 1.0000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0041 - accuracy: 0.5298 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9642 - accuracy: 0.5698 - recall_26: 0.0042 - recall_27: 0.0000e+00 - precision_26: 0.4286 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9416 - accuracy: 0.5951 - recall_26: 0.0066 - recall_27: 0.0000e+00 - precision_26: 0.4118 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9480 - accuracy: 0.5874 - recall_26: 0.0088 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9271 - accuracy: 0.6078 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.3714 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9388 - accuracy: 0.5960 - recall_26: 0.0068 - recall_27: 0.0000e+00 - precision_26: 0.3611 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9444 - accuracy: 0.5907 - recall_26: 0.0059 - recall_27: 0.0000e+00 - precision_26: 0.3182 - precision_27: 0.0000e+00\n",
      "Epoch 00171: val_loss did not improve from 1.01104\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9460 - accuracy: 0.5896 - recall_26: 0.0059 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00 - val_loss: 1.0127 - val_accuracy: 0.5013 - val_recall_26: 0.0357 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4179 - val_precision_27: 0.0000e+00 - lr: 0.0151\n",
      "Epoch 172/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0129 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0047 - accuracy: 0.5293 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.2000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9637 - accuracy: 0.5701 - recall_26: 0.0056 - recall_27: 0.0000e+00 - precision_26: 0.4444 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9417 - accuracy: 0.5951 - recall_26: 0.0066 - recall_27: 0.0000e+00 - precision_26: 0.4118 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9402 - accuracy: 0.5962 - recall_26: 0.0082 - recall_27: 0.0000e+00 - precision_26: 0.3529 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9101 - accuracy: 0.6219 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.3421 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9390 - accuracy: 0.5959 - recall_26: 0.0068 - recall_27: 0.0000e+00 - precision_26: 0.3250 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9444 - accuracy: 0.5907 - recall_26: 0.0063 - recall_27: 0.0000e+00 - precision_26: 0.3182 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9462 - accuracy: 0.5895 - recall_26: 0.0055 - recall_27: 0.0000e+00 - precision_26: 0.2979 - precision_27: 0.0000e+00\n",
      "Epoch 00172: val_loss did not improve from 1.01104\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9462 - accuracy: 0.5895 - recall_26: 0.0055 - recall_27: 0.0000e+00 - precision_26: 0.2979 - precision_27: 0.0000e+00 - val_loss: 1.0138 - val_accuracy: 0.5010 - val_recall_26: 0.0331 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4094 - val_precision_27: 0.0000e+00 - lr: 0.0151\n",
      "Epoch 173/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0128 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0052 - accuracy: 0.5298 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9643 - accuracy: 0.5695 - recall_26: 0.0014 - recall_27: 0.0000e+00 - precision_26: 0.2000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9446 - accuracy: 0.5913 - recall_26: 0.0031 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9407 - accuracy: 0.5938 - recall_26: 0.0041 - recall_27: 0.0000e+00 - precision_26: 0.2381 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9271 - accuracy: 0.6075 - recall_26: 0.0064 - recall_27: 0.0000e+00 - precision_26: 0.3226 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9217 - accuracy: 0.6122 - recall_26: 0.0057 - recall_27: 0.0000e+00 - precision_26: 0.3226 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9399 - accuracy: 0.5948 - recall_26: 0.0053 - recall_27: 0.0000e+00 - precision_26: 0.2973 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9457 - accuracy: 0.5894 - recall_26: 0.0043 - recall_27: 0.0000e+00 - precision_26: 0.2683 - precision_27: 0.0000e+00\n",
      "Epoch 00173: val_loss did not improve from 1.01104\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9457 - accuracy: 0.5894 - recall_26: 0.0043 - recall_27: 0.0000e+00 - precision_26: 0.2683 - precision_27: 0.0000e+00 - val_loss: 1.0137 - val_accuracy: 0.5018 - val_recall_26: 0.0382 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4225 - val_precision_27: 0.0000e+00 - lr: 0.0151\n",
      "Epoch 174/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0124 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0047 - accuracy: 0.5298 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9484 - accuracy: 0.5863 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.4667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9415 - accuracy: 0.5951 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9401 - accuracy: 0.5964 - recall_26: 0.0102 - recall_27: 0.0000e+00 - precision_26: 0.3261 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9098 - accuracy: 0.6222 - recall_26: 0.0105 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9397 - accuracy: 0.5948 - recall_26: 0.0087 - recall_27: 0.0000e+00 - precision_26: 0.3051 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9456 - accuracy: 0.5895 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.2969 - precision_27: 0.0000e+00\n",
      "Epoch 00174: val_loss did not improve from 1.01104\n",
      "\n",
      "Epoch 00174: ReduceLROnPlateau reducing learning rate to 0.012079595029354096.\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9456 - accuracy: 0.5895 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.2969 - precision_27: 0.0000e+00 - val_loss: 1.0134 - val_accuracy: 0.5024 - val_recall_26: 0.0414 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4194 - val_precision_27: 0.0000e+00 - lr: 0.0151\n",
      "Epoch 175/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0119 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9750 - accuracy: 0.5598 - recall_26: 0.0067 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9484 - accuracy: 0.5858 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9418 - accuracy: 0.5949 - recall_26: 0.0066 - recall_27: 0.0000e+00 - precision_26: 0.3500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9479 - accuracy: 0.5871 - recall_26: 0.0080 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9097 - accuracy: 0.6217 - recall_26: 0.0074 - recall_27: 0.0000e+00 - precision_26: 0.3077 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9384 - accuracy: 0.5956 - recall_26: 0.0063 - recall_27: 0.0000e+00 - precision_26: 0.2791 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9437 - accuracy: 0.5903 - recall_26: 0.0059 - recall_27: 0.0000e+00 - precision_26: 0.2692 - precision_27: 0.0000e+00\n",
      "Epoch 00175: val_loss did not improve from 1.01104\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9452 - accuracy: 0.5893 - recall_26: 0.0059 - recall_27: 0.0000e+00 - precision_26: 0.2830 - precision_27: 0.0000e+00 - val_loss: 1.0126 - val_accuracy: 0.5020 - val_recall_26: 0.0439 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4107 - val_precision_27: 0.0000e+00 - lr: 0.0121\n",
      "Epoch 176/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0134 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0056 - accuracy: 0.5298 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9489 - accuracy: 0.5863 - recall_26: 0.0104 - recall_27: 0.0000e+00 - precision_26: 0.4500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9410 - accuracy: 0.5942 - recall_26: 0.0091 - recall_27: 0.0000e+00 - precision_26: 0.3143 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9403 - accuracy: 0.5961 - recall_26: 0.0109 - recall_27: 0.0000e+00 - precision_26: 0.3404 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9218 - accuracy: 0.6121 - recall_26: 0.0097 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9400 - accuracy: 0.5943 - recall_26: 0.0087 - recall_27: 0.0000e+00 - precision_26: 0.2903 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9441 - accuracy: 0.5902 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.2727 - precision_27: 0.0000e+00\n",
      "Epoch 00176: val_loss did not improve from 1.01104\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9456 - accuracy: 0.5891 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.2836 - precision_27: 0.0000e+00 - val_loss: 1.0125 - val_accuracy: 0.5024 - val_recall_26: 0.0414 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4194 - val_precision_27: 0.0000e+00 - lr: 0.0121\n",
      "Epoch 177/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0125 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0042 - accuracy: 0.5298 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9634 - accuracy: 0.5701 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.3846 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9444 - accuracy: 0.5917 - recall_26: 0.0072 - recall_27: 0.0000e+00 - precision_26: 0.3889 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9480 - accuracy: 0.5872 - recall_26: 0.0095 - recall_27: 0.0000e+00 - precision_26: 0.3421 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9097 - accuracy: 0.6217 - recall_26: 0.0087 - recall_27: 0.0000e+00 - precision_26: 0.3043 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9384 - accuracy: 0.5957 - recall_26: 0.0073 - recall_27: 0.0000e+00 - precision_26: 0.2800 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9436 - accuracy: 0.5901 - recall_26: 0.0067 - recall_27: 0.0000e+00 - precision_26: 0.2586 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9454 - accuracy: 0.5891 - recall_26: 0.0063 - recall_27: 0.0000e+00 - precision_26: 0.2581 - precision_27: 0.0000e+00\n",
      "Epoch 00177: val_loss did not improve from 1.01104\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9454 - accuracy: 0.5891 - recall_26: 0.0063 - recall_27: 0.0000e+00 - precision_26: 0.2581 - precision_27: 0.0000e+00 - val_loss: 1.0131 - val_accuracy: 0.5021 - val_recall_26: 0.0401 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4228 - val_precision_27: 0.0000e+00 - lr: 0.0121\n",
      "Epoch 178/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0134 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0052 - accuracy: 0.5298 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9483 - accuracy: 0.5860 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9415 - accuracy: 0.5949 - recall_26: 0.0066 - recall_27: 0.0000e+00 - precision_26: 0.3889 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9395 - accuracy: 0.5958 - recall_26: 0.0082 - recall_27: 0.0000e+00 - precision_26: 0.3243 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9213 - accuracy: 0.6119 - recall_26: 0.0074 - recall_27: 0.0000e+00 - precision_26: 0.3171 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9396 - accuracy: 0.5943 - recall_26: 0.0068 - recall_27: 0.0000e+00 - precision_26: 0.2800 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9452 - accuracy: 0.5891 - recall_26: 0.0059 - recall_27: 0.0000e+00 - precision_26: 0.2727 - precision_27: 0.0000e+00\n",
      "Epoch 00178: val_loss did not improve from 1.01104\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9452 - accuracy: 0.5891 - recall_26: 0.0059 - recall_27: 0.0000e+00 - precision_26: 0.2727 - precision_27: 0.0000e+00 - val_loss: 1.0132 - val_accuracy: 0.5023 - val_recall_26: 0.0408 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4238 - val_precision_27: 0.0000e+00 - lr: 0.0121\n",
      "Epoch 179/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0141 - accuracy: 0.5264 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0072 - accuracy: 0.5288 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9653 - accuracy: 0.5692 - recall_26: 0.0028 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9457 - accuracy: 0.5913 - recall_26: 0.0052 - recall_27: 0.0000e+00 - precision_26: 0.3846 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9413 - accuracy: 0.5938 - recall_26: 0.0058 - recall_27: 0.0000e+00 - precision_26: 0.2800 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9274 - accuracy: 0.6074 - recall_26: 0.0077 - recall_27: 0.0000e+00 - precision_26: 0.3429 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9220 - accuracy: 0.6120 - recall_26: 0.0068 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9440 - accuracy: 0.5902 - recall_26: 0.0058 - recall_27: 0.0000e+00 - precision_26: 0.2889 - precision_27: 0.0000e+00\n",
      "Epoch 00179: val_loss did not improve from 1.01104\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9457 - accuracy: 0.5892 - recall_26: 0.0055 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+00 - val_loss: 1.0135 - val_accuracy: 0.5020 - val_recall_26: 0.0389 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4236 - val_precision_27: 0.0000e+00 - lr: 0.0121\n",
      "Epoch 180/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0132 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0047 - accuracy: 0.5293 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.2000 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9487 - accuracy: 0.5858 - recall_26: 0.0058 - recall_27: 0.0000e+00 - precision_26: 0.4545 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9418 - accuracy: 0.5949 - recall_26: 0.0056 - recall_27: 0.0000e+00 - precision_26: 0.3529 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9397 - accuracy: 0.5961 - recall_26: 0.0082 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9097 - accuracy: 0.6218 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.3250 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9383 - accuracy: 0.5958 - recall_26: 0.0068 - recall_27: 0.0000e+00 - precision_26: 0.2955 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9439 - accuracy: 0.5904 - recall_26: 0.0063 - recall_27: 0.0000e+00 - precision_26: 0.2727 - precision_27: 0.0000e+00\n",
      "Epoch 00180: val_loss did not improve from 1.01104\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9454 - accuracy: 0.5894 - recall_26: 0.0063 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+00 - val_loss: 1.0131 - val_accuracy: 0.5023 - val_recall_26: 0.0408 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4267 - val_precision_27: 0.0000e+00 - lr: 0.0121\n",
      "Epoch 181/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0131 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0051 - accuracy: 0.5293 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2222 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9633 - accuracy: 0.5701 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.3846 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9418 - accuracy: 0.5951 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.3636 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9481 - accuracy: 0.5871 - recall_26: 0.0095 - recall_27: 0.0000e+00 - precision_26: 0.3421 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9097 - accuracy: 0.6217 - recall_26: 0.0087 - recall_27: 0.0000e+00 - precision_26: 0.3111 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9385 - accuracy: 0.5956 - recall_26: 0.0073 - recall_27: 0.0000e+00 - precision_26: 0.2800 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9436 - accuracy: 0.5902 - recall_26: 0.0071 - recall_27: 0.0000e+00 - precision_26: 0.2759 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9453 - accuracy: 0.5892 - recall_26: 0.0067 - recall_27: 0.0000e+00 - precision_26: 0.2742 - precision_27: 0.0000e+00\n",
      "Epoch 00181: val_loss did not improve from 1.01104\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9453 - accuracy: 0.5892 - recall_26: 0.0067 - recall_27: 0.0000e+00 - precision_26: 0.2742 - precision_27: 0.0000e+00 - val_loss: 1.0143 - val_accuracy: 0.5020 - val_recall_26: 0.0389 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4236 - val_precision_27: 0.0000e+00 - lr: 0.0121\n",
      "Epoch 182/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0118 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0041 - accuracy: 0.5298 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9487 - accuracy: 0.5860 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.4375 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9407 - accuracy: 0.5942 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9400 - accuracy: 0.5962 - recall_26: 0.0089 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9214 - accuracy: 0.6122 - recall_26: 0.0080 - recall_27: 0.0000e+00 - precision_26: 0.3182 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9396 - accuracy: 0.5947 - recall_26: 0.0078 - recall_27: 0.0000e+00 - precision_26: 0.2963 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9453 - accuracy: 0.5894 - recall_26: 0.0067 - recall_27: 0.0000e+00 - precision_26: 0.2881 - precision_27: 0.0000e+00\n",
      "Epoch 00182: val_loss did not improve from 1.01104\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9453 - accuracy: 0.5894 - recall_26: 0.0067 - recall_27: 0.0000e+00 - precision_26: 0.2881 - precision_27: 0.0000e+00 - val_loss: 1.0143 - val_accuracy: 0.5023 - val_recall_26: 0.0408 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4267 - val_precision_27: 0.0000e+00 - lr: 0.0121\n",
      "Epoch 183/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0118 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0046 - accuracy: 0.5293 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2222 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9489 - accuracy: 0.5858 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.4118 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9408 - accuracy: 0.5937 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.2727 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9400 - accuracy: 0.5958 - recall_26: 0.0089 - recall_27: 0.0000e+00 - precision_26: 0.3095 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9097 - accuracy: 0.6216 - recall_26: 0.0087 - recall_27: 0.0000e+00 - precision_26: 0.3111 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9398 - accuracy: 0.5944 - recall_26: 0.0082 - recall_27: 0.0000e+00 - precision_26: 0.2931 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9440 - accuracy: 0.5903 - recall_26: 0.0071 - recall_27: 0.0000e+00 - precision_26: 0.2742 - precision_27: 0.0000e+00\n",
      "Epoch 00183: val_loss did not improve from 1.01104\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9454 - accuracy: 0.5892 - recall_26: 0.0071 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+00 - val_loss: 1.0136 - val_accuracy: 0.5020 - val_recall_26: 0.0395 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4218 - val_precision_27: 0.0000e+00 - lr: 0.0121\n",
      "Epoch 184/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0138 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0050 - accuracy: 0.5293 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2222 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9486 - accuracy: 0.5855 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.3750 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9418 - accuracy: 0.5948 - recall_26: 0.0066 - recall_27: 0.0000e+00 - precision_26: 0.3182 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9483 - accuracy: 0.5870 - recall_26: 0.0088 - recall_27: 0.0000e+00 - precision_26: 0.3243 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9098 - accuracy: 0.6216 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.2955 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9384 - accuracy: 0.5955 - recall_26: 0.0068 - recall_27: 0.0000e+00 - precision_26: 0.2653 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9436 - accuracy: 0.5901 - recall_26: 0.0067 - recall_27: 0.0000e+00 - precision_26: 0.2632 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9454 - accuracy: 0.5891 - recall_26: 0.0063 - recall_27: 0.0000e+00 - precision_26: 0.2623 - precision_27: 0.0000e+00\n",
      "Epoch 00184: val_loss did not improve from 1.01104\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9454 - accuracy: 0.5891 - recall_26: 0.0063 - recall_27: 0.0000e+00 - precision_26: 0.2623 - precision_27: 0.0000e+00 - val_loss: 1.0136 - val_accuracy: 0.5021 - val_recall_26: 0.0395 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4247 - val_precision_27: 0.0000e+00 - lr: 0.0121\n",
      "Epoch 185/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0128 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0033 - accuracy: 0.5303 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9627 - accuracy: 0.5704 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.4286 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9415 - accuracy: 0.5953 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.3913 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9397 - accuracy: 0.5961 - recall_26: 0.0095 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9096 - accuracy: 0.6218 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9394 - accuracy: 0.5945 - recall_26: 0.0082 - recall_27: 0.0000e+00 - precision_26: 0.2982 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9451 - accuracy: 0.5893 - recall_26: 0.0071 - recall_27: 0.0000e+00 - precision_26: 0.2903 - precision_27: 0.0000e+00\n",
      "Epoch 00185: val_loss did not improve from 1.01104\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9451 - accuracy: 0.5893 - recall_26: 0.0071 - recall_27: 0.0000e+00 - precision_26: 0.2903 - precision_27: 0.0000e+00 - val_loss: 1.0138 - val_accuracy: 0.5023 - val_recall_26: 0.0408 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4238 - val_precision_27: 0.0000e+00 - lr: 0.0121\n",
      "Epoch 186/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0145 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9754 - accuracy: 0.5601 - recall_26: 0.0083 - recall_27: 0.0000e+00 - precision_26: 0.3846 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9493 - accuracy: 0.5860 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.4375 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9406 - accuracy: 0.5942 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9402 - accuracy: 0.5961 - recall_26: 0.0089 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9100 - accuracy: 0.6218 - recall_26: 0.0087 - recall_27: 0.0000e+00 - precision_26: 0.3256 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9385 - accuracy: 0.5957 - recall_26: 0.0073 - recall_27: 0.0000e+00 - precision_26: 0.2917 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9435 - accuracy: 0.5902 - recall_26: 0.0071 - recall_27: 0.0000e+00 - precision_26: 0.2807 - precision_27: 0.0000e+00\n",
      "Epoch 00186: val_loss did not improve from 1.01104\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9454 - accuracy: 0.5892 - recall_26: 0.0067 - recall_27: 0.0000e+00 - precision_26: 0.2787 - precision_27: 0.0000e+00 - val_loss: 1.0138 - val_accuracy: 0.5021 - val_recall_26: 0.0395 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4276 - val_precision_27: 0.0000e+00 - lr: 0.0121\n",
      "Epoch 187/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0136 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0050 - accuracy: 0.5298 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9635 - accuracy: 0.5701 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.4167 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9446 - accuracy: 0.5920 - recall_26: 0.0083 - recall_27: 0.0000e+00 - precision_26: 0.4444 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9405 - accuracy: 0.5942 - recall_26: 0.0083 - recall_27: 0.0000e+00 - precision_26: 0.3226 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9399 - accuracy: 0.5960 - recall_26: 0.0089 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9098 - accuracy: 0.6217 - recall_26: 0.0087 - recall_27: 0.0000e+00 - precision_26: 0.3256 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9396 - accuracy: 0.5946 - recall_26: 0.0078 - recall_27: 0.0000e+00 - precision_26: 0.3077 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9439 - accuracy: 0.5904 - recall_26: 0.0067 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+00\n",
      "Epoch 00187: val_loss did not improve from 1.01104\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9454 - accuracy: 0.5894 - recall_26: 0.0067 - recall_27: 0.0000e+00 - precision_26: 0.2982 - precision_27: 0.0000e+00 - val_loss: 1.0139 - val_accuracy: 0.5018 - val_recall_26: 0.0382 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4225 - val_precision_27: 0.0000e+00 - lr: 0.0121\n",
      "Epoch 188/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0121 - accuracy: 0.5308 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.6667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9752 - accuracy: 0.5601 - recall_26: 0.0083 - recall_27: 0.0000e+00 - precision_26: 0.4167 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9487 - accuracy: 0.5860 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.4667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9408 - accuracy: 0.5940 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9403 - accuracy: 0.5961 - recall_26: 0.0089 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9100 - accuracy: 0.6218 - recall_26: 0.0087 - recall_27: 0.0000e+00 - precision_26: 0.3256 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9397 - accuracy: 0.5946 - recall_26: 0.0078 - recall_27: 0.0000e+00 - precision_26: 0.3019 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9441 - accuracy: 0.5904 - recall_26: 0.0067 - recall_27: 0.0000e+00 - precision_26: 0.2807 - precision_27: 0.0000e+00\n",
      "Epoch 00188: val_loss did not improve from 1.01104\n",
      "\n",
      "Epoch 00188: ReduceLROnPlateau reducing learning rate to 0.009663675725460053.\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9456 - accuracy: 0.5894 - recall_26: 0.0067 - recall_27: 0.0000e+00 - precision_26: 0.2931 - precision_27: 0.0000e+00 - val_loss: 1.0132 - val_accuracy: 0.5013 - val_recall_26: 0.0357 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4179 - val_precision_27: 0.0000e+00 - lr: 0.0121\n",
      "Epoch 189/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0132 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0057 - accuracy: 0.5293 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.1667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9487 - accuracy: 0.5858 - recall_26: 0.0058 - recall_27: 0.0000e+00 - precision_26: 0.4167 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9415 - accuracy: 0.5949 - recall_26: 0.0056 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9394 - accuracy: 0.5961 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.3235 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9094 - accuracy: 0.6218 - recall_26: 0.0074 - recall_27: 0.0000e+00 - precision_26: 0.3243 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9378 - accuracy: 0.5960 - recall_26: 0.0068 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9431 - accuracy: 0.5906 - recall_26: 0.0067 - recall_27: 0.0000e+00 - precision_26: 0.3125 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9448 - accuracy: 0.5895 - recall_26: 0.0063 - recall_27: 0.0000e+00 - precision_26: 0.3077 - precision_27: 0.0000e+00\n",
      "Epoch 00189: val_loss did not improve from 1.01104\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9448 - accuracy: 0.5895 - recall_26: 0.0063 - recall_27: 0.0000e+00 - precision_26: 0.3077 - precision_27: 0.0000e+00 - val_loss: 1.0122 - val_accuracy: 0.5018 - val_recall_26: 0.0382 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4286 - val_precision_27: 0.0000e+00 - lr: 0.0097\n",
      "Epoch 190/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0107 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0044 - accuracy: 0.5298 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9633 - accuracy: 0.5698 - recall_26: 0.0056 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9412 - accuracy: 0.5951 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.3810 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9476 - accuracy: 0.5874 - recall_26: 0.0095 - recall_27: 0.0000e+00 - precision_26: 0.3611 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9268 - accuracy: 0.6078 - recall_26: 0.0090 - recall_27: 0.0000e+00 - precision_26: 0.3500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9213 - accuracy: 0.6124 - recall_26: 0.0080 - recall_27: 0.0000e+00 - precision_26: 0.3500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9432 - accuracy: 0.5909 - recall_26: 0.0085 - recall_27: 0.0000e+00 - precision_26: 0.3393 - precision_27: 0.0000e+00\n",
      "Epoch 00190: val_loss did not improve from 1.01104\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9451 - accuracy: 0.5898 - recall_26: 0.0078 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00 - val_loss: 1.0118 - val_accuracy: 0.5023 - val_recall_26: 0.0414 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4194 - val_precision_27: 0.0000e+00 - lr: 0.0097\n",
      "Epoch 191/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0134 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0052 - accuracy: 0.5288 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9636 - accuracy: 0.5692 - recall_26: 0.0056 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9419 - accuracy: 0.5946 - recall_26: 0.0066 - recall_27: 0.0000e+00 - precision_26: 0.3182 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9481 - accuracy: 0.5872 - recall_26: 0.0095 - recall_27: 0.0000e+00 - precision_26: 0.3611 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9267 - accuracy: 0.6075 - recall_26: 0.0090 - recall_27: 0.0000e+00 - precision_26: 0.3256 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9381 - accuracy: 0.5960 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9432 - accuracy: 0.5907 - recall_26: 0.0080 - recall_27: 0.0000e+00 - precision_26: 0.3273 - precision_27: 0.0000e+00\n",
      "Epoch 00191: val_loss did not improve from 1.01104\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9450 - accuracy: 0.5896 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.3220 - precision_27: 0.0000e+00 - val_loss: 1.0114 - val_accuracy: 0.5024 - val_recall_26: 0.0414 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4221 - val_precision_27: 0.0000e+00 - lr: 0.0097\n",
      "Epoch 192/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0105 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0036 - accuracy: 0.5288 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9479 - accuracy: 0.5853 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.3684 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9413 - accuracy: 0.5942 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.2963 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9396 - accuracy: 0.5956 - recall_26: 0.0095 - recall_27: 0.0000e+00 - precision_26: 0.2979 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9092 - accuracy: 0.6214 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9377 - accuracy: 0.5957 - recall_26: 0.0094 - recall_27: 0.0000e+00 - precision_26: 0.3214 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9429 - accuracy: 0.5905 - recall_26: 0.0094 - recall_27: 0.0000e+00 - precision_26: 0.3231 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9446 - accuracy: 0.5894 - recall_26: 0.0086 - recall_27: 0.0000e+00 - precision_26: 0.3188 - precision_27: 0.0000e+00\n",
      "Epoch 00192: val_loss did not improve from 1.01104\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9446 - accuracy: 0.5894 - recall_26: 0.0086 - recall_27: 0.0000e+00 - precision_26: 0.3188 - precision_27: 0.0000e+00 - val_loss: 1.0111 - val_accuracy: 0.5020 - val_recall_26: 0.0439 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4132 - val_precision_27: 0.0000e+00 - lr: 0.0097\n",
      "Epoch 193/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0096 - accuracy: 0.5308 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.6667 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0041 - accuracy: 0.5293 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.2727 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9476 - accuracy: 0.5853 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.3684 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9409 - accuracy: 0.5944 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.2963 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9394 - accuracy: 0.5958 - recall_26: 0.0102 - recall_27: 0.0000e+00 - precision_26: 0.3191 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9209 - accuracy: 0.6119 - recall_26: 0.0091 - recall_27: 0.0000e+00 - precision_26: 0.3077 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9390 - accuracy: 0.5948 - recall_26: 0.0107 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9433 - accuracy: 0.5906 - recall_26: 0.0092 - recall_27: 0.0000e+00 - precision_26: 0.3099 - precision_27: 0.0000e+00\n",
      "Epoch 00193: val_loss improved from 1.01104 to 1.01085, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.9447 - accuracy: 0.5895 - recall_26: 0.0090 - recall_27: 0.0000e+00 - precision_26: 0.3194 - precision_27: 0.0000e+00 - val_loss: 1.0109 - val_accuracy: 0.5016 - val_recall_26: 0.0471 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4000 - val_precision_27: 0.0000e+00 - lr: 0.0097\n",
      "Epoch 194/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0100 - accuracy: 0.5323 - recall_26: 0.0242 - recall_27: 0.0000e+00 - precision_26: 0.7500 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0035 - accuracy: 0.5298 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9473 - accuracy: 0.5858 - recall_26: 0.0104 - recall_27: 0.0000e+00 - precision_26: 0.4286 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9405 - accuracy: 0.5946 - recall_26: 0.0094 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9466 - accuracy: 0.5868 - recall_26: 0.0109 - recall_27: 0.0000e+00 - precision_26: 0.3261 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9087 - accuracy: 0.6216 - recall_26: 0.0112 - recall_27: 0.0000e+00 - precision_26: 0.3273 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9373 - accuracy: 0.5961 - recall_26: 0.0115 - recall_27: 0.0000e+00 - precision_26: 0.3607 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9426 - accuracy: 0.5907 - recall_26: 0.0112 - recall_27: 0.0000e+00 - precision_26: 0.3472 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9446 - accuracy: 0.5896 - recall_26: 0.0098 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00\n",
      "Epoch 00194: val_loss improved from 1.01085 to 1.01076, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.9446 - accuracy: 0.5896 - recall_26: 0.0098 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00 - val_loss: 1.0108 - val_accuracy: 0.5023 - val_recall_26: 0.0497 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4084 - val_precision_27: 0.0000e+00 - lr: 0.0097\n",
      "Epoch 195/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0123 - accuracy: 0.5323 - recall_26: 0.0242 - recall_27: 0.0000e+00 - precision_26: 0.7500 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0037 - accuracy: 0.5298 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9631 - accuracy: 0.5695 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.3529 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9402 - accuracy: 0.5944 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.3103 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9470 - accuracy: 0.5870 - recall_26: 0.0109 - recall_27: 0.0000e+00 - precision_26: 0.3261 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9261 - accuracy: 0.6072 - recall_26: 0.0103 - recall_27: 0.0000e+00 - precision_26: 0.3019 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9372 - accuracy: 0.5960 - recall_26: 0.0110 - recall_27: 0.0000e+00 - precision_26: 0.3443 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9424 - accuracy: 0.5907 - recall_26: 0.0103 - recall_27: 0.0000e+00 - precision_26: 0.3286 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9444 - accuracy: 0.5895 - recall_26: 0.0090 - recall_27: 0.0000e+00 - precision_26: 0.3151 - precision_27: 0.0000e+00\n",
      "Epoch 00195: val_loss did not improve from 1.01076\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9444 - accuracy: 0.5895 - recall_26: 0.0090 - recall_27: 0.0000e+00 - precision_26: 0.3151 - precision_27: 0.0000e+00 - val_loss: 1.0112 - val_accuracy: 0.5013 - val_recall_26: 0.0452 - val_recall_27: 0.0000e+00 - val_precision_26: 0.3966 - val_precision_27: 0.0000e+00 - lr: 0.0097\n",
      "Epoch 196/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0129 - accuracy: 0.5308 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.6667 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0048 - accuracy: 0.5293 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.2727 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9637 - accuracy: 0.5695 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9411 - accuracy: 0.5942 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.2963 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9472 - accuracy: 0.5865 - recall_26: 0.0095 - recall_27: 0.0000e+00 - precision_26: 0.3023 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9091 - accuracy: 0.6217 - recall_26: 0.0112 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9374 - accuracy: 0.5960 - recall_26: 0.0105 - recall_27: 0.0000e+00 - precision_26: 0.3509 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9429 - accuracy: 0.5908 - recall_26: 0.0107 - recall_27: 0.0000e+00 - precision_26: 0.3582 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9450 - accuracy: 0.5897 - recall_26: 0.0098 - recall_27: 0.0000e+00 - precision_26: 0.3472 - precision_27: 0.0000e+00\n",
      "Epoch 00196: val_loss improved from 1.01076 to 1.01036, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.9450 - accuracy: 0.5897 - recall_26: 0.0098 - recall_27: 0.0000e+00 - precision_26: 0.3472 - precision_27: 0.0000e+00 - val_loss: 1.0104 - val_accuracy: 0.5016 - val_recall_26: 0.0465 - val_recall_27: 0.0000e+00 - val_precision_26: 0.3967 - val_precision_27: 0.0000e+00 - lr: 0.0097\n",
      "Epoch 197/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0134 - accuracy: 0.5308 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.6667 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0061 - accuracy: 0.5298 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9490 - accuracy: 0.5858 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.4211 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9418 - accuracy: 0.5946 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.3214 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9401 - accuracy: 0.5956 - recall_26: 0.0089 - recall_27: 0.0000e+00 - precision_26: 0.2826 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9216 - accuracy: 0.6118 - recall_26: 0.0085 - recall_27: 0.0000e+00 - precision_26: 0.2778 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9394 - accuracy: 0.5944 - recall_26: 0.0087 - recall_27: 0.0000e+00 - precision_26: 0.2812 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9455 - accuracy: 0.5892 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.2714 - precision_27: 0.0000e+00\n",
      "Epoch 00197: val_loss did not improve from 1.01036\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9455 - accuracy: 0.5892 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.2714 - precision_27: 0.0000e+00 - val_loss: 1.0105 - val_accuracy: 0.5024 - val_recall_26: 0.0414 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4194 - val_precision_27: 0.0000e+00 - lr: 0.0097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0117 - accuracy: 0.5308 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.6667 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0044 - accuracy: 0.5303 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9479 - accuracy: 0.5860 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.4375 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9409 - accuracy: 0.5951 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.3810 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9389 - accuracy: 0.5962 - recall_26: 0.0082 - recall_27: 0.0000e+00 - precision_26: 0.3429 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9089 - accuracy: 0.6222 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.3750 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9375 - accuracy: 0.5962 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.3721 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9434 - accuracy: 0.5908 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00\n",
      "Epoch 00198: val_loss improved from 1.01036 to 1.01036, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.9450 - accuracy: 0.5898 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.3455 - precision_27: 0.0000e+00 - val_loss: 1.0104 - val_accuracy: 0.5018 - val_recall_26: 0.0439 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4107 - val_precision_27: 0.0000e+00 - lr: 0.0097\n",
      "Epoch 199/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0125 - accuracy: 0.5308 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.6667 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0053 - accuracy: 0.5303 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9487 - accuracy: 0.5860 - recall_26: 0.0081 - recall_27: 0.0012 - precision_26: 0.3889 - precision_27: 1.0000       - ETA: 0s - loss: 0.9418 - accuracy: 0.5949 - recall_26: 0.0075 - recall_27: 8.7336e-04 - precision_26: 0.3333 - precision_27: 1.00 - ETA: 0s - loss: 0.9476 - accuracy: 0.5872 - recall_26: 0.0095 - recall_27: 6.9061e-04 - precision_26: 0.3514 - precision_27: 1.00 - ETA: 0s - loss: 0.9095 - accuracy: 0.6218 - recall_26: 0.0093 - recall_27: 5.7438e-04 - precision_26: 0.3125 - precision_27: 1.00 - ETA: 0s - loss: 0.9379 - accuracy: 0.5960 - recall_26: 0.0084 - recall_27: 4.4903e-04 - precision_26: 0.3137 - precision_27: 1.00 - ETA: 0s - loss: 0.9435 - accuracy: 0.5907 - recall_26: 0.0085 - recall_27: 3.9872e-04 - precision_26: 0.3220 - precision_27: 1.0000\n",
      "Epoch 00199: val_loss did not improve from 1.01036\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9453 - accuracy: 0.5895 - recall_26: 0.0075 - recall_27: 3.6101e-04 - precision_26: 0.3065 - precision_27: 0.5000 - val_loss: 1.0106 - val_accuracy: 0.5024 - val_recall_26: 0.0408 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4238 - val_precision_27: 0.0000e+00 - lr: 0.0097\n",
      "Epoch 200/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0110 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0045 - accuracy: 0.5298 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9636 - accuracy: 0.5701 - recall_26: 0.0056 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9432 - accuracy: 0.5917 - recall_26: 0.0062 - recall_27: 0.0000e+00 - precision_26: 0.3529 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9388 - accuracy: 0.5942 - recall_26: 0.0066 - recall_27: 0.0000e+00 - precision_26: 0.2963 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9389 - accuracy: 0.5965 - recall_26: 0.0095 - recall_27: 0.0000e+00 - precision_26: 0.3684 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9206 - accuracy: 0.6126 - recall_26: 0.0091 - recall_27: 0.0000e+00 - precision_26: 0.3636 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9387 - accuracy: 0.5955 - recall_26: 0.0107 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9432 - accuracy: 0.5914 - recall_26: 0.0105 - recall_27: 0.0000e+00 - precision_26: 0.3906 - precision_27: 0.0000e+00\n",
      "Epoch 00200: val_loss improved from 1.01036 to 1.01001, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.9449 - accuracy: 0.5904 - recall_26: 0.0106 - recall_27: 0.0000e+00 - precision_26: 0.4091 - precision_27: 0.0000e+00 - val_loss: 1.0100 - val_accuracy: 0.5016 - val_recall_26: 0.0433 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4072 - val_precision_27: 0.0000e+00 - lr: 0.0097\n",
      "Epoch 201/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0081 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9729 - accuracy: 0.5594 - recall_26: 0.0067 - recall_27: 0.0000e+00 - precision_26: 0.3077 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9464 - accuracy: 0.5858 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9399 - accuracy: 0.5946 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9464 - accuracy: 0.5871 - recall_26: 0.0109 - recall_27: 0.0000e+00 - precision_26: 0.3261 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9258 - accuracy: 0.6076 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9203 - accuracy: 0.6122 - recall_26: 0.0102 - recall_27: 0.0000e+00 - precision_26: 0.3158 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9428 - accuracy: 0.5907 - recall_26: 0.0107 - recall_27: 0.0000e+00 - precision_26: 0.3200 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9446 - accuracy: 0.5895 - recall_26: 0.0094 - recall_27: 0.0000e+00 - precision_26: 0.3038 - precision_27: 0.0000e+00\n",
      "Epoch 00201: val_loss improved from 1.01001 to 1.00875, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.9446 - accuracy: 0.5895 - recall_26: 0.0094 - recall_27: 0.0000e+00 - precision_26: 0.3038 - precision_27: 0.0000e+00 - val_loss: 1.0087 - val_accuracy: 0.5018 - val_recall_26: 0.0452 - val_recall_27: 6.5920e-04 - val_precision_26: 0.4011 - val_precision_27: 0.5000 - lr: 0.0097\n",
      "Epoch 202/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0105 - accuracy: 0.5323 - recall_26: 0.0242 - recall_27: 0.0000e+00 - precision_26: 0.7500 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0032 - accuracy: 0.5298 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.3636 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9636 - accuracy: 0.5695 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.3750 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9443 - accuracy: 0.5911 - recall_26: 0.0083 - recall_27: 0.0000e+00 - precision_26: 0.3200 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9396 - accuracy: 0.5935 - recall_26: 0.0083 - recall_27: 0.0000e+00 - precision_26: 0.2632 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9268 - accuracy: 0.6074 - recall_26: 0.0103 - recall_27: 0.0000e+00 - precision_26: 0.3200 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9213 - accuracy: 0.6121 - recall_26: 0.0091 - recall_27: 0.0000e+00 - precision_26: 0.3077 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9393 - accuracy: 0.5948 - recall_26: 0.0102 - recall_27: 0.0000e+00 - precision_26: 0.3088 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9450 - accuracy: 0.5896 - recall_26: 0.0090 - recall_27: 0.0000e+00 - precision_26: 0.3067 - precision_27: 0.0000e+00\n",
      "Epoch 00202: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9450 - accuracy: 0.5896 - recall_26: 0.0090 - recall_27: 0.0000e+00 - precision_26: 0.3067 - precision_27: 0.0000e+00 - val_loss: 1.0100 - val_accuracy: 0.5020 - val_recall_26: 0.0452 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4128 - val_precision_27: 0.0000e+00 - lr: 0.0097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 203/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0089 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0023 - accuracy: 0.5283 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9617 - accuracy: 0.5686 - recall_26: 0.0056 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9398 - accuracy: 0.5940 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9463 - accuracy: 0.5868 - recall_26: 0.0109 - recall_27: 0.0000e+00 - precision_26: 0.3125 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9084 - accuracy: 0.6215 - recall_26: 0.0112 - recall_27: 0.0000e+00 - precision_26: 0.3051 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9372 - accuracy: 0.5958 - recall_26: 0.0115 - recall_27: 0.0000e+00 - precision_26: 0.3284 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9427 - accuracy: 0.5906 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.3291 - precision_27: 0.0000e+00\n",
      "Epoch 00203: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9448 - accuracy: 0.5895 - recall_26: 0.0106 - recall_27: 0.0000e+00 - precision_26: 0.3253 - precision_27: 0.0000e+00 - val_loss: 1.0100 - val_accuracy: 0.5018 - val_recall_26: 0.0484 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4064 - val_precision_27: 0.0000e+00 - lr: 0.0097\n",
      "Epoch 204/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0102 - accuracy: 0.5323 - recall_26: 0.0242 - recall_27: 0.0000e+00 - precision_26: 0.7500 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0031 - accuracy: 0.5298 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9473 - accuracy: 0.5863 - recall_26: 0.0128 - recall_27: 0.0000e+00 - precision_26: 0.4583 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9393 - accuracy: 0.5942 - recall_26: 0.0108 - recall_27: 0.0000e+00 - precision_26: 0.3250 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9389 - accuracy: 0.5962 - recall_26: 0.0123 - recall_27: 0.0000e+00 - precision_26: 0.3462 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9089 - accuracy: 0.6220 - recall_26: 0.0124 - recall_27: 0.0000e+00 - precision_26: 0.3509 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9376 - accuracy: 0.5962 - recall_26: 0.0115 - recall_27: 0.0000e+00 - precision_26: 0.3492 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9430 - accuracy: 0.5909 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.3562 - precision_27: 0.0000e+00\n",
      "Epoch 00204: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9448 - accuracy: 0.5899 - recall_26: 0.0110 - recall_27: 0.0000e+00 - precision_26: 0.3590 - precision_27: 0.0000e+00 - val_loss: 1.0105 - val_accuracy: 0.5015 - val_recall_26: 0.0427 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4036 - val_precision_27: 0.0000e+00 - lr: 0.0097\n",
      "Epoch 205/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0095 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0037 - accuracy: 0.5293 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9636 - accuracy: 0.5698 - recall_26: 0.0056 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9435 - accuracy: 0.5915 - recall_26: 0.0072 - recall_27: 0.0000e+00 - precision_26: 0.3684 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9392 - accuracy: 0.5938 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9266 - accuracy: 0.6076 - recall_26: 0.0103 - recall_27: 0.0000e+00 - precision_26: 0.3478 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9210 - accuracy: 0.6124 - recall_26: 0.0097 - recall_27: 0.0000e+00 - precision_26: 0.3469 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9392 - accuracy: 0.5951 - recall_26: 0.0102 - recall_27: 0.0000e+00 - precision_26: 0.3500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9436 - accuracy: 0.5909 - recall_26: 0.0096 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00\n",
      "Epoch 00205: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9451 - accuracy: 0.5898 - recall_26: 0.0090 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00 - val_loss: 1.0104 - val_accuracy: 0.5026 - val_recall_26: 0.0414 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4305 - val_precision_27: 0.0000e+00 - lr: 0.0097\n",
      "Epoch 206/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0083 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0038 - accuracy: 0.5283 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.1000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9479 - accuracy: 0.5850 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9393 - accuracy: 0.5934 - recall_26: 0.0066 - recall_27: 0.0000e+00 - precision_26: 0.2222 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9393 - accuracy: 0.5958 - recall_26: 0.0089 - recall_27: 0.0000e+00 - precision_26: 0.2826 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9093 - accuracy: 0.6218 - recall_26: 0.0099 - recall_27: 0.0000e+00 - precision_26: 0.3137 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9378 - accuracy: 0.5958 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.2909 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9435 - accuracy: 0.5903 - recall_26: 0.0080 - recall_27: 0.0000e+00 - precision_26: 0.2812 - precision_27: 0.0000e+00\n",
      "Epoch 00206: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9452 - accuracy: 0.5893 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.2794 - precision_27: 0.0000e+00 - val_loss: 1.0098 - val_accuracy: 0.5026 - val_recall_26: 0.0414 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4305 - val_precision_27: 0.0000e+00 - lr: 0.0097\n",
      "Epoch 207/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0100 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9737 - accuracy: 0.5601 - recall_26: 0.0067 - recall_27: 0.0000e+00 - precision_26: 0.3636 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9473 - accuracy: 0.5863 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.4706 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9410 - accuracy: 0.5951 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.3750 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9391 - accuracy: 0.5962 - recall_26: 0.0095 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9089 - accuracy: 0.6223 - recall_26: 0.0112 - recall_27: 0.0000e+00 - precision_26: 0.3673 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9376 - accuracy: 0.5966 - recall_26: 0.0110 - recall_27: 0.0000e+00 - precision_26: 0.3750 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9432 - accuracy: 0.5913 - recall_26: 0.0107 - recall_27: 0.0000e+00 - precision_26: 0.3692 - precision_27: 0.0000e+00\n",
      "Epoch 00207: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9451 - accuracy: 0.5901 - recall_26: 0.0098 - recall_27: 0.0000e+00 - precision_26: 0.3571 - precision_27: 0.0000e+00 - val_loss: 1.0096 - val_accuracy: 0.5026 - val_recall_26: 0.0420 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4286 - val_precision_27: 0.0000e+00 - lr: 0.0097\n",
      "Epoch 208/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0120 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0033 - accuracy: 0.5293 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.1667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9474 - accuracy: 0.5860 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.4667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9408 - accuracy: 0.5949 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.3810 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9471 - accuracy: 0.5872 - recall_26: 0.0095 - recall_27: 0.0000e+00 - precision_26: 0.3824 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9094 - accuracy: 0.6220 - recall_26: 0.0099 - recall_27: 0.0000e+00 - precision_26: 0.3810 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9393 - accuracy: 0.5950 - recall_26: 0.0102 - recall_27: 0.0000e+00 - precision_26: 0.3818 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9439 - accuracy: 0.5910 - recall_26: 0.0101 - recall_27: 0.0000e+00 - precision_26: 0.3810 - precision_27: 0.0000e+00\n",
      "Epoch 00208: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9453 - accuracy: 0.5899 - recall_26: 0.0098 - recall_27: 0.0000e+00 - precision_26: 0.3906 - precision_27: 0.0000e+00 - val_loss: 1.0098 - val_accuracy: 0.5020 - val_recall_26: 0.0382 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4286 - val_precision_27: 0.0000e+00 - lr: 0.0097\n",
      "Epoch 209/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0094 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 1.0000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0024 - accuracy: 0.5293 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9625 - accuracy: 0.5698 - recall_26: 0.0042 - recall_27: 0.0000e+00 - precision_26: 0.3750 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9423 - accuracy: 0.5917 - recall_26: 0.0072 - recall_27: 0.0000e+00 - precision_26: 0.4375 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9463 - accuracy: 0.5875 - recall_26: 0.0102 - recall_27: 0.0000e+00 - precision_26: 0.4242 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9259 - accuracy: 0.6078 - recall_26: 0.0097 - recall_27: 0.0000e+00 - precision_26: 0.3659 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9206 - accuracy: 0.6125 - recall_26: 0.0091 - recall_27: 0.0000e+00 - precision_26: 0.3721 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9432 - accuracy: 0.5909 - recall_26: 0.0089 - recall_27: 0.0000e+00 - precision_26: 0.3636 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9449 - accuracy: 0.5899 - recall_26: 0.0086 - recall_27: 0.0000e+00 - precision_26: 0.3667 - precision_27: 0.0000e+00\n",
      "Epoch 00209: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9449 - accuracy: 0.5899 - recall_26: 0.0086 - recall_27: 0.0000e+00 - precision_26: 0.3667 - precision_27: 0.0000e+00 - val_loss: 1.0094 - val_accuracy: 0.5024 - val_recall_26: 0.0408 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4324 - val_precision_27: 0.0000e+00 - lr: 0.0097\n",
      "Epoch 210/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0110 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0041 - accuracy: 0.5293 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.1667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9634 - accuracy: 0.5698 - recall_26: 0.0042 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9409 - accuracy: 0.5946 - recall_26: 0.0056 - recall_27: 0.0000e+00 - precision_26: 0.3529 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9468 - accuracy: 0.5871 - recall_26: 0.0080 - recall_27: 0.0000e+00 - precision_26: 0.3793 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9261 - accuracy: 0.6075 - recall_26: 0.0077 - recall_27: 0.0000e+00 - precision_26: 0.3529 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9376 - accuracy: 0.5960 - recall_26: 0.0073 - recall_27: 0.0000e+00 - precision_26: 0.3500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9431 - accuracy: 0.5908 - recall_26: 0.0085 - recall_27: 0.0000e+00 - precision_26: 0.3654 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9451 - accuracy: 0.5898 - recall_26: 0.0078 - recall_27: 0.0000e+00 - precision_26: 0.3571 - precision_27: 0.0000e+00\n",
      "Epoch 00210: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9451 - accuracy: 0.5898 - recall_26: 0.0078 - recall_27: 0.0000e+00 - precision_26: 0.3571 - precision_27: 0.0000e+00 - val_loss: 1.0103 - val_accuracy: 0.5023 - val_recall_26: 0.0408 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4295 - val_precision_27: 0.0000e+00 - lr: 0.0097\n",
      "Epoch 211/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0086 - accuracy: 0.5308 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 1.0000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0029 - accuracy: 0.5303 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9631 - accuracy: 0.5701 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.3571 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9401 - accuracy: 0.5949 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.3478 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9386 - accuracy: 0.5964 - recall_26: 0.0095 - recall_27: 0.0000e+00 - precision_26: 0.3500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9083 - accuracy: 0.6222 - recall_26: 0.0099 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9370 - accuracy: 0.5965 - recall_26: 0.0105 - recall_27: 0.0000e+00 - precision_26: 0.3571 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9426 - accuracy: 0.5909 - recall_26: 0.0103 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9444 - accuracy: 0.5898 - recall_26: 0.0090 - recall_27: 0.0000e+00 - precision_26: 0.3194 - precision_27: 0.0000e+00\n",
      "Epoch 00211: val_loss did not improve from 1.00875\n",
      "\n",
      "Epoch 00211: ReduceLROnPlateau reducing learning rate to 0.007730940729379654.\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9444 - accuracy: 0.5898 - recall_26: 0.0090 - recall_27: 0.0000e+00 - precision_26: 0.3194 - precision_27: 0.0000e+00 - val_loss: 1.0096 - val_accuracy: 0.5020 - val_recall_26: 0.0446 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4118 - val_precision_27: 0.0000e+00 - lr: 0.0097\n",
      "Epoch 212/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0092 - accuracy: 0.5293 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0026 - accuracy: 0.5283 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.1818 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9625 - accuracy: 0.5689 - recall_26: 0.0056 - recall_27: 0.0000e+00 - precision_26: 0.2667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9402 - accuracy: 0.5942 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9463 - accuracy: 0.5865 - recall_26: 0.0102 - recall_27: 0.0000e+00 - precision_26: 0.2979 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9256 - accuracy: 0.6069 - recall_26: 0.0097 - recall_27: 0.0000e+00 - precision_26: 0.2778 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9201 - accuracy: 0.6120 - recall_26: 0.0108 - recall_27: 0.0000e+00 - precision_26: 0.3115 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9424 - accuracy: 0.5912 - recall_26: 0.0134 - recall_27: 0.0000e+00 - precision_26: 0.3704 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9442 - accuracy: 0.5901 - recall_26: 0.0126 - recall_27: 0.0000e+00 - precision_26: 0.3678 - precision_27: 0.0000e+00\n",
      "Epoch 00212: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9442 - accuracy: 0.5901 - recall_26: 0.0126 - recall_27: 0.0000e+00 - precision_26: 0.3678 - precision_27: 0.0000e+00 - val_loss: 1.0098 - val_accuracy: 0.5023 - val_recall_26: 0.0503 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4051 - val_precision_27: 0.0000e+00 - lr: 0.0077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 213/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0109 - accuracy: 0.5323 - recall_26: 0.0242 - recall_27: 0.0000e+00 - precision_26: 0.7500 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0030 - accuracy: 0.5298 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9468 - accuracy: 0.5855 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.3810 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9403 - accuracy: 0.5944 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.3103 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9391 - accuracy: 0.5962 - recall_26: 0.0123 - recall_27: 0.0000e+00 - precision_26: 0.3462 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9209 - accuracy: 0.6125 - recall_26: 0.0131 - recall_27: 0.0000e+00 - precision_26: 0.3710 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9388 - accuracy: 0.5955 - recall_26: 0.0155 - recall_27: 0.0000e+00 - precision_26: 0.3951 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9431 - accuracy: 0.5913 - recall_26: 0.0147 - recall_27: 0.0000e+00 - precision_26: 0.3846 - precision_27: 0.0000e+00\n",
      "Epoch 00213: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9446 - accuracy: 0.5902 - recall_26: 0.0141 - recall_27: 0.0000e+00 - precision_26: 0.3913 - precision_27: 0.0000e+00 - val_loss: 1.0111 - val_accuracy: 0.5020 - val_recall_26: 0.0503 - val_recall_27: 0.0000e+00 - val_precision_26: 0.3990 - val_precision_27: 0.0000e+00 - lr: 0.0077\n",
      "Epoch 214/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0083 - accuracy: 0.5337 - recall_26: 0.0323 - recall_27: 0.0000e+00 - precision_26: 0.8000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0028 - accuracy: 0.5298 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.3846 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9623 - accuracy: 0.5698 - recall_26: 0.0111 - recall_27: 0.0000e+00 - precision_26: 0.4211 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9405 - accuracy: 0.5948 - recall_26: 0.0112 - recall_27: 0.0000e+00 - precision_26: 0.3750 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9466 - accuracy: 0.5870 - recall_26: 0.0131 - recall_27: 0.0000e+00 - precision_26: 0.3600 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9088 - accuracy: 0.6218 - recall_26: 0.0124 - recall_27: 0.0000e+00 - precision_26: 0.3509 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9373 - accuracy: 0.5961 - recall_26: 0.0136 - recall_27: 0.0000e+00 - precision_26: 0.3714 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9424 - accuracy: 0.5907 - recall_26: 0.0138 - recall_27: 0.0000e+00 - precision_26: 0.3647 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9442 - accuracy: 0.5897 - recall_26: 0.0126 - recall_27: 0.0000e+00 - precision_26: 0.3596 - precision_27: 0.0000e+00\n",
      "Epoch 00214: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9442 - accuracy: 0.5897 - recall_26: 0.0126 - recall_27: 0.0000e+00 - precision_26: 0.3596 - precision_27: 0.0000e+00 - val_loss: 1.0115 - val_accuracy: 0.5023 - val_recall_26: 0.0522 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4039 - val_precision_27: 0.0000e+00 - lr: 0.0077\n",
      "Epoch 215/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0111 - accuracy: 0.5308 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.6667 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0044 - accuracy: 0.5288 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9634 - accuracy: 0.5689 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.2941 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9413 - accuracy: 0.5942 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.2963 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9394 - accuracy: 0.5957 - recall_26: 0.0102 - recall_27: 0.0000e+00 - precision_26: 0.3061 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9093 - accuracy: 0.6215 - recall_26: 0.0099 - recall_27: 0.0000e+00 - precision_26: 0.2963 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9377 - accuracy: 0.5962 - recall_26: 0.0121 - recall_27: 0.0000e+00 - precision_26: 0.3538 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9429 - accuracy: 0.5908 - recall_26: 0.0125 - recall_27: 0.0000e+00 - precision_26: 0.3500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9446 - accuracy: 0.5897 - recall_26: 0.0114 - recall_27: 0.0000e+00 - precision_26: 0.3412 - precision_27: 0.0000e+00\n",
      "Epoch 00215: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9446 - accuracy: 0.5897 - recall_26: 0.0114 - recall_27: 0.0000e+00 - precision_26: 0.3412 - precision_27: 0.0000e+00 - val_loss: 1.0115 - val_accuracy: 0.5026 - val_recall_26: 0.0535 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4098 - val_precision_27: 0.0000e+00 - lr: 0.0077\n",
      "Epoch 216/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0093 - accuracy: 0.5337 - recall_26: 0.0403 - recall_27: 0.0000e+00 - precision_26: 0.7143 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0029 - accuracy: 0.5303 - recall_26: 0.0140 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9477 - accuracy: 0.5855 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9393 - accuracy: 0.5935 - recall_26: 0.0099 - recall_27: 0.0000e+00 - precision_26: 0.2727 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9258 - accuracy: 0.6072 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.3103 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9204 - accuracy: 0.6122 - recall_26: 0.0125 - recall_27: 0.0000e+00 - precision_26: 0.3492 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9425 - accuracy: 0.5908 - recall_26: 0.0143 - recall_27: 0.0000e+00 - precision_26: 0.3596 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9443 - accuracy: 0.5898 - recall_26: 0.0129 - recall_27: 0.0000e+00 - precision_26: 0.3548 - precision_27: 0.0000e+00\n",
      "Epoch 00216: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9443 - accuracy: 0.5898 - recall_26: 0.0129 - recall_27: 0.0000e+00 - precision_26: 0.3548 - precision_27: 0.0000e+00 - val_loss: 1.0115 - val_accuracy: 0.5026 - val_recall_26: 0.0535 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4098 - val_precision_27: 0.0000e+00 - lr: 0.0077\n",
      "Epoch 217/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0104 - accuracy: 0.5323 - recall_26: 0.0242 - recall_27: 0.0000e+00 - precision_26: 0.7500 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0035 - accuracy: 0.5298 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.3636 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9629 - accuracy: 0.5695 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.3529 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9435 - accuracy: 0.5913 - recall_26: 0.0083 - recall_27: 0.0000e+00 - precision_26: 0.3478 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9470 - accuracy: 0.5872 - recall_26: 0.0109 - recall_27: 0.0000e+00 - precision_26: 0.3571 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9259 - accuracy: 0.6075 - recall_26: 0.0109 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9204 - accuracy: 0.6123 - recall_26: 0.0102 - recall_27: 0.0000e+00 - precision_26: 0.3462 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9385 - accuracy: 0.5950 - recall_26: 0.0121 - recall_27: 0.0000e+00 - precision_26: 0.3623 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9443 - accuracy: 0.5898 - recall_26: 0.0106 - recall_27: 0.0000e+00 - precision_26: 0.3553 - precision_27: 0.0000e+00\n",
      "Epoch 00217: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9443 - accuracy: 0.5898 - recall_26: 0.0106 - recall_27: 0.0000e+00 - precision_26: 0.3553 - precision_27: 0.0000e+00 - val_loss: 1.0118 - val_accuracy: 0.5024 - val_recall_26: 0.0535 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4078 - val_precision_27: 0.0000e+00 - lr: 0.0077\n",
      "Epoch 218/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0108 - accuracy: 0.5308 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.6667 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0040 - accuracy: 0.5288 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9479 - accuracy: 0.5853 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.3810 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9409 - accuracy: 0.5942 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.3103 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9392 - accuracy: 0.5954 - recall_26: 0.0102 - recall_27: 0.0000e+00 - precision_26: 0.3061 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9209 - accuracy: 0.6118 - recall_26: 0.0097 - recall_27: 0.0000e+00 - precision_26: 0.3091 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9386 - accuracy: 0.5946 - recall_26: 0.0121 - recall_27: 0.0000e+00 - precision_26: 0.3378 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9446 - accuracy: 0.5894 - recall_26: 0.0110 - recall_27: 0.0000e+00 - precision_26: 0.3373 - precision_27: 0.0000e+00\n",
      "Epoch 00218: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9446 - accuracy: 0.5894 - recall_26: 0.0110 - recall_27: 0.0000e+00 - precision_26: 0.3373 - precision_27: 0.0000e+00 - val_loss: 1.0118 - val_accuracy: 0.5020 - val_recall_26: 0.0490 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4053 - val_precision_27: 0.0000e+00 - lr: 0.0077\n",
      "Epoch 219/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0120 - accuracy: 0.5279 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0039 - accuracy: 0.5288 - recall_26: 0.0023 - recall_27: 0.0000e+00 - precision_26: 0.1250 - precision_27: 0.0000e+00       - ETA: 0s - loss: 0.9481 - accuracy: 0.5853 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9412 - accuracy: 0.5946 - recall_26: 0.0066 - recall_27: 0.0000e+00 - precision_26: 0.3043 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9471 - accuracy: 0.5868 - recall_26: 0.0088 - recall_27: 0.0000e+00 - precision_26: 0.3077 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9089 - accuracy: 0.6217 - recall_26: 0.0087 - recall_27: 0.0000e+00 - precision_26: 0.2979 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9374 - accuracy: 0.5960 - recall_26: 0.0089 - recall_27: 0.0000e+00 - precision_26: 0.3148 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9430 - accuracy: 0.5907 - recall_26: 0.0080 - recall_27: 0.0000e+00 - precision_26: 0.2879 - precision_27: 0.0000e+00\n",
      "Epoch 00219: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9445 - accuracy: 0.5896 - recall_26: 0.0078 - recall_27: 0.0000e+00 - precision_26: 0.2985 - precision_27: 0.0000e+00 - val_loss: 1.0112 - val_accuracy: 0.5015 - val_recall_26: 0.0452 - val_recall_27: 0.0000e+00 - val_precision_26: 0.3989 - val_precision_27: 0.0000e+00 - lr: 0.0077\n",
      "Epoch 220/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0104 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0046 - accuracy: 0.5288 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9627 - accuracy: 0.5689 - recall_26: 0.0056 - recall_27: 0.0000e+00 - precision_26: 0.2667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9404 - accuracy: 0.5944 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.3200 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9464 - accuracy: 0.5868 - recall_26: 0.0102 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9255 - accuracy: 0.6070 - recall_26: 0.0097 - recall_27: 0.0000e+00 - precision_26: 0.2941 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9369 - accuracy: 0.5960 - recall_26: 0.0110 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9422 - accuracy: 0.5907 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.3377 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9443 - accuracy: 0.5897 - recall_26: 0.0106 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00\n",
      "Epoch 00220: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9443 - accuracy: 0.5897 - recall_26: 0.0106 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00 - val_loss: 1.0108 - val_accuracy: 0.5013 - val_recall_26: 0.0465 - val_recall_27: 0.0000e+00 - val_precision_26: 0.3989 - val_precision_27: 0.0000e+00 - lr: 0.0077\n",
      "Epoch 221/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0107 - accuracy: 0.5279 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0042 - accuracy: 0.5283 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.1818 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9479 - accuracy: 0.5850 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9395 - accuracy: 0.5934 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.2647 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9390 - accuracy: 0.5953 - recall_26: 0.0089 - recall_27: 0.0000e+00 - precision_26: 0.2889 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9203 - accuracy: 0.6115 - recall_26: 0.0080 - recall_27: 0.0000e+00 - precision_26: 0.2800 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9382 - accuracy: 0.5943 - recall_26: 0.0092 - recall_27: 0.0000e+00 - precision_26: 0.2923 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9440 - accuracy: 0.5891 - recall_26: 0.0082 - recall_27: 0.0000e+00 - precision_26: 0.2838 - precision_27: 0.0000e+00\n",
      "Epoch 00221: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9440 - accuracy: 0.5891 - recall_26: 0.0082 - recall_27: 0.0000e+00 - precision_26: 0.2838 - precision_27: 0.0000e+00 - val_loss: 1.0109 - val_accuracy: 0.5011 - val_recall_26: 0.0459 - val_recall_27: 0.0000e+00 - val_precision_26: 0.3934 - val_precision_27: 0.0000e+00 - lr: 0.0077\n",
      "Epoch 222/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0098 - accuracy: 0.5279 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0044 - accuracy: 0.5288 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9484 - accuracy: 0.5855 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9413 - accuracy: 0.5946 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.3462 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9473 - accuracy: 0.5871 - recall_26: 0.0109 - recall_27: 0.0000e+00 - precision_26: 0.3571 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9260 - accuracy: 0.6075 - recall_26: 0.0103 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9207 - accuracy: 0.6123 - recall_26: 0.0097 - recall_27: 0.0000e+00 - precision_26: 0.3400 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9428 - accuracy: 0.5908 - recall_26: 0.0112 - recall_27: 0.0000e+00 - precision_26: 0.3472 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9444 - accuracy: 0.5898 - recall_26: 0.0102 - recall_27: 0.0000e+00 - precision_26: 0.3421 - precision_27: 0.0000e+00\n",
      "Epoch 00222: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9444 - accuracy: 0.5898 - recall_26: 0.0102 - recall_27: 0.0000e+00 - precision_26: 0.3421 - precision_27: 0.0000e+00 - val_loss: 1.0108 - val_accuracy: 0.5020 - val_recall_26: 0.0452 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4057 - val_precision_27: 0.0000e+00 - lr: 0.0077\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0119 - accuracy: 0.5279 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0047 - accuracy: 0.5293 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.2727 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9624 - accuracy: 0.5695 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.3529 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9403 - accuracy: 0.5951 - recall_26: 0.0103 - recall_27: 0.0000e+00 - precision_26: 0.4074 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9384 - accuracy: 0.5965 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.3953 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9086 - accuracy: 0.6223 - recall_26: 0.0118 - recall_27: 0.0000e+00 - precision_26: 0.3800 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9382 - accuracy: 0.5952 - recall_26: 0.0121 - recall_27: 0.0000e+00 - precision_26: 0.3731 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9427 - accuracy: 0.5910 - recall_26: 0.0109 - recall_27: 0.0000e+00 - precision_26: 0.3514 - precision_27: 0.0000e+00\n",
      "Epoch 00223: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9441 - accuracy: 0.5899 - recall_26: 0.0106 - recall_27: 0.0000e+00 - precision_26: 0.3600 - precision_27: 0.0000e+00 - val_loss: 1.0109 - val_accuracy: 0.5016 - val_recall_26: 0.0452 - val_recall_27: 0.0000e+00 - val_precision_26: 0.3989 - val_precision_27: 0.0000e+00 - lr: 0.0077\n",
      "Epoch 224/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0100 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0032 - accuracy: 0.5288 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9622 - accuracy: 0.5689 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.2941 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9403 - accuracy: 0.5944 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9464 - accuracy: 0.5868 - recall_26: 0.0109 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9084 - accuracy: 0.6216 - recall_26: 0.0105 - recall_27: 0.0000e+00 - precision_26: 0.3269 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9369 - accuracy: 0.5959 - recall_26: 0.0110 - recall_27: 0.0000e+00 - precision_26: 0.3443 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9424 - accuracy: 0.5905 - recall_26: 0.0112 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9443 - accuracy: 0.5894 - recall_26: 0.0102 - recall_27: 0.0000e+00 - precision_26: 0.3250 - precision_27: 0.0000e+00\n",
      "Epoch 00224: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9443 - accuracy: 0.5894 - recall_26: 0.0102 - recall_27: 0.0000e+00 - precision_26: 0.3250 - precision_27: 0.0000e+00 - val_loss: 1.0111 - val_accuracy: 0.5015 - val_recall_26: 0.0452 - val_recall_27: 0.0000e+00 - val_precision_26: 0.3966 - val_precision_27: 0.0000e+00 - lr: 0.0077\n",
      "Epoch 225/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0107 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0032 - accuracy: 0.5283 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.1818 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9469 - accuracy: 0.5850 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.3500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9402 - accuracy: 0.5942 - recall_26: 0.0075 - recall_27: 0.0000e+00 - precision_26: 0.2963 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9463 - accuracy: 0.5867 - recall_26: 0.0102 - recall_27: 0.0000e+00 - precision_26: 0.3256 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9254 - accuracy: 0.6070 - recall_26: 0.0103 - recall_27: 0.0000e+00 - precision_26: 0.3077 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9369 - accuracy: 0.5958 - recall_26: 0.0110 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9424 - accuracy: 0.5903 - recall_26: 0.0107 - recall_27: 0.0000e+00 - precision_26: 0.3158 - precision_27: 0.0000e+00\n",
      "Epoch 00225: val_loss did not improve from 1.00875\n",
      "\n",
      "Epoch 00225: ReduceLROnPlateau reducing learning rate to 0.00618475265800953.\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9442 - accuracy: 0.5892 - recall_26: 0.0098 - recall_27: 0.0000e+00 - precision_26: 0.3086 - precision_27: 0.0000e+00 - val_loss: 1.0113 - val_accuracy: 0.5011 - val_recall_26: 0.0452 - val_recall_27: 0.0000e+00 - val_precision_26: 0.3923 - val_precision_27: 0.0000e+00 - lr: 0.0077\n",
      "Epoch 226/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0139 - accuracy: 0.5293 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0037 - accuracy: 0.5293 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9619 - accuracy: 0.5695 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.3750 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9404 - accuracy: 0.5948 - recall_26: 0.0094 - recall_27: 0.0000e+00 - precision_26: 0.3704 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9467 - accuracy: 0.5871 - recall_26: 0.0109 - recall_27: 0.0000e+00 - precision_26: 0.3488 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9085 - accuracy: 0.6218 - recall_26: 0.0112 - recall_27: 0.0000e+00 - precision_26: 0.3396 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9366 - accuracy: 0.5962 - recall_26: 0.0121 - recall_27: 0.0000e+00 - precision_26: 0.3651 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9424 - accuracy: 0.5909 - recall_26: 0.0117 - recall_27: 0.0000e+00 - precision_26: 0.3544 - precision_27: 0.0000e+00\n",
      "Epoch 00226: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9438 - accuracy: 0.5898 - recall_26: 0.0114 - recall_27: 0.0000e+00 - precision_26: 0.3625 - precision_27: 0.0000e+00 - val_loss: 1.0109 - val_accuracy: 0.5011 - val_recall_26: 0.0459 - val_recall_27: 0.0000e+00 - val_precision_26: 0.3956 - val_precision_27: 0.0000e+00 - lr: 0.0062\n",
      "Epoch 227/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0110 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0032 - accuracy: 0.5283 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.1818 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9470 - accuracy: 0.5853 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.3636 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9406 - accuracy: 0.5942 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.2903 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9386 - accuracy: 0.5956 - recall_26: 0.0102 - recall_27: 0.0000e+00 - precision_26: 0.2885 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9086 - accuracy: 0.6216 - recall_26: 0.0112 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9370 - accuracy: 0.5961 - recall_26: 0.0121 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9430 - accuracy: 0.5906 - recall_26: 0.0113 - recall_27: 0.0000e+00 - precision_26: 0.3103 - precision_27: 0.0000e+00\n",
      "Epoch 00227: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9444 - accuracy: 0.5895 - recall_26: 0.0110 - recall_27: 0.0000e+00 - precision_26: 0.3182 - precision_27: 0.0000e+00 - val_loss: 1.0108 - val_accuracy: 0.5011 - val_recall_26: 0.0459 - val_recall_27: 0.0000e+00 - val_precision_26: 0.3956 - val_precision_27: 0.0000e+00 - lr: 0.0062\n",
      "Epoch 228/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0101 - accuracy: 0.5308 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.6667 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0039 - accuracy: 0.5293 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.2727 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9627 - accuracy: 0.5692 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.3158 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9435 - accuracy: 0.5911 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.3462 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9388 - accuracy: 0.5935 - recall_26: 0.0091 - recall_27: 0.0000e+00 - precision_26: 0.2821 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9256 - accuracy: 0.6069 - recall_26: 0.0103 - recall_27: 0.0000e+00 - precision_26: 0.2963 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9201 - accuracy: 0.6115 - recall_26: 0.0091 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9419 - accuracy: 0.5903 - recall_26: 0.0112 - recall_27: 0.0000e+00 - precision_26: 0.3165 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9440 - accuracy: 0.5892 - recall_26: 0.0102 - recall_27: 0.0000e+00 - precision_26: 0.3095 - precision_27: 0.0000e+00\n",
      "Epoch 00228: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9440 - accuracy: 0.5892 - recall_26: 0.0102 - recall_27: 0.0000e+00 - precision_26: 0.3095 - precision_27: 0.0000e+00 - val_loss: 1.0109 - val_accuracy: 0.5011 - val_recall_26: 0.0459 - val_recall_27: 0.0000e+00 - val_precision_26: 0.3934 - val_precision_27: 0.0000e+00 - lr: 0.0062\n",
      "Epoch 229/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0123 - accuracy: 0.5279 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0051 - accuracy: 0.5279 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.1538 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9633 - accuracy: 0.5686 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.2632 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9437 - accuracy: 0.5909 - recall_26: 0.0083 - recall_27: 0.0000e+00 - precision_26: 0.3077 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9468 - accuracy: 0.5867 - recall_26: 0.0109 - recall_27: 0.0000e+00 - precision_26: 0.3125 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9256 - accuracy: 0.6074 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.3273 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9202 - accuracy: 0.6124 - recall_26: 0.0125 - recall_27: 0.0000e+00 - precision_26: 0.3667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9383 - accuracy: 0.5954 - recall_26: 0.0150 - recall_27: 0.0000e+00 - precision_26: 0.3924 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9425 - accuracy: 0.5913 - recall_26: 0.0138 - recall_27: 0.0000e+00 - precision_26: 0.3837 - precision_27: 0.0000e+00\n",
      "Epoch 00229: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9440 - accuracy: 0.5901 - recall_26: 0.0133 - recall_27: 0.0000e+00 - precision_26: 0.3864 - precision_27: 0.0000e+00 - val_loss: 1.0110 - val_accuracy: 0.5013 - val_recall_26: 0.0465 - val_recall_27: 0.0000e+00 - val_precision_26: 0.3967 - val_precision_27: 0.0000e+00 - lr: 0.0062\n",
      "Epoch 230/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0122 - accuracy: 0.5323 - recall_26: 0.0242 - recall_27: 0.0000e+00 - precision_26: 0.7500 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0040 - accuracy: 0.5298 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.3077 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9626 - accuracy: 0.5698 - recall_26: 0.0097 - recall_27: 0.0000e+00 - precision_26: 0.3500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9406 - accuracy: 0.5946 - recall_26: 0.0094 - recall_27: 0.0000e+00 - precision_26: 0.3226 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9469 - accuracy: 0.5868 - recall_26: 0.0117 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9260 - accuracy: 0.6072 - recall_26: 0.0109 - recall_27: 0.0000e+00 - precision_26: 0.3148 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9206 - accuracy: 0.6118 - recall_26: 0.0097 - recall_27: 0.0000e+00 - precision_26: 0.2982 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9426 - accuracy: 0.5907 - recall_26: 0.0121 - recall_27: 0.0000e+00 - precision_26: 0.3418 - precision_27: 0.0000e+00\n",
      "Epoch 00230: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9442 - accuracy: 0.5896 - recall_26: 0.0110 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00 - val_loss: 1.0114 - val_accuracy: 0.5011 - val_recall_26: 0.0465 - val_recall_27: 0.0000e+00 - val_precision_26: 0.3925 - val_precision_27: 0.0000e+00 - lr: 0.0062\n",
      "Epoch 231/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0128 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0046 - accuracy: 0.5283 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.1818 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9631 - accuracy: 0.5689 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.2778 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9406 - accuracy: 0.5944 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.3103 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9464 - accuracy: 0.5868 - recall_26: 0.0117 - recall_27: 0.0000e+00 - precision_26: 0.3265 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9254 - accuracy: 0.6072 - recall_26: 0.0109 - recall_27: 0.0000e+00 - precision_26: 0.2982 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9366 - accuracy: 0.5961 - recall_26: 0.0126 - recall_27: 0.0000e+00 - precision_26: 0.3429 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9420 - accuracy: 0.5907 - recall_26: 0.0125 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9441 - accuracy: 0.5896 - recall_26: 0.0114 - recall_27: 0.0000e+00 - precision_26: 0.3295 - precision_27: 0.0000e+00\n",
      "Epoch 00231: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9441 - accuracy: 0.5896 - recall_26: 0.0114 - recall_27: 0.0000e+00 - precision_26: 0.3295 - precision_27: 0.0000e+00 - val_loss: 1.0112 - val_accuracy: 0.5013 - val_recall_26: 0.0471 - val_recall_27: 0.0000e+00 - val_precision_26: 0.3957 - val_precision_27: 0.0000e+00 - lr: 0.0062\n",
      "Epoch 232/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0125 - accuracy: 0.5308 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.6667 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0038 - accuracy: 0.5293 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9623 - accuracy: 0.5692 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.3158 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9402 - accuracy: 0.5944 - recall_26: 0.0094 - recall_27: 0.0000e+00 - precision_26: 0.3125 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9466 - accuracy: 0.5868 - recall_26: 0.0117 - recall_27: 0.0000e+00 - precision_26: 0.3265 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9258 - accuracy: 0.6072 - recall_26: 0.0109 - recall_27: 0.0000e+00 - precision_26: 0.3091 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9204 - accuracy: 0.6118 - recall_26: 0.0102 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9383 - accuracy: 0.5950 - recall_26: 0.0136 - recall_27: 0.0000e+00 - precision_26: 0.3544 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9429 - accuracy: 0.5908 - recall_26: 0.0117 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00\n",
      "Epoch 00232: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9442 - accuracy: 0.5898 - recall_26: 0.0114 - recall_27: 0.0000e+00 - precision_26: 0.3412 - precision_27: 0.0000e+00 - val_loss: 1.0113 - val_accuracy: 0.5015 - val_recall_26: 0.0465 - val_recall_27: 0.0000e+00 - val_precision_26: 0.3967 - val_precision_27: 0.0000e+00 - lr: 0.0062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0120 - accuracy: 0.5293 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0040 - accuracy: 0.5298 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9623 - accuracy: 0.5704 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9430 - accuracy: 0.5922 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.4286 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9459 - accuracy: 0.5874 - recall_26: 0.0109 - recall_27: 0.0000e+00 - precision_26: 0.3571 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9248 - accuracy: 0.6078 - recall_26: 0.0109 - recall_27: 0.0000e+00 - precision_26: 0.3400 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9194 - accuracy: 0.6123 - recall_26: 0.0102 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9415 - accuracy: 0.5913 - recall_26: 0.0134 - recall_27: 0.0000e+00 - precision_26: 0.3797 - precision_27: 0.0000e+00\n",
      "Epoch 00233: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9431 - accuracy: 0.5901 - recall_26: 0.0122 - recall_27: 0.0000e+00 - precision_26: 0.3690 - precision_27: 0.0000e+00 - val_loss: 1.0105 - val_accuracy: 0.5020 - val_recall_26: 0.0497 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4021 - val_precision_27: 0.0000e+00 - lr: 0.0062\n",
      "Epoch 234/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0102 - accuracy: 0.5308 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.6667 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0021 - accuracy: 0.5288 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.2308 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9608 - accuracy: 0.5692 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.3158 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9395 - accuracy: 0.5946 - recall_26: 0.0112 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9459 - accuracy: 0.5870 - recall_26: 0.0131 - recall_27: 0.0000e+00 - precision_26: 0.3214 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9077 - accuracy: 0.6222 - recall_26: 0.0149 - recall_27: 0.0000e+00 - precision_26: 0.3380 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9362 - accuracy: 0.5965 - recall_26: 0.0162 - recall_27: 0.0000e+00 - precision_26: 0.3647 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9419 - accuracy: 0.5911 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.3600 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9438 - accuracy: 0.5898 - recall_26: 0.0145 - recall_27: 0.0000e+00 - precision_26: 0.3491 - precision_27: 0.0000e+00\n",
      "Epoch 00234: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9438 - accuracy: 0.5898 - recall_26: 0.0145 - recall_27: 0.0000e+00 - precision_26: 0.3491 - precision_27: 0.0000e+00 - val_loss: 1.0103 - val_accuracy: 0.5028 - val_recall_26: 0.0541 - val_recall_27: 6.5920e-04 - val_precision_26: 0.4106 - val_precision_27: 1.0000 - lr: 0.0062\n",
      "Epoch 235/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0111 - accuracy: 0.5308 - recall_26: 0.0242 - recall_27: 0.0000e+00 - precision_26: 0.6000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0027 - accuracy: 0.5293 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9622 - accuracy: 0.5692 - recall_26: 0.0097 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9428 - accuracy: 0.5911 - recall_26: 0.0104 - recall_27: 0.0000e+00 - precision_26: 0.3448 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9460 - accuracy: 0.5867 - recall_26: 0.0124 - recall_27: 0.0000e+00 - precision_26: 0.3208 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9252 - accuracy: 0.6073 - recall_26: 0.0129 - recall_27: 0.0000e+00 - precision_26: 0.3226 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9199 - accuracy: 0.6122 - recall_26: 0.0137 - recall_27: 0.0000e+00 - precision_26: 0.3429 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9383 - accuracy: 0.5951 - recall_26: 0.0160 - recall_27: 0.0000e+00 - precision_26: 0.3667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9443 - accuracy: 0.5898 - recall_26: 0.0145 - recall_27: 0.0000e+00 - precision_26: 0.3627 - precision_27: 0.0000e+00\n",
      "Epoch 00235: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9443 - accuracy: 0.5898 - recall_26: 0.0145 - recall_27: 0.0000e+00 - precision_26: 0.3627 - precision_27: 0.0000e+00 - val_loss: 1.0103 - val_accuracy: 0.5016 - val_recall_26: 0.0478 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4032 - val_precision_27: 0.0000e+00 - lr: 0.0062\n",
      "Epoch 236/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0089 - accuracy: 0.5323 - recall_26: 0.0242 - recall_27: 0.0000e+00 - precision_26: 0.7500 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0033 - accuracy: 0.5293 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.3077 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9469 - accuracy: 0.5855 - recall_26: 0.0104 - recall_27: 0.0000e+00 - precision_26: 0.4091 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9401 - accuracy: 0.5944 - recall_26: 0.0094 - recall_27: 0.0000e+00 - precision_26: 0.3226 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9458 - accuracy: 0.5865 - recall_26: 0.0109 - recall_27: 0.0000e+00 - precision_26: 0.3061 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9080 - accuracy: 0.6215 - recall_26: 0.0118 - recall_27: 0.0000e+00 - precision_26: 0.3115 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9365 - accuracy: 0.5962 - recall_26: 0.0136 - recall_27: 0.0000e+00 - precision_26: 0.3611 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9418 - accuracy: 0.5908 - recall_26: 0.0138 - recall_27: 0.0000e+00 - precision_26: 0.3563 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9438 - accuracy: 0.5897 - recall_26: 0.0126 - recall_27: 0.0000e+00 - precision_26: 0.3478 - precision_27: 0.0000e+00\n",
      "Epoch 00236: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9438 - accuracy: 0.5897 - recall_26: 0.0126 - recall_27: 0.0000e+00 - precision_26: 0.3478 - precision_27: 0.0000e+00 - val_loss: 1.0108 - val_accuracy: 0.5016 - val_recall_26: 0.0452 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4011 - val_precision_27: 0.0000e+00 - lr: 0.0062\n",
      "Epoch 237/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0126 - accuracy: 0.5279 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0043 - accuracy: 0.5283 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.1667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9626 - accuracy: 0.5689 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.2632 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9405 - accuracy: 0.5944 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9464 - accuracy: 0.5868 - recall_26: 0.0109 - recall_27: 0.0000e+00 - precision_26: 0.3191 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9086 - accuracy: 0.6216 - recall_26: 0.0105 - recall_27: 0.0000e+00 - precision_26: 0.3036 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9368 - accuracy: 0.5959 - recall_26: 0.0110 - recall_27: 0.0000e+00 - precision_26: 0.3231 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9423 - accuracy: 0.5908 - recall_26: 0.0125 - recall_27: 0.0000e+00 - precision_26: 0.3457 - precision_27: 0.0000e+00\n",
      "Epoch 00237: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9442 - accuracy: 0.5898 - recall_26: 0.0118 - recall_27: 0.0000e+00 - precision_26: 0.3488 - precision_27: 0.0000e+00 - val_loss: 1.0113 - val_accuracy: 0.5018 - val_recall_26: 0.0452 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4057 - val_precision_27: 0.0000e+00 - lr: 0.0062\n",
      "Epoch 238/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0113 - accuracy: 0.5308 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.6667 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0030 - accuracy: 0.5288 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9623 - accuracy: 0.5692 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9429 - accuracy: 0.5909 - recall_26: 0.0083 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9388 - accuracy: 0.5934 - recall_26: 0.0083 - recall_27: 0.0000e+00 - precision_26: 0.2632 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9388 - accuracy: 0.5953 - recall_26: 0.0102 - recall_27: 0.0000e+00 - precision_26: 0.2830 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9205 - accuracy: 0.6118 - recall_26: 0.0108 - recall_27: 0.0000e+00 - precision_26: 0.3115 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9424 - accuracy: 0.5906 - recall_26: 0.0121 - recall_27: 0.0000e+00 - precision_26: 0.3293 - precision_27: 0.0000e+00\n",
      "Epoch 00238: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9442 - accuracy: 0.5895 - recall_26: 0.0110 - recall_27: 0.0000e+00 - precision_26: 0.3256 - precision_27: 0.0000e+00 - val_loss: 1.0118 - val_accuracy: 0.5020 - val_recall_26: 0.0459 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4091 - val_precision_27: 0.0000e+00 - lr: 0.0062\n",
      "Epoch 239/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0091 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0028 - accuracy: 0.5288 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.2000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9624 - accuracy: 0.5692 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.3125 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9405 - accuracy: 0.5946 - recall_26: 0.0094 - recall_27: 0.0000e+00 - precision_26: 0.3571 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9468 - accuracy: 0.5867 - recall_26: 0.0109 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9258 - accuracy: 0.6072 - recall_26: 0.0109 - recall_27: 0.0000e+00 - precision_26: 0.3208 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9371 - accuracy: 0.5962 - recall_26: 0.0131 - recall_27: 0.0000e+00 - precision_26: 0.3731 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9424 - accuracy: 0.5909 - recall_26: 0.0138 - recall_27: 0.0000e+00 - precision_26: 0.3735 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9443 - accuracy: 0.5898 - recall_26: 0.0126 - recall_27: 0.0000e+00 - precision_26: 0.3636 - precision_27: 0.0000e+00\n",
      "Epoch 00239: val_loss did not improve from 1.00875\n",
      "\n",
      "Epoch 00239: ReduceLROnPlateau reducing learning rate to 0.004947802051901817.\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9443 - accuracy: 0.5898 - recall_26: 0.0126 - recall_27: 0.0000e+00 - precision_26: 0.3636 - precision_27: 0.0000e+00 - val_loss: 1.0118 - val_accuracy: 0.5020 - val_recall_26: 0.0459 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4091 - val_precision_27: 0.0000e+00 - lr: 0.0062\n",
      "Epoch 240/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0097 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0035 - accuracy: 0.5283 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.1818 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9621 - accuracy: 0.5689 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.2941 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9400 - accuracy: 0.5944 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9463 - accuracy: 0.5868 - recall_26: 0.0109 - recall_27: 0.0000e+00 - precision_26: 0.3409 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9255 - accuracy: 0.6072 - recall_26: 0.0109 - recall_27: 0.0000e+00 - precision_26: 0.3208 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9201 - accuracy: 0.6120 - recall_26: 0.0108 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9382 - accuracy: 0.5949 - recall_26: 0.0131 - recall_27: 0.0000e+00 - precision_26: 0.3600 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9427 - accuracy: 0.5908 - recall_26: 0.0121 - recall_27: 0.0000e+00 - precision_26: 0.3494 - precision_27: 0.0000e+00\n",
      "Epoch 00240: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9439 - accuracy: 0.5898 - recall_26: 0.0118 - recall_27: 0.0000e+00 - precision_26: 0.3571 - precision_27: 0.0000e+00 - val_loss: 1.0117 - val_accuracy: 0.5011 - val_recall_26: 0.0452 - val_recall_27: 0.0000e+00 - val_precision_26: 0.3944 - val_precision_27: 0.0000e+00 - lr: 0.0049\n",
      "Epoch 241/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0116 - accuracy: 0.5293 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9737 - accuracy: 0.5590 - recall_26: 0.0100 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9432 - accuracy: 0.5913 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.3750 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9390 - accuracy: 0.5935 - recall_26: 0.0091 - recall_27: 0.0000e+00 - precision_26: 0.2895 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9257 - accuracy: 0.6070 - recall_26: 0.0109 - recall_27: 0.0000e+00 - precision_26: 0.3036 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9370 - accuracy: 0.5957 - recall_26: 0.0115 - recall_27: 0.0000e+00 - precision_26: 0.3284 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9423 - accuracy: 0.5904 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.3210 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9441 - accuracy: 0.5893 - recall_26: 0.0106 - recall_27: 0.0000e+00 - precision_26: 0.3140 - precision_27: 0.0000e+00\n",
      "Epoch 00241: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9441 - accuracy: 0.5893 - recall_26: 0.0106 - recall_27: 0.0000e+00 - precision_26: 0.3140 - precision_27: 0.0000e+00 - val_loss: 1.0114 - val_accuracy: 0.5011 - val_recall_26: 0.0465 - val_recall_27: 0.0000e+00 - val_precision_26: 0.3946 - val_precision_27: 0.0000e+00 - lr: 0.0049\n",
      "Epoch 242/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0092 - accuracy: 0.5308 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.6667 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0028 - accuracy: 0.5293 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9474 - accuracy: 0.5855 - recall_26: 0.0104 - recall_27: 0.0000e+00 - precision_26: 0.3913 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9405 - accuracy: 0.5944 - recall_26: 0.0094 - recall_27: 0.0000e+00 - precision_26: 0.3226 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9383 - accuracy: 0.5954 - recall_26: 0.0109 - recall_27: 0.0000e+00 - precision_26: 0.2963 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9199 - accuracy: 0.6115 - recall_26: 0.0097 - recall_27: 0.0000e+00 - precision_26: 0.2833 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9377 - accuracy: 0.5945 - recall_26: 0.0126 - recall_27: 0.0000e+00 - precision_26: 0.3210 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9420 - accuracy: 0.5904 - recall_26: 0.0121 - recall_27: 0.0000e+00 - precision_26: 0.3187 - precision_27: 0.0000e+00\n",
      "Epoch 00242: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9435 - accuracy: 0.5893 - recall_26: 0.0118 - recall_27: 0.0000e+00 - precision_26: 0.3226 - precision_27: 0.0000e+00 - val_loss: 1.0107 - val_accuracy: 0.5021 - val_recall_26: 0.0510 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4061 - val_precision_27: 0.0000e+00 - lr: 0.0049\n",
      "Epoch 243/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0108 - accuracy: 0.5352 - recall_26: 0.0403 - recall_27: 0.0000e+00 - precision_26: 0.8333 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0030 - accuracy: 0.5313 - recall_26: 0.0163 - recall_27: 0.0000e+00 - precision_26: 0.4375 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9617 - accuracy: 0.5707 - recall_26: 0.0139 - recall_27: 0.0000e+00 - precision_26: 0.4545 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9400 - accuracy: 0.5953 - recall_26: 0.0131 - recall_27: 0.0000e+00 - precision_26: 0.4118 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9463 - accuracy: 0.5875 - recall_26: 0.0153 - recall_27: 0.0000e+00 - precision_26: 0.3889 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9254 - accuracy: 0.6079 - recall_26: 0.0148 - recall_27: 0.0000e+00 - precision_26: 0.3770 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9367 - accuracy: 0.5968 - recall_26: 0.0178 - recall_27: 0.0000e+00 - precision_26: 0.4146 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9426 - accuracy: 0.5914 - recall_26: 0.0163 - recall_27: 0.0000e+00 - precision_26: 0.3900 - precision_27: 0.0000e+00\n",
      "Epoch 00243: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9440 - accuracy: 0.5902 - recall_26: 0.0157 - recall_27: 0.0000e+00 - precision_26: 0.3922 - precision_27: 0.0000e+00 - val_loss: 1.0100 - val_accuracy: 0.5026 - val_recall_26: 0.0535 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4118 - val_precision_27: 0.0000e+00 - lr: 0.0049\n",
      "Epoch 244/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0089 - accuracy: 0.5337 - recall_26: 0.0323 - recall_27: 0.0000e+00 - precision_26: 0.6667 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0030 - accuracy: 0.5303 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.3571 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9612 - accuracy: 0.5698 - recall_26: 0.0111 - recall_27: 0.0000e+00 - precision_26: 0.3636 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9395 - accuracy: 0.5946 - recall_26: 0.0112 - recall_27: 0.0000e+00 - precision_26: 0.3429 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9460 - accuracy: 0.5865 - recall_26: 0.0131 - recall_27: 0.0000e+00 - precision_26: 0.3214 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9252 - accuracy: 0.6067 - recall_26: 0.0122 - recall_27: 0.0000e+00 - precision_26: 0.2923 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9199 - accuracy: 0.6115 - recall_26: 0.0119 - recall_27: 0.0000e+00 - precision_26: 0.2958 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9377 - accuracy: 0.5948 - recall_26: 0.0165 - recall_27: 0.0000e+00 - precision_26: 0.3542 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9436 - accuracy: 0.5894 - recall_26: 0.0137 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00\n",
      "Epoch 00244: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9436 - accuracy: 0.5894 - recall_26: 0.0137 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00 - val_loss: 1.0097 - val_accuracy: 0.5024 - val_recall_26: 0.0529 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4129 - val_precision_27: 0.0000e+00 - lr: 0.0049\n",
      "Epoch 245/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0101 - accuracy: 0.5323 - recall_26: 0.0323 - recall_27: 0.0000e+00 - precision_26: 0.6667 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0028 - accuracy: 0.5298 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9619 - accuracy: 0.5698 - recall_26: 0.0111 - recall_27: 0.0000e+00 - precision_26: 0.3636 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9428 - accuracy: 0.5917 - recall_26: 0.0124 - recall_27: 0.0000e+00 - precision_26: 0.3871 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9464 - accuracy: 0.5871 - recall_26: 0.0139 - recall_27: 0.0000e+00 - precision_26: 0.3519 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9086 - accuracy: 0.6218 - recall_26: 0.0143 - recall_27: 0.0000e+00 - precision_26: 0.3382 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9368 - accuracy: 0.5965 - recall_26: 0.0168 - recall_27: 0.0000e+00 - precision_26: 0.3810 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9421 - accuracy: 0.5912 - recall_26: 0.0165 - recall_27: 0.0000e+00 - precision_26: 0.3776 - precision_27: 0.0000e+00\n",
      "Epoch 00245: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9439 - accuracy: 0.5899 - recall_26: 0.0149 - recall_27: 0.0000e+00 - precision_26: 0.3654 - precision_27: 0.0000e+00 - val_loss: 1.0098 - val_accuracy: 0.5026 - val_recall_26: 0.0529 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4171 - val_precision_27: 0.0000e+00 - lr: 0.0049\n",
      "Epoch 246/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0099 - accuracy: 0.5308 - recall_26: 0.0242 - recall_27: 0.0000e+00 - precision_26: 0.6000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9729 - accuracy: 0.5594 - recall_26: 0.0117 - recall_27: 0.0000e+00 - precision_26: 0.3500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9468 - accuracy: 0.5858 - recall_26: 0.0128 - recall_27: 0.0000e+00 - precision_26: 0.4074 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9398 - accuracy: 0.5946 - recall_26: 0.0112 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9461 - accuracy: 0.5867 - recall_26: 0.0131 - recall_27: 0.0000e+00 - precision_26: 0.3273 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9254 - accuracy: 0.6069 - recall_26: 0.0129 - recall_27: 0.0000e+00 - precision_26: 0.3030 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9365 - accuracy: 0.5963 - recall_26: 0.0162 - recall_27: 0.0000e+00 - precision_26: 0.3827 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9419 - accuracy: 0.5907 - recall_26: 0.0156 - recall_27: 0.0000e+00 - precision_26: 0.3646 - precision_27: 0.0000e+00\n",
      "Epoch 00246: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9438 - accuracy: 0.5895 - recall_26: 0.0141 - recall_27: 0.0000e+00 - precision_26: 0.3529 - precision_27: 0.0000e+00 - val_loss: 1.0102 - val_accuracy: 0.5023 - val_recall_26: 0.0522 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4121 - val_precision_27: 0.0000e+00 - lr: 0.0049\n",
      "Epoch 247/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0105 - accuracy: 0.5308 - recall_26: 0.0242 - recall_27: 0.0000e+00 - precision_26: 0.6000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0039 - accuracy: 0.5288 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9619 - accuracy: 0.5692 - recall_26: 0.0097 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9425 - accuracy: 0.5911 - recall_26: 0.0104 - recall_27: 0.0000e+00 - precision_26: 0.3448 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9385 - accuracy: 0.5934 - recall_26: 0.0099 - recall_27: 0.0000e+00 - precision_26: 0.2791 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9382 - accuracy: 0.5953 - recall_26: 0.0123 - recall_27: 0.0000e+00 - precision_26: 0.3051 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9196 - accuracy: 0.6115 - recall_26: 0.0114 - recall_27: 0.0000e+00 - precision_26: 0.3030 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9417 - accuracy: 0.5907 - recall_26: 0.0147 - recall_27: 0.0000e+00 - precision_26: 0.3548 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9435 - accuracy: 0.5894 - recall_26: 0.0133 - recall_27: 0.0000e+00 - precision_26: 0.3434 - precision_27: 0.0000e+00\n",
      "Epoch 00247: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9435 - accuracy: 0.5894 - recall_26: 0.0133 - recall_27: 0.0000e+00 - precision_26: 0.3434 - precision_27: 0.0000e+00 - val_loss: 1.0101 - val_accuracy: 0.5028 - val_recall_26: 0.0535 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4179 - val_precision_27: 0.0000e+00 - lr: 0.0049\n",
      "Epoch 248/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0077 - accuracy: 0.5308 - recall_26: 0.0242 - recall_27: 0.0000e+00 - precision_26: 0.6000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0022 - accuracy: 0.5288 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.2667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9622 - accuracy: 0.5689 - recall_26: 0.0097 - recall_27: 0.0000e+00 - precision_26: 0.3043 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9428 - accuracy: 0.5909 - recall_26: 0.0104 - recall_27: 0.0000e+00 - precision_26: 0.3226 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9462 - accuracy: 0.5867 - recall_26: 0.0124 - recall_27: 0.0000e+00 - precision_26: 0.3091 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9253 - accuracy: 0.6068 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9366 - accuracy: 0.5956 - recall_26: 0.0131 - recall_27: 0.0000e+00 - precision_26: 0.3165 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9421 - accuracy: 0.5906 - recall_26: 0.0143 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9441 - accuracy: 0.5894 - recall_26: 0.0129 - recall_27: 0.0000e+00 - precision_26: 0.3235 - precision_27: 0.0000e+00\n",
      "Epoch 00248: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9441 - accuracy: 0.5894 - recall_26: 0.0129 - recall_27: 0.0000e+00 - precision_26: 0.3235 - precision_27: 0.0000e+00 - val_loss: 1.0098 - val_accuracy: 0.5028 - val_recall_26: 0.0535 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4158 - val_precision_27: 0.0000e+00 - lr: 0.0049\n",
      "Epoch 249/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0087 - accuracy: 0.5308 - recall_26: 0.0242 - recall_27: 0.0000e+00 - precision_26: 0.6000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0029 - accuracy: 0.5288 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.2667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9471 - accuracy: 0.5855 - recall_26: 0.0128 - recall_27: 0.0000e+00 - precision_26: 0.3929 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9403 - accuracy: 0.5942 - recall_26: 0.0112 - recall_27: 0.0000e+00 - precision_26: 0.3243 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9385 - accuracy: 0.5953 - recall_26: 0.0129 - recall_27: 0.0000e+00 - precision_26: 0.3065 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9085 - accuracy: 0.6215 - recall_26: 0.0143 - recall_27: 0.0000e+00 - precision_26: 0.3239 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9368 - accuracy: 0.5960 - recall_26: 0.0152 - recall_27: 0.0000e+00 - precision_26: 0.3537 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9422 - accuracy: 0.5906 - recall_26: 0.0152 - recall_27: 0.0000e+00 - precision_26: 0.3469 - precision_27: 0.0000e+00\n",
      "Epoch 00249: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9441 - accuracy: 0.5895 - recall_26: 0.0141 - recall_27: 0.0000e+00 - precision_26: 0.3462 - precision_27: 0.0000e+00 - val_loss: 1.0101 - val_accuracy: 0.5020 - val_recall_26: 0.0490 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4096 - val_precision_27: 0.0000e+00 - lr: 0.0049\n",
      "Epoch 250/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0113 - accuracy: 0.5279 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0037 - accuracy: 0.5279 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.1538 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9623 - accuracy: 0.5683 - recall_26: 0.0056 - recall_27: 0.0000e+00 - precision_26: 0.2222 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9403 - accuracy: 0.5940 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.2903 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9464 - accuracy: 0.5862 - recall_26: 0.0109 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9253 - accuracy: 0.6064 - recall_26: 0.0109 - recall_27: 0.0000e+00 - precision_26: 0.2787 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9365 - accuracy: 0.5958 - recall_26: 0.0136 - recall_27: 0.0000e+00 - precision_26: 0.3421 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9420 - accuracy: 0.5905 - recall_26: 0.0143 - recall_27: 0.0000e+00 - precision_26: 0.3441 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9438 - accuracy: 0.5894 - recall_26: 0.0129 - recall_27: 0.0000e+00 - precision_26: 0.3367 - precision_27: 0.0000e+00\n",
      "Epoch 00250: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9438 - accuracy: 0.5894 - recall_26: 0.0129 - recall_27: 0.0000e+00 - precision_26: 0.3367 - precision_27: 0.0000e+00 - val_loss: 1.0100 - val_accuracy: 0.5016 - val_recall_26: 0.0465 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4033 - val_precision_27: 0.0000e+00 - lr: 0.0049\n",
      "Epoch 251/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0104 - accuracy: 0.5308 - recall_26: 0.0242 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0032 - accuracy: 0.5298 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.3125 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9627 - accuracy: 0.5698 - recall_26: 0.0111 - recall_27: 0.0000e+00 - precision_26: 0.3636 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9402 - accuracy: 0.5951 - recall_26: 0.0122 - recall_27: 0.0000e+00 - precision_26: 0.3824 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9466 - accuracy: 0.5875 - recall_26: 0.0146 - recall_27: 0.0000e+00 - precision_26: 0.3774 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9257 - accuracy: 0.6076 - recall_26: 0.0142 - recall_27: 0.0000e+00 - precision_26: 0.3438 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9368 - accuracy: 0.5968 - recall_26: 0.0162 - recall_27: 0.0000e+00 - precision_26: 0.3875 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9423 - accuracy: 0.5913 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.3750 - precision_27: 0.0000e+00\n",
      "Epoch 00251: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9443 - accuracy: 0.5901 - recall_26: 0.0145 - recall_27: 0.0000e+00 - precision_26: 0.3663 - precision_27: 0.0000e+00 - val_loss: 1.0100 - val_accuracy: 0.5015 - val_recall_26: 0.0459 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4000 - val_precision_27: 0.0000e+00 - lr: 0.0049\n",
      "Epoch 252/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0102 - accuracy: 0.5308 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.6667 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0038 - accuracy: 0.5303 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.3636 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9472 - accuracy: 0.5863 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.4762 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9384 - accuracy: 0.5945 - recall_26: 0.0108 - recall_27: 0.0000e+00 - precision_26: 0.3611 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9380 - accuracy: 0.5962 - recall_26: 0.0123 - recall_27: 0.0000e+00 - precision_26: 0.3673 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9198 - accuracy: 0.6126 - recall_26: 0.0125 - recall_27: 0.0000e+00 - precision_26: 0.3793 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9379 - accuracy: 0.5957 - recall_26: 0.0160 - recall_27: 0.0000e+00 - precision_26: 0.4074 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9425 - accuracy: 0.5915 - recall_26: 0.0151 - recall_27: 0.0000e+00 - precision_26: 0.3956 - precision_27: 0.0000e+00\n",
      "Epoch 00252: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9438 - accuracy: 0.5902 - recall_26: 0.0145 - recall_27: 0.0000e+00 - precision_26: 0.3936 - precision_27: 0.0000e+00 - val_loss: 1.0096 - val_accuracy: 0.5021 - val_recall_26: 0.0459 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4114 - val_precision_27: 0.0000e+00 - lr: 0.0049\n",
      "Epoch 253/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0106 - accuracy: 0.5293 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0025 - accuracy: 0.5298 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.3077 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9463 - accuracy: 0.5860 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.4348 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9378 - accuracy: 0.5938 - recall_26: 0.0099 - recall_27: 0.0000e+00 - precision_26: 0.3077 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9376 - accuracy: 0.5960 - recall_26: 0.0123 - recall_27: 0.0000e+00 - precision_26: 0.3214 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9075 - accuracy: 0.6222 - recall_26: 0.0143 - recall_27: 0.0000e+00 - precision_26: 0.3485 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9376 - accuracy: 0.5954 - recall_26: 0.0165 - recall_27: 0.0000e+00 - precision_26: 0.3736 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9423 - accuracy: 0.5914 - recall_26: 0.0155 - recall_27: 0.0000e+00 - precision_26: 0.3700 - precision_27: 0.0000e+00\n",
      "Epoch 00253: val_loss did not improve from 1.00875\n",
      "\n",
      "Epoch 00253: ReduceLROnPlateau reducing learning rate to 0.003958241641521454.\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9436 - accuracy: 0.5902 - recall_26: 0.0149 - recall_27: 0.0000e+00 - precision_26: 0.3725 - precision_27: 0.0000e+00 - val_loss: 1.0093 - val_accuracy: 0.5018 - val_recall_26: 0.0471 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4066 - val_precision_27: 0.0000e+00 - lr: 0.0049\n",
      "Epoch 254/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0092 - accuracy: 0.5293 - recall_26: 0.0081 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0028 - accuracy: 0.5288 - recall_26: 0.0047 - recall_27: 0.0000e+00 - precision_26: 0.1818 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9461 - accuracy: 0.5858 - recall_26: 0.0104 - recall_27: 0.0000e+00 - precision_26: 0.3913 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9380 - accuracy: 0.5935 - recall_26: 0.0091 - recall_27: 0.0000e+00 - precision_26: 0.2750 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9380 - accuracy: 0.5954 - recall_26: 0.0109 - recall_27: 0.0000e+00 - precision_26: 0.2963 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9197 - accuracy: 0.6120 - recall_26: 0.0119 - recall_27: 0.0000e+00 - precision_26: 0.3231 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9375 - accuracy: 0.5953 - recall_26: 0.0155 - recall_27: 0.0000e+00 - precision_26: 0.3721 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9421 - accuracy: 0.5912 - recall_26: 0.0147 - recall_27: 0.0000e+00 - precision_26: 0.3608 - precision_27: 0.0000e+00\n",
      "Epoch 00254: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9436 - accuracy: 0.5900 - recall_26: 0.0141 - recall_27: 0.0000e+00 - precision_26: 0.3636 - precision_27: 0.0000e+00 - val_loss: 1.0094 - val_accuracy: 0.5016 - val_recall_26: 0.0471 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4044 - val_precision_27: 0.0000e+00 - lr: 0.0040\n",
      "Epoch 255/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0101 - accuracy: 0.5308 - recall_26: 0.0242 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0035 - accuracy: 0.5288 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9619 - accuracy: 0.5692 - recall_26: 0.0097 - recall_27: 0.0000e+00 - precision_26: 0.3182 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9396 - accuracy: 0.5944 - recall_26: 0.0103 - recall_27: 0.0000e+00 - precision_26: 0.3235 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9457 - accuracy: 0.5867 - recall_26: 0.0131 - recall_27: 0.0000e+00 - precision_26: 0.3273 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9249 - accuracy: 0.6070 - recall_26: 0.0129 - recall_27: 0.0000e+00 - precision_26: 0.3030 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9196 - accuracy: 0.6118 - recall_26: 0.0119 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9378 - accuracy: 0.5949 - recall_26: 0.0155 - recall_27: 0.0000e+00 - precision_26: 0.3478 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9435 - accuracy: 0.5898 - recall_26: 0.0141 - recall_27: 0.0000e+00 - precision_26: 0.3462 - precision_27: 0.0000e+00\n",
      "Epoch 00255: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9435 - accuracy: 0.5898 - recall_26: 0.0141 - recall_27: 0.0000e+00 - precision_26: 0.3462 - precision_27: 0.0000e+00 - val_loss: 1.0098 - val_accuracy: 0.5015 - val_recall_26: 0.0471 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4000 - val_precision_27: 0.0000e+00 - lr: 0.0040\n",
      "Epoch 256/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0110 - accuracy: 0.5308 - recall_26: 0.0242 - recall_27: 0.0000e+00 - precision_26: 0.6000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0031 - accuracy: 0.5288 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.2667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9620 - accuracy: 0.5692 - recall_26: 0.0097 - recall_27: 0.0000e+00 - precision_26: 0.3182 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9397 - accuracy: 0.5944 - recall_26: 0.0103 - recall_27: 0.0000e+00 - precision_26: 0.3143 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9378 - accuracy: 0.5952 - recall_26: 0.0109 - recall_27: 0.0000e+00 - precision_26: 0.2807 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9194 - accuracy: 0.6115 - recall_26: 0.0114 - recall_27: 0.0000e+00 - precision_26: 0.2985 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9376 - accuracy: 0.5947 - recall_26: 0.0146 - recall_27: 0.0000e+00 - precision_26: 0.3371 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9435 - accuracy: 0.5894 - recall_26: 0.0129 - recall_27: 0.0000e+00 - precision_26: 0.3267 - precision_27: 0.0000e+00\n",
      "Epoch 00256: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9435 - accuracy: 0.5894 - recall_26: 0.0129 - recall_27: 0.0000e+00 - precision_26: 0.3267 - precision_27: 0.0000e+00 - val_loss: 1.0105 - val_accuracy: 0.5018 - val_recall_26: 0.0490 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4053 - val_precision_27: 0.0000e+00 - lr: 0.0040\n",
      "Epoch 257/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0104 - accuracy: 0.5308 - recall_26: 0.0242 - recall_27: 0.0000e+00 - precision_26: 0.6000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0034 - accuracy: 0.5288 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9622 - accuracy: 0.5689 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.3158 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9403 - accuracy: 0.5944 - recall_26: 0.0103 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9465 - accuracy: 0.5867 - recall_26: 0.0124 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9253 - accuracy: 0.6072 - recall_26: 0.0129 - recall_27: 0.0000e+00 - precision_26: 0.3226 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9366 - accuracy: 0.5967 - recall_26: 0.0178 - recall_27: 0.0000e+00 - precision_26: 0.4048 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9420 - accuracy: 0.5913 - recall_26: 0.0183 - recall_27: 0.0000e+00 - precision_26: 0.4020 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9437 - accuracy: 0.5901 - recall_26: 0.0165 - recall_27: 0.0000e+00 - precision_26: 0.3925 - precision_27: 0.0000e+00\n",
      "Epoch 00257: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9437 - accuracy: 0.5901 - recall_26: 0.0165 - recall_27: 0.0000e+00 - precision_26: 0.3925 - precision_27: 0.0000e+00 - val_loss: 1.0094 - val_accuracy: 0.5020 - val_recall_26: 0.0484 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4108 - val_precision_27: 0.0000e+00 - lr: 0.0040\n",
      "Epoch 258/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0108 - accuracy: 0.5323 - recall_26: 0.0242 - recall_27: 0.0000e+00 - precision_26: 0.7500 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0035 - accuracy: 0.5293 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9624 - accuracy: 0.5692 - recall_26: 0.0097 - recall_27: 0.0000e+00 - precision_26: 0.3182 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9398 - accuracy: 0.5940 - recall_26: 0.0103 - recall_27: 0.0000e+00 - precision_26: 0.2973 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9461 - accuracy: 0.5868 - recall_26: 0.0139 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9077 - accuracy: 0.6218 - recall_26: 0.0143 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9360 - accuracy: 0.5966 - recall_26: 0.0168 - recall_27: 0.0000e+00 - precision_26: 0.3855 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9415 - accuracy: 0.5913 - recall_26: 0.0174 - recall_27: 0.0000e+00 - precision_26: 0.3824 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9434 - accuracy: 0.5901 - recall_26: 0.0157 - recall_27: 0.0000e+00 - precision_26: 0.3704 - precision_27: 0.0000e+00\n",
      "Epoch 00258: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9434 - accuracy: 0.5901 - recall_26: 0.0157 - recall_27: 0.0000e+00 - precision_26: 0.3704 - precision_27: 0.0000e+00 - val_loss: 1.0092 - val_accuracy: 0.5018 - val_recall_26: 0.0497 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4041 - val_precision_27: 0.0000e+00 - lr: 0.0040\n",
      "Epoch 259/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0077 - accuracy: 0.5323 - recall_26: 0.0242 - recall_27: 0.0000e+00 - precision_26: 0.7500 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0025 - accuracy: 0.5288 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.2667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9617 - accuracy: 0.5689 - recall_26: 0.0097 - recall_27: 0.0000e+00 - precision_26: 0.3182 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9421 - accuracy: 0.5909 - recall_26: 0.0114 - recall_27: 0.0000e+00 - precision_26: 0.3438 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9451 - accuracy: 0.5864 - recall_26: 0.0131 - recall_27: 0.0000e+00 - precision_26: 0.3214 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9244 - accuracy: 0.6065 - recall_26: 0.0129 - recall_27: 0.0000e+00 - precision_26: 0.2941 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9191 - accuracy: 0.6120 - recall_26: 0.0154 - recall_27: 0.0000e+00 - precision_26: 0.3418 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9371 - accuracy: 0.5950 - recall_26: 0.0189 - recall_27: 0.0000e+00 - precision_26: 0.3750 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9418 - accuracy: 0.5907 - recall_26: 0.0172 - recall_27: 0.0000e+00 - precision_26: 0.3504 - precision_27: 0.0000e+00\n",
      "Epoch 00259: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9431 - accuracy: 0.5896 - recall_26: 0.0165 - recall_27: 0.0000e+00 - precision_26: 0.3559 - precision_27: 0.0000e+00 - val_loss: 1.0088 - val_accuracy: 0.5028 - val_recall_26: 0.0529 - val_recall_27: 6.5920e-04 - val_precision_26: 0.4171 - val_precision_27: 1.0000 - lr: 0.0040\n",
      "Epoch 260/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0099 - accuracy: 0.5308 - recall_26: 0.0242 - recall_27: 0.0000e+00 - precision_26: 0.6000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0027 - accuracy: 0.5293 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.3125 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9461 - accuracy: 0.5855 - recall_26: 0.0139 - recall_27: 0.0000e+00 - precision_26: 0.4138 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9376 - accuracy: 0.5935 - recall_26: 0.0124 - recall_27: 0.0000e+00 - precision_26: 0.3125 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9377 - accuracy: 0.5953 - recall_26: 0.0143 - recall_27: 0.0000e+00 - precision_26: 0.3182 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9078 - accuracy: 0.6215 - recall_26: 0.0155 - recall_27: 0.0000e+00 - precision_26: 0.3289 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9378 - accuracy: 0.5949 - recall_26: 0.0180 - recall_27: 0.0000e+00 - precision_26: 0.3663 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9425 - accuracy: 0.5908 - recall_26: 0.0168 - recall_27: 0.0000e+00 - precision_26: 0.3604 - precision_27: 0.0000e+00\n",
      "Epoch 00260: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9438 - accuracy: 0.5898 - recall_26: 0.0165 - recall_27: 0.0000e+00 - precision_26: 0.3684 - precision_27: 0.0000e+00 - val_loss: 1.0096 - val_accuracy: 0.5016 - val_recall_26: 0.0497 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4062 - val_precision_27: 0.0000e+00 - lr: 0.0040\n",
      "Epoch 261/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0076 - accuracy: 0.5308 - recall_26: 0.0242 - recall_27: 0.0000e+00 - precision_26: 0.6000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0018 - accuracy: 0.5298 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.3571 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9608 - accuracy: 0.5698 - recall_26: 0.0111 - recall_27: 0.0000e+00 - precision_26: 0.3810 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9416 - accuracy: 0.5915 - recall_26: 0.0124 - recall_27: 0.0000e+00 - precision_26: 0.3871 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9453 - accuracy: 0.5870 - recall_26: 0.0139 - recall_27: 0.0000e+00 - precision_26: 0.3455 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9247 - accuracy: 0.6073 - recall_26: 0.0135 - recall_27: 0.0000e+00 - precision_26: 0.3281 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9193 - accuracy: 0.6123 - recall_26: 0.0142 - recall_27: 0.0000e+00 - precision_26: 0.3472 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9372 - accuracy: 0.5953 - recall_26: 0.0170 - recall_27: 0.0000e+00 - precision_26: 0.3763 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9417 - accuracy: 0.5912 - recall_26: 0.0159 - recall_27: 0.0000e+00 - precision_26: 0.3689 - precision_27: 0.0000e+00\n",
      "Epoch 00261: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9432 - accuracy: 0.5901 - recall_26: 0.0153 - recall_27: 0.0000e+00 - precision_26: 0.3750 - precision_27: 0.0000e+00 - val_loss: 1.0101 - val_accuracy: 0.5021 - val_recall_26: 0.0497 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4127 - val_precision_27: 0.0000e+00 - lr: 0.0040\n",
      "Epoch 262/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0092 - accuracy: 0.5293 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0031 - accuracy: 0.5283 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.2143 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9463 - accuracy: 0.5850 - recall_26: 0.0104 - recall_27: 0.0000e+00 - precision_26: 0.3462 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9378 - accuracy: 0.5930 - recall_26: 0.0091 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9244 - accuracy: 0.6068 - recall_26: 0.0122 - recall_27: 0.0000e+00 - precision_26: 0.2969 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9359 - accuracy: 0.5961 - recall_26: 0.0152 - recall_27: 0.0000e+00 - precision_26: 0.3537 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9414 - accuracy: 0.5910 - recall_26: 0.0165 - recall_27: 0.0000e+00 - precision_26: 0.3663 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9433 - accuracy: 0.5897 - recall_26: 0.0149 - recall_27: 0.0000e+00 - precision_26: 0.3519 - precision_27: 0.0000e+00\n",
      "Epoch 00262: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9433 - accuracy: 0.5897 - recall_26: 0.0149 - recall_27: 0.0000e+00 - precision_26: 0.3519 - precision_27: 0.0000e+00 - val_loss: 1.0102 - val_accuracy: 0.5021 - val_recall_26: 0.0522 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4100 - val_precision_27: 0.0000e+00 - lr: 0.0040\n",
      "Epoch 263/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0106 - accuracy: 0.5308 - recall_26: 0.0242 - recall_27: 0.0000e+00 - precision_26: 0.6000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0034 - accuracy: 0.5293 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9617 - accuracy: 0.5692 - recall_26: 0.0097 - recall_27: 0.0000e+00 - precision_26: 0.3182 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9400 - accuracy: 0.5942 - recall_26: 0.0103 - recall_27: 0.0000e+00 - precision_26: 0.3056 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9462 - accuracy: 0.5867 - recall_26: 0.0139 - recall_27: 0.0000e+00 - precision_26: 0.3220 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9253 - accuracy: 0.6070 - recall_26: 0.0135 - recall_27: 0.0000e+00 - precision_26: 0.3088 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9365 - accuracy: 0.5961 - recall_26: 0.0157 - recall_27: 0.0000e+00 - precision_26: 0.3488 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9419 - accuracy: 0.5908 - recall_26: 0.0165 - recall_27: 0.0000e+00 - precision_26: 0.3558 - precision_27: 0.0000e+00\n",
      "Epoch 00263: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9438 - accuracy: 0.5898 - recall_26: 0.0149 - recall_27: 0.0000e+00 - precision_26: 0.3519 - precision_27: 0.0000e+00 - val_loss: 1.0100 - val_accuracy: 0.5018 - val_recall_26: 0.0490 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4074 - val_precision_27: 0.0000e+00 - lr: 0.0040\n",
      "Epoch 264/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0096 - accuracy: 0.5308 - recall_26: 0.0242 - recall_27: 0.0000e+00 - precision_26: 0.6000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0029 - accuracy: 0.5293 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9626 - accuracy: 0.5695 - recall_26: 0.0111 - recall_27: 0.0000e+00 - precision_26: 0.3810 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9428 - accuracy: 0.5913 - recall_26: 0.0114 - recall_27: 0.0000e+00 - precision_26: 0.3929 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9459 - accuracy: 0.5865 - recall_26: 0.0124 - recall_27: 0.0000e+00 - precision_26: 0.3269 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9077 - accuracy: 0.6215 - recall_26: 0.0136 - recall_27: 0.0000e+00 - precision_26: 0.3188 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9373 - accuracy: 0.5951 - recall_26: 0.0165 - recall_27: 0.0000e+00 - precision_26: 0.3696 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9419 - accuracy: 0.5910 - recall_26: 0.0155 - recall_27: 0.0000e+00 - precision_26: 0.3592 - precision_27: 0.0000e+00\n",
      "Epoch 00264: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9433 - accuracy: 0.5898 - recall_26: 0.0149 - recall_27: 0.0000e+00 - precision_26: 0.3619 - precision_27: 0.0000e+00 - val_loss: 1.0091 - val_accuracy: 0.5020 - val_recall_26: 0.0484 - val_recall_27: 6.5920e-04 - val_precision_26: 0.4086 - val_precision_27: 1.0000 - lr: 0.0040\n",
      "Epoch 265/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0107 - accuracy: 0.5293 - recall_26: 0.0242 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0033 - accuracy: 0.5288 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.2667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9619 - accuracy: 0.5692 - recall_26: 0.0097 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9396 - accuracy: 0.5946 - recall_26: 0.0103 - recall_27: 0.0000e+00 - precision_26: 0.3438 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9457 - accuracy: 0.5868 - recall_26: 0.0124 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9245 - accuracy: 0.6070 - recall_26: 0.0122 - recall_27: 0.0000e+00 - precision_26: 0.3115 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9359 - accuracy: 0.5964 - recall_26: 0.0157 - recall_27: 0.0000e+00 - precision_26: 0.3797 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9412 - accuracy: 0.5911 - recall_26: 0.0165 - recall_27: 0.0000e+00 - precision_26: 0.3814 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9433 - accuracy: 0.5900 - recall_26: 0.0153 - recall_27: 0.0000e+00 - precision_26: 0.3750 - precision_27: 0.0000e+00\n",
      "Epoch 00265: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9433 - accuracy: 0.5900 - recall_26: 0.0153 - recall_27: 0.0000e+00 - precision_26: 0.3750 - precision_27: 0.0000e+00 - val_loss: 1.0101 - val_accuracy: 0.5018 - val_recall_26: 0.0484 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4064 - val_precision_27: 0.0000e+00 - lr: 0.0040\n",
      "Epoch 266/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0134 - accuracy: 0.5308 - recall_26: 0.0242 - recall_27: 0.0000e+00 - precision_26: 0.6000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0041 - accuracy: 0.5298 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9617 - accuracy: 0.5698 - recall_26: 0.0111 - recall_27: 0.0000e+00 - precision_26: 0.3810 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9402 - accuracy: 0.5946 - recall_26: 0.0112 - recall_27: 0.0000e+00 - precision_26: 0.3429 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9383 - accuracy: 0.5952 - recall_26: 0.0123 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9080 - accuracy: 0.6212 - recall_26: 0.0130 - recall_27: 0.0000e+00 - precision_26: 0.3088 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9361 - accuracy: 0.5958 - recall_26: 0.0142 - recall_27: 0.0000e+00 - precision_26: 0.3375 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9418 - accuracy: 0.5907 - recall_26: 0.0142 - recall_27: 0.0000e+00 - precision_26: 0.3366 - precision_27: 0.0000e+00\n",
      "Epoch 00266: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9432 - accuracy: 0.5895 - recall_26: 0.0137 - recall_27: 0.0000e+00 - precision_26: 0.3398 - precision_27: 0.0000e+00 - val_loss: 1.0106 - val_accuracy: 0.5016 - val_recall_26: 0.0478 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4032 - val_precision_27: 0.0000e+00 - lr: 0.0040\n",
      "Epoch 267/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0112 - accuracy: 0.5308 - recall_26: 0.0242 - recall_27: 0.0000e+00 - precision_26: 0.6000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0035 - accuracy: 0.5298 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9618 - accuracy: 0.5695 - recall_26: 0.0111 - recall_27: 0.0000e+00 - precision_26: 0.3478 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9402 - accuracy: 0.5948 - recall_26: 0.0112 - recall_27: 0.0000e+00 - precision_26: 0.3529 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9460 - accuracy: 0.5868 - recall_26: 0.0131 - recall_27: 0.0000e+00 - precision_26: 0.3396 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9249 - accuracy: 0.6070 - recall_26: 0.0129 - recall_27: 0.0000e+00 - precision_26: 0.3175 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9362 - accuracy: 0.5960 - recall_26: 0.0147 - recall_27: 0.0000e+00 - precision_26: 0.3590 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9414 - accuracy: 0.5908 - recall_26: 0.0156 - recall_27: 0.0000e+00 - precision_26: 0.3684 - precision_27: 0.0000e+00\n",
      "Epoch 00267: val_loss did not improve from 1.00875\n",
      "\n",
      "Epoch 00267: ReduceLROnPlateau reducing learning rate to 0.003166593238711357.\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9434 - accuracy: 0.5898 - recall_26: 0.0145 - recall_27: 0.0000e+00 - precision_26: 0.3663 - precision_27: 0.0000e+00 - val_loss: 1.0110 - val_accuracy: 0.5018 - val_recall_26: 0.0490 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4074 - val_precision_27: 0.0000e+00 - lr: 0.0040\n",
      "Epoch 268/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0098 - accuracy: 0.5323 - recall_26: 0.0323 - recall_27: 0.0000e+00 - precision_26: 0.6667 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0039 - accuracy: 0.5298 - recall_26: 0.0140 - recall_27: 0.0000e+00 - precision_26: 0.3529 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9463 - accuracy: 0.5863 - recall_26: 0.0151 - recall_27: 0.0000e+00 - precision_26: 0.4643 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9378 - accuracy: 0.5942 - recall_26: 0.0132 - recall_27: 0.0000e+00 - precision_26: 0.3478 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9378 - accuracy: 0.5956 - recall_26: 0.0143 - recall_27: 0.0000e+00 - precision_26: 0.3281 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9194 - accuracy: 0.6119 - recall_26: 0.0142 - recall_27: 0.0000e+00 - precision_26: 0.3247 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9373 - accuracy: 0.5952 - recall_26: 0.0180 - recall_27: 0.0000e+00 - precision_26: 0.3700 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9419 - accuracy: 0.5910 - recall_26: 0.0163 - recall_27: 0.0000e+00 - precision_26: 0.3578 - precision_27: 0.0000e+00\n",
      "Epoch 00268: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9434 - accuracy: 0.5898 - recall_26: 0.0157 - recall_27: 0.0000e+00 - precision_26: 0.3604 - precision_27: 0.0000e+00 - val_loss: 1.0108 - val_accuracy: 0.5016 - val_recall_26: 0.0490 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4053 - val_precision_27: 0.0000e+00 - lr: 0.0032\n",
      "Epoch 269/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0104 - accuracy: 0.5323 - recall_26: 0.0242 - recall_27: 0.0000e+00 - precision_26: 0.7500 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0030 - accuracy: 0.5293 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.3125 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9475 - accuracy: 0.5853 - recall_26: 0.0128 - recall_27: 0.0000e+00 - precision_26: 0.3793 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9404 - accuracy: 0.5942 - recall_26: 0.0112 - recall_27: 0.0000e+00 - precision_26: 0.3158 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9467 - accuracy: 0.5864 - recall_26: 0.0124 - recall_27: 0.0000e+00 - precision_26: 0.3036 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9081 - accuracy: 0.6215 - recall_26: 0.0130 - recall_27: 0.0000e+00 - precision_26: 0.3043 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9363 - accuracy: 0.5963 - recall_26: 0.0157 - recall_27: 0.0000e+00 - precision_26: 0.3614 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9415 - accuracy: 0.5909 - recall_26: 0.0156 - recall_27: 0.0000e+00 - precision_26: 0.3571 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9435 - accuracy: 0.5897 - recall_26: 0.0141 - recall_27: 0.0000e+00 - precision_26: 0.3462 - precision_27: 0.0000e+00\n",
      "Epoch 00269: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9435 - accuracy: 0.5897 - recall_26: 0.0141 - recall_27: 0.0000e+00 - precision_26: 0.3462 - precision_27: 0.0000e+00 - val_loss: 1.0109 - val_accuracy: 0.5016 - val_recall_26: 0.0484 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4043 - val_precision_27: 0.0000e+00 - lr: 0.0032\n",
      "Epoch 270/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0110 - accuracy: 0.5308 - recall_26: 0.0242 - recall_27: 0.0000e+00 - precision_26: 0.6000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0030 - accuracy: 0.5283 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9464 - accuracy: 0.5853 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.3846 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9380 - accuracy: 0.5932 - recall_26: 0.0099 - recall_27: 0.0000e+00 - precision_26: 0.2667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9377 - accuracy: 0.5949 - recall_26: 0.0109 - recall_27: 0.0000e+00 - precision_26: 0.2623 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9076 - accuracy: 0.6209 - recall_26: 0.0118 - recall_27: 0.0000e+00 - precision_26: 0.2676 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9371 - accuracy: 0.5945 - recall_26: 0.0146 - recall_27: 0.0000e+00 - precision_26: 0.3158 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9418 - accuracy: 0.5903 - recall_26: 0.0134 - recall_27: 0.0000e+00 - precision_26: 0.3048 - precision_27: 0.0000e+00\n",
      "Epoch 00270: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9432 - accuracy: 0.5891 - recall_26: 0.0129 - recall_27: 0.0000e+00 - precision_26: 0.3084 - precision_27: 0.0000e+00 - val_loss: 1.0104 - val_accuracy: 0.5018 - val_recall_26: 0.0510 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4061 - val_precision_27: 0.0000e+00 - lr: 0.0032\n",
      "Epoch 271/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0080 - accuracy: 0.5308 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.6667 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0028 - accuracy: 0.5293 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.2500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9612 - accuracy: 0.5692 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9393 - accuracy: 0.5940 - recall_26: 0.0094 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9457 - accuracy: 0.5862 - recall_26: 0.0117 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9077 - accuracy: 0.6212 - recall_26: 0.0124 - recall_27: 0.0000e+00 - precision_26: 0.2899 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9362 - accuracy: 0.5959 - recall_26: 0.0152 - recall_27: 0.0000e+00 - precision_26: 0.3412 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9421 - accuracy: 0.5907 - recall_26: 0.0147 - recall_27: 0.0000e+00 - precision_26: 0.3365 - precision_27: 0.0000e+00\n",
      "Epoch 00271: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9434 - accuracy: 0.5895 - recall_26: 0.0141 - recall_27: 0.0000e+00 - precision_26: 0.3396 - precision_27: 0.0000e+00 - val_loss: 1.0102 - val_accuracy: 0.5023 - val_recall_26: 0.0529 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4129 - val_precision_27: 0.0000e+00 - lr: 0.0032\n",
      "Epoch 272/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0101 - accuracy: 0.5308 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.6667 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0028 - accuracy: 0.5288 - recall_26: 0.0070 - recall_27: 0.0000e+00 - precision_26: 0.2308 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9620 - accuracy: 0.5689 - recall_26: 0.0084 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9400 - accuracy: 0.5942 - recall_26: 0.0094 - recall_27: 0.0000e+00 - precision_26: 0.3030 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9457 - accuracy: 0.5868 - recall_26: 0.0117 - recall_27: 0.0000e+00 - precision_26: 0.3137 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9076 - accuracy: 0.6215 - recall_26: 0.0124 - recall_27: 0.0000e+00 - precision_26: 0.2941 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9358 - accuracy: 0.5961 - recall_26: 0.0147 - recall_27: 0.0000e+00 - precision_26: 0.3415 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9411 - accuracy: 0.5907 - recall_26: 0.0147 - recall_27: 0.0000e+00 - precision_26: 0.3367 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9429 - accuracy: 0.5894 - recall_26: 0.0133 - recall_27: 0.0000e+00 - precision_26: 0.3269 - precision_27: 0.0000e+00\n",
      "Epoch 00272: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9429 - accuracy: 0.5894 - recall_26: 0.0133 - recall_27: 0.0000e+00 - precision_26: 0.3269 - precision_27: 0.0000e+00 - val_loss: 1.0098 - val_accuracy: 0.5024 - val_recall_26: 0.0529 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4129 - val_precision_27: 0.0000e+00 - lr: 0.0032\n",
      "Epoch 273/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0099 - accuracy: 0.5323 - recall_26: 0.0242 - recall_27: 0.0000e+00 - precision_26: 0.6000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0034 - accuracy: 0.5298 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.3125 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9620 - accuracy: 0.5698 - recall_26: 0.0111 - recall_27: 0.0000e+00 - precision_26: 0.3478 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9395 - accuracy: 0.5948 - recall_26: 0.0122 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9452 - accuracy: 0.5870 - recall_26: 0.0153 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9069 - accuracy: 0.6222 - recall_26: 0.0174 - recall_27: 0.0000e+00 - precision_26: 0.3544 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9354 - accuracy: 0.5967 - recall_26: 0.0189 - recall_27: 0.0000e+00 - precision_26: 0.3871 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9406 - accuracy: 0.5913 - recall_26: 0.0192 - recall_27: 0.0000e+00 - precision_26: 0.3874 - precision_27: 0.0000e+00\n",
      "Epoch 00273: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9425 - accuracy: 0.5901 - recall_26: 0.0173 - recall_27: 0.0000e+00 - precision_26: 0.3729 - precision_27: 0.0000e+00 - val_loss: 1.0099 - val_accuracy: 0.5029 - val_recall_26: 0.0548 - val_recall_27: 6.5920e-04 - val_precision_26: 0.4115 - val_precision_27: 1.0000 - lr: 0.0032\n",
      "Epoch 274/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0089 - accuracy: 0.5352 - recall_26: 0.0403 - recall_27: 0.0000e+00 - precision_26: 0.8333 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0025 - accuracy: 0.5303 - recall_26: 0.0140 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9467 - accuracy: 0.5858 - recall_26: 0.0139 - recall_27: 0.0000e+00 - precision_26: 0.4286 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9400 - accuracy: 0.5946 - recall_26: 0.0122 - recall_27: 0.0000e+00 - precision_26: 0.3514 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9383 - accuracy: 0.5953 - recall_26: 0.0129 - recall_27: 0.0000e+00 - precision_26: 0.2969 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9200 - accuracy: 0.6116 - recall_26: 0.0131 - recall_27: 0.0000e+00 - precision_26: 0.3108 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9380 - accuracy: 0.5948 - recall_26: 0.0165 - recall_27: 0.0000e+00 - precision_26: 0.3505 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9424 - accuracy: 0.5906 - recall_26: 0.0151 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+00\n",
      "Epoch 00274: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9438 - accuracy: 0.5895 - recall_26: 0.0145 - recall_27: 0.0000e+00 - precision_26: 0.3364 - precision_27: 0.0000e+00 - val_loss: 1.0103 - val_accuracy: 0.5029 - val_recall_26: 0.0548 - val_recall_27: 6.5920e-04 - val_precision_26: 0.4115 - val_precision_27: 1.0000 - lr: 0.0032\n",
      "Epoch 275/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0111 - accuracy: 0.5308 - recall_26: 0.0242 - recall_27: 0.0000e+00 - precision_26: 0.5000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0038 - accuracy: 0.5288 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.2778 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9627 - accuracy: 0.5692 - recall_26: 0.0125 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9402 - accuracy: 0.5944 - recall_26: 0.0122 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9464 - accuracy: 0.5865 - recall_26: 0.0139 - recall_27: 0.0000e+00 - precision_26: 0.3167 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9253 - accuracy: 0.6068 - recall_26: 0.0129 - recall_27: 0.0000e+00 - precision_26: 0.2941 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9199 - accuracy: 0.6119 - recall_26: 0.0142 - recall_27: 0.0000e+00 - precision_26: 0.3289 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9416 - accuracy: 0.5908 - recall_26: 0.0174 - recall_27: 0.0000e+00 - precision_26: 0.3679 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9433 - accuracy: 0.5896 - recall_26: 0.0157 - recall_27: 0.0000e+00 - precision_26: 0.3571 - precision_27: 0.0000e+00\n",
      "Epoch 00275: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9433 - accuracy: 0.5896 - recall_26: 0.0157 - recall_27: 0.0000e+00 - precision_26: 0.3571 - precision_27: 0.0000e+00 - val_loss: 1.0104 - val_accuracy: 0.5028 - val_recall_26: 0.0541 - val_recall_27: 6.5920e-04 - val_precision_26: 0.4146 - val_precision_27: 1.0000 - lr: 0.0032\n",
      "Epoch 276/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0101 - accuracy: 0.5337 - recall_26: 0.0403 - recall_27: 0.0000e+00 - precision_26: 0.7143 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0033 - accuracy: 0.5298 - recall_26: 0.0140 - recall_27: 0.0000e+00 - precision_26: 0.3529 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9616 - accuracy: 0.5698 - recall_26: 0.0125 - recall_27: 0.0000e+00 - precision_26: 0.3750 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9397 - accuracy: 0.5948 - recall_26: 0.0122 - recall_27: 0.0000e+00 - precision_26: 0.3514 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9457 - accuracy: 0.5872 - recall_26: 0.0146 - recall_27: 0.0000e+00 - precision_26: 0.3509 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9245 - accuracy: 0.6075 - recall_26: 0.0148 - recall_27: 0.0000e+00 - precision_26: 0.3382 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9194 - accuracy: 0.6124 - recall_26: 0.0154 - recall_27: 0.0000e+00 - precision_26: 0.3600 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9371 - accuracy: 0.5956 - recall_26: 0.0189 - recall_27: 0.0000e+00 - precision_26: 0.3980 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9432 - accuracy: 0.5902 - recall_26: 0.0169 - recall_27: 0.0000e+00 - precision_26: 0.3909 - precision_27: 0.0000e+00\n",
      "Epoch 00276: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.9432 - accuracy: 0.5902 - recall_26: 0.0169 - recall_27: 0.0000e+00 - precision_26: 0.3909 - precision_27: 0.0000e+00 - val_loss: 1.0100 - val_accuracy: 0.5029 - val_recall_26: 0.0541 - val_recall_27: 6.5920e-04 - val_precision_26: 0.4106 - val_precision_27: 1.0000 - lr: 0.0032\n",
      "Epoch 277/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0094 - accuracy: 0.5323 - recall_26: 0.0323 - recall_27: 0.0000e+00 - precision_26: 0.6667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9721 - accuracy: 0.5594 - recall_26: 0.0150 - recall_27: 0.0000e+00 - precision_26: 0.3750 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9454 - accuracy: 0.5855 - recall_26: 0.0139 - recall_27: 0.0000e+00 - precision_26: 0.4138 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9379 - accuracy: 0.5934 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.2917 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9373 - accuracy: 0.5956 - recall_26: 0.0136 - recall_27: 0.0000e+00 - precision_26: 0.3125 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9073 - accuracy: 0.6215 - recall_26: 0.0136 - recall_27: 0.0000e+00 - precision_26: 0.3099 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9355 - accuracy: 0.5962 - recall_26: 0.0168 - recall_27: 0.0000e+00 - precision_26: 0.3556 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9414 - accuracy: 0.5908 - recall_26: 0.0163 - recall_27: 0.0000e+00 - precision_26: 0.3482 - precision_27: 0.0000e+00\n",
      "Epoch 00277: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9428 - accuracy: 0.5897 - recall_26: 0.0157 - recall_27: 0.0000e+00 - precision_26: 0.3478 - precision_27: 0.0000e+00 - val_loss: 1.0101 - val_accuracy: 0.5029 - val_recall_26: 0.0548 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4135 - val_precision_27: 0.0000e+00 - lr: 0.0032\n",
      "Epoch 278/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0100 - accuracy: 0.5367 - recall_26: 0.0484 - recall_27: 0.0000e+00 - precision_26: 0.7500 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0027 - accuracy: 0.5308 - recall_26: 0.0163 - recall_27: 0.0000e+00 - precision_26: 0.3889 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9614 - accuracy: 0.5704 - recall_26: 0.0139 - recall_27: 0.0000e+00 - precision_26: 0.4167 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9400 - accuracy: 0.5951 - recall_26: 0.0131 - recall_27: 0.0000e+00 - precision_26: 0.3784 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9464 - accuracy: 0.5874 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.3667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9252 - accuracy: 0.6075 - recall_26: 0.0155 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9363 - accuracy: 0.5964 - recall_26: 0.0178 - recall_27: 0.0000e+00 - precision_26: 0.3778 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9415 - accuracy: 0.5909 - recall_26: 0.0170 - recall_27: 0.0000e+00 - precision_26: 0.3654 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9434 - accuracy: 0.5898 - recall_26: 0.0157 - recall_27: 0.0000e+00 - precision_26: 0.3636 - precision_27: 0.0000e+00\n",
      "Epoch 00278: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9434 - accuracy: 0.5898 - recall_26: 0.0157 - recall_27: 0.0000e+00 - precision_26: 0.3636 - precision_27: 0.0000e+00 - val_loss: 1.0105 - val_accuracy: 0.5028 - val_recall_26: 0.0548 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4115 - val_precision_27: 0.0000e+00 - lr: 0.0032\n",
      "Epoch 279/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0096 - accuracy: 0.5308 - recall_26: 0.0242 - recall_27: 0.0000e+00 - precision_26: 0.6000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0021 - accuracy: 0.5288 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.2667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9462 - accuracy: 0.5850 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.3448 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9380 - accuracy: 0.5932 - recall_26: 0.0108 - recall_27: 0.0000e+00 - precision_26: 0.2653 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9378 - accuracy: 0.5950 - recall_26: 0.0129 - recall_27: 0.0000e+00 - precision_26: 0.2794 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9078 - accuracy: 0.6211 - recall_26: 0.0143 - recall_27: 0.0000e+00 - precision_26: 0.2987 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9360 - accuracy: 0.5957 - recall_26: 0.0168 - recall_27: 0.0000e+00 - precision_26: 0.3368 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9412 - accuracy: 0.5907 - recall_26: 0.0179 - recall_27: 0.0000e+00 - precision_26: 0.3540 - precision_27: 0.0000e+00\n",
      "Epoch 00279: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9432 - accuracy: 0.5894 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.3445 - precision_27: 0.0000e+00 - val_loss: 1.0103 - val_accuracy: 0.5029 - val_recall_26: 0.0548 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4135 - val_precision_27: 0.0000e+00 - lr: 0.0032\n",
      "Epoch 280/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0117 - accuracy: 0.5337 - recall_26: 0.0323 - recall_27: 0.0000e+00 - precision_26: 0.8000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0026 - accuracy: 0.5298 - recall_26: 0.0140 - recall_27: 0.0000e+00 - precision_26: 0.3529 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9616 - accuracy: 0.5695 - recall_26: 0.0125 - recall_27: 0.0000e+00 - precision_26: 0.3600 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9397 - accuracy: 0.5946 - recall_26: 0.0131 - recall_27: 0.0000e+00 - precision_26: 0.3500 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9458 - accuracy: 0.5867 - recall_26: 0.0153 - recall_27: 0.0000e+00 - precision_26: 0.3387 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9074 - accuracy: 0.6215 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9358 - accuracy: 0.5962 - recall_26: 0.0183 - recall_27: 0.0000e+00 - precision_26: 0.3723 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9414 - accuracy: 0.5907 - recall_26: 0.0174 - recall_27: 0.0000e+00 - precision_26: 0.3578 - precision_27: 0.0000e+00\n",
      "Epoch 00280: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9434 - accuracy: 0.5894 - recall_26: 0.0157 - recall_27: 0.0000e+00 - precision_26: 0.3448 - precision_27: 0.0000e+00 - val_loss: 1.0104 - val_accuracy: 0.5029 - val_recall_26: 0.0548 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4135 - val_precision_27: 0.0000e+00 - lr: 0.0032\n",
      "Epoch 281/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0106 - accuracy: 0.5337 - recall_26: 0.0323 - recall_27: 0.0000e+00 - precision_26: 0.8000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0035 - accuracy: 0.5303 - recall_26: 0.0140 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9468 - accuracy: 0.5860 - recall_26: 0.0139 - recall_27: 0.0000e+00 - precision_26: 0.4444 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9386 - accuracy: 0.5938 - recall_26: 0.0124 - recall_27: 0.0000e+00 - precision_26: 0.3125 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9384 - accuracy: 0.5956 - recall_26: 0.0136 - recall_27: 0.0000e+00 - precision_26: 0.3175 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9199 - accuracy: 0.6119 - recall_26: 0.0137 - recall_27: 0.0000e+00 - precision_26: 0.3288 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9377 - accuracy: 0.5949 - recall_26: 0.0175 - recall_27: 0.0000e+00 - precision_26: 0.3673 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9434 - accuracy: 0.5895 - recall_26: 0.0153 - recall_27: 0.0000e+00 - precision_26: 0.3545 - precision_27: 0.0000e+00\n",
      "Epoch 00281: val_loss did not improve from 1.00875\n",
      "\n",
      "Epoch 00281: ReduceLROnPlateau reducing learning rate to 0.00253327451646328.\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9434 - accuracy: 0.5895 - recall_26: 0.0153 - recall_27: 0.0000e+00 - precision_26: 0.3545 - precision_27: 0.0000e+00 - val_loss: 1.0104 - val_accuracy: 0.5028 - val_recall_26: 0.0541 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4126 - val_precision_27: 0.0000e+00 - lr: 0.0032\n",
      "Epoch 282/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0124 - accuracy: 0.5308 - recall_26: 0.0242 - recall_27: 0.0000e+00 - precision_26: 0.6000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0047 - accuracy: 0.5283 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.2667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9483 - accuracy: 0.5846 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.3571 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9410 - accuracy: 0.5937 - recall_26: 0.0103 - recall_27: 0.0000e+00 - precision_26: 0.3056 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9468 - accuracy: 0.5862 - recall_26: 0.0124 - recall_27: 0.0000e+00 - precision_26: 0.3036 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9252 - accuracy: 0.6064 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.2727 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9363 - accuracy: 0.5958 - recall_26: 0.0152 - recall_27: 0.0000e+00 - precision_26: 0.3452 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9415 - accuracy: 0.5907 - recall_26: 0.0165 - recall_27: 0.0000e+00 - precision_26: 0.3592 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9435 - accuracy: 0.5894 - recall_26: 0.0149 - recall_27: 0.0000e+00 - precision_26: 0.3486 - precision_27: 0.0000e+00\n",
      "Epoch 00282: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9435 - accuracy: 0.5894 - recall_26: 0.0149 - recall_27: 0.0000e+00 - precision_26: 0.3486 - precision_27: 0.0000e+00 - val_loss: 1.0105 - val_accuracy: 0.5026 - val_recall_26: 0.0535 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4158 - val_precision_27: 0.0000e+00 - lr: 0.0025\n",
      "Epoch 283/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0104 - accuracy: 0.5323 - recall_26: 0.0323 - recall_27: 0.0000e+00 - precision_26: 0.6667 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0031 - accuracy: 0.5293 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.3125 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9627 - accuracy: 0.5689 - recall_26: 0.0111 - recall_27: 0.0000e+00 - precision_26: 0.3200 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9404 - accuracy: 0.5940 - recall_26: 0.0112 - recall_27: 0.0000e+00 - precision_26: 0.3158 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9464 - accuracy: 0.5864 - recall_26: 0.0139 - recall_27: 0.0000e+00 - precision_26: 0.3115 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9251 - accuracy: 0.6068 - recall_26: 0.0135 - recall_27: 0.0000e+00 - precision_26: 0.2958 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9361 - accuracy: 0.5961 - recall_26: 0.0173 - recall_27: 0.0000e+00 - precision_26: 0.3626 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9414 - accuracy: 0.5907 - recall_26: 0.0170 - recall_27: 0.0000e+00 - precision_26: 0.3585 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9432 - accuracy: 0.5895 - recall_26: 0.0153 - recall_27: 0.0000e+00 - precision_26: 0.3482 - precision_27: 0.0000e+00\n",
      "Epoch 00283: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9432 - accuracy: 0.5895 - recall_26: 0.0153 - recall_27: 0.0000e+00 - precision_26: 0.3482 - precision_27: 0.0000e+00 - val_loss: 1.0105 - val_accuracy: 0.5026 - val_recall_26: 0.0535 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4158 - val_precision_27: 0.0000e+00 - lr: 0.0025\n",
      "Epoch 284/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0094 - accuracy: 0.5337 - recall_26: 0.0323 - recall_27: 0.0000e+00 - precision_26: 0.8000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0021 - accuracy: 0.5303 - recall_26: 0.0140 - recall_27: 0.0000e+00 - precision_26: 0.3750 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9616 - accuracy: 0.5701 - recall_26: 0.0125 - recall_27: 0.0000e+00 - precision_26: 0.3913 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9402 - accuracy: 0.5948 - recall_26: 0.0112 - recall_27: 0.0000e+00 - precision_26: 0.3429 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9379 - accuracy: 0.5960 - recall_26: 0.0136 - recall_27: 0.0000e+00 - precision_26: 0.3279 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9078 - accuracy: 0.6219 - recall_26: 0.0149 - recall_27: 0.0000e+00 - precision_26: 0.3429 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9360 - accuracy: 0.5964 - recall_26: 0.0173 - recall_27: 0.0000e+00 - precision_26: 0.3793 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9419 - accuracy: 0.5908 - recall_26: 0.0155 - recall_27: 0.0000e+00 - precision_26: 0.3524 - precision_27: 0.0000e+00\n",
      "Epoch 00284: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9432 - accuracy: 0.5898 - recall_26: 0.0153 - recall_27: 0.0000e+00 - precision_26: 0.3611 - precision_27: 0.0000e+00 - val_loss: 1.0106 - val_accuracy: 0.5024 - val_recall_26: 0.0535 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4078 - val_precision_27: 0.0000e+00 - lr: 0.0025\n",
      "Epoch 285/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0114 - accuracy: 0.5337 - recall_26: 0.0323 - recall_27: 0.0000e+00 - precision_26: 0.8000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0040 - accuracy: 0.5293 - recall_26: 0.0140 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9465 - accuracy: 0.5853 - recall_26: 0.0139 - recall_27: 0.0000e+00 - precision_26: 0.3750 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9395 - accuracy: 0.5942 - recall_26: 0.0122 - recall_27: 0.0000e+00 - precision_26: 0.3250 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9377 - accuracy: 0.5952 - recall_26: 0.0136 - recall_27: 0.0000e+00 - precision_26: 0.2985 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9075 - accuracy: 0.6214 - recall_26: 0.0149 - recall_27: 0.0000e+00 - precision_26: 0.3200 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9356 - accuracy: 0.5960 - recall_26: 0.0168 - recall_27: 0.0000e+00 - precision_26: 0.3556 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9407 - accuracy: 0.5907 - recall_26: 0.0174 - recall_27: 0.0000e+00 - precision_26: 0.3578 - precision_27: 0.0000e+00\n",
      "Epoch 00285: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9426 - accuracy: 0.5895 - recall_26: 0.0157 - recall_27: 0.0000e+00 - precision_26: 0.3478 - precision_27: 0.0000e+00 - val_loss: 1.0102 - val_accuracy: 0.5029 - val_recall_26: 0.0548 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4135 - val_precision_27: 0.0000e+00 - lr: 0.0025\n",
      "Epoch 286/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0119 - accuracy: 0.5337 - recall_26: 0.0323 - recall_27: 0.0000e+00 - precision_26: 0.8000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0044 - accuracy: 0.5293 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9474 - accuracy: 0.5855 - recall_26: 0.0128 - recall_27: 0.0000e+00 - precision_26: 0.4074 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9406 - accuracy: 0.5944 - recall_26: 0.0112 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9384 - accuracy: 0.5950 - recall_26: 0.0123 - recall_27: 0.0000e+00 - precision_26: 0.2951 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9197 - accuracy: 0.6115 - recall_26: 0.0131 - recall_27: 0.0000e+00 - precision_26: 0.3067 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9374 - accuracy: 0.5946 - recall_26: 0.0160 - recall_27: 0.0000e+00 - precision_26: 0.3402 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9418 - accuracy: 0.5903 - recall_26: 0.0147 - recall_27: 0.0000e+00 - precision_26: 0.3271 - precision_27: 0.0000e+00\n",
      "Epoch 00286: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9432 - accuracy: 0.5893 - recall_26: 0.0141 - recall_27: 0.0000e+00 - precision_26: 0.3303 - precision_27: 0.0000e+00 - val_loss: 1.0099 - val_accuracy: 0.5029 - val_recall_26: 0.0548 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4115 - val_precision_27: 0.0000e+00 - lr: 0.0025\n",
      "Epoch 287/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0133 - accuracy: 0.5337 - recall_26: 0.0323 - recall_27: 0.0000e+00 - precision_26: 0.8000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0045 - accuracy: 0.5298 - recall_26: 0.0140 - recall_27: 0.0000e+00 - precision_26: 0.3750 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9618 - accuracy: 0.5695 - recall_26: 0.0125 - recall_27: 0.0000e+00 - precision_26: 0.3913 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9401 - accuracy: 0.5946 - recall_26: 0.0122 - recall_27: 0.0000e+00 - precision_26: 0.3611 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9460 - accuracy: 0.5867 - recall_26: 0.0139 - recall_27: 0.0000e+00 - precision_26: 0.3220 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9250 - accuracy: 0.6069 - recall_26: 0.0135 - recall_27: 0.0000e+00 - precision_26: 0.3043 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9193 - accuracy: 0.6119 - recall_26: 0.0142 - recall_27: 0.0000e+00 - precision_26: 0.3289 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9408 - accuracy: 0.5906 - recall_26: 0.0165 - recall_27: 0.0000e+00 - precision_26: 0.3524 - precision_27: 0.0000e+00\n",
      "Epoch 00287: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9425 - accuracy: 0.5894 - recall_26: 0.0149 - recall_27: 0.0000e+00 - precision_26: 0.3423 - precision_27: 0.0000e+00 - val_loss: 1.0096 - val_accuracy: 0.5029 - val_recall_26: 0.0548 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4115 - val_precision_27: 0.0000e+00 - lr: 0.0025\n",
      "Epoch 288/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0118 - accuracy: 0.5323 - recall_26: 0.0242 - recall_27: 0.0000e+00 - precision_26: 0.7500 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0039 - accuracy: 0.5293 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.2857 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9470 - accuracy: 0.5855 - recall_26: 0.0104 - recall_27: 0.0000e+00 - precision_26: 0.3750 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9401 - accuracy: 0.5944 - recall_26: 0.0094 - recall_27: 0.0000e+00 - precision_26: 0.3030 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9381 - accuracy: 0.5957 - recall_26: 0.0123 - recall_27: 0.0000e+00 - precision_26: 0.3000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9079 - accuracy: 0.6218 - recall_26: 0.0136 - recall_27: 0.0000e+00 - precision_26: 0.3188 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9360 - accuracy: 0.5963 - recall_26: 0.0168 - recall_27: 0.0000e+00 - precision_26: 0.3636 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9416 - accuracy: 0.5909 - recall_26: 0.0165 - recall_27: 0.0000e+00 - precision_26: 0.3558 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9433 - accuracy: 0.5897 - recall_26: 0.0149 - recall_27: 0.0000e+00 - precision_26: 0.3393 - precision_27: 0.0000e+00\n",
      "Epoch 00288: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9433 - accuracy: 0.5897 - recall_26: 0.0149 - recall_27: 0.0000e+00 - precision_26: 0.3393 - precision_27: 0.0000e+00 - val_loss: 1.0094 - val_accuracy: 0.5024 - val_recall_26: 0.0554 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4047 - val_precision_27: 0.0000e+00 - lr: 0.0025\n",
      "Epoch 289/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0111 - accuracy: 0.5337 - recall_26: 0.0323 - recall_27: 0.0000e+00 - precision_26: 0.8000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0028 - accuracy: 0.5303 - recall_26: 0.0140 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9464 - accuracy: 0.5858 - recall_26: 0.0139 - recall_27: 0.0000e+00 - precision_26: 0.4444 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9399 - accuracy: 0.5946 - recall_26: 0.0122 - recall_27: 0.0000e+00 - precision_26: 0.3714 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9461 - accuracy: 0.5870 - recall_26: 0.0153 - recall_27: 0.0000e+00 - precision_26: 0.3684 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9251 - accuracy: 0.6072 - recall_26: 0.0148 - recall_27: 0.0000e+00 - precision_26: 0.3433 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9361 - accuracy: 0.5964 - recall_26: 0.0189 - recall_27: 0.0000e+00 - precision_26: 0.4045 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9414 - accuracy: 0.5910 - recall_26: 0.0188 - recall_27: 0.0000e+00 - precision_26: 0.3962 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9433 - accuracy: 0.5898 - recall_26: 0.0169 - recall_27: 0.0000e+00 - precision_26: 0.3772 - precision_27: 0.0000e+00\n",
      "Epoch 00289: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9433 - accuracy: 0.5898 - recall_26: 0.0169 - recall_27: 0.0000e+00 - precision_26: 0.3772 - precision_27: 0.0000e+00 - val_loss: 1.0094 - val_accuracy: 0.5029 - val_recall_26: 0.0548 - val_recall_27: 6.5920e-04 - val_precision_26: 0.4095 - val_precision_27: 1.0000 - lr: 0.0025\n",
      "Epoch 290/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0104 - accuracy: 0.5323 - recall_26: 0.0323 - recall_27: 0.0000e+00 - precision_26: 0.6667 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0029 - accuracy: 0.5293 - recall_26: 0.0140 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9623 - accuracy: 0.5692 - recall_26: 0.0125 - recall_27: 0.0000e+00 - precision_26: 0.3462 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9404 - accuracy: 0.5944 - recall_26: 0.0122 - recall_27: 0.0000e+00 - precision_26: 0.3250 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9464 - accuracy: 0.5868 - recall_26: 0.0153 - recall_27: 0.0000e+00 - precision_26: 0.3387 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9080 - accuracy: 0.6216 - recall_26: 0.0149 - recall_27: 0.0000e+00 - precision_26: 0.3200 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9362 - accuracy: 0.5962 - recall_26: 0.0173 - recall_27: 0.0000e+00 - precision_26: 0.3626 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9416 - accuracy: 0.5910 - recall_26: 0.0179 - recall_27: 0.0000e+00 - precision_26: 0.3704 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9434 - accuracy: 0.5898 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.3565 - precision_27: 0.0000e+00\n",
      "Epoch 00290: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9434 - accuracy: 0.5898 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.3565 - precision_27: 0.0000e+00 - val_loss: 1.0094 - val_accuracy: 0.5031 - val_recall_26: 0.0548 - val_recall_27: 6.5920e-04 - val_precision_26: 0.4095 - val_precision_27: 1.0000 - lr: 0.0025\n",
      "Epoch 291/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0108 - accuracy: 0.5352 - recall_26: 0.0403 - recall_27: 0.0000e+00 - precision_26: 0.8333 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0038 - accuracy: 0.5298 - recall_26: 0.0163 - recall_27: 0.0000e+00 - precision_26: 0.3684 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9469 - accuracy: 0.5855 - recall_26: 0.0151 - recall_27: 0.0000e+00 - precision_26: 0.4062 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9385 - accuracy: 0.5937 - recall_26: 0.0132 - recall_27: 0.0000e+00 - precision_26: 0.3200 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9381 - accuracy: 0.5956 - recall_26: 0.0150 - recall_27: 0.0000e+00 - precision_26: 0.3235 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9079 - accuracy: 0.6217 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.3377 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9360 - accuracy: 0.5962 - recall_26: 0.0183 - recall_27: 0.0000e+00 - precision_26: 0.3723 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9412 - accuracy: 0.5907 - recall_26: 0.0179 - recall_27: 0.0000e+00 - precision_26: 0.3636 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9431 - accuracy: 0.5896 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.3534 - precision_27: 0.0000e+00\n",
      "Epoch 00291: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9431 - accuracy: 0.5896 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.3534 - precision_27: 0.0000e+00 - val_loss: 1.0093 - val_accuracy: 0.5031 - val_recall_26: 0.0548 - val_recall_27: 6.5920e-04 - val_precision_26: 0.4135 - val_precision_27: 1.0000 - lr: 0.0025\n",
      "Epoch 292/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0082 - accuracy: 0.5323 - recall_26: 0.0323 - recall_27: 0.0000e+00 - precision_26: 0.6667 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0019 - accuracy: 0.5293 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.3125 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9460 - accuracy: 0.5858 - recall_26: 0.0139 - recall_27: 0.0000e+00 - precision_26: 0.4286 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9394 - accuracy: 0.5944 - recall_26: 0.0122 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9375 - accuracy: 0.5956 - recall_26: 0.0143 - recall_27: 0.0000e+00 - precision_26: 0.3231 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9075 - accuracy: 0.6216 - recall_26: 0.0149 - recall_27: 0.0000e+00 - precision_26: 0.3243 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9358 - accuracy: 0.5961 - recall_26: 0.0168 - recall_27: 0.0000e+00 - precision_26: 0.3556 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9414 - accuracy: 0.5907 - recall_26: 0.0170 - recall_27: 0.0000e+00 - precision_26: 0.3551 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9433 - accuracy: 0.5895 - recall_26: 0.0153 - recall_27: 0.0000e+00 - precision_26: 0.3421 - precision_27: 0.0000e+00\n",
      "Epoch 00292: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9433 - accuracy: 0.5895 - recall_26: 0.0153 - recall_27: 0.0000e+00 - precision_26: 0.3421 - precision_27: 0.0000e+00 - val_loss: 1.0091 - val_accuracy: 0.5031 - val_recall_26: 0.0548 - val_recall_27: 6.5920e-04 - val_precision_26: 0.4115 - val_precision_27: 1.0000 - lr: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0081 - accuracy: 0.5352 - recall_26: 0.0403 - recall_27: 0.0000e+00 - precision_26: 0.8333 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0019 - accuracy: 0.5318 - recall_26: 0.0186 - recall_27: 0.0000e+00 - precision_26: 0.4706 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9615 - accuracy: 0.5707 - recall_26: 0.0153 - recall_27: 0.0000e+00 - precision_26: 0.4400 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9397 - accuracy: 0.5953 - recall_26: 0.0140 - recall_27: 0.0000e+00 - precision_26: 0.3947 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9462 - accuracy: 0.5872 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.3607 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9082 - accuracy: 0.6220 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.3514 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9364 - accuracy: 0.5967 - recall_26: 0.0183 - recall_27: 0.0000e+00 - precision_26: 0.3933 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9416 - accuracy: 0.5912 - recall_26: 0.0179 - recall_27: 0.0000e+00 - precision_26: 0.3810 - precision_27: 0.0000e+00\n",
      "Epoch 00293: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9437 - accuracy: 0.5899 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.3694 - precision_27: 0.0000e+00 - val_loss: 1.0096 - val_accuracy: 0.5029 - val_recall_26: 0.0548 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4155 - val_precision_27: 0.0000e+00 - lr: 0.0025\n",
      "Epoch 294/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0089 - accuracy: 0.5352 - recall_26: 0.0403 - recall_27: 0.0000e+00 - precision_26: 0.8333 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0022 - accuracy: 0.5303 - recall_26: 0.0140 - recall_27: 0.0000e+00 - precision_26: 0.3750 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9615 - accuracy: 0.5698 - recall_26: 0.0125 - recall_27: 0.0000e+00 - precision_26: 0.3913 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9397 - accuracy: 0.5946 - recall_26: 0.0131 - recall_27: 0.0000e+00 - precision_26: 0.3590 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9383 - accuracy: 0.5954 - recall_26: 0.0143 - recall_27: 0.0000e+00 - precision_26: 0.3231 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9082 - accuracy: 0.6216 - recall_26: 0.0155 - recall_27: 0.0000e+00 - precision_26: 0.3378 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9363 - accuracy: 0.5962 - recall_26: 0.0173 - recall_27: 0.0000e+00 - precision_26: 0.3750 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9422 - accuracy: 0.5907 - recall_26: 0.0159 - recall_27: 0.0000e+00 - precision_26: 0.3551 - precision_27: 0.0000e+00\n",
      "Epoch 00294: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9437 - accuracy: 0.5896 - recall_26: 0.0153 - recall_27: 0.0000e+00 - precision_26: 0.3578 - precision_27: 0.0000e+00 - val_loss: 1.0099 - val_accuracy: 0.5026 - val_recall_26: 0.0535 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4118 - val_precision_27: 0.0000e+00 - lr: 0.0025\n",
      "Epoch 295/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0093 - accuracy: 0.5337 - recall_26: 0.0323 - recall_27: 0.0000e+00 - precision_26: 0.8000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0030 - accuracy: 0.5293 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.3125 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9470 - accuracy: 0.5855 - recall_26: 0.0128 - recall_27: 0.0000e+00 - precision_26: 0.4074 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9399 - accuracy: 0.5944 - recall_26: 0.0112 - recall_27: 0.0000e+00 - precision_26: 0.3429 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9382 - accuracy: 0.5954 - recall_26: 0.0129 - recall_27: 0.0000e+00 - precision_26: 0.3115 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9079 - accuracy: 0.6215 - recall_26: 0.0136 - recall_27: 0.0000e+00 - precision_26: 0.3188 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9362 - accuracy: 0.5960 - recall_26: 0.0162 - recall_27: 0.0000e+00 - precision_26: 0.3605 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9415 - accuracy: 0.5907 - recall_26: 0.0156 - recall_27: 0.0000e+00 - precision_26: 0.3535 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9435 - accuracy: 0.5895 - recall_26: 0.0141 - recall_27: 0.0000e+00 - precision_26: 0.3462 - precision_27: 0.0000e+00\n",
      "Epoch 00295: val_loss did not improve from 1.00875\n",
      "\n",
      "Epoch 00295: ReduceLROnPlateau reducing learning rate to 0.002026619575917721.\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9435 - accuracy: 0.5895 - recall_26: 0.0141 - recall_27: 0.0000e+00 - precision_26: 0.3462 - precision_27: 0.0000e+00 - val_loss: 1.0102 - val_accuracy: 0.5024 - val_recall_26: 0.0535 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4098 - val_precision_27: 0.0000e+00 - lr: 0.0025\n",
      "Epoch 296/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0080 - accuracy: 0.5323 - recall_26: 0.0323 - recall_27: 0.0000e+00 - precision_26: 0.6667 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0036 - accuracy: 0.5298 - recall_26: 0.0140 - recall_27: 0.0000e+00 - precision_26: 0.3750 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9620 - accuracy: 0.5698 - recall_26: 0.0125 - recall_27: 0.0000e+00 - precision_26: 0.3913 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9429 - accuracy: 0.5913 - recall_26: 0.0114 - recall_27: 0.0000e+00 - precision_26: 0.3667 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9381 - accuracy: 0.5937 - recall_26: 0.0124 - recall_27: 0.0000e+00 - precision_26: 0.3125 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9249 - accuracy: 0.6069 - recall_26: 0.0135 - recall_27: 0.0000e+00 - precision_26: 0.3043 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9195 - accuracy: 0.6119 - recall_26: 0.0142 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9412 - accuracy: 0.5908 - recall_26: 0.0174 - recall_27: 0.0000e+00 - precision_26: 0.3679 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9430 - accuracy: 0.5897 - recall_26: 0.0157 - recall_27: 0.0000e+00 - precision_26: 0.3604 - precision_27: 0.0000e+00\n",
      "Epoch 00296: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9430 - accuracy: 0.5897 - recall_26: 0.0157 - recall_27: 0.0000e+00 - precision_26: 0.3604 - precision_27: 0.0000e+00 - val_loss: 1.0101 - val_accuracy: 0.5028 - val_recall_26: 0.0548 - val_recall_27: 0.0000e+00 - val_precision_26: 0.4115 - val_precision_27: 0.0000e+00 - lr: 0.0020\n",
      "Epoch 297/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0105 - accuracy: 0.5337 - recall_26: 0.0323 - recall_27: 0.0000e+00 - precision_26: 0.8000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0022 - accuracy: 0.5303 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.3846 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9460 - accuracy: 0.5858 - recall_26: 0.0128 - recall_27: 0.0000e+00 - precision_26: 0.4400 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9397 - accuracy: 0.5946 - recall_26: 0.0112 - recall_27: 0.0000e+00 - precision_26: 0.3429 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9381 - accuracy: 0.5954 - recall_26: 0.0129 - recall_27: 0.0000e+00 - precision_26: 0.3065 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9080 - accuracy: 0.6214 - recall_26: 0.0130 - recall_27: 0.0000e+00 - precision_26: 0.3088 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9361 - accuracy: 0.5960 - recall_26: 0.0157 - recall_27: 0.0000e+00 - precision_26: 0.3571 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9416 - accuracy: 0.5907 - recall_26: 0.0155 - recall_27: 0.0000e+00 - precision_26: 0.3458 - precision_27: 0.0000e+00\n",
      "Epoch 00297: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9432 - accuracy: 0.5895 - recall_26: 0.0149 - recall_27: 0.0000e+00 - precision_26: 0.3455 - precision_27: 0.0000e+00 - val_loss: 1.0100 - val_accuracy: 0.5029 - val_recall_26: 0.0548 - val_recall_27: 6.5920e-04 - val_precision_26: 0.4076 - val_precision_27: 1.0000 - lr: 0.0020\n",
      "Epoch 298/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0099 - accuracy: 0.5323 - recall_26: 0.0242 - recall_27: 0.0000e+00 - precision_26: 0.7500 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0038 - accuracy: 0.5298 - recall_26: 0.0093 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9469 - accuracy: 0.5860 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.4348 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9401 - accuracy: 0.5948 - recall_26: 0.0103 - recall_27: 0.0000e+00 - precision_26: 0.3438 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9382 - accuracy: 0.5957 - recall_26: 0.0129 - recall_27: 0.0000e+00 - precision_26: 0.3115 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9196 - accuracy: 0.6120 - recall_26: 0.0137 - recall_27: 0.0000e+00 - precision_26: 0.3288 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9373 - accuracy: 0.5952 - recall_26: 0.0175 - recall_27: 0.0000e+00 - precision_26: 0.3750 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9432 - accuracy: 0.5899 - recall_26: 0.0153 - recall_27: 0.0000e+00 - precision_26: 0.3611 - precision_27: 0.0000e+00\n",
      "Epoch 00298: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9432 - accuracy: 0.5899 - recall_26: 0.0153 - recall_27: 0.0000e+00 - precision_26: 0.3611 - precision_27: 0.0000e+00 - val_loss: 1.0098 - val_accuracy: 0.5026 - val_recall_26: 0.0548 - val_recall_27: 6.5920e-04 - val_precision_26: 0.4019 - val_precision_27: 1.0000 - lr: 0.0020\n",
      "Epoch 299/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0097 - accuracy: 0.5337 - recall_26: 0.0323 - recall_27: 0.0000e+00 - precision_26: 0.8000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0024 - accuracy: 0.5298 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.3571 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9455 - accuracy: 0.5858 - recall_26: 0.0128 - recall_27: 0.0000e+00 - precision_26: 0.4231 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9390 - accuracy: 0.5946 - recall_26: 0.0112 - recall_27: 0.0000e+00 - precision_26: 0.3429 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9372 - accuracy: 0.5958 - recall_26: 0.0143 - recall_27: 0.0000e+00 - precision_26: 0.3333 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9190 - accuracy: 0.6121 - recall_26: 0.0148 - recall_27: 0.0000e+00 - precision_26: 0.3421 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9368 - accuracy: 0.5952 - recall_26: 0.0180 - recall_27: 0.0000e+00 - precision_26: 0.3776 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9423 - accuracy: 0.5898 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.3628 - precision_27: 0.0000e+00\n",
      "Epoch 00299: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.9423 - accuracy: 0.5898 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.3628 - precision_27: 0.0000e+00 - val_loss: 1.0098 - val_accuracy: 0.5026 - val_recall_26: 0.0573 - val_recall_27: 6.5920e-04 - val_precision_26: 0.4036 - val_precision_27: 1.0000 - lr: 0.0020\n",
      "Epoch 300/1000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.0083 - accuracy: 0.5337 - recall_26: 0.0323 - recall_27: 0.0000e+00 - precision_26: 0.8000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0031 - accuracy: 0.5303 - recall_26: 0.0140 - recall_27: 0.0000e+00 - precision_26: 0.4000 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9611 - accuracy: 0.5701 - recall_26: 0.0125 - recall_27: 0.0000e+00 - precision_26: 0.4091 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9424 - accuracy: 0.5915 - recall_26: 0.0124 - recall_27: 0.0000e+00 - precision_26: 0.3750 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9455 - accuracy: 0.5871 - recall_26: 0.0153 - recall_27: 0.0000e+00 - precision_26: 0.3387 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9247 - accuracy: 0.6073 - recall_26: 0.0142 - recall_27: 0.0000e+00 - precision_26: 0.3099 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9195 - accuracy: 0.6121 - recall_26: 0.0148 - recall_27: 0.0000e+00 - precision_26: 0.3291 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9410 - accuracy: 0.5910 - recall_26: 0.0179 - recall_27: 0.0000e+00 - precision_26: 0.3670 - precision_27: 0.0000e+00\n",
      "Epoch 00300: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9430 - accuracy: 0.5898 - recall_26: 0.0161 - recall_27: 0.0000e+00 - precision_26: 0.3504 - precision_27: 0.0000e+00 - val_loss: 1.0097 - val_accuracy: 0.5028 - val_recall_26: 0.0586 - val_recall_27: 6.5920e-04 - val_precision_26: 0.4017 - val_precision_27: 1.0000 - lr: 0.0020\n",
      "Epoch 301/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0105 - accuracy: 0.5337 - recall_26: 0.0323 - recall_27: 0.0000e+00 - precision_26: 0.8000 - precision_27: 0.0000e+ - ETA: 0s - loss: 1.0036 - accuracy: 0.5303 - recall_26: 0.0116 - recall_27: 0.0000e+00 - precision_26: 0.3571 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9465 - accuracy: 0.5865 - recall_26: 0.0139 - recall_27: 0.0000e+00 - precision_26: 0.4800 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9400 - accuracy: 0.5951 - recall_26: 0.0122 - recall_27: 0.0000e+00 - precision_26: 0.3824 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9460 - accuracy: 0.5872 - recall_26: 0.0146 - recall_27: 0.0000e+00 - precision_26: 0.3448 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9248 - accuracy: 0.6074 - recall_26: 0.0135 - recall_27: 0.0000e+00 - precision_26: 0.3134 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9359 - accuracy: 0.5966 - recall_26: 0.0178 - recall_27: 0.0000e+00 - precision_26: 0.3864 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9409 - accuracy: 0.5913 - recall_26: 0.0192 - recall_27: 0.0000e+00 - precision_26: 0.3909 - precision_27: 0.0000e+ - ETA: 0s - loss: 0.9426 - accuracy: 0.5901 - recall_26: 0.0177 - recall_27: 0.0000e+00 - precision_26: 0.3782 - precision_27: 0.0000e+00\n",
      "Epoch 00301: val_loss did not improve from 1.00875\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.9426 - accuracy: 0.5901 - recall_26: 0.0177 - recall_27: 0.0000e+00 - precision_26: 0.3782 - precision_27: 0.0000e+00 - val_loss: 1.0096 - val_accuracy: 0.5028 - val_recall_26: 0.0586 - val_recall_27: 6.5920e-04 - val_precision_26: 0.4017 - val_precision_27: 1.0000 - lr: 0.0020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16fb6bb2e48>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "logdir = \"logs\\\\scalars\\\\\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "weight_path=\"{}_weights.best.hdf5\".format('stroke_lstm_model')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=10, verbose=1, mode='auto', epsilon=0.0001, cooldown=5, min_lr=0.001)\n",
    "early = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=100) \n",
    "callbacks_list = [checkpoint\n",
    "                  , early\n",
    "                  , reduceLROnPlat\n",
    "                  , tensorboard_callback\n",
    "                 ]\n",
    "\n",
    "\n",
    "from IPython.display import clear_output\n",
    "model.fit(train_dataset,\n",
    "                      validation_data = v_dataset, \n",
    "#                       batch_size = 10,\n",
    "                      epochs = 1000,\n",
    "                      use_multiprocessing = True,\n",
    "                      callbacks = callbacks_list)\n",
    "\n",
    "# model.fit([train_X, train_X2], [train_y, train_y],\n",
    "#                       validation_data = ([valid_X, valid_X2], [valid_y, valid_y]), \n",
    "#                       batch_size = batch_size,\n",
    "#                       epochs = 500,\n",
    "#                       callbacks = callbacks_list)\n",
    "\n",
    "#clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9b4790925984514e64ca5a9b46de8b309062e0cf",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] 0.8723 - accuracy: 0.6701 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+ - 0s 9ms/step - loss: 0.9350 - accuracy: 0.6083 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+0 - 0s 11ms/step - loss: 0.9339 - accuracy: 0.6109 - recall_26: 0.0000e+00 - recall_27: 0.0000e+00 - precision_26: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "{'loss': 0.9339232444763184, 'accuracy': 0.6109482049942017, 'recall_26': 0.0, 'recall_27': 0.0, 'precision_26': 0.0, 'precision_27': 0.0}\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(weight_path)\n",
    "lstm_results = model.evaluate(test_dataset, return_dict=True)\n",
    "print(lstm_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9339232444763184, 'accuracy': 0.6109482049942017, 'recall_26': 0.0, 'recall_27': 0.0, 'precision_26': 0.0, 'precision_27': 0.0}\n"
     ]
    }
   ],
   "source": [
    "print(lstm_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./trained_model.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c3340d6d6ce75585f90c98f1728b1cd664d7f33f"
   },
   "source": [
    "Load and normalize the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test(ts_length = 150000):\n",
    "    base_dir = 'input/test/'\n",
    "    test_files = [f for f in listdir(base_dir) if isfile(join(base_dir, f))]\n",
    "\n",
    "    ts = np.empty([len(test_files), ts_length])\n",
    "    ids = []\n",
    "    \n",
    "    i = 0\n",
    "    for f in tqdm_notebook(test_files):\n",
    "        ids.append(splitext(f)[0])\n",
    "        t_df = pd.read_csv(base_dir + f, dtype={\"acoustic_data\": np.int8})\n",
    "        ts[i, :] = t_df['acoustic_data'].values\n",
    "        i = i + 1\n",
    "\n",
    "    return ts, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0f005579ea08913f4f68a3749bd761df6cef2b1b"
   },
   "outputs": [],
   "source": [
    "test_data, test_ids = load_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0c3b7a864a9f53af142a08883def46c3866c5464"
   },
   "outputs": [],
   "source": [
    "X_test = test_data\n",
    "X_test = np.expand_dims(X_test, 2)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bf9b36929e5228d4d94b3b7ad1b9011bf088ac44"
   },
   "source": [
    "Load best model and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "435449fda2bf96635e67d69f56227e140c4cea99"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9aaf9fb44edba5879a75c68820527d9180d2b3c6"
   },
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({'seg_id': test_ids, 'time_to_failure': y_pred[:, 0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9b9d5c63161f637de2e39b59e8e4d7c2f3049581"
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"submission.csv\"> Download File </a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb.transform([-1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "nn = np.array([[1., 0.,2], [2., 1.,3], [0., 0.,4]])\n",
    "print(nn[1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "print(valid_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(valid_X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset.take(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, \n",
    "                          loss='categorical_crossentropy',\n",
    "                          loss_weights=[1., 1.]\n",
    "#                           loss_weights=[1.]\n",
    "#               \n",
    "                            , metrics=[Recall(thresholds=0.5, class_id=0, top_k=1)\n",
    "                                 , Recall(thresholds=0.5, class_id=2, top_k=1)\n",
    "                                   , Precision(thresholds=0.5, class_id=0, top_k=1)\n",
    "                                  , Precision(thresholds=0.5, class_id=2, top_k=1)\n",
    "                                  ]\n",
    "             )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
