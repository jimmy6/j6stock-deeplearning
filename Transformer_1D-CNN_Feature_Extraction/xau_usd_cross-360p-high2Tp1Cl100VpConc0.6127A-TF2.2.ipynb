{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": false,
    "_uuid": "e1baa7518f18a7ff1f2767df1b29c051955502ff"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow_addons as tfa\n",
    "from os import listdir, makedirs\n",
    "from os.path import isfile, join, basename, splitext, isfile, exists\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.metrics import top_k_categorical_accuracy, CategoricalHinge, Recall, Precision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "# from tensorflow.keras import metrics\n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.compat.v2.keras.layers import Input\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import random, os, sys\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.initializers import *\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.layers import Layer\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "tf.compat.v1.disable_eager_execution\n",
    "pd.set_option('precision', 30)\n",
    "np.set_printoptions(precision = 30)\n",
    "\n",
    "\n",
    "#np.random.seed(368)\n",
    "#tf.random.set_seed(368)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Size : <TensorSliceDataset shapes: (((3,), (5,)), (3,)), types: ((tf.float64, tf.float64), tf.int32)>\n",
      "Total Filtered Size : <TensorSliceDataset shapes: (((3,), (5,)), (3,)), types: ((tf.float64, tf.float64), tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "xfile='C:\\\\workspace\\\\j6stock\\\\xau_usd_OHLC2.0Tp1.0Cl100Vp.txt'\n",
    "\n",
    "seq_len = 60*6 #60*10 # 3 days + 2 features is enough memory\n",
    "batch_size = int(2048/3)       # Batch size\n",
    "# mini_batch_size = 64       # Batch size\n",
    "\n",
    "learning_rate = 0.001  #0.0001  # Learning rate (default is 0.001)\n",
    "epochs = 500\n",
    "\n",
    "\n",
    "y_column = 6\n",
    "compute_val_at = 0\n",
    "acc_filtered_r = 0.8\n",
    "\n",
    "\n",
    "upperTailFilter = 0.4\n",
    "lowerTailFilter = 0.4\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import debug as tf_debug\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt2\n",
    "import pandas as pd\n",
    "from pandas import datetime\n",
    "import math, time\n",
    "import itertools\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers.core import Dense, Dropout, Activation\n",
    "#from keras.layers.recurrent import LSTM\n",
    "#from keras.models import load_model\n",
    "#import keras\n",
    "import pandas as pd ## can be remove once pandas_datareader 0.7 using\n",
    "pd.core.common.is_list_like = pd.api.types.is_list_like ## can be remove once pandas_datareader 0.7 using\n",
    "import pandas_datareader.data as web\n",
    "\n",
    "\n",
    "\n",
    "def get_stock_data(normalize=True, ma=[]):\n",
    "    \"\"\"\n",
    "    Return a dataframe of that stock and normalize all the values. \n",
    "    (Optional: create moving average)\n",
    "    \"\"\"\n",
    "    global upperTailFilter, lowerTailFilter\n",
    "    \n",
    "    df = pd.read_csv(filepath_or_buffer  = xfile )\n",
    "    #TODO Use previous close instead of open\n",
    "    df['change'] = df['close'] - df['open']\n",
    "    df['tail_upper'] = df['high'].copy()\n",
    "    df['tail_lower'] = df['low'].copy()\n",
    "    for i, row in df.iterrows():\n",
    "        df.at[i, 'tail_upper'] = df.at[i, 'high'] - (df.at[i, 'open'] if df.at[i, 'open'] > df.at[i, 'close'] else df.at[i, 'close'])\n",
    "        df.at[i, 'tail_lower'] = (df.at[i, 'close'] if df.at[i, 'close'] < df.at[i, 'open'] else df.at[i, 'open']) - df.at[i, 'low']\n",
    "    \n",
    "    df.dropna(inplace=True)\n",
    "    df.drop('open', axis=1, inplace=True)\n",
    "    df.drop('high', axis=1, inplace=True)\n",
    "    df.drop('low', axis=1, inplace=True)\n",
    "    # Moving Average    \n",
    "    if ma != []:\n",
    "        for moving in ma:\n",
    "            df['{}ma'.format(moving)] = df['close'].rolling(window=moving).mean() \n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    if normalize:\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        #df['open'] = min_max_scaler.fit_transform(df.open.values.reshape(-1,1))\n",
    "        #df['high'] = min_max_scaler.fit_transform(df.high.values.reshape(-1,1))\n",
    "        #df['low'] = min_max_scaler.fit_transform(df.low.values.reshape(-1,1))\n",
    "        #df['vol'] = min_max_scaler.fit_transform(df.vol.values.reshape(-1,1))\n",
    "        df['close'] = min_max_scaler.fit_transform(df['close'].values.reshape(-1,1))\n",
    "#         df['change'] = min_max_scaler.fit_transform(df['change'].values.reshape(-1,1)) # no rescale for keep the negative value\n",
    "        df['tail_upper'] = min_max_scaler.fit_transform(df['tail_upper'].values.reshape(-1,1))\n",
    "        upperTailFilter = min_max_scaler.transform([[upperTailFilter]])[0][0] \n",
    "        df['tail_lower'] = min_max_scaler.fit_transform(df['tail_lower'].values.reshape(-1,1))\n",
    "        lowerTailFilter = min_max_scaler.transform([[lowerTailFilter]])[0][0] \n",
    "        \n",
    "        if ma != []:\n",
    "            for moving in ma:\n",
    "                df['{}ma'.format(moving)] = min_max_scaler.fit_transform(df['{}ma'.format(moving)].values.reshape(-1,1))   \n",
    "                #pd.concat([min_max_scaler.fit_transform(df['{}ma'.format(moving)].values.reshape(-1,1)), df], axis=1)\n",
    "                ma_data = df['{}ma'.format(moving)]\n",
    "                df.drop(labels=['{}ma'.format(moving)], axis=1, inplace=True)\n",
    "                df = pd.concat([ma_data, df], axis=1)\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    \n",
    "    # Move y_result to the rightmost for the ease of training\n",
    "    adj_close = df['y_result']\n",
    "    df.drop(labels=['y_result'], axis=1, inplace=True)\n",
    "    df = pd.concat([df, adj_close], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "#df = get_stock_data( ma=[50, 100, 200])\n",
    "df = get_stock_data(ma=[60, 240])\n",
    "\n",
    "# amount_of_features = len(df.columns)-1+(input2Length*-1)\n",
    "\n",
    "# def load_data(stock, seq_len):\n",
    "#     print (\"Amount of features = {}\".format(amount_of_features))\n",
    "#     data = stock.as_matrix()\n",
    "#     sequence_length = seq_len + 1 # index starting from 0\n",
    "#     x_result = []\n",
    "#     x_result2 = []\n",
    "#     y_result = []\n",
    "#     for index in range(seq_len, len(data) ): # maxmimum date = lastest date - sequence length\n",
    "#         x_result.append(data[index-seq_len: index,\n",
    "#                              :-1 + (input2Length*-1) # -2 is ignore Input2 features\n",
    "#                             ]) # index : index + 22days\n",
    "#         x_result2.append(data[index, -1 + (input2Length*-1):-1])\n",
    "#         y_result.append(data[index ,-1]);\n",
    "\n",
    "#     x_result, x_result2, y_result = shuffle(x_result, x_result2, y_result , random_state=2)\n",
    "\n",
    "#     #print('---', data[0])\n",
    "#     #print('---', x_result[0])\n",
    "#     #print('---', y_result[0])\n",
    "#     x_result = np.array(x_result)\n",
    "#     x_result2 = np.array(x_result2)\n",
    "#     y_result = np.array(y_result)\n",
    "#     print (\"Amount of data = {}\".format(y_result.shape[0]))\n",
    "\n",
    "#     percentageSplit = 0.5 # 60% split\n",
    "#     row = round(percentageSplit * y_result.shape[0]) \n",
    "#     print (\"Split = {}\".format(row))\n",
    " \n",
    "#     X_train = x_result[:int(row), :] \n",
    "#     X_train2 = x_result2[:int(row), :] \n",
    "#     y_train = y_result[:int(row)] \n",
    "#     print (\"Amount of training data = {}\".format(y_train.shape[0]))\n",
    "#     X_test = x_result[int(row):, :]\n",
    "#     X_test2 = x_result2[int(row):, :]\n",
    "#     y_test = y_result[int(row):]\n",
    "#     # filter for 1 and -1 for validation only\n",
    "#     X_test = X_test[y_test[:]!=0,:]\n",
    "#     X_test2 = X_test2[y_test[:]!=0,:]\n",
    "#     y_test = y_test[y_test[:]!=0]\n",
    "    \n",
    "#     # split 50% again for test and validation set\n",
    "#     row = round(percentageSplit * y_test.shape[0]) \n",
    "#     X_val = X_test[int(row):, :]\n",
    "#     X_val2 = X_test2[int(row):, :]\n",
    "#     y_val = y_test[int(row):]\n",
    "#     print (\"Amount of validation data = {}\".format(y_val.shape[0]))\n",
    "#     X_test = X_test[:int(row), :]\n",
    "#     X_test2 = X_test2[:int(row), :]\n",
    "#     y_test = y_test[:int(row)]\n",
    "#     print (\"Amount of testing data = {}\".format(y_test.shape[0]))\n",
    "#     #print(result.shape[0], len(y_result), int(row), y_result[int(row):])\n",
    "#     #X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], amount_of_features-1))\n",
    "#     #X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], amount_of_features-1))    \n",
    "#     return [X_train, X_train2, y_train, X_test, X_test2, y_test, X_val, X_val2, y_val]\n",
    "\n",
    "\n",
    "\n",
    "classes = [1, 0, -1]\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(classes)\n",
    "lb.transform([-1, 0, 1])\n",
    "\n",
    "df_to_dataset = df[[ 'change', '60ma', '240ma'\n",
    "                   ]].copy()\n",
    "df_to_dataset_input2 = df[[ 'tail_upper', 'tail_lower', 'change' ,'cross_360p_high', 'cross_1440p_high'\n",
    "                          ]].copy()\n",
    "\n",
    "amount_of_features = len(df_to_dataset.columns)\n",
    "input2Length = len(df_to_dataset_input2.columns)\n",
    "\n",
    "df.drop(labels=['close'], axis=1, inplace=True)\n",
    "df.drop(labels=['change'], axis=1, inplace=True)\n",
    "df.drop(labels=['tail_upper'], axis=1, inplace=True)\n",
    "df.drop(labels=['tail_lower'], axis=1, inplace=True)\n",
    "df.drop(labels=['cross_360p_high'], axis=1, inplace=True)\n",
    "df.drop(labels=['cross_1440p_high'], axis=1, inplace=True)\n",
    "\n",
    "df_to_dataset_y = lb.transform(df[['y_result']].copy())\n",
    "df.drop(labels=['y_result'], axis=1, inplace=True)\n",
    "\n",
    "train_data_no = int(len(df_to_dataset_y)/2)\n",
    "test_data_no = int(train_data_no/2)\n",
    "v_data_no = test_data_no\n",
    "\n",
    "train_x_1 = df_to_dataset.iloc[:train_data_no].values\n",
    "train_x_2 = df_to_dataset_input2.iloc[:train_data_no].values\n",
    "train_y = df_to_dataset_y[:train_data_no]                                                   \n",
    "\n",
    "test_x_1 = df_to_dataset.iloc[train_data_no:train_data_no+test_data_no].values\n",
    "test_x_2 = df_to_dataset_input2.iloc[train_data_no:train_data_no+test_data_no].values\n",
    "test_y = df_to_dataset_y[train_data_no:train_data_no+test_data_no]                                                   \n",
    "\n",
    "v_x_1 = df_to_dataset.iloc[train_data_no+test_data_no:].values\n",
    "v_x_2 = df_to_dataset_input2.iloc[train_data_no+test_data_no:].values\n",
    "v_y = df_to_dataset_y[train_data_no+test_data_no:]                                                   \n",
    "\n",
    "\n",
    "def make_window_dataset(ds, window_size=seq_len, shift=1, stride=1):\n",
    "  windows = ds.window(window_size, shift=shift, stride=stride)\n",
    "\n",
    "  def batch(sub):\n",
    "    ret = ()\n",
    "    for index in range(2):\n",
    "      ret = ret + ( sub[index].batch(window_size, drop_remainder=True), )\n",
    "    return ret\n",
    "  def sub_to_batch(sub, sub2): \n",
    "    return tf.data.Dataset.zip((batch(sub), (sub2.batch(window_size, drop_remainder=True))))\n",
    "  \n",
    "  windows = windows.flat_map(sub_to_batch)\n",
    "  windows = windows.map(lambda sub1, sub2: ((sub1[0], sub1[1][-1:][0]), (sub2[-1:][0] #, sub2[-1:][0]\n",
    "                                                                        )))\n",
    "  return windows\n",
    "\n",
    "def filter_fn(a, b):\n",
    "#   return a[1][0]>=upperTailFilter or a[1][1]>=lowerTailFilter or a[1][3]==1 or a[1][4]==1\n",
    "  return a[1][3]==1\n",
    "\n",
    "train_dataset_x = tf.data.Dataset.from_tensor_slices(((train_x_1, train_x_2),(train_y)))\n",
    "train_dataset = make_window_dataset(train_dataset_x).filter(filter_fn).cache().batch(batch_size, drop_remainder=True) \n",
    "\n",
    "test_dataset_x = tf.data.Dataset.from_tensor_slices(((test_x_1, test_x_2),(test_y)))\n",
    "test_dataset = make_window_dataset(test_dataset_x).filter(filter_fn).cache().batch(batch_size, drop_remainder=True)\n",
    "\n",
    "v_dataset_x = tf.data.Dataset.from_tensor_slices(((v_x_1, v_x_2),(v_y)))\n",
    "v_dataset = make_window_dataset(v_dataset_x).filter(filter_fn).cache().batch(batch_size, drop_remainder=True)\n",
    "\n",
    "\n",
    "print('Total Size : {}'.format(train_dataset_x))\n",
    "print('Total Filtered Size : {}'.format(v_dataset_x))\n",
    "\n",
    "\n",
    "# X_tr, X_tr2, lab_tr, X_test, X_test2, lab_test, X_vld, X_vld2, lab_vld = load_data(df, seq_len)\n",
    "# y_tr = lb.transform(lab_tr)\n",
    "# y_vld = lb.transform(lab_vld)\n",
    "# y_test = lb.transform(lab_test)\n",
    "\n",
    "\n",
    "# train_X = X_tr\n",
    "# train_X2 = X_tr2\n",
    "# train_y = y_tr\n",
    "# valid_X = X_vld\n",
    "# valid_X2 = X_vld2\n",
    "# valid_y = y_vld\n",
    "# test_X = X_test\n",
    "# test_X2 = X_test2\n",
    "# test_y = y_test\n",
    "\n",
    "# print(train_X.shape)\n",
    "# print(train_y[0])\n",
    "# print(train_y[1])\n",
    "# print(train_y[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/shujian/transformer-with-lstm\n",
    "\n",
    "try:\n",
    "    from dataloader import TokenList, pad_to_longest\n",
    "    # for transformer\n",
    "except: pass\n",
    "\n",
    "\n",
    "\n",
    "embed_size = 60\n",
    "\n",
    "class LayerNormalization(Layer):\n",
    "    def __init__(self, eps=1e-6, **kwargs):\n",
    "        self.eps = eps\n",
    "        super(LayerNormalization, self).__init__(**kwargs)\n",
    "    def build(self, input_shape):\n",
    "        self.gamma = self.add_weight(name='gamma', shape=input_shape[-1:],\n",
    "                                     initializer=Ones(), trainable=True)\n",
    "        self.beta = self.add_weight(name='beta', shape=input_shape[-1:],\n",
    "                                    initializer=Zeros(), trainable=True)\n",
    "        super(LayerNormalization, self).build(input_shape)\n",
    "    def call(self, x):\n",
    "        mean = K.mean(x, axis=-1, keepdims=True)\n",
    "        std = K.std(x, axis=-1, keepdims=True)\n",
    "        return self.gamma * (x - mean) / (std + self.eps) + self.beta\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "class ScaledDotProductAttention():\n",
    "    def __init__(self, d_model, attn_dropout=0.1):\n",
    "        self.temper = np.sqrt(d_model)\n",
    "        self.dropout = Dropout(attn_dropout)\n",
    "    def __call__(self, q, k, v, mask):\n",
    "        attn = Lambda(lambda x:K.batch_dot(x[0],x[1],axes=[2,2])/self.temper)([q, k])\n",
    "        if mask is not None:\n",
    "            mmask = Lambda(lambda x:(-1e+10)*(1-x))(mask)\n",
    "            attn = Add()([attn, mmask])\n",
    "        attn = Activation('softmax')(attn)\n",
    "        attn = self.dropout(attn)\n",
    "        output = Lambda(lambda x:K.batch_dot(x[0], x[1]))([attn, v])\n",
    "        return output, attn\n",
    "\n",
    "class MultiHeadAttention():\n",
    "    # mode 0 - big martixes, faster; mode 1 - more clear implementation\n",
    "    def __init__(self, n_head, d_model, d_k, d_v, dropout, mode=0, use_norm=True):\n",
    "        self.mode = mode\n",
    "        self.n_head = n_head\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        self.dropout = dropout\n",
    "        if mode == 0:\n",
    "            self.qs_layer = Dense(n_head*d_k, use_bias=False)\n",
    "            self.ks_layer = Dense(n_head*d_k, use_bias=False)\n",
    "            self.vs_layer = Dense(n_head*d_v, use_bias=False)\n",
    "        elif mode == 1:\n",
    "            self.qs_layers = []\n",
    "            self.ks_layers = []\n",
    "            self.vs_layers = []\n",
    "            for _ in range(n_head):\n",
    "                self.qs_layers.append(TimeDistributed(Dense(d_k, use_bias=False)))\n",
    "                self.ks_layers.append(TimeDistributed(Dense(d_k, use_bias=False)))\n",
    "                self.vs_layers.append(TimeDistributed(Dense(d_v, use_bias=False)))\n",
    "        self.attention = ScaledDotProductAttention(d_model)\n",
    "        self.layer_norm = LayerNormalization() if use_norm else None\n",
    "        self.w_o = TimeDistributed(Dense(d_model))\n",
    "\n",
    "    def __call__(self, q, k, v, mask=None):\n",
    "        d_k, d_v = self.d_k, self.d_v\n",
    "        n_head = self.n_head\n",
    "\n",
    "        if self.mode == 0:\n",
    "            qs = self.qs_layer(q)  # [batch_size, len_q, n_head*d_k]\n",
    "            ks = self.ks_layer(k)\n",
    "            vs = self.vs_layer(v)\n",
    "\n",
    "            def reshape1(x):\n",
    "                s = tf.shape(x)   # [batch_size, len_q, n_head * d_k]\n",
    "                x = tf.reshape(x, [s[0], s[1], n_head, d_k])\n",
    "                x = tf.transpose(x, [2, 0, 1, 3])  \n",
    "                x = tf.reshape(x, [-1, s[1], d_k])  # [n_head * batch_size, len_q, d_k]\n",
    "                return x\n",
    "            qs = Lambda(reshape1)(qs)\n",
    "            ks = Lambda(reshape1)(ks)\n",
    "            vs = Lambda(reshape1)(vs)\n",
    "\n",
    "            if mask is not None:\n",
    "                mask = Lambda(lambda x:K.repeat_elements(x, n_head, 0))(mask)\n",
    "            head, attn = self.attention(qs, ks, vs, mask=mask)  \n",
    "                \n",
    "            def reshape2(x):\n",
    "                s = tf.shape(x)   # [n_head * batch_size, len_v, d_v]\n",
    "                x = tf.reshape(x, [n_head, -1, s[1], s[2]]) \n",
    "                x = tf.transpose(x, [1, 2, 0, 3])\n",
    "                x = tf.reshape(x, [-1, s[1], n_head*d_v])  # [batch_size, len_v, n_head * d_v]\n",
    "                return x\n",
    "            head = Lambda(reshape2)(head)\n",
    "        elif self.mode == 1:\n",
    "            heads = []; attns = []\n",
    "            for i in range(n_head):\n",
    "                qs = self.qs_layers[i](q)   \n",
    "                ks = self.ks_layers[i](k) \n",
    "                vs = self.vs_layers[i](v) \n",
    "                head, attn = self.attention(qs, ks, vs, mask)\n",
    "                heads.append(head); attns.append(attn)\n",
    "            head = Concatenate()(heads) if n_head > 1 else heads[0]\n",
    "            attn = Concatenate()(attns) if n_head > 1 else attns[0]\n",
    "\n",
    "        outputs = self.w_o(head)\n",
    "        outputs = Dropout(self.dropout)(outputs)\n",
    "        if not self.layer_norm: return outputs, attn\n",
    "        # outputs = Add()([outputs, q]) # sl: fix\n",
    "        return self.layer_norm(outputs), attn\n",
    "\n",
    "class PositionwiseFeedForward():\n",
    "    def __init__(self, d_hid, d_inner_hid, dropout=0.1):\n",
    "        self.w_1 = Conv1D(d_inner_hid, 1, activation='tanh')\n",
    "        self.w_2 = Conv1D(d_hid, 1)\n",
    "        self.layer_norm = LayerNormalization()\n",
    "        self.dropout = Dropout(dropout)\n",
    "    def __call__(self, x):\n",
    "        output = self.w_1(x) \n",
    "        output = self.w_2(output)\n",
    "        output = self.dropout(output)\n",
    "        output = Add()([output, x])\n",
    "        return self.layer_norm(output)\n",
    "\n",
    "class EncoderLayer():\n",
    "    def __init__(self, d_model, d_inner_hid, n_head, d_k, d_v, dropout=0.1):\n",
    "        self.self_att_layer = MultiHeadAttention(n_head, d_model, d_k, d_v, dropout=dropout)\n",
    "        self.pos_ffn_layer  = PositionwiseFeedForward(d_model, d_inner_hid, dropout=dropout)\n",
    "    def __call__(self, enc_input, mask=None):\n",
    "        output, slf_attn = self.self_att_layer(enc_input, enc_input, enc_input, mask=mask)\n",
    "        output = self.pos_ffn_layer(output)\n",
    "        return output, slf_attn\n",
    "\n",
    "\n",
    "def GetPosEncodingMatrix(max_len, d_emb):\n",
    "    pos_enc = np.array([\n",
    "        [pos / np.power(10000, 2 * (j // 2) / d_emb) for j in range(d_emb)] \n",
    "        if pos != 0 else np.zeros(d_emb) \n",
    "            for pos in range(max_len)\n",
    "            ])\n",
    "    pos_enc[1:, 0::2] = np.sin(pos_enc[1:, 0::2]) # dim 2i\n",
    "    pos_enc[1:, 1::2] = np.cos(pos_enc[1:, 1::2]) # dim 2i+1\n",
    "    return pos_enc\n",
    "\n",
    "def GetPadMask(q, k):\n",
    "    ones = K.expand_dims(K.ones_like(q, 'float32'), -1)\n",
    "    mask = K.cast(K.expand_dims(K.not_equal(k, 0), 1), 'float32')\n",
    "    mask = K.batch_dot(ones, mask, axes=[2,1])\n",
    "    return mask\n",
    "\n",
    "def GetSubMask(s):\n",
    "    len_s = tf.shape(s)[1]\n",
    "    bs = tf.shape(s)[:1]\n",
    "    mask = K.cumsum(tf.eye(len_s, batch_shape=bs), 1)\n",
    "    return mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
    "def CnnTransformerModel():\n",
    "#    i = tf.compat.v2.keras.layers.Flatten(input_shape=(batch_size, amount_of_features))\n",
    "    i = tf.compat.v2.keras.layers.Input(shape = (seq_len, amount_of_features)#, batch_size=mini_batch_size\n",
    "                                       )\n",
    "    \n",
    "    x = tf.compat.v2.keras.layers.Convolution1D(64*2, kernel_size = 3, dilation_rate=2)(i)\n",
    "#     x = tf.compat.v2.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.compat.v2.keras.layers.Activation('tanh')(x)\n",
    "    x = tf.keras.layers.Dropout(rate=0.2)(x)\n",
    "    x = tf.compat.v2.keras.layers.Convolution1D(64, kernel_size = 3, dilation_rate=2)(x)\n",
    "    x = tf.compat.v2.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.compat.v2.keras.layers.Activation('tanh')(x)\n",
    "    x = tf.keras.layers.Dropout(rate=0.2)(x)\n",
    "    x = tf.compat.v2.keras.layers.Convolution1D(64, kernel_size = 3, dilation_rate=2)(x)\n",
    "    x = tf.compat.v2.keras.layers.Activation('tanh')(x)\n",
    "    x = tf.keras.layers.Dropout(rate=0.2)(x)\n",
    "    x = tf.compat.v2.keras.layers.Convolution1D(64, kernel_size = 3, dilation_rate=2)(x)\n",
    "    x = tf.compat.v2.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.compat.v2.keras.layers.Activation('tanh')(x)\n",
    "    x = tf.keras.layers.Dropout(rate=0.2)(x)\n",
    "\n",
    "    x2 = tf.compat.v2.keras.layers.Convolution1D(64*2, kernel_size = 3, strides=2)(i)\n",
    "#     x2 = tf.compat.v2.keras.layers.BatchNormalization()(x2)\n",
    "    x2 = tf.compat.v2.keras.layers.Activation('tanh')(x2)\n",
    "    x2 = tf.keras.layers.Dropout(rate=0.2)(x2)\n",
    "    x2 = tf.compat.v2.keras.layers.Convolution1D(64, kernel_size = 3, strides=2)(x2)\n",
    "    x2 = tf.compat.v2.keras.layers.BatchNormalization()(x2)\n",
    "    x2 = tf.compat.v2.keras.layers.Activation('tanh')(x2)\n",
    "    x2 = tf.keras.layers.Dropout(rate=0.2)(x2)\n",
    "    x2 = tf.compat.v2.keras.layers.Convolution1D(64, kernel_size = 3, strides=2)(x2)\n",
    "    x2 = tf.compat.v2.keras.layers.Activation('tanh')(x2)\n",
    "    x2 = tf.keras.layers.Dropout(rate=0.2)(x2)\n",
    "    x2 = tf.compat.v2.keras.layers.Convolution1D(64, kernel_size = 3, strides=2)(x2)\n",
    "    x2 = tf.compat.v2.keras.layers.BatchNormalization()(x2)\n",
    "    x2 = tf.compat.v2.keras.layers.Activation('tanh')(x2)\n",
    "    x2 = tf.keras.layers.Dropout(rate=0.2)(x2)\n",
    "\n",
    "    \n",
    "#     x = tf.compat.v2.keras.layers.Convolution1D(32, kernel_size = 4, strides = 2)(x)\n",
    "#     x = tf.compat.v2.keras.layers.BatchNormalization()(x)\n",
    "#     x = tf.compat.v2.keras.layers.Activation('relu')(x)\n",
    "#     x = tf.keras.layers.Dropout(rate=0.2)(x)\n",
    "#     x = tf.keras.layers.MaxPool1D(pool_size=2)(x)\n",
    "#     x = tf.compat.v2.keras.layers.Convolution1D(32, kernel_size = 4, dilation_rate=5)(x)\n",
    "#     x = tf.compat.v2.keras.layers.BatchNormalization()(x)\n",
    "#     x = tf.compat.v2.keras.layers.Activation('relu')(x)\n",
    "#     x = (CuDNNLSTM(16, return_sequences = True, return_state = False))(x)\n",
    "#     x, slf_attn = MultiHeadAttention(n_head=int(80), d_model=300, d_k=64, d_v=64, dropout=0.1)(x, x, x)\n",
    "    \n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    avg_pool2 = GlobalAveragePooling1D()(x2)\n",
    "    max_pool2 = GlobalMaxPooling1D()(x2)\n",
    "    \n",
    "    x = Dense(300)(concatenate([max_pool, avg_pool, max_pool2, avg_pool2]))\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('tanh')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = Dense(600)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('tanh')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    x = Dense(1200)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('tanh')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    x = Dense(600)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('tanh')(x)    \n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    x = Dense(300)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('tanh')(x)    \n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = Dense(130)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('tanh')(x)    \n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = Dense(70)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('tanh')(x)    \n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = Dense(35)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('tanh')(x)    \n",
    "    \n",
    "    x = Dense(15)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('tanh')(x)    \n",
    "    \n",
    "    x = Dense(7)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('tanh')(x)\n",
    "    \n",
    "    tailInput = Input(shape=(input2Length,))\n",
    "    tailLayers = Dense(input2Length, activation='tanh')(tailInput)\n",
    "    tailLayers = Dense(input2Length*2, activation='tanh')(tailInput)\n",
    "    tailLayers = Dense(input2Length*2*2, activation='tanh')(tailInput)\n",
    "    tailLayers = BatchNormalization()(tailInput)\n",
    "    tailLayers = Dropout(0.2)(tailInput)\n",
    "    tailLayers = Dense(input2Length*2*2*2, activation='tanh')(tailInput)\n",
    "    tailLayers = BatchNormalization()(tailInput)\n",
    "    tailLayers = Dropout(0.2)(tailInput)\n",
    "    tailLayers = Dense(input2Length*2*2, activation='tanh')(tailInput)    \n",
    "    tailLayers = Dense(input2Length*2, activation='tanh')(tailInput)\n",
    "    tailLayers = Dense(3, activation='tanh')(tailInput)\n",
    "    \n",
    "#     concat = concatenate([avg_pool, max_pool, tailLayers])\n",
    "    concat = concatenate([x, tailLayers])\n",
    "\n",
    "    y = Dense(3,activation = 'softmax')(concat)\n",
    "    \n",
    "\n",
    "    return Model(inputs = [i, tailInput], outputs = [y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_21 (InputLayer)           [(None, 360, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_80 (Conv1D)              (None, 356, 128)     1280        input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_84 (Conv1D)              (None, 179, 128)     1280        input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 356, 128)     0           conv1d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 179, 128)     0           conv1d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_164 (Dropout)           (None, 356, 128)     0           activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_168 (Dropout)           (None, 179, 128)     0           activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_81 (Conv1D)              (None, 352, 64)      24640       dropout_164[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_85 (Conv1D)              (None, 89, 64)       24640       dropout_168[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 352, 64)      256         conv1d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 89, 64)       256         conv1d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 352, 64)      0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 89, 64)       0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_165 (Dropout)           (None, 352, 64)      0           activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_169 (Dropout)           (None, 89, 64)       0           activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_82 (Conv1D)              (None, 348, 64)      12352       dropout_165[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_86 (Conv1D)              (None, 44, 64)       12352       dropout_169[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 348, 64)      0           conv1d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 44, 64)       0           conv1d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_166 (Dropout)           (None, 348, 64)      0           activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_170 (Dropout)           (None, 44, 64)       0           activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_83 (Conv1D)              (None, 344, 64)      12352       dropout_166[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_87 (Conv1D)              (None, 21, 64)       12352       dropout_170[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 344, 64)      256         conv1d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 21, 64)       256         conv1d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 344, 64)      0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 21, 64)       0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_167 (Dropout)           (None, 344, 64)      0           activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_171 (Dropout)           (None, 21, 64)       0           activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_20 (Global (None, 64)           0           dropout_167[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_20 (Gl (None, 64)           0           dropout_167[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_21 (Global (None, 64)           0           dropout_171[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_21 (Gl (None, 64)           0           dropout_171[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 256)          0           global_max_pooling1d_20[0][0]    \n",
      "                                                                 global_average_pooling1d_20[0][0]\n",
      "                                                                 global_max_pooling1d_21[0][0]    \n",
      "                                                                 global_average_pooling1d_21[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_158 (Dense)               (None, 300)          77100       concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 300)          1200        dense_158[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 300)          0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_172 (Dropout)           (None, 300)          0           activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_159 (Dense)               (None, 600)          180600      dropout_172[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 600)          2400        dense_159[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 600)          0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_173 (Dropout)           (None, 600)          0           activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_160 (Dense)               (None, 1200)         721200      dropout_173[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 1200)         4800        dense_160[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 1200)         0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_174 (Dropout)           (None, 1200)         0           activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_161 (Dense)               (None, 600)          720600      dropout_174[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 600)          2400        dense_161[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 600)          0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_175 (Dropout)           (None, 600)          0           activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_162 (Dense)               (None, 300)          180300      dropout_175[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 300)          1200        dense_162[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 300)          0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_176 (Dropout)           (None, 300)          0           activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_163 (Dense)               (None, 130)          39130       dropout_176[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 130)          520         dense_163[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 130)          0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_177 (Dropout)           (None, 130)          0           activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_164 (Dense)               (None, 70)           9170        dropout_177[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 70)           280         dense_164[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 70)           0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_178 (Dropout)           (None, 70)           0           activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_165 (Dense)               (None, 35)           2485        dropout_178[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 35)           140         dense_165[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 35)           0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_166 (Dense)               (None, 15)           540         activation_195[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 15)           60          dense_166[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 15)           0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_167 (Dense)               (None, 7)            112         activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 7)            28          dense_167[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_22 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 7)            0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_174 (Dense)               (None, 3)            18          input_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 10)           0           activation_197[0][0]             \n",
      "                                                                 dense_174[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_175 (Dense)               (None, 3)            33          concatenate_16[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 2,046,588\n",
      "Trainable params: 2,039,562\n",
      "Non-trainable params: 7,026\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = CnnTransformerModel()\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.090, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer=optimizer, \n",
    "                          loss='categorical_crossentropy'\n",
    "#                           loss_weights=[1., 1.]\n",
    "#                           loss_weights=[1.]\n",
    "#                             , metrics=['accuracy']\n",
    "                           , metrics=['accuracy' \n",
    "#                                       , tfa.metrics.MultiLabelConfusionMatrix(num_classes=3)\n",
    "#                                       , Recall(class_id=0)\n",
    "#                                 , Recall(class_id=2)\n",
    "#                                   , Precision(class_id=0)\n",
    "#                                  , Precision(class_id=2)\n",
    "                                 ]\n",
    "             )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizing The Model Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"6160pt\" viewBox=\"0.00 0.00 1850.00 4620.00\" width=\"2467pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1.33333 1.33333) rotate(0) translate(4 4616)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-4616 1846,-4616 1846,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 2537642080128 -->\n",
       "<g class=\"node\" id=\"node1\"><title>2537642080128</title>\n",
       "<polygon fill=\"none\" points=\"752,-4565.5 752,-4611.5 1024,-4611.5 1024,-4565.5 752,-4565.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"818.5\" y=\"-4584.8\">input_21: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"885,-4565.5 885,-4611.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"913\" y=\"-4596.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"885,-4588.5 941,-4588.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"913\" y=\"-4573.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"941,-4565.5 941,-4611.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"982.5\" y=\"-4596.3\">[(?, 360, 3)]</text>\n",
       "<polyline fill=\"none\" points=\"941,-4588.5 1024,-4588.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"982.5\" y=\"-4573.3\">[(?, 360, 3)]</text>\n",
       "</g>\n",
       "<!-- 2537642080352 -->\n",
       "<g class=\"node\" id=\"node2\"><title>2537642080352</title>\n",
       "<polygon fill=\"none\" points=\"595.5,-4482.5 595.5,-4528.5 872.5,-4528.5 872.5,-4482.5 595.5,-4482.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"662.5\" y=\"-4501.8\">conv1d_80: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"729.5,-4482.5 729.5,-4528.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"757.5\" y=\"-4513.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"729.5,-4505.5 785.5,-4505.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"757.5\" y=\"-4490.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"785.5,-4482.5 785.5,-4528.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"829\" y=\"-4513.3\">(?, 360, 3)</text>\n",
       "<polyline fill=\"none\" points=\"785.5,-4505.5 872.5,-4505.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"829\" y=\"-4490.3\">(?, 356, 128)</text>\n",
       "</g>\n",
       "<!-- 2537642080128&#45;&gt;2537642080352 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>2537642080128-&gt;2537642080352</title>\n",
       "<path d=\"M845.919,-4565.37C827.075,-4555.46 804.692,-4543.68 784.913,-4533.28\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"786.51,-4530.16 776.03,-4528.61 783.251,-4536.36 786.51,-4530.16\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537698338240 -->\n",
       "<g class=\"node\" id=\"node3\"><title>2537698338240</title>\n",
       "<polygon fill=\"none\" points=\"903.5,-4482.5 903.5,-4528.5 1180.5,-4528.5 1180.5,-4482.5 903.5,-4482.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"970.5\" y=\"-4501.8\">conv1d_84: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"1037.5,-4482.5 1037.5,-4528.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1065.5\" y=\"-4513.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1037.5,-4505.5 1093.5,-4505.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1065.5\" y=\"-4490.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1093.5,-4482.5 1093.5,-4528.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1137\" y=\"-4513.3\">(?, 360, 3)</text>\n",
       "<polyline fill=\"none\" points=\"1093.5,-4505.5 1180.5,-4505.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1137\" y=\"-4490.3\">(?, 179, 128)</text>\n",
       "</g>\n",
       "<!-- 2537642080128&#45;&gt;2537698338240 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>2537642080128-&gt;2537698338240</title>\n",
       "<path d=\"M930.081,-4565.37C948.925,-4555.46 971.308,-4543.68 991.087,-4533.28\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"992.749,-4536.36 999.97,-4528.61 989.49,-4530.16 992.749,-4536.36\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537816808584 -->\n",
       "<g class=\"node\" id=\"node4\"><title>2537816808584</title>\n",
       "<polygon fill=\"none\" points=\"575,-4399.5 575,-4445.5 879,-4445.5 879,-4399.5 575,-4399.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"655.5\" y=\"-4418.8\">activation_180: Activation</text>\n",
       "<polyline fill=\"none\" points=\"736,-4399.5 736,-4445.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"764\" y=\"-4430.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"736,-4422.5 792,-4422.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"764\" y=\"-4407.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"792,-4399.5 792,-4445.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"835.5\" y=\"-4430.3\">(?, 356, 128)</text>\n",
       "<polyline fill=\"none\" points=\"792,-4422.5 879,-4422.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"835.5\" y=\"-4407.3\">(?, 356, 128)</text>\n",
       "</g>\n",
       "<!-- 2537642080352&#45;&gt;2537816808584 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>2537642080352-&gt;2537816808584</title>\n",
       "<path d=\"M732.087,-4482.37C731.377,-4474.15 730.557,-4464.66 729.785,-4455.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"733.259,-4455.27 728.91,-4445.61 726.285,-4455.87 733.259,-4455.27\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537698445352 -->\n",
       "<g class=\"node\" id=\"node5\"><title>2537698445352</title>\n",
       "<polygon fill=\"none\" points=\"948,-4399.5 948,-4445.5 1252,-4445.5 1252,-4399.5 948,-4399.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1028.5\" y=\"-4418.8\">activation_184: Activation</text>\n",
       "<polyline fill=\"none\" points=\"1109,-4399.5 1109,-4445.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1137\" y=\"-4430.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1109,-4422.5 1165,-4422.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1137\" y=\"-4407.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1165,-4399.5 1165,-4445.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1208.5\" y=\"-4430.3\">(?, 179, 128)</text>\n",
       "<polyline fill=\"none\" points=\"1165,-4422.5 1252,-4422.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1208.5\" y=\"-4407.3\">(?, 179, 128)</text>\n",
       "</g>\n",
       "<!-- 2537698338240&#45;&gt;2537698445352 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>2537698338240-&gt;2537698445352</title>\n",
       "<path d=\"M1057.85,-4482.37C1064.11,-4473.62 1071.42,-4463.41 1078.17,-4453.99\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1081.19,-4455.78 1084.17,-4445.61 1075.5,-4451.7 1081.19,-4455.78\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537654150256 -->\n",
       "<g class=\"node\" id=\"node6\"><title>2537654150256</title>\n",
       "<polygon fill=\"none\" points=\"559,-4316.5 559,-4362.5 845,-4362.5 845,-4316.5 559,-4316.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"630.5\" y=\"-4335.8\">dropout_164: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"702,-4316.5 702,-4362.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"730\" y=\"-4347.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"702,-4339.5 758,-4339.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"730\" y=\"-4324.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"758,-4316.5 758,-4362.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"801.5\" y=\"-4347.3\">(?, 356, 128)</text>\n",
       "<polyline fill=\"none\" points=\"758,-4339.5 845,-4339.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"801.5\" y=\"-4324.3\">(?, 356, 128)</text>\n",
       "</g>\n",
       "<!-- 2537816808584&#45;&gt;2537654150256 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>2537816808584-&gt;2537654150256</title>\n",
       "<path d=\"M720.169,-4399.37C717.606,-4391.06 714.639,-4381.45 711.856,-4372.43\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"715.117,-4371.13 708.823,-4362.61 708.428,-4373.19 715.117,-4371.13\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537698446136 -->\n",
       "<g class=\"node\" id=\"node7\"><title>2537698446136</title>\n",
       "<polygon fill=\"none\" points=\"970,-4316.5 970,-4362.5 1256,-4362.5 1256,-4316.5 970,-4316.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1041.5\" y=\"-4335.8\">dropout_168: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"1113,-4316.5 1113,-4362.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1141\" y=\"-4347.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1113,-4339.5 1169,-4339.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1141\" y=\"-4324.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1169,-4316.5 1169,-4362.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1212.5\" y=\"-4347.3\">(?, 179, 128)</text>\n",
       "<polyline fill=\"none\" points=\"1169,-4339.5 1256,-4339.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1212.5\" y=\"-4324.3\">(?, 179, 128)</text>\n",
       "</g>\n",
       "<!-- 2537698445352&#45;&gt;2537698446136 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>2537698445352-&gt;2537698446136</title>\n",
       "<path d=\"M1103.55,-4399.37C1104.87,-4391.15 1106.39,-4381.66 1107.83,-4372.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1111.32,-4373.04 1109.45,-4362.61 1104.41,-4371.93 1111.32,-4373.04\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537642079904 -->\n",
       "<g class=\"node\" id=\"node8\"><title>2537642079904</title>\n",
       "<polygon fill=\"none\" points=\"557.5,-4233.5 557.5,-4279.5 834.5,-4279.5 834.5,-4233.5 557.5,-4233.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"624.5\" y=\"-4252.8\">conv1d_81: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"691.5,-4233.5 691.5,-4279.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"719.5\" y=\"-4264.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"691.5,-4256.5 747.5,-4256.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"719.5\" y=\"-4241.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"747.5,-4233.5 747.5,-4279.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"791\" y=\"-4264.3\">(?, 356, 128)</text>\n",
       "<polyline fill=\"none\" points=\"747.5,-4256.5 834.5,-4256.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"791\" y=\"-4241.3\">(?, 352, 64)</text>\n",
       "</g>\n",
       "<!-- 2537654150256&#45;&gt;2537642079904 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>2537654150256-&gt;2537642079904</title>\n",
       "<path d=\"M700.36,-4316.37C699.752,-4308.15 699.049,-4298.66 698.387,-4289.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"701.867,-4289.32 697.638,-4279.61 694.886,-4289.84 701.867,-4289.32\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537698446976 -->\n",
       "<g class=\"node\" id=\"node9\"><title>2537698446976</title>\n",
       "<polygon fill=\"none\" points=\"977.5,-4233.5 977.5,-4279.5 1254.5,-4279.5 1254.5,-4233.5 977.5,-4233.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1044.5\" y=\"-4252.8\">conv1d_85: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"1111.5,-4233.5 1111.5,-4279.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1139.5\" y=\"-4264.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1111.5,-4256.5 1167.5,-4256.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1139.5\" y=\"-4241.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1167.5,-4233.5 1167.5,-4279.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1211\" y=\"-4264.3\">(?, 179, 128)</text>\n",
       "<polyline fill=\"none\" points=\"1167.5,-4256.5 1254.5,-4256.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1211\" y=\"-4241.3\">(?, 89, 64)</text>\n",
       "</g>\n",
       "<!-- 2537698446136&#45;&gt;2537698446976 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>2537698446136-&gt;2537698446976</title>\n",
       "<path d=\"M1113.82,-4316.37C1114.12,-4308.15 1114.48,-4298.66 1114.81,-4289.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1118.31,-4289.73 1115.18,-4279.61 1111.31,-4289.47 1118.31,-4289.73\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537642075864 -->\n",
       "<g class=\"node\" id=\"node10\"><title>2537642075864</title>\n",
       "<polygon fill=\"none\" points=\"489.5,-4150.5 489.5,-4196.5 898.5,-4196.5 898.5,-4150.5 489.5,-4150.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"626\" y=\"-4169.8\">batch_normalization_194: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"762.5,-4150.5 762.5,-4196.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"790.5\" y=\"-4181.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"762.5,-4173.5 818.5,-4173.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"790.5\" y=\"-4158.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"818.5,-4150.5 818.5,-4196.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"858.5\" y=\"-4181.3\">(?, 352, 64)</text>\n",
       "<polyline fill=\"none\" points=\"818.5,-4173.5 898.5,-4173.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"858.5\" y=\"-4158.3\">(?, 352, 64)</text>\n",
       "</g>\n",
       "<!-- 2537642079904&#45;&gt;2537642075864 -->\n",
       "<g class=\"edge\" id=\"edge9\"><title>2537642079904-&gt;2537642075864</title>\n",
       "<path d=\"M695.453,-4233.37C695.251,-4225.15 695.016,-4215.66 694.796,-4206.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"698.292,-4206.52 694.546,-4196.61 691.294,-4206.69 698.292,-4206.52\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537698627312 -->\n",
       "<g class=\"node\" id=\"node11\"><title>2537698627312</title>\n",
       "<polygon fill=\"none\" points=\"936.5,-4150.5 936.5,-4196.5 1339.5,-4196.5 1339.5,-4150.5 936.5,-4150.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1073\" y=\"-4169.8\">batch_normalization_196: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"1209.5,-4150.5 1209.5,-4196.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1237.5\" y=\"-4181.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1209.5,-4173.5 1265.5,-4173.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1237.5\" y=\"-4158.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1265.5,-4150.5 1265.5,-4196.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1302.5\" y=\"-4181.3\">(?, 89, 64)</text>\n",
       "<polyline fill=\"none\" points=\"1265.5,-4173.5 1339.5,-4173.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1302.5\" y=\"-4158.3\">(?, 89, 64)</text>\n",
       "</g>\n",
       "<!-- 2537698446976&#45;&gt;2537698627312 -->\n",
       "<g class=\"edge\" id=\"edge10\"><title>2537698446976-&gt;2537698627312</title>\n",
       "<path d=\"M1122.01,-4233.37C1124.27,-4225.06 1126.88,-4215.45 1129.33,-4206.43\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1132.75,-4207.17 1132,-4196.61 1126,-4205.34 1132.75,-4207.17\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537697245392 -->\n",
       "<g class=\"node\" id=\"node12\"><title>2537697245392</title>\n",
       "<polygon fill=\"none\" points=\"535.5,-4067.5 535.5,-4113.5 832.5,-4113.5 832.5,-4067.5 535.5,-4067.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"616\" y=\"-4086.8\">activation_181: Activation</text>\n",
       "<polyline fill=\"none\" points=\"696.5,-4067.5 696.5,-4113.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"724.5\" y=\"-4098.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"696.5,-4090.5 752.5,-4090.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"724.5\" y=\"-4075.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"752.5,-4067.5 752.5,-4113.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"792.5\" y=\"-4098.3\">(?, 352, 64)</text>\n",
       "<polyline fill=\"none\" points=\"752.5,-4090.5 832.5,-4090.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"792.5\" y=\"-4075.3\">(?, 352, 64)</text>\n",
       "</g>\n",
       "<!-- 2537642075864&#45;&gt;2537697245392 -->\n",
       "<g class=\"edge\" id=\"edge11\"><title>2537642075864-&gt;2537697245392</title>\n",
       "<path d=\"M691.267,-4150.37C690.253,-4142.15 689.081,-4132.66 687.978,-4123.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"691.428,-4123.1 686.729,-4113.61 684.481,-4123.96 691.428,-4123.1\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537698674784 -->\n",
       "<g class=\"node\" id=\"node13\"><title>2537698674784</title>\n",
       "<polygon fill=\"none\" points=\"995.5,-4067.5 995.5,-4113.5 1286.5,-4113.5 1286.5,-4067.5 995.5,-4067.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1076\" y=\"-4086.8\">activation_185: Activation</text>\n",
       "<polyline fill=\"none\" points=\"1156.5,-4067.5 1156.5,-4113.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1184.5\" y=\"-4098.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1156.5,-4090.5 1212.5,-4090.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1184.5\" y=\"-4075.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1212.5,-4067.5 1212.5,-4113.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1249.5\" y=\"-4098.3\">(?, 89, 64)</text>\n",
       "<polyline fill=\"none\" points=\"1212.5,-4090.5 1286.5,-4090.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1249.5\" y=\"-4075.3\">(?, 89, 64)</text>\n",
       "</g>\n",
       "<!-- 2537698627312&#45;&gt;2537698674784 -->\n",
       "<g class=\"edge\" id=\"edge12\"><title>2537698627312-&gt;2537698674784</title>\n",
       "<path d=\"M1138.82,-4150.37C1139.12,-4142.15 1139.48,-4132.66 1139.81,-4123.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1143.31,-4123.73 1140.18,-4113.61 1136.31,-4123.47 1143.31,-4123.73\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537697246512 -->\n",
       "<g class=\"node\" id=\"node14\"><title>2537697246512</title>\n",
       "<polygon fill=\"none\" points=\"543.5,-3984.5 543.5,-4030.5 822.5,-4030.5 822.5,-3984.5 543.5,-3984.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"615\" y=\"-4003.8\">dropout_165: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"686.5,-3984.5 686.5,-4030.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"714.5\" y=\"-4015.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"686.5,-4007.5 742.5,-4007.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"714.5\" y=\"-3992.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"742.5,-3984.5 742.5,-4030.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"782.5\" y=\"-4015.3\">(?, 352, 64)</text>\n",
       "<polyline fill=\"none\" points=\"742.5,-4007.5 822.5,-4007.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"782.5\" y=\"-3992.3\">(?, 352, 64)</text>\n",
       "</g>\n",
       "<!-- 2537697245392&#45;&gt;2537697246512 -->\n",
       "<g class=\"edge\" id=\"edge13\"><title>2537697245392-&gt;2537697246512</title>\n",
       "<path d=\"M683.727,-4067.37C683.625,-4059.15 683.508,-4049.66 683.398,-4040.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"686.896,-4040.56 683.273,-4030.61 679.897,-4040.65 686.896,-4040.56\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537698675176 -->\n",
       "<g class=\"node\" id=\"node15\"><title>2537698675176</title>\n",
       "<polygon fill=\"none\" points=\"1005.5,-3984.5 1005.5,-4030.5 1278.5,-4030.5 1278.5,-3984.5 1005.5,-3984.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1077\" y=\"-4003.8\">dropout_169: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"1148.5,-3984.5 1148.5,-4030.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1176.5\" y=\"-4015.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1148.5,-4007.5 1204.5,-4007.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1176.5\" y=\"-3992.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1204.5,-3984.5 1204.5,-4030.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1241.5\" y=\"-4015.3\">(?, 89, 64)</text>\n",
       "<polyline fill=\"none\" points=\"1204.5,-4007.5 1278.5,-4007.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1241.5\" y=\"-3992.3\">(?, 89, 64)</text>\n",
       "</g>\n",
       "<!-- 2537698674784&#45;&gt;2537698675176 -->\n",
       "<g class=\"edge\" id=\"edge14\"><title>2537698674784-&gt;2537698675176</title>\n",
       "<path d=\"M1141.27,-4067.37C1141.37,-4059.15 1141.49,-4049.66 1141.6,-4040.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1145.1,-4040.65 1141.73,-4030.61 1138.1,-4040.56 1145.1,-4040.65\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537697680968 -->\n",
       "<g class=\"node\" id=\"node16\"><title>2537697680968</title>\n",
       "<polygon fill=\"none\" points=\"548,-3901.5 548,-3947.5 818,-3947.5 818,-3901.5 548,-3901.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"615\" y=\"-3920.8\">conv1d_82: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"682,-3901.5 682,-3947.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"710\" y=\"-3932.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"682,-3924.5 738,-3924.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"710\" y=\"-3909.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"738,-3901.5 738,-3947.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"778\" y=\"-3932.3\">(?, 352, 64)</text>\n",
       "<polyline fill=\"none\" points=\"738,-3924.5 818,-3924.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"778\" y=\"-3909.3\">(?, 348, 64)</text>\n",
       "</g>\n",
       "<!-- 2537697246512&#45;&gt;2537697680968 -->\n",
       "<g class=\"edge\" id=\"edge15\"><title>2537697246512-&gt;2537697680968</title>\n",
       "<path d=\"M683,-3984.37C683,-3976.15 683,-3966.66 683,-3957.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"686.5,-3957.61 683,-3947.61 679.5,-3957.61 686.5,-3957.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537699033216 -->\n",
       "<g class=\"node\" id=\"node17\"><title>2537699033216</title>\n",
       "<polygon fill=\"none\" points=\"1010,-3901.5 1010,-3947.5 1274,-3947.5 1274,-3901.5 1010,-3901.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1077\" y=\"-3920.8\">conv1d_86: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"1144,-3901.5 1144,-3947.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1172\" y=\"-3932.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1144,-3924.5 1200,-3924.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1172\" y=\"-3909.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1200,-3901.5 1200,-3947.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1237\" y=\"-3932.3\">(?, 89, 64)</text>\n",
       "<polyline fill=\"none\" points=\"1200,-3924.5 1274,-3924.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1237\" y=\"-3909.3\">(?, 44, 64)</text>\n",
       "</g>\n",
       "<!-- 2537698675176&#45;&gt;2537699033216 -->\n",
       "<g class=\"edge\" id=\"edge16\"><title>2537698675176-&gt;2537699033216</title>\n",
       "<path d=\"M1142,-3984.37C1142,-3976.15 1142,-3966.66 1142,-3957.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1145.5,-3957.61 1142,-3947.61 1138.5,-3957.61 1145.5,-3957.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537697775176 -->\n",
       "<g class=\"node\" id=\"node18\"><title>2537697775176</title>\n",
       "<polygon fill=\"none\" points=\"534.5,-3818.5 534.5,-3864.5 831.5,-3864.5 831.5,-3818.5 534.5,-3818.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"615\" y=\"-3837.8\">activation_182: Activation</text>\n",
       "<polyline fill=\"none\" points=\"695.5,-3818.5 695.5,-3864.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"723.5\" y=\"-3849.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"695.5,-3841.5 751.5,-3841.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"723.5\" y=\"-3826.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"751.5,-3818.5 751.5,-3864.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"791.5\" y=\"-3849.3\">(?, 348, 64)</text>\n",
       "<polyline fill=\"none\" points=\"751.5,-3841.5 831.5,-3841.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"791.5\" y=\"-3826.3\">(?, 348, 64)</text>\n",
       "</g>\n",
       "<!-- 2537697680968&#45;&gt;2537697775176 -->\n",
       "<g class=\"edge\" id=\"edge17\"><title>2537697680968-&gt;2537697775176</title>\n",
       "<path d=\"M683,-3901.37C683,-3893.15 683,-3883.66 683,-3874.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"686.5,-3874.61 683,-3864.61 679.5,-3874.61 686.5,-3874.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537699090160 -->\n",
       "<g class=\"node\" id=\"node19\"><title>2537699090160</title>\n",
       "<polygon fill=\"none\" points=\"1001.5,-3818.5 1001.5,-3864.5 1292.5,-3864.5 1292.5,-3818.5 1001.5,-3818.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1082\" y=\"-3837.8\">activation_186: Activation</text>\n",
       "<polyline fill=\"none\" points=\"1162.5,-3818.5 1162.5,-3864.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1190.5\" y=\"-3849.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1162.5,-3841.5 1218.5,-3841.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1190.5\" y=\"-3826.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1218.5,-3818.5 1218.5,-3864.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1255.5\" y=\"-3849.3\">(?, 44, 64)</text>\n",
       "<polyline fill=\"none\" points=\"1218.5,-3841.5 1292.5,-3841.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1255.5\" y=\"-3826.3\">(?, 44, 64)</text>\n",
       "</g>\n",
       "<!-- 2537699033216&#45;&gt;2537699090160 -->\n",
       "<g class=\"edge\" id=\"edge18\"><title>2537699033216-&gt;2537699090160</title>\n",
       "<path d=\"M1143.37,-3901.37C1143.87,-3893.15 1144.46,-3883.66 1145.01,-3874.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1148.51,-3874.8 1145.64,-3864.61 1141.53,-3874.37 1148.51,-3874.8\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537697730800 -->\n",
       "<g class=\"node\" id=\"node20\"><title>2537697730800</title>\n",
       "<polygon fill=\"none\" points=\"543.5,-3735.5 543.5,-3781.5 822.5,-3781.5 822.5,-3735.5 543.5,-3735.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"615\" y=\"-3754.8\">dropout_166: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"686.5,-3735.5 686.5,-3781.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"714.5\" y=\"-3766.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"686.5,-3758.5 742.5,-3758.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"714.5\" y=\"-3743.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"742.5,-3735.5 742.5,-3781.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"782.5\" y=\"-3766.3\">(?, 348, 64)</text>\n",
       "<polyline fill=\"none\" points=\"742.5,-3758.5 822.5,-3758.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"782.5\" y=\"-3743.3\">(?, 348, 64)</text>\n",
       "</g>\n",
       "<!-- 2537697775176&#45;&gt;2537697730800 -->\n",
       "<g class=\"edge\" id=\"edge19\"><title>2537697775176-&gt;2537697730800</title>\n",
       "<path d=\"M683,-3818.37C683,-3810.15 683,-3800.66 683,-3791.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"686.5,-3791.61 683,-3781.61 679.5,-3791.61 686.5,-3791.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537699152728 -->\n",
       "<g class=\"node\" id=\"node21\"><title>2537699152728</title>\n",
       "<polygon fill=\"none\" points=\"1010.5,-3735.5 1010.5,-3781.5 1283.5,-3781.5 1283.5,-3735.5 1010.5,-3735.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1082\" y=\"-3754.8\">dropout_170: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"1153.5,-3735.5 1153.5,-3781.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1181.5\" y=\"-3766.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1153.5,-3758.5 1209.5,-3758.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1181.5\" y=\"-3743.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1209.5,-3735.5 1209.5,-3781.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1246.5\" y=\"-3766.3\">(?, 44, 64)</text>\n",
       "<polyline fill=\"none\" points=\"1209.5,-3758.5 1283.5,-3758.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1246.5\" y=\"-3743.3\">(?, 44, 64)</text>\n",
       "</g>\n",
       "<!-- 2537699090160&#45;&gt;2537699152728 -->\n",
       "<g class=\"edge\" id=\"edge20\"><title>2537699090160-&gt;2537699152728</title>\n",
       "<path d=\"M1147,-3818.37C1147,-3810.15 1147,-3800.66 1147,-3791.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1150.5,-3791.61 1147,-3781.61 1143.5,-3791.61 1150.5,-3791.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537697731976 -->\n",
       "<g class=\"node\" id=\"node22\"><title>2537697731976</title>\n",
       "<polygon fill=\"none\" points=\"548,-3652.5 548,-3698.5 818,-3698.5 818,-3652.5 548,-3652.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"615\" y=\"-3671.8\">conv1d_83: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"682,-3652.5 682,-3698.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"710\" y=\"-3683.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"682,-3675.5 738,-3675.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"710\" y=\"-3660.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"738,-3652.5 738,-3698.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"778\" y=\"-3683.3\">(?, 348, 64)</text>\n",
       "<polyline fill=\"none\" points=\"738,-3675.5 818,-3675.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"778\" y=\"-3660.3\">(?, 344, 64)</text>\n",
       "</g>\n",
       "<!-- 2537697730800&#45;&gt;2537697731976 -->\n",
       "<g class=\"edge\" id=\"edge21\"><title>2537697730800-&gt;2537697731976</title>\n",
       "<path d=\"M683,-3735.37C683,-3727.15 683,-3717.66 683,-3708.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"686.5,-3708.61 683,-3698.61 679.5,-3708.61 686.5,-3708.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537699153400 -->\n",
       "<g class=\"node\" id=\"node23\"><title>2537699153400</title>\n",
       "<polygon fill=\"none\" points=\"1015,-3652.5 1015,-3698.5 1279,-3698.5 1279,-3652.5 1015,-3652.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1082\" y=\"-3671.8\">conv1d_87: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"1149,-3652.5 1149,-3698.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1177\" y=\"-3683.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1149,-3675.5 1205,-3675.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1177\" y=\"-3660.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1205,-3652.5 1205,-3698.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1242\" y=\"-3683.3\">(?, 44, 64)</text>\n",
       "<polyline fill=\"none\" points=\"1205,-3675.5 1279,-3675.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1242\" y=\"-3660.3\">(?, 21, 64)</text>\n",
       "</g>\n",
       "<!-- 2537699152728&#45;&gt;2537699153400 -->\n",
       "<g class=\"edge\" id=\"edge22\"><title>2537699152728-&gt;2537699153400</title>\n",
       "<path d=\"M1147,-3735.37C1147,-3727.15 1147,-3717.66 1147,-3708.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1150.5,-3708.61 1147,-3698.61 1143.5,-3708.61 1150.5,-3708.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537697996752 -->\n",
       "<g class=\"node\" id=\"node24\"><title>2537697996752</title>\n",
       "<polygon fill=\"none\" points=\"478.5,-3569.5 478.5,-3615.5 887.5,-3615.5 887.5,-3569.5 478.5,-3569.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"615\" y=\"-3588.8\">batch_normalization_195: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"751.5,-3569.5 751.5,-3615.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"779.5\" y=\"-3600.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"751.5,-3592.5 807.5,-3592.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"779.5\" y=\"-3577.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"807.5,-3569.5 807.5,-3615.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"847.5\" y=\"-3600.3\">(?, 344, 64)</text>\n",
       "<polyline fill=\"none\" points=\"807.5,-3592.5 887.5,-3592.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"847.5\" y=\"-3577.3\">(?, 344, 64)</text>\n",
       "</g>\n",
       "<!-- 2537697731976&#45;&gt;2537697996752 -->\n",
       "<g class=\"edge\" id=\"edge23\"><title>2537697731976-&gt;2537697996752</title>\n",
       "<path d=\"M683,-3652.37C683,-3644.15 683,-3634.66 683,-3625.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"686.5,-3625.61 683,-3615.61 679.5,-3625.61 686.5,-3625.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537699334128 -->\n",
       "<g class=\"node\" id=\"node25\"><title>2537699334128</title>\n",
       "<polygon fill=\"none\" points=\"946.5,-3569.5 946.5,-3615.5 1349.5,-3615.5 1349.5,-3569.5 946.5,-3569.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1083\" y=\"-3588.8\">batch_normalization_197: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"1219.5,-3569.5 1219.5,-3615.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1247.5\" y=\"-3600.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1219.5,-3592.5 1275.5,-3592.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1247.5\" y=\"-3577.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1275.5,-3569.5 1275.5,-3615.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1312.5\" y=\"-3600.3\">(?, 21, 64)</text>\n",
       "<polyline fill=\"none\" points=\"1275.5,-3592.5 1349.5,-3592.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1312.5\" y=\"-3577.3\">(?, 21, 64)</text>\n",
       "</g>\n",
       "<!-- 2537699153400&#45;&gt;2537699334128 -->\n",
       "<g class=\"edge\" id=\"edge24\"><title>2537699153400-&gt;2537699334128</title>\n",
       "<path d=\"M1147.27,-3652.37C1147.37,-3644.15 1147.49,-3634.66 1147.6,-3625.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1151.1,-3625.65 1147.73,-3615.61 1144.1,-3625.56 1151.1,-3625.65\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537697942216 -->\n",
       "<g class=\"node\" id=\"node26\"><title>2537697942216</title>\n",
       "<polygon fill=\"none\" points=\"534.5,-3486.5 534.5,-3532.5 831.5,-3532.5 831.5,-3486.5 534.5,-3486.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"615\" y=\"-3505.8\">activation_183: Activation</text>\n",
       "<polyline fill=\"none\" points=\"695.5,-3486.5 695.5,-3532.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"723.5\" y=\"-3517.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"695.5,-3509.5 751.5,-3509.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"723.5\" y=\"-3494.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"751.5,-3486.5 751.5,-3532.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"791.5\" y=\"-3517.3\">(?, 344, 64)</text>\n",
       "<polyline fill=\"none\" points=\"751.5,-3509.5 831.5,-3509.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"791.5\" y=\"-3494.3\">(?, 344, 64)</text>\n",
       "</g>\n",
       "<!-- 2537697996752&#45;&gt;2537697942216 -->\n",
       "<g class=\"edge\" id=\"edge25\"><title>2537697996752-&gt;2537697942216</title>\n",
       "<path d=\"M683,-3569.37C683,-3561.15 683,-3551.66 683,-3542.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"686.5,-3542.61 683,-3532.61 679.5,-3542.61 686.5,-3542.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537699334240 -->\n",
       "<g class=\"node\" id=\"node27\"><title>2537699334240</title>\n",
       "<polygon fill=\"none\" points=\"1002.5,-3486.5 1002.5,-3532.5 1293.5,-3532.5 1293.5,-3486.5 1002.5,-3486.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1083\" y=\"-3505.8\">activation_187: Activation</text>\n",
       "<polyline fill=\"none\" points=\"1163.5,-3486.5 1163.5,-3532.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1191.5\" y=\"-3517.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1163.5,-3509.5 1219.5,-3509.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1191.5\" y=\"-3494.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1219.5,-3486.5 1219.5,-3532.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1256.5\" y=\"-3517.3\">(?, 21, 64)</text>\n",
       "<polyline fill=\"none\" points=\"1219.5,-3509.5 1293.5,-3509.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1256.5\" y=\"-3494.3\">(?, 21, 64)</text>\n",
       "</g>\n",
       "<!-- 2537699334128&#45;&gt;2537699334240 -->\n",
       "<g class=\"edge\" id=\"edge26\"><title>2537699334128-&gt;2537699334240</title>\n",
       "<path d=\"M1148,-3569.37C1148,-3561.15 1148,-3551.66 1148,-3542.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1151.5,-3542.61 1148,-3532.61 1144.5,-3542.61 1151.5,-3542.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537697940816 -->\n",
       "<g class=\"node\" id=\"node28\"><title>2537697940816</title>\n",
       "<polygon fill=\"none\" points=\"543.5,-3403.5 543.5,-3449.5 822.5,-3449.5 822.5,-3403.5 543.5,-3403.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"615\" y=\"-3422.8\">dropout_167: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"686.5,-3403.5 686.5,-3449.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"714.5\" y=\"-3434.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"686.5,-3426.5 742.5,-3426.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"714.5\" y=\"-3411.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"742.5,-3403.5 742.5,-3449.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"782.5\" y=\"-3434.3\">(?, 344, 64)</text>\n",
       "<polyline fill=\"none\" points=\"742.5,-3426.5 822.5,-3426.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"782.5\" y=\"-3411.3\">(?, 344, 64)</text>\n",
       "</g>\n",
       "<!-- 2537697942216&#45;&gt;2537697940816 -->\n",
       "<g class=\"edge\" id=\"edge27\"><title>2537697942216-&gt;2537697940816</title>\n",
       "<path d=\"M683,-3486.37C683,-3478.15 683,-3468.66 683,-3459.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"686.5,-3459.61 683,-3449.61 679.5,-3459.61 686.5,-3459.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537699389000 -->\n",
       "<g class=\"node\" id=\"node29\"><title>2537699389000</title>\n",
       "<polygon fill=\"none\" points=\"1011.5,-3403.5 1011.5,-3449.5 1284.5,-3449.5 1284.5,-3403.5 1011.5,-3403.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1083\" y=\"-3422.8\">dropout_171: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"1154.5,-3403.5 1154.5,-3449.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1182.5\" y=\"-3434.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1154.5,-3426.5 1210.5,-3426.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1182.5\" y=\"-3411.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1210.5,-3403.5 1210.5,-3449.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1247.5\" y=\"-3434.3\">(?, 21, 64)</text>\n",
       "<polyline fill=\"none\" points=\"1210.5,-3426.5 1284.5,-3426.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1247.5\" y=\"-3411.3\">(?, 21, 64)</text>\n",
       "</g>\n",
       "<!-- 2537699334240&#45;&gt;2537699389000 -->\n",
       "<g class=\"edge\" id=\"edge28\"><title>2537699334240-&gt;2537699389000</title>\n",
       "<path d=\"M1148,-3486.37C1148,-3478.15 1148,-3468.66 1148,-3459.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1151.5,-3459.61 1148,-3449.61 1144.5,-3459.61 1151.5,-3459.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537699688744 -->\n",
       "<g class=\"node\" id=\"node30\"><title>2537699688744</title>\n",
       "<polygon fill=\"none\" points=\"0,-3320.5 0,-3366.5 430,-3366.5 430,-3320.5 0,-3320.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"147\" y=\"-3339.8\">global_max_pooling1d_20: GlobalMaxPooling1D</text>\n",
       "<polyline fill=\"none\" points=\"294,-3320.5 294,-3366.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"322\" y=\"-3351.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"294,-3343.5 350,-3343.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"322\" y=\"-3328.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"350,-3320.5 350,-3366.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"390\" y=\"-3351.3\">(?, 344, 64)</text>\n",
       "<polyline fill=\"none\" points=\"350,-3343.5 430,-3343.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"390\" y=\"-3328.3\">(?, 64)</text>\n",
       "</g>\n",
       "<!-- 2537697940816&#45;&gt;2537699688744 -->\n",
       "<g class=\"edge\" id=\"edge29\"><title>2537697940816-&gt;2537699688744</title>\n",
       "<path d=\"M555.735,-3403.47C492.788,-3392.58 416.726,-3379.41 352.45,-3368.29\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"352.69,-3364.78 342.24,-3366.52 351.496,-3371.68 352.69,-3364.78\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537699689192 -->\n",
       "<g class=\"node\" id=\"node31\"><title>2537699689192</title>\n",
       "<polygon fill=\"none\" points=\"448,-3320.5 448,-3366.5 918,-3366.5 918,-3320.5 448,-3320.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"615\" y=\"-3339.8\">global_average_pooling1d_20: GlobalAveragePooling1D</text>\n",
       "<polyline fill=\"none\" points=\"782,-3320.5 782,-3366.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"810\" y=\"-3351.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"782,-3343.5 838,-3343.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"810\" y=\"-3328.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"838,-3320.5 838,-3366.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"878\" y=\"-3351.3\">(?, 344, 64)</text>\n",
       "<polyline fill=\"none\" points=\"838,-3343.5 918,-3343.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"878\" y=\"-3328.3\">(?, 64)</text>\n",
       "</g>\n",
       "<!-- 2537697940816&#45;&gt;2537699689192 -->\n",
       "<g class=\"edge\" id=\"edge30\"><title>2537697940816-&gt;2537699689192</title>\n",
       "<path d=\"M683,-3403.37C683,-3395.15 683,-3385.66 683,-3376.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"686.5,-3376.61 683,-3366.61 679.5,-3376.61 686.5,-3376.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537699849104 -->\n",
       "<g class=\"node\" id=\"node32\"><title>2537699849104</title>\n",
       "<polygon fill=\"none\" points=\"936,-3320.5 936,-3366.5 1360,-3366.5 1360,-3320.5 936,-3320.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1083\" y=\"-3339.8\">global_max_pooling1d_21: GlobalMaxPooling1D</text>\n",
       "<polyline fill=\"none\" points=\"1230,-3320.5 1230,-3366.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1258\" y=\"-3351.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1230,-3343.5 1286,-3343.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1258\" y=\"-3328.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1286,-3320.5 1286,-3366.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1323\" y=\"-3351.3\">(?, 21, 64)</text>\n",
       "<polyline fill=\"none\" points=\"1286,-3343.5 1360,-3343.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1323\" y=\"-3328.3\">(?, 64)</text>\n",
       "</g>\n",
       "<!-- 2537699389000&#45;&gt;2537699849104 -->\n",
       "<g class=\"edge\" id=\"edge31\"><title>2537699389000-&gt;2537699849104</title>\n",
       "<path d=\"M1148,-3403.37C1148,-3395.15 1148,-3385.66 1148,-3376.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1151.5,-3376.61 1148,-3366.61 1144.5,-3376.61 1151.5,-3376.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537699801688 -->\n",
       "<g class=\"node\" id=\"node33\"><title>2537699801688</title>\n",
       "<polygon fill=\"none\" points=\"1378,-3320.5 1378,-3366.5 1842,-3366.5 1842,-3320.5 1378,-3320.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1545\" y=\"-3339.8\">global_average_pooling1d_21: GlobalAveragePooling1D</text>\n",
       "<polyline fill=\"none\" points=\"1712,-3320.5 1712,-3366.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1740\" y=\"-3351.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1712,-3343.5 1768,-3343.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1740\" y=\"-3328.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1768,-3320.5 1768,-3366.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1805\" y=\"-3351.3\">(?, 21, 64)</text>\n",
       "<polyline fill=\"none\" points=\"1768,-3343.5 1842,-3343.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1805\" y=\"-3328.3\">(?, 64)</text>\n",
       "</g>\n",
       "<!-- 2537699389000&#45;&gt;2537699801688 -->\n",
       "<g class=\"edge\" id=\"edge32\"><title>2537699389000-&gt;2537699801688</title>\n",
       "<path d=\"M1273.63,-3403.47C1335.77,-3392.58 1410.86,-3379.41 1474.31,-3368.29\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1475.15,-3371.7 1484.39,-3366.52 1473.94,-3364.8 1475.15,-3371.7\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537699882264 -->\n",
       "<g class=\"node\" id=\"node34\"><title>2537699882264</title>\n",
       "<polygon fill=\"none\" points=\"701.5,-3237.5 701.5,-3283.5 1128.5,-3283.5 1128.5,-3237.5 701.5,-3237.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"791\" y=\"-3256.8\">concatenate_15: Concatenate</text>\n",
       "<polyline fill=\"none\" points=\"880.5,-3237.5 880.5,-3283.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"908.5\" y=\"-3268.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"880.5,-3260.5 936.5,-3260.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"908.5\" y=\"-3245.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"936.5,-3237.5 936.5,-3283.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1032.5\" y=\"-3268.3\">[(?, 64), (?, 64), (?, 64), (?, 64)]</text>\n",
       "<polyline fill=\"none\" points=\"936.5,-3260.5 1128.5,-3260.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1032.5\" y=\"-3245.3\">(?, 256)</text>\n",
       "</g>\n",
       "<!-- 2537699688744&#45;&gt;2537699882264 -->\n",
       "<g class=\"edge\" id=\"edge33\"><title>2537699688744-&gt;2537699882264</title>\n",
       "<path d=\"M405.353,-3320.47C501.249,-3309.38 617.493,-3295.93 714.734,-3284.67\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"715.153,-3288.15 724.684,-3283.52 714.348,-3281.19 715.153,-3288.15\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537699689192&#45;&gt;2537699882264 -->\n",
       "<g class=\"edge\" id=\"edge34\"><title>2537699689192-&gt;2537699882264</title>\n",
       "<path d=\"M746.089,-3320.47C775.752,-3310.12 811.291,-3297.71 842.1,-3286.95\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"843.637,-3290.12 851.924,-3283.52 841.329,-3283.51 843.637,-3290.12\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537699849104&#45;&gt;2537699882264 -->\n",
       "<g class=\"edge\" id=\"edge35\"><title>2537699849104-&gt;2537699882264</title>\n",
       "<path d=\"M1084.64,-3320.47C1054.72,-3310.07 1018.85,-3297.6 987.812,-3286.81\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"988.943,-3283.5 978.348,-3283.52 986.644,-3290.11 988.943,-3283.5\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537699801688&#45;&gt;2537699882264 -->\n",
       "<g class=\"edge\" id=\"edge36\"><title>2537699801688-&gt;2537699882264</title>\n",
       "<path d=\"M1421.01,-3320.47C1325.89,-3309.39 1210.62,-3295.95 1114.13,-3284.71\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1114.29,-3281.2 1103.96,-3283.52 1113.48,-3288.16 1114.29,-3281.2\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537699851568 -->\n",
       "<g class=\"node\" id=\"node35\"><title>2537699851568</title>\n",
       "<polygon fill=\"none\" points=\"798.5,-3154.5 798.5,-3200.5 1031.5,-3200.5 1031.5,-3154.5 798.5,-3154.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"857.5\" y=\"-3173.8\">dense_158: Dense</text>\n",
       "<polyline fill=\"none\" points=\"916.5,-3154.5 916.5,-3200.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"944.5\" y=\"-3185.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"916.5,-3177.5 972.5,-3177.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"944.5\" y=\"-3162.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"972.5,-3154.5 972.5,-3200.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1002\" y=\"-3185.3\">(?, 256)</text>\n",
       "<polyline fill=\"none\" points=\"972.5,-3177.5 1031.5,-3177.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1002\" y=\"-3162.3\">(?, 300)</text>\n",
       "</g>\n",
       "<!-- 2537699882264&#45;&gt;2537699851568 -->\n",
       "<g class=\"edge\" id=\"edge37\"><title>2537699882264-&gt;2537699851568</title>\n",
       "<path d=\"M915,-3237.37C915,-3229.15 915,-3219.66 915,-3210.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"918.5,-3210.61 915,-3200.61 911.5,-3210.61 918.5,-3210.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537699883496 -->\n",
       "<g class=\"node\" id=\"node36\"><title>2537699883496</title>\n",
       "<polygon fill=\"none\" points=\"721,-3071.5 721,-3117.5 1109,-3117.5 1109,-3071.5 721,-3071.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"857.5\" y=\"-3090.8\">batch_normalization_198: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"994,-3071.5 994,-3117.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1022\" y=\"-3102.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"994,-3094.5 1050,-3094.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1022\" y=\"-3079.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1050,-3071.5 1050,-3117.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1079.5\" y=\"-3102.3\">(?, 300)</text>\n",
       "<polyline fill=\"none\" points=\"1050,-3094.5 1109,-3094.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1079.5\" y=\"-3079.3\">(?, 300)</text>\n",
       "</g>\n",
       "<!-- 2537699851568&#45;&gt;2537699883496 -->\n",
       "<g class=\"edge\" id=\"edge38\"><title>2537699851568-&gt;2537699883496</title>\n",
       "<path d=\"M915,-3154.37C915,-3146.15 915,-3136.66 915,-3127.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"918.5,-3127.61 915,-3117.61 911.5,-3127.61 918.5,-3127.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537699884168 -->\n",
       "<g class=\"node\" id=\"node37\"><title>2537699884168</title>\n",
       "<polygon fill=\"none\" points=\"777,-2988.5 777,-3034.5 1053,-3034.5 1053,-2988.5 777,-2988.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"857.5\" y=\"-3007.8\">activation_188: Activation</text>\n",
       "<polyline fill=\"none\" points=\"938,-2988.5 938,-3034.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"966\" y=\"-3019.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"938,-3011.5 994,-3011.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"966\" y=\"-2996.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"994,-2988.5 994,-3034.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1023.5\" y=\"-3019.3\">(?, 300)</text>\n",
       "<polyline fill=\"none\" points=\"994,-3011.5 1053,-3011.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1023.5\" y=\"-2996.3\">(?, 300)</text>\n",
       "</g>\n",
       "<!-- 2537699883496&#45;&gt;2537699884168 -->\n",
       "<g class=\"edge\" id=\"edge39\"><title>2537699883496-&gt;2537699884168</title>\n",
       "<path d=\"M915,-3071.37C915,-3063.15 915,-3053.66 915,-3044.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"918.5,-3044.61 915,-3034.61 911.5,-3044.61 918.5,-3044.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537699910712 -->\n",
       "<g class=\"node\" id=\"node38\"><title>2537699910712</title>\n",
       "<polygon fill=\"none\" points=\"786,-2905.5 786,-2951.5 1044,-2951.5 1044,-2905.5 786,-2905.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"857.5\" y=\"-2924.8\">dropout_172: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"929,-2905.5 929,-2951.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"957\" y=\"-2936.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"929,-2928.5 985,-2928.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"957\" y=\"-2913.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"985,-2905.5 985,-2951.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1014.5\" y=\"-2936.3\">(?, 300)</text>\n",
       "<polyline fill=\"none\" points=\"985,-2928.5 1044,-2928.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1014.5\" y=\"-2913.3\">(?, 300)</text>\n",
       "</g>\n",
       "<!-- 2537699884168&#45;&gt;2537699910712 -->\n",
       "<g class=\"edge\" id=\"edge40\"><title>2537699884168-&gt;2537699910712</title>\n",
       "<path d=\"M915,-2988.37C915,-2980.15 915,-2970.66 915,-2961.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"918.5,-2961.61 915,-2951.61 911.5,-2961.61 918.5,-2961.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537699913680 -->\n",
       "<g class=\"node\" id=\"node39\"><title>2537699913680</title>\n",
       "<polygon fill=\"none\" points=\"798.5,-2822.5 798.5,-2868.5 1031.5,-2868.5 1031.5,-2822.5 798.5,-2822.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"857.5\" y=\"-2841.8\">dense_159: Dense</text>\n",
       "<polyline fill=\"none\" points=\"916.5,-2822.5 916.5,-2868.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"944.5\" y=\"-2853.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"916.5,-2845.5 972.5,-2845.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"944.5\" y=\"-2830.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"972.5,-2822.5 972.5,-2868.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1002\" y=\"-2853.3\">(?, 300)</text>\n",
       "<polyline fill=\"none\" points=\"972.5,-2845.5 1031.5,-2845.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1002\" y=\"-2830.3\">(?, 600)</text>\n",
       "</g>\n",
       "<!-- 2537699910712&#45;&gt;2537699913680 -->\n",
       "<g class=\"edge\" id=\"edge41\"><title>2537699910712-&gt;2537699913680</title>\n",
       "<path d=\"M915,-2905.37C915,-2897.15 915,-2887.66 915,-2878.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"918.5,-2878.61 915,-2868.61 911.5,-2878.61 918.5,-2878.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537700335288 -->\n",
       "<g class=\"node\" id=\"node40\"><title>2537700335288</title>\n",
       "<polygon fill=\"none\" points=\"721,-2739.5 721,-2785.5 1109,-2785.5 1109,-2739.5 721,-2739.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"857.5\" y=\"-2758.8\">batch_normalization_199: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"994,-2739.5 994,-2785.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1022\" y=\"-2770.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"994,-2762.5 1050,-2762.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1022\" y=\"-2747.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1050,-2739.5 1050,-2785.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1079.5\" y=\"-2770.3\">(?, 600)</text>\n",
       "<polyline fill=\"none\" points=\"1050,-2762.5 1109,-2762.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1079.5\" y=\"-2747.3\">(?, 600)</text>\n",
       "</g>\n",
       "<!-- 2537699913680&#45;&gt;2537700335288 -->\n",
       "<g class=\"edge\" id=\"edge42\"><title>2537699913680-&gt;2537700335288</title>\n",
       "<path d=\"M915,-2822.37C915,-2814.15 915,-2804.66 915,-2795.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"918.5,-2795.61 915,-2785.61 911.5,-2795.61 918.5,-2795.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537700333440 -->\n",
       "<g class=\"node\" id=\"node41\"><title>2537700333440</title>\n",
       "<polygon fill=\"none\" points=\"777,-2656.5 777,-2702.5 1053,-2702.5 1053,-2656.5 777,-2656.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"857.5\" y=\"-2675.8\">activation_189: Activation</text>\n",
       "<polyline fill=\"none\" points=\"938,-2656.5 938,-2702.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"966\" y=\"-2687.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"938,-2679.5 994,-2679.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"966\" y=\"-2664.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"994,-2656.5 994,-2702.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1023.5\" y=\"-2687.3\">(?, 600)</text>\n",
       "<polyline fill=\"none\" points=\"994,-2679.5 1053,-2679.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1023.5\" y=\"-2664.3\">(?, 600)</text>\n",
       "</g>\n",
       "<!-- 2537700335288&#45;&gt;2537700333440 -->\n",
       "<g class=\"edge\" id=\"edge43\"><title>2537700335288-&gt;2537700333440</title>\n",
       "<path d=\"M915,-2739.37C915,-2731.15 915,-2721.66 915,-2712.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"918.5,-2712.61 915,-2702.61 911.5,-2712.61 918.5,-2712.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537700389496 -->\n",
       "<g class=\"node\" id=\"node42\"><title>2537700389496</title>\n",
       "<polygon fill=\"none\" points=\"786,-2573.5 786,-2619.5 1044,-2619.5 1044,-2573.5 786,-2573.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"857.5\" y=\"-2592.8\">dropout_173: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"929,-2573.5 929,-2619.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"957\" y=\"-2604.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"929,-2596.5 985,-2596.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"957\" y=\"-2581.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"985,-2573.5 985,-2619.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1014.5\" y=\"-2604.3\">(?, 600)</text>\n",
       "<polyline fill=\"none\" points=\"985,-2596.5 1044,-2596.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1014.5\" y=\"-2581.3\">(?, 600)</text>\n",
       "</g>\n",
       "<!-- 2537700333440&#45;&gt;2537700389496 -->\n",
       "<g class=\"edge\" id=\"edge44\"><title>2537700333440-&gt;2537700389496</title>\n",
       "<path d=\"M915,-2656.37C915,-2648.15 915,-2638.66 915,-2629.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"918.5,-2629.61 915,-2619.61 911.5,-2629.61 918.5,-2629.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537700389272 -->\n",
       "<g class=\"node\" id=\"node43\"><title>2537700389272</title>\n",
       "<polygon fill=\"none\" points=\"795,-2490.5 795,-2536.5 1035,-2536.5 1035,-2490.5 795,-2490.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"854\" y=\"-2509.8\">dense_160: Dense</text>\n",
       "<polyline fill=\"none\" points=\"913,-2490.5 913,-2536.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"941\" y=\"-2521.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"913,-2513.5 969,-2513.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"941\" y=\"-2498.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"969,-2490.5 969,-2536.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1002\" y=\"-2521.3\">(?, 600)</text>\n",
       "<polyline fill=\"none\" points=\"969,-2513.5 1035,-2513.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1002\" y=\"-2498.3\">(?, 1200)</text>\n",
       "</g>\n",
       "<!-- 2537700389496&#45;&gt;2537700389272 -->\n",
       "<g class=\"edge\" id=\"edge45\"><title>2537700389496-&gt;2537700389272</title>\n",
       "<path d=\"M915,-2573.37C915,-2565.15 915,-2555.66 915,-2546.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"918.5,-2546.61 915,-2536.61 911.5,-2546.61 918.5,-2546.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537700818056 -->\n",
       "<g class=\"node\" id=\"node44\"><title>2537700818056</title>\n",
       "<polygon fill=\"none\" points=\"717.5,-2407.5 717.5,-2453.5 1112.5,-2453.5 1112.5,-2407.5 717.5,-2407.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"854\" y=\"-2426.8\">batch_normalization_200: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"990.5,-2407.5 990.5,-2453.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1018.5\" y=\"-2438.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"990.5,-2430.5 1046.5,-2430.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1018.5\" y=\"-2415.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1046.5,-2407.5 1046.5,-2453.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1079.5\" y=\"-2438.3\">(?, 1200)</text>\n",
       "<polyline fill=\"none\" points=\"1046.5,-2430.5 1112.5,-2430.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1079.5\" y=\"-2415.3\">(?, 1200)</text>\n",
       "</g>\n",
       "<!-- 2537700389272&#45;&gt;2537700818056 -->\n",
       "<g class=\"edge\" id=\"edge46\"><title>2537700389272-&gt;2537700818056</title>\n",
       "<path d=\"M915,-2490.37C915,-2482.15 915,-2472.66 915,-2463.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"918.5,-2463.61 915,-2453.61 911.5,-2463.61 918.5,-2463.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537700817160 -->\n",
       "<g class=\"node\" id=\"node45\"><title>2537700817160</title>\n",
       "<polygon fill=\"none\" points=\"773.5,-2324.5 773.5,-2370.5 1056.5,-2370.5 1056.5,-2324.5 773.5,-2324.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"854\" y=\"-2343.8\">activation_190: Activation</text>\n",
       "<polyline fill=\"none\" points=\"934.5,-2324.5 934.5,-2370.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"962.5\" y=\"-2355.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"934.5,-2347.5 990.5,-2347.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"962.5\" y=\"-2332.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"990.5,-2324.5 990.5,-2370.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1023.5\" y=\"-2355.3\">(?, 1200)</text>\n",
       "<polyline fill=\"none\" points=\"990.5,-2347.5 1056.5,-2347.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1023.5\" y=\"-2332.3\">(?, 1200)</text>\n",
       "</g>\n",
       "<!-- 2537700818056&#45;&gt;2537700817160 -->\n",
       "<g class=\"edge\" id=\"edge47\"><title>2537700818056-&gt;2537700817160</title>\n",
       "<path d=\"M915,-2407.37C915,-2399.15 915,-2389.66 915,-2380.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"918.5,-2380.61 915,-2370.61 911.5,-2380.61 918.5,-2380.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537700816992 -->\n",
       "<g class=\"node\" id=\"node46\"><title>2537700816992</title>\n",
       "<polygon fill=\"none\" points=\"782.5,-2241.5 782.5,-2287.5 1047.5,-2287.5 1047.5,-2241.5 782.5,-2241.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"854\" y=\"-2260.8\">dropout_174: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"925.5,-2241.5 925.5,-2287.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"953.5\" y=\"-2272.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"925.5,-2264.5 981.5,-2264.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"953.5\" y=\"-2249.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"981.5,-2241.5 981.5,-2287.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1014.5\" y=\"-2272.3\">(?, 1200)</text>\n",
       "<polyline fill=\"none\" points=\"981.5,-2264.5 1047.5,-2264.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1014.5\" y=\"-2249.3\">(?, 1200)</text>\n",
       "</g>\n",
       "<!-- 2537700817160&#45;&gt;2537700816992 -->\n",
       "<g class=\"edge\" id=\"edge48\"><title>2537700817160-&gt;2537700816992</title>\n",
       "<path d=\"M915,-2324.37C915,-2316.15 915,-2306.66 915,-2297.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"918.5,-2297.61 915,-2287.61 911.5,-2297.61 918.5,-2297.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537700862608 -->\n",
       "<g class=\"node\" id=\"node47\"><title>2537700862608</title>\n",
       "<polygon fill=\"none\" points=\"795,-2158.5 795,-2204.5 1035,-2204.5 1035,-2158.5 795,-2158.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"854\" y=\"-2177.8\">dense_161: Dense</text>\n",
       "<polyline fill=\"none\" points=\"913,-2158.5 913,-2204.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"941\" y=\"-2189.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"913,-2181.5 969,-2181.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"941\" y=\"-2166.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"969,-2158.5 969,-2204.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1002\" y=\"-2189.3\">(?, 1200)</text>\n",
       "<polyline fill=\"none\" points=\"969,-2181.5 1035,-2181.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1002\" y=\"-2166.3\">(?, 600)</text>\n",
       "</g>\n",
       "<!-- 2537700816992&#45;&gt;2537700862608 -->\n",
       "<g class=\"edge\" id=\"edge49\"><title>2537700816992-&gt;2537700862608</title>\n",
       "<path d=\"M915,-2241.37C915,-2233.15 915,-2223.66 915,-2214.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"918.5,-2214.61 915,-2204.61 911.5,-2214.61 918.5,-2214.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537701292576 -->\n",
       "<g class=\"node\" id=\"node48\"><title>2537701292576</title>\n",
       "<polygon fill=\"none\" points=\"721,-2075.5 721,-2121.5 1109,-2121.5 1109,-2075.5 721,-2075.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"857.5\" y=\"-2094.8\">batch_normalization_201: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"994,-2075.5 994,-2121.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1022\" y=\"-2106.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"994,-2098.5 1050,-2098.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1022\" y=\"-2083.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1050,-2075.5 1050,-2121.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1079.5\" y=\"-2106.3\">(?, 600)</text>\n",
       "<polyline fill=\"none\" points=\"1050,-2098.5 1109,-2098.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1079.5\" y=\"-2083.3\">(?, 600)</text>\n",
       "</g>\n",
       "<!-- 2537700862608&#45;&gt;2537701292576 -->\n",
       "<g class=\"edge\" id=\"edge50\"><title>2537700862608-&gt;2537701292576</title>\n",
       "<path d=\"M915,-2158.37C915,-2150.15 915,-2140.66 915,-2131.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"918.5,-2131.61 915,-2121.61 911.5,-2131.61 918.5,-2131.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537701290616 -->\n",
       "<g class=\"node\" id=\"node49\"><title>2537701290616</title>\n",
       "<polygon fill=\"none\" points=\"777,-1992.5 777,-2038.5 1053,-2038.5 1053,-1992.5 777,-1992.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"857.5\" y=\"-2011.8\">activation_191: Activation</text>\n",
       "<polyline fill=\"none\" points=\"938,-1992.5 938,-2038.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"966\" y=\"-2023.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"938,-2015.5 994,-2015.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"966\" y=\"-2000.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"994,-1992.5 994,-2038.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1023.5\" y=\"-2023.3\">(?, 600)</text>\n",
       "<polyline fill=\"none\" points=\"994,-2015.5 1053,-2015.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1023.5\" y=\"-2000.3\">(?, 600)</text>\n",
       "</g>\n",
       "<!-- 2537701292576&#45;&gt;2537701290616 -->\n",
       "<g class=\"edge\" id=\"edge51\"><title>2537701292576-&gt;2537701290616</title>\n",
       "<path d=\"M915,-2075.37C915,-2067.15 915,-2057.66 915,-2048.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"918.5,-2048.61 915,-2038.61 911.5,-2048.61 918.5,-2048.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537701293080 -->\n",
       "<g class=\"node\" id=\"node50\"><title>2537701293080</title>\n",
       "<polygon fill=\"none\" points=\"786,-1909.5 786,-1955.5 1044,-1955.5 1044,-1909.5 786,-1909.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"857.5\" y=\"-1928.8\">dropout_175: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"929,-1909.5 929,-1955.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"957\" y=\"-1940.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"929,-1932.5 985,-1932.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"957\" y=\"-1917.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"985,-1909.5 985,-1955.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1014.5\" y=\"-1940.3\">(?, 600)</text>\n",
       "<polyline fill=\"none\" points=\"985,-1932.5 1044,-1932.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1014.5\" y=\"-1917.3\">(?, 600)</text>\n",
       "</g>\n",
       "<!-- 2537701290616&#45;&gt;2537701293080 -->\n",
       "<g class=\"edge\" id=\"edge52\"><title>2537701290616-&gt;2537701293080</title>\n",
       "<path d=\"M915,-1992.37C915,-1984.15 915,-1974.66 915,-1965.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"918.5,-1965.61 915,-1955.61 911.5,-1965.61 918.5,-1965.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537701337184 -->\n",
       "<g class=\"node\" id=\"node51\"><title>2537701337184</title>\n",
       "<polygon fill=\"none\" points=\"798.5,-1826.5 798.5,-1872.5 1031.5,-1872.5 1031.5,-1826.5 798.5,-1826.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"857.5\" y=\"-1845.8\">dense_162: Dense</text>\n",
       "<polyline fill=\"none\" points=\"916.5,-1826.5 916.5,-1872.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"944.5\" y=\"-1857.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"916.5,-1849.5 972.5,-1849.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"944.5\" y=\"-1834.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"972.5,-1826.5 972.5,-1872.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1002\" y=\"-1857.3\">(?, 600)</text>\n",
       "<polyline fill=\"none\" points=\"972.5,-1849.5 1031.5,-1849.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1002\" y=\"-1834.3\">(?, 300)</text>\n",
       "</g>\n",
       "<!-- 2537701293080&#45;&gt;2537701337184 -->\n",
       "<g class=\"edge\" id=\"edge53\"><title>2537701293080-&gt;2537701337184</title>\n",
       "<path d=\"M915,-1909.37C915,-1901.15 915,-1891.66 915,-1882.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"918.5,-1882.61 915,-1872.61 911.5,-1882.61 918.5,-1882.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537701763112 -->\n",
       "<g class=\"node\" id=\"node52\"><title>2537701763112</title>\n",
       "<polygon fill=\"none\" points=\"721,-1743.5 721,-1789.5 1109,-1789.5 1109,-1743.5 721,-1743.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"857.5\" y=\"-1762.8\">batch_normalization_202: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"994,-1743.5 994,-1789.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1022\" y=\"-1774.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"994,-1766.5 1050,-1766.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1022\" y=\"-1751.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1050,-1743.5 1050,-1789.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1079.5\" y=\"-1774.3\">(?, 300)</text>\n",
       "<polyline fill=\"none\" points=\"1050,-1766.5 1109,-1766.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1079.5\" y=\"-1751.3\">(?, 300)</text>\n",
       "</g>\n",
       "<!-- 2537701337184&#45;&gt;2537701763112 -->\n",
       "<g class=\"edge\" id=\"edge54\"><title>2537701337184-&gt;2537701763112</title>\n",
       "<path d=\"M915,-1826.37C915,-1818.15 915,-1808.66 915,-1799.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"918.5,-1799.61 915,-1789.61 911.5,-1799.61 918.5,-1799.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537701764064 -->\n",
       "<g class=\"node\" id=\"node53\"><title>2537701764064</title>\n",
       "<polygon fill=\"none\" points=\"777,-1660.5 777,-1706.5 1053,-1706.5 1053,-1660.5 777,-1660.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"857.5\" y=\"-1679.8\">activation_192: Activation</text>\n",
       "<polyline fill=\"none\" points=\"938,-1660.5 938,-1706.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"966\" y=\"-1691.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"938,-1683.5 994,-1683.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"966\" y=\"-1668.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"994,-1660.5 994,-1706.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1023.5\" y=\"-1691.3\">(?, 300)</text>\n",
       "<polyline fill=\"none\" points=\"994,-1683.5 1053,-1683.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1023.5\" y=\"-1668.3\">(?, 300)</text>\n",
       "</g>\n",
       "<!-- 2537701763112&#45;&gt;2537701764064 -->\n",
       "<g class=\"edge\" id=\"edge55\"><title>2537701763112-&gt;2537701764064</title>\n",
       "<path d=\"M915,-1743.37C915,-1735.15 915,-1725.66 915,-1716.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"918.5,-1716.61 915,-1706.61 911.5,-1716.61 918.5,-1716.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537701763952 -->\n",
       "<g class=\"node\" id=\"node54\"><title>2537701763952</title>\n",
       "<polygon fill=\"none\" points=\"786,-1577.5 786,-1623.5 1044,-1623.5 1044,-1577.5 786,-1577.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"857.5\" y=\"-1596.8\">dropout_176: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"929,-1577.5 929,-1623.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"957\" y=\"-1608.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"929,-1600.5 985,-1600.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"957\" y=\"-1585.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"985,-1577.5 985,-1623.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1014.5\" y=\"-1608.3\">(?, 300)</text>\n",
       "<polyline fill=\"none\" points=\"985,-1600.5 1044,-1600.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1014.5\" y=\"-1585.3\">(?, 300)</text>\n",
       "</g>\n",
       "<!-- 2537701764064&#45;&gt;2537701763952 -->\n",
       "<g class=\"edge\" id=\"edge56\"><title>2537701764064-&gt;2537701763952</title>\n",
       "<path d=\"M915,-1660.37C915,-1652.15 915,-1642.66 915,-1633.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"918.5,-1633.61 915,-1623.61 911.5,-1633.61 918.5,-1633.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537701807440 -->\n",
       "<g class=\"node\" id=\"node55\"><title>2537701807440</title>\n",
       "<polygon fill=\"none\" points=\"798.5,-1494.5 798.5,-1540.5 1031.5,-1540.5 1031.5,-1494.5 798.5,-1494.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"857.5\" y=\"-1513.8\">dense_163: Dense</text>\n",
       "<polyline fill=\"none\" points=\"916.5,-1494.5 916.5,-1540.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"944.5\" y=\"-1525.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"916.5,-1517.5 972.5,-1517.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"944.5\" y=\"-1502.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"972.5,-1494.5 972.5,-1540.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1002\" y=\"-1525.3\">(?, 300)</text>\n",
       "<polyline fill=\"none\" points=\"972.5,-1517.5 1031.5,-1517.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1002\" y=\"-1502.3\">(?, 130)</text>\n",
       "</g>\n",
       "<!-- 2537701763952&#45;&gt;2537701807440 -->\n",
       "<g class=\"edge\" id=\"edge57\"><title>2537701763952-&gt;2537701807440</title>\n",
       "<path d=\"M915,-1577.37C915,-1569.15 915,-1559.66 915,-1550.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"918.5,-1550.61 915,-1540.61 911.5,-1550.61 918.5,-1550.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537702186792 -->\n",
       "<g class=\"node\" id=\"node56\"><title>2537702186792</title>\n",
       "<polygon fill=\"none\" points=\"721,-1411.5 721,-1457.5 1109,-1457.5 1109,-1411.5 721,-1411.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"857.5\" y=\"-1430.8\">batch_normalization_203: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"994,-1411.5 994,-1457.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1022\" y=\"-1442.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"994,-1434.5 1050,-1434.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1022\" y=\"-1419.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1050,-1411.5 1050,-1457.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1079.5\" y=\"-1442.3\">(?, 130)</text>\n",
       "<polyline fill=\"none\" points=\"1050,-1434.5 1109,-1434.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1079.5\" y=\"-1419.3\">(?, 130)</text>\n",
       "</g>\n",
       "<!-- 2537701807440&#45;&gt;2537702186792 -->\n",
       "<g class=\"edge\" id=\"edge58\"><title>2537701807440-&gt;2537702186792</title>\n",
       "<path d=\"M915,-1494.37C915,-1486.15 915,-1476.66 915,-1467.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"918.5,-1467.61 915,-1457.61 911.5,-1467.61 918.5,-1467.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537702246888 -->\n",
       "<g class=\"node\" id=\"node57\"><title>2537702246888</title>\n",
       "<polygon fill=\"none\" points=\"777,-1328.5 777,-1374.5 1053,-1374.5 1053,-1328.5 777,-1328.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"857.5\" y=\"-1347.8\">activation_193: Activation</text>\n",
       "<polyline fill=\"none\" points=\"938,-1328.5 938,-1374.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"966\" y=\"-1359.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"938,-1351.5 994,-1351.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"966\" y=\"-1336.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"994,-1328.5 994,-1374.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1023.5\" y=\"-1359.3\">(?, 130)</text>\n",
       "<polyline fill=\"none\" points=\"994,-1351.5 1053,-1351.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1023.5\" y=\"-1336.3\">(?, 130)</text>\n",
       "</g>\n",
       "<!-- 2537702186792&#45;&gt;2537702246888 -->\n",
       "<g class=\"edge\" id=\"edge59\"><title>2537702186792-&gt;2537702246888</title>\n",
       "<path d=\"M915,-1411.37C915,-1403.15 915,-1393.66 915,-1384.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"918.5,-1384.61 915,-1374.61 911.5,-1384.61 918.5,-1384.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537702246776 -->\n",
       "<g class=\"node\" id=\"node58\"><title>2537702246776</title>\n",
       "<polygon fill=\"none\" points=\"786,-1245.5 786,-1291.5 1044,-1291.5 1044,-1245.5 786,-1245.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"857.5\" y=\"-1264.8\">dropout_177: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"929,-1245.5 929,-1291.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"957\" y=\"-1276.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"929,-1268.5 985,-1268.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"957\" y=\"-1253.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"985,-1245.5 985,-1291.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1014.5\" y=\"-1276.3\">(?, 130)</text>\n",
       "<polyline fill=\"none\" points=\"985,-1268.5 1044,-1268.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1014.5\" y=\"-1253.3\">(?, 130)</text>\n",
       "</g>\n",
       "<!-- 2537702246888&#45;&gt;2537702246776 -->\n",
       "<g class=\"edge\" id=\"edge60\"><title>2537702246888-&gt;2537702246776</title>\n",
       "<path d=\"M915,-1328.37C915,-1320.15 915,-1310.66 915,-1301.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"918.5,-1301.61 915,-1291.61 911.5,-1301.61 918.5,-1301.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537702286168 -->\n",
       "<g class=\"node\" id=\"node59\"><title>2537702286168</title>\n",
       "<polygon fill=\"none\" points=\"798.5,-1162.5 798.5,-1208.5 1031.5,-1208.5 1031.5,-1162.5 798.5,-1162.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"857.5\" y=\"-1181.8\">dense_164: Dense</text>\n",
       "<polyline fill=\"none\" points=\"916.5,-1162.5 916.5,-1208.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"944.5\" y=\"-1193.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"916.5,-1185.5 972.5,-1185.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"944.5\" y=\"-1170.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"972.5,-1162.5 972.5,-1208.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1002\" y=\"-1193.3\">(?, 130)</text>\n",
       "<polyline fill=\"none\" points=\"972.5,-1185.5 1031.5,-1185.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1002\" y=\"-1170.3\">(?, 70)</text>\n",
       "</g>\n",
       "<!-- 2537702246776&#45;&gt;2537702286168 -->\n",
       "<g class=\"edge\" id=\"edge61\"><title>2537702246776-&gt;2537702286168</title>\n",
       "<path d=\"M915,-1245.37C915,-1237.15 915,-1227.66 915,-1218.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"918.5,-1218.61 915,-1208.61 911.5,-1218.61 918.5,-1218.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537702670288 -->\n",
       "<g class=\"node\" id=\"node60\"><title>2537702670288</title>\n",
       "<polygon fill=\"none\" points=\"724,-1079.5 724,-1125.5 1106,-1125.5 1106,-1079.5 724,-1079.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"860.5\" y=\"-1098.8\">batch_normalization_204: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"997,-1079.5 997,-1125.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1025\" y=\"-1110.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"997,-1102.5 1053,-1102.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1025\" y=\"-1087.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1053,-1079.5 1053,-1125.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1079.5\" y=\"-1110.3\">(?, 70)</text>\n",
       "<polyline fill=\"none\" points=\"1053,-1102.5 1106,-1102.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1079.5\" y=\"-1087.3\">(?, 70)</text>\n",
       "</g>\n",
       "<!-- 2537702286168&#45;&gt;2537702670288 -->\n",
       "<g class=\"edge\" id=\"edge62\"><title>2537702286168-&gt;2537702670288</title>\n",
       "<path d=\"M915,-1162.37C915,-1154.15 915,-1144.66 915,-1135.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"918.5,-1135.61 915,-1125.61 911.5,-1135.61 918.5,-1135.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537702721520 -->\n",
       "<g class=\"node\" id=\"node61\"><title>2537702721520</title>\n",
       "<polygon fill=\"none\" points=\"780,-996.5 780,-1042.5 1050,-1042.5 1050,-996.5 780,-996.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"860.5\" y=\"-1015.8\">activation_194: Activation</text>\n",
       "<polyline fill=\"none\" points=\"941,-996.5 941,-1042.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"969\" y=\"-1027.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"941,-1019.5 997,-1019.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"969\" y=\"-1004.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"997,-996.5 997,-1042.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1023.5\" y=\"-1027.3\">(?, 70)</text>\n",
       "<polyline fill=\"none\" points=\"997,-1019.5 1050,-1019.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1023.5\" y=\"-1004.3\">(?, 70)</text>\n",
       "</g>\n",
       "<!-- 2537702670288&#45;&gt;2537702721520 -->\n",
       "<g class=\"edge\" id=\"edge63\"><title>2537702670288-&gt;2537702721520</title>\n",
       "<path d=\"M915,-1079.37C915,-1071.15 915,-1061.66 915,-1052.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"918.5,-1052.61 915,-1042.61 911.5,-1052.61 918.5,-1052.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537702721408 -->\n",
       "<g class=\"node\" id=\"node62\"><title>2537702721408</title>\n",
       "<polygon fill=\"none\" points=\"789,-913.5 789,-959.5 1041,-959.5 1041,-913.5 789,-913.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"860.5\" y=\"-932.8\">dropout_178: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"932,-913.5 932,-959.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"960\" y=\"-944.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"932,-936.5 988,-936.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"960\" y=\"-921.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"988,-913.5 988,-959.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1014.5\" y=\"-944.3\">(?, 70)</text>\n",
       "<polyline fill=\"none\" points=\"988,-936.5 1041,-936.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1014.5\" y=\"-921.3\">(?, 70)</text>\n",
       "</g>\n",
       "<!-- 2537702721520&#45;&gt;2537702721408 -->\n",
       "<g class=\"edge\" id=\"edge64\"><title>2537702721520-&gt;2537702721408</title>\n",
       "<path d=\"M915,-996.366C915,-988.152 915,-978.658 915,-969.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"918.5,-969.607 915,-959.607 911.5,-969.607 918.5,-969.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537702760520 -->\n",
       "<g class=\"node\" id=\"node63\"><title>2537702760520</title>\n",
       "<polygon fill=\"none\" points=\"801.5,-830.5 801.5,-876.5 1028.5,-876.5 1028.5,-830.5 801.5,-830.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"860.5\" y=\"-849.8\">dense_165: Dense</text>\n",
       "<polyline fill=\"none\" points=\"919.5,-830.5 919.5,-876.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"947.5\" y=\"-861.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"919.5,-853.5 975.5,-853.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"947.5\" y=\"-838.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"975.5,-830.5 975.5,-876.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1002\" y=\"-861.3\">(?, 70)</text>\n",
       "<polyline fill=\"none\" points=\"975.5,-853.5 1028.5,-853.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1002\" y=\"-838.3\">(?, 35)</text>\n",
       "</g>\n",
       "<!-- 2537702721408&#45;&gt;2537702760520 -->\n",
       "<g class=\"edge\" id=\"edge65\"><title>2537702721408-&gt;2537702760520</title>\n",
       "<path d=\"M915,-913.366C915,-905.152 915,-895.658 915,-886.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"918.5,-886.607 915,-876.607 911.5,-886.607 918.5,-886.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537703048080 -->\n",
       "<g class=\"node\" id=\"node64\"><title>2537703048080</title>\n",
       "<polygon fill=\"none\" points=\"724,-747.5 724,-793.5 1106,-793.5 1106,-747.5 724,-747.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"860.5\" y=\"-766.8\">batch_normalization_205: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"997,-747.5 997,-793.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1025\" y=\"-778.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"997,-770.5 1053,-770.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1025\" y=\"-755.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1053,-747.5 1053,-793.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1079.5\" y=\"-778.3\">(?, 35)</text>\n",
       "<polyline fill=\"none\" points=\"1053,-770.5 1106,-770.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1079.5\" y=\"-755.3\">(?, 35)</text>\n",
       "</g>\n",
       "<!-- 2537702760520&#45;&gt;2537703048080 -->\n",
       "<g class=\"edge\" id=\"edge66\"><title>2537702760520-&gt;2537703048080</title>\n",
       "<path d=\"M915,-830.366C915,-822.152 915,-812.658 915,-803.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"918.5,-803.607 915,-793.607 911.5,-803.607 918.5,-803.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537703186160 -->\n",
       "<g class=\"node\" id=\"node65\"><title>2537703186160</title>\n",
       "<polygon fill=\"none\" points=\"780,-664.5 780,-710.5 1050,-710.5 1050,-664.5 780,-664.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"860.5\" y=\"-683.8\">activation_195: Activation</text>\n",
       "<polyline fill=\"none\" points=\"941,-664.5 941,-710.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"969\" y=\"-695.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"941,-687.5 997,-687.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"969\" y=\"-672.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"997,-664.5 997,-710.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1023.5\" y=\"-695.3\">(?, 35)</text>\n",
       "<polyline fill=\"none\" points=\"997,-687.5 1050,-687.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1023.5\" y=\"-672.3\">(?, 35)</text>\n",
       "</g>\n",
       "<!-- 2537703048080&#45;&gt;2537703186160 -->\n",
       "<g class=\"edge\" id=\"edge67\"><title>2537703048080-&gt;2537703186160</title>\n",
       "<path d=\"M915,-747.366C915,-739.152 915,-729.658 915,-720.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"918.5,-720.607 915,-710.607 911.5,-720.607 918.5,-720.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537703182464 -->\n",
       "<g class=\"node\" id=\"node66\"><title>2537703182464</title>\n",
       "<polygon fill=\"none\" points=\"801.5,-581.5 801.5,-627.5 1028.5,-627.5 1028.5,-581.5 801.5,-581.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"860.5\" y=\"-600.8\">dense_166: Dense</text>\n",
       "<polyline fill=\"none\" points=\"919.5,-581.5 919.5,-627.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"947.5\" y=\"-612.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"919.5,-604.5 975.5,-604.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"947.5\" y=\"-589.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"975.5,-581.5 975.5,-627.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1002\" y=\"-612.3\">(?, 35)</text>\n",
       "<polyline fill=\"none\" points=\"975.5,-604.5 1028.5,-604.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1002\" y=\"-589.3\">(?, 15)</text>\n",
       "</g>\n",
       "<!-- 2537703186160&#45;&gt;2537703182464 -->\n",
       "<g class=\"edge\" id=\"edge68\"><title>2537703186160-&gt;2537703182464</title>\n",
       "<path d=\"M915,-664.366C915,-656.152 915,-646.658 915,-637.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"918.5,-637.607 915,-627.607 911.5,-637.607 918.5,-637.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537703518448 -->\n",
       "<g class=\"node\" id=\"node67\"><title>2537703518448</title>\n",
       "<polygon fill=\"none\" points=\"724,-498.5 724,-544.5 1106,-544.5 1106,-498.5 724,-498.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"860.5\" y=\"-517.8\">batch_normalization_206: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"997,-498.5 997,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1025\" y=\"-529.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"997,-521.5 1053,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1025\" y=\"-506.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1053,-498.5 1053,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1079.5\" y=\"-529.3\">(?, 15)</text>\n",
       "<polyline fill=\"none\" points=\"1053,-521.5 1106,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1079.5\" y=\"-506.3\">(?, 15)</text>\n",
       "</g>\n",
       "<!-- 2537703182464&#45;&gt;2537703518448 -->\n",
       "<g class=\"edge\" id=\"edge69\"><title>2537703182464-&gt;2537703518448</title>\n",
       "<path d=\"M915,-581.366C915,-573.152 915,-563.658 915,-554.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"918.5,-554.607 915,-544.607 911.5,-554.607 918.5,-554.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537703521080 -->\n",
       "<g class=\"node\" id=\"node68\"><title>2537703521080</title>\n",
       "<polygon fill=\"none\" points=\"780,-415.5 780,-461.5 1050,-461.5 1050,-415.5 780,-415.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"860.5\" y=\"-434.8\">activation_196: Activation</text>\n",
       "<polyline fill=\"none\" points=\"941,-415.5 941,-461.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"969\" y=\"-446.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"941,-438.5 997,-438.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"969\" y=\"-423.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"997,-415.5 997,-461.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1023.5\" y=\"-446.3\">(?, 15)</text>\n",
       "<polyline fill=\"none\" points=\"997,-438.5 1050,-438.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1023.5\" y=\"-423.3\">(?, 15)</text>\n",
       "</g>\n",
       "<!-- 2537703518448&#45;&gt;2537703521080 -->\n",
       "<g class=\"edge\" id=\"edge70\"><title>2537703518448-&gt;2537703521080</title>\n",
       "<path d=\"M915,-498.366C915,-490.152 915,-480.658 915,-471.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"918.5,-471.607 915,-461.607 911.5,-471.607 918.5,-471.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537703520968 -->\n",
       "<g class=\"node\" id=\"node69\"><title>2537703520968</title>\n",
       "<polygon fill=\"none\" points=\"801.5,-332.5 801.5,-378.5 1028.5,-378.5 1028.5,-332.5 801.5,-332.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"860.5\" y=\"-351.8\">dense_167: Dense</text>\n",
       "<polyline fill=\"none\" points=\"919.5,-332.5 919.5,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"947.5\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"919.5,-355.5 975.5,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"947.5\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"975.5,-332.5 975.5,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1002\" y=\"-363.3\">(?, 15)</text>\n",
       "<polyline fill=\"none\" points=\"975.5,-355.5 1028.5,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1002\" y=\"-340.3\">(?, 7)</text>\n",
       "</g>\n",
       "<!-- 2537703521080&#45;&gt;2537703520968 -->\n",
       "<g class=\"edge\" id=\"edge71\"><title>2537703521080-&gt;2537703520968</title>\n",
       "<path d=\"M915,-415.366C915,-407.152 915,-397.658 915,-388.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"918.5,-388.607 915,-378.607 911.5,-388.607 918.5,-388.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537703830752 -->\n",
       "<g class=\"node\" id=\"node70\"><title>2537703830752</title>\n",
       "<polygon fill=\"none\" points=\"727.5,-249.5 727.5,-295.5 1102.5,-295.5 1102.5,-249.5 727.5,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"864\" y=\"-268.8\">batch_normalization_207: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"1000.5,-249.5 1000.5,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1028.5\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1000.5,-272.5 1056.5,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1028.5\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1056.5,-249.5 1056.5,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1079.5\" y=\"-280.3\">(?, 7)</text>\n",
       "<polyline fill=\"none\" points=\"1056.5,-272.5 1102.5,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1079.5\" y=\"-257.3\">(?, 7)</text>\n",
       "</g>\n",
       "<!-- 2537703520968&#45;&gt;2537703830752 -->\n",
       "<g class=\"edge\" id=\"edge72\"><title>2537703520968-&gt;2537703830752</title>\n",
       "<path d=\"M915,-332.366C915,-324.152 915,-314.658 915,-305.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"918.5,-305.607 915,-295.607 911.5,-305.607 918.5,-305.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537703832152 -->\n",
       "<g class=\"node\" id=\"node72\"><title>2537703832152</title>\n",
       "<polygon fill=\"none\" points=\"817.5,-166.5 817.5,-212.5 1080.5,-212.5 1080.5,-166.5 817.5,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"898\" y=\"-185.8\">activation_197: Activation</text>\n",
       "<polyline fill=\"none\" points=\"978.5,-166.5 978.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1006.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"978.5,-189.5 1034.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1006.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1034.5,-166.5 1034.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1057.5\" y=\"-197.3\">(?, 7)</text>\n",
       "<polyline fill=\"none\" points=\"1034.5,-189.5 1080.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1057.5\" y=\"-174.3\">(?, 7)</text>\n",
       "</g>\n",
       "<!-- 2537703830752&#45;&gt;2537703832152 -->\n",
       "<g class=\"edge\" id=\"edge73\"><title>2537703830752-&gt;2537703832152</title>\n",
       "<path d=\"M924.291,-249.366C927.851,-240.884 931.984,-231.037 935.839,-221.853\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"939.077,-223.182 939.721,-212.607 932.623,-220.473 939.077,-223.182\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537703833160 -->\n",
       "<g class=\"node\" id=\"node71\"><title>2537703833160</title>\n",
       "<polygon fill=\"none\" points=\"1121,-249.5 1121,-295.5 1365,-295.5 1365,-249.5 1121,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1187.5\" y=\"-268.8\">input_22: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"1254,-249.5 1254,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1282\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1254,-272.5 1310,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1282\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1310,-249.5 1310,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1337.5\" y=\"-280.3\">[(?, 5)]</text>\n",
       "<polyline fill=\"none\" points=\"1310,-272.5 1365,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1337.5\" y=\"-257.3\">[(?, 5)]</text>\n",
       "</g>\n",
       "<!-- 2537705127888 -->\n",
       "<g class=\"node\" id=\"node73\"><title>2537705127888</title>\n",
       "<polygon fill=\"none\" points=\"1116,-166.5 1116,-212.5 1336,-212.5 1336,-166.5 1116,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1175\" y=\"-185.8\">dense_174: Dense</text>\n",
       "<polyline fill=\"none\" points=\"1234,-166.5 1234,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1262\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1234,-189.5 1290,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1262\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1290,-166.5 1290,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1313\" y=\"-197.3\">(?, 5)</text>\n",
       "<polyline fill=\"none\" points=\"1290,-189.5 1336,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1313\" y=\"-174.3\">(?, 3)</text>\n",
       "</g>\n",
       "<!-- 2537703833160&#45;&gt;2537705127888 -->\n",
       "<g class=\"edge\" id=\"edge74\"><title>2537703833160-&gt;2537705127888</title>\n",
       "<path d=\"M1238.35,-249.366C1236.61,-241.062 1234.59,-231.451 1232.7,-222.434\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1236.12,-221.675 1230.64,-212.607 1229.27,-223.113 1236.12,-221.675\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537705175472 -->\n",
       "<g class=\"node\" id=\"node74\"><title>2537705175472</title>\n",
       "<polygon fill=\"none\" points=\"923.5,-83.5 923.5,-129.5 1250.5,-129.5 1250.5,-83.5 923.5,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1013\" y=\"-102.8\">concatenate_16: Concatenate</text>\n",
       "<polyline fill=\"none\" points=\"1102.5,-83.5 1102.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1130.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1102.5,-106.5 1158.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1130.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1158.5,-83.5 1158.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1204.5\" y=\"-114.3\">[(?, 7), (?, 3)]</text>\n",
       "<polyline fill=\"none\" points=\"1158.5,-106.5 1250.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1204.5\" y=\"-91.3\">(?, 10)</text>\n",
       "</g>\n",
       "<!-- 2537703832152&#45;&gt;2537705175472 -->\n",
       "<g class=\"edge\" id=\"edge75\"><title>2537703832152-&gt;2537705175472</title>\n",
       "<path d=\"M986.709,-166.366C1003.29,-156.634 1022.93,-145.106 1040.42,-134.842\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1042.48,-137.687 1049.34,-129.607 1038.94,-131.65 1042.48,-137.687\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537705127888&#45;&gt;2537705175472 -->\n",
       "<g class=\"edge\" id=\"edge76\"><title>2537705127888-&gt;2537705175472</title>\n",
       "<path d=\"M1188.02,-166.366C1171.32,-156.634 1151.53,-145.106 1133.92,-134.842\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1135.34,-131.618 1124.94,-129.607 1131.81,-137.666 1135.34,-131.618\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2537705209192 -->\n",
       "<g class=\"node\" id=\"node75\"><title>2537705209192</title>\n",
       "<polygon fill=\"none\" points=\"973.5,-0.5 973.5,-46.5 1200.5,-46.5 1200.5,-0.5 973.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1032.5\" y=\"-19.8\">dense_175: Dense</text>\n",
       "<polyline fill=\"none\" points=\"1091.5,-0.5 1091.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1119.5\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1091.5,-23.5 1147.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1119.5\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1147.5,-0.5 1147.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1174\" y=\"-31.3\">(?, 10)</text>\n",
       "<polyline fill=\"none\" points=\"1147.5,-23.5 1200.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1174\" y=\"-8.3\">(?, 3)</text>\n",
       "</g>\n",
       "<!-- 2537705175472&#45;&gt;2537705209192 -->\n",
       "<g class=\"edge\" id=\"edge77\"><title>2537705175472-&gt;2537705209192</title>\n",
       "<path d=\"M1087,-83.3664C1087,-75.1516 1087,-65.6579 1087,-56.7252\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1090.5,-56.6068 1087,-46.6068 1083.5,-56.6069 1090.5,-56.6068\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from tensorflow.python.keras.utils.vis_utils import model_to_dot\n",
    "SVG(model_to_dot(model,show_shapes = True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5bed51171db8bf8c5e1731119fd31205bfd80a82"
   },
   "source": [
    "Train the model with early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": false,
    "_uuid": "e1061c7cde0687450300f516735aad0cc5dbf08f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0613 11:29:24.824129 13976 callbacks.py:2207] `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "      2/Unknown - 0s 0s/step - loss: 1.3516 - accuracy: 0.32 - 3s 2s/step - loss: 1.2167 - accuracy: 0.3893"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0613 11:29:39.326326 13976 callbacks.py:307] Method (on_train_batch_end) is slow compared to the batch update (1.663653). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     19/Unknown - 3s 1s/step - loss: 1.1479 - accuracy: 0.44 - 4s 879ms/step - loss: 1.0862 - accuracy: 0.494 - 4s 715ms/step - loss: 1.0606 - accuracy: 0.517 - 4s 609ms/step - loss: 1.0318 - accuracy: 0.541 - 4s 471ms/step - loss: 1.0099 - accuracy: 0.561 - 4s 425ms/step - loss: 1.0081 - accuracy: 0.564 - 4s 389ms/step - loss: 1.0111 - accuracy: 0.560 - 4s 359ms/step - loss: 1.0039 - accuracy: 0.570 - 4s 335ms/step - loss: 0.9900 - accuracy: 0.584 - 4s 314ms/step - loss: 0.9675 - accuracy: 0.600 - 4s 296ms/step - loss: 0.9848 - accuracy: 0.592 - 4s 280ms/step - loss: 1.0161 - accuracy: 0.577 - 4s 267ms/step - loss: 1.0171 - accuracy: 0.577 - 4s 255ms/step - loss: 1.0196 - accuracy: 0.574 - 4s 244ms/step - loss: 1.0167 - accuracy: 0.575 - 4s 234ms/step - loss: 1.0162 - accuracy: 0.5749\n",
      "Epoch 00001: val_loss improved from inf to 1.12381, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 5s 269ms/step - loss: 1.0162 - accuracy: 0.5749 - val_loss: 1.1238 - val_accuracy: 0.2595 - lr: 0.0900\n",
      "Epoch 2/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0628 - accuracy: 0.45 - ETA: 0s - loss: 1.0564 - accuracy: 0.46 - ETA: 0s - loss: 1.0507 - accuracy: 0.47 - ETA: 0s - loss: 1.0294 - accuracy: 0.51 - ETA: 0s - loss: 1.0142 - accuracy: 0.53 - ETA: 0s - loss: 0.9937 - accuracy: 0.55 - ETA: 0s - loss: 0.9847 - accuracy: 0.56 - ETA: 0s - loss: 0.9806 - accuracy: 0.57 - ETA: 0s - loss: 0.9850 - accuracy: 0.57 - ETA: 0s - loss: 0.9864 - accuracy: 0.58 - ETA: 0s - loss: 0.9673 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.60 - ETA: 0s - loss: 0.9568 - accuracy: 0.59 - ETA: 0s - loss: 0.9768 - accuracy: 0.58 - ETA: 0s - loss: 0.9772 - accuracy: 0.58 - ETA: 0s - loss: 0.9811 - accuracy: 0.58 - ETA: 0s - loss: 0.9810 - accuracy: 0.58 - ETA: 0s - loss: 0.9831 - accuracy: 0.5803\n",
      "Epoch 00002: val_loss improved from 1.12381 to 1.04518, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 1s 74ms/step - loss: 0.9831 - accuracy: 0.5803 - val_loss: 1.0452 - val_accuracy: 0.5008 - lr: 0.0900\n",
      "Epoch 3/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0326 - accuracy: 0.53 - ETA: 0s - loss: 1.0340 - accuracy: 0.52 - ETA: 0s - loss: 1.0297 - accuracy: 0.53 - ETA: 0s - loss: 1.0145 - accuracy: 0.55 - ETA: 0s - loss: 1.0056 - accuracy: 0.57 - ETA: 0s - loss: 0.9907 - accuracy: 0.58 - ETA: 0s - loss: 0.9813 - accuracy: 0.59 - ETA: 0s - loss: 0.9746 - accuracy: 0.59 - ETA: 0s - loss: 0.9731 - accuracy: 0.59 - ETA: 0s - loss: 0.9849 - accuracy: 0.58 - ETA: 0s - loss: 0.9728 - accuracy: 0.59 - ETA: 0s - loss: 0.9549 - accuracy: 0.60 - ETA: 0s - loss: 0.9489 - accuracy: 0.61 - ETA: 0s - loss: 0.9717 - accuracy: 0.59 - ETA: 0s - loss: 0.9730 - accuracy: 0.59 - ETA: 0s - loss: 0.9767 - accuracy: 0.59 - ETA: 0s - loss: 0.9765 - accuracy: 0.59 - ETA: 0s - loss: 0.9774 - accuracy: 0.5898\n",
      "Epoch 00003: val_loss did not improve from 1.04518\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9774 - accuracy: 0.5898 - val_loss: 1.0475 - val_accuracy: 0.5020 - lr: 0.0900\n",
      "Epoch 4/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0266 - accuracy: 0.53 - ETA: 0s - loss: 1.0236 - accuracy: 0.52 - ETA: 0s - loss: 1.0218 - accuracy: 0.53 - ETA: 0s - loss: 1.0023 - accuracy: 0.55 - ETA: 0s - loss: 0.9951 - accuracy: 0.56 - ETA: 0s - loss: 0.9798 - accuracy: 0.58 - ETA: 0s - loss: 0.9755 - accuracy: 0.59 - ETA: 0s - loss: 0.9721 - accuracy: 0.59 - ETA: 0s - loss: 0.9717 - accuracy: 0.59 - ETA: 0s - loss: 0.9827 - accuracy: 0.58 - ETA: 0s - loss: 0.9526 - accuracy: 0.60 - ETA: 0s - loss: 0.9305 - accuracy: 0.62 - ETA: 0s - loss: 0.9455 - accuracy: 0.61 - ETA: 0s - loss: 0.9665 - accuracy: 0.59 - ETA: 0s - loss: 0.9683 - accuracy: 0.59 - ETA: 0s - loss: 0.9733 - accuracy: 0.59 - ETA: 0s - loss: 0.9740 - accuracy: 0.59 - ETA: 0s - loss: 0.9759 - accuracy: 0.5892\n",
      "Epoch 00004: val_loss improved from 1.04518 to 1.03954, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 1s 74ms/step - loss: 0.9759 - accuracy: 0.5892 - val_loss: 1.0395 - val_accuracy: 0.5010 - lr: 0.0900\n",
      "Epoch 5/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0088 - accuracy: 0.52 - ETA: 0s - loss: 1.0215 - accuracy: 0.51 - ETA: 0s - loss: 1.0155 - accuracy: 0.52 - ETA: 0s - loss: 0.9980 - accuracy: 0.55 - ETA: 0s - loss: 0.9899 - accuracy: 0.56 - ETA: 0s - loss: 0.9745 - accuracy: 0.58 - ETA: 0s - loss: 0.9680 - accuracy: 0.58 - ETA: 0s - loss: 0.9672 - accuracy: 0.59 - ETA: 0s - loss: 0.9698 - accuracy: 0.59 - ETA: 0s - loss: 0.9791 - accuracy: 0.58 - ETA: 0s - loss: 0.9681 - accuracy: 0.59 - ETA: 0s - loss: 0.9507 - accuracy: 0.60 - ETA: 0s - loss: 0.9463 - accuracy: 0.60 - ETA: 0s - loss: 0.9705 - accuracy: 0.59 - ETA: 0s - loss: 0.9712 - accuracy: 0.59 - ETA: 0s - loss: 0.9754 - accuracy: 0.58 - ETA: 0s - loss: 0.9756 - accuracy: 0.58 - ETA: 0s - loss: 0.9770 - accuracy: 0.5877\n",
      "Epoch 00005: val_loss did not improve from 1.03954\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9770 - accuracy: 0.5877 - val_loss: 1.0559 - val_accuracy: 0.5011 - lr: 0.0900\n",
      "Epoch 6/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0264 - accuracy: 0.53 - ETA: 0s - loss: 1.0329 - accuracy: 0.52 - ETA: 0s - loss: 1.0240 - accuracy: 0.52 - ETA: 0s - loss: 1.0053 - accuracy: 0.55 - ETA: 0s - loss: 0.9948 - accuracy: 0.57 - ETA: 0s - loss: 0.9779 - accuracy: 0.58 - ETA: 0s - loss: 0.9707 - accuracy: 0.59 - ETA: 0s - loss: 0.9666 - accuracy: 0.59 - ETA: 0s - loss: 0.9655 - accuracy: 0.59 - ETA: 0s - loss: 0.9769 - accuracy: 0.58 - ETA: 0s - loss: 0.9666 - accuracy: 0.59 - ETA: 0s - loss: 0.9481 - accuracy: 0.60 - ETA: 0s - loss: 0.9262 - accuracy: 0.62 - ETA: 0s - loss: 0.9414 - accuracy: 0.61 - ETA: 0s - loss: 0.9662 - accuracy: 0.59 - ETA: 0s - loss: 0.9704 - accuracy: 0.59 - ETA: 0s - loss: 0.9702 - accuracy: 0.59 - ETA: 0s - loss: 0.9704 - accuracy: 0.5898\n",
      "Epoch 00006: val_loss did not improve from 1.03954\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9704 - accuracy: 0.5898 - val_loss: 1.1158 - val_accuracy: 0.2577 - lr: 0.0900\n",
      "Epoch 7/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0112 - accuracy: 0.51 - ETA: 0s - loss: 1.0314 - accuracy: 0.49 - ETA: 0s - loss: 1.0123 - accuracy: 0.48 - ETA: 0s - loss: 1.0018 - accuracy: 0.50 - ETA: 0s - loss: 0.9894 - accuracy: 0.53 - ETA: 0s - loss: 0.9823 - accuracy: 0.54 - ETA: 0s - loss: 0.9748 - accuracy: 0.55 - ETA: 0s - loss: 0.9745 - accuracy: 0.55 - ETA: 0s - loss: 0.9862 - accuracy: 0.55 - ETA: 0s - loss: 0.9725 - accuracy: 0.56 - ETA: 0s - loss: 0.9566 - accuracy: 0.58 - ETA: 0s - loss: 0.9350 - accuracy: 0.59 - ETA: 0s - loss: 0.9730 - accuracy: 0.57 - ETA: 0s - loss: 0.9737 - accuracy: 0.57 - ETA: 0s - loss: 0.9769 - accuracy: 0.57 - ETA: 0s - loss: 0.9767 - accuracy: 0.57 - ETA: 0s - loss: 0.9779 - accuracy: 0.5729\n",
      "Epoch 00007: val_loss did not improve from 1.03954\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9779 - accuracy: 0.5729 - val_loss: 1.0502 - val_accuracy: 0.5026 - lr: 0.0900\n",
      "Epoch 8/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0273 - accuracy: 0.52 - ETA: 0s - loss: 1.0286 - accuracy: 0.51 - ETA: 0s - loss: 1.0208 - accuracy: 0.52 - ETA: 0s - loss: 1.0057 - accuracy: 0.55 - ETA: 0s - loss: 0.9951 - accuracy: 0.56 - ETA: 0s - loss: 0.9802 - accuracy: 0.58 - ETA: 0s - loss: 0.9741 - accuracy: 0.58 - ETA: 0s - loss: 0.9671 - accuracy: 0.59 - ETA: 0s - loss: 0.9654 - accuracy: 0.59 - ETA: 0s - loss: 0.9750 - accuracy: 0.58 - ETA: 0s - loss: 0.9463 - accuracy: 0.60 - ETA: 0s - loss: 0.9259 - accuracy: 0.61 - ETA: 0s - loss: 0.9403 - accuracy: 0.61 - ETA: 0s - loss: 0.9623 - accuracy: 0.59 - ETA: 0s - loss: 0.9635 - accuracy: 0.59 - ETA: 0s - loss: 0.9679 - accuracy: 0.58 - ETA: 0s - loss: 0.9686 - accuracy: 0.58 - ETA: 0s - loss: 0.9707 - accuracy: 0.5881\n",
      "Epoch 00008: val_loss did not improve from 1.03954\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9707 - accuracy: 0.5881 - val_loss: 1.0422 - val_accuracy: 0.4971 - lr: 0.0900\n",
      "Epoch 9/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0223 - accuracy: 0.52 - ETA: 0s - loss: 1.0389 - accuracy: 0.51 - ETA: 0s - loss: 1.0327 - accuracy: 0.52 - ETA: 0s - loss: 1.0081 - accuracy: 0.55 - ETA: 0s - loss: 0.9948 - accuracy: 0.56 - ETA: 0s - loss: 0.9758 - accuracy: 0.58 - ETA: 0s - loss: 0.9705 - accuracy: 0.59 - ETA: 0s - loss: 0.9670 - accuracy: 0.59 - ETA: 0s - loss: 0.9675 - accuracy: 0.59 - ETA: 0s - loss: 0.9811 - accuracy: 0.58 - ETA: 0s - loss: 0.9685 - accuracy: 0.59 - ETA: 0s - loss: 0.9500 - accuracy: 0.60 - ETA: 0s - loss: 0.9283 - accuracy: 0.62 - ETA: 0s - loss: 0.9650 - accuracy: 0.59 - ETA: 0s - loss: 0.9657 - accuracy: 0.59 - ETA: 0s - loss: 0.9692 - accuracy: 0.59 - ETA: 0s - loss: 0.9697 - accuracy: 0.59 - ETA: 0s - loss: 0.9713 - accuracy: 0.5895\n",
      "Epoch 00009: val_loss did not improve from 1.03954\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9713 - accuracy: 0.5895 - val_loss: 1.0455 - val_accuracy: 0.5039 - lr: 0.0900\n",
      "Epoch 10/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0228 - accuracy: 0.52 - ETA: 0s - loss: 1.0285 - accuracy: 0.51 - ETA: 0s - loss: 1.0259 - accuracy: 0.52 - ETA: 0s - loss: 1.0069 - accuracy: 0.54 - ETA: 0s - loss: 0.9972 - accuracy: 0.55 - ETA: 0s - loss: 0.9814 - accuracy: 0.57 - ETA: 0s - loss: 0.9744 - accuracy: 0.58 - ETA: 0s - loss: 0.9686 - accuracy: 0.58 - ETA: 0s - loss: 0.9678 - accuracy: 0.58 - ETA: 0s - loss: 0.9787 - accuracy: 0.58 - ETA: 0s - loss: 0.9661 - accuracy: 0.59 - ETA: 0s - loss: 0.9486 - accuracy: 0.60 - ETA: 0s - loss: 0.9273 - accuracy: 0.61 - ETA: 0s - loss: 0.9427 - accuracy: 0.60 - ETA: 0s - loss: 0.9654 - accuracy: 0.59 - ETA: 0s - loss: 0.9665 - accuracy: 0.59 - ETA: 0s - loss: 0.9706 - accuracy: 0.58 - ETA: 0s - loss: 0.9702 - accuracy: 0.58 - ETA: 0s - loss: 0.9715 - accuracy: 0.5868\n",
      "Epoch 00010: val_loss improved from 1.03954 to 1.03821, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 1s 74ms/step - loss: 0.9715 - accuracy: 0.5868 - val_loss: 1.0382 - val_accuracy: 0.5044 - lr: 0.0900\n",
      "Epoch 11/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0211 - accuracy: 0.52 - ETA: 0s - loss: 1.0287 - accuracy: 0.51 - ETA: 0s - loss: 1.0049 - accuracy: 0.55 - ETA: 0s - loss: 0.9932 - accuracy: 0.56 - ETA: 0s - loss: 0.9747 - accuracy: 0.58 - ETA: 0s - loss: 0.9664 - accuracy: 0.58 - ETA: 0s - loss: 0.9613 - accuracy: 0.59 - ETA: 0s - loss: 0.9601 - accuracy: 0.59 - ETA: 0s - loss: 0.9718 - accuracy: 0.58 - ETA: 0s - loss: 0.9600 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.60 - ETA: 0s - loss: 0.9210 - accuracy: 0.62 - ETA: 0s - loss: 0.9369 - accuracy: 0.61 - ETA: 0s - loss: 0.9587 - accuracy: 0.59 - ETA: 0s - loss: 0.9601 - accuracy: 0.59 - ETA: 0s - loss: 0.9648 - accuracy: 0.59 - ETA: 0s - loss: 0.9663 - accuracy: 0.5891\n",
      "Epoch 00011: val_loss improved from 1.03821 to 1.03161, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 1s 74ms/step - loss: 0.9663 - accuracy: 0.5891 - val_loss: 1.0316 - val_accuracy: 0.4971 - lr: 0.0900\n",
      "Epoch 12/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0264 - accuracy: 0.52 - ETA: 0s - loss: 1.0303 - accuracy: 0.52 - ETA: 0s - loss: 1.0101 - accuracy: 0.55 - ETA: 0s - loss: 1.0002 - accuracy: 0.56 - ETA: 0s - loss: 0.9823 - accuracy: 0.58 - ETA: 0s - loss: 0.9735 - accuracy: 0.59 - ETA: 0s - loss: 0.9695 - accuracy: 0.59 - ETA: 0s - loss: 0.9698 - accuracy: 0.59 - ETA: 0s - loss: 0.9805 - accuracy: 0.58 - ETA: 0s - loss: 0.9670 - accuracy: 0.59 - ETA: 0s - loss: 0.9490 - accuracy: 0.60 - ETA: 0s - loss: 0.9276 - accuracy: 0.62 - ETA: 0s - loss: 0.9629 - accuracy: 0.59 - ETA: 0s - loss: 0.9644 - accuracy: 0.59 - ETA: 0s - loss: 0.9692 - accuracy: 0.59 - ETA: 0s - loss: 0.9699 - accuracy: 0.59 - ETA: 0s - loss: 0.9715 - accuracy: 0.5895\n",
      "Epoch 00012: val_loss did not improve from 1.03161\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9715 - accuracy: 0.5895 - val_loss: 1.0411 - val_accuracy: 0.4989 - lr: 0.0900\n",
      "Epoch 13/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0110 - accuracy: 0.52 - ETA: 0s - loss: 1.0186 - accuracy: 0.51 - ETA: 0s - loss: 1.0127 - accuracy: 0.52 - ETA: 0s - loss: 0.9898 - accuracy: 0.55 - ETA: 0s - loss: 0.9795 - accuracy: 0.56 - ETA: 0s - loss: 0.9612 - accuracy: 0.57 - ETA: 0s - loss: 0.9588 - accuracy: 0.58 - ETA: 0s - loss: 0.9581 - accuracy: 0.59 - ETA: 0s - loss: 0.9598 - accuracy: 0.59 - ETA: 0s - loss: 0.9734 - accuracy: 0.58 - ETA: 0s - loss: 0.9439 - accuracy: 0.60 - ETA: 0s - loss: 0.9226 - accuracy: 0.61 - ETA: 0s - loss: 0.9377 - accuracy: 0.60 - ETA: 0s - loss: 0.9595 - accuracy: 0.59 - ETA: 0s - loss: 0.9611 - accuracy: 0.59 - ETA: 0s - loss: 0.9659 - accuracy: 0.58 - ETA: 0s - loss: 0.9664 - accuracy: 0.58 - ETA: 0s - loss: 0.9678 - accuracy: 0.5877\n",
      "Epoch 00013: val_loss did not improve from 1.03161\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9678 - accuracy: 0.5877 - val_loss: 1.0452 - val_accuracy: 0.4971 - lr: 0.0900\n",
      "Epoch 14/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0051 - accuracy: 0.52 - ETA: 0s - loss: 1.0183 - accuracy: 0.51 - ETA: 0s - loss: 1.0200 - accuracy: 0.52 - ETA: 0s - loss: 1.0039 - accuracy: 0.55 - ETA: 0s - loss: 0.9942 - accuracy: 0.56 - ETA: 0s - loss: 0.9742 - accuracy: 0.58 - ETA: 0s - loss: 0.9666 - accuracy: 0.59 - ETA: 0s - loss: 0.9649 - accuracy: 0.59 - ETA: 0s - loss: 0.9664 - accuracy: 0.59 - ETA: 0s - loss: 0.9787 - accuracy: 0.58 - ETA: 0s - loss: 0.9657 - accuracy: 0.59 - ETA: 0s - loss: 0.9485 - accuracy: 0.60 - ETA: 0s - loss: 0.9273 - accuracy: 0.62 - ETA: 0s - loss: 0.9634 - accuracy: 0.59 - ETA: 0s - loss: 0.9647 - accuracy: 0.59 - ETA: 0s - loss: 0.9688 - accuracy: 0.59 - ETA: 0s - loss: 0.9689 - accuracy: 0.59 - ETA: 0s - loss: 0.9700 - accuracy: 0.5891\n",
      "Epoch 00014: val_loss did not improve from 1.03161\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9700 - accuracy: 0.5891 - val_loss: 1.0378 - val_accuracy: 0.4971 - lr: 0.0900\n",
      "Epoch 15/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0124 - accuracy: 0.52 - ETA: 0s - loss: 1.0192 - accuracy: 0.51 - ETA: 0s - loss: 1.0180 - accuracy: 0.52 - ETA: 0s - loss: 0.9961 - accuracy: 0.55 - ETA: 0s - loss: 0.9861 - accuracy: 0.56 - ETA: 0s - loss: 0.9672 - accuracy: 0.57 - ETA: 0s - loss: 0.9622 - accuracy: 0.58 - ETA: 0s - loss: 0.9614 - accuracy: 0.59 - ETA: 0s - loss: 0.9615 - accuracy: 0.59 - ETA: 0s - loss: 0.9737 - accuracy: 0.58 - ETA: 0s - loss: 0.9615 - accuracy: 0.59 - ETA: 0s - loss: 0.9439 - accuracy: 0.60 - ETA: 0s - loss: 0.9230 - accuracy: 0.61 - ETA: 0s - loss: 0.9378 - accuracy: 0.60 - ETA: 0s - loss: 0.9585 - accuracy: 0.59 - ETA: 0s - loss: 0.9601 - accuracy: 0.59 - ETA: 0s - loss: 0.9648 - accuracy: 0.58 - ETA: 0s - loss: 0.9659 - accuracy: 0.5889\n",
      "Epoch 00015: val_loss did not improve from 1.03161\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9682 - accuracy: 0.5878 - val_loss: 1.0395 - val_accuracy: 0.4971 - lr: 0.0900\n",
      "Epoch 16/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0185 - accuracy: 0.52 - ETA: 0s - loss: 1.0271 - accuracy: 0.51 - ETA: 0s - loss: 1.0224 - accuracy: 0.52 - ETA: 0s - loss: 0.9982 - accuracy: 0.55 - ETA: 0s - loss: 0.9876 - accuracy: 0.56 - ETA: 0s - loss: 0.9674 - accuracy: 0.57 - ETA: 0s - loss: 0.9612 - accuracy: 0.58 - ETA: 0s - loss: 0.9590 - accuracy: 0.59 - ETA: 0s - loss: 0.9584 - accuracy: 0.59 - ETA: 0s - loss: 0.9706 - accuracy: 0.58 - ETA: 0s - loss: 0.9584 - accuracy: 0.59 - ETA: 0s - loss: 0.9411 - accuracy: 0.60 - ETA: 0s - loss: 0.9201 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.60 - ETA: 0s - loss: 0.9544 - accuracy: 0.59 - ETA: 0s - loss: 0.9563 - accuracy: 0.59 - ETA: 0s - loss: 0.9612 - accuracy: 0.58 - ETA: 0s - loss: 0.9652 - accuracy: 0.5878\n",
      "Epoch 00016: val_loss did not improve from 1.03161\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9652 - accuracy: 0.5878 - val_loss: 1.0406 - val_accuracy: 0.4971 - lr: 0.0900\n",
      "Epoch 17/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0116 - accuracy: 0.52 - ETA: 0s - loss: 1.0129 - accuracy: 0.51 - ETA: 0s - loss: 1.0068 - accuracy: 0.52 - ETA: 0s - loss: 0.9792 - accuracy: 0.55 - ETA: 0s - loss: 0.9695 - accuracy: 0.56 - ETA: 0s - loss: 0.9518 - accuracy: 0.57 - ETA: 0s - loss: 0.9500 - accuracy: 0.58 - ETA: 0s - loss: 0.9530 - accuracy: 0.58 - ETA: 0s - loss: 0.9534 - accuracy: 0.58 - ETA: 0s - loss: 0.9656 - accuracy: 0.58 - ETA: 0s - loss: 0.9541 - accuracy: 0.59 - ETA: 0s - loss: 0.9378 - accuracy: 0.60 - ETA: 0s - loss: 0.9177 - accuracy: 0.61 - ETA: 0s - loss: 0.9545 - accuracy: 0.59 - ETA: 0s - loss: 0.9560 - accuracy: 0.59 - ETA: 0s - loss: 0.9606 - accuracy: 0.58 - ETA: 0s - loss: 0.9613 - accuracy: 0.58 - ETA: 0s - loss: 0.9629 - accuracy: 0.5876\n",
      "Epoch 00017: val_loss did not improve from 1.03161\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9629 - accuracy: 0.5876 - val_loss: 1.0377 - val_accuracy: 0.5060 - lr: 0.0900\n",
      "Epoch 18/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0032 - accuracy: 0.53 - ETA: 0s - loss: 1.0076 - accuracy: 0.52 - ETA: 0s - loss: 1.0071 - accuracy: 0.51 - ETA: 0s - loss: 0.9875 - accuracy: 0.54 - ETA: 0s - loss: 0.9780 - accuracy: 0.54 - ETA: 0s - loss: 0.9606 - accuracy: 0.56 - ETA: 0s - loss: 0.9558 - accuracy: 0.57 - ETA: 0s - loss: 0.9566 - accuracy: 0.58 - ETA: 0s - loss: 0.9570 - accuracy: 0.58 - ETA: 0s - loss: 0.9700 - accuracy: 0.57 - ETA: 0s - loss: 0.9579 - accuracy: 0.58 - ETA: 0s - loss: 0.9424 - accuracy: 0.59 - ETA: 0s - loss: 0.9227 - accuracy: 0.61 - ETA: 0s - loss: 0.9370 - accuracy: 0.60 - ETA: 0s - loss: 0.9584 - accuracy: 0.58 - ETA: 0s - loss: 0.9596 - accuracy: 0.58 - ETA: 0s - loss: 0.9639 - accuracy: 0.58 - ETA: 0s - loss: 0.9639 - accuracy: 0.5843\n",
      "Epoch 00018: val_loss did not improve from 1.03161\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9652 - accuracy: 0.5835 - val_loss: 1.0386 - val_accuracy: 0.4971 - lr: 0.0900\n",
      "Epoch 19/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9950 - accuracy: 0.52 - ETA: 0s - loss: 1.0101 - accuracy: 0.51 - ETA: 0s - loss: 1.0077 - accuracy: 0.52 - ETA: 0s - loss: 0.9886 - accuracy: 0.55 - ETA: 0s - loss: 0.9766 - accuracy: 0.56 - ETA: 0s - loss: 0.9597 - accuracy: 0.58 - ETA: 0s - loss: 0.9540 - accuracy: 0.59 - ETA: 0s - loss: 0.9531 - accuracy: 0.59 - ETA: 0s - loss: 0.9535 - accuracy: 0.59 - ETA: 0s - loss: 0.9664 - accuracy: 0.58 - ETA: 0s - loss: 0.9551 - accuracy: 0.59 - ETA: 0s - loss: 0.9381 - accuracy: 0.60 - ETA: 0s - loss: 0.9179 - accuracy: 0.62 - ETA: 0s - loss: 0.9545 - accuracy: 0.59 - ETA: 0s - loss: 0.9557 - accuracy: 0.59 - ETA: 0s - loss: 0.9597 - accuracy: 0.59 - ETA: 0s - loss: 0.9602 - accuracy: 0.59 - ETA: 0s - loss: 0.9616 - accuracy: 0.5894\n",
      "Epoch 00019: val_loss improved from 1.03161 to 1.01682, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 1s 74ms/step - loss: 0.9616 - accuracy: 0.5894 - val_loss: 1.0168 - val_accuracy: 0.4987 - lr: 0.0900\n",
      "Epoch 20/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0065 - accuracy: 0.53 - ETA: 0s - loss: 1.0117 - accuracy: 0.52 - ETA: 0s - loss: 1.0059 - accuracy: 0.52 - ETA: 0s - loss: 0.9860 - accuracy: 0.55 - ETA: 0s - loss: 0.9767 - accuracy: 0.56 - ETA: 0s - loss: 0.9587 - accuracy: 0.57 - ETA: 0s - loss: 0.9569 - accuracy: 0.58 - ETA: 0s - loss: 0.9579 - accuracy: 0.58 - ETA: 0s - loss: 0.9562 - accuracy: 0.58 - ETA: 0s - loss: 0.9687 - accuracy: 0.58 - ETA: 0s - loss: 0.9569 - accuracy: 0.59 - ETA: 0s - loss: 0.9405 - accuracy: 0.60 - ETA: 0s - loss: 0.9206 - accuracy: 0.61 - ETA: 0s - loss: 0.9355 - accuracy: 0.60 - ETA: 0s - loss: 0.9571 - accuracy: 0.59 - ETA: 0s - loss: 0.9583 - accuracy: 0.59 - ETA: 0s - loss: 0.9634 - accuracy: 0.58 - ETA: 0s - loss: 0.9650 - accuracy: 0.5872\n",
      "Epoch 00020: val_loss did not improve from 1.01682\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9650 - accuracy: 0.5872 - val_loss: 1.0388 - val_accuracy: 0.4971 - lr: 0.0900\n",
      "Epoch 21/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0057 - accuracy: 0.52 - ETA: 0s - loss: 1.0147 - accuracy: 0.51 - ETA: 0s - loss: 1.0123 - accuracy: 0.52 - ETA: 0s - loss: 0.9937 - accuracy: 0.55 - ETA: 0s - loss: 0.9825 - accuracy: 0.56 - ETA: 0s - loss: 0.9653 - accuracy: 0.58 - ETA: 0s - loss: 0.9575 - accuracy: 0.58 - ETA: 0s - loss: 0.9564 - accuracy: 0.58 - ETA: 0s - loss: 0.9540 - accuracy: 0.58 - ETA: 0s - loss: 0.9664 - accuracy: 0.58 - ETA: 0s - loss: 0.9557 - accuracy: 0.59 - ETA: 0s - loss: 0.9375 - accuracy: 0.60 - ETA: 0s - loss: 0.9327 - accuracy: 0.60 - ETA: 0s - loss: 0.9545 - accuracy: 0.59 - ETA: 0s - loss: 0.9558 - accuracy: 0.59 - ETA: 0s - loss: 0.9599 - accuracy: 0.58 - ETA: 0s - loss: 0.9617 - accuracy: 0.58 - ETA: 0s - loss: 0.9643 - accuracy: 0.5872\n",
      "Epoch 00021: val_loss did not improve from 1.01682\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9643 - accuracy: 0.5872 - val_loss: 1.0320 - val_accuracy: 0.4971 - lr: 0.0900\n",
      "Epoch 22/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0194 - accuracy: 0.52 - ETA: 0s - loss: 1.0226 - accuracy: 0.51 - ETA: 0s - loss: 1.0169 - accuracy: 0.52 - ETA: 0s - loss: 0.9903 - accuracy: 0.55 - ETA: 0s - loss: 0.9788 - accuracy: 0.56 - ETA: 0s - loss: 0.9625 - accuracy: 0.57 - ETA: 0s - loss: 0.9600 - accuracy: 0.58 - ETA: 0s - loss: 0.9598 - accuracy: 0.58 - ETA: 0s - loss: 0.9572 - accuracy: 0.58 - ETA: 0s - loss: 0.9687 - accuracy: 0.58 - ETA: 0s - loss: 0.9567 - accuracy: 0.59 - ETA: 0s - loss: 0.9407 - accuracy: 0.60 - ETA: 0s - loss: 0.9214 - accuracy: 0.61 - ETA: 0s - loss: 0.9554 - accuracy: 0.59 - ETA: 0s - loss: 0.9569 - accuracy: 0.59 - ETA: 0s - loss: 0.9616 - accuracy: 0.58 - ETA: 0s - loss: 0.9636 - accuracy: 0.58 - ETA: 0s - loss: 0.9664 - accuracy: 0.5876\n",
      "Epoch 00022: val_loss did not improve from 1.01682\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9664 - accuracy: 0.5876 - val_loss: 1.0324 - val_accuracy: 0.4971 - lr: 0.0900\n",
      "Epoch 23/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0126 - accuracy: 0.51 - ETA: 0s - loss: 1.0168 - accuracy: 0.51 - ETA: 0s - loss: 1.0121 - accuracy: 0.52 - ETA: 0s - loss: 0.9850 - accuracy: 0.55 - ETA: 0s - loss: 0.9743 - accuracy: 0.56 - ETA: 0s - loss: 0.9522 - accuracy: 0.57 - ETA: 0s - loss: 0.9460 - accuracy: 0.58 - ETA: 0s - loss: 0.9495 - accuracy: 0.58 - ETA: 0s - loss: 0.9515 - accuracy: 0.58 - ETA: 0s - loss: 0.9660 - accuracy: 0.58 - ETA: 0s - loss: 0.9550 - accuracy: 0.59 - ETA: 0s - loss: 0.9381 - accuracy: 0.60 - ETA: 0s - loss: 0.9181 - accuracy: 0.61 - ETA: 0s - loss: 0.9320 - accuracy: 0.60 - ETA: 0s - loss: 0.9520 - accuracy: 0.59 - ETA: 0s - loss: 0.9531 - accuracy: 0.59 - ETA: 0s - loss: 0.9575 - accuracy: 0.58 - ETA: 0s - loss: 0.9581 - accuracy: 0.5882\n",
      "Epoch 00023: val_loss did not improve from 1.01682\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9598 - accuracy: 0.5872 - val_loss: 1.0338 - val_accuracy: 0.4971 - lr: 0.0900\n",
      "Epoch 24/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0159 - accuracy: 0.51 - ETA: 0s - loss: 1.0113 - accuracy: 0.52 - ETA: 0s - loss: 0.9910 - accuracy: 0.55 - ETA: 0s - loss: 0.9808 - accuracy: 0.56 - ETA: 0s - loss: 0.9672 - accuracy: 0.58 - ETA: 0s - loss: 0.9652 - accuracy: 0.59 - ETA: 0s - loss: 0.9619 - accuracy: 0.59 - ETA: 0s - loss: 0.9592 - accuracy: 0.59 - ETA: 0s - loss: 0.9698 - accuracy: 0.58 - ETA: 0s - loss: 0.9579 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.60 - ETA: 0s - loss: 0.9212 - accuracy: 0.62 - ETA: 0s - loss: 0.9359 - accuracy: 0.61 - ETA: 0s - loss: 0.9576 - accuracy: 0.59 - ETA: 0s - loss: 0.9632 - accuracy: 0.59 - ETA: 0s - loss: 0.9642 - accuracy: 0.59 - ETA: 0s - loss: 0.9662 - accuracy: 0.5897\n",
      "Epoch 00024: val_loss did not improve from 1.01682\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9662 - accuracy: 0.5897 - val_loss: 1.0332 - val_accuracy: 0.5047 - lr: 0.0900\n",
      "Epoch 25/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0149 - accuracy: 0.52 - ETA: 0s - loss: 1.0166 - accuracy: 0.51 - ETA: 0s - loss: 1.0109 - accuracy: 0.52 - ETA: 0s - loss: 0.9901 - accuracy: 0.55 - ETA: 0s - loss: 0.9776 - accuracy: 0.56 - ETA: 0s - loss: 0.9630 - accuracy: 0.57 - ETA: 0s - loss: 0.9587 - accuracy: 0.58 - ETA: 0s - loss: 0.9550 - accuracy: 0.59 - ETA: 0s - loss: 0.9550 - accuracy: 0.59 - ETA: 0s - loss: 0.9687 - accuracy: 0.58 - ETA: 0s - loss: 0.9568 - accuracy: 0.59 - ETA: 0s - loss: 0.9193 - accuracy: 0.61 - ETA: 0s - loss: 0.9340 - accuracy: 0.60 - ETA: 0s - loss: 0.9558 - accuracy: 0.59 - ETA: 0s - loss: 0.9565 - accuracy: 0.59 - ETA: 0s - loss: 0.9608 - accuracy: 0.58 - ETA: 0s - loss: 0.9615 - accuracy: 0.58 - ETA: 0s - loss: 0.9631 - accuracy: 0.5877\n",
      "Epoch 00025: val_loss did not improve from 1.01682\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9631 - accuracy: 0.5877 - val_loss: 1.0430 - val_accuracy: 0.4974 - lr: 0.0900\n",
      "Epoch 26/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0132 - accuracy: 0.52 - ETA: 0s - loss: 1.0157 - accuracy: 0.51 - ETA: 0s - loss: 1.0073 - accuracy: 0.52 - ETA: 0s - loss: 0.9770 - accuracy: 0.55 - ETA: 0s - loss: 0.9633 - accuracy: 0.56 - ETA: 0s - loss: 0.9493 - accuracy: 0.58 - ETA: 0s - loss: 0.9479 - accuracy: 0.58 - ETA: 0s - loss: 0.9496 - accuracy: 0.59 - ETA: 0s - loss: 0.9512 - accuracy: 0.59 - ETA: 0s - loss: 0.9656 - accuracy: 0.58 - ETA: 0s - loss: 0.9538 - accuracy: 0.59 - ETA: 0s - loss: 0.9373 - accuracy: 0.60 - ETA: 0s - loss: 0.9178 - accuracy: 0.61 - ETA: 0s - loss: 0.9499 - accuracy: 0.59 - ETA: 0s - loss: 0.9511 - accuracy: 0.59 - ETA: 0s - loss: 0.9556 - accuracy: 0.58 - ETA: 0s - loss: 0.9563 - accuracy: 0.58 - ETA: 0s - loss: 0.9576 - accuracy: 0.5882\n",
      "Epoch 00026: val_loss did not improve from 1.01682\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9576 - accuracy: 0.5882 - val_loss: 1.0171 - val_accuracy: 0.4974 - lr: 0.0900\n",
      "Epoch 27/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0018 - accuracy: 0.53 - ETA: 0s - loss: 1.0057 - accuracy: 0.51 - ETA: 0s - loss: 1.0018 - accuracy: 0.52 - ETA: 0s - loss: 0.9800 - accuracy: 0.55 - ETA: 0s - loss: 0.9695 - accuracy: 0.56 - ETA: 0s - loss: 0.9552 - accuracy: 0.57 - ETA: 0s - loss: 0.9509 - accuracy: 0.58 - ETA: 0s - loss: 0.9526 - accuracy: 0.58 - ETA: 0s - loss: 0.9510 - accuracy: 0.58 - ETA: 0s - loss: 0.9629 - accuracy: 0.58 - ETA: 0s - loss: 0.9514 - accuracy: 0.59 - ETA: 0s - loss: 0.9351 - accuracy: 0.60 - ETA: 0s - loss: 0.9151 - accuracy: 0.61 - ETA: 0s - loss: 0.9522 - accuracy: 0.59 - ETA: 0s - loss: 0.9538 - accuracy: 0.59 - ETA: 0s - loss: 0.9581 - accuracy: 0.58 - ETA: 0s - loss: 0.9591 - accuracy: 0.58 - ETA: 0s - loss: 0.9610 - accuracy: 0.5867\n",
      "Epoch 00027: val_loss did not improve from 1.01682\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9610 - accuracy: 0.5867 - val_loss: 1.0284 - val_accuracy: 0.4974 - lr: 0.0900\n",
      "Epoch 28/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0122 - accuracy: 0.51 - ETA: 0s - loss: 1.0201 - accuracy: 0.51 - ETA: 0s - loss: 1.0165 - accuracy: 0.51 - ETA: 0s - loss: 0.9961 - accuracy: 0.54 - ETA: 0s - loss: 0.9823 - accuracy: 0.55 - ETA: 0s - loss: 0.9631 - accuracy: 0.57 - ETA: 0s - loss: 0.9539 - accuracy: 0.58 - ETA: 0s - loss: 0.9527 - accuracy: 0.58 - ETA: 0s - loss: 0.9515 - accuracy: 0.58 - ETA: 0s - loss: 0.9642 - accuracy: 0.58 - ETA: 0s - loss: 0.9530 - accuracy: 0.59 - ETA: 0s - loss: 0.9355 - accuracy: 0.60 - ETA: 0s - loss: 0.9304 - accuracy: 0.60 - ETA: 0s - loss: 0.9509 - accuracy: 0.59 - ETA: 0s - loss: 0.9523 - accuracy: 0.59 - ETA: 0s - loss: 0.9567 - accuracy: 0.58 - ETA: 0s - loss: 0.9587 - accuracy: 0.58 - ETA: 0s - loss: 0.9618 - accuracy: 0.5860\n",
      "Epoch 00028: val_loss did not improve from 1.01682\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9618 - accuracy: 0.5860 - val_loss: 1.0325 - val_accuracy: 0.4971 - lr: 0.0900\n",
      "Epoch 29/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0152 - accuracy: 0.52 - ETA: 0s - loss: 1.0187 - accuracy: 0.51 - ETA: 0s - loss: 1.0100 - accuracy: 0.52 - ETA: 0s - loss: 0.9796 - accuracy: 0.55 - ETA: 0s - loss: 0.9689 - accuracy: 0.56 - ETA: 0s - loss: 0.9507 - accuracy: 0.58 - ETA: 0s - loss: 0.9488 - accuracy: 0.58 - ETA: 0s - loss: 0.9501 - accuracy: 0.59 - ETA: 0s - loss: 0.9495 - accuracy: 0.59 - ETA: 0s - loss: 0.9630 - accuracy: 0.58 - ETA: 0s - loss: 0.9520 - accuracy: 0.59 - ETA: 0s - loss: 0.9354 - accuracy: 0.60 - ETA: 0s - loss: 0.9159 - accuracy: 0.62 - ETA: 0s - loss: 0.9298 - accuracy: 0.61 - ETA: 0s - loss: 0.9507 - accuracy: 0.59 - ETA: 0s - loss: 0.9550 - accuracy: 0.58 - ETA: 0s - loss: 0.9559 - accuracy: 0.58 - ETA: 0s - loss: 0.9575 - accuracy: 0.5881\n",
      "Epoch 00029: val_loss did not improve from 1.01682\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.07200000286102295.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9575 - accuracy: 0.5881 - val_loss: 1.0373 - val_accuracy: 0.4971 - lr: 0.0900\n",
      "Epoch 30/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0063 - accuracy: 0.51 - ETA: 0s - loss: 1.0087 - accuracy: 0.51 - ETA: 0s - loss: 1.0041 - accuracy: 0.52 - ETA: 0s - loss: 0.9825 - accuracy: 0.54 - ETA: 0s - loss: 0.9734 - accuracy: 0.55 - ETA: 0s - loss: 0.9577 - accuracy: 0.56 - ETA: 0s - loss: 0.9530 - accuracy: 0.57 - ETA: 0s - loss: 0.9544 - accuracy: 0.58 - ETA: 0s - loss: 0.9545 - accuracy: 0.58 - ETA: 0s - loss: 0.9648 - accuracy: 0.57 - ETA: 0s - loss: 0.9545 - accuracy: 0.58 - ETA: 0s - loss: 0.9381 - accuracy: 0.59 - ETA: 0s - loss: 0.9176 - accuracy: 0.61 - ETA: 0s - loss: 0.9325 - accuracy: 0.60 - ETA: 0s - loss: 0.9551 - accuracy: 0.58 - ETA: 0s - loss: 0.9619 - accuracy: 0.58 - ETA: 0s - loss: 0.9616 - accuracy: 0.58 - ETA: 0s - loss: 0.9625 - accuracy: 0.5838\n",
      "Epoch 00030: val_loss did not improve from 1.01682\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9625 - accuracy: 0.5838 - val_loss: 1.0319 - val_accuracy: 0.4971 - lr: 0.0720\n",
      "Epoch 31/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0070 - accuracy: 0.52 - ETA: 0s - loss: 1.0102 - accuracy: 0.52 - ETA: 0s - loss: 1.0058 - accuracy: 0.52 - ETA: 0s - loss: 0.9832 - accuracy: 0.55 - ETA: 0s - loss: 0.9739 - accuracy: 0.55 - ETA: 0s - loss: 0.9601 - accuracy: 0.57 - ETA: 0s - loss: 0.9562 - accuracy: 0.57 - ETA: 0s - loss: 0.9567 - accuracy: 0.57 - ETA: 0s - loss: 0.9542 - accuracy: 0.57 - ETA: 0s - loss: 0.9645 - accuracy: 0.57 - ETA: 0s - loss: 0.9530 - accuracy: 0.58 - ETA: 0s - loss: 0.9361 - accuracy: 0.59 - ETA: 0s - loss: 0.9320 - accuracy: 0.60 - ETA: 0s - loss: 0.9564 - accuracy: 0.58 - ETA: 0s - loss: 0.9583 - accuracy: 0.58 - ETA: 0s - loss: 0.9631 - accuracy: 0.58 - ETA: 0s - loss: 0.9630 - accuracy: 0.58 - ETA: 0s - loss: 0.9643 - accuracy: 0.5821\n",
      "Epoch 00031: val_loss did not improve from 1.01682\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9643 - accuracy: 0.5821 - val_loss: 1.0256 - val_accuracy: 0.4971 - lr: 0.0720\n",
      "Epoch 32/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0082 - accuracy: 0.52 - ETA: 0s - loss: 1.0168 - accuracy: 0.51 - ETA: 0s - loss: 1.0120 - accuracy: 0.52 - ETA: 0s - loss: 0.9938 - accuracy: 0.55 - ETA: 0s - loss: 0.9845 - accuracy: 0.56 - ETA: 0s - loss: 0.9716 - accuracy: 0.58 - ETA: 0s - loss: 0.9677 - accuracy: 0.58 - ETA: 0s - loss: 0.9635 - accuracy: 0.59 - ETA: 0s - loss: 0.9581 - accuracy: 0.59 - ETA: 0s - loss: 0.9665 - accuracy: 0.58 - ETA: 0s - loss: 0.9547 - accuracy: 0.59 - ETA: 0s - loss: 0.9375 - accuracy: 0.60 - ETA: 0s - loss: 0.9159 - accuracy: 0.62 - ETA: 0s - loss: 0.9348 - accuracy: 0.61 - ETA: 0s - loss: 0.9614 - accuracy: 0.59 - ETA: 0s - loss: 0.9632 - accuracy: 0.59 - ETA: 0s - loss: 0.9675 - accuracy: 0.58 - ETA: 0s - loss: 0.9672 - accuracy: 0.5900\n",
      "Epoch 00032: val_loss did not improve from 1.01682\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9683 - accuracy: 0.5889 - val_loss: 1.0288 - val_accuracy: 0.4982 - lr: 0.0720\n",
      "Epoch 33/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0242 - accuracy: 0.52 - ETA: 0s - loss: 1.0278 - accuracy: 0.52 - ETA: 0s - loss: 1.0011 - accuracy: 0.55 - ETA: 0s - loss: 0.9909 - accuracy: 0.56 - ETA: 0s - loss: 0.9719 - accuracy: 0.57 - ETA: 0s - loss: 0.9624 - accuracy: 0.58 - ETA: 0s - loss: 0.9616 - accuracy: 0.58 - ETA: 0s - loss: 0.9611 - accuracy: 0.58 - ETA: 0s - loss: 0.9747 - accuracy: 0.58 - ETA: 0s - loss: 0.9622 - accuracy: 0.59 - ETA: 0s - loss: 0.9439 - accuracy: 0.60 - ETA: 0s - loss: 0.9220 - accuracy: 0.61 - ETA: 0s - loss: 0.9385 - accuracy: 0.60 - ETA: 0s - loss: 0.9617 - accuracy: 0.59 - ETA: 0s - loss: 0.9628 - accuracy: 0.59 - ETA: 0s - loss: 0.9670 - accuracy: 0.58 - ETA: 0s - loss: 0.9679 - accuracy: 0.5874\n",
      "Epoch 00033: val_loss did not improve from 1.01682\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9679 - accuracy: 0.5874 - val_loss: 1.0292 - val_accuracy: 0.4971 - lr: 0.0720\n",
      "Epoch 34/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0166 - accuracy: 0.52 - ETA: 0s - loss: 1.0212 - accuracy: 0.51 - ETA: 0s - loss: 1.0166 - accuracy: 0.52 - ETA: 0s - loss: 0.9963 - accuracy: 0.55 - ETA: 0s - loss: 0.9862 - accuracy: 0.56 - ETA: 0s - loss: 0.9688 - accuracy: 0.58 - ETA: 0s - loss: 0.9608 - accuracy: 0.59 - ETA: 0s - loss: 0.9564 - accuracy: 0.59 - ETA: 0s - loss: 0.9541 - accuracy: 0.59 - ETA: 0s - loss: 0.9662 - accuracy: 0.58 - ETA: 0s - loss: 0.9543 - accuracy: 0.59 - ETA: 0s - loss: 0.9363 - accuracy: 0.60 - ETA: 0s - loss: 0.9152 - accuracy: 0.62 - ETA: 0s - loss: 0.9331 - accuracy: 0.61 - ETA: 0s - loss: 0.9573 - accuracy: 0.59 - ETA: 0s - loss: 0.9628 - accuracy: 0.59 - ETA: 0s - loss: 0.9637 - accuracy: 0.59 - ETA: 0s - loss: 0.9655 - accuracy: 0.5886\n",
      "Epoch 00034: val_loss did not improve from 1.01682\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9655 - accuracy: 0.5886 - val_loss: 1.0269 - val_accuracy: 0.5101 - lr: 0.0720\n",
      "Epoch 35/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0174 - accuracy: 0.52 - ETA: 0s - loss: 1.0296 - accuracy: 0.51 - ETA: 0s - loss: 1.0249 - accuracy: 0.52 - ETA: 0s - loss: 1.0084 - accuracy: 0.55 - ETA: 0s - loss: 0.9991 - accuracy: 0.56 - ETA: 0s - loss: 0.9839 - accuracy: 0.58 - ETA: 0s - loss: 0.9745 - accuracy: 0.58 - ETA: 0s - loss: 0.9687 - accuracy: 0.59 - ETA: 0s - loss: 0.9655 - accuracy: 0.59 - ETA: 0s - loss: 0.9725 - accuracy: 0.58 - ETA: 0s - loss: 0.9606 - accuracy: 0.59 - ETA: 0s - loss: 0.9436 - accuracy: 0.60 - ETA: 0s - loss: 0.9223 - accuracy: 0.62 - ETA: 0s - loss: 0.9397 - accuracy: 0.61 - ETA: 0s - loss: 0.9675 - accuracy: 0.59 - ETA: 0s - loss: 0.9721 - accuracy: 0.58 - ETA: 0s - loss: 0.9720 - accuracy: 0.58 - ETA: 0s - loss: 0.9727 - accuracy: 0.5888\n",
      "Epoch 00035: val_loss did not improve from 1.01682\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9727 - accuracy: 0.5888 - val_loss: 1.0322 - val_accuracy: 0.4971 - lr: 0.0720\n",
      "Epoch 36/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0081 - accuracy: 0.52 - ETA: 0s - loss: 1.0297 - accuracy: 0.51 - ETA: 0s - loss: 1.0266 - accuracy: 0.52 - ETA: 0s - loss: 0.9999 - accuracy: 0.56 - ETA: 0s - loss: 0.9808 - accuracy: 0.58 - ETA: 0s - loss: 0.9692 - accuracy: 0.59 - ETA: 0s - loss: 0.9655 - accuracy: 0.59 - ETA: 0s - loss: 0.9641 - accuracy: 0.59 - ETA: 0s - loss: 0.9755 - accuracy: 0.58 - ETA: 0s - loss: 0.9626 - accuracy: 0.59 - ETA: 0s - loss: 0.9437 - accuracy: 0.60 - ETA: 0s - loss: 0.9207 - accuracy: 0.62 - ETA: 0s - loss: 0.9382 - accuracy: 0.61 - ETA: 0s - loss: 0.9617 - accuracy: 0.59 - ETA: 0s - loss: 0.9629 - accuracy: 0.59 - ETA: 0s - loss: 0.9669 - accuracy: 0.59 - ETA: 0s - loss: 0.9671 - accuracy: 0.59 - ETA: 0s - loss: 0.9684 - accuracy: 0.5895\n",
      "Epoch 00036: val_loss did not improve from 1.01682\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9684 - accuracy: 0.5895 - val_loss: 1.0370 - val_accuracy: 0.5075 - lr: 0.0720\n",
      "Epoch 37/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0177 - accuracy: 0.51 - ETA: 0s - loss: 1.0242 - accuracy: 0.51 - ETA: 0s - loss: 1.0213 - accuracy: 0.52 - ETA: 0s - loss: 1.0020 - accuracy: 0.55 - ETA: 0s - loss: 0.9912 - accuracy: 0.56 - ETA: 0s - loss: 0.9748 - accuracy: 0.57 - ETA: 0s - loss: 0.9669 - accuracy: 0.58 - ETA: 0s - loss: 0.9651 - accuracy: 0.59 - ETA: 0s - loss: 0.9624 - accuracy: 0.59 - ETA: 0s - loss: 0.9733 - accuracy: 0.58 - ETA: 0s - loss: 0.9605 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.60 - ETA: 0s - loss: 0.9209 - accuracy: 0.61 - ETA: 0s - loss: 0.9381 - accuracy: 0.60 - ETA: 0s - loss: 0.9641 - accuracy: 0.59 - ETA: 0s - loss: 0.9687 - accuracy: 0.58 - ETA: 0s - loss: 0.9682 - accuracy: 0.58 - ETA: 0s - loss: 0.9690 - accuracy: 0.5877\n",
      "Epoch 00037: val_loss did not improve from 1.01682\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9690 - accuracy: 0.5877 - val_loss: 1.0325 - val_accuracy: 0.4971 - lr: 0.0720\n",
      "Epoch 38/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0129 - accuracy: 0.52 - ETA: 0s - loss: 1.0253 - accuracy: 0.51 - ETA: 0s - loss: 1.0223 - accuracy: 0.52 - ETA: 0s - loss: 1.0036 - accuracy: 0.55 - ETA: 0s - loss: 0.9945 - accuracy: 0.56 - ETA: 0s - loss: 0.9782 - accuracy: 0.57 - ETA: 0s - loss: 0.9698 - accuracy: 0.58 - ETA: 0s - loss: 0.9668 - accuracy: 0.58 - ETA: 0s - loss: 0.9622 - accuracy: 0.58 - ETA: 0s - loss: 0.9732 - accuracy: 0.58 - ETA: 0s - loss: 0.9613 - accuracy: 0.59 - ETA: 0s - loss: 0.9421 - accuracy: 0.60 - ETA: 0s - loss: 0.9193 - accuracy: 0.61 - ETA: 0s - loss: 0.9389 - accuracy: 0.60 - ETA: 0s - loss: 0.9640 - accuracy: 0.59 - ETA: 0s - loss: 0.9656 - accuracy: 0.59 - ETA: 0s - loss: 0.9691 - accuracy: 0.58 - ETA: 0s - loss: 0.9689 - accuracy: 0.58 - ETA: 0s - loss: 0.9702 - accuracy: 0.5871\n",
      "Epoch 00038: val_loss did not improve from 1.01682\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9702 - accuracy: 0.5871 - val_loss: 1.0298 - val_accuracy: 0.5024 - lr: 0.0720\n",
      "Epoch 39/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0250 - accuracy: 0.52 - ETA: 0s - loss: 1.0263 - accuracy: 0.51 - ETA: 0s - loss: 1.0195 - accuracy: 0.52 - ETA: 0s - loss: 0.9971 - accuracy: 0.55 - ETA: 0s - loss: 0.9852 - accuracy: 0.56 - ETA: 0s - loss: 0.9672 - accuracy: 0.58 - ETA: 0s - loss: 0.9590 - accuracy: 0.59 - ETA: 0s - loss: 0.9559 - accuracy: 0.59 - ETA: 0s - loss: 0.9564 - accuracy: 0.59 - ETA: 0s - loss: 0.9698 - accuracy: 0.58 - ETA: 0s - loss: 0.9576 - accuracy: 0.59 - ETA: 0s - loss: 0.9405 - accuracy: 0.60 - ETA: 0s - loss: 0.9197 - accuracy: 0.62 - ETA: 0s - loss: 0.9592 - accuracy: 0.59 - ETA: 0s - loss: 0.9601 - accuracy: 0.59 - ETA: 0s - loss: 0.9640 - accuracy: 0.59 - ETA: 0s - loss: 0.9638 - accuracy: 0.59 - ETA: 0s - loss: 0.9640 - accuracy: 0.5894\n",
      "Epoch 00039: val_loss did not improve from 1.01682\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9640 - accuracy: 0.5894 - val_loss: 1.0243 - val_accuracy: 0.4971 - lr: 0.0720\n",
      "Epoch 40/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0134 - accuracy: 0.52 - ETA: 0s - loss: 1.0170 - accuracy: 0.52 - ETA: 0s - loss: 1.0111 - accuracy: 0.52 - ETA: 0s - loss: 0.9890 - accuracy: 0.55 - ETA: 0s - loss: 0.9801 - accuracy: 0.56 - ETA: 0s - loss: 0.9660 - accuracy: 0.58 - ETA: 0s - loss: 0.9601 - accuracy: 0.58 - ETA: 0s - loss: 0.9562 - accuracy: 0.59 - ETA: 0s - loss: 0.9600 - accuracy: 0.59 - ETA: 0s - loss: 0.9735 - accuracy: 0.58 - ETA: 0s - loss: 0.9610 - accuracy: 0.59 - ETA: 0s - loss: 0.9430 - accuracy: 0.60 - ETA: 0s - loss: 0.9383 - accuracy: 0.61 - ETA: 0s - loss: 0.9625 - accuracy: 0.59 - ETA: 0s - loss: 0.9638 - accuracy: 0.59 - ETA: 0s - loss: 0.9675 - accuracy: 0.58 - ETA: 0s - loss: 0.9672 - accuracy: 0.58 - ETA: 0s - loss: 0.9680 - accuracy: 0.5884\n",
      "Epoch 00040: val_loss did not improve from 1.01682\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9680 - accuracy: 0.5884 - val_loss: 1.0438 - val_accuracy: 0.5062 - lr: 0.0720\n",
      "Epoch 41/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0026 - accuracy: 0.52 - ETA: 0s - loss: 1.0149 - accuracy: 0.51 - ETA: 0s - loss: 1.0124 - accuracy: 0.52 - ETA: 0s - loss: 0.9994 - accuracy: 0.55 - ETA: 0s - loss: 0.9922 - accuracy: 0.56 - ETA: 0s - loss: 0.9809 - accuracy: 0.58 - ETA: 0s - loss: 0.9761 - accuracy: 0.58 - ETA: 0s - loss: 0.9704 - accuracy: 0.59 - ETA: 0s - loss: 0.9665 - accuracy: 0.59 - ETA: 0s - loss: 0.9735 - accuracy: 0.58 - ETA: 0s - loss: 0.9613 - accuracy: 0.59 - ETA: 0s - loss: 0.9445 - accuracy: 0.60 - ETA: 0s - loss: 0.9233 - accuracy: 0.61 - ETA: 0s - loss: 0.9407 - accuracy: 0.61 - ETA: 0s - loss: 0.9666 - accuracy: 0.59 - ETA: 0s - loss: 0.9686 - accuracy: 0.59 - ETA: 0s - loss: 0.9727 - accuracy: 0.58 - ETA: 0s - loss: 0.9735 - accuracy: 0.5881\n",
      "Epoch 00041: val_loss did not improve from 1.01682\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9735 - accuracy: 0.5881 - val_loss: 1.0254 - val_accuracy: 0.4971 - lr: 0.0720\n",
      "Epoch 42/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0204 - accuracy: 0.52 - ETA: 0s - loss: 1.0261 - accuracy: 0.51 - ETA: 0s - loss: 1.0204 - accuracy: 0.52 - ETA: 0s - loss: 0.9971 - accuracy: 0.55 - ETA: 0s - loss: 0.9862 - accuracy: 0.56 - ETA: 0s - loss: 0.9672 - accuracy: 0.58 - ETA: 0s - loss: 0.9602 - accuracy: 0.58 - ETA: 0s - loss: 0.9602 - accuracy: 0.59 - ETA: 0s - loss: 0.9566 - accuracy: 0.59 - ETA: 0s - loss: 0.9701 - accuracy: 0.58 - ETA: 0s - loss: 0.9582 - accuracy: 0.59 - ETA: 0s - loss: 0.9398 - accuracy: 0.60 - ETA: 0s - loss: 0.9346 - accuracy: 0.60 - ETA: 0s - loss: 0.9573 - accuracy: 0.59 - ETA: 0s - loss: 0.9585 - accuracy: 0.59 - ETA: 0s - loss: 0.9624 - accuracy: 0.58 - ETA: 0s - loss: 0.9624 - accuracy: 0.58 - ETA: 0s - loss: 0.9637 - accuracy: 0.5879\n",
      "Epoch 00042: val_loss did not improve from 1.01682\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9637 - accuracy: 0.5879 - val_loss: 1.0267 - val_accuracy: 0.4971 - lr: 0.0720\n",
      "Epoch 43/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0231 - accuracy: 0.52 - ETA: 0s - loss: 1.0240 - accuracy: 0.52 - ETA: 0s - loss: 1.0048 - accuracy: 0.55 - ETA: 0s - loss: 0.9976 - accuracy: 0.56 - ETA: 0s - loss: 0.9821 - accuracy: 0.58 - ETA: 0s - loss: 0.9739 - accuracy: 0.59 - ETA: 0s - loss: 0.9700 - accuracy: 0.59 - ETA: 0s - loss: 0.9677 - accuracy: 0.59 - ETA: 0s - loss: 0.9756 - accuracy: 0.58 - ETA: 0s - loss: 0.9632 - accuracy: 0.59 - ETA: 0s - loss: 0.9453 - accuracy: 0.60 - ETA: 0s - loss: 0.9229 - accuracy: 0.62 - ETA: 0s - loss: 0.9406 - accuracy: 0.61 - ETA: 0s - loss: 0.9662 - accuracy: 0.59 - ETA: 0s - loss: 0.9678 - accuracy: 0.59 - ETA: 0s - loss: 0.9732 - accuracy: 0.59 - ETA: 0s - loss: 0.9724 - accuracy: 0.59 - ETA: 0s - loss: 0.9728 - accuracy: 0.5894\n",
      "Epoch 00043: val_loss did not improve from 1.01682\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.05760000348091126.\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9728 - accuracy: 0.5894 - val_loss: 1.0257 - val_accuracy: 0.4971 - lr: 0.0720\n",
      "Epoch 44/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9985 - accuracy: 0.52 - ETA: 0s - loss: 1.0142 - accuracy: 0.51 - ETA: 0s - loss: 1.0081 - accuracy: 0.52 - ETA: 0s - loss: 0.9907 - accuracy: 0.55 - ETA: 0s - loss: 0.9824 - accuracy: 0.56 - ETA: 0s - loss: 0.9702 - accuracy: 0.58 - ETA: 0s - loss: 0.9667 - accuracy: 0.59 - ETA: 0s - loss: 0.9625 - accuracy: 0.59 - ETA: 0s - loss: 0.9580 - accuracy: 0.59 - ETA: 0s - loss: 0.9656 - accuracy: 0.58 - ETA: 0s - loss: 0.9550 - accuracy: 0.59 - ETA: 0s - loss: 0.9376 - accuracy: 0.60 - ETA: 0s - loss: 0.9159 - accuracy: 0.62 - ETA: 0s - loss: 0.9346 - accuracy: 0.61 - ETA: 0s - loss: 0.9611 - accuracy: 0.59 - ETA: 0s - loss: 0.9637 - accuracy: 0.59 - ETA: 0s - loss: 0.9697 - accuracy: 0.59 - ETA: 0s - loss: 0.9699 - accuracy: 0.5893\n",
      "Epoch 00044: val_loss did not improve from 1.01682\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9699 - accuracy: 0.5893 - val_loss: 1.0266 - val_accuracy: 0.4971 - lr: 0.0576\n",
      "Epoch 45/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0035 - accuracy: 0.52 - ETA: 0s - loss: 1.0134 - accuracy: 0.51 - ETA: 0s - loss: 1.0076 - accuracy: 0.52 - ETA: 0s - loss: 0.9856 - accuracy: 0.55 - ETA: 0s - loss: 0.9781 - accuracy: 0.56 - ETA: 0s - loss: 0.9688 - accuracy: 0.57 - ETA: 0s - loss: 0.9664 - accuracy: 0.57 - ETA: 0s - loss: 0.9657 - accuracy: 0.58 - ETA: 0s - loss: 0.9613 - accuracy: 0.58 - ETA: 0s - loss: 0.9683 - accuracy: 0.57 - ETA: 0s - loss: 0.9587 - accuracy: 0.58 - ETA: 0s - loss: 0.9424 - accuracy: 0.59 - ETA: 0s - loss: 0.9221 - accuracy: 0.61 - ETA: 0s - loss: 0.9384 - accuracy: 0.60 - ETA: 0s - loss: 0.9647 - accuracy: 0.58 - ETA: 0s - loss: 0.9707 - accuracy: 0.58 - ETA: 0s - loss: 0.9703 - accuracy: 0.58 - ETA: 0s - loss: 0.9713 - accuracy: 0.5834\n",
      "Epoch 00045: val_loss did not improve from 1.01682\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9713 - accuracy: 0.5834 - val_loss: 1.0458 - val_accuracy: 0.4971 - lr: 0.0576\n",
      "Epoch 46/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0138 - accuracy: 0.52 - ETA: 0s - loss: 1.0273 - accuracy: 0.51 - ETA: 0s - loss: 1.0173 - accuracy: 0.52 - ETA: 0s - loss: 0.9955 - accuracy: 0.55 - ETA: 0s - loss: 0.9870 - accuracy: 0.56 - ETA: 0s - loss: 0.9732 - accuracy: 0.58 - ETA: 0s - loss: 0.9673 - accuracy: 0.59 - ETA: 0s - loss: 0.9641 - accuracy: 0.59 - ETA: 0s - loss: 0.9593 - accuracy: 0.59 - ETA: 0s - loss: 0.9660 - accuracy: 0.58 - ETA: 0s - loss: 0.9555 - accuracy: 0.59 - ETA: 0s - loss: 0.9382 - accuracy: 0.60 - ETA: 0s - loss: 0.9164 - accuracy: 0.62 - ETA: 0s - loss: 0.9344 - accuracy: 0.61 - ETA: 0s - loss: 0.9604 - accuracy: 0.59 - ETA: 0s - loss: 0.9691 - accuracy: 0.59 - ETA: 0s - loss: 0.9685 - accuracy: 0.59 - ETA: 0s - loss: 0.9687 - accuracy: 0.5896\n",
      "Epoch 00046: val_loss improved from 1.01682 to 1.01404, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 1s 74ms/step - loss: 0.9687 - accuracy: 0.5896 - val_loss: 1.0140 - val_accuracy: 0.4982 - lr: 0.0576\n",
      "Epoch 47/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0109 - accuracy: 0.52 - ETA: 0s - loss: 1.0115 - accuracy: 0.51 - ETA: 0s - loss: 1.0072 - accuracy: 0.52 - ETA: 0s - loss: 0.9865 - accuracy: 0.55 - ETA: 0s - loss: 0.9817 - accuracy: 0.56 - ETA: 0s - loss: 0.9686 - accuracy: 0.58 - ETA: 0s - loss: 0.9651 - accuracy: 0.58 - ETA: 0s - loss: 0.9640 - accuracy: 0.59 - ETA: 0s - loss: 0.9588 - accuracy: 0.59 - ETA: 0s - loss: 0.9645 - accuracy: 0.58 - ETA: 0s - loss: 0.9548 - accuracy: 0.59 - ETA: 0s - loss: 0.9392 - accuracy: 0.60 - ETA: 0s - loss: 0.9199 - accuracy: 0.61 - ETA: 0s - loss: 0.9343 - accuracy: 0.60 - ETA: 0s - loss: 0.9573 - accuracy: 0.59 - ETA: 0s - loss: 0.9597 - accuracy: 0.59 - ETA: 0s - loss: 0.9660 - accuracy: 0.58 - ETA: 0s - loss: 0.9670 - accuracy: 0.5878\n",
      "Epoch 00047: val_loss did not improve from 1.01404\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9670 - accuracy: 0.5878 - val_loss: 1.0573 - val_accuracy: 0.4971 - lr: 0.0576\n",
      "Epoch 48/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0126 - accuracy: 0.52 - ETA: 0s - loss: 1.0232 - accuracy: 0.51 - ETA: 0s - loss: 1.0106 - accuracy: 0.52 - ETA: 0s - loss: 0.9848 - accuracy: 0.55 - ETA: 0s - loss: 0.9742 - accuracy: 0.56 - ETA: 0s - loss: 0.9614 - accuracy: 0.58 - ETA: 0s - loss: 0.9564 - accuracy: 0.59 - ETA: 0s - loss: 0.9572 - accuracy: 0.59 - ETA: 0s - loss: 0.9548 - accuracy: 0.59 - ETA: 0s - loss: 0.9619 - accuracy: 0.58 - ETA: 0s - loss: 0.9518 - accuracy: 0.59 - ETA: 0s - loss: 0.9357 - accuracy: 0.60 - ETA: 0s - loss: 0.9311 - accuracy: 0.61 - ETA: 0s - loss: 0.9550 - accuracy: 0.59 - ETA: 0s - loss: 0.9575 - accuracy: 0.59 - ETA: 0s - loss: 0.9635 - accuracy: 0.59 - ETA: 0s - loss: 0.9634 - accuracy: 0.59 - ETA: 0s - loss: 0.9642 - accuracy: 0.5894\n",
      "Epoch 00048: val_loss did not improve from 1.01404\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9642 - accuracy: 0.5894 - val_loss: 1.0362 - val_accuracy: 0.4971 - lr: 0.0576\n",
      "Epoch 49/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0069 - accuracy: 0.52 - ETA: 0s - loss: 1.0147 - accuracy: 0.51 - ETA: 0s - loss: 1.0069 - accuracy: 0.52 - ETA: 0s - loss: 0.9824 - accuracy: 0.55 - ETA: 0s - loss: 0.9746 - accuracy: 0.56 - ETA: 0s - loss: 0.9625 - accuracy: 0.58 - ETA: 0s - loss: 0.9580 - accuracy: 0.59 - ETA: 0s - loss: 0.9577 - accuracy: 0.59 - ETA: 0s - loss: 0.9548 - accuracy: 0.59 - ETA: 0s - loss: 0.9612 - accuracy: 0.58 - ETA: 0s - loss: 0.9530 - accuracy: 0.59 - ETA: 0s - loss: 0.9392 - accuracy: 0.60 - ETA: 0s - loss: 0.9348 - accuracy: 0.61 - ETA: 0s - loss: 0.9556 - accuracy: 0.59 - ETA: 0s - loss: 0.9574 - accuracy: 0.59 - ETA: 0s - loss: 0.9636 - accuracy: 0.59 - ETA: 0s - loss: 0.9635 - accuracy: 0.59 - ETA: 0s - loss: 0.9647 - accuracy: 0.5891\n",
      "Epoch 00049: val_loss did not improve from 1.01404\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9647 - accuracy: 0.5891 - val_loss: 1.0589 - val_accuracy: 0.4971 - lr: 0.0576\n",
      "Epoch 50/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0172 - accuracy: 0.52 - ETA: 0s - loss: 1.0307 - accuracy: 0.51 - ETA: 0s - loss: 1.0183 - accuracy: 0.52 - ETA: 0s - loss: 0.9885 - accuracy: 0.55 - ETA: 0s - loss: 0.9775 - accuracy: 0.56 - ETA: 0s - loss: 0.9612 - accuracy: 0.58 - ETA: 0s - loss: 0.9549 - accuracy: 0.59 - ETA: 0s - loss: 0.9525 - accuracy: 0.59 - ETA: 0s - loss: 0.9497 - accuracy: 0.59 - ETA: 0s - loss: 0.9562 - accuracy: 0.58 - ETA: 0s - loss: 0.9476 - accuracy: 0.59 - ETA: 0s - loss: 0.9325 - accuracy: 0.60 - ETA: 0s - loss: 0.9138 - accuracy: 0.62 - ETA: 0s - loss: 0.9507 - accuracy: 0.59 - ETA: 0s - loss: 0.9527 - accuracy: 0.59 - ETA: 0s - loss: 0.9588 - accuracy: 0.59 - ETA: 0s - loss: 0.9588 - accuracy: 0.59 - ETA: 0s - loss: 0.9594 - accuracy: 0.5898\n",
      "Epoch 00050: val_loss did not improve from 1.01404\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9594 - accuracy: 0.5898 - val_loss: 1.0525 - val_accuracy: 0.4971 - lr: 0.0576\n",
      "Epoch 51/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0051 - accuracy: 0.53 - ETA: 0s - loss: 1.0094 - accuracy: 0.52 - ETA: 0s - loss: 1.0014 - accuracy: 0.53 - ETA: 0s - loss: 0.9765 - accuracy: 0.56 - ETA: 0s - loss: 0.9691 - accuracy: 0.57 - ETA: 0s - loss: 0.9566 - accuracy: 0.58 - ETA: 0s - loss: 0.9533 - accuracy: 0.59 - ETA: 0s - loss: 0.9528 - accuracy: 0.59 - ETA: 0s - loss: 0.9504 - accuracy: 0.59 - ETA: 0s - loss: 0.9563 - accuracy: 0.58 - ETA: 0s - loss: 0.9485 - accuracy: 0.59 - ETA: 0s - loss: 0.9352 - accuracy: 0.60 - ETA: 0s - loss: 0.9181 - accuracy: 0.62 - ETA: 0s - loss: 0.9314 - accuracy: 0.61 - ETA: 0s - loss: 0.9525 - accuracy: 0.59 - ETA: 0s - loss: 0.9582 - accuracy: 0.59 - ETA: 0s - loss: 0.9581 - accuracy: 0.59 - ETA: 0s - loss: 0.9589 - accuracy: 0.5898\n",
      "Epoch 00051: val_loss did not improve from 1.01404\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9589 - accuracy: 0.5898 - val_loss: 1.0316 - val_accuracy: 0.4971 - lr: 0.0576\n",
      "Epoch 52/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0125 - accuracy: 0.52 - ETA: 0s - loss: 1.0220 - accuracy: 0.51 - ETA: 0s - loss: 1.0109 - accuracy: 0.52 - ETA: 0s - loss: 0.9810 - accuracy: 0.55 - ETA: 0s - loss: 0.9687 - accuracy: 0.56 - ETA: 0s - loss: 0.9528 - accuracy: 0.58 - ETA: 0s - loss: 0.9485 - accuracy: 0.59 - ETA: 0s - loss: 0.9461 - accuracy: 0.59 - ETA: 0s - loss: 0.9440 - accuracy: 0.59 - ETA: 0s - loss: 0.9504 - accuracy: 0.58 - ETA: 0s - loss: 0.9435 - accuracy: 0.59 - ETA: 0s - loss: 0.9300 - accuracy: 0.60 - ETA: 0s - loss: 0.9141 - accuracy: 0.62 - ETA: 0s - loss: 0.9453 - accuracy: 0.59 - ETA: 0s - loss: 0.9467 - accuracy: 0.59 - ETA: 0s - loss: 0.9516 - accuracy: 0.59 - ETA: 0s - loss: 0.9521 - accuracy: 0.59 - ETA: 0s - loss: 0.9528 - accuracy: 0.5895\n",
      "Epoch 00052: val_loss improved from 1.01404 to 1.01161, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 1s 74ms/step - loss: 0.9528 - accuracy: 0.5895 - val_loss: 1.0116 - val_accuracy: 0.4971 - lr: 0.0576\n",
      "Epoch 53/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0078 - accuracy: 0.52 - ETA: 0s - loss: 1.0119 - accuracy: 0.51 - ETA: 0s - loss: 0.9731 - accuracy: 0.55 - ETA: 0s - loss: 0.9635 - accuracy: 0.56 - ETA: 0s - loss: 0.9491 - accuracy: 0.58 - ETA: 0s - loss: 0.9458 - accuracy: 0.59 - ETA: 0s - loss: 0.9447 - accuracy: 0.59 - ETA: 0s - loss: 0.9421 - accuracy: 0.59 - ETA: 0s - loss: 0.9489 - accuracy: 0.58 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9273 - accuracy: 0.60 - ETA: 0s - loss: 0.9098 - accuracy: 0.62 - ETA: 0s - loss: 0.9239 - accuracy: 0.61 - ETA: 0s - loss: 0.9444 - accuracy: 0.59 - ETA: 0s - loss: 0.9463 - accuracy: 0.59 - ETA: 0s - loss: 0.9520 - accuracy: 0.59 - ETA: 0s - loss: 0.9524 - accuracy: 0.59 - ETA: 0s - loss: 0.9533 - accuracy: 0.5897\n",
      "Epoch 00053: val_loss did not improve from 1.01161\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9533 - accuracy: 0.5897 - val_loss: 1.0208 - val_accuracy: 0.4971 - lr: 0.0576\n",
      "Epoch 54/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0104 - accuracy: 0.52 - ETA: 0s - loss: 1.0156 - accuracy: 0.51 - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 0.9764 - accuracy: 0.55 - ETA: 0s - loss: 0.9662 - accuracy: 0.56 - ETA: 0s - loss: 0.9520 - accuracy: 0.58 - ETA: 0s - loss: 0.9472 - accuracy: 0.59 - ETA: 0s - loss: 0.9457 - accuracy: 0.59 - ETA: 0s - loss: 0.9433 - accuracy: 0.59 - ETA: 0s - loss: 0.9498 - accuracy: 0.58 - ETA: 0s - loss: 0.9428 - accuracy: 0.59 - ETA: 0s - loss: 0.9300 - accuracy: 0.60 - ETA: 0s - loss: 0.9261 - accuracy: 0.61 - ETA: 0s - loss: 0.9452 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.59 - ETA: 0s - loss: 0.9524 - accuracy: 0.59 - ETA: 0s - loss: 0.9529 - accuracy: 0.59 - ETA: 0s - loss: 0.9536 - accuracy: 0.5895\n",
      "Epoch 00054: val_loss did not improve from 1.01161\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9536 - accuracy: 0.5895 - val_loss: 1.0315 - val_accuracy: 0.4971 - lr: 0.0576\n",
      "Epoch 55/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0081 - accuracy: 0.52 - ETA: 0s - loss: 1.0152 - accuracy: 0.51 - ETA: 0s - loss: 1.0051 - accuracy: 0.52 - ETA: 0s - loss: 0.9751 - accuracy: 0.55 - ETA: 0s - loss: 0.9644 - accuracy: 0.56 - ETA: 0s - loss: 0.9488 - accuracy: 0.58 - ETA: 0s - loss: 0.9432 - accuracy: 0.59 - ETA: 0s - loss: 0.9422 - accuracy: 0.59 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9472 - accuracy: 0.58 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9263 - accuracy: 0.60 - ETA: 0s - loss: 0.9092 - accuracy: 0.62 - ETA: 0s - loss: 0.9223 - accuracy: 0.61 - ETA: 0s - loss: 0.9420 - accuracy: 0.59 - ETA: 0s - loss: 0.9492 - accuracy: 0.59 - ETA: 0s - loss: 0.9499 - accuracy: 0.59 - ETA: 0s - loss: 0.9508 - accuracy: 0.5895\n",
      "Epoch 00055: val_loss did not improve from 1.01161\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9508 - accuracy: 0.5895 - val_loss: 1.0194 - val_accuracy: 0.4971 - lr: 0.0576\n",
      "Epoch 56/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0055 - accuracy: 0.52 - ETA: 0s - loss: 1.0121 - accuracy: 0.51 - ETA: 0s - loss: 0.9728 - accuracy: 0.55 - ETA: 0s - loss: 0.9628 - accuracy: 0.56 - ETA: 0s - loss: 0.9484 - accuracy: 0.58 - ETA: 0s - loss: 0.9447 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.59 - ETA: 0s - loss: 0.9486 - accuracy: 0.58 - ETA: 0s - loss: 0.9410 - accuracy: 0.59 - ETA: 0s - loss: 0.9277 - accuracy: 0.60 - ETA: 0s - loss: 0.9105 - accuracy: 0.62 - ETA: 0s - loss: 0.9236 - accuracy: 0.61 - ETA: 0s - loss: 0.9430 - accuracy: 0.59 - ETA: 0s - loss: 0.9448 - accuracy: 0.59 - ETA: 0s - loss: 0.9504 - accuracy: 0.59 - ETA: 0s - loss: 0.9508 - accuracy: 0.59 - ETA: 0s - loss: 0.9518 - accuracy: 0.5895\n",
      "Epoch 00056: val_loss did not improve from 1.01161\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9518 - accuracy: 0.5895 - val_loss: 1.0289 - val_accuracy: 0.4971 - lr: 0.0576\n",
      "Epoch 57/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0067 - accuracy: 0.52 - ETA: 0s - loss: 1.0151 - accuracy: 0.51 - ETA: 0s - loss: 1.0050 - accuracy: 0.52 - ETA: 0s - loss: 0.9752 - accuracy: 0.55 - ETA: 0s - loss: 0.9643 - accuracy: 0.56 - ETA: 0s - loss: 0.9492 - accuracy: 0.58 - ETA: 0s - loss: 0.9447 - accuracy: 0.59 - ETA: 0s - loss: 0.9434 - accuracy: 0.59 - ETA: 0s - loss: 0.9407 - accuracy: 0.59 - ETA: 0s - loss: 0.9478 - accuracy: 0.58 - ETA: 0s - loss: 0.9400 - accuracy: 0.59 - ETA: 0s - loss: 0.9272 - accuracy: 0.60 - ETA: 0s - loss: 0.9103 - accuracy: 0.62 - ETA: 0s - loss: 0.9233 - accuracy: 0.61 - ETA: 0s - loss: 0.9427 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.59 - ETA: 0s - loss: 0.9506 - accuracy: 0.59 - ETA: 0s - loss: 0.9513 - accuracy: 0.5895\n",
      "Epoch 00057: val_loss did not improve from 1.01161\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9513 - accuracy: 0.5895 - val_loss: 1.0193 - val_accuracy: 0.4971 - lr: 0.0576\n",
      "Epoch 58/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0073 - accuracy: 0.52 - ETA: 0s - loss: 1.0132 - accuracy: 0.51 - ETA: 0s - loss: 1.0029 - accuracy: 0.52 - ETA: 0s - loss: 0.9732 - accuracy: 0.55 - ETA: 0s - loss: 0.9622 - accuracy: 0.56 - ETA: 0s - loss: 0.9431 - accuracy: 0.59 - ETA: 0s - loss: 0.9418 - accuracy: 0.59 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9392 - accuracy: 0.59 - ETA: 0s - loss: 0.9261 - accuracy: 0.60 - ETA: 0s - loss: 0.9092 - accuracy: 0.62 - ETA: 0s - loss: 0.9226 - accuracy: 0.61 - ETA: 0s - loss: 0.9421 - accuracy: 0.59 - ETA: 0s - loss: 0.9440 - accuracy: 0.59 - ETA: 0s - loss: 0.9498 - accuracy: 0.59 - ETA: 0s - loss: 0.9502 - accuracy: 0.59 - ETA: 0s - loss: 0.9510 - accuracy: 0.5895\n",
      "Epoch 00058: val_loss did not improve from 1.01161\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9510 - accuracy: 0.5895 - val_loss: 1.0142 - val_accuracy: 0.4971 - lr: 0.0576\n",
      "Epoch 59/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0092 - accuracy: 0.52 - ETA: 0s - loss: 1.0135 - accuracy: 0.51 - ETA: 0s - loss: 1.0031 - accuracy: 0.52 - ETA: 0s - loss: 0.9730 - accuracy: 0.55 - ETA: 0s - loss: 0.9623 - accuracy: 0.56 - ETA: 0s - loss: 0.9475 - accuracy: 0.58 - ETA: 0s - loss: 0.9443 - accuracy: 0.59 - ETA: 0s - loss: 0.9430 - accuracy: 0.59 - ETA: 0s - loss: 0.9401 - accuracy: 0.59 - ETA: 0s - loss: 0.9473 - accuracy: 0.58 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9264 - accuracy: 0.60 - ETA: 0s - loss: 0.9096 - accuracy: 0.62 - ETA: 0s - loss: 0.9225 - accuracy: 0.61 - ETA: 0s - loss: 0.9441 - accuracy: 0.59 - ETA: 0s - loss: 0.9498 - accuracy: 0.59 - ETA: 0s - loss: 0.9502 - accuracy: 0.59 - ETA: 0s - loss: 0.9512 - accuracy: 0.5894\n",
      "Epoch 00059: val_loss did not improve from 1.01161\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9512 - accuracy: 0.5894 - val_loss: 1.0255 - val_accuracy: 0.4971 - lr: 0.0576\n",
      "Epoch 60/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0062 - accuracy: 0.52 - ETA: 0s - loss: 1.0131 - accuracy: 0.51 - ETA: 0s - loss: 1.0034 - accuracy: 0.52 - ETA: 0s - loss: 0.9738 - accuracy: 0.55 - ETA: 0s - loss: 0.9629 - accuracy: 0.56 - ETA: 0s - loss: 0.9482 - accuracy: 0.58 - ETA: 0s - loss: 0.9439 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.59 - ETA: 0s - loss: 0.9400 - accuracy: 0.59 - ETA: 0s - loss: 0.9471 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9260 - accuracy: 0.60 - ETA: 0s - loss: 0.9091 - accuracy: 0.62 - ETA: 0s - loss: 0.9225 - accuracy: 0.61 - ETA: 0s - loss: 0.9419 - accuracy: 0.59 - ETA: 0s - loss: 0.9438 - accuracy: 0.59 - ETA: 0s - loss: 0.9495 - accuracy: 0.59 - ETA: 0s - loss: 0.9510 - accuracy: 0.5895\n",
      "Epoch 00060: val_loss did not improve from 1.01161\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9510 - accuracy: 0.5895 - val_loss: 1.0396 - val_accuracy: 0.4971 - lr: 0.0576\n",
      "Epoch 61/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0074 - accuracy: 0.52 - ETA: 0s - loss: 1.0141 - accuracy: 0.51 - ETA: 0s - loss: 1.0050 - accuracy: 0.52 - ETA: 0s - loss: 0.9755 - accuracy: 0.55 - ETA: 0s - loss: 0.9649 - accuracy: 0.56 - ETA: 0s - loss: 0.9500 - accuracy: 0.58 - ETA: 0s - loss: 0.9446 - accuracy: 0.59 - ETA: 0s - loss: 0.9433 - accuracy: 0.59 - ETA: 0s - loss: 0.9408 - accuracy: 0.59 - ETA: 0s - loss: 0.9481 - accuracy: 0.58 - ETA: 0s - loss: 0.9400 - accuracy: 0.59 - ETA: 0s - loss: 0.9268 - accuracy: 0.60 - ETA: 0s - loss: 0.9096 - accuracy: 0.62 - ETA: 0s - loss: 0.9227 - accuracy: 0.61 - ETA: 0s - loss: 0.9423 - accuracy: 0.59 - ETA: 0s - loss: 0.9442 - accuracy: 0.59 - ETA: 0s - loss: 0.9500 - accuracy: 0.59 - ETA: 0s - loss: 0.9514 - accuracy: 0.5895\n",
      "Epoch 00061: val_loss did not improve from 1.01161\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9514 - accuracy: 0.5895 - val_loss: 1.0141 - val_accuracy: 0.4971 - lr: 0.0576\n",
      "Epoch 62/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0087 - accuracy: 0.52 - ETA: 0s - loss: 1.0125 - accuracy: 0.51 - ETA: 0s - loss: 1.0021 - accuracy: 0.52 - ETA: 0s - loss: 0.9708 - accuracy: 0.55 - ETA: 0s - loss: 0.9607 - accuracy: 0.56 - ETA: 0s - loss: 0.9470 - accuracy: 0.58 - ETA: 0s - loss: 0.9437 - accuracy: 0.59 - ETA: 0s - loss: 0.9424 - accuracy: 0.59 - ETA: 0s - loss: 0.9399 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.58 - ETA: 0s - loss: 0.9397 - accuracy: 0.59 - ETA: 0s - loss: 0.9271 - accuracy: 0.60 - ETA: 0s - loss: 0.9102 - accuracy: 0.62 - ETA: 0s - loss: 0.9230 - accuracy: 0.61 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9442 - accuracy: 0.59 - ETA: 0s - loss: 0.9499 - accuracy: 0.59 - ETA: 0s - loss: 0.9503 - accuracy: 0.59 - ETA: 0s - loss: 0.9515 - accuracy: 0.5895\n",
      "Epoch 00062: val_loss did not improve from 1.01161\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.04608000218868256.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9515 - accuracy: 0.5895 - val_loss: 1.0189 - val_accuracy: 0.4971 - lr: 0.0576\n",
      "Epoch 63/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0088 - accuracy: 0.52 - ETA: 0s - loss: 1.0166 - accuracy: 0.51 - ETA: 0s - loss: 1.0059 - accuracy: 0.52 - ETA: 0s - loss: 0.9750 - accuracy: 0.55 - ETA: 0s - loss: 0.9644 - accuracy: 0.56 - ETA: 0s - loss: 0.9493 - accuracy: 0.58 - ETA: 0s - loss: 0.9450 - accuracy: 0.59 - ETA: 0s - loss: 0.9428 - accuracy: 0.59 - ETA: 0s - loss: 0.9406 - accuracy: 0.59 - ETA: 0s - loss: 0.9475 - accuracy: 0.58 - ETA: 0s - loss: 0.9405 - accuracy: 0.59 - ETA: 0s - loss: 0.9274 - accuracy: 0.60 - ETA: 0s - loss: 0.9106 - accuracy: 0.62 - ETA: 0s - loss: 0.9231 - accuracy: 0.61 - ETA: 0s - loss: 0.9411 - accuracy: 0.59 - ETA: 0s - loss: 0.9428 - accuracy: 0.59 - ETA: 0s - loss: 0.9481 - accuracy: 0.59 - ETA: 0s - loss: 0.9493 - accuracy: 0.5895\n",
      "Epoch 00063: val_loss did not improve from 1.01161\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9493 - accuracy: 0.5895 - val_loss: 1.0165 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 64/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0055 - accuracy: 0.52 - ETA: 0s - loss: 1.0113 - accuracy: 0.51 - ETA: 0s - loss: 1.0009 - accuracy: 0.52 - ETA: 0s - loss: 0.9710 - accuracy: 0.55 - ETA: 0s - loss: 0.9603 - accuracy: 0.56 - ETA: 0s - loss: 0.9449 - accuracy: 0.58 - ETA: 0s - loss: 0.9401 - accuracy: 0.59 - ETA: 0s - loss: 0.9397 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9459 - accuracy: 0.58 - ETA: 0s - loss: 0.9390 - accuracy: 0.59 - ETA: 0s - loss: 0.9259 - accuracy: 0.60 - ETA: 0s - loss: 0.9088 - accuracy: 0.62 - ETA: 0s - loss: 0.9219 - accuracy: 0.61 - ETA: 0s - loss: 0.9429 - accuracy: 0.59 - ETA: 0s - loss: 0.9484 - accuracy: 0.59 - ETA: 0s - loss: 0.9489 - accuracy: 0.59 - ETA: 0s - loss: 0.9501 - accuracy: 0.5892\n",
      "Epoch 00064: val_loss did not improve from 1.01161\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9501 - accuracy: 0.5892 - val_loss: 1.0277 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 65/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0092 - accuracy: 0.52 - ETA: 0s - loss: 1.0150 - accuracy: 0.51 - ETA: 0s - loss: 1.0049 - accuracy: 0.52 - ETA: 0s - loss: 0.9751 - accuracy: 0.55 - ETA: 0s - loss: 0.9648 - accuracy: 0.56 - ETA: 0s - loss: 0.9494 - accuracy: 0.58 - ETA: 0s - loss: 0.9437 - accuracy: 0.59 - ETA: 0s - loss: 0.9422 - accuracy: 0.59 - ETA: 0s - loss: 0.9400 - accuracy: 0.59 - ETA: 0s - loss: 0.9473 - accuracy: 0.58 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9101 - accuracy: 0.62 - ETA: 0s - loss: 0.9228 - accuracy: 0.61 - ETA: 0s - loss: 0.9414 - accuracy: 0.59 - ETA: 0s - loss: 0.9434 - accuracy: 0.59 - ETA: 0s - loss: 0.9488 - accuracy: 0.59 - ETA: 0s - loss: 0.9493 - accuracy: 0.59 - ETA: 0s - loss: 0.9504 - accuracy: 0.5894\n",
      "Epoch 00065: val_loss did not improve from 1.01161\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9504 - accuracy: 0.5894 - val_loss: 1.0137 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 66/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0041 - accuracy: 0.52 - ETA: 0s - loss: 1.0086 - accuracy: 0.51 - ETA: 0s - loss: 0.9993 - accuracy: 0.52 - ETA: 0s - loss: 0.9685 - accuracy: 0.55 - ETA: 0s - loss: 0.9582 - accuracy: 0.56 - ETA: 0s - loss: 0.9433 - accuracy: 0.58 - ETA: 0s - loss: 0.9386 - accuracy: 0.59 - ETA: 0s - loss: 0.9385 - accuracy: 0.59 - ETA: 0s - loss: 0.9360 - accuracy: 0.59 - ETA: 0s - loss: 0.9439 - accuracy: 0.58 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9236 - accuracy: 0.60 - ETA: 0s - loss: 0.9065 - accuracy: 0.62 - ETA: 0s - loss: 0.9197 - accuracy: 0.61 - ETA: 0s - loss: 0.9406 - accuracy: 0.59 - ETA: 0s - loss: 0.9462 - accuracy: 0.59 - ETA: 0s - loss: 0.9467 - accuracy: 0.59 - ETA: 0s - loss: 0.9478 - accuracy: 0.5897\n",
      "Epoch 00066: val_loss improved from 1.01161 to 1.00676, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 1s 74ms/step - loss: 0.9478 - accuracy: 0.5897 - val_loss: 1.0068 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 67/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0051 - accuracy: 0.52 - ETA: 0s - loss: 1.0072 - accuracy: 0.51 - ETA: 0s - loss: 0.9984 - accuracy: 0.52 - ETA: 0s - loss: 0.9685 - accuracy: 0.55 - ETA: 0s - loss: 0.9583 - accuracy: 0.56 - ETA: 0s - loss: 0.9443 - accuracy: 0.58 - ETA: 0s - loss: 0.9409 - accuracy: 0.59 - ETA: 0s - loss: 0.9397 - accuracy: 0.59 - ETA: 0s - loss: 0.9371 - accuracy: 0.59 - ETA: 0s - loss: 0.9442 - accuracy: 0.58 - ETA: 0s - loss: 0.9372 - accuracy: 0.59 - ETA: 0s - loss: 0.9246 - accuracy: 0.60 - ETA: 0s - loss: 0.9076 - accuracy: 0.62 - ETA: 0s - loss: 0.9206 - accuracy: 0.61 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.59 - ETA: 0s - loss: 0.9474 - accuracy: 0.59 - ETA: 0s - loss: 0.9486 - accuracy: 0.5894\n",
      "Epoch 00067: val_loss did not improve from 1.00676\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9486 - accuracy: 0.5894 - val_loss: 1.0096 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 68/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0042 - accuracy: 0.52 - ETA: 0s - loss: 1.0093 - accuracy: 0.51 - ETA: 0s - loss: 1.0000 - accuracy: 0.52 - ETA: 0s - loss: 0.9702 - accuracy: 0.55 - ETA: 0s - loss: 0.9598 - accuracy: 0.56 - ETA: 0s - loss: 0.9451 - accuracy: 0.58 - ETA: 0s - loss: 0.9406 - accuracy: 0.59 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9445 - accuracy: 0.58 - ETA: 0s - loss: 0.9370 - accuracy: 0.59 - ETA: 0s - loss: 0.9242 - accuracy: 0.60 - ETA: 0s - loss: 0.9073 - accuracy: 0.62 - ETA: 0s - loss: 0.9201 - accuracy: 0.61 - ETA: 0s - loss: 0.9391 - accuracy: 0.59 - ETA: 0s - loss: 0.9464 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.59 - ETA: 0s - loss: 0.9479 - accuracy: 0.5895\n",
      "Epoch 00068: val_loss improved from 1.00676 to 1.00657, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 1s 74ms/step - loss: 0.9479 - accuracy: 0.5895 - val_loss: 1.0066 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 69/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0038 - accuracy: 0.52 - ETA: 0s - loss: 1.0077 - accuracy: 0.51 - ETA: 0s - loss: 0.9987 - accuracy: 0.52 - ETA: 0s - loss: 0.9689 - accuracy: 0.55 - ETA: 0s - loss: 0.9579 - accuracy: 0.56 - ETA: 0s - loss: 0.9438 - accuracy: 0.58 - ETA: 0s - loss: 0.9397 - accuracy: 0.59 - ETA: 0s - loss: 0.9385 - accuracy: 0.59 - ETA: 0s - loss: 0.9363 - accuracy: 0.59 - ETA: 0s - loss: 0.9439 - accuracy: 0.58 - ETA: 0s - loss: 0.9363 - accuracy: 0.59 - ETA: 0s - loss: 0.9234 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.62 - ETA: 0s - loss: 0.9194 - accuracy: 0.61 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9405 - accuracy: 0.59 - ETA: 0s - loss: 0.9461 - accuracy: 0.59 - ETA: 0s - loss: 0.9466 - accuracy: 0.59 - ETA: 0s - loss: 0.9478 - accuracy: 0.5894\n",
      "Epoch 00069: val_loss did not improve from 1.00657\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9478 - accuracy: 0.5894 - val_loss: 1.0105 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 70/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0047 - accuracy: 0.52 - ETA: 0s - loss: 1.0087 - accuracy: 0.51 - ETA: 0s - loss: 0.9984 - accuracy: 0.52 - ETA: 0s - loss: 0.9684 - accuracy: 0.55 - ETA: 0s - loss: 0.9580 - accuracy: 0.56 - ETA: 0s - loss: 0.9437 - accuracy: 0.58 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9385 - accuracy: 0.59 - ETA: 0s - loss: 0.9362 - accuracy: 0.59 - ETA: 0s - loss: 0.9442 - accuracy: 0.58 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9238 - accuracy: 0.60 - ETA: 0s - loss: 0.9069 - accuracy: 0.62 - ETA: 0s - loss: 0.9200 - accuracy: 0.61 - ETA: 0s - loss: 0.9391 - accuracy: 0.59 - ETA: 0s - loss: 0.9407 - accuracy: 0.59 - ETA: 0s - loss: 0.9462 - accuracy: 0.59 - ETA: 0s - loss: 0.9464 - accuracy: 0.5907\n",
      "Epoch 00070: val_loss did not improve from 1.00657\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9474 - accuracy: 0.5895 - val_loss: 1.0102 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 71/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0039 - accuracy: 0.52 - ETA: 0s - loss: 1.0078 - accuracy: 0.51 - ETA: 0s - loss: 0.9986 - accuracy: 0.52 - ETA: 0s - loss: 0.9679 - accuracy: 0.55 - ETA: 0s - loss: 0.9576 - accuracy: 0.56 - ETA: 0s - loss: 0.9429 - accuracy: 0.58 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9353 - accuracy: 0.59 - ETA: 0s - loss: 0.9432 - accuracy: 0.58 - ETA: 0s - loss: 0.9355 - accuracy: 0.59 - ETA: 0s - loss: 0.9230 - accuracy: 0.60 - ETA: 0s - loss: 0.9061 - accuracy: 0.62 - ETA: 0s - loss: 0.9189 - accuracy: 0.61 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9398 - accuracy: 0.59 - ETA: 0s - loss: 0.9456 - accuracy: 0.59 - ETA: 0s - loss: 0.9461 - accuracy: 0.59 - ETA: 0s - loss: 0.9476 - accuracy: 0.5896\n",
      "Epoch 00071: val_loss did not improve from 1.00657\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9476 - accuracy: 0.5896 - val_loss: 1.0124 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 72/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0071 - accuracy: 0.52 - ETA: 0s - loss: 1.0114 - accuracy: 0.51 - ETA: 0s - loss: 1.0010 - accuracy: 0.52 - ETA: 0s - loss: 0.9711 - accuracy: 0.55 - ETA: 0s - loss: 0.9606 - accuracy: 0.56 - ETA: 0s - loss: 0.9457 - accuracy: 0.58 - ETA: 0s - loss: 0.9405 - accuracy: 0.59 - ETA: 0s - loss: 0.9390 - accuracy: 0.59 - ETA: 0s - loss: 0.9365 - accuracy: 0.59 - ETA: 0s - loss: 0.9442 - accuracy: 0.58 - ETA: 0s - loss: 0.9365 - accuracy: 0.59 - ETA: 0s - loss: 0.9238 - accuracy: 0.60 - ETA: 0s - loss: 0.9067 - accuracy: 0.62 - ETA: 0s - loss: 0.9193 - accuracy: 0.61 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9457 - accuracy: 0.59 - ETA: 0s - loss: 0.9461 - accuracy: 0.59 - ETA: 0s - loss: 0.9472 - accuracy: 0.5895\n",
      "Epoch 00072: val_loss improved from 1.00657 to 1.00585, saving model to stroke_lstm_model_weights.best.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 74ms/step - loss: 0.9472 - accuracy: 0.5895 - val_loss: 1.0059 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 73/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0049 - accuracy: 0.52 - ETA: 0s - loss: 1.0066 - accuracy: 0.51 - ETA: 0s - loss: 0.9978 - accuracy: 0.52 - ETA: 0s - loss: 0.9676 - accuracy: 0.55 - ETA: 0s - loss: 0.9567 - accuracy: 0.56 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9352 - accuracy: 0.59 - ETA: 0s - loss: 0.9434 - accuracy: 0.58 - ETA: 0s - loss: 0.9357 - accuracy: 0.59 - ETA: 0s - loss: 0.9229 - accuracy: 0.60 - ETA: 0s - loss: 0.9059 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9377 - accuracy: 0.59 - ETA: 0s - loss: 0.9397 - accuracy: 0.59 - ETA: 0s - loss: 0.9453 - accuracy: 0.59 - ETA: 0s - loss: 0.9458 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.5897\n",
      "Epoch 00073: val_loss did not improve from 1.00585\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9470 - accuracy: 0.5897 - val_loss: 1.0175 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 74/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0046 - accuracy: 0.52 - ETA: 0s - loss: 1.0083 - accuracy: 0.51 - ETA: 0s - loss: 0.9981 - accuracy: 0.52 - ETA: 0s - loss: 0.9689 - accuracy: 0.55 - ETA: 0s - loss: 0.9583 - accuracy: 0.56 - ETA: 0s - loss: 0.9436 - accuracy: 0.58 - ETA: 0s - loss: 0.9397 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9364 - accuracy: 0.59 - ETA: 0s - loss: 0.9442 - accuracy: 0.58 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9240 - accuracy: 0.60 - ETA: 0s - loss: 0.9067 - accuracy: 0.62 - ETA: 0s - loss: 0.9196 - accuracy: 0.61 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9462 - accuracy: 0.59 - ETA: 0s - loss: 0.9466 - accuracy: 0.59 - ETA: 0s - loss: 0.9477 - accuracy: 0.5895\n",
      "Epoch 00074: val_loss did not improve from 1.00585\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9477 - accuracy: 0.5895 - val_loss: 1.0188 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 75/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0037 - accuracy: 0.52 - ETA: 0s - loss: 1.0080 - accuracy: 0.51 - ETA: 0s - loss: 0.9983 - accuracy: 0.52 - ETA: 0s - loss: 0.9681 - accuracy: 0.55 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9390 - accuracy: 0.59 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9359 - accuracy: 0.59 - ETA: 0s - loss: 0.9434 - accuracy: 0.58 - ETA: 0s - loss: 0.9359 - accuracy: 0.59 - ETA: 0s - loss: 0.9058 - accuracy: 0.62 - ETA: 0s - loss: 0.9187 - accuracy: 0.61 - ETA: 0s - loss: 0.9377 - accuracy: 0.59 - ETA: 0s - loss: 0.9395 - accuracy: 0.59 - ETA: 0s - loss: 0.9451 - accuracy: 0.59 - ETA: 0s - loss: 0.9457 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.5894\n",
      "Epoch 00075: val_loss improved from 1.00585 to 1.00499, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 1s 74ms/step - loss: 0.9469 - accuracy: 0.5894 - val_loss: 1.0050 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 76/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0047 - accuracy: 0.52 - ETA: 0s - loss: 1.0073 - accuracy: 0.51 - ETA: 0s - loss: 0.9977 - accuracy: 0.52 - ETA: 0s - loss: 0.9678 - accuracy: 0.55 - ETA: 0s - loss: 0.9573 - accuracy: 0.56 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9375 - accuracy: 0.59 - ETA: 0s - loss: 0.9352 - accuracy: 0.59 - ETA: 0s - loss: 0.9432 - accuracy: 0.58 - ETA: 0s - loss: 0.9358 - accuracy: 0.59 - ETA: 0s - loss: 0.9234 - accuracy: 0.60 - ETA: 0s - loss: 0.9061 - accuracy: 0.62 - ETA: 0s - loss: 0.9187 - accuracy: 0.61 - ETA: 0s - loss: 0.9376 - accuracy: 0.59 - ETA: 0s - loss: 0.9397 - accuracy: 0.59 - ETA: 0s - loss: 0.9454 - accuracy: 0.59 - ETA: 0s - loss: 0.9458 - accuracy: 0.5910\n",
      "Epoch 00076: val_loss did not improve from 1.00499\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9472 - accuracy: 0.5898 - val_loss: 1.0217 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 77/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0036 - accuracy: 0.52 - ETA: 0s - loss: 1.0077 - accuracy: 0.51 - ETA: 0s - loss: 0.9994 - accuracy: 0.52 - ETA: 0s - loss: 0.9688 - accuracy: 0.55 - ETA: 0s - loss: 0.9581 - accuracy: 0.56 - ETA: 0s - loss: 0.9434 - accuracy: 0.58 - ETA: 0s - loss: 0.9390 - accuracy: 0.59 - ETA: 0s - loss: 0.9373 - accuracy: 0.59 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9429 - accuracy: 0.58 - ETA: 0s - loss: 0.9352 - accuracy: 0.59 - ETA: 0s - loss: 0.9229 - accuracy: 0.60 - ETA: 0s - loss: 0.9061 - accuracy: 0.62 - ETA: 0s - loss: 0.9183 - accuracy: 0.61 - ETA: 0s - loss: 0.9375 - accuracy: 0.59 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9449 - accuracy: 0.59 - ETA: 0s - loss: 0.9452 - accuracy: 0.5907\n",
      "Epoch 00077: val_loss did not improve from 1.00499\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9465 - accuracy: 0.5896 - val_loss: 1.0114 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 78/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0057 - accuracy: 0.52 - ETA: 0s - loss: 1.0077 - accuracy: 0.51 - ETA: 0s - loss: 0.9969 - accuracy: 0.52 - ETA: 0s - loss: 0.9665 - accuracy: 0.55 - ETA: 0s - loss: 0.9562 - accuracy: 0.56 - ETA: 0s - loss: 0.9415 - accuracy: 0.58 - ETA: 0s - loss: 0.9373 - accuracy: 0.59 - ETA: 0s - loss: 0.9361 - accuracy: 0.59 - ETA: 0s - loss: 0.9338 - accuracy: 0.59 - ETA: 0s - loss: 0.9418 - accuracy: 0.58 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9224 - accuracy: 0.60 - ETA: 0s - loss: 0.9049 - accuracy: 0.62 - ETA: 0s - loss: 0.9371 - accuracy: 0.59 - ETA: 0s - loss: 0.9391 - accuracy: 0.59 - ETA: 0s - loss: 0.9446 - accuracy: 0.59 - ETA: 0s - loss: 0.9452 - accuracy: 0.59 - ETA: 0s - loss: 0.9464 - accuracy: 0.5897\n",
      "Epoch 00078: val_loss improved from 1.00499 to 1.00278, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 1s 74ms/step - loss: 0.9464 - accuracy: 0.5897 - val_loss: 1.0028 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 79/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0031 - accuracy: 0.52 - ETA: 0s - loss: 0.9971 - accuracy: 0.52 - ETA: 0s - loss: 0.9669 - accuracy: 0.55 - ETA: 0s - loss: 0.9563 - accuracy: 0.56 - ETA: 0s - loss: 0.9417 - accuracy: 0.58 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9374 - accuracy: 0.59 - ETA: 0s - loss: 0.9354 - accuracy: 0.59 - ETA: 0s - loss: 0.9433 - accuracy: 0.58 - ETA: 0s - loss: 0.9359 - accuracy: 0.59 - ETA: 0s - loss: 0.9235 - accuracy: 0.60 - ETA: 0s - loss: 0.9061 - accuracy: 0.62 - ETA: 0s - loss: 0.9191 - accuracy: 0.61 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9405 - accuracy: 0.59 - ETA: 0s - loss: 0.9460 - accuracy: 0.59 - ETA: 0s - loss: 0.9462 - accuracy: 0.5908\n",
      "Epoch 00079: val_loss did not improve from 1.00278\n",
      "19/19 [==============================] - 1s 69ms/step - loss: 0.9475 - accuracy: 0.5897 - val_loss: 1.0125 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 80/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0056 - accuracy: 0.52 - ETA: 0s - loss: 1.0107 - accuracy: 0.51 - ETA: 0s - loss: 1.0004 - accuracy: 0.52 - ETA: 0s - loss: 0.9703 - accuracy: 0.55 - ETA: 0s - loss: 0.9593 - accuracy: 0.56 - ETA: 0s - loss: 0.9439 - accuracy: 0.58 - ETA: 0s - loss: 0.9390 - accuracy: 0.59 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9440 - accuracy: 0.58 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9241 - accuracy: 0.60 - ETA: 0s - loss: 0.9067 - accuracy: 0.62 - ETA: 0s - loss: 0.9195 - accuracy: 0.61 - ETA: 0s - loss: 0.9385 - accuracy: 0.59 - ETA: 0s - loss: 0.9402 - accuracy: 0.59 - ETA: 0s - loss: 0.9458 - accuracy: 0.59 - ETA: 0s - loss: 0.9461 - accuracy: 0.59 - ETA: 0s - loss: 0.9472 - accuracy: 0.5896\n",
      "Epoch 00080: val_loss improved from 1.00278 to 0.99970, saving model to stroke_lstm_model_weights.best.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 74ms/step - loss: 0.9472 - accuracy: 0.5896 - val_loss: 0.9997 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 81/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0015 - accuracy: 0.52 - ETA: 0s - loss: 1.0043 - accuracy: 0.51 - ETA: 0s - loss: 0.9947 - accuracy: 0.52 - ETA: 0s - loss: 0.9657 - accuracy: 0.55 - ETA: 0s - loss: 0.9549 - accuracy: 0.56 - ETA: 0s - loss: 0.9409 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9345 - accuracy: 0.59 - ETA: 0s - loss: 0.9424 - accuracy: 0.58 - ETA: 0s - loss: 0.9351 - accuracy: 0.59 - ETA: 0s - loss: 0.9226 - accuracy: 0.60 - ETA: 0s - loss: 0.9058 - accuracy: 0.62 - ETA: 0s - loss: 0.9392 - accuracy: 0.59 - ETA: 0s - loss: 0.9409 - accuracy: 0.59 - ETA: 0s - loss: 0.9464 - accuracy: 0.59 - ETA: 0s - loss: 0.9466 - accuracy: 0.59 - ETA: 0s - loss: 0.9478 - accuracy: 0.5891\n",
      "Epoch 00081: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9478 - accuracy: 0.5891 - val_loss: 1.0135 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 82/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0063 - accuracy: 0.52 - ETA: 0s - loss: 1.0105 - accuracy: 0.51 - ETA: 0s - loss: 1.0004 - accuracy: 0.52 - ETA: 0s - loss: 0.9709 - accuracy: 0.55 - ETA: 0s - loss: 0.9604 - accuracy: 0.56 - ETA: 0s - loss: 0.9458 - accuracy: 0.58 - ETA: 0s - loss: 0.9422 - accuracy: 0.59 - ETA: 0s - loss: 0.9401 - accuracy: 0.59 - ETA: 0s - loss: 0.9378 - accuracy: 0.59 - ETA: 0s - loss: 0.9450 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9250 - accuracy: 0.60 - ETA: 0s - loss: 0.9079 - accuracy: 0.62 - ETA: 0s - loss: 0.9210 - accuracy: 0.61 - ETA: 0s - loss: 0.9401 - accuracy: 0.59 - ETA: 0s - loss: 0.9418 - accuracy: 0.59 - ETA: 0s - loss: 0.9469 - accuracy: 0.59 - ETA: 0s - loss: 0.9482 - accuracy: 0.5899\n",
      "Epoch 00082: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9482 - accuracy: 0.5899 - val_loss: 1.0261 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 83/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0045 - accuracy: 0.52 - ETA: 0s - loss: 1.0115 - accuracy: 0.51 - ETA: 0s - loss: 1.0007 - accuracy: 0.52 - ETA: 0s - loss: 0.9723 - accuracy: 0.55 - ETA: 0s - loss: 0.9615 - accuracy: 0.56 - ETA: 0s - loss: 0.9464 - accuracy: 0.58 - ETA: 0s - loss: 0.9411 - accuracy: 0.59 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9370 - accuracy: 0.59 - ETA: 0s - loss: 0.9445 - accuracy: 0.58 - ETA: 0s - loss: 0.9370 - accuracy: 0.59 - ETA: 0s - loss: 0.9237 - accuracy: 0.60 - ETA: 0s - loss: 0.9065 - accuracy: 0.62 - ETA: 0s - loss: 0.9202 - accuracy: 0.61 - ETA: 0s - loss: 0.9399 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.59 - ETA: 0s - loss: 0.9474 - accuracy: 0.59 - ETA: 0s - loss: 0.9484 - accuracy: 0.5894\n",
      "Epoch 00083: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9484 - accuracy: 0.5894 - val_loss: 1.0259 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 84/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0036 - accuracy: 0.52 - ETA: 0s - loss: 1.0061 - accuracy: 0.51 - ETA: 0s - loss: 0.9970 - accuracy: 0.52 - ETA: 0s - loss: 0.9669 - accuracy: 0.55 - ETA: 0s - loss: 0.9569 - accuracy: 0.56 - ETA: 0s - loss: 0.9420 - accuracy: 0.58 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9374 - accuracy: 0.59 - ETA: 0s - loss: 0.9351 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9350 - accuracy: 0.59 - ETA: 0s - loss: 0.9225 - accuracy: 0.60 - ETA: 0s - loss: 0.9054 - accuracy: 0.62 - ETA: 0s - loss: 0.9188 - accuracy: 0.61 - ETA: 0s - loss: 0.9398 - accuracy: 0.59 - ETA: 0s - loss: 0.9450 - accuracy: 0.59 - ETA: 0s - loss: 0.9454 - accuracy: 0.59 - ETA: 0s - loss: 0.9465 - accuracy: 0.5898\n",
      "Epoch 00084: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9465 - accuracy: 0.5898 - val_loss: 1.0194 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 85/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0035 - accuracy: 0.52 - ETA: 0s - loss: 1.0037 - accuracy: 0.51 - ETA: 0s - loss: 0.9663 - accuracy: 0.55 - ETA: 0s - loss: 0.9561 - accuracy: 0.56 - ETA: 0s - loss: 0.9409 - accuracy: 0.58 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9355 - accuracy: 0.59 - ETA: 0s - loss: 0.9333 - accuracy: 0.59 - ETA: 0s - loss: 0.9411 - accuracy: 0.58 - ETA: 0s - loss: 0.9340 - accuracy: 0.59 - ETA: 0s - loss: 0.9217 - accuracy: 0.60 - ETA: 0s - loss: 0.9042 - accuracy: 0.62 - ETA: 0s - loss: 0.9176 - accuracy: 0.61 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9392 - accuracy: 0.59 - ETA: 0s - loss: 0.9448 - accuracy: 0.59 - ETA: 0s - loss: 0.9452 - accuracy: 0.59 - ETA: 0s - loss: 0.9461 - accuracy: 0.5899\n",
      "Epoch 00085: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9461 - accuracy: 0.5899 - val_loss: 1.0137 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 86/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0012 - accuracy: 0.52 - ETA: 0s - loss: 1.0051 - accuracy: 0.51 - ETA: 0s - loss: 0.9956 - accuracy: 0.52 - ETA: 0s - loss: 0.9661 - accuracy: 0.55 - ETA: 0s - loss: 0.9558 - accuracy: 0.56 - ETA: 0s - loss: 0.9418 - accuracy: 0.58 - ETA: 0s - loss: 0.9383 - accuracy: 0.59 - ETA: 0s - loss: 0.9365 - accuracy: 0.59 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9420 - accuracy: 0.58 - ETA: 0s - loss: 0.9353 - accuracy: 0.59 - ETA: 0s - loss: 0.9228 - accuracy: 0.60 - ETA: 0s - loss: 0.9189 - accuracy: 0.61 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9401 - accuracy: 0.59 - ETA: 0s - loss: 0.9456 - accuracy: 0.59 - ETA: 0s - loss: 0.9460 - accuracy: 0.59 - ETA: 0s - loss: 0.9470 - accuracy: 0.5894\n",
      "Epoch 00086: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9470 - accuracy: 0.5894 - val_loss: 1.0242 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 87/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0048 - accuracy: 0.52 - ETA: 0s - loss: 1.0067 - accuracy: 0.51 - ETA: 0s - loss: 0.9976 - accuracy: 0.52 - ETA: 0s - loss: 0.9682 - accuracy: 0.55 - ETA: 0s - loss: 0.9575 - accuracy: 0.56 - ETA: 0s - loss: 0.9428 - accuracy: 0.58 - ETA: 0s - loss: 0.9388 - accuracy: 0.59 - ETA: 0s - loss: 0.9372 - accuracy: 0.59 - ETA: 0s - loss: 0.9351 - accuracy: 0.59 - ETA: 0s - loss: 0.9432 - accuracy: 0.58 - ETA: 0s - loss: 0.9357 - accuracy: 0.59 - ETA: 0s - loss: 0.9229 - accuracy: 0.60 - ETA: 0s - loss: 0.9054 - accuracy: 0.62 - ETA: 0s - loss: 0.9181 - accuracy: 0.61 - ETA: 0s - loss: 0.9398 - accuracy: 0.59 - ETA: 0s - loss: 0.9453 - accuracy: 0.59 - ETA: 0s - loss: 0.9454 - accuracy: 0.59 - ETA: 0s - loss: 0.9465 - accuracy: 0.5907\n",
      "Epoch 00087: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9465 - accuracy: 0.5907 - val_loss: 1.0266 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 88/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0056 - accuracy: 0.52 - ETA: 0s - loss: 1.0058 - accuracy: 0.51 - ETA: 0s - loss: 0.9963 - accuracy: 0.53 - ETA: 0s - loss: 0.9661 - accuracy: 0.56 - ETA: 0s - loss: 0.9561 - accuracy: 0.57 - ETA: 0s - loss: 0.9412 - accuracy: 0.58 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9365 - accuracy: 0.59 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9422 - accuracy: 0.58 - ETA: 0s - loss: 0.9348 - accuracy: 0.59 - ETA: 0s - loss: 0.9221 - accuracy: 0.60 - ETA: 0s - loss: 0.9046 - accuracy: 0.62 - ETA: 0s - loss: 0.9179 - accuracy: 0.61 - ETA: 0s - loss: 0.9371 - accuracy: 0.59 - ETA: 0s - loss: 0.9390 - accuracy: 0.59 - ETA: 0s - loss: 0.9446 - accuracy: 0.59 - ETA: 0s - loss: 0.9449 - accuracy: 0.59 - ETA: 0s - loss: 0.9460 - accuracy: 0.5892\n",
      "Epoch 00088: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9460 - accuracy: 0.5892 - val_loss: 1.0053 - val_accuracy: 0.4971 - lr: 0.0461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0040 - accuracy: 0.52 - ETA: 0s - loss: 1.0049 - accuracy: 0.51 - ETA: 0s - loss: 0.9958 - accuracy: 0.52 - ETA: 0s - loss: 0.9661 - accuracy: 0.55 - ETA: 0s - loss: 0.9564 - accuracy: 0.56 - ETA: 0s - loss: 0.9420 - accuracy: 0.58 - ETA: 0s - loss: 0.9386 - accuracy: 0.59 - ETA: 0s - loss: 0.9374 - accuracy: 0.59 - ETA: 0s - loss: 0.9352 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.58 - ETA: 0s - loss: 0.9353 - accuracy: 0.59 - ETA: 0s - loss: 0.9229 - accuracy: 0.60 - ETA: 0s - loss: 0.9058 - accuracy: 0.62 - ETA: 0s - loss: 0.9184 - accuracy: 0.61 - ETA: 0s - loss: 0.9374 - accuracy: 0.59 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9449 - accuracy: 0.59 - ETA: 0s - loss: 0.9450 - accuracy: 0.59 - ETA: 0s - loss: 0.9463 - accuracy: 0.5894\n",
      "Epoch 00089: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9463 - accuracy: 0.5894 - val_loss: 1.0128 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 90/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0000 - accuracy: 0.52 - ETA: 0s - loss: 1.0061 - accuracy: 0.51 - ETA: 0s - loss: 0.9959 - accuracy: 0.52 - ETA: 0s - loss: 0.9660 - accuracy: 0.55 - ETA: 0s - loss: 0.9554 - accuracy: 0.56 - ETA: 0s - loss: 0.9410 - accuracy: 0.58 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9353 - accuracy: 0.59 - ETA: 0s - loss: 0.9227 - accuracy: 0.60 - ETA: 0s - loss: 0.9055 - accuracy: 0.62 - ETA: 0s - loss: 0.9187 - accuracy: 0.61 - ETA: 0s - loss: 0.9382 - accuracy: 0.59 - ETA: 0s - loss: 0.9408 - accuracy: 0.59 - ETA: 0s - loss: 0.9468 - accuracy: 0.59 - ETA: 0s - loss: 0.9483 - accuracy: 0.5897\n",
      "Epoch 00090: val_loss did not improve from 0.99970\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 0.03686400055885315.\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9483 - accuracy: 0.5897 - val_loss: 1.0252 - val_accuracy: 0.4971 - lr: 0.0461\n",
      "Epoch 91/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 1.0084 - accuracy: 0.51 - ETA: 0s - loss: 0.9693 - accuracy: 0.55 - ETA: 0s - loss: 0.9587 - accuracy: 0.56 - ETA: 0s - loss: 0.9434 - accuracy: 0.58 - ETA: 0s - loss: 0.9387 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9347 - accuracy: 0.59 - ETA: 0s - loss: 0.9429 - accuracy: 0.58 - ETA: 0s - loss: 0.9354 - accuracy: 0.59 - ETA: 0s - loss: 0.9232 - accuracy: 0.60 - ETA: 0s - loss: 0.9067 - accuracy: 0.62 - ETA: 0s - loss: 0.9187 - accuracy: 0.61 - ETA: 0s - loss: 0.9369 - accuracy: 0.59 - ETA: 0s - loss: 0.9392 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.59 - ETA: 0s - loss: 0.9448 - accuracy: 0.59 - ETA: 0s - loss: 0.9459 - accuracy: 0.5898\n",
      "Epoch 00091: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9459 - accuracy: 0.5898 - val_loss: 1.0105 - val_accuracy: 0.4980 - lr: 0.0369\n",
      "Epoch 92/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 1.0042 - accuracy: 0.51 - ETA: 0s - loss: 0.9961 - accuracy: 0.52 - ETA: 0s - loss: 0.9663 - accuracy: 0.55 - ETA: 0s - loss: 0.9560 - accuracy: 0.56 - ETA: 0s - loss: 0.9403 - accuracy: 0.58 - ETA: 0s - loss: 0.9369 - accuracy: 0.59 - ETA: 0s - loss: 0.9358 - accuracy: 0.59 - ETA: 0s - loss: 0.9333 - accuracy: 0.59 - ETA: 0s - loss: 0.9418 - accuracy: 0.58 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9217 - accuracy: 0.60 - ETA: 0s - loss: 0.9046 - accuracy: 0.62 - ETA: 0s - loss: 0.9175 - accuracy: 0.61 - ETA: 0s - loss: 0.9365 - accuracy: 0.59 - ETA: 0s - loss: 0.9389 - accuracy: 0.59 - ETA: 0s - loss: 0.9444 - accuracy: 0.58 - ETA: 0s - loss: 0.9448 - accuracy: 0.58 - ETA: 0s - loss: 0.9462 - accuracy: 0.5887\n",
      "Epoch 00092: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9462 - accuracy: 0.5887 - val_loss: 1.0329 - val_accuracy: 0.4971 - lr: 0.0369\n",
      "Epoch 93/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0026 - accuracy: 0.52 - ETA: 0s - loss: 1.0076 - accuracy: 0.51 - ETA: 0s - loss: 0.9990 - accuracy: 0.52 - ETA: 0s - loss: 0.9695 - accuracy: 0.55 - ETA: 0s - loss: 0.9590 - accuracy: 0.56 - ETA: 0s - loss: 0.9438 - accuracy: 0.58 - ETA: 0s - loss: 0.9385 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9348 - accuracy: 0.59 - ETA: 0s - loss: 0.9430 - accuracy: 0.58 - ETA: 0s - loss: 0.9350 - accuracy: 0.59 - ETA: 0s - loss: 0.9226 - accuracy: 0.60 - ETA: 0s - loss: 0.9056 - accuracy: 0.62 - ETA: 0s - loss: 0.9181 - accuracy: 0.61 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9445 - accuracy: 0.59 - ETA: 0s - loss: 0.9449 - accuracy: 0.59 - ETA: 0s - loss: 0.9464 - accuracy: 0.5896\n",
      "Epoch 00093: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9464 - accuracy: 0.5896 - val_loss: 1.0290 - val_accuracy: 0.4971 - lr: 0.0369\n",
      "Epoch 94/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0016 - accuracy: 0.52 - ETA: 0s - loss: 1.0050 - accuracy: 0.51 - ETA: 0s - loss: 0.9972 - accuracy: 0.52 - ETA: 0s - loss: 0.9679 - accuracy: 0.55 - ETA: 0s - loss: 0.9571 - accuracy: 0.56 - ETA: 0s - loss: 0.9418 - accuracy: 0.58 - ETA: 0s - loss: 0.9366 - accuracy: 0.59 - ETA: 0s - loss: 0.9353 - accuracy: 0.59 - ETA: 0s - loss: 0.9330 - accuracy: 0.59 - ETA: 0s - loss: 0.9338 - accuracy: 0.59 - ETA: 0s - loss: 0.9211 - accuracy: 0.60 - ETA: 0s - loss: 0.9040 - accuracy: 0.62 - ETA: 0s - loss: 0.9166 - accuracy: 0.61 - ETA: 0s - loss: 0.9354 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9436 - accuracy: 0.59 - ETA: 0s - loss: 0.9439 - accuracy: 0.59 - ETA: 0s - loss: 0.9453 - accuracy: 0.5894\n",
      "Epoch 00094: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9453 - accuracy: 0.5894 - val_loss: 1.0076 - val_accuracy: 0.4971 - lr: 0.0369\n",
      "Epoch 95/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0042 - accuracy: 0.52 - ETA: 0s - loss: 1.0055 - accuracy: 0.51 - ETA: 0s - loss: 0.9956 - accuracy: 0.52 - ETA: 0s - loss: 0.9655 - accuracy: 0.55 - ETA: 0s - loss: 0.9553 - accuracy: 0.56 - ETA: 0s - loss: 0.9410 - accuracy: 0.58 - ETA: 0s - loss: 0.9378 - accuracy: 0.59 - ETA: 0s - loss: 0.9364 - accuracy: 0.59 - ETA: 0s - loss: 0.9339 - accuracy: 0.59 - ETA: 0s - loss: 0.9417 - accuracy: 0.58 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9219 - accuracy: 0.60 - ETA: 0s - loss: 0.9052 - accuracy: 0.62 - ETA: 0s - loss: 0.9182 - accuracy: 0.61 - ETA: 0s - loss: 0.9385 - accuracy: 0.59 - ETA: 0s - loss: 0.9437 - accuracy: 0.59 - ETA: 0s - loss: 0.9442 - accuracy: 0.59 - ETA: 0s - loss: 0.9454 - accuracy: 0.5899\n",
      "Epoch 00095: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9454 - accuracy: 0.5899 - val_loss: 1.0212 - val_accuracy: 0.4971 - lr: 0.0369\n",
      "Epoch 96/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0013 - accuracy: 0.52 - ETA: 0s - loss: 1.0049 - accuracy: 0.51 - ETA: 0s - loss: 0.9971 - accuracy: 0.52 - ETA: 0s - loss: 0.9674 - accuracy: 0.55 - ETA: 0s - loss: 0.9566 - accuracy: 0.56 - ETA: 0s - loss: 0.9414 - accuracy: 0.58 - ETA: 0s - loss: 0.9360 - accuracy: 0.59 - ETA: 0s - loss: 0.9349 - accuracy: 0.59 - ETA: 0s - loss: 0.9327 - accuracy: 0.59 - ETA: 0s - loss: 0.9409 - accuracy: 0.58 - ETA: 0s - loss: 0.9342 - accuracy: 0.59 - ETA: 0s - loss: 0.9219 - accuracy: 0.60 - ETA: 0s - loss: 0.9049 - accuracy: 0.62 - ETA: 0s - loss: 0.9172 - accuracy: 0.61 - ETA: 0s - loss: 0.9359 - accuracy: 0.59 - ETA: 0s - loss: 0.9436 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.59 - ETA: 0s - loss: 0.9456 - accuracy: 0.5895\n",
      "Epoch 00096: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9456 - accuracy: 0.5895 - val_loss: 1.0159 - val_accuracy: 0.4977 - lr: 0.0369\n",
      "Epoch 97/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0040 - accuracy: 0.52 - ETA: 0s - loss: 1.0037 - accuracy: 0.51 - ETA: 0s - loss: 0.9953 - accuracy: 0.52 - ETA: 0s - loss: 0.9656 - accuracy: 0.55 - ETA: 0s - loss: 0.9551 - accuracy: 0.56 - ETA: 0s - loss: 0.9395 - accuracy: 0.58 - ETA: 0s - loss: 0.9350 - accuracy: 0.59 - ETA: 0s - loss: 0.9338 - accuracy: 0.59 - ETA: 0s - loss: 0.9317 - accuracy: 0.59 - ETA: 0s - loss: 0.9398 - accuracy: 0.58 - ETA: 0s - loss: 0.9325 - accuracy: 0.59 - ETA: 0s - loss: 0.9200 - accuracy: 0.60 - ETA: 0s - loss: 0.9029 - accuracy: 0.62 - ETA: 0s - loss: 0.9349 - accuracy: 0.59 - ETA: 0s - loss: 0.9372 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.59 - ETA: 0s - loss: 0.9428 - accuracy: 0.59 - ETA: 0s - loss: 0.9445 - accuracy: 0.5899\n",
      "Epoch 00097: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9445 - accuracy: 0.5899 - val_loss: 1.0174 - val_accuracy: 0.4972 - lr: 0.0369\n",
      "Epoch 98/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0022 - accuracy: 0.52 - ETA: 0s - loss: 1.0034 - accuracy: 0.51 - ETA: 0s - loss: 0.9938 - accuracy: 0.52 - ETA: 0s - loss: 0.9634 - accuracy: 0.55 - ETA: 0s - loss: 0.9531 - accuracy: 0.56 - ETA: 0s - loss: 0.9381 - accuracy: 0.58 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9331 - accuracy: 0.59 - ETA: 0s - loss: 0.9311 - accuracy: 0.59 - ETA: 0s - loss: 0.9397 - accuracy: 0.58 - ETA: 0s - loss: 0.9325 - accuracy: 0.59 - ETA: 0s - loss: 0.9203 - accuracy: 0.60 - ETA: 0s - loss: 0.9030 - accuracy: 0.62 - ETA: 0s - loss: 0.9157 - accuracy: 0.61 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9428 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5895\n",
      "Epoch 00098: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9441 - accuracy: 0.5895 - val_loss: 1.0249 - val_accuracy: 0.4971 - lr: 0.0369\n",
      "Epoch 99/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0041 - accuracy: 0.52 - ETA: 0s - loss: 1.0060 - accuracy: 0.52 - ETA: 0s - loss: 0.9973 - accuracy: 0.53 - ETA: 0s - loss: 0.9665 - accuracy: 0.56 - ETA: 0s - loss: 0.9559 - accuracy: 0.57 - ETA: 0s - loss: 0.9403 - accuracy: 0.58 - ETA: 0s - loss: 0.9361 - accuracy: 0.59 - ETA: 0s - loss: 0.9348 - accuracy: 0.59 - ETA: 0s - loss: 0.9328 - accuracy: 0.59 - ETA: 0s - loss: 0.9407 - accuracy: 0.58 - ETA: 0s - loss: 0.9330 - accuracy: 0.59 - ETA: 0s - loss: 0.9203 - accuracy: 0.60 - ETA: 0s - loss: 0.9032 - accuracy: 0.62 - ETA: 0s - loss: 0.9155 - accuracy: 0.61 - ETA: 0s - loss: 0.9342 - accuracy: 0.59 - ETA: 0s - loss: 0.9416 - accuracy: 0.59 - ETA: 0s - loss: 0.9420 - accuracy: 0.59 - ETA: 0s - loss: 0.9434 - accuracy: 0.5900\n",
      "Epoch 00099: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9434 - accuracy: 0.5900 - val_loss: 1.0247 - val_accuracy: 0.4971 - lr: 0.0369\n",
      "Epoch 100/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0020 - accuracy: 0.52 - ETA: 0s - loss: 1.0028 - accuracy: 0.51 - ETA: 0s - loss: 0.9945 - accuracy: 0.52 - ETA: 0s - loss: 0.9636 - accuracy: 0.55 - ETA: 0s - loss: 0.9534 - accuracy: 0.56 - ETA: 0s - loss: 0.9391 - accuracy: 0.58 - ETA: 0s - loss: 0.9347 - accuracy: 0.59 - ETA: 0s - loss: 0.9336 - accuracy: 0.59 - ETA: 0s - loss: 0.9317 - accuracy: 0.59 - ETA: 0s - loss: 0.9394 - accuracy: 0.58 - ETA: 0s - loss: 0.9322 - accuracy: 0.59 - ETA: 0s - loss: 0.9201 - accuracy: 0.60 - ETA: 0s - loss: 0.9034 - accuracy: 0.62 - ETA: 0s - loss: 0.9158 - accuracy: 0.61 - ETA: 0s - loss: 0.9345 - accuracy: 0.59 - ETA: 0s - loss: 0.9364 - accuracy: 0.59 - ETA: 0s - loss: 0.9418 - accuracy: 0.59 - ETA: 0s - loss: 0.9440 - accuracy: 0.5897\n",
      "Epoch 00100: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9440 - accuracy: 0.5897 - val_loss: 1.0265 - val_accuracy: 0.4971 - lr: 0.0369\n",
      "Epoch 101/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9990 - accuracy: 0.52 - ETA: 0s - loss: 1.0037 - accuracy: 0.51 - ETA: 0s - loss: 0.9953 - accuracy: 0.52 - ETA: 0s - loss: 0.9658 - accuracy: 0.55 - ETA: 0s - loss: 0.9557 - accuracy: 0.56 - ETA: 0s - loss: 0.9405 - accuracy: 0.58 - ETA: 0s - loss: 0.9354 - accuracy: 0.59 - ETA: 0s - loss: 0.9339 - accuracy: 0.59 - ETA: 0s - loss: 0.9320 - accuracy: 0.59 - ETA: 0s - loss: 0.9402 - accuracy: 0.58 - ETA: 0s - loss: 0.9327 - accuracy: 0.59 - ETA: 0s - loss: 0.9205 - accuracy: 0.60 - ETA: 0s - loss: 0.9159 - accuracy: 0.61 - ETA: 0s - loss: 0.9346 - accuracy: 0.59 - ETA: 0s - loss: 0.9371 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.59 - ETA: 0s - loss: 0.9432 - accuracy: 0.59 - ETA: 0s - loss: 0.9446 - accuracy: 0.5904\n",
      "Epoch 00101: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9446 - accuracy: 0.5904 - val_loss: 1.0121 - val_accuracy: 0.4976 - lr: 0.0369\n",
      "Epoch 102/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0036 - accuracy: 0.52 - ETA: 0s - loss: 1.0046 - accuracy: 0.51 - ETA: 0s - loss: 0.9949 - accuracy: 0.52 - ETA: 0s - loss: 0.9652 - accuracy: 0.55 - ETA: 0s - loss: 0.9546 - accuracy: 0.56 - ETA: 0s - loss: 0.9388 - accuracy: 0.58 - ETA: 0s - loss: 0.9337 - accuracy: 0.59 - ETA: 0s - loss: 0.9320 - accuracy: 0.59 - ETA: 0s - loss: 0.9301 - accuracy: 0.59 - ETA: 0s - loss: 0.9382 - accuracy: 0.58 - ETA: 0s - loss: 0.9307 - accuracy: 0.59 - ETA: 0s - loss: 0.9018 - accuracy: 0.62 - ETA: 0s - loss: 0.9145 - accuracy: 0.61 - ETA: 0s - loss: 0.9336 - accuracy: 0.59 - ETA: 0s - loss: 0.9360 - accuracy: 0.59 - ETA: 0s - loss: 0.9413 - accuracy: 0.59 - ETA: 0s - loss: 0.9422 - accuracy: 0.59 - ETA: 0s - loss: 0.9435 - accuracy: 0.5916\n",
      "Epoch 00102: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9435 - accuracy: 0.5916 - val_loss: 1.0155 - val_accuracy: 0.4976 - lr: 0.0369\n",
      "Epoch 103/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0059 - accuracy: 0.52 - ETA: 0s - loss: 1.0060 - accuracy: 0.51 - ETA: 0s - loss: 0.9971 - accuracy: 0.52 - ETA: 0s - loss: 0.9663 - accuracy: 0.55 - ETA: 0s - loss: 0.9555 - accuracy: 0.56 - ETA: 0s - loss: 0.9408 - accuracy: 0.58 - ETA: 0s - loss: 0.9367 - accuracy: 0.59 - ETA: 0s - loss: 0.9351 - accuracy: 0.59 - ETA: 0s - loss: 0.9331 - accuracy: 0.59 - ETA: 0s - loss: 0.9414 - accuracy: 0.58 - ETA: 0s - loss: 0.9335 - accuracy: 0.59 - ETA: 0s - loss: 0.9213 - accuracy: 0.60 - ETA: 0s - loss: 0.9040 - accuracy: 0.62 - ETA: 0s - loss: 0.9167 - accuracy: 0.61 - ETA: 0s - loss: 0.9350 - accuracy: 0.59 - ETA: 0s - loss: 0.9369 - accuracy: 0.59 - ETA: 0s - loss: 0.9426 - accuracy: 0.59 - ETA: 0s - loss: 0.9446 - accuracy: 0.5893\n",
      "Epoch 00103: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9446 - accuracy: 0.5893 - val_loss: 1.0119 - val_accuracy: 0.4971 - lr: 0.0369\n",
      "Epoch 104/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0031 - accuracy: 0.52 - ETA: 0s - loss: 1.0085 - accuracy: 0.51 - ETA: 0s - loss: 0.9978 - accuracy: 0.52 - ETA: 0s - loss: 0.9672 - accuracy: 0.55 - ETA: 0s - loss: 0.9566 - accuracy: 0.56 - ETA: 0s - loss: 0.9405 - accuracy: 0.58 - ETA: 0s - loss: 0.9355 - accuracy: 0.59 - ETA: 0s - loss: 0.9337 - accuracy: 0.59 - ETA: 0s - loss: 0.9319 - accuracy: 0.59 - ETA: 0s - loss: 0.9404 - accuracy: 0.58 - ETA: 0s - loss: 0.9328 - accuracy: 0.59 - ETA: 0s - loss: 0.9206 - accuracy: 0.60 - ETA: 0s - loss: 0.9033 - accuracy: 0.62 - ETA: 0s - loss: 0.9162 - accuracy: 0.61 - ETA: 0s - loss: 0.9349 - accuracy: 0.59 - ETA: 0s - loss: 0.9368 - accuracy: 0.59 - ETA: 0s - loss: 0.9424 - accuracy: 0.59 - ETA: 0s - loss: 0.9429 - accuracy: 0.59 - ETA: 0s - loss: 0.9441 - accuracy: 0.5898\n",
      "Epoch 00104: val_loss did not improve from 0.99970\n",
      "\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 0.029491201043128967.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9441 - accuracy: 0.5898 - val_loss: 1.0058 - val_accuracy: 0.4990 - lr: 0.0369\n",
      "Epoch 105/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0021 - accuracy: 0.52 - ETA: 0s - loss: 1.0049 - accuracy: 0.51 - ETA: 0s - loss: 0.9955 - accuracy: 0.52 - ETA: 0s - loss: 0.9649 - accuracy: 0.55 - ETA: 0s - loss: 0.9539 - accuracy: 0.56 - ETA: 0s - loss: 0.9383 - accuracy: 0.58 - ETA: 0s - loss: 0.9341 - accuracy: 0.59 - ETA: 0s - loss: 0.9329 - accuracy: 0.59 - ETA: 0s - loss: 0.9309 - accuracy: 0.59 - ETA: 0s - loss: 0.9392 - accuracy: 0.58 - ETA: 0s - loss: 0.9322 - accuracy: 0.59 - ETA: 0s - loss: 0.9199 - accuracy: 0.60 - ETA: 0s - loss: 0.9027 - accuracy: 0.62 - ETA: 0s - loss: 0.9327 - accuracy: 0.59 - ETA: 0s - loss: 0.9350 - accuracy: 0.59 - ETA: 0s - loss: 0.9404 - accuracy: 0.59 - ETA: 0s - loss: 0.9410 - accuracy: 0.59 - ETA: 0s - loss: 0.9423 - accuracy: 0.5904\n",
      "Epoch 00105: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9423 - accuracy: 0.5904 - val_loss: 1.0116 - val_accuracy: 0.4972 - lr: 0.0295\n",
      "Epoch 106/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0024 - accuracy: 0.52 - ETA: 0s - loss: 1.0031 - accuracy: 0.52 - ETA: 0s - loss: 0.9942 - accuracy: 0.52 - ETA: 0s - loss: 0.9639 - accuracy: 0.55 - ETA: 0s - loss: 0.9533 - accuracy: 0.56 - ETA: 0s - loss: 0.9374 - accuracy: 0.58 - ETA: 0s - loss: 0.9331 - accuracy: 0.59 - ETA: 0s - loss: 0.9318 - accuracy: 0.59 - ETA: 0s - loss: 0.9296 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.58 - ETA: 0s - loss: 0.9304 - accuracy: 0.59 - ETA: 0s - loss: 0.9184 - accuracy: 0.60 - ETA: 0s - loss: 0.9012 - accuracy: 0.62 - ETA: 0s - loss: 0.9129 - accuracy: 0.61 - ETA: 0s - loss: 0.9335 - accuracy: 0.59 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9401 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.5902\n",
      "Epoch 00106: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9415 - accuracy: 0.5902 - val_loss: 1.0271 - val_accuracy: 0.4971 - lr: 0.0295\n",
      "Epoch 107/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0022 - accuracy: 0.52 - ETA: 0s - loss: 1.0031 - accuracy: 0.52 - ETA: 0s - loss: 0.9950 - accuracy: 0.52 - ETA: 0s - loss: 0.9638 - accuracy: 0.56 - ETA: 0s - loss: 0.9527 - accuracy: 0.57 - ETA: 0s - loss: 0.9372 - accuracy: 0.58 - ETA: 0s - loss: 0.9325 - accuracy: 0.59 - ETA: 0s - loss: 0.9316 - accuracy: 0.59 - ETA: 0s - loss: 0.9295 - accuracy: 0.59 - ETA: 0s - loss: 0.9383 - accuracy: 0.58 - ETA: 0s - loss: 0.9308 - accuracy: 0.59 - ETA: 0s - loss: 0.9189 - accuracy: 0.60 - ETA: 0s - loss: 0.9021 - accuracy: 0.62 - ETA: 0s - loss: 0.9141 - accuracy: 0.61 - ETA: 0s - loss: 0.9322 - accuracy: 0.59 - ETA: 0s - loss: 0.9346 - accuracy: 0.59 - ETA: 0s - loss: 0.9397 - accuracy: 0.59 - ETA: 0s - loss: 0.9402 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.5906\n",
      "Epoch 00107: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9415 - accuracy: 0.5906 - val_loss: 1.0449 - val_accuracy: 0.4972 - lr: 0.0295\n",
      "Epoch 108/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0006 - accuracy: 0.52 - ETA: 0s - loss: 1.0020 - accuracy: 0.52 - ETA: 0s - loss: 0.9935 - accuracy: 0.53 - ETA: 0s - loss: 0.9638 - accuracy: 0.56 - ETA: 0s - loss: 0.9527 - accuracy: 0.57 - ETA: 0s - loss: 0.9368 - accuracy: 0.58 - ETA: 0s - loss: 0.9318 - accuracy: 0.59 - ETA: 0s - loss: 0.9306 - accuracy: 0.59 - ETA: 0s - loss: 0.9289 - accuracy: 0.59 - ETA: 0s - loss: 0.9374 - accuracy: 0.58 - ETA: 0s - loss: 0.9300 - accuracy: 0.59 - ETA: 0s - loss: 0.9179 - accuracy: 0.60 - ETA: 0s - loss: 0.9009 - accuracy: 0.62 - ETA: 0s - loss: 0.9133 - accuracy: 0.61 - ETA: 0s - loss: 0.9317 - accuracy: 0.59 - ETA: 0s - loss: 0.9394 - accuracy: 0.59 - ETA: 0s - loss: 0.9398 - accuracy: 0.59 - ETA: 0s - loss: 0.9411 - accuracy: 0.5909\n",
      "Epoch 00108: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9411 - accuracy: 0.5909 - val_loss: 1.0284 - val_accuracy: 0.4979 - lr: 0.0295\n",
      "Epoch 109/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9948 - accuracy: 0.53 - ETA: 0s - loss: 0.9988 - accuracy: 0.52 - ETA: 0s - loss: 0.9915 - accuracy: 0.53 - ETA: 0s - loss: 0.9602 - accuracy: 0.56 - ETA: 0s - loss: 0.9499 - accuracy: 0.57 - ETA: 0s - loss: 0.9349 - accuracy: 0.58 - ETA: 0s - loss: 0.9311 - accuracy: 0.59 - ETA: 0s - loss: 0.9295 - accuracy: 0.59 - ETA: 0s - loss: 0.9278 - accuracy: 0.59 - ETA: 0s - loss: 0.9370 - accuracy: 0.58 - ETA: 0s - loss: 0.9297 - accuracy: 0.59 - ETA: 0s - loss: 0.9178 - accuracy: 0.60 - ETA: 0s - loss: 0.9011 - accuracy: 0.62 - ETA: 0s - loss: 0.9135 - accuracy: 0.61 - ETA: 0s - loss: 0.9320 - accuracy: 0.59 - ETA: 0s - loss: 0.9400 - accuracy: 0.59 - ETA: 0s - loss: 0.9405 - accuracy: 0.59 - ETA: 0s - loss: 0.9422 - accuracy: 0.5895\n",
      "Epoch 00109: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9422 - accuracy: 0.5895 - val_loss: 1.0243 - val_accuracy: 0.4977 - lr: 0.0295\n",
      "Epoch 110/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0009 - accuracy: 0.52 - ETA: 0s - loss: 1.0045 - accuracy: 0.52 - ETA: 0s - loss: 0.9961 - accuracy: 0.53 - ETA: 0s - loss: 0.9655 - accuracy: 0.56 - ETA: 0s - loss: 0.9551 - accuracy: 0.57 - ETA: 0s - loss: 0.9400 - accuracy: 0.58 - ETA: 0s - loss: 0.9355 - accuracy: 0.59 - ETA: 0s - loss: 0.9333 - accuracy: 0.59 - ETA: 0s - loss: 0.9315 - accuracy: 0.59 - ETA: 0s - loss: 0.9400 - accuracy: 0.58 - ETA: 0s - loss: 0.9323 - accuracy: 0.59 - ETA: 0s - loss: 0.9032 - accuracy: 0.62 - ETA: 0s - loss: 0.9154 - accuracy: 0.61 - ETA: 0s - loss: 0.9336 - accuracy: 0.59 - ETA: 0s - loss: 0.9360 - accuracy: 0.59 - ETA: 0s - loss: 0.9413 - accuracy: 0.59 - ETA: 0s - loss: 0.9417 - accuracy: 0.59 - ETA: 0s - loss: 0.9433 - accuracy: 0.5906\n",
      "Epoch 00110: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9433 - accuracy: 0.5906 - val_loss: 1.0082 - val_accuracy: 0.5041 - lr: 0.0295\n",
      "Epoch 111/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.9989 - accuracy: 0.53 - ETA: 0s - loss: 1.0005 - accuracy: 0.52 - ETA: 0s - loss: 0.9938 - accuracy: 0.53 - ETA: 0s - loss: 0.9630 - accuracy: 0.56 - ETA: 0s - loss: 0.9526 - accuracy: 0.56 - ETA: 0s - loss: 0.9375 - accuracy: 0.58 - ETA: 0s - loss: 0.9346 - accuracy: 0.59 - ETA: 0s - loss: 0.9329 - accuracy: 0.59 - ETA: 0s - loss: 0.9308 - accuracy: 0.59 - ETA: 0s - loss: 0.9393 - accuracy: 0.58 - ETA: 0s - loss: 0.9319 - accuracy: 0.59 - ETA: 0s - loss: 0.9196 - accuracy: 0.60 - ETA: 0s - loss: 0.9027 - accuracy: 0.62 - ETA: 0s - loss: 0.9150 - accuracy: 0.61 - ETA: 0s - loss: 0.9334 - accuracy: 0.59 - ETA: 0s - loss: 0.9359 - accuracy: 0.59 - ETA: 0s - loss: 0.9412 - accuracy: 0.59 - ETA: 0s - loss: 0.9417 - accuracy: 0.5907\n",
      "Epoch 00111: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9433 - accuracy: 0.5895 - val_loss: 1.0241 - val_accuracy: 0.5008 - lr: 0.0295\n",
      "Epoch 112/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.9970 - accuracy: 0.52 - ETA: 0s - loss: 0.9980 - accuracy: 0.51 - ETA: 0s - loss: 0.9913 - accuracy: 0.52 - ETA: 0s - loss: 0.9602 - accuracy: 0.55 - ETA: 0s - loss: 0.9507 - accuracy: 0.56 - ETA: 0s - loss: 0.9359 - accuracy: 0.58 - ETA: 0s - loss: 0.9320 - accuracy: 0.59 - ETA: 0s - loss: 0.9305 - accuracy: 0.59 - ETA: 0s - loss: 0.9288 - accuracy: 0.59 - ETA: 0s - loss: 0.9374 - accuracy: 0.58 - ETA: 0s - loss: 0.9303 - accuracy: 0.59 - ETA: 0s - loss: 0.9182 - accuracy: 0.60 - ETA: 0s - loss: 0.9012 - accuracy: 0.62 - ETA: 0s - loss: 0.9136 - accuracy: 0.61 - ETA: 0s - loss: 0.9319 - accuracy: 0.59 - ETA: 0s - loss: 0.9348 - accuracy: 0.59 - ETA: 0s - loss: 0.9399 - accuracy: 0.59 - ETA: 0s - loss: 0.9403 - accuracy: 0.5912\n",
      "Epoch 00112: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9417 - accuracy: 0.5900 - val_loss: 1.0222 - val_accuracy: 0.4992 - lr: 0.0295\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9987 - accuracy: 0.52 - ETA: 0s - loss: 1.0002 - accuracy: 0.51 - ETA: 0s - loss: 0.9613 - accuracy: 0.55 - ETA: 0s - loss: 0.9515 - accuracy: 0.56 - ETA: 0s - loss: 0.9367 - accuracy: 0.58 - ETA: 0s - loss: 0.9331 - accuracy: 0.58 - ETA: 0s - loss: 0.9320 - accuracy: 0.59 - ETA: 0s - loss: 0.9302 - accuracy: 0.59 - ETA: 0s - loss: 0.9383 - accuracy: 0.58 - ETA: 0s - loss: 0.9309 - accuracy: 0.59 - ETA: 0s - loss: 0.9188 - accuracy: 0.60 - ETA: 0s - loss: 0.9021 - accuracy: 0.62 - ETA: 0s - loss: 0.9145 - accuracy: 0.61 - ETA: 0s - loss: 0.9327 - accuracy: 0.59 - ETA: 0s - loss: 0.9351 - accuracy: 0.59 - ETA: 0s - loss: 0.9405 - accuracy: 0.59 - ETA: 0s - loss: 0.9409 - accuracy: 0.59 - ETA: 0s - loss: 0.9427 - accuracy: 0.5902\n",
      "Epoch 00113: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9427 - accuracy: 0.5902 - val_loss: 1.0218 - val_accuracy: 0.4979 - lr: 0.0295\n",
      "Epoch 114/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9993 - accuracy: 0.52 - ETA: 0s - loss: 1.0003 - accuracy: 0.51 - ETA: 0s - loss: 0.9937 - accuracy: 0.52 - ETA: 0s - loss: 0.9634 - accuracy: 0.55 - ETA: 0s - loss: 0.9534 - accuracy: 0.56 - ETA: 0s - loss: 0.9378 - accuracy: 0.58 - ETA: 0s - loss: 0.9341 - accuracy: 0.59 - ETA: 0s - loss: 0.9321 - accuracy: 0.59 - ETA: 0s - loss: 0.9300 - accuracy: 0.59 - ETA: 0s - loss: 0.9381 - accuracy: 0.58 - ETA: 0s - loss: 0.9302 - accuracy: 0.59 - ETA: 0s - loss: 0.9186 - accuracy: 0.60 - ETA: 0s - loss: 0.9014 - accuracy: 0.62 - ETA: 0s - loss: 0.9142 - accuracy: 0.61 - ETA: 0s - loss: 0.9326 - accuracy: 0.59 - ETA: 0s - loss: 0.9349 - accuracy: 0.59 - ETA: 0s - loss: 0.9403 - accuracy: 0.59 - ETA: 0s - loss: 0.9407 - accuracy: 0.59 - ETA: 0s - loss: 0.9421 - accuracy: 0.5900\n",
      "Epoch 00114: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9421 - accuracy: 0.5900 - val_loss: 1.0256 - val_accuracy: 0.4974 - lr: 0.0295\n",
      "Epoch 115/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9972 - accuracy: 0.52 - ETA: 0s - loss: 1.0005 - accuracy: 0.52 - ETA: 0s - loss: 0.9938 - accuracy: 0.53 - ETA: 0s - loss: 0.9639 - accuracy: 0.56 - ETA: 0s - loss: 0.9528 - accuracy: 0.57 - ETA: 0s - loss: 0.9374 - accuracy: 0.58 - ETA: 0s - loss: 0.9336 - accuracy: 0.59 - ETA: 0s - loss: 0.9324 - accuracy: 0.59 - ETA: 0s - loss: 0.9301 - accuracy: 0.59 - ETA: 0s - loss: 0.9386 - accuracy: 0.58 - ETA: 0s - loss: 0.9304 - accuracy: 0.59 - ETA: 0s - loss: 0.9184 - accuracy: 0.60 - ETA: 0s - loss: 0.9012 - accuracy: 0.62 - ETA: 0s - loss: 0.9140 - accuracy: 0.61 - ETA: 0s - loss: 0.9324 - accuracy: 0.59 - ETA: 0s - loss: 0.9347 - accuracy: 0.59 - ETA: 0s - loss: 0.9404 - accuracy: 0.59 - ETA: 0s - loss: 0.9425 - accuracy: 0.5900\n",
      "Epoch 00115: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9425 - accuracy: 0.5900 - val_loss: 1.0433 - val_accuracy: 0.4974 - lr: 0.0295\n",
      "Epoch 116/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9987 - accuracy: 0.53 - ETA: 0s - loss: 1.0007 - accuracy: 0.52 - ETA: 0s - loss: 0.9927 - accuracy: 0.53 - ETA: 0s - loss: 0.9630 - accuracy: 0.56 - ETA: 0s - loss: 0.9526 - accuracy: 0.57 - ETA: 0s - loss: 0.9371 - accuracy: 0.58 - ETA: 0s - loss: 0.9325 - accuracy: 0.59 - ETA: 0s - loss: 0.9314 - accuracy: 0.59 - ETA: 0s - loss: 0.9298 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.58 - ETA: 0s - loss: 0.9304 - accuracy: 0.59 - ETA: 0s - loss: 0.9184 - accuracy: 0.60 - ETA: 0s - loss: 0.9014 - accuracy: 0.62 - ETA: 0s - loss: 0.9141 - accuracy: 0.61 - ETA: 0s - loss: 0.9326 - accuracy: 0.59 - ETA: 0s - loss: 0.9349 - accuracy: 0.59 - ETA: 0s - loss: 0.9403 - accuracy: 0.59 - ETA: 0s - loss: 0.9423 - accuracy: 0.5909\n",
      "Epoch 00116: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9423 - accuracy: 0.5909 - val_loss: 1.0296 - val_accuracy: 0.4972 - lr: 0.0295\n",
      "Epoch 117/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0018 - accuracy: 0.52 - ETA: 0s - loss: 1.0029 - accuracy: 0.51 - ETA: 0s - loss: 0.9938 - accuracy: 0.52 - ETA: 0s - loss: 0.9630 - accuracy: 0.55 - ETA: 0s - loss: 0.9521 - accuracy: 0.56 - ETA: 0s - loss: 0.9363 - accuracy: 0.58 - ETA: 0s - loss: 0.9323 - accuracy: 0.59 - ETA: 0s - loss: 0.9305 - accuracy: 0.59 - ETA: 0s - loss: 0.9284 - accuracy: 0.59 - ETA: 0s - loss: 0.9370 - accuracy: 0.58 - ETA: 0s - loss: 0.9299 - accuracy: 0.59 - ETA: 0s - loss: 0.9179 - accuracy: 0.60 - ETA: 0s - loss: 0.9008 - accuracy: 0.62 - ETA: 0s - loss: 0.9133 - accuracy: 0.61 - ETA: 0s - loss: 0.9316 - accuracy: 0.59 - ETA: 0s - loss: 0.9392 - accuracy: 0.59 - ETA: 0s - loss: 0.9397 - accuracy: 0.59 - ETA: 0s - loss: 0.9413 - accuracy: 0.5891\n",
      "Epoch 00117: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9413 - accuracy: 0.5891 - val_loss: 1.0270 - val_accuracy: 0.4974 - lr: 0.0295\n",
      "Epoch 118/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0007 - accuracy: 0.52 - ETA: 0s - loss: 1.0018 - accuracy: 0.52 - ETA: 0s - loss: 0.9930 - accuracy: 0.53 - ETA: 0s - loss: 0.9632 - accuracy: 0.56 - ETA: 0s - loss: 0.9524 - accuracy: 0.57 - ETA: 0s - loss: 0.9363 - accuracy: 0.58 - ETA: 0s - loss: 0.9319 - accuracy: 0.59 - ETA: 0s - loss: 0.9303 - accuracy: 0.59 - ETA: 0s - loss: 0.9283 - accuracy: 0.59 - ETA: 0s - loss: 0.9363 - accuracy: 0.58 - ETA: 0s - loss: 0.9288 - accuracy: 0.59 - ETA: 0s - loss: 0.9171 - accuracy: 0.60 - ETA: 0s - loss: 0.9001 - accuracy: 0.62 - ETA: 0s - loss: 0.9126 - accuracy: 0.61 - ETA: 0s - loss: 0.9314 - accuracy: 0.59 - ETA: 0s - loss: 0.9337 - accuracy: 0.59 - ETA: 0s - loss: 0.9393 - accuracy: 0.59 - ETA: 0s - loss: 0.9398 - accuracy: 0.59 - ETA: 0s - loss: 0.9413 - accuracy: 0.5901\n",
      "Epoch 00118: val_loss did not improve from 0.99970\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 0.023592960834503175.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9413 - accuracy: 0.5901 - val_loss: 1.0187 - val_accuracy: 0.4971 - lr: 0.0295\n",
      "Epoch 119/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0010 - accuracy: 0.53 - ETA: 0s - loss: 1.0010 - accuracy: 0.52 - ETA: 0s - loss: 0.9927 - accuracy: 0.53 - ETA: 0s - loss: 0.9614 - accuracy: 0.56 - ETA: 0s - loss: 0.9496 - accuracy: 0.57 - ETA: 0s - loss: 0.9336 - accuracy: 0.58 - ETA: 0s - loss: 0.9291 - accuracy: 0.59 - ETA: 0s - loss: 0.9279 - accuracy: 0.59 - ETA: 0s - loss: 0.9269 - accuracy: 0.59 - ETA: 0s - loss: 0.9351 - accuracy: 0.58 - ETA: 0s - loss: 0.9281 - accuracy: 0.59 - ETA: 0s - loss: 0.9163 - accuracy: 0.60 - ETA: 0s - loss: 0.8991 - accuracy: 0.62 - ETA: 0s - loss: 0.9120 - accuracy: 0.61 - ETA: 0s - loss: 0.9300 - accuracy: 0.59 - ETA: 0s - loss: 0.9378 - accuracy: 0.59 - ETA: 0s - loss: 0.9386 - accuracy: 0.59 - ETA: 0s - loss: 0.9402 - accuracy: 0.5896\n",
      "Epoch 00119: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9402 - accuracy: 0.5896 - val_loss: 1.0152 - val_accuracy: 0.4969 - lr: 0.0236\n",
      "Epoch 120/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0007 - accuracy: 0.53 - ETA: 0s - loss: 1.0007 - accuracy: 0.52 - ETA: 0s - loss: 0.9922 - accuracy: 0.53 - ETA: 0s - loss: 0.9615 - accuracy: 0.56 - ETA: 0s - loss: 0.9507 - accuracy: 0.57 - ETA: 0s - loss: 0.9347 - accuracy: 0.58 - ETA: 0s - loss: 0.9306 - accuracy: 0.59 - ETA: 0s - loss: 0.9285 - accuracy: 0.59 - ETA: 0s - loss: 0.9268 - accuracy: 0.59 - ETA: 0s - loss: 0.9355 - accuracy: 0.58 - ETA: 0s - loss: 0.9282 - accuracy: 0.59 - ETA: 0s - loss: 0.9163 - accuracy: 0.60 - ETA: 0s - loss: 0.8995 - accuracy: 0.62 - ETA: 0s - loss: 0.9126 - accuracy: 0.61 - ETA: 0s - loss: 0.9311 - accuracy: 0.59 - ETA: 0s - loss: 0.9337 - accuracy: 0.59 - ETA: 0s - loss: 0.9392 - accuracy: 0.59 - ETA: 0s - loss: 0.9399 - accuracy: 0.59 - ETA: 0s - loss: 0.9415 - accuracy: 0.5904\n",
      "Epoch 00120: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9415 - accuracy: 0.5904 - val_loss: 1.0078 - val_accuracy: 0.4992 - lr: 0.0236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0012 - accuracy: 0.52 - ETA: 0s - loss: 1.0033 - accuracy: 0.51 - ETA: 0s - loss: 0.9947 - accuracy: 0.53 - ETA: 0s - loss: 0.9633 - accuracy: 0.56 - ETA: 0s - loss: 0.9515 - accuracy: 0.57 - ETA: 0s - loss: 0.9366 - accuracy: 0.58 - ETA: 0s - loss: 0.9329 - accuracy: 0.59 - ETA: 0s - loss: 0.9315 - accuracy: 0.59 - ETA: 0s - loss: 0.9293 - accuracy: 0.59 - ETA: 0s - loss: 0.9372 - accuracy: 0.58 - ETA: 0s - loss: 0.9300 - accuracy: 0.59 - ETA: 0s - loss: 0.9178 - accuracy: 0.60 - ETA: 0s - loss: 0.9010 - accuracy: 0.62 - ETA: 0s - loss: 0.9132 - accuracy: 0.61 - ETA: 0s - loss: 0.9317 - accuracy: 0.59 - ETA: 0s - loss: 0.9341 - accuracy: 0.59 - ETA: 0s - loss: 0.9391 - accuracy: 0.59 - ETA: 0s - loss: 0.9396 - accuracy: 0.59 - ETA: 0s - loss: 0.9409 - accuracy: 0.5902\n",
      "Epoch 00121: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9409 - accuracy: 0.5902 - val_loss: 1.0094 - val_accuracy: 0.4989 - lr: 0.0236\n",
      "Epoch 122/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9995 - accuracy: 0.52 - ETA: 0s - loss: 1.0015 - accuracy: 0.51 - ETA: 0s - loss: 0.9931 - accuracy: 0.53 - ETA: 0s - loss: 0.9620 - accuracy: 0.56 - ETA: 0s - loss: 0.9509 - accuracy: 0.57 - ETA: 0s - loss: 0.9351 - accuracy: 0.58 - ETA: 0s - loss: 0.9306 - accuracy: 0.59 - ETA: 0s - loss: 0.9289 - accuracy: 0.59 - ETA: 0s - loss: 0.9271 - accuracy: 0.59 - ETA: 0s - loss: 0.9354 - accuracy: 0.58 - ETA: 0s - loss: 0.9283 - accuracy: 0.59 - ETA: 0s - loss: 0.9160 - accuracy: 0.60 - ETA: 0s - loss: 0.8988 - accuracy: 0.62 - ETA: 0s - loss: 0.9122 - accuracy: 0.61 - ETA: 0s - loss: 0.9303 - accuracy: 0.59 - ETA: 0s - loss: 0.9329 - accuracy: 0.59 - ETA: 0s - loss: 0.9383 - accuracy: 0.59 - ETA: 0s - loss: 0.9390 - accuracy: 0.59 - ETA: 0s - loss: 0.9405 - accuracy: 0.5897\n",
      "Epoch 00122: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9405 - accuracy: 0.5897 - val_loss: 1.0239 - val_accuracy: 0.4974 - lr: 0.0236\n",
      "Epoch 123/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0037 - accuracy: 0.52 - ETA: 0s - loss: 1.0044 - accuracy: 0.52 - ETA: 0s - loss: 0.9936 - accuracy: 0.53 - ETA: 0s - loss: 0.9621 - accuracy: 0.56 - ETA: 0s - loss: 0.9504 - accuracy: 0.57 - ETA: 0s - loss: 0.9343 - accuracy: 0.58 - ETA: 0s - loss: 0.9300 - accuracy: 0.59 - ETA: 0s - loss: 0.9291 - accuracy: 0.59 - ETA: 0s - loss: 0.9271 - accuracy: 0.59 - ETA: 0s - loss: 0.9355 - accuracy: 0.58 - ETA: 0s - loss: 0.9285 - accuracy: 0.59 - ETA: 0s - loss: 0.9158 - accuracy: 0.60 - ETA: 0s - loss: 0.8990 - accuracy: 0.62 - ETA: 0s - loss: 0.9119 - accuracy: 0.61 - ETA: 0s - loss: 0.9302 - accuracy: 0.59 - ETA: 0s - loss: 0.9324 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9397 - accuracy: 0.5906\n",
      "Epoch 00123: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9397 - accuracy: 0.5906 - val_loss: 1.0181 - val_accuracy: 0.4969 - lr: 0.0236\n",
      "Epoch 124/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0021 - accuracy: 0.52 - ETA: 0s - loss: 1.0006 - accuracy: 0.52 - ETA: 0s - loss: 0.9912 - accuracy: 0.53 - ETA: 0s - loss: 0.9613 - accuracy: 0.56 - ETA: 0s - loss: 0.9509 - accuracy: 0.56 - ETA: 0s - loss: 0.9351 - accuracy: 0.58 - ETA: 0s - loss: 0.9313 - accuracy: 0.59 - ETA: 0s - loss: 0.9305 - accuracy: 0.59 - ETA: 0s - loss: 0.9284 - accuracy: 0.59 - ETA: 0s - loss: 0.9364 - accuracy: 0.58 - ETA: 0s - loss: 0.9288 - accuracy: 0.59 - ETA: 0s - loss: 0.9169 - accuracy: 0.60 - ETA: 0s - loss: 0.9000 - accuracy: 0.62 - ETA: 0s - loss: 0.9123 - accuracy: 0.61 - ETA: 0s - loss: 0.9312 - accuracy: 0.59 - ETA: 0s - loss: 0.9333 - accuracy: 0.59 - ETA: 0s - loss: 0.9383 - accuracy: 0.59 - ETA: 0s - loss: 0.9386 - accuracy: 0.59 - ETA: 0s - loss: 0.9400 - accuracy: 0.5898\n",
      "Epoch 00124: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9400 - accuracy: 0.5898 - val_loss: 1.0161 - val_accuracy: 0.4972 - lr: 0.0236\n",
      "Epoch 125/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0038 - accuracy: 0.53 - ETA: 0s - loss: 1.0020 - accuracy: 0.52 - ETA: 0s - loss: 0.9927 - accuracy: 0.53 - ETA: 0s - loss: 0.9629 - accuracy: 0.56 - ETA: 0s - loss: 0.9523 - accuracy: 0.57 - ETA: 0s - loss: 0.9358 - accuracy: 0.58 - ETA: 0s - loss: 0.9308 - accuracy: 0.59 - ETA: 0s - loss: 0.9294 - accuracy: 0.59 - ETA: 0s - loss: 0.9280 - accuracy: 0.59 - ETA: 0s - loss: 0.9362 - accuracy: 0.58 - ETA: 0s - loss: 0.9290 - accuracy: 0.59 - ETA: 0s - loss: 0.9169 - accuracy: 0.60 - ETA: 0s - loss: 0.8998 - accuracy: 0.62 - ETA: 0s - loss: 0.9120 - accuracy: 0.61 - ETA: 0s - loss: 0.9301 - accuracy: 0.59 - ETA: 0s - loss: 0.9326 - accuracy: 0.59 - ETA: 0s - loss: 0.9383 - accuracy: 0.59 - ETA: 0s - loss: 0.9397 - accuracy: 0.5909\n",
      "Epoch 00125: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9397 - accuracy: 0.5909 - val_loss: 1.0122 - val_accuracy: 0.4969 - lr: 0.0236\n",
      "Epoch 126/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0025 - accuracy: 0.53 - ETA: 0s - loss: 1.0025 - accuracy: 0.52 - ETA: 0s - loss: 0.9921 - accuracy: 0.53 - ETA: 0s - loss: 0.9627 - accuracy: 0.56 - ETA: 0s - loss: 0.9349 - accuracy: 0.58 - ETA: 0s - loss: 0.9296 - accuracy: 0.59 - ETA: 0s - loss: 0.9278 - accuracy: 0.59 - ETA: 0s - loss: 0.9270 - accuracy: 0.59 - ETA: 0s - loss: 0.9353 - accuracy: 0.58 - ETA: 0s - loss: 0.9276 - accuracy: 0.59 - ETA: 0s - loss: 0.9155 - accuracy: 0.60 - ETA: 0s - loss: 0.8985 - accuracy: 0.62 - ETA: 0s - loss: 0.9111 - accuracy: 0.61 - ETA: 0s - loss: 0.9296 - accuracy: 0.59 - ETA: 0s - loss: 0.9322 - accuracy: 0.59 - ETA: 0s - loss: 0.9372 - accuracy: 0.59 - ETA: 0s - loss: 0.9380 - accuracy: 0.59 - ETA: 0s - loss: 0.9396 - accuracy: 0.5890\n",
      "Epoch 00126: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9396 - accuracy: 0.5890 - val_loss: 1.0135 - val_accuracy: 0.4995 - lr: 0.0236\n",
      "Epoch 127/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9984 - accuracy: 0.53 - ETA: 0s - loss: 0.9987 - accuracy: 0.52 - ETA: 0s - loss: 0.9889 - accuracy: 0.53 - ETA: 0s - loss: 0.9590 - accuracy: 0.56 - ETA: 0s - loss: 0.9490 - accuracy: 0.57 - ETA: 0s - loss: 0.9333 - accuracy: 0.58 - ETA: 0s - loss: 0.9292 - accuracy: 0.59 - ETA: 0s - loss: 0.9274 - accuracy: 0.59 - ETA: 0s - loss: 0.9257 - accuracy: 0.59 - ETA: 0s - loss: 0.9346 - accuracy: 0.58 - ETA: 0s - loss: 0.9276 - accuracy: 0.59 - ETA: 0s - loss: 0.9159 - accuracy: 0.60 - ETA: 0s - loss: 0.8990 - accuracy: 0.62 - ETA: 0s - loss: 0.9299 - accuracy: 0.59 - ETA: 0s - loss: 0.9324 - accuracy: 0.59 - ETA: 0s - loss: 0.9377 - accuracy: 0.59 - ETA: 0s - loss: 0.9383 - accuracy: 0.59 - ETA: 0s - loss: 0.9398 - accuracy: 0.5898\n",
      "Epoch 00127: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9398 - accuracy: 0.5898 - val_loss: 1.0094 - val_accuracy: 0.5007 - lr: 0.0236\n",
      "Epoch 128/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 1.0016 - accuracy: 0.52 - ETA: 0s - loss: 0.9922 - accuracy: 0.53 - ETA: 0s - loss: 0.9612 - accuracy: 0.56 - ETA: 0s - loss: 0.9495 - accuracy: 0.57 - ETA: 0s - loss: 0.9339 - accuracy: 0.58 - ETA: 0s - loss: 0.9295 - accuracy: 0.59 - ETA: 0s - loss: 0.9281 - accuracy: 0.59 - ETA: 0s - loss: 0.9265 - accuracy: 0.59 - ETA: 0s - loss: 0.9349 - accuracy: 0.59 - ETA: 0s - loss: 0.9276 - accuracy: 0.59 - ETA: 0s - loss: 0.9159 - accuracy: 0.61 - ETA: 0s - loss: 0.8991 - accuracy: 0.62 - ETA: 0s - loss: 0.9114 - accuracy: 0.61 - ETA: 0s - loss: 0.9297 - accuracy: 0.59 - ETA: 0s - loss: 0.9319 - accuracy: 0.59 - ETA: 0s - loss: 0.9371 - accuracy: 0.59 - ETA: 0s - loss: 0.9377 - accuracy: 0.5929\n",
      "Epoch 00128: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9393 - accuracy: 0.5918 - val_loss: 1.0137 - val_accuracy: 0.4985 - lr: 0.0236\n",
      "Epoch 129/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9987 - accuracy: 0.53 - ETA: 0s - loss: 0.9993 - accuracy: 0.52 - ETA: 0s - loss: 0.9900 - accuracy: 0.53 - ETA: 0s - loss: 0.9601 - accuracy: 0.56 - ETA: 0s - loss: 0.9495 - accuracy: 0.57 - ETA: 0s - loss: 0.9343 - accuracy: 0.58 - ETA: 0s - loss: 0.9293 - accuracy: 0.59 - ETA: 0s - loss: 0.9279 - accuracy: 0.59 - ETA: 0s - loss: 0.9261 - accuracy: 0.59 - ETA: 0s - loss: 0.9351 - accuracy: 0.58 - ETA: 0s - loss: 0.9279 - accuracy: 0.59 - ETA: 0s - loss: 0.9158 - accuracy: 0.60 - ETA: 0s - loss: 0.8987 - accuracy: 0.62 - ETA: 0s - loss: 0.9113 - accuracy: 0.61 - ETA: 0s - loss: 0.9299 - accuracy: 0.59 - ETA: 0s - loss: 0.9325 - accuracy: 0.59 - ETA: 0s - loss: 0.9377 - accuracy: 0.59 - ETA: 0s - loss: 0.9384 - accuracy: 0.59 - ETA: 0s - loss: 0.9399 - accuracy: 0.5920\n",
      "Epoch 00129: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9399 - accuracy: 0.5920 - val_loss: 1.0109 - val_accuracy: 0.5003 - lr: 0.0236\n",
      "Epoch 130/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0000 - accuracy: 0.53 - ETA: 0s - loss: 0.9972 - accuracy: 0.52 - ETA: 0s - loss: 0.9900 - accuracy: 0.53 - ETA: 0s - loss: 0.9603 - accuracy: 0.56 - ETA: 0s - loss: 0.9499 - accuracy: 0.57 - ETA: 0s - loss: 0.9336 - accuracy: 0.58 - ETA: 0s - loss: 0.9290 - accuracy: 0.59 - ETA: 0s - loss: 0.9258 - accuracy: 0.59 - ETA: 0s - loss: 0.9345 - accuracy: 0.59 - ETA: 0s - loss: 0.9276 - accuracy: 0.59 - ETA: 0s - loss: 0.9159 - accuracy: 0.60 - ETA: 0s - loss: 0.8990 - accuracy: 0.62 - ETA: 0s - loss: 0.9112 - accuracy: 0.61 - ETA: 0s - loss: 0.9295 - accuracy: 0.59 - ETA: 0s - loss: 0.9321 - accuracy: 0.59 - ETA: 0s - loss: 0.9374 - accuracy: 0.59 - ETA: 0s - loss: 0.9379 - accuracy: 0.59 - ETA: 0s - loss: 0.9392 - accuracy: 0.5916\n",
      "Epoch 00130: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9392 - accuracy: 0.5916 - val_loss: 1.0153 - val_accuracy: 0.4993 - lr: 0.0236\n",
      "Epoch 131/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0001 - accuracy: 0.53 - ETA: 0s - loss: 0.9981 - accuracy: 0.52 - ETA: 0s - loss: 0.9918 - accuracy: 0.53 - ETA: 0s - loss: 0.9610 - accuracy: 0.56 - ETA: 0s - loss: 0.9501 - accuracy: 0.57 - ETA: 0s - loss: 0.9337 - accuracy: 0.58 - ETA: 0s - loss: 0.9291 - accuracy: 0.59 - ETA: 0s - loss: 0.9272 - accuracy: 0.59 - ETA: 0s - loss: 0.9260 - accuracy: 0.59 - ETA: 0s - loss: 0.9345 - accuracy: 0.58 - ETA: 0s - loss: 0.9272 - accuracy: 0.59 - ETA: 0s - loss: 0.9155 - accuracy: 0.60 - ETA: 0s - loss: 0.8984 - accuracy: 0.62 - ETA: 0s - loss: 0.9108 - accuracy: 0.61 - ETA: 0s - loss: 0.9288 - accuracy: 0.59 - ETA: 0s - loss: 0.9365 - accuracy: 0.59 - ETA: 0s - loss: 0.9372 - accuracy: 0.59 - ETA: 0s - loss: 0.9388 - accuracy: 0.5904\n",
      "Epoch 00131: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9388 - accuracy: 0.5904 - val_loss: 1.0188 - val_accuracy: 0.4982 - lr: 0.0236\n",
      "Epoch 132/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0021 - accuracy: 0.53 - ETA: 0s - loss: 1.0007 - accuracy: 0.52 - ETA: 0s - loss: 0.9915 - accuracy: 0.53 - ETA: 0s - loss: 0.9605 - accuracy: 0.56 - ETA: 0s - loss: 0.9494 - accuracy: 0.57 - ETA: 0s - loss: 0.9331 - accuracy: 0.58 - ETA: 0s - loss: 0.9284 - accuracy: 0.59 - ETA: 0s - loss: 0.9263 - accuracy: 0.59 - ETA: 0s - loss: 0.9243 - accuracy: 0.59 - ETA: 0s - loss: 0.9330 - accuracy: 0.59 - ETA: 0s - loss: 0.9258 - accuracy: 0.59 - ETA: 0s - loss: 0.9143 - accuracy: 0.60 - ETA: 0s - loss: 0.8972 - accuracy: 0.62 - ETA: 0s - loss: 0.9098 - accuracy: 0.61 - ETA: 0s - loss: 0.9283 - accuracy: 0.59 - ETA: 0s - loss: 0.9304 - accuracy: 0.59 - ETA: 0s - loss: 0.9358 - accuracy: 0.59 - ETA: 0s - loss: 0.9361 - accuracy: 0.59 - ETA: 0s - loss: 0.9378 - accuracy: 0.5909\n",
      "Epoch 00132: val_loss did not improve from 0.99970\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 0.018874368071556093.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9378 - accuracy: 0.5909 - val_loss: 1.0218 - val_accuracy: 0.4971 - lr: 0.0236\n",
      "Epoch 133/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0011 - accuracy: 0.53 - ETA: 0s - loss: 1.0033 - accuracy: 0.52 - ETA: 0s - loss: 0.9933 - accuracy: 0.53 - ETA: 0s - loss: 0.9619 - accuracy: 0.56 - ETA: 0s - loss: 0.9517 - accuracy: 0.57 - ETA: 0s - loss: 0.9356 - accuracy: 0.58 - ETA: 0s - loss: 0.9306 - accuracy: 0.59 - ETA: 0s - loss: 0.9291 - accuracy: 0.59 - ETA: 0s - loss: 0.9269 - accuracy: 0.59 - ETA: 0s - loss: 0.9355 - accuracy: 0.59 - ETA: 0s - loss: 0.9279 - accuracy: 0.59 - ETA: 0s - loss: 0.9160 - accuracy: 0.60 - ETA: 0s - loss: 0.8988 - accuracy: 0.62 - ETA: 0s - loss: 0.9110 - accuracy: 0.61 - ETA: 0s - loss: 0.9294 - accuracy: 0.59 - ETA: 0s - loss: 0.9317 - accuracy: 0.59 - ETA: 0s - loss: 0.9370 - accuracy: 0.59 - ETA: 0s - loss: 0.9376 - accuracy: 0.59 - ETA: 0s - loss: 0.9394 - accuracy: 0.5902\n",
      "Epoch 00133: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9394 - accuracy: 0.5902 - val_loss: 1.0079 - val_accuracy: 0.4990 - lr: 0.0189\n",
      "Epoch 134/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.9987 - accuracy: 0.53 - ETA: 0s - loss: 0.9990 - accuracy: 0.52 - ETA: 0s - loss: 0.9906 - accuracy: 0.53 - ETA: 0s - loss: 0.9590 - accuracy: 0.56 - ETA: 0s - loss: 0.9479 - accuracy: 0.57 - ETA: 0s - loss: 0.9318 - accuracy: 0.58 - ETA: 0s - loss: 0.9270 - accuracy: 0.59 - ETA: 0s - loss: 0.9261 - accuracy: 0.59 - ETA: 0s - loss: 0.9245 - accuracy: 0.59 - ETA: 0s - loss: 0.9332 - accuracy: 0.58 - ETA: 0s - loss: 0.9261 - accuracy: 0.59 - ETA: 0s - loss: 0.9142 - accuracy: 0.60 - ETA: 0s - loss: 0.8973 - accuracy: 0.62 - ETA: 0s - loss: 0.9097 - accuracy: 0.61 - ETA: 0s - loss: 0.9283 - accuracy: 0.59 - ETA: 0s - loss: 0.9309 - accuracy: 0.59 - ETA: 0s - loss: 0.9359 - accuracy: 0.59 - ETA: 0s - loss: 0.9365 - accuracy: 0.5920\n",
      "Epoch 00134: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9382 - accuracy: 0.5903 - val_loss: 1.0036 - val_accuracy: 0.5036 - lr: 0.0189\n",
      "Epoch 135/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9997 - accuracy: 0.52 - ETA: 0s - loss: 0.9990 - accuracy: 0.52 - ETA: 0s - loss: 0.9894 - accuracy: 0.53 - ETA: 0s - loss: 0.9576 - accuracy: 0.56 - ETA: 0s - loss: 0.9466 - accuracy: 0.57 - ETA: 0s - loss: 0.9307 - accuracy: 0.58 - ETA: 0s - loss: 0.9260 - accuracy: 0.59 - ETA: 0s - loss: 0.9246 - accuracy: 0.59 - ETA: 0s - loss: 0.9231 - accuracy: 0.59 - ETA: 0s - loss: 0.9323 - accuracy: 0.59 - ETA: 0s - loss: 0.9254 - accuracy: 0.59 - ETA: 0s - loss: 0.9133 - accuracy: 0.61 - ETA: 0s - loss: 0.8964 - accuracy: 0.62 - ETA: 0s - loss: 0.9085 - accuracy: 0.61 - ETA: 0s - loss: 0.9266 - accuracy: 0.59 - ETA: 0s - loss: 0.9292 - accuracy: 0.59 - ETA: 0s - loss: 0.9345 - accuracy: 0.59 - ETA: 0s - loss: 0.9352 - accuracy: 0.59 - ETA: 0s - loss: 0.9370 - accuracy: 0.5919\n",
      "Epoch 00135: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9370 - accuracy: 0.5919 - val_loss: 1.0057 - val_accuracy: 0.5015 - lr: 0.0189\n",
      "Epoch 136/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0008 - accuracy: 0.53 - ETA: 0s - loss: 0.9980 - accuracy: 0.52 - ETA: 0s - loss: 0.9875 - accuracy: 0.53 - ETA: 0s - loss: 0.9568 - accuracy: 0.56 - ETA: 0s - loss: 0.9464 - accuracy: 0.57 - ETA: 0s - loss: 0.9300 - accuracy: 0.58 - ETA: 0s - loss: 0.9256 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.59 - ETA: 0s - loss: 0.9225 - accuracy: 0.59 - ETA: 0s - loss: 0.9314 - accuracy: 0.59 - ETA: 0s - loss: 0.9252 - accuracy: 0.59 - ETA: 0s - loss: 0.9137 - accuracy: 0.60 - ETA: 0s - loss: 0.8967 - accuracy: 0.62 - ETA: 0s - loss: 0.9091 - accuracy: 0.61 - ETA: 0s - loss: 0.9276 - accuracy: 0.59 - ETA: 0s - loss: 0.9300 - accuracy: 0.59 - ETA: 0s - loss: 0.9355 - accuracy: 0.59 - ETA: 0s - loss: 0.9373 - accuracy: 0.5918\n",
      "Epoch 00136: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9373 - accuracy: 0.5918 - val_loss: 1.0047 - val_accuracy: 0.4990 - lr: 0.0189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9988 - accuracy: 0.53 - ETA: 0s - loss: 0.9981 - accuracy: 0.52 - ETA: 0s - loss: 0.9874 - accuracy: 0.53 - ETA: 0s - loss: 0.9571 - accuracy: 0.56 - ETA: 0s - loss: 0.9473 - accuracy: 0.57 - ETA: 0s - loss: 0.9316 - accuracy: 0.58 - ETA: 0s - loss: 0.9282 - accuracy: 0.59 - ETA: 0s - loss: 0.9263 - accuracy: 0.59 - ETA: 0s - loss: 0.9243 - accuracy: 0.59 - ETA: 0s - loss: 0.9328 - accuracy: 0.58 - ETA: 0s - loss: 0.9255 - accuracy: 0.59 - ETA: 0s - loss: 0.9138 - accuracy: 0.60 - ETA: 0s - loss: 0.8964 - accuracy: 0.62 - ETA: 0s - loss: 0.9088 - accuracy: 0.61 - ETA: 0s - loss: 0.9296 - accuracy: 0.59 - ETA: 0s - loss: 0.9349 - accuracy: 0.59 - ETA: 0s - loss: 0.9358 - accuracy: 0.59 - ETA: 0s - loss: 0.9376 - accuracy: 0.5918\n",
      "Epoch 00137: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9376 - accuracy: 0.5918 - val_loss: 1.0011 - val_accuracy: 0.5042 - lr: 0.0189\n",
      "Epoch 138/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0003 - accuracy: 0.53 - ETA: 0s - loss: 0.9980 - accuracy: 0.53 - ETA: 0s - loss: 0.9893 - accuracy: 0.53 - ETA: 0s - loss: 0.9580 - accuracy: 0.56 - ETA: 0s - loss: 0.9473 - accuracy: 0.57 - ETA: 0s - loss: 0.9313 - accuracy: 0.58 - ETA: 0s - loss: 0.9271 - accuracy: 0.59 - ETA: 0s - loss: 0.9251 - accuracy: 0.59 - ETA: 0s - loss: 0.9232 - accuracy: 0.59 - ETA: 0s - loss: 0.9324 - accuracy: 0.59 - ETA: 0s - loss: 0.9255 - accuracy: 0.59 - ETA: 0s - loss: 0.9135 - accuracy: 0.60 - ETA: 0s - loss: 0.8963 - accuracy: 0.62 - ETA: 0s - loss: 0.9091 - accuracy: 0.61 - ETA: 0s - loss: 0.9273 - accuracy: 0.59 - ETA: 0s - loss: 0.9295 - accuracy: 0.59 - ETA: 0s - loss: 0.9348 - accuracy: 0.59 - ETA: 0s - loss: 0.9371 - accuracy: 0.5921\n",
      "Epoch 00138: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9371 - accuracy: 0.5921 - val_loss: 1.0011 - val_accuracy: 0.5033 - lr: 0.0189\n",
      "Epoch 139/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0030 - accuracy: 0.53 - ETA: 0s - loss: 0.9993 - accuracy: 0.52 - ETA: 0s - loss: 0.9904 - accuracy: 0.53 - ETA: 0s - loss: 0.9593 - accuracy: 0.56 - ETA: 0s - loss: 0.9480 - accuracy: 0.57 - ETA: 0s - loss: 0.9317 - accuracy: 0.58 - ETA: 0s - loss: 0.9268 - accuracy: 0.59 - ETA: 0s - loss: 0.9251 - accuracy: 0.59 - ETA: 0s - loss: 0.9235 - accuracy: 0.59 - ETA: 0s - loss: 0.9328 - accuracy: 0.59 - ETA: 0s - loss: 0.9259 - accuracy: 0.59 - ETA: 0s - loss: 0.9142 - accuracy: 0.60 - ETA: 0s - loss: 0.8972 - accuracy: 0.62 - ETA: 0s - loss: 0.9096 - accuracy: 0.61 - ETA: 0s - loss: 0.9281 - accuracy: 0.59 - ETA: 0s - loss: 0.9302 - accuracy: 0.59 - ETA: 0s - loss: 0.9357 - accuracy: 0.59 - ETA: 0s - loss: 0.9364 - accuracy: 0.5922\n",
      "Epoch 00139: val_loss did not improve from 0.99970\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9378 - accuracy: 0.5911 - val_loss: 1.0035 - val_accuracy: 0.5020 - lr: 0.0189\n",
      "Epoch 140/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9992 - accuracy: 0.54 - ETA: 0s - loss: 0.9967 - accuracy: 0.53 - ETA: 0s - loss: 0.9882 - accuracy: 0.54 - ETA: 0s - loss: 0.9578 - accuracy: 0.56 - ETA: 0s - loss: 0.9466 - accuracy: 0.57 - ETA: 0s - loss: 0.9296 - accuracy: 0.58 - ETA: 0s - loss: 0.9245 - accuracy: 0.59 - ETA: 0s - loss: 0.9228 - accuracy: 0.59 - ETA: 0s - loss: 0.9210 - accuracy: 0.59 - ETA: 0s - loss: 0.9300 - accuracy: 0.58 - ETA: 0s - loss: 0.9230 - accuracy: 0.59 - ETA: 0s - loss: 0.9109 - accuracy: 0.60 - ETA: 0s - loss: 0.8937 - accuracy: 0.62 - ETA: 0s - loss: 0.9067 - accuracy: 0.61 - ETA: 0s - loss: 0.9250 - accuracy: 0.59 - ETA: 0s - loss: 0.9276 - accuracy: 0.59 - ETA: 0s - loss: 0.9330 - accuracy: 0.59 - ETA: 0s - loss: 0.9335 - accuracy: 0.59 - ETA: 0s - loss: 0.9348 - accuracy: 0.5917\n",
      "Epoch 00140: val_loss improved from 0.99970 to 0.99394, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 1s 74ms/step - loss: 0.9348 - accuracy: 0.5917 - val_loss: 0.9939 - val_accuracy: 0.5044 - lr: 0.0189\n",
      "Epoch 141/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0014 - accuracy: 0.54 - ETA: 0s - loss: 0.9939 - accuracy: 0.53 - ETA: 0s - loss: 0.9856 - accuracy: 0.54 - ETA: 0s - loss: 0.9560 - accuracy: 0.57 - ETA: 0s - loss: 0.9459 - accuracy: 0.57 - ETA: 0s - loss: 0.9240 - accuracy: 0.60 - ETA: 0s - loss: 0.9221 - accuracy: 0.60 - ETA: 0s - loss: 0.9208 - accuracy: 0.60 - ETA: 0s - loss: 0.9300 - accuracy: 0.59 - ETA: 0s - loss: 0.9235 - accuracy: 0.60 - ETA: 0s - loss: 0.9117 - accuracy: 0.61 - ETA: 0s - loss: 0.8949 - accuracy: 0.62 - ETA: 0s - loss: 0.9078 - accuracy: 0.61 - ETA: 0s - loss: 0.9268 - accuracy: 0.60 - ETA: 0s - loss: 0.9287 - accuracy: 0.59 - ETA: 0s - loss: 0.9342 - accuracy: 0.59 - ETA: 0s - loss: 0.9348 - accuracy: 0.59 - ETA: 0s - loss: 0.9361 - accuracy: 0.5938\n",
      "Epoch 00141: val_loss did not improve from 0.99394\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9361 - accuracy: 0.5938 - val_loss: 0.9953 - val_accuracy: 0.5067 - lr: 0.0189\n",
      "Epoch 142/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9961 - accuracy: 0.54 - ETA: 0s - loss: 0.9951 - accuracy: 0.53 - ETA: 0s - loss: 0.9850 - accuracy: 0.53 - ETA: 0s - loss: 0.9549 - accuracy: 0.56 - ETA: 0s - loss: 0.9437 - accuracy: 0.57 - ETA: 0s - loss: 0.9283 - accuracy: 0.58 - ETA: 0s - loss: 0.9253 - accuracy: 0.59 - ETA: 0s - loss: 0.9236 - accuracy: 0.59 - ETA: 0s - loss: 0.9216 - accuracy: 0.59 - ETA: 0s - loss: 0.9306 - accuracy: 0.58 - ETA: 0s - loss: 0.9235 - accuracy: 0.59 - ETA: 0s - loss: 0.9120 - accuracy: 0.60 - ETA: 0s - loss: 0.8949 - accuracy: 0.62 - ETA: 0s - loss: 0.9083 - accuracy: 0.61 - ETA: 0s - loss: 0.9267 - accuracy: 0.59 - ETA: 0s - loss: 0.9290 - accuracy: 0.59 - ETA: 0s - loss: 0.9342 - accuracy: 0.59 - ETA: 0s - loss: 0.9363 - accuracy: 0.5909\n",
      "Epoch 00142: val_loss did not improve from 0.99394\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9363 - accuracy: 0.5909 - val_loss: 1.0012 - val_accuracy: 0.5036 - lr: 0.0189\n",
      "Epoch 143/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0021 - accuracy: 0.53 - ETA: 0s - loss: 0.9975 - accuracy: 0.53 - ETA: 0s - loss: 0.9892 - accuracy: 0.53 - ETA: 0s - loss: 0.9587 - accuracy: 0.56 - ETA: 0s - loss: 0.9469 - accuracy: 0.57 - ETA: 0s - loss: 0.9297 - accuracy: 0.58 - ETA: 0s - loss: 0.9252 - accuracy: 0.59 - ETA: 0s - loss: 0.9232 - accuracy: 0.59 - ETA: 0s - loss: 0.9215 - accuracy: 0.59 - ETA: 0s - loss: 0.9307 - accuracy: 0.58 - ETA: 0s - loss: 0.9240 - accuracy: 0.59 - ETA: 0s - loss: 0.9127 - accuracy: 0.60 - ETA: 0s - loss: 0.8955 - accuracy: 0.62 - ETA: 0s - loss: 0.9089 - accuracy: 0.61 - ETA: 0s - loss: 0.9274 - accuracy: 0.59 - ETA: 0s - loss: 0.9292 - accuracy: 0.59 - ETA: 0s - loss: 0.9345 - accuracy: 0.59 - ETA: 0s - loss: 0.9350 - accuracy: 0.59 - ETA: 0s - loss: 0.9367 - accuracy: 0.5911\n",
      "Epoch 00143: val_loss did not improve from 0.99394\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9367 - accuracy: 0.5911 - val_loss: 1.0037 - val_accuracy: 0.5031 - lr: 0.0189\n",
      "Epoch 144/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0009 - accuracy: 0.53 - ETA: 0s - loss: 1.0043 - accuracy: 0.52 - ETA: 0s - loss: 0.9927 - accuracy: 0.53 - ETA: 0s - loss: 0.9603 - accuracy: 0.56 - ETA: 0s - loss: 0.9483 - accuracy: 0.57 - ETA: 0s - loss: 0.9319 - accuracy: 0.58 - ETA: 0s - loss: 0.9277 - accuracy: 0.59 - ETA: 0s - loss: 0.9253 - accuracy: 0.59 - ETA: 0s - loss: 0.9232 - accuracy: 0.59 - ETA: 0s - loss: 0.9321 - accuracy: 0.59 - ETA: 0s - loss: 0.9252 - accuracy: 0.59 - ETA: 0s - loss: 0.9135 - accuracy: 0.60 - ETA: 0s - loss: 0.8962 - accuracy: 0.62 - ETA: 0s - loss: 0.9091 - accuracy: 0.61 - ETA: 0s - loss: 0.9272 - accuracy: 0.59 - ETA: 0s - loss: 0.9296 - accuracy: 0.59 - ETA: 0s - loss: 0.9351 - accuracy: 0.59 - ETA: 0s - loss: 0.9357 - accuracy: 0.59 - ETA: 0s - loss: 0.9374 - accuracy: 0.5928\n",
      "Epoch 00144: val_loss did not improve from 0.99394\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9374 - accuracy: 0.5928 - val_loss: 1.0134 - val_accuracy: 0.4998 - lr: 0.0189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0054 - accuracy: 0.53 - ETA: 0s - loss: 1.0018 - accuracy: 0.53 - ETA: 0s - loss: 0.9911 - accuracy: 0.54 - ETA: 0s - loss: 0.9602 - accuracy: 0.56 - ETA: 0s - loss: 0.9493 - accuracy: 0.57 - ETA: 0s - loss: 0.9323 - accuracy: 0.59 - ETA: 0s - loss: 0.9269 - accuracy: 0.59 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9227 - accuracy: 0.59 - ETA: 0s - loss: 0.9319 - accuracy: 0.59 - ETA: 0s - loss: 0.9247 - accuracy: 0.60 - ETA: 0s - loss: 0.9134 - accuracy: 0.61 - ETA: 0s - loss: 0.8964 - accuracy: 0.62 - ETA: 0s - loss: 0.9087 - accuracy: 0.61 - ETA: 0s - loss: 0.9268 - accuracy: 0.59 - ETA: 0s - loss: 0.9346 - accuracy: 0.59 - ETA: 0s - loss: 0.9351 - accuracy: 0.59 - ETA: 0s - loss: 0.9363 - accuracy: 0.5932\n",
      "Epoch 00145: val_loss did not improve from 0.99394\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9363 - accuracy: 0.5932 - val_loss: 1.0223 - val_accuracy: 0.4995 - lr: 0.0189\n",
      "Epoch 146/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9968 - accuracy: 0.54 - ETA: 0s - loss: 0.9964 - accuracy: 0.53 - ETA: 0s - loss: 0.9899 - accuracy: 0.54 - ETA: 0s - loss: 0.9594 - accuracy: 0.57 - ETA: 0s - loss: 0.9481 - accuracy: 0.58 - ETA: 0s - loss: 0.9315 - accuracy: 0.59 - ETA: 0s - loss: 0.9259 - accuracy: 0.60 - ETA: 0s - loss: 0.9234 - accuracy: 0.60 - ETA: 0s - loss: 0.9216 - accuracy: 0.60 - ETA: 0s - loss: 0.9314 - accuracy: 0.59 - ETA: 0s - loss: 0.9242 - accuracy: 0.60 - ETA: 0s - loss: 0.9129 - accuracy: 0.61 - ETA: 0s - loss: 0.8958 - accuracy: 0.62 - ETA: 0s - loss: 0.9085 - accuracy: 0.61 - ETA: 0s - loss: 0.9271 - accuracy: 0.60 - ETA: 0s - loss: 0.9295 - accuracy: 0.59 - ETA: 0s - loss: 0.9353 - accuracy: 0.59 - ETA: 0s - loss: 0.9360 - accuracy: 0.59 - ETA: 0s - loss: 0.9376 - accuracy: 0.5924\n",
      "Epoch 00146: val_loss did not improve from 0.99394\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9376 - accuracy: 0.5924 - val_loss: 1.0075 - val_accuracy: 0.5072 - lr: 0.0189\n",
      "Epoch 147/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0033 - accuracy: 0.53 - ETA: 0s - loss: 0.9997 - accuracy: 0.52 - ETA: 0s - loss: 0.9897 - accuracy: 0.53 - ETA: 0s - loss: 0.9561 - accuracy: 0.56 - ETA: 0s - loss: 0.9445 - accuracy: 0.57 - ETA: 0s - loss: 0.9292 - accuracy: 0.59 - ETA: 0s - loss: 0.9240 - accuracy: 0.59 - ETA: 0s - loss: 0.9230 - accuracy: 0.60 - ETA: 0s - loss: 0.9210 - accuracy: 0.59 - ETA: 0s - loss: 0.9303 - accuracy: 0.59 - ETA: 0s - loss: 0.9234 - accuracy: 0.60 - ETA: 0s - loss: 0.9120 - accuracy: 0.61 - ETA: 0s - loss: 0.8951 - accuracy: 0.62 - ETA: 0s - loss: 0.9080 - accuracy: 0.61 - ETA: 0s - loss: 0.9261 - accuracy: 0.59 - ETA: 0s - loss: 0.9283 - accuracy: 0.59 - ETA: 0s - loss: 0.9347 - accuracy: 0.59 - ETA: 0s - loss: 0.9358 - accuracy: 0.5921\n",
      "Epoch 00147: val_loss did not improve from 0.99394\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9358 - accuracy: 0.5921 - val_loss: 1.0079 - val_accuracy: 0.5039 - lr: 0.0189\n",
      "Epoch 148/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0024 - accuracy: 0.54 - ETA: 0s - loss: 0.9972 - accuracy: 0.53 - ETA: 0s - loss: 0.9891 - accuracy: 0.54 - ETA: 0s - loss: 0.9572 - accuracy: 0.57 - ETA: 0s - loss: 0.9453 - accuracy: 0.57 - ETA: 0s - loss: 0.9294 - accuracy: 0.59 - ETA: 0s - loss: 0.9256 - accuracy: 0.59 - ETA: 0s - loss: 0.9232 - accuracy: 0.60 - ETA: 0s - loss: 0.9214 - accuracy: 0.60 - ETA: 0s - loss: 0.9304 - accuracy: 0.59 - ETA: 0s - loss: 0.9239 - accuracy: 0.60 - ETA: 0s - loss: 0.9126 - accuracy: 0.61 - ETA: 0s - loss: 0.8953 - accuracy: 0.62 - ETA: 0s - loss: 0.9082 - accuracy: 0.61 - ETA: 0s - loss: 0.9268 - accuracy: 0.59 - ETA: 0s - loss: 0.9287 - accuracy: 0.59 - ETA: 0s - loss: 0.9341 - accuracy: 0.59 - ETA: 0s - loss: 0.9361 - accuracy: 0.5920\n",
      "Epoch 00148: val_loss did not improve from 0.99394\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9361 - accuracy: 0.5920 - val_loss: 1.0240 - val_accuracy: 0.5000 - lr: 0.0189\n",
      "Epoch 149/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9993 - accuracy: 0.53 - ETA: 0s - loss: 0.9957 - accuracy: 0.53 - ETA: 0s - loss: 0.9871 - accuracy: 0.54 - ETA: 0s - loss: 0.9561 - accuracy: 0.57 - ETA: 0s - loss: 0.9446 - accuracy: 0.58 - ETA: 0s - loss: 0.9290 - accuracy: 0.59 - ETA: 0s - loss: 0.9241 - accuracy: 0.60 - ETA: 0s - loss: 0.9223 - accuracy: 0.60 - ETA: 0s - loss: 0.9199 - accuracy: 0.60 - ETA: 0s - loss: 0.9299 - accuracy: 0.59 - ETA: 0s - loss: 0.9228 - accuracy: 0.60 - ETA: 0s - loss: 0.9117 - accuracy: 0.61 - ETA: 0s - loss: 0.9079 - accuracy: 0.61 - ETA: 0s - loss: 0.9269 - accuracy: 0.59 - ETA: 0s - loss: 0.9284 - accuracy: 0.59 - ETA: 0s - loss: 0.9338 - accuracy: 0.59 - ETA: 0s - loss: 0.9345 - accuracy: 0.59 - ETA: 0s - loss: 0.9357 - accuracy: 0.5921\n",
      "Epoch 00149: val_loss did not improve from 0.99394\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9357 - accuracy: 0.5921 - val_loss: 1.0047 - val_accuracy: 0.5029 - lr: 0.0189\n",
      "Epoch 150/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0001 - accuracy: 0.53 - ETA: 0s - loss: 0.9928 - accuracy: 0.53 - ETA: 0s - loss: 0.9858 - accuracy: 0.54 - ETA: 0s - loss: 0.9570 - accuracy: 0.56 - ETA: 0s - loss: 0.9461 - accuracy: 0.57 - ETA: 0s - loss: 0.9301 - accuracy: 0.58 - ETA: 0s - loss: 0.9250 - accuracy: 0.59 - ETA: 0s - loss: 0.9229 - accuracy: 0.59 - ETA: 0s - loss: 0.9214 - accuracy: 0.59 - ETA: 0s - loss: 0.9303 - accuracy: 0.59 - ETA: 0s - loss: 0.9239 - accuracy: 0.59 - ETA: 0s - loss: 0.9122 - accuracy: 0.60 - ETA: 0s - loss: 0.8958 - accuracy: 0.62 - ETA: 0s - loss: 0.9096 - accuracy: 0.61 - ETA: 0s - loss: 0.9280 - accuracy: 0.59 - ETA: 0s - loss: 0.9298 - accuracy: 0.59 - ETA: 0s - loss: 0.9349 - accuracy: 0.59 - ETA: 0s - loss: 0.9360 - accuracy: 0.59 - ETA: 0s - loss: 0.9371 - accuracy: 0.5911\n",
      "Epoch 00150: val_loss did not improve from 0.99394\n",
      "\n",
      "Epoch 00150: ReduceLROnPlateau reducing learning rate to 0.01509949415922165.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9371 - accuracy: 0.5911 - val_loss: 1.0022 - val_accuracy: 0.5033 - lr: 0.0189\n",
      "Epoch 151/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9987 - accuracy: 0.53 - ETA: 0s - loss: 0.9943 - accuracy: 0.52 - ETA: 0s - loss: 0.9865 - accuracy: 0.53 - ETA: 0s - loss: 0.9568 - accuracy: 0.56 - ETA: 0s - loss: 0.9468 - accuracy: 0.57 - ETA: 0s - loss: 0.9311 - accuracy: 0.58 - ETA: 0s - loss: 0.9275 - accuracy: 0.59 - ETA: 0s - loss: 0.9256 - accuracy: 0.59 - ETA: 0s - loss: 0.9231 - accuracy: 0.59 - ETA: 0s - loss: 0.9321 - accuracy: 0.58 - ETA: 0s - loss: 0.9250 - accuracy: 0.59 - ETA: 0s - loss: 0.9128 - accuracy: 0.60 - ETA: 0s - loss: 0.8962 - accuracy: 0.62 - ETA: 0s - loss: 0.9092 - accuracy: 0.61 - ETA: 0s - loss: 0.9272 - accuracy: 0.59 - ETA: 0s - loss: 0.9348 - accuracy: 0.59 - ETA: 0s - loss: 0.9354 - accuracy: 0.59 - ETA: 0s - loss: 0.9364 - accuracy: 0.5910\n",
      "Epoch 00151: val_loss did not improve from 0.99394\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9364 - accuracy: 0.5910 - val_loss: 1.0042 - val_accuracy: 0.5065 - lr: 0.0151\n",
      "Epoch 152/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0020 - accuracy: 0.54 - ETA: 0s - loss: 0.9956 - accuracy: 0.53 - ETA: 0s - loss: 0.9870 - accuracy: 0.53 - ETA: 0s - loss: 0.9577 - accuracy: 0.56 - ETA: 0s - loss: 0.9463 - accuracy: 0.57 - ETA: 0s - loss: 0.9304 - accuracy: 0.59 - ETA: 0s - loss: 0.9260 - accuracy: 0.59 - ETA: 0s - loss: 0.9236 - accuracy: 0.59 - ETA: 0s - loss: 0.9216 - accuracy: 0.59 - ETA: 0s - loss: 0.9315 - accuracy: 0.59 - ETA: 0s - loss: 0.9245 - accuracy: 0.59 - ETA: 0s - loss: 0.9125 - accuracy: 0.61 - ETA: 0s - loss: 0.8958 - accuracy: 0.62 - ETA: 0s - loss: 0.9083 - accuracy: 0.61 - ETA: 0s - loss: 0.9262 - accuracy: 0.59 - ETA: 0s - loss: 0.9285 - accuracy: 0.59 - ETA: 0s - loss: 0.9335 - accuracy: 0.59 - ETA: 0s - loss: 0.9343 - accuracy: 0.59 - ETA: 0s - loss: 0.9357 - accuracy: 0.5925\n",
      "Epoch 00152: val_loss did not improve from 0.99394\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9357 - accuracy: 0.5925 - val_loss: 1.0033 - val_accuracy: 0.5039 - lr: 0.0151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9990 - accuracy: 0.53 - ETA: 0s - loss: 0.9964 - accuracy: 0.52 - ETA: 0s - loss: 0.9866 - accuracy: 0.53 - ETA: 0s - loss: 0.9565 - accuracy: 0.56 - ETA: 0s - loss: 0.9444 - accuracy: 0.57 - ETA: 0s - loss: 0.9289 - accuracy: 0.59 - ETA: 0s - loss: 0.9247 - accuracy: 0.59 - ETA: 0s - loss: 0.9221 - accuracy: 0.60 - ETA: 0s - loss: 0.9209 - accuracy: 0.59 - ETA: 0s - loss: 0.9307 - accuracy: 0.59 - ETA: 0s - loss: 0.9232 - accuracy: 0.59 - ETA: 0s - loss: 0.9113 - accuracy: 0.60 - ETA: 0s - loss: 0.8944 - accuracy: 0.62 - ETA: 0s - loss: 0.9073 - accuracy: 0.61 - ETA: 0s - loss: 0.9278 - accuracy: 0.59 - ETA: 0s - loss: 0.9333 - accuracy: 0.59 - ETA: 0s - loss: 0.9340 - accuracy: 0.59 - ETA: 0s - loss: 0.9353 - accuracy: 0.5909\n",
      "Epoch 00153: val_loss did not improve from 0.99394\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9353 - accuracy: 0.5909 - val_loss: 1.0087 - val_accuracy: 0.5077 - lr: 0.0151\n",
      "Epoch 154/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9963 - accuracy: 0.54 - ETA: 0s - loss: 0.9916 - accuracy: 0.53 - ETA: 0s - loss: 0.9852 - accuracy: 0.54 - ETA: 0s - loss: 0.9582 - accuracy: 0.56 - ETA: 0s - loss: 0.9476 - accuracy: 0.57 - ETA: 0s - loss: 0.9304 - accuracy: 0.59 - ETA: 0s - loss: 0.9256 - accuracy: 0.59 - ETA: 0s - loss: 0.9232 - accuracy: 0.60 - ETA: 0s - loss: 0.9215 - accuracy: 0.59 - ETA: 0s - loss: 0.9306 - accuracy: 0.59 - ETA: 0s - loss: 0.9234 - accuracy: 0.60 - ETA: 0s - loss: 0.9119 - accuracy: 0.61 - ETA: 0s - loss: 0.8951 - accuracy: 0.62 - ETA: 0s - loss: 0.9076 - accuracy: 0.61 - ETA: 0s - loss: 0.9254 - accuracy: 0.59 - ETA: 0s - loss: 0.9331 - accuracy: 0.59 - ETA: 0s - loss: 0.9337 - accuracy: 0.59 - ETA: 0s - loss: 0.9350 - accuracy: 0.5930\n",
      "Epoch 00154: val_loss improved from 0.99394 to 0.99202, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 1s 74ms/step - loss: 0.9350 - accuracy: 0.5930 - val_loss: 0.9920 - val_accuracy: 0.5060 - lr: 0.0151\n",
      "Epoch 155/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9993 - accuracy: 0.54 - ETA: 0s - loss: 0.9928 - accuracy: 0.53 - ETA: 0s - loss: 0.9856 - accuracy: 0.54 - ETA: 0s - loss: 0.9545 - accuracy: 0.56 - ETA: 0s - loss: 0.9435 - accuracy: 0.57 - ETA: 0s - loss: 0.9275 - accuracy: 0.59 - ETA: 0s - loss: 0.9232 - accuracy: 0.59 - ETA: 0s - loss: 0.9213 - accuracy: 0.60 - ETA: 0s - loss: 0.9197 - accuracy: 0.60 - ETA: 0s - loss: 0.9294 - accuracy: 0.59 - ETA: 0s - loss: 0.9226 - accuracy: 0.60 - ETA: 0s - loss: 0.9111 - accuracy: 0.61 - ETA: 0s - loss: 0.8944 - accuracy: 0.62 - ETA: 0s - loss: 0.9072 - accuracy: 0.61 - ETA: 0s - loss: 0.9255 - accuracy: 0.60 - ETA: 0s - loss: 0.9278 - accuracy: 0.59 - ETA: 0s - loss: 0.9331 - accuracy: 0.59 - ETA: 0s - loss: 0.9344 - accuracy: 0.59 - ETA: 0s - loss: 0.9357 - accuracy: 0.5925\n",
      "Epoch 00155: val_loss improved from 0.99202 to 0.99131, saving model to stroke_lstm_model_weights.best.hdf5\n",
      "19/19 [==============================] - 1s 75ms/step - loss: 0.9357 - accuracy: 0.5925 - val_loss: 0.9913 - val_accuracy: 0.5065 - lr: 0.0151\n",
      "Epoch 156/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9983 - accuracy: 0.54 - ETA: 0s - loss: 0.9934 - accuracy: 0.53 - ETA: 0s - loss: 0.9842 - accuracy: 0.54 - ETA: 0s - loss: 0.9529 - accuracy: 0.57 - ETA: 0s - loss: 0.9416 - accuracy: 0.58 - ETA: 0s - loss: 0.9256 - accuracy: 0.59 - ETA: 0s - loss: 0.9218 - accuracy: 0.60 - ETA: 0s - loss: 0.9202 - accuracy: 0.60 - ETA: 0s - loss: 0.9184 - accuracy: 0.60 - ETA: 0s - loss: 0.9282 - accuracy: 0.59 - ETA: 0s - loss: 0.9213 - accuracy: 0.60 - ETA: 0s - loss: 0.9104 - accuracy: 0.61 - ETA: 0s - loss: 0.8936 - accuracy: 0.62 - ETA: 0s - loss: 0.9064 - accuracy: 0.61 - ETA: 0s - loss: 0.9244 - accuracy: 0.60 - ETA: 0s - loss: 0.9269 - accuracy: 0.59 - ETA: 0s - loss: 0.9324 - accuracy: 0.59 - ETA: 0s - loss: 0.9330 - accuracy: 0.59 - ETA: 0s - loss: 0.9346 - accuracy: 0.5935\n",
      "Epoch 00156: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9346 - accuracy: 0.5935 - val_loss: 0.9972 - val_accuracy: 0.5047 - lr: 0.0151\n",
      "Epoch 157/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9986 - accuracy: 0.54 - ETA: 0s - loss: 0.9923 - accuracy: 0.53 - ETA: 0s - loss: 0.9844 - accuracy: 0.54 - ETA: 0s - loss: 0.9547 - accuracy: 0.57 - ETA: 0s - loss: 0.9436 - accuracy: 0.58 - ETA: 0s - loss: 0.9283 - accuracy: 0.59 - ETA: 0s - loss: 0.9251 - accuracy: 0.60 - ETA: 0s - loss: 0.9235 - accuracy: 0.60 - ETA: 0s - loss: 0.9216 - accuracy: 0.60 - ETA: 0s - loss: 0.9309 - accuracy: 0.59 - ETA: 0s - loss: 0.9237 - accuracy: 0.60 - ETA: 0s - loss: 0.9121 - accuracy: 0.61 - ETA: 0s - loss: 0.8949 - accuracy: 0.62 - ETA: 0s - loss: 0.9074 - accuracy: 0.61 - ETA: 0s - loss: 0.9275 - accuracy: 0.60 - ETA: 0s - loss: 0.9330 - accuracy: 0.59 - ETA: 0s - loss: 0.9339 - accuracy: 0.59 - ETA: 0s - loss: 0.9351 - accuracy: 0.5944\n",
      "Epoch 00157: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9351 - accuracy: 0.5944 - val_loss: 0.9984 - val_accuracy: 0.5073 - lr: 0.0151\n",
      "Epoch 158/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0002 - accuracy: 0.54 - ETA: 0s - loss: 0.9927 - accuracy: 0.53 - ETA: 0s - loss: 0.9851 - accuracy: 0.53 - ETA: 0s - loss: 0.9556 - accuracy: 0.56 - ETA: 0s - loss: 0.9442 - accuracy: 0.57 - ETA: 0s - loss: 0.9281 - accuracy: 0.59 - ETA: 0s - loss: 0.9232 - accuracy: 0.59 - ETA: 0s - loss: 0.9205 - accuracy: 0.60 - ETA: 0s - loss: 0.9189 - accuracy: 0.60 - ETA: 0s - loss: 0.9286 - accuracy: 0.59 - ETA: 0s - loss: 0.9218 - accuracy: 0.60 - ETA: 0s - loss: 0.9102 - accuracy: 0.61 - ETA: 0s - loss: 0.8934 - accuracy: 0.62 - ETA: 0s - loss: 0.9066 - accuracy: 0.61 - ETA: 0s - loss: 0.9248 - accuracy: 0.59 - ETA: 0s - loss: 0.9265 - accuracy: 0.59 - ETA: 0s - loss: 0.9319 - accuracy: 0.59 - ETA: 0s - loss: 0.9339 - accuracy: 0.5915\n",
      "Epoch 00158: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9339 - accuracy: 0.5915 - val_loss: 0.9993 - val_accuracy: 0.5052 - lr: 0.0151\n",
      "Epoch 159/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0028 - accuracy: 0.54 - ETA: 0s - loss: 0.9963 - accuracy: 0.53 - ETA: 0s - loss: 0.9852 - accuracy: 0.54 - ETA: 0s - loss: 0.9520 - accuracy: 0.57 - ETA: 0s - loss: 0.9409 - accuracy: 0.58 - ETA: 0s - loss: 0.9251 - accuracy: 0.59 - ETA: 0s - loss: 0.9216 - accuracy: 0.60 - ETA: 0s - loss: 0.9192 - accuracy: 0.60 - ETA: 0s - loss: 0.9178 - accuracy: 0.60 - ETA: 0s - loss: 0.9281 - accuracy: 0.59 - ETA: 0s - loss: 0.9209 - accuracy: 0.60 - ETA: 0s - loss: 0.9100 - accuracy: 0.61 - ETA: 0s - loss: 0.8932 - accuracy: 0.62 - ETA: 0s - loss: 0.9054 - accuracy: 0.61 - ETA: 0s - loss: 0.9236 - accuracy: 0.60 - ETA: 0s - loss: 0.9258 - accuracy: 0.60 - ETA: 0s - loss: 0.9316 - accuracy: 0.59 - ETA: 0s - loss: 0.9323 - accuracy: 0.59 - ETA: 0s - loss: 0.9335 - accuracy: 0.5945\n",
      "Epoch 00159: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9335 - accuracy: 0.5945 - val_loss: 1.0049 - val_accuracy: 0.5096 - lr: 0.0151\n",
      "Epoch 160/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0046 - accuracy: 0.53 - ETA: 0s - loss: 0.9949 - accuracy: 0.53 - ETA: 0s - loss: 0.9853 - accuracy: 0.54 - ETA: 0s - loss: 0.9542 - accuracy: 0.57 - ETA: 0s - loss: 0.9424 - accuracy: 0.58 - ETA: 0s - loss: 0.9259 - accuracy: 0.59 - ETA: 0s - loss: 0.9225 - accuracy: 0.60 - ETA: 0s - loss: 0.9204 - accuracy: 0.60 - ETA: 0s - loss: 0.9185 - accuracy: 0.60 - ETA: 0s - loss: 0.9286 - accuracy: 0.59 - ETA: 0s - loss: 0.9217 - accuracy: 0.60 - ETA: 0s - loss: 0.9105 - accuracy: 0.61 - ETA: 0s - loss: 0.8935 - accuracy: 0.62 - ETA: 0s - loss: 0.9245 - accuracy: 0.60 - ETA: 0s - loss: 0.9259 - accuracy: 0.59 - ETA: 0s - loss: 0.9311 - accuracy: 0.59 - ETA: 0s - loss: 0.9323 - accuracy: 0.59 - ETA: 0s - loss: 0.9333 - accuracy: 0.5932\n",
      "Epoch 00160: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9333 - accuracy: 0.5932 - val_loss: 1.0078 - val_accuracy: 0.5060 - lr: 0.0151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9992 - accuracy: 0.53 - ETA: 0s - loss: 0.9960 - accuracy: 0.53 - ETA: 0s - loss: 0.9859 - accuracy: 0.54 - ETA: 0s - loss: 0.9555 - accuracy: 0.56 - ETA: 0s - loss: 0.9435 - accuracy: 0.57 - ETA: 0s - loss: 0.9274 - accuracy: 0.59 - ETA: 0s - loss: 0.9234 - accuracy: 0.59 - ETA: 0s - loss: 0.9206 - accuracy: 0.60 - ETA: 0s - loss: 0.9186 - accuracy: 0.60 - ETA: 0s - loss: 0.9278 - accuracy: 0.59 - ETA: 0s - loss: 0.9214 - accuracy: 0.60 - ETA: 0s - loss: 0.9101 - accuracy: 0.61 - ETA: 0s - loss: 0.8934 - accuracy: 0.62 - ETA: 0s - loss: 0.9064 - accuracy: 0.61 - ETA: 0s - loss: 0.9246 - accuracy: 0.60 - ETA: 0s - loss: 0.9264 - accuracy: 0.59 - ETA: 0s - loss: 0.9318 - accuracy: 0.59 - ETA: 0s - loss: 0.9338 - accuracy: 0.5929\n",
      "Epoch 00161: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9338 - accuracy: 0.5929 - val_loss: 1.0177 - val_accuracy: 0.5049 - lr: 0.0151\n",
      "Epoch 162/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0001 - accuracy: 0.53 - ETA: 0s - loss: 0.9925 - accuracy: 0.53 - ETA: 0s - loss: 0.9850 - accuracy: 0.53 - ETA: 0s - loss: 0.9540 - accuracy: 0.57 - ETA: 0s - loss: 0.9424 - accuracy: 0.58 - ETA: 0s - loss: 0.9263 - accuracy: 0.59 - ETA: 0s - loss: 0.9212 - accuracy: 0.60 - ETA: 0s - loss: 0.9184 - accuracy: 0.60 - ETA: 0s - loss: 0.9166 - accuracy: 0.60 - ETA: 0s - loss: 0.9267 - accuracy: 0.59 - ETA: 0s - loss: 0.9204 - accuracy: 0.60 - ETA: 0s - loss: 0.9087 - accuracy: 0.61 - ETA: 0s - loss: 0.8918 - accuracy: 0.62 - ETA: 0s - loss: 0.9046 - accuracy: 0.61 - ETA: 0s - loss: 0.9229 - accuracy: 0.60 - ETA: 0s - loss: 0.9253 - accuracy: 0.60 - ETA: 0s - loss: 0.9308 - accuracy: 0.59 - ETA: 0s - loss: 0.9318 - accuracy: 0.59 - ETA: 0s - loss: 0.9331 - accuracy: 0.5940\n",
      "Epoch 00162: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9331 - accuracy: 0.5940 - val_loss: 1.0114 - val_accuracy: 0.5042 - lr: 0.0151\n",
      "Epoch 163/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0016 - accuracy: 0.53 - ETA: 0s - loss: 0.9934 - accuracy: 0.53 - ETA: 0s - loss: 0.9834 - accuracy: 0.54 - ETA: 0s - loss: 0.9525 - accuracy: 0.57 - ETA: 0s - loss: 0.9406 - accuracy: 0.57 - ETA: 0s - loss: 0.9255 - accuracy: 0.59 - ETA: 0s - loss: 0.9220 - accuracy: 0.60 - ETA: 0s - loss: 0.9197 - accuracy: 0.60 - ETA: 0s - loss: 0.9180 - accuracy: 0.60 - ETA: 0s - loss: 0.9272 - accuracy: 0.59 - ETA: 0s - loss: 0.9205 - accuracy: 0.60 - ETA: 0s - loss: 0.9095 - accuracy: 0.61 - ETA: 0s - loss: 0.8928 - accuracy: 0.62 - ETA: 0s - loss: 0.9053 - accuracy: 0.61 - ETA: 0s - loss: 0.9234 - accuracy: 0.60 - ETA: 0s - loss: 0.9257 - accuracy: 0.60 - ETA: 0s - loss: 0.9313 - accuracy: 0.59 - ETA: 0s - loss: 0.9320 - accuracy: 0.59 - ETA: 0s - loss: 0.9332 - accuracy: 0.5938\n",
      "Epoch 00163: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9332 - accuracy: 0.5938 - val_loss: 1.0109 - val_accuracy: 0.5057 - lr: 0.0151\n",
      "Epoch 164/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9984 - accuracy: 0.54 - ETA: 0s - loss: 0.9886 - accuracy: 0.53 - ETA: 0s - loss: 0.9803 - accuracy: 0.54 - ETA: 0s - loss: 0.9493 - accuracy: 0.57 - ETA: 0s - loss: 0.9390 - accuracy: 0.58 - ETA: 0s - loss: 0.9239 - accuracy: 0.59 - ETA: 0s - loss: 0.9199 - accuracy: 0.60 - ETA: 0s - loss: 0.9167 - accuracy: 0.60 - ETA: 0s - loss: 0.9150 - accuracy: 0.60 - ETA: 0s - loss: 0.9249 - accuracy: 0.59 - ETA: 0s - loss: 0.9183 - accuracy: 0.60 - ETA: 0s - loss: 0.9068 - accuracy: 0.61 - ETA: 0s - loss: 0.8907 - accuracy: 0.62 - ETA: 0s - loss: 0.9040 - accuracy: 0.61 - ETA: 0s - loss: 0.9225 - accuracy: 0.60 - ETA: 0s - loss: 0.9247 - accuracy: 0.60 - ETA: 0s - loss: 0.9310 - accuracy: 0.59 - ETA: 0s - loss: 0.9319 - accuracy: 0.5942\n",
      "Epoch 00164: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9319 - accuracy: 0.5942 - val_loss: 1.0097 - val_accuracy: 0.5132 - lr: 0.0151\n",
      "Epoch 165/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9998 - accuracy: 0.54 - ETA: 0s - loss: 0.9920 - accuracy: 0.54 - ETA: 0s - loss: 0.9835 - accuracy: 0.54 - ETA: 0s - loss: 0.9524 - accuracy: 0.57 - ETA: 0s - loss: 0.9410 - accuracy: 0.58 - ETA: 0s - loss: 0.9260 - accuracy: 0.59 - ETA: 0s - loss: 0.9215 - accuracy: 0.60 - ETA: 0s - loss: 0.9186 - accuracy: 0.60 - ETA: 0s - loss: 0.9169 - accuracy: 0.60 - ETA: 0s - loss: 0.9266 - accuracy: 0.59 - ETA: 0s - loss: 0.9196 - accuracy: 0.60 - ETA: 0s - loss: 0.9086 - accuracy: 0.61 - ETA: 0s - loss: 0.9048 - accuracy: 0.61 - ETA: 0s - loss: 0.9234 - accuracy: 0.60 - ETA: 0s - loss: 0.9255 - accuracy: 0.60 - ETA: 0s - loss: 0.9312 - accuracy: 0.59 - ETA: 0s - loss: 0.9322 - accuracy: 0.59 - ETA: 0s - loss: 0.9337 - accuracy: 0.5947\n",
      "Epoch 00165: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00165: ReduceLROnPlateau reducing learning rate to 0.012079595029354096.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9337 - accuracy: 0.5947 - val_loss: 1.0081 - val_accuracy: 0.5055 - lr: 0.0151\n",
      "Epoch 166/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0039 - accuracy: 0.53 - ETA: 0s - loss: 0.9959 - accuracy: 0.53 - ETA: 0s - loss: 0.9878 - accuracy: 0.54 - ETA: 0s - loss: 0.9569 - accuracy: 0.56 - ETA: 0s - loss: 0.9448 - accuracy: 0.57 - ETA: 0s - loss: 0.9298 - accuracy: 0.59 - ETA: 0s - loss: 0.9248 - accuracy: 0.59 - ETA: 0s - loss: 0.9215 - accuracy: 0.60 - ETA: 0s - loss: 0.9196 - accuracy: 0.60 - ETA: 0s - loss: 0.9284 - accuracy: 0.59 - ETA: 0s - loss: 0.9214 - accuracy: 0.60 - ETA: 0s - loss: 0.9100 - accuracy: 0.61 - ETA: 0s - loss: 0.8934 - accuracy: 0.62 - ETA: 0s - loss: 0.9063 - accuracy: 0.61 - ETA: 0s - loss: 0.9243 - accuracy: 0.60 - ETA: 0s - loss: 0.9314 - accuracy: 0.59 - ETA: 0s - loss: 0.9323 - accuracy: 0.59 - ETA: 0s - loss: 0.9338 - accuracy: 0.5928\n",
      "Epoch 00166: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9338 - accuracy: 0.5928 - val_loss: 1.0007 - val_accuracy: 0.5044 - lr: 0.0121\n",
      "Epoch 167/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9961 - accuracy: 0.53 - ETA: 0s - loss: 0.9908 - accuracy: 0.53 - ETA: 0s - loss: 0.9836 - accuracy: 0.54 - ETA: 0s - loss: 0.9521 - accuracy: 0.57 - ETA: 0s - loss: 0.9408 - accuracy: 0.58 - ETA: 0s - loss: 0.9260 - accuracy: 0.59 - ETA: 0s - loss: 0.9217 - accuracy: 0.60 - ETA: 0s - loss: 0.9193 - accuracy: 0.60 - ETA: 0s - loss: 0.9174 - accuracy: 0.60 - ETA: 0s - loss: 0.9266 - accuracy: 0.59 - ETA: 0s - loss: 0.9196 - accuracy: 0.60 - ETA: 0s - loss: 0.9085 - accuracy: 0.61 - ETA: 0s - loss: 0.8920 - accuracy: 0.62 - ETA: 0s - loss: 0.9047 - accuracy: 0.61 - ETA: 0s - loss: 0.9225 - accuracy: 0.60 - ETA: 0s - loss: 0.9242 - accuracy: 0.60 - ETA: 0s - loss: 0.9294 - accuracy: 0.59 - ETA: 0s - loss: 0.9315 - accuracy: 0.5946\n",
      "Epoch 00167: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9315 - accuracy: 0.5946 - val_loss: 1.0002 - val_accuracy: 0.5119 - lr: 0.0121\n",
      "Epoch 168/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0017 - accuracy: 0.53 - ETA: 0s - loss: 0.9903 - accuracy: 0.53 - ETA: 0s - loss: 0.9805 - accuracy: 0.54 - ETA: 0s - loss: 0.9491 - accuracy: 0.57 - ETA: 0s - loss: 0.9379 - accuracy: 0.58 - ETA: 0s - loss: 0.9225 - accuracy: 0.59 - ETA: 0s - loss: 0.9189 - accuracy: 0.60 - ETA: 0s - loss: 0.9162 - accuracy: 0.60 - ETA: 0s - loss: 0.9249 - accuracy: 0.59 - ETA: 0s - loss: 0.9180 - accuracy: 0.60 - ETA: 0s - loss: 0.9066 - accuracy: 0.61 - ETA: 0s - loss: 0.8899 - accuracy: 0.62 - ETA: 0s - loss: 0.9034 - accuracy: 0.61 - ETA: 0s - loss: 0.9218 - accuracy: 0.60 - ETA: 0s - loss: 0.9232 - accuracy: 0.60 - ETA: 0s - loss: 0.9285 - accuracy: 0.59 - ETA: 0s - loss: 0.9294 - accuracy: 0.59 - ETA: 0s - loss: 0.9303 - accuracy: 0.5965\n",
      "Epoch 00168: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9303 - accuracy: 0.5965 - val_loss: 1.0075 - val_accuracy: 0.5057 - lr: 0.0121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0022 - accuracy: 0.53 - ETA: 0s - loss: 0.9907 - accuracy: 0.53 - ETA: 0s - loss: 0.9805 - accuracy: 0.54 - ETA: 0s - loss: 0.9514 - accuracy: 0.57 - ETA: 0s - loss: 0.9399 - accuracy: 0.58 - ETA: 0s - loss: 0.9245 - accuracy: 0.59 - ETA: 0s - loss: 0.9203 - accuracy: 0.60 - ETA: 0s - loss: 0.9173 - accuracy: 0.60 - ETA: 0s - loss: 0.9158 - accuracy: 0.60 - ETA: 0s - loss: 0.9257 - accuracy: 0.59 - ETA: 0s - loss: 0.9196 - accuracy: 0.60 - ETA: 0s - loss: 0.9079 - accuracy: 0.61 - ETA: 0s - loss: 0.9039 - accuracy: 0.61 - ETA: 0s - loss: 0.9222 - accuracy: 0.60 - ETA: 0s - loss: 0.9241 - accuracy: 0.60 - ETA: 0s - loss: 0.9294 - accuracy: 0.59 - ETA: 0s - loss: 0.9303 - accuracy: 0.59 - ETA: 0s - loss: 0.9313 - accuracy: 0.5969\n",
      "Epoch 00169: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9313 - accuracy: 0.5969 - val_loss: 1.0057 - val_accuracy: 0.5075 - lr: 0.0121\n",
      "Epoch 170/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9976 - accuracy: 0.54 - ETA: 0s - loss: 0.9885 - accuracy: 0.54 - ETA: 0s - loss: 0.9795 - accuracy: 0.55 - ETA: 0s - loss: 0.9484 - accuracy: 0.57 - ETA: 0s - loss: 0.9355 - accuracy: 0.58 - ETA: 0s - loss: 0.9201 - accuracy: 0.60 - ETA: 0s - loss: 0.9164 - accuracy: 0.60 - ETA: 0s - loss: 0.9145 - accuracy: 0.60 - ETA: 0s - loss: 0.9131 - accuracy: 0.60 - ETA: 0s - loss: 0.9233 - accuracy: 0.59 - ETA: 0s - loss: 0.9167 - accuracy: 0.60 - ETA: 0s - loss: 0.9058 - accuracy: 0.61 - ETA: 0s - loss: 0.9022 - accuracy: 0.61 - ETA: 0s - loss: 0.9207 - accuracy: 0.60 - ETA: 0s - loss: 0.9221 - accuracy: 0.60 - ETA: 0s - loss: 0.9275 - accuracy: 0.59 - ETA: 0s - loss: 0.9284 - accuracy: 0.59 - ETA: 0s - loss: 0.9295 - accuracy: 0.5956\n",
      "Epoch 00170: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9295 - accuracy: 0.5956 - val_loss: 1.0090 - val_accuracy: 0.5068 - lr: 0.0121\n",
      "Epoch 171/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9973 - accuracy: 0.53 - ETA: 0s - loss: 0.9912 - accuracy: 0.53 - ETA: 0s - loss: 0.9813 - accuracy: 0.54 - ETA: 0s - loss: 0.9506 - accuracy: 0.57 - ETA: 0s - loss: 0.9370 - accuracy: 0.58 - ETA: 0s - loss: 0.9223 - accuracy: 0.59 - ETA: 0s - loss: 0.9187 - accuracy: 0.60 - ETA: 0s - loss: 0.9169 - accuracy: 0.60 - ETA: 0s - loss: 0.9151 - accuracy: 0.60 - ETA: 0s - loss: 0.9258 - accuracy: 0.59 - ETA: 0s - loss: 0.9190 - accuracy: 0.60 - ETA: 0s - loss: 0.9077 - accuracy: 0.61 - ETA: 0s - loss: 0.8909 - accuracy: 0.62 - ETA: 0s - loss: 0.9036 - accuracy: 0.61 - ETA: 0s - loss: 0.9217 - accuracy: 0.60 - ETA: 0s - loss: 0.9236 - accuracy: 0.60 - ETA: 0s - loss: 0.9288 - accuracy: 0.59 - ETA: 0s - loss: 0.9297 - accuracy: 0.59 - ETA: 0s - loss: 0.9311 - accuracy: 0.5952\n",
      "Epoch 00171: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9311 - accuracy: 0.5952 - val_loss: 1.0130 - val_accuracy: 0.5042 - lr: 0.0121\n",
      "Epoch 172/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9988 - accuracy: 0.54 - ETA: 0s - loss: 0.9837 - accuracy: 0.54 - ETA: 0s - loss: 0.9777 - accuracy: 0.55 - ETA: 0s - loss: 0.9475 - accuracy: 0.57 - ETA: 0s - loss: 0.9356 - accuracy: 0.58 - ETA: 0s - loss: 0.9217 - accuracy: 0.60 - ETA: 0s - loss: 0.9175 - accuracy: 0.60 - ETA: 0s - loss: 0.9150 - accuracy: 0.60 - ETA: 0s - loss: 0.9142 - accuracy: 0.60 - ETA: 0s - loss: 0.9245 - accuracy: 0.59 - ETA: 0s - loss: 0.9188 - accuracy: 0.60 - ETA: 0s - loss: 0.9078 - accuracy: 0.61 - ETA: 0s - loss: 0.8907 - accuracy: 0.62 - ETA: 0s - loss: 0.9035 - accuracy: 0.61 - ETA: 0s - loss: 0.9214 - accuracy: 0.60 - ETA: 0s - loss: 0.9229 - accuracy: 0.60 - ETA: 0s - loss: 0.9283 - accuracy: 0.59 - ETA: 0s - loss: 0.9291 - accuracy: 0.59 - ETA: 0s - loss: 0.9300 - accuracy: 0.5959\n",
      "Epoch 00172: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9300 - accuracy: 0.5959 - val_loss: 1.0181 - val_accuracy: 0.4943 - lr: 0.0121\n",
      "Epoch 173/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0016 - accuracy: 0.53 - ETA: 0s - loss: 0.9916 - accuracy: 0.53 - ETA: 0s - loss: 0.9843 - accuracy: 0.54 - ETA: 0s - loss: 0.9525 - accuracy: 0.57 - ETA: 0s - loss: 0.9403 - accuracy: 0.58 - ETA: 0s - loss: 0.9245 - accuracy: 0.59 - ETA: 0s - loss: 0.9199 - accuracy: 0.60 - ETA: 0s - loss: 0.9175 - accuracy: 0.60 - ETA: 0s - loss: 0.9160 - accuracy: 0.60 - ETA: 0s - loss: 0.9252 - accuracy: 0.59 - ETA: 0s - loss: 0.9180 - accuracy: 0.60 - ETA: 0s - loss: 0.9071 - accuracy: 0.61 - ETA: 0s - loss: 0.8907 - accuracy: 0.62 - ETA: 0s - loss: 0.9034 - accuracy: 0.61 - ETA: 0s - loss: 0.9215 - accuracy: 0.60 - ETA: 0s - loss: 0.9286 - accuracy: 0.59 - ETA: 0s - loss: 0.9296 - accuracy: 0.59 - ETA: 0s - loss: 0.9306 - accuracy: 0.5958\n",
      "Epoch 00173: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9306 - accuracy: 0.5958 - val_loss: 1.0158 - val_accuracy: 0.5041 - lr: 0.0121\n",
      "Epoch 174/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9994 - accuracy: 0.54 - ETA: 0s - loss: 0.9899 - accuracy: 0.54 - ETA: 0s - loss: 0.9845 - accuracy: 0.54 - ETA: 0s - loss: 0.9510 - accuracy: 0.57 - ETA: 0s - loss: 0.9384 - accuracy: 0.58 - ETA: 0s - loss: 0.9235 - accuracy: 0.60 - ETA: 0s - loss: 0.9200 - accuracy: 0.60 - ETA: 0s - loss: 0.9176 - accuracy: 0.60 - ETA: 0s - loss: 0.9162 - accuracy: 0.60 - ETA: 0s - loss: 0.9261 - accuracy: 0.59 - ETA: 0s - loss: 0.9188 - accuracy: 0.60 - ETA: 0s - loss: 0.9079 - accuracy: 0.61 - ETA: 0s - loss: 0.8915 - accuracy: 0.62 - ETA: 0s - loss: 0.9041 - accuracy: 0.61 - ETA: 0s - loss: 0.9222 - accuracy: 0.60 - ETA: 0s - loss: 0.9238 - accuracy: 0.60 - ETA: 0s - loss: 0.9290 - accuracy: 0.59 - ETA: 0s - loss: 0.9299 - accuracy: 0.59 - ETA: 0s - loss: 0.9308 - accuracy: 0.5962\n",
      "Epoch 00174: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9308 - accuracy: 0.5962 - val_loss: 1.0150 - val_accuracy: 0.5051 - lr: 0.0121\n",
      "Epoch 175/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9960 - accuracy: 0.54 - ETA: 0s - loss: 0.9879 - accuracy: 0.53 - ETA: 0s - loss: 0.9826 - accuracy: 0.54 - ETA: 0s - loss: 0.9518 - accuracy: 0.57 - ETA: 0s - loss: 0.9392 - accuracy: 0.58 - ETA: 0s - loss: 0.9232 - accuracy: 0.59 - ETA: 0s - loss: 0.9195 - accuracy: 0.60 - ETA: 0s - loss: 0.9171 - accuracy: 0.60 - ETA: 0s - loss: 0.9156 - accuracy: 0.60 - ETA: 0s - loss: 0.9254 - accuracy: 0.59 - ETA: 0s - loss: 0.9185 - accuracy: 0.60 - ETA: 0s - loss: 0.9073 - accuracy: 0.61 - ETA: 0s - loss: 0.8910 - accuracy: 0.62 - ETA: 0s - loss: 0.9039 - accuracy: 0.61 - ETA: 0s - loss: 0.9227 - accuracy: 0.60 - ETA: 0s - loss: 0.9245 - accuracy: 0.60 - ETA: 0s - loss: 0.9298 - accuracy: 0.59 - ETA: 0s - loss: 0.9315 - accuracy: 0.5944\n",
      "Epoch 00175: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9315 - accuracy: 0.5944 - val_loss: 1.0142 - val_accuracy: 0.5016 - lr: 0.0121\n",
      "Epoch 176/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0011 - accuracy: 0.54 - ETA: 0s - loss: 0.9916 - accuracy: 0.53 - ETA: 0s - loss: 0.9837 - accuracy: 0.54 - ETA: 0s - loss: 0.9519 - accuracy: 0.57 - ETA: 0s - loss: 0.9402 - accuracy: 0.58 - ETA: 0s - loss: 0.9246 - accuracy: 0.59 - ETA: 0s - loss: 0.9204 - accuracy: 0.60 - ETA: 0s - loss: 0.9177 - accuracy: 0.60 - ETA: 0s - loss: 0.9162 - accuracy: 0.60 - ETA: 0s - loss: 0.9259 - accuracy: 0.59 - ETA: 0s - loss: 0.9186 - accuracy: 0.60 - ETA: 0s - loss: 0.9077 - accuracy: 0.61 - ETA: 0s - loss: 0.8908 - accuracy: 0.62 - ETA: 0s - loss: 0.9036 - accuracy: 0.61 - ETA: 0s - loss: 0.9222 - accuracy: 0.60 - ETA: 0s - loss: 0.9236 - accuracy: 0.60 - ETA: 0s - loss: 0.9291 - accuracy: 0.59 - ETA: 0s - loss: 0.9296 - accuracy: 0.5968\n",
      "Epoch 00176: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9309 - accuracy: 0.5951 - val_loss: 1.0106 - val_accuracy: 0.5002 - lr: 0.0121\n",
      "Epoch 177/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.0006 - accuracy: 0.54 - ETA: 0s - loss: 0.9889 - accuracy: 0.54 - ETA: 0s - loss: 0.9797 - accuracy: 0.55 - ETA: 0s - loss: 0.9502 - accuracy: 0.57 - ETA: 0s - loss: 0.9383 - accuracy: 0.58 - ETA: 0s - loss: 0.9226 - accuracy: 0.60 - ETA: 0s - loss: 0.9191 - accuracy: 0.60 - ETA: 0s - loss: 0.9166 - accuracy: 0.61 - ETA: 0s - loss: 0.9149 - accuracy: 0.60 - ETA: 0s - loss: 0.9250 - accuracy: 0.59 - ETA: 0s - loss: 0.9187 - accuracy: 0.60 - ETA: 0s - loss: 0.9074 - accuracy: 0.61 - ETA: 0s - loss: 0.8910 - accuracy: 0.62 - ETA: 0s - loss: 0.9036 - accuracy: 0.61 - ETA: 0s - loss: 0.9219 - accuracy: 0.60 - ETA: 0s - loss: 0.9244 - accuracy: 0.60 - ETA: 0s - loss: 0.9295 - accuracy: 0.59 - ETA: 0s - loss: 0.9305 - accuracy: 0.59 - ETA: 0s - loss: 0.9316 - accuracy: 0.5954\n",
      "Epoch 00177: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9316 - accuracy: 0.5954 - val_loss: 1.0114 - val_accuracy: 0.5111 - lr: 0.0121\n",
      "Epoch 178/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9922 - accuracy: 0.55 - ETA: 0s - loss: 0.9843 - accuracy: 0.54 - ETA: 0s - loss: 0.9808 - accuracy: 0.55 - ETA: 0s - loss: 0.9489 - accuracy: 0.57 - ETA: 0s - loss: 0.9380 - accuracy: 0.58 - ETA: 0s - loss: 0.9227 - accuracy: 0.60 - ETA: 0s - loss: 0.9190 - accuracy: 0.60 - ETA: 0s - loss: 0.9161 - accuracy: 0.60 - ETA: 0s - loss: 0.9145 - accuracy: 0.60 - ETA: 0s - loss: 0.9245 - accuracy: 0.59 - ETA: 0s - loss: 0.9177 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.61 - ETA: 0s - loss: 0.8899 - accuracy: 0.62 - ETA: 0s - loss: 0.9028 - accuracy: 0.61 - ETA: 0s - loss: 0.9205 - accuracy: 0.60 - ETA: 0s - loss: 0.9220 - accuracy: 0.60 - ETA: 0s - loss: 0.9292 - accuracy: 0.59 - ETA: 0s - loss: 0.9302 - accuracy: 0.5963\n",
      "Epoch 00178: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9302 - accuracy: 0.5963 - val_loss: 1.0139 - val_accuracy: 0.5093 - lr: 0.0121\n",
      "Epoch 179/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9970 - accuracy: 0.53 - ETA: 0s - loss: 0.9882 - accuracy: 0.53 - ETA: 0s - loss: 0.9804 - accuracy: 0.54 - ETA: 0s - loss: 0.9513 - accuracy: 0.57 - ETA: 0s - loss: 0.9397 - accuracy: 0.58 - ETA: 0s - loss: 0.9246 - accuracy: 0.59 - ETA: 0s - loss: 0.9197 - accuracy: 0.60 - ETA: 0s - loss: 0.9170 - accuracy: 0.60 - ETA: 0s - loss: 0.9260 - accuracy: 0.59 - ETA: 0s - loss: 0.9188 - accuracy: 0.60 - ETA: 0s - loss: 0.9077 - accuracy: 0.61 - ETA: 0s - loss: 0.8914 - accuracy: 0.62 - ETA: 0s - loss: 0.9042 - accuracy: 0.61 - ETA: 0s - loss: 0.9228 - accuracy: 0.60 - ETA: 0s - loss: 0.9241 - accuracy: 0.60 - ETA: 0s - loss: 0.9294 - accuracy: 0.59 - ETA: 0s - loss: 0.9301 - accuracy: 0.59 - ETA: 0s - loss: 0.9311 - accuracy: 0.5952\n",
      "Epoch 00179: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00179: ReduceLROnPlateau reducing learning rate to 0.009663675725460053.\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9311 - accuracy: 0.5952 - val_loss: 1.0097 - val_accuracy: 0.5055 - lr: 0.0121\n",
      "Epoch 180/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9943 - accuracy: 0.54 - ETA: 0s - loss: 0.9865 - accuracy: 0.53 - ETA: 0s - loss: 0.9792 - accuracy: 0.54 - ETA: 0s - loss: 0.9493 - accuracy: 0.57 - ETA: 0s - loss: 0.9382 - accuracy: 0.58 - ETA: 0s - loss: 0.9218 - accuracy: 0.59 - ETA: 0s - loss: 0.9171 - accuracy: 0.60 - ETA: 0s - loss: 0.9153 - accuracy: 0.60 - ETA: 0s - loss: 0.9140 - accuracy: 0.60 - ETA: 0s - loss: 0.9242 - accuracy: 0.59 - ETA: 0s - loss: 0.9179 - accuracy: 0.60 - ETA: 0s - loss: 0.9063 - accuracy: 0.61 - ETA: 0s - loss: 0.8898 - accuracy: 0.62 - ETA: 0s - loss: 0.9024 - accuracy: 0.61 - ETA: 0s - loss: 0.9212 - accuracy: 0.60 - ETA: 0s - loss: 0.9227 - accuracy: 0.60 - ETA: 0s - loss: 0.9281 - accuracy: 0.59 - ETA: 0s - loss: 0.9293 - accuracy: 0.59 - ETA: 0s - loss: 0.9300 - accuracy: 0.5945\n",
      "Epoch 00180: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9300 - accuracy: 0.5945 - val_loss: 1.0130 - val_accuracy: 0.4964 - lr: 0.0097\n",
      "Epoch 181/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9966 - accuracy: 0.54 - ETA: 0s - loss: 0.9886 - accuracy: 0.53 - ETA: 0s - loss: 0.9805 - accuracy: 0.54 - ETA: 0s - loss: 0.9505 - accuracy: 0.57 - ETA: 0s - loss: 0.9391 - accuracy: 0.58 - ETA: 0s - loss: 0.9228 - accuracy: 0.60 - ETA: 0s - loss: 0.9181 - accuracy: 0.60 - ETA: 0s - loss: 0.9158 - accuracy: 0.61 - ETA: 0s - loss: 0.9153 - accuracy: 0.60 - ETA: 0s - loss: 0.9175 - accuracy: 0.60 - ETA: 0s - loss: 0.9064 - accuracy: 0.61 - ETA: 0s - loss: 0.8901 - accuracy: 0.63 - ETA: 0s - loss: 0.9024 - accuracy: 0.62 - ETA: 0s - loss: 0.9210 - accuracy: 0.60 - ETA: 0s - loss: 0.9227 - accuracy: 0.60 - ETA: 0s - loss: 0.9277 - accuracy: 0.59 - ETA: 0s - loss: 0.9283 - accuracy: 0.59 - ETA: 0s - loss: 0.9290 - accuracy: 0.5962\n",
      "Epoch 00181: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9290 - accuracy: 0.5962 - val_loss: 1.0054 - val_accuracy: 0.5059 - lr: 0.0097\n",
      "Epoch 182/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9973 - accuracy: 0.53 - ETA: 0s - loss: 0.9875 - accuracy: 0.53 - ETA: 0s - loss: 0.9786 - accuracy: 0.54 - ETA: 0s - loss: 0.9465 - accuracy: 0.57 - ETA: 0s - loss: 0.9350 - accuracy: 0.58 - ETA: 0s - loss: 0.9209 - accuracy: 0.59 - ETA: 0s - loss: 0.9179 - accuracy: 0.60 - ETA: 0s - loss: 0.9161 - accuracy: 0.60 - ETA: 0s - loss: 0.9139 - accuracy: 0.60 - ETA: 0s - loss: 0.9231 - accuracy: 0.59 - ETA: 0s - loss: 0.9163 - accuracy: 0.60 - ETA: 0s - loss: 0.9052 - accuracy: 0.61 - ETA: 0s - loss: 0.8890 - accuracy: 0.62 - ETA: 0s - loss: 0.9013 - accuracy: 0.61 - ETA: 0s - loss: 0.9196 - accuracy: 0.60 - ETA: 0s - loss: 0.9210 - accuracy: 0.60 - ETA: 0s - loss: 0.9266 - accuracy: 0.59 - ETA: 0s - loss: 0.9273 - accuracy: 0.59 - ETA: 0s - loss: 0.9285 - accuracy: 0.5945\n",
      "Epoch 00182: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9285 - accuracy: 0.5945 - val_loss: 1.0153 - val_accuracy: 0.5057 - lr: 0.0097\n",
      "Epoch 183/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9964 - accuracy: 0.54 - ETA: 0s - loss: 0.9871 - accuracy: 0.54 - ETA: 0s - loss: 0.9834 - accuracy: 0.54 - ETA: 0s - loss: 0.9499 - accuracy: 0.57 - ETA: 0s - loss: 0.9386 - accuracy: 0.58 - ETA: 0s - loss: 0.9231 - accuracy: 0.59 - ETA: 0s - loss: 0.9186 - accuracy: 0.60 - ETA: 0s - loss: 0.9160 - accuracy: 0.60 - ETA: 0s - loss: 0.9151 - accuracy: 0.60 - ETA: 0s - loss: 0.9256 - accuracy: 0.59 - ETA: 0s - loss: 0.9186 - accuracy: 0.60 - ETA: 0s - loss: 0.9076 - accuracy: 0.61 - ETA: 0s - loss: 0.8911 - accuracy: 0.62 - ETA: 0s - loss: 0.9033 - accuracy: 0.61 - ETA: 0s - loss: 0.9213 - accuracy: 0.60 - ETA: 0s - loss: 0.9230 - accuracy: 0.60 - ETA: 0s - loss: 0.9282 - accuracy: 0.59 - ETA: 0s - loss: 0.9289 - accuracy: 0.59 - ETA: 0s - loss: 0.9298 - accuracy: 0.5957\n",
      "Epoch 00183: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9298 - accuracy: 0.5957 - val_loss: 1.0145 - val_accuracy: 0.5052 - lr: 0.0097\n",
      "Epoch 184/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9943 - accuracy: 0.54 - ETA: 0s - loss: 0.9866 - accuracy: 0.54 - ETA: 0s - loss: 0.9790 - accuracy: 0.55 - ETA: 0s - loss: 0.9490 - accuracy: 0.57 - ETA: 0s - loss: 0.9360 - accuracy: 0.58 - ETA: 0s - loss: 0.9207 - accuracy: 0.60 - ETA: 0s - loss: 0.9164 - accuracy: 0.60 - ETA: 0s - loss: 0.9146 - accuracy: 0.61 - ETA: 0s - loss: 0.9135 - accuracy: 0.60 - ETA: 0s - loss: 0.9230 - accuracy: 0.60 - ETA: 0s - loss: 0.9160 - accuracy: 0.60 - ETA: 0s - loss: 0.9057 - accuracy: 0.61 - ETA: 0s - loss: 0.8890 - accuracy: 0.63 - ETA: 0s - loss: 0.9016 - accuracy: 0.62 - ETA: 0s - loss: 0.9196 - accuracy: 0.60 - ETA: 0s - loss: 0.9210 - accuracy: 0.60 - ETA: 0s - loss: 0.9274 - accuracy: 0.59 - ETA: 0s - loss: 0.9286 - accuracy: 0.5969\n",
      "Epoch 00184: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9286 - accuracy: 0.5969 - val_loss: 1.0147 - val_accuracy: 0.5049 - lr: 0.0097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.9978 - accuracy: 0.53 - ETA: 0s - loss: 0.9853 - accuracy: 0.54 - ETA: 0s - loss: 0.9790 - accuracy: 0.54 - ETA: 0s - loss: 0.9474 - accuracy: 0.57 - ETA: 0s - loss: 0.9344 - accuracy: 0.58 - ETA: 0s - loss: 0.9208 - accuracy: 0.60 - ETA: 0s - loss: 0.9161 - accuracy: 0.60 - ETA: 0s - loss: 0.9143 - accuracy: 0.60 - ETA: 0s - loss: 0.9134 - accuracy: 0.60 - ETA: 0s - loss: 0.9232 - accuracy: 0.59 - ETA: 0s - loss: 0.9159 - accuracy: 0.60 - ETA: 0s - loss: 0.9054 - accuracy: 0.61 - ETA: 0s - loss: 0.8887 - accuracy: 0.63 - ETA: 0s - loss: 0.9010 - accuracy: 0.62 - ETA: 0s - loss: 0.9198 - accuracy: 0.60 - ETA: 0s - loss: 0.9216 - accuracy: 0.60 - ETA: 0s - loss: 0.9271 - accuracy: 0.59 - ETA: 0s - loss: 0.9283 - accuracy: 0.5980\n",
      "Epoch 00185: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9296 - accuracy: 0.5968 - val_loss: 1.0195 - val_accuracy: 0.5039 - lr: 0.0097\n",
      "Epoch 186/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9984 - accuracy: 0.54 - ETA: 0s - loss: 0.9919 - accuracy: 0.54 - ETA: 0s - loss: 0.9848 - accuracy: 0.54 - ETA: 0s - loss: 0.9512 - accuracy: 0.57 - ETA: 0s - loss: 0.9399 - accuracy: 0.58 - ETA: 0s - loss: 0.9246 - accuracy: 0.59 - ETA: 0s - loss: 0.9216 - accuracy: 0.60 - ETA: 0s - loss: 0.9187 - accuracy: 0.60 - ETA: 0s - loss: 0.9170 - accuracy: 0.60 - ETA: 0s - loss: 0.9265 - accuracy: 0.59 - ETA: 0s - loss: 0.9192 - accuracy: 0.60 - ETA: 0s - loss: 0.9078 - accuracy: 0.61 - ETA: 0s - loss: 0.8908 - accuracy: 0.63 - ETA: 0s - loss: 0.9032 - accuracy: 0.62 - ETA: 0s - loss: 0.9214 - accuracy: 0.60 - ETA: 0s - loss: 0.9228 - accuracy: 0.60 - ETA: 0s - loss: 0.9278 - accuracy: 0.60 - ETA: 0s - loss: 0.9288 - accuracy: 0.59 - ETA: 0s - loss: 0.9297 - accuracy: 0.5982\n",
      "Epoch 00186: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9297 - accuracy: 0.5982 - val_loss: 1.0139 - val_accuracy: 0.5041 - lr: 0.0097\n",
      "Epoch 187/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9981 - accuracy: 0.54 - ETA: 0s - loss: 0.9857 - accuracy: 0.54 - ETA: 0s - loss: 0.9826 - accuracy: 0.55 - ETA: 0s - loss: 0.9503 - accuracy: 0.57 - ETA: 0s - loss: 0.9383 - accuracy: 0.58 - ETA: 0s - loss: 0.9237 - accuracy: 0.60 - ETA: 0s - loss: 0.9192 - accuracy: 0.60 - ETA: 0s - loss: 0.9157 - accuracy: 0.61 - ETA: 0s - loss: 0.9144 - accuracy: 0.60 - ETA: 0s - loss: 0.9238 - accuracy: 0.60 - ETA: 0s - loss: 0.9161 - accuracy: 0.60 - ETA: 0s - loss: 0.9053 - accuracy: 0.61 - ETA: 0s - loss: 0.8883 - accuracy: 0.63 - ETA: 0s - loss: 0.8999 - accuracy: 0.62 - ETA: 0s - loss: 0.9181 - accuracy: 0.60 - ETA: 0s - loss: 0.9204 - accuracy: 0.60 - ETA: 0s - loss: 0.9258 - accuracy: 0.59 - ETA: 0s - loss: 0.9267 - accuracy: 0.59 - ETA: 0s - loss: 0.9276 - accuracy: 0.5982\n",
      "Epoch 00187: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9276 - accuracy: 0.5982 - val_loss: 1.0192 - val_accuracy: 0.5078 - lr: 0.0097\n",
      "Epoch 188/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0005 - accuracy: 0.54 - ETA: 0s - loss: 0.9901 - accuracy: 0.54 - ETA: 0s - loss: 0.9830 - accuracy: 0.54 - ETA: 0s - loss: 0.9514 - accuracy: 0.57 - ETA: 0s - loss: 0.9382 - accuracy: 0.58 - ETA: 0s - loss: 0.9223 - accuracy: 0.60 - ETA: 0s - loss: 0.9178 - accuracy: 0.60 - ETA: 0s - loss: 0.9153 - accuracy: 0.61 - ETA: 0s - loss: 0.9141 - accuracy: 0.60 - ETA: 0s - loss: 0.9244 - accuracy: 0.60 - ETA: 0s - loss: 0.9175 - accuracy: 0.60 - ETA: 0s - loss: 0.9066 - accuracy: 0.61 - ETA: 0s - loss: 0.8903 - accuracy: 0.63 - ETA: 0s - loss: 0.9026 - accuracy: 0.61 - ETA: 0s - loss: 0.9215 - accuracy: 0.60 - ETA: 0s - loss: 0.9229 - accuracy: 0.60 - ETA: 0s - loss: 0.9279 - accuracy: 0.59 - ETA: 0s - loss: 0.9293 - accuracy: 0.59 - ETA: 0s - loss: 0.9301 - accuracy: 0.5958\n",
      "Epoch 00188: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9301 - accuracy: 0.5958 - val_loss: 1.0177 - val_accuracy: 0.5026 - lr: 0.0097\n",
      "Epoch 189/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9973 - accuracy: 0.53 - ETA: 0s - loss: 0.9873 - accuracy: 0.53 - ETA: 0s - loss: 0.9792 - accuracy: 0.54 - ETA: 0s - loss: 0.9483 - accuracy: 0.57 - ETA: 0s - loss: 0.9365 - accuracy: 0.58 - ETA: 0s - loss: 0.9217 - accuracy: 0.59 - ETA: 0s - loss: 0.9181 - accuracy: 0.60 - ETA: 0s - loss: 0.9157 - accuracy: 0.60 - ETA: 0s - loss: 0.9144 - accuracy: 0.60 - ETA: 0s - loss: 0.9246 - accuracy: 0.59 - ETA: 0s - loss: 0.9170 - accuracy: 0.60 - ETA: 0s - loss: 0.9065 - accuracy: 0.61 - ETA: 0s - loss: 0.8898 - accuracy: 0.62 - ETA: 0s - loss: 0.9025 - accuracy: 0.61 - ETA: 0s - loss: 0.9204 - accuracy: 0.60 - ETA: 0s - loss: 0.9224 - accuracy: 0.60 - ETA: 0s - loss: 0.9278 - accuracy: 0.59 - ETA: 0s - loss: 0.9286 - accuracy: 0.59 - ETA: 0s - loss: 0.9295 - accuracy: 0.5951\n",
      "Epoch 00189: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9295 - accuracy: 0.5951 - val_loss: 1.0157 - val_accuracy: 0.5060 - lr: 0.0097\n",
      "Epoch 190/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9969 - accuracy: 0.54 - ETA: 0s - loss: 0.9821 - accuracy: 0.54 - ETA: 0s - loss: 0.9767 - accuracy: 0.55 - ETA: 0s - loss: 0.9463 - accuracy: 0.57 - ETA: 0s - loss: 0.9348 - accuracy: 0.58 - ETA: 0s - loss: 0.9194 - accuracy: 0.60 - ETA: 0s - loss: 0.9155 - accuracy: 0.60 - ETA: 0s - loss: 0.9132 - accuracy: 0.60 - ETA: 0s - loss: 0.9115 - accuracy: 0.60 - ETA: 0s - loss: 0.9214 - accuracy: 0.60 - ETA: 0s - loss: 0.9147 - accuracy: 0.60 - ETA: 0s - loss: 0.9038 - accuracy: 0.61 - ETA: 0s - loss: 0.8872 - accuracy: 0.63 - ETA: 0s - loss: 0.9003 - accuracy: 0.62 - ETA: 0s - loss: 0.9186 - accuracy: 0.60 - ETA: 0s - loss: 0.9203 - accuracy: 0.60 - ETA: 0s - loss: 0.9254 - accuracy: 0.59 - ETA: 0s - loss: 0.9266 - accuracy: 0.59 - ETA: 0s - loss: 0.9279 - accuracy: 0.5968\n",
      "Epoch 00190: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9279 - accuracy: 0.5968 - val_loss: 1.0232 - val_accuracy: 0.4938 - lr: 0.0097\n",
      "Epoch 191/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0011 - accuracy: 0.53 - ETA: 0s - loss: 0.9834 - accuracy: 0.54 - ETA: 0s - loss: 0.9775 - accuracy: 0.54 - ETA: 0s - loss: 0.9448 - accuracy: 0.57 - ETA: 0s - loss: 0.9318 - accuracy: 0.58 - ETA: 0s - loss: 0.9170 - accuracy: 0.60 - ETA: 0s - loss: 0.9129 - accuracy: 0.60 - ETA: 0s - loss: 0.9111 - accuracy: 0.61 - ETA: 0s - loss: 0.9099 - accuracy: 0.60 - ETA: 0s - loss: 0.9196 - accuracy: 0.60 - ETA: 0s - loss: 0.9126 - accuracy: 0.60 - ETA: 0s - loss: 0.9020 - accuracy: 0.61 - ETA: 0s - loss: 0.8859 - accuracy: 0.63 - ETA: 0s - loss: 0.8979 - accuracy: 0.62 - ETA: 0s - loss: 0.9156 - accuracy: 0.60 - ETA: 0s - loss: 0.9180 - accuracy: 0.60 - ETA: 0s - loss: 0.9234 - accuracy: 0.59 - ETA: 0s - loss: 0.9245 - accuracy: 0.59 - ETA: 0s - loss: 0.9263 - accuracy: 0.5975\n",
      "Epoch 00191: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9263 - accuracy: 0.5975 - val_loss: 1.0252 - val_accuracy: 0.5046 - lr: 0.0097\n",
      "Epoch 192/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9987 - accuracy: 0.54 - ETA: 0s - loss: 0.9872 - accuracy: 0.54 - ETA: 0s - loss: 0.9841 - accuracy: 0.55 - ETA: 0s - loss: 0.9535 - accuracy: 0.57 - ETA: 0s - loss: 0.9411 - accuracy: 0.58 - ETA: 0s - loss: 0.9254 - accuracy: 0.59 - ETA: 0s - loss: 0.9200 - accuracy: 0.60 - ETA: 0s - loss: 0.9166 - accuracy: 0.60 - ETA: 0s - loss: 0.9147 - accuracy: 0.60 - ETA: 0s - loss: 0.9240 - accuracy: 0.59 - ETA: 0s - loss: 0.9167 - accuracy: 0.60 - ETA: 0s - loss: 0.9060 - accuracy: 0.61 - ETA: 0s - loss: 0.8894 - accuracy: 0.63 - ETA: 0s - loss: 0.9008 - accuracy: 0.62 - ETA: 0s - loss: 0.9193 - accuracy: 0.60 - ETA: 0s - loss: 0.9210 - accuracy: 0.60 - ETA: 0s - loss: 0.9259 - accuracy: 0.59 - ETA: 0s - loss: 0.9268 - accuracy: 0.59 - ETA: 0s - loss: 0.9287 - accuracy: 0.5979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00192: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9287 - accuracy: 0.5979 - val_loss: 1.0158 - val_accuracy: 0.5039 - lr: 0.0097\n",
      "Epoch 193/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9978 - accuracy: 0.53 - ETA: 0s - loss: 0.9873 - accuracy: 0.53 - ETA: 0s - loss: 0.9801 - accuracy: 0.54 - ETA: 0s - loss: 0.9501 - accuracy: 0.57 - ETA: 0s - loss: 0.9376 - accuracy: 0.58 - ETA: 0s - loss: 0.9222 - accuracy: 0.59 - ETA: 0s - loss: 0.9166 - accuracy: 0.60 - ETA: 0s - loss: 0.9142 - accuracy: 0.60 - ETA: 0s - loss: 0.9130 - accuracy: 0.60 - ETA: 0s - loss: 0.9221 - accuracy: 0.59 - ETA: 0s - loss: 0.9155 - accuracy: 0.60 - ETA: 0s - loss: 0.9041 - accuracy: 0.61 - ETA: 0s - loss: 0.8879 - accuracy: 0.62 - ETA: 0s - loss: 0.9001 - accuracy: 0.61 - ETA: 0s - loss: 0.9189 - accuracy: 0.60 - ETA: 0s - loss: 0.9201 - accuracy: 0.60 - ETA: 0s - loss: 0.9253 - accuracy: 0.59 - ETA: 0s - loss: 0.9263 - accuracy: 0.59 - ETA: 0s - loss: 0.9276 - accuracy: 0.5954\n",
      "Epoch 00193: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00193: ReduceLROnPlateau reducing learning rate to 0.007730940729379654.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9276 - accuracy: 0.5954 - val_loss: 1.0120 - val_accuracy: 0.5005 - lr: 0.0097\n",
      "Epoch 194/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0003 - accuracy: 0.53 - ETA: 0s - loss: 0.9871 - accuracy: 0.53 - ETA: 0s - loss: 0.9811 - accuracy: 0.54 - ETA: 0s - loss: 0.9474 - accuracy: 0.57 - ETA: 0s - loss: 0.9345 - accuracy: 0.58 - ETA: 0s - loss: 0.9195 - accuracy: 0.60 - ETA: 0s - loss: 0.9153 - accuracy: 0.60 - ETA: 0s - loss: 0.9118 - accuracy: 0.61 - ETA: 0s - loss: 0.9112 - accuracy: 0.60 - ETA: 0s - loss: 0.9211 - accuracy: 0.60 - ETA: 0s - loss: 0.9142 - accuracy: 0.60 - ETA: 0s - loss: 0.9036 - accuracy: 0.61 - ETA: 0s - loss: 0.8872 - accuracy: 0.63 - ETA: 0s - loss: 0.8997 - accuracy: 0.62 - ETA: 0s - loss: 0.9180 - accuracy: 0.60 - ETA: 0s - loss: 0.9198 - accuracy: 0.60 - ETA: 0s - loss: 0.9251 - accuracy: 0.60 - ETA: 0s - loss: 0.9260 - accuracy: 0.59 - ETA: 0s - loss: 0.9272 - accuracy: 0.5982\n",
      "Epoch 00194: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9272 - accuracy: 0.5982 - val_loss: 1.0167 - val_accuracy: 0.5028 - lr: 0.0077\n",
      "Epoch 195/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9934 - accuracy: 0.54 - ETA: 0s - loss: 0.9828 - accuracy: 0.54 - ETA: 0s - loss: 0.9802 - accuracy: 0.55 - ETA: 0s - loss: 0.9462 - accuracy: 0.58 - ETA: 0s - loss: 0.9349 - accuracy: 0.59 - ETA: 0s - loss: 0.9198 - accuracy: 0.60 - ETA: 0s - loss: 0.9157 - accuracy: 0.61 - ETA: 0s - loss: 0.9131 - accuracy: 0.61 - ETA: 0s - loss: 0.9115 - accuracy: 0.61 - ETA: 0s - loss: 0.9215 - accuracy: 0.60 - ETA: 0s - loss: 0.9146 - accuracy: 0.61 - ETA: 0s - loss: 0.9044 - accuracy: 0.62 - ETA: 0s - loss: 0.8878 - accuracy: 0.63 - ETA: 0s - loss: 0.9001 - accuracy: 0.62 - ETA: 0s - loss: 0.9195 - accuracy: 0.60 - ETA: 0s - loss: 0.9246 - accuracy: 0.60 - ETA: 0s - loss: 0.9257 - accuracy: 0.60 - ETA: 0s - loss: 0.9270 - accuracy: 0.5999\n",
      "Epoch 00195: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9270 - accuracy: 0.5999 - val_loss: 1.0134 - val_accuracy: 0.5029 - lr: 0.0077\n",
      "Epoch 196/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9944 - accuracy: 0.53 - ETA: 0s - loss: 0.9842 - accuracy: 0.54 - ETA: 0s - loss: 0.9757 - accuracy: 0.54 - ETA: 0s - loss: 0.9450 - accuracy: 0.57 - ETA: 0s - loss: 0.9329 - accuracy: 0.58 - ETA: 0s - loss: 0.9173 - accuracy: 0.60 - ETA: 0s - loss: 0.9135 - accuracy: 0.60 - ETA: 0s - loss: 0.9115 - accuracy: 0.61 - ETA: 0s - loss: 0.9101 - accuracy: 0.61 - ETA: 0s - loss: 0.9197 - accuracy: 0.60 - ETA: 0s - loss: 0.9127 - accuracy: 0.60 - ETA: 0s - loss: 0.9018 - accuracy: 0.61 - ETA: 0s - loss: 0.8858 - accuracy: 0.63 - ETA: 0s - loss: 0.8984 - accuracy: 0.62 - ETA: 0s - loss: 0.9169 - accuracy: 0.60 - ETA: 0s - loss: 0.9184 - accuracy: 0.60 - ETA: 0s - loss: 0.9244 - accuracy: 0.59 - ETA: 0s - loss: 0.9254 - accuracy: 0.5969\n",
      "Epoch 00196: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9254 - accuracy: 0.5969 - val_loss: 1.0179 - val_accuracy: 0.5018 - lr: 0.0077\n",
      "Epoch 197/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.9993 - accuracy: 0.54 - ETA: 0s - loss: 0.9858 - accuracy: 0.54 - ETA: 0s - loss: 0.9762 - accuracy: 0.55 - ETA: 0s - loss: 0.9445 - accuracy: 0.57 - ETA: 0s - loss: 0.9329 - accuracy: 0.58 - ETA: 0s - loss: 0.9185 - accuracy: 0.60 - ETA: 0s - loss: 0.9135 - accuracy: 0.60 - ETA: 0s - loss: 0.9110 - accuracy: 0.61 - ETA: 0s - loss: 0.9091 - accuracy: 0.61 - ETA: 0s - loss: 0.9184 - accuracy: 0.60 - ETA: 0s - loss: 0.9112 - accuracy: 0.61 - ETA: 0s - loss: 0.9011 - accuracy: 0.61 - ETA: 0s - loss: 0.8845 - accuracy: 0.63 - ETA: 0s - loss: 0.8974 - accuracy: 0.62 - ETA: 0s - loss: 0.9154 - accuracy: 0.60 - ETA: 0s - loss: 0.9171 - accuracy: 0.60 - ETA: 0s - loss: 0.9223 - accuracy: 0.60 - ETA: 0s - loss: 0.9233 - accuracy: 0.6020\n",
      "Epoch 00197: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9251 - accuracy: 0.6006 - val_loss: 1.0263 - val_accuracy: 0.5034 - lr: 0.0077\n",
      "Epoch 198/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9969 - accuracy: 0.54 - ETA: 0s - loss: 0.9847 - accuracy: 0.54 - ETA: 0s - loss: 0.9788 - accuracy: 0.55 - ETA: 0s - loss: 0.9445 - accuracy: 0.58 - ETA: 0s - loss: 0.9319 - accuracy: 0.59 - ETA: 0s - loss: 0.9187 - accuracy: 0.60 - ETA: 0s - loss: 0.9137 - accuracy: 0.61 - ETA: 0s - loss: 0.9116 - accuracy: 0.61 - ETA: 0s - loss: 0.9096 - accuracy: 0.61 - ETA: 0s - loss: 0.9190 - accuracy: 0.60 - ETA: 0s - loss: 0.9120 - accuracy: 0.61 - ETA: 0s - loss: 0.9022 - accuracy: 0.62 - ETA: 0s - loss: 0.8857 - accuracy: 0.63 - ETA: 0s - loss: 0.8981 - accuracy: 0.62 - ETA: 0s - loss: 0.9168 - accuracy: 0.60 - ETA: 0s - loss: 0.9186 - accuracy: 0.60 - ETA: 0s - loss: 0.9240 - accuracy: 0.60 - ETA: 0s - loss: 0.9252 - accuracy: 0.60 - ETA: 0s - loss: 0.9264 - accuracy: 0.6005\n",
      "Epoch 00198: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9264 - accuracy: 0.6005 - val_loss: 1.0232 - val_accuracy: 0.4990 - lr: 0.0077\n",
      "Epoch 199/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9972 - accuracy: 0.53 - ETA: 0s - loss: 0.9839 - accuracy: 0.54 - ETA: 0s - loss: 0.9799 - accuracy: 0.54 - ETA: 0s - loss: 0.9444 - accuracy: 0.57 - ETA: 0s - loss: 0.9320 - accuracy: 0.58 - ETA: 0s - loss: 0.9174 - accuracy: 0.60 - ETA: 0s - loss: 0.9126 - accuracy: 0.60 - ETA: 0s - loss: 0.9099 - accuracy: 0.61 - ETA: 0s - loss: 0.9088 - accuracy: 0.61 - ETA: 0s - loss: 0.9179 - accuracy: 0.60 - ETA: 0s - loss: 0.9105 - accuracy: 0.61 - ETA: 0s - loss: 0.9007 - accuracy: 0.61 - ETA: 0s - loss: 0.8842 - accuracy: 0.63 - ETA: 0s - loss: 0.8963 - accuracy: 0.62 - ETA: 0s - loss: 0.9146 - accuracy: 0.60 - ETA: 0s - loss: 0.9164 - accuracy: 0.60 - ETA: 0s - loss: 0.9217 - accuracy: 0.60 - ETA: 0s - loss: 0.9242 - accuracy: 0.5999\n",
      "Epoch 00199: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9242 - accuracy: 0.5999 - val_loss: 1.0256 - val_accuracy: 0.4987 - lr: 0.0077\n",
      "Epoch 200/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9915 - accuracy: 0.54 - ETA: 0s - loss: 0.9840 - accuracy: 0.54 - ETA: 0s - loss: 0.9791 - accuracy: 0.55 - ETA: 0s - loss: 0.9447 - accuracy: 0.57 - ETA: 0s - loss: 0.9330 - accuracy: 0.58 - ETA: 0s - loss: 0.9183 - accuracy: 0.60 - ETA: 0s - loss: 0.9141 - accuracy: 0.60 - ETA: 0s - loss: 0.9109 - accuracy: 0.61 - ETA: 0s - loss: 0.9095 - accuracy: 0.61 - ETA: 0s - loss: 0.9176 - accuracy: 0.60 - ETA: 0s - loss: 0.9111 - accuracy: 0.61 - ETA: 0s - loss: 0.9009 - accuracy: 0.61 - ETA: 0s - loss: 0.8840 - accuracy: 0.63 - ETA: 0s - loss: 0.8964 - accuracy: 0.62 - ETA: 0s - loss: 0.9141 - accuracy: 0.61 - ETA: 0s - loss: 0.9158 - accuracy: 0.60 - ETA: 0s - loss: 0.9212 - accuracy: 0.60 - ETA: 0s - loss: 0.9221 - accuracy: 0.60 - ETA: 0s - loss: 0.9234 - accuracy: 0.6023\n",
      "Epoch 00200: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9234 - accuracy: 0.6023 - val_loss: 1.0290 - val_accuracy: 0.4963 - lr: 0.0077\n",
      "Epoch 201/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9959 - accuracy: 0.53 - ETA: 0s - loss: 0.9853 - accuracy: 0.54 - ETA: 0s - loss: 0.9822 - accuracy: 0.54 - ETA: 0s - loss: 0.9495 - accuracy: 0.57 - ETA: 0s - loss: 0.9379 - accuracy: 0.58 - ETA: 0s - loss: 0.9215 - accuracy: 0.59 - ETA: 0s - loss: 0.9168 - accuracy: 0.60 - ETA: 0s - loss: 0.9129 - accuracy: 0.61 - ETA: 0s - loss: 0.9114 - accuracy: 0.60 - ETA: 0s - loss: 0.9205 - accuracy: 0.60 - ETA: 0s - loss: 0.9135 - accuracy: 0.60 - ETA: 0s - loss: 0.9032 - accuracy: 0.61 - ETA: 0s - loss: 0.8864 - accuracy: 0.63 - ETA: 0s - loss: 0.8995 - accuracy: 0.61 - ETA: 0s - loss: 0.9182 - accuracy: 0.60 - ETA: 0s - loss: 0.9197 - accuracy: 0.60 - ETA: 0s - loss: 0.9250 - accuracy: 0.59 - ETA: 0s - loss: 0.9258 - accuracy: 0.59 - ETA: 0s - loss: 0.9272 - accuracy: 0.5976\n",
      "Epoch 00201: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9272 - accuracy: 0.5976 - val_loss: 1.0245 - val_accuracy: 0.5016 - lr: 0.0077\n",
      "Epoch 202/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9997 - accuracy: 0.54 - ETA: 0s - loss: 0.9807 - accuracy: 0.55 - ETA: 0s - loss: 0.9755 - accuracy: 0.55 - ETA: 0s - loss: 0.9419 - accuracy: 0.58 - ETA: 0s - loss: 0.9318 - accuracy: 0.59 - ETA: 0s - loss: 0.9169 - accuracy: 0.60 - ETA: 0s - loss: 0.9111 - accuracy: 0.61 - ETA: 0s - loss: 0.9091 - accuracy: 0.61 - ETA: 0s - loss: 0.9086 - accuracy: 0.61 - ETA: 0s - loss: 0.9173 - accuracy: 0.60 - ETA: 0s - loss: 0.9103 - accuracy: 0.61 - ETA: 0s - loss: 0.9003 - accuracy: 0.62 - ETA: 0s - loss: 0.8841 - accuracy: 0.63 - ETA: 0s - loss: 0.8966 - accuracy: 0.62 - ETA: 0s - loss: 0.9151 - accuracy: 0.61 - ETA: 0s - loss: 0.9170 - accuracy: 0.60 - ETA: 0s - loss: 0.9221 - accuracy: 0.60 - ETA: 0s - loss: 0.9232 - accuracy: 0.60 - ETA: 0s - loss: 0.9248 - accuracy: 0.6009\n",
      "Epoch 00202: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9248 - accuracy: 0.6009 - val_loss: 1.0253 - val_accuracy: 0.5003 - lr: 0.0077\n",
      "Epoch 203/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0028 - accuracy: 0.53 - ETA: 0s - loss: 0.9885 - accuracy: 0.54 - ETA: 0s - loss: 0.9788 - accuracy: 0.55 - ETA: 0s - loss: 0.9456 - accuracy: 0.57 - ETA: 0s - loss: 0.9332 - accuracy: 0.58 - ETA: 0s - loss: 0.9171 - accuracy: 0.60 - ETA: 0s - loss: 0.9116 - accuracy: 0.61 - ETA: 0s - loss: 0.9087 - accuracy: 0.61 - ETA: 0s - loss: 0.9086 - accuracy: 0.61 - ETA: 0s - loss: 0.9176 - accuracy: 0.60 - ETA: 0s - loss: 0.9113 - accuracy: 0.61 - ETA: 0s - loss: 0.9014 - accuracy: 0.61 - ETA: 0s - loss: 0.8852 - accuracy: 0.63 - ETA: 0s - loss: 0.8979 - accuracy: 0.62 - ETA: 0s - loss: 0.9168 - accuracy: 0.60 - ETA: 0s - loss: 0.9185 - accuracy: 0.60 - ETA: 0s - loss: 0.9234 - accuracy: 0.60 - ETA: 0s - loss: 0.9245 - accuracy: 0.60 - ETA: 0s - loss: 0.9262 - accuracy: 0.5984\n",
      "Epoch 00203: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9262 - accuracy: 0.5984 - val_loss: 1.0228 - val_accuracy: 0.5024 - lr: 0.0077\n",
      "Epoch 204/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0058 - accuracy: 0.52 - ETA: 0s - loss: 0.9900 - accuracy: 0.53 - ETA: 0s - loss: 0.9794 - accuracy: 0.55 - ETA: 0s - loss: 0.9463 - accuracy: 0.57 - ETA: 0s - loss: 0.9332 - accuracy: 0.58 - ETA: 0s - loss: 0.9190 - accuracy: 0.60 - ETA: 0s - loss: 0.9138 - accuracy: 0.60 - ETA: 0s - loss: 0.9115 - accuracy: 0.61 - ETA: 0s - loss: 0.9097 - accuracy: 0.61 - ETA: 0s - loss: 0.9190 - accuracy: 0.60 - ETA: 0s - loss: 0.9129 - accuracy: 0.61 - ETA: 0s - loss: 0.9031 - accuracy: 0.61 - ETA: 0s - loss: 0.8861 - accuracy: 0.63 - ETA: 0s - loss: 0.8985 - accuracy: 0.62 - ETA: 0s - loss: 0.9169 - accuracy: 0.60 - ETA: 0s - loss: 0.9186 - accuracy: 0.60 - ETA: 0s - loss: 0.9238 - accuracy: 0.60 - ETA: 0s - loss: 0.9249 - accuracy: 0.60 - ETA: 0s - loss: 0.9263 - accuracy: 0.5995\n",
      "Epoch 00204: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9263 - accuracy: 0.5995 - val_loss: 1.0203 - val_accuracy: 0.5049 - lr: 0.0077\n",
      "Epoch 205/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0004 - accuracy: 0.54 - ETA: 0s - loss: 0.9864 - accuracy: 0.54 - ETA: 0s - loss: 0.9819 - accuracy: 0.55 - ETA: 0s - loss: 0.9480 - accuracy: 0.57 - ETA: 0s - loss: 0.9353 - accuracy: 0.58 - ETA: 0s - loss: 0.9191 - accuracy: 0.60 - ETA: 0s - loss: 0.9140 - accuracy: 0.61 - ETA: 0s - loss: 0.9117 - accuracy: 0.61 - ETA: 0s - loss: 0.9096 - accuracy: 0.61 - ETA: 0s - loss: 0.9188 - accuracy: 0.60 - ETA: 0s - loss: 0.9126 - accuracy: 0.61 - ETA: 0s - loss: 0.9026 - accuracy: 0.62 - ETA: 0s - loss: 0.8865 - accuracy: 0.63 - ETA: 0s - loss: 0.8982 - accuracy: 0.62 - ETA: 0s - loss: 0.9167 - accuracy: 0.60 - ETA: 0s - loss: 0.9183 - accuracy: 0.60 - ETA: 0s - loss: 0.9233 - accuracy: 0.60 - ETA: 0s - loss: 0.9243 - accuracy: 0.60 - ETA: 0s - loss: 0.9258 - accuracy: 0.6002\n",
      "Epoch 00205: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9258 - accuracy: 0.6002 - val_loss: 1.0220 - val_accuracy: 0.5021 - lr: 0.0077\n",
      "Epoch 206/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0005 - accuracy: 0.53 - ETA: 0s - loss: 0.9837 - accuracy: 0.54 - ETA: 0s - loss: 0.9765 - accuracy: 0.54 - ETA: 0s - loss: 0.9423 - accuracy: 0.57 - ETA: 0s - loss: 0.9297 - accuracy: 0.58 - ETA: 0s - loss: 0.9154 - accuracy: 0.60 - ETA: 0s - loss: 0.9107 - accuracy: 0.60 - ETA: 0s - loss: 0.9089 - accuracy: 0.61 - ETA: 0s - loss: 0.9078 - accuracy: 0.61 - ETA: 0s - loss: 0.9166 - accuracy: 0.60 - ETA: 0s - loss: 0.9105 - accuracy: 0.61 - ETA: 0s - loss: 0.9006 - accuracy: 0.61 - ETA: 0s - loss: 0.8844 - accuracy: 0.63 - ETA: 0s - loss: 0.8969 - accuracy: 0.62 - ETA: 0s - loss: 0.9155 - accuracy: 0.60 - ETA: 0s - loss: 0.9172 - accuracy: 0.60 - ETA: 0s - loss: 0.9226 - accuracy: 0.60 - ETA: 0s - loss: 0.9237 - accuracy: 0.60 - ETA: 0s - loss: 0.9250 - accuracy: 0.5996\n",
      "Epoch 00206: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9250 - accuracy: 0.5996 - val_loss: 1.0270 - val_accuracy: 0.4998 - lr: 0.0077\n",
      "Epoch 207/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0016 - accuracy: 0.53 - ETA: 0s - loss: 0.9853 - accuracy: 0.54 - ETA: 0s - loss: 0.9816 - accuracy: 0.55 - ETA: 0s - loss: 0.9493 - accuracy: 0.57 - ETA: 0s - loss: 0.9353 - accuracy: 0.58 - ETA: 0s - loss: 0.9192 - accuracy: 0.60 - ETA: 0s - loss: 0.9129 - accuracy: 0.61 - ETA: 0s - loss: 0.9098 - accuracy: 0.61 - ETA: 0s - loss: 0.9081 - accuracy: 0.61 - ETA: 0s - loss: 0.9166 - accuracy: 0.60 - ETA: 0s - loss: 0.9095 - accuracy: 0.61 - ETA: 0s - loss: 0.8997 - accuracy: 0.62 - ETA: 0s - loss: 0.8838 - accuracy: 0.63 - ETA: 0s - loss: 0.8957 - accuracy: 0.62 - ETA: 0s - loss: 0.9145 - accuracy: 0.60 - ETA: 0s - loss: 0.9157 - accuracy: 0.60 - ETA: 0s - loss: 0.9207 - accuracy: 0.60 - ETA: 0s - loss: 0.9214 - accuracy: 0.60 - ETA: 0s - loss: 0.9232 - accuracy: 0.6001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00207: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00207: ReduceLROnPlateau reducing learning rate to 0.00618475265800953.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9232 - accuracy: 0.6001 - val_loss: 1.0306 - val_accuracy: 0.4940 - lr: 0.0077\n",
      "Epoch 208/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9929 - accuracy: 0.54 - ETA: 0s - loss: 0.9766 - accuracy: 0.55 - ETA: 0s - loss: 0.9735 - accuracy: 0.55 - ETA: 0s - loss: 0.9418 - accuracy: 0.58 - ETA: 0s - loss: 0.9298 - accuracy: 0.59 - ETA: 0s - loss: 0.9151 - accuracy: 0.60 - ETA: 0s - loss: 0.9099 - accuracy: 0.61 - ETA: 0s - loss: 0.9074 - accuracy: 0.61 - ETA: 0s - loss: 0.9070 - accuracy: 0.61 - ETA: 0s - loss: 0.9166 - accuracy: 0.60 - ETA: 0s - loss: 0.9097 - accuracy: 0.61 - ETA: 0s - loss: 0.9002 - accuracy: 0.61 - ETA: 0s - loss: 0.8840 - accuracy: 0.63 - ETA: 0s - loss: 0.8962 - accuracy: 0.62 - ETA: 0s - loss: 0.9150 - accuracy: 0.60 - ETA: 0s - loss: 0.9161 - accuracy: 0.60 - ETA: 0s - loss: 0.9211 - accuracy: 0.60 - ETA: 0s - loss: 0.9219 - accuracy: 0.60 - ETA: 0s - loss: 0.9236 - accuracy: 0.5993\n",
      "Epoch 00208: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9236 - accuracy: 0.5993 - val_loss: 1.0294 - val_accuracy: 0.4984 - lr: 0.0062\n",
      "Epoch 209/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9953 - accuracy: 0.54 - ETA: 0s - loss: 0.9770 - accuracy: 0.54 - ETA: 0s - loss: 0.9715 - accuracy: 0.55 - ETA: 0s - loss: 0.9384 - accuracy: 0.58 - ETA: 0s - loss: 0.9270 - accuracy: 0.59 - ETA: 0s - loss: 0.9116 - accuracy: 0.60 - ETA: 0s - loss: 0.9059 - accuracy: 0.61 - ETA: 0s - loss: 0.9042 - accuracy: 0.61 - ETA: 0s - loss: 0.9027 - accuracy: 0.61 - ETA: 0s - loss: 0.9111 - accuracy: 0.60 - ETA: 0s - loss: 0.9052 - accuracy: 0.61 - ETA: 0s - loss: 0.8960 - accuracy: 0.62 - ETA: 0s - loss: 0.8798 - accuracy: 0.63 - ETA: 0s - loss: 0.8936 - accuracy: 0.62 - ETA: 0s - loss: 0.9124 - accuracy: 0.60 - ETA: 0s - loss: 0.9140 - accuracy: 0.60 - ETA: 0s - loss: 0.9187 - accuracy: 0.60 - ETA: 0s - loss: 0.9199 - accuracy: 0.60 - ETA: 0s - loss: 0.9218 - accuracy: 0.6000\n",
      "Epoch 00209: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9218 - accuracy: 0.6000 - val_loss: 1.0360 - val_accuracy: 0.4917 - lr: 0.0062\n",
      "Epoch 210/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9996 - accuracy: 0.53 - ETA: 0s - loss: 0.9819 - accuracy: 0.54 - ETA: 0s - loss: 0.9762 - accuracy: 0.55 - ETA: 0s - loss: 0.9435 - accuracy: 0.57 - ETA: 0s - loss: 0.9311 - accuracy: 0.58 - ETA: 0s - loss: 0.9169 - accuracy: 0.60 - ETA: 0s - loss: 0.9114 - accuracy: 0.60 - ETA: 0s - loss: 0.9109 - accuracy: 0.61 - ETA: 0s - loss: 0.9105 - accuracy: 0.60 - ETA: 0s - loss: 0.9169 - accuracy: 0.60 - ETA: 0s - loss: 0.9102 - accuracy: 0.61 - ETA: 0s - loss: 0.9006 - accuracy: 0.61 - ETA: 0s - loss: 0.8843 - accuracy: 0.63 - ETA: 0s - loss: 0.8972 - accuracy: 0.62 - ETA: 0s - loss: 0.9162 - accuracy: 0.60 - ETA: 0s - loss: 0.9176 - accuracy: 0.60 - ETA: 0s - loss: 0.9230 - accuracy: 0.60 - ETA: 0s - loss: 0.9247 - accuracy: 0.5995\n",
      "Epoch 00210: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9247 - accuracy: 0.5995 - val_loss: 1.0396 - val_accuracy: 0.4839 - lr: 0.0062\n",
      "Epoch 211/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0006 - accuracy: 0.53 - ETA: 0s - loss: 0.9784 - accuracy: 0.54 - ETA: 0s - loss: 0.9753 - accuracy: 0.55 - ETA: 0s - loss: 0.9421 - accuracy: 0.58 - ETA: 0s - loss: 0.9304 - accuracy: 0.58 - ETA: 0s - loss: 0.9149 - accuracy: 0.60 - ETA: 0s - loss: 0.9097 - accuracy: 0.61 - ETA: 0s - loss: 0.9074 - accuracy: 0.61 - ETA: 0s - loss: 0.9066 - accuracy: 0.61 - ETA: 0s - loss: 0.9151 - accuracy: 0.60 - ETA: 0s - loss: 0.9084 - accuracy: 0.61 - ETA: 0s - loss: 0.8991 - accuracy: 0.62 - ETA: 0s - loss: 0.8825 - accuracy: 0.63 - ETA: 0s - loss: 0.8950 - accuracy: 0.62 - ETA: 0s - loss: 0.9137 - accuracy: 0.60 - ETA: 0s - loss: 0.9154 - accuracy: 0.60 - ETA: 0s - loss: 0.9201 - accuracy: 0.60 - ETA: 0s - loss: 0.9209 - accuracy: 0.60 - ETA: 0s - loss: 0.9228 - accuracy: 0.5999\n",
      "Epoch 00211: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9228 - accuracy: 0.5999 - val_loss: 1.0359 - val_accuracy: 0.4946 - lr: 0.0062\n",
      "Epoch 212/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9920 - accuracy: 0.53 - ETA: 0s - loss: 0.9777 - accuracy: 0.54 - ETA: 0s - loss: 0.9758 - accuracy: 0.55 - ETA: 0s - loss: 0.9426 - accuracy: 0.58 - ETA: 0s - loss: 0.9308 - accuracy: 0.58 - ETA: 0s - loss: 0.9171 - accuracy: 0.60 - ETA: 0s - loss: 0.9115 - accuracy: 0.60 - ETA: 0s - loss: 0.9090 - accuracy: 0.61 - ETA: 0s - loss: 0.9081 - accuracy: 0.61 - ETA: 0s - loss: 0.9166 - accuracy: 0.60 - ETA: 0s - loss: 0.9097 - accuracy: 0.61 - ETA: 0s - loss: 0.9005 - accuracy: 0.61 - ETA: 0s - loss: 0.8838 - accuracy: 0.63 - ETA: 0s - loss: 0.8949 - accuracy: 0.62 - ETA: 0s - loss: 0.9129 - accuracy: 0.60 - ETA: 0s - loss: 0.9152 - accuracy: 0.60 - ETA: 0s - loss: 0.9198 - accuracy: 0.60 - ETA: 0s - loss: 0.9204 - accuracy: 0.60 - ETA: 0s - loss: 0.9216 - accuracy: 0.6013\n",
      "Epoch 00212: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9216 - accuracy: 0.6013 - val_loss: 1.0409 - val_accuracy: 0.4904 - lr: 0.0062\n",
      "Epoch 213/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0068 - accuracy: 0.53 - ETA: 0s - loss: 0.9872 - accuracy: 0.54 - ETA: 0s - loss: 0.9824 - accuracy: 0.54 - ETA: 0s - loss: 0.9496 - accuracy: 0.57 - ETA: 0s - loss: 0.9360 - accuracy: 0.58 - ETA: 0s - loss: 0.9211 - accuracy: 0.59 - ETA: 0s - loss: 0.9144 - accuracy: 0.60 - ETA: 0s - loss: 0.9116 - accuracy: 0.60 - ETA: 0s - loss: 0.9104 - accuracy: 0.60 - ETA: 0s - loss: 0.9182 - accuracy: 0.60 - ETA: 0s - loss: 0.9110 - accuracy: 0.61 - ETA: 0s - loss: 0.9018 - accuracy: 0.61 - ETA: 0s - loss: 0.8853 - accuracy: 0.63 - ETA: 0s - loss: 0.8966 - accuracy: 0.62 - ETA: 0s - loss: 0.9150 - accuracy: 0.60 - ETA: 0s - loss: 0.9166 - accuracy: 0.60 - ETA: 0s - loss: 0.9213 - accuracy: 0.60 - ETA: 0s - loss: 0.9237 - accuracy: 0.5990\n",
      "Epoch 00213: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9237 - accuracy: 0.5990 - val_loss: 1.0433 - val_accuracy: 0.4847 - lr: 0.0062\n",
      "Epoch 214/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0018 - accuracy: 0.53 - ETA: 0s - loss: 0.9879 - accuracy: 0.54 - ETA: 0s - loss: 0.9795 - accuracy: 0.54 - ETA: 0s - loss: 0.9445 - accuracy: 0.57 - ETA: 0s - loss: 0.9317 - accuracy: 0.58 - ETA: 0s - loss: 0.9181 - accuracy: 0.60 - ETA: 0s - loss: 0.9127 - accuracy: 0.60 - ETA: 0s - loss: 0.9105 - accuracy: 0.60 - ETA: 0s - loss: 0.9099 - accuracy: 0.60 - ETA: 0s - loss: 0.9174 - accuracy: 0.60 - ETA: 0s - loss: 0.9109 - accuracy: 0.60 - ETA: 0s - loss: 0.9013 - accuracy: 0.61 - ETA: 0s - loss: 0.8848 - accuracy: 0.63 - ETA: 0s - loss: 0.8971 - accuracy: 0.62 - ETA: 0s - loss: 0.9156 - accuracy: 0.60 - ETA: 0s - loss: 0.9176 - accuracy: 0.60 - ETA: 0s - loss: 0.9225 - accuracy: 0.60 - ETA: 0s - loss: 0.9242 - accuracy: 0.5983\n",
      "Epoch 00214: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9242 - accuracy: 0.5983 - val_loss: 1.0371 - val_accuracy: 0.4969 - lr: 0.0062\n",
      "Epoch 215/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9903 - accuracy: 0.54 - ETA: 0s - loss: 0.9752 - accuracy: 0.54 - ETA: 0s - loss: 0.9699 - accuracy: 0.55 - ETA: 0s - loss: 0.9366 - accuracy: 0.58 - ETA: 0s - loss: 0.9263 - accuracy: 0.59 - ETA: 0s - loss: 0.9128 - accuracy: 0.60 - ETA: 0s - loss: 0.9069 - accuracy: 0.61 - ETA: 0s - loss: 0.9042 - accuracy: 0.61 - ETA: 0s - loss: 0.9039 - accuracy: 0.61 - ETA: 0s - loss: 0.9126 - accuracy: 0.60 - ETA: 0s - loss: 0.9057 - accuracy: 0.61 - ETA: 0s - loss: 0.8970 - accuracy: 0.62 - ETA: 0s - loss: 0.8810 - accuracy: 0.63 - ETA: 0s - loss: 0.8932 - accuracy: 0.62 - ETA: 0s - loss: 0.9121 - accuracy: 0.61 - ETA: 0s - loss: 0.9138 - accuracy: 0.61 - ETA: 0s - loss: 0.9189 - accuracy: 0.60 - ETA: 0s - loss: 0.9202 - accuracy: 0.60 - ETA: 0s - loss: 0.9219 - accuracy: 0.6019\n",
      "Epoch 00215: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9219 - accuracy: 0.6019 - val_loss: 1.0394 - val_accuracy: 0.4964 - lr: 0.0062\n",
      "Epoch 216/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9996 - accuracy: 0.54 - ETA: 0s - loss: 0.9787 - accuracy: 0.54 - ETA: 0s - loss: 0.9743 - accuracy: 0.55 - ETA: 0s - loss: 0.9388 - accuracy: 0.58 - ETA: 0s - loss: 0.9276 - accuracy: 0.59 - ETA: 0s - loss: 0.9143 - accuracy: 0.60 - ETA: 0s - loss: 0.9093 - accuracy: 0.61 - ETA: 0s - loss: 0.9075 - accuracy: 0.61 - ETA: 0s - loss: 0.9074 - accuracy: 0.61 - ETA: 0s - loss: 0.9156 - accuracy: 0.60 - ETA: 0s - loss: 0.9085 - accuracy: 0.61 - ETA: 0s - loss: 0.8996 - accuracy: 0.62 - ETA: 0s - loss: 0.8833 - accuracy: 0.63 - ETA: 0s - loss: 0.8951 - accuracy: 0.62 - ETA: 0s - loss: 0.9138 - accuracy: 0.60 - ETA: 0s - loss: 0.9155 - accuracy: 0.60 - ETA: 0s - loss: 0.9204 - accuracy: 0.60 - ETA: 0s - loss: 0.9207 - accuracy: 0.60 - ETA: 0s - loss: 0.9222 - accuracy: 0.6006\n",
      "Epoch 00216: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9222 - accuracy: 0.6006 - val_loss: 1.0390 - val_accuracy: 0.4945 - lr: 0.0062\n",
      "Epoch 217/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0014 - accuracy: 0.54 - ETA: 0s - loss: 0.9839 - accuracy: 0.54 - ETA: 0s - loss: 0.9786 - accuracy: 0.55 - ETA: 0s - loss: 0.9436 - accuracy: 0.58 - ETA: 0s - loss: 0.9310 - accuracy: 0.59 - ETA: 0s - loss: 0.9165 - accuracy: 0.60 - ETA: 0s - loss: 0.9105 - accuracy: 0.60 - ETA: 0s - loss: 0.9092 - accuracy: 0.61 - ETA: 0s - loss: 0.9080 - accuracy: 0.61 - ETA: 0s - loss: 0.9163 - accuracy: 0.60 - ETA: 0s - loss: 0.9097 - accuracy: 0.61 - ETA: 0s - loss: 0.9006 - accuracy: 0.61 - ETA: 0s - loss: 0.8841 - accuracy: 0.63 - ETA: 0s - loss: 0.8959 - accuracy: 0.62 - ETA: 0s - loss: 0.9141 - accuracy: 0.60 - ETA: 0s - loss: 0.9157 - accuracy: 0.60 - ETA: 0s - loss: 0.9206 - accuracy: 0.60 - ETA: 0s - loss: 0.9211 - accuracy: 0.60 - ETA: 0s - loss: 0.9224 - accuracy: 0.5996\n",
      "Epoch 00217: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9224 - accuracy: 0.5996 - val_loss: 1.0393 - val_accuracy: 0.4974 - lr: 0.0062\n",
      "Epoch 218/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9970 - accuracy: 0.53 - ETA: 0s - loss: 0.9782 - accuracy: 0.54 - ETA: 0s - loss: 0.9736 - accuracy: 0.55 - ETA: 0s - loss: 0.9401 - accuracy: 0.57 - ETA: 0s - loss: 0.9272 - accuracy: 0.58 - ETA: 0s - loss: 0.9128 - accuracy: 0.60 - ETA: 0s - loss: 0.9077 - accuracy: 0.61 - ETA: 0s - loss: 0.9061 - accuracy: 0.61 - ETA: 0s - loss: 0.9041 - accuracy: 0.61 - ETA: 0s - loss: 0.9131 - accuracy: 0.60 - ETA: 0s - loss: 0.9066 - accuracy: 0.61 - ETA: 0s - loss: 0.8980 - accuracy: 0.62 - ETA: 0s - loss: 0.8818 - accuracy: 0.63 - ETA: 0s - loss: 0.8935 - accuracy: 0.62 - ETA: 0s - loss: 0.9119 - accuracy: 0.60 - ETA: 0s - loss: 0.9191 - accuracy: 0.60 - ETA: 0s - loss: 0.9198 - accuracy: 0.60 - ETA: 0s - loss: 0.9210 - accuracy: 0.6008\n",
      "Epoch 00218: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9210 - accuracy: 0.6008 - val_loss: 1.0423 - val_accuracy: 0.4901 - lr: 0.0062\n",
      "Epoch 219/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9927 - accuracy: 0.54 - ETA: 0s - loss: 0.9791 - accuracy: 0.55 - ETA: 0s - loss: 0.9731 - accuracy: 0.55 - ETA: 0s - loss: 0.9382 - accuracy: 0.58 - ETA: 0s - loss: 0.9254 - accuracy: 0.59 - ETA: 0s - loss: 0.9126 - accuracy: 0.60 - ETA: 0s - loss: 0.9074 - accuracy: 0.61 - ETA: 0s - loss: 0.9050 - accuracy: 0.61 - ETA: 0s - loss: 0.9031 - accuracy: 0.61 - ETA: 0s - loss: 0.9115 - accuracy: 0.60 - ETA: 0s - loss: 0.9059 - accuracy: 0.61 - ETA: 0s - loss: 0.8973 - accuracy: 0.62 - ETA: 0s - loss: 0.8814 - accuracy: 0.63 - ETA: 0s - loss: 0.8929 - accuracy: 0.62 - ETA: 0s - loss: 0.9118 - accuracy: 0.61 - ETA: 0s - loss: 0.9132 - accuracy: 0.60 - ETA: 0s - loss: 0.9194 - accuracy: 0.60 - ETA: 0s - loss: 0.9209 - accuracy: 0.6016\n",
      "Epoch 00219: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9209 - accuracy: 0.6016 - val_loss: 1.0373 - val_accuracy: 0.5028 - lr: 0.0062\n",
      "Epoch 220/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9942 - accuracy: 0.54 - ETA: 0s - loss: 0.9758 - accuracy: 0.55 - ETA: 0s - loss: 0.9719 - accuracy: 0.55 - ETA: 0s - loss: 0.9382 - accuracy: 0.58 - ETA: 0s - loss: 0.9262 - accuracy: 0.59 - ETA: 0s - loss: 0.9122 - accuracy: 0.60 - ETA: 0s - loss: 0.9066 - accuracy: 0.61 - ETA: 0s - loss: 0.9046 - accuracy: 0.61 - ETA: 0s - loss: 0.9044 - accuracy: 0.61 - ETA: 0s - loss: 0.9123 - accuracy: 0.60 - ETA: 0s - loss: 0.9054 - accuracy: 0.61 - ETA: 0s - loss: 0.8969 - accuracy: 0.62 - ETA: 0s - loss: 0.8804 - accuracy: 0.63 - ETA: 0s - loss: 0.8931 - accuracy: 0.62 - ETA: 0s - loss: 0.9118 - accuracy: 0.61 - ETA: 0s - loss: 0.9133 - accuracy: 0.60 - ETA: 0s - loss: 0.9188 - accuracy: 0.60 - ETA: 0s - loss: 0.9191 - accuracy: 0.60 - ETA: 0s - loss: 0.9201 - accuracy: 0.6031\n",
      "Epoch 00220: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9201 - accuracy: 0.6031 - val_loss: 1.0437 - val_accuracy: 0.4925 - lr: 0.0062\n",
      "Epoch 221/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0047 - accuracy: 0.54 - ETA: 0s - loss: 0.9789 - accuracy: 0.55 - ETA: 0s - loss: 0.9737 - accuracy: 0.55 - ETA: 0s - loss: 0.9395 - accuracy: 0.58 - ETA: 0s - loss: 0.9273 - accuracy: 0.59 - ETA: 0s - loss: 0.9125 - accuracy: 0.60 - ETA: 0s - loss: 0.9064 - accuracy: 0.61 - ETA: 0s - loss: 0.9049 - accuracy: 0.61 - ETA: 0s - loss: 0.9041 - accuracy: 0.61 - ETA: 0s - loss: 0.9111 - accuracy: 0.60 - ETA: 0s - loss: 0.9049 - accuracy: 0.61 - ETA: 0s - loss: 0.8966 - accuracy: 0.62 - ETA: 0s - loss: 0.8800 - accuracy: 0.63 - ETA: 0s - loss: 0.8919 - accuracy: 0.62 - ETA: 0s - loss: 0.9112 - accuracy: 0.60 - ETA: 0s - loss: 0.9133 - accuracy: 0.60 - ETA: 0s - loss: 0.9185 - accuracy: 0.60 - ETA: 0s - loss: 0.9191 - accuracy: 0.60 - ETA: 0s - loss: 0.9208 - accuracy: 0.6009\n",
      "Epoch 00221: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00221: ReduceLROnPlateau reducing learning rate to 0.004947802051901817.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9208 - accuracy: 0.6009 - val_loss: 1.0468 - val_accuracy: 0.4923 - lr: 0.0062\n",
      "Epoch 222/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.9964 - accuracy: 0.53 - ETA: 0s - loss: 0.9733 - accuracy: 0.54 - ETA: 0s - loss: 0.9677 - accuracy: 0.55 - ETA: 0s - loss: 0.9364 - accuracy: 0.57 - ETA: 0s - loss: 0.9245 - accuracy: 0.59 - ETA: 0s - loss: 0.9104 - accuracy: 0.60 - ETA: 0s - loss: 0.9050 - accuracy: 0.61 - ETA: 0s - loss: 0.9030 - accuracy: 0.61 - ETA: 0s - loss: 0.9027 - accuracy: 0.61 - ETA: 0s - loss: 0.9100 - accuracy: 0.60 - ETA: 0s - loss: 0.9039 - accuracy: 0.61 - ETA: 0s - loss: 0.8951 - accuracy: 0.62 - ETA: 0s - loss: 0.8791 - accuracy: 0.63 - ETA: 0s - loss: 0.8910 - accuracy: 0.62 - ETA: 0s - loss: 0.9093 - accuracy: 0.60 - ETA: 0s - loss: 0.9111 - accuracy: 0.60 - ETA: 0s - loss: 0.9161 - accuracy: 0.60 - ETA: 0s - loss: 0.9169 - accuracy: 0.6033\n",
      "Epoch 00222: val_loss did not improve from 0.99131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9184 - accuracy: 0.6018 - val_loss: 1.0452 - val_accuracy: 0.4953 - lr: 0.0049\n",
      "Epoch 223/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9960 - accuracy: 0.54 - ETA: 0s - loss: 0.9785 - accuracy: 0.55 - ETA: 0s - loss: 0.9712 - accuracy: 0.56 - ETA: 0s - loss: 0.9384 - accuracy: 0.58 - ETA: 0s - loss: 0.9272 - accuracy: 0.59 - ETA: 0s - loss: 0.9133 - accuracy: 0.60 - ETA: 0s - loss: 0.9076 - accuracy: 0.61 - ETA: 0s - loss: 0.9059 - accuracy: 0.61 - ETA: 0s - loss: 0.9045 - accuracy: 0.61 - ETA: 0s - loss: 0.9128 - accuracy: 0.60 - ETA: 0s - loss: 0.9061 - accuracy: 0.61 - ETA: 0s - loss: 0.8973 - accuracy: 0.62 - ETA: 0s - loss: 0.8807 - accuracy: 0.63 - ETA: 0s - loss: 0.8936 - accuracy: 0.62 - ETA: 0s - loss: 0.9127 - accuracy: 0.61 - ETA: 0s - loss: 0.9143 - accuracy: 0.60 - ETA: 0s - loss: 0.9193 - accuracy: 0.60 - ETA: 0s - loss: 0.9203 - accuracy: 0.60 - ETA: 0s - loss: 0.9217 - accuracy: 0.6016\n",
      "Epoch 00223: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9217 - accuracy: 0.6016 - val_loss: 1.0569 - val_accuracy: 0.4845 - lr: 0.0049\n",
      "Epoch 224/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9957 - accuracy: 0.54 - ETA: 0s - loss: 0.9712 - accuracy: 0.55 - ETA: 0s - loss: 0.9660 - accuracy: 0.56 - ETA: 0s - loss: 0.9370 - accuracy: 0.58 - ETA: 0s - loss: 0.9249 - accuracy: 0.59 - ETA: 0s - loss: 0.9103 - accuracy: 0.60 - ETA: 0s - loss: 0.9053 - accuracy: 0.61 - ETA: 0s - loss: 0.9044 - accuracy: 0.61 - ETA: 0s - loss: 0.9039 - accuracy: 0.61 - ETA: 0s - loss: 0.9121 - accuracy: 0.60 - ETA: 0s - loss: 0.9050 - accuracy: 0.61 - ETA: 0s - loss: 0.8960 - accuracy: 0.62 - ETA: 0s - loss: 0.8797 - accuracy: 0.63 - ETA: 0s - loss: 0.8928 - accuracy: 0.62 - ETA: 0s - loss: 0.9119 - accuracy: 0.60 - ETA: 0s - loss: 0.9137 - accuracy: 0.60 - ETA: 0s - loss: 0.9187 - accuracy: 0.60 - ETA: 0s - loss: 0.9198 - accuracy: 0.60 - ETA: 0s - loss: 0.9212 - accuracy: 0.6009\n",
      "Epoch 00224: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9212 - accuracy: 0.6009 - val_loss: 1.0531 - val_accuracy: 0.4837 - lr: 0.0049\n",
      "Epoch 225/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9992 - accuracy: 0.53 - ETA: 0s - loss: 0.9736 - accuracy: 0.55 - ETA: 0s - loss: 0.9728 - accuracy: 0.55 - ETA: 0s - loss: 0.9418 - accuracy: 0.58 - ETA: 0s - loss: 0.9313 - accuracy: 0.58 - ETA: 0s - loss: 0.9156 - accuracy: 0.60 - ETA: 0s - loss: 0.9090 - accuracy: 0.61 - ETA: 0s - loss: 0.9079 - accuracy: 0.61 - ETA: 0s - loss: 0.9066 - accuracy: 0.61 - ETA: 0s - loss: 0.9135 - accuracy: 0.60 - ETA: 0s - loss: 0.9071 - accuracy: 0.61 - ETA: 0s - loss: 0.8980 - accuracy: 0.62 - ETA: 0s - loss: 0.8815 - accuracy: 0.63 - ETA: 0s - loss: 0.8931 - accuracy: 0.62 - ETA: 0s - loss: 0.9113 - accuracy: 0.61 - ETA: 0s - loss: 0.9127 - accuracy: 0.60 - ETA: 0s - loss: 0.9180 - accuracy: 0.60 - ETA: 0s - loss: 0.9191 - accuracy: 0.60 - ETA: 0s - loss: 0.9204 - accuracy: 0.6019\n",
      "Epoch 00225: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9204 - accuracy: 0.6019 - val_loss: 1.0580 - val_accuracy: 0.4778 - lr: 0.0049\n",
      "Epoch 226/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9972 - accuracy: 0.54 - ETA: 0s - loss: 0.9743 - accuracy: 0.55 - ETA: 0s - loss: 0.9710 - accuracy: 0.55 - ETA: 0s - loss: 0.9359 - accuracy: 0.58 - ETA: 0s - loss: 0.9243 - accuracy: 0.59 - ETA: 0s - loss: 0.9094 - accuracy: 0.61 - ETA: 0s - loss: 0.9050 - accuracy: 0.61 - ETA: 0s - loss: 0.9033 - accuracy: 0.61 - ETA: 0s - loss: 0.9025 - accuracy: 0.61 - ETA: 0s - loss: 0.9109 - accuracy: 0.60 - ETA: 0s - loss: 0.9036 - accuracy: 0.61 - ETA: 0s - loss: 0.8786 - accuracy: 0.63 - ETA: 0s - loss: 0.8911 - accuracy: 0.62 - ETA: 0s - loss: 0.9092 - accuracy: 0.61 - ETA: 0s - loss: 0.9107 - accuracy: 0.61 - ETA: 0s - loss: 0.9159 - accuracy: 0.60 - ETA: 0s - loss: 0.9167 - accuracy: 0.60 - ETA: 0s - loss: 0.9181 - accuracy: 0.6050\n",
      "Epoch 00226: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9181 - accuracy: 0.6050 - val_loss: 1.0603 - val_accuracy: 0.4831 - lr: 0.0049\n",
      "Epoch 227/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0000 - accuracy: 0.53 - ETA: 0s - loss: 0.9755 - accuracy: 0.54 - ETA: 0s - loss: 0.9703 - accuracy: 0.55 - ETA: 0s - loss: 0.9371 - accuracy: 0.58 - ETA: 0s - loss: 0.9254 - accuracy: 0.59 - ETA: 0s - loss: 0.9107 - accuracy: 0.60 - ETA: 0s - loss: 0.9058 - accuracy: 0.61 - ETA: 0s - loss: 0.9030 - accuracy: 0.61 - ETA: 0s - loss: 0.9022 - accuracy: 0.61 - ETA: 0s - loss: 0.9110 - accuracy: 0.60 - ETA: 0s - loss: 0.9037 - accuracy: 0.61 - ETA: 0s - loss: 0.8954 - accuracy: 0.62 - ETA: 0s - loss: 0.8789 - accuracy: 0.63 - ETA: 0s - loss: 0.8917 - accuracy: 0.62 - ETA: 0s - loss: 0.9132 - accuracy: 0.60 - ETA: 0s - loss: 0.9178 - accuracy: 0.60 - ETA: 0s - loss: 0.9186 - accuracy: 0.60 - ETA: 0s - loss: 0.9198 - accuracy: 0.6004\n",
      "Epoch 00227: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9198 - accuracy: 0.6004 - val_loss: 1.0534 - val_accuracy: 0.4850 - lr: 0.0049\n",
      "Epoch 228/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9954 - accuracy: 0.54 - ETA: 0s - loss: 0.9696 - accuracy: 0.55 - ETA: 0s - loss: 0.9709 - accuracy: 0.56 - ETA: 0s - loss: 0.9365 - accuracy: 0.58 - ETA: 0s - loss: 0.9258 - accuracy: 0.59 - ETA: 0s - loss: 0.9116 - accuracy: 0.60 - ETA: 0s - loss: 0.9066 - accuracy: 0.61 - ETA: 0s - loss: 0.9049 - accuracy: 0.61 - ETA: 0s - loss: 0.9040 - accuracy: 0.61 - ETA: 0s - loss: 0.9124 - accuracy: 0.60 - ETA: 0s - loss: 0.9048 - accuracy: 0.61 - ETA: 0s - loss: 0.8964 - accuracy: 0.62 - ETA: 0s - loss: 0.8798 - accuracy: 0.63 - ETA: 0s - loss: 0.8919 - accuracy: 0.62 - ETA: 0s - loss: 0.9105 - accuracy: 0.61 - ETA: 0s - loss: 0.9123 - accuracy: 0.60 - ETA: 0s - loss: 0.9174 - accuracy: 0.60 - ETA: 0s - loss: 0.9198 - accuracy: 0.6022\n",
      "Epoch 00228: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9198 - accuracy: 0.6022 - val_loss: 1.0620 - val_accuracy: 0.4821 - lr: 0.0049\n",
      "Epoch 229/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9960 - accuracy: 0.54 - ETA: 0s - loss: 0.9709 - accuracy: 0.55 - ETA: 0s - loss: 0.9669 - accuracy: 0.55 - ETA: 0s - loss: 0.9348 - accuracy: 0.58 - ETA: 0s - loss: 0.9240 - accuracy: 0.59 - ETA: 0s - loss: 0.9096 - accuracy: 0.60 - ETA: 0s - loss: 0.9042 - accuracy: 0.61 - ETA: 0s - loss: 0.9034 - accuracy: 0.61 - ETA: 0s - loss: 0.9031 - accuracy: 0.61 - ETA: 0s - loss: 0.9120 - accuracy: 0.60 - ETA: 0s - loss: 0.9055 - accuracy: 0.61 - ETA: 0s - loss: 0.8965 - accuracy: 0.62 - ETA: 0s - loss: 0.8800 - accuracy: 0.63 - ETA: 0s - loss: 0.8923 - accuracy: 0.62 - ETA: 0s - loss: 0.9109 - accuracy: 0.61 - ETA: 0s - loss: 0.9126 - accuracy: 0.60 - ETA: 0s - loss: 0.9172 - accuracy: 0.60 - ETA: 0s - loss: 0.9181 - accuracy: 0.60 - ETA: 0s - loss: 0.9196 - accuracy: 0.6027\n",
      "Epoch 00229: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9196 - accuracy: 0.6027 - val_loss: 1.0623 - val_accuracy: 0.4816 - lr: 0.0049\n",
      "Epoch 230/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9948 - accuracy: 0.54 - ETA: 0s - loss: 0.9733 - accuracy: 0.55 - ETA: 0s - loss: 0.9699 - accuracy: 0.55 - ETA: 0s - loss: 0.9334 - accuracy: 0.58 - ETA: 0s - loss: 0.9211 - accuracy: 0.59 - ETA: 0s - loss: 0.9067 - accuracy: 0.61 - ETA: 0s - loss: 0.9017 - accuracy: 0.61 - ETA: 0s - loss: 0.8993 - accuracy: 0.61 - ETA: 0s - loss: 0.8994 - accuracy: 0.61 - ETA: 0s - loss: 0.9087 - accuracy: 0.60 - ETA: 0s - loss: 0.9023 - accuracy: 0.61 - ETA: 0s - loss: 0.8945 - accuracy: 0.62 - ETA: 0s - loss: 0.8781 - accuracy: 0.63 - ETA: 0s - loss: 0.8896 - accuracy: 0.62 - ETA: 0s - loss: 0.9081 - accuracy: 0.61 - ETA: 0s - loss: 0.9097 - accuracy: 0.61 - ETA: 0s - loss: 0.9150 - accuracy: 0.60 - ETA: 0s - loss: 0.9158 - accuracy: 0.60 - ETA: 0s - loss: 0.9173 - accuracy: 0.6040\n",
      "Epoch 00230: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9173 - accuracy: 0.6040 - val_loss: 1.0583 - val_accuracy: 0.4907 - lr: 0.0049\n",
      "Epoch 231/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9918 - accuracy: 0.54 - ETA: 0s - loss: 0.9671 - accuracy: 0.55 - ETA: 0s - loss: 0.9659 - accuracy: 0.56 - ETA: 0s - loss: 0.9326 - accuracy: 0.58 - ETA: 0s - loss: 0.9210 - accuracy: 0.59 - ETA: 0s - loss: 0.9068 - accuracy: 0.60 - ETA: 0s - loss: 0.9019 - accuracy: 0.61 - ETA: 0s - loss: 0.9004 - accuracy: 0.61 - ETA: 0s - loss: 0.8990 - accuracy: 0.61 - ETA: 0s - loss: 0.9070 - accuracy: 0.60 - ETA: 0s - loss: 0.9007 - accuracy: 0.61 - ETA: 0s - loss: 0.8925 - accuracy: 0.62 - ETA: 0s - loss: 0.8764 - accuracy: 0.63 - ETA: 0s - loss: 0.8888 - accuracy: 0.62 - ETA: 0s - loss: 0.9078 - accuracy: 0.61 - ETA: 0s - loss: 0.9092 - accuracy: 0.60 - ETA: 0s - loss: 0.9141 - accuracy: 0.60 - ETA: 0s - loss: 0.9150 - accuracy: 0.60 - ETA: 0s - loss: 0.9173 - accuracy: 0.6026\n",
      "Epoch 00231: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9173 - accuracy: 0.6026 - val_loss: 1.0650 - val_accuracy: 0.4881 - lr: 0.0049\n",
      "Epoch 232/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0008 - accuracy: 0.53 - ETA: 0s - loss: 0.9780 - accuracy: 0.54 - ETA: 0s - loss: 0.9738 - accuracy: 0.55 - ETA: 0s - loss: 0.9400 - accuracy: 0.58 - ETA: 0s - loss: 0.9264 - accuracy: 0.59 - ETA: 0s - loss: 0.9118 - accuracy: 0.60 - ETA: 0s - loss: 0.9064 - accuracy: 0.61 - ETA: 0s - loss: 0.9047 - accuracy: 0.61 - ETA: 0s - loss: 0.9035 - accuracy: 0.61 - ETA: 0s - loss: 0.9107 - accuracy: 0.60 - ETA: 0s - loss: 0.9046 - accuracy: 0.61 - ETA: 0s - loss: 0.8960 - accuracy: 0.62 - ETA: 0s - loss: 0.8794 - accuracy: 0.63 - ETA: 0s - loss: 0.8912 - accuracy: 0.62 - ETA: 0s - loss: 0.9097 - accuracy: 0.60 - ETA: 0s - loss: 0.9108 - accuracy: 0.60 - ETA: 0s - loss: 0.9156 - accuracy: 0.60 - ETA: 0s - loss: 0.9164 - accuracy: 0.60 - ETA: 0s - loss: 0.9178 - accuracy: 0.6023\n",
      "Epoch 00232: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9178 - accuracy: 0.6023 - val_loss: 1.0596 - val_accuracy: 0.4899 - lr: 0.0049\n",
      "Epoch 233/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9943 - accuracy: 0.54 - ETA: 0s - loss: 0.9698 - accuracy: 0.55 - ETA: 0s - loss: 0.9673 - accuracy: 0.55 - ETA: 0s - loss: 0.9329 - accuracy: 0.58 - ETA: 0s - loss: 0.9211 - accuracy: 0.59 - ETA: 0s - loss: 0.9068 - accuracy: 0.60 - ETA: 0s - loss: 0.9024 - accuracy: 0.61 - ETA: 0s - loss: 0.9012 - accuracy: 0.61 - ETA: 0s - loss: 0.9009 - accuracy: 0.61 - ETA: 0s - loss: 0.9084 - accuracy: 0.60 - ETA: 0s - loss: 0.9023 - accuracy: 0.61 - ETA: 0s - loss: 0.8939 - accuracy: 0.62 - ETA: 0s - loss: 0.8777 - accuracy: 0.63 - ETA: 0s - loss: 0.8904 - accuracy: 0.62 - ETA: 0s - loss: 0.9086 - accuracy: 0.60 - ETA: 0s - loss: 0.9147 - accuracy: 0.60 - ETA: 0s - loss: 0.9158 - accuracy: 0.60 - ETA: 0s - loss: 0.9174 - accuracy: 0.6009\n",
      "Epoch 00233: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9174 - accuracy: 0.6009 - val_loss: 1.0577 - val_accuracy: 0.4935 - lr: 0.0049\n",
      "Epoch 234/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0022 - accuracy: 0.54 - ETA: 0s - loss: 0.9781 - accuracy: 0.54 - ETA: 0s - loss: 0.9364 - accuracy: 0.58 - ETA: 0s - loss: 0.9240 - accuracy: 0.59 - ETA: 0s - loss: 0.9097 - accuracy: 0.60 - ETA: 0s - loss: 0.9045 - accuracy: 0.61 - ETA: 0s - loss: 0.9036 - accuracy: 0.61 - ETA: 0s - loss: 0.9029 - accuracy: 0.61 - ETA: 0s - loss: 0.9107 - accuracy: 0.60 - ETA: 0s - loss: 0.9047 - accuracy: 0.61 - ETA: 0s - loss: 0.8959 - accuracy: 0.62 - ETA: 0s - loss: 0.8790 - accuracy: 0.63 - ETA: 0s - loss: 0.8906 - accuracy: 0.62 - ETA: 0s - loss: 0.9093 - accuracy: 0.60 - ETA: 0s - loss: 0.9105 - accuracy: 0.60 - ETA: 0s - loss: 0.9152 - accuracy: 0.60 - ETA: 0s - loss: 0.9162 - accuracy: 0.60 - ETA: 0s - loss: 0.9179 - accuracy: 0.6002\n",
      "Epoch 00234: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9179 - accuracy: 0.6002 - val_loss: 1.0614 - val_accuracy: 0.4956 - lr: 0.0049\n",
      "Epoch 235/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9928 - accuracy: 0.54 - ETA: 0s - loss: 0.9671 - accuracy: 0.55 - ETA: 0s - loss: 0.9647 - accuracy: 0.56 - ETA: 0s - loss: 0.9305 - accuracy: 0.58 - ETA: 0s - loss: 0.9196 - accuracy: 0.59 - ETA: 0s - loss: 0.9058 - accuracy: 0.61 - ETA: 0s - loss: 0.9013 - accuracy: 0.61 - ETA: 0s - loss: 0.9006 - accuracy: 0.61 - ETA: 0s - loss: 0.8997 - accuracy: 0.61 - ETA: 0s - loss: 0.9080 - accuracy: 0.60 - ETA: 0s - loss: 0.9019 - accuracy: 0.61 - ETA: 0s - loss: 0.8934 - accuracy: 0.62 - ETA: 0s - loss: 0.8767 - accuracy: 0.63 - ETA: 0s - loss: 0.8890 - accuracy: 0.62 - ETA: 0s - loss: 0.9085 - accuracy: 0.61 - ETA: 0s - loss: 0.9102 - accuracy: 0.60 - ETA: 0s - loss: 0.9150 - accuracy: 0.60 - ETA: 0s - loss: 0.9160 - accuracy: 0.60 - ETA: 0s - loss: 0.9174 - accuracy: 0.6023\n",
      "Epoch 00235: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00235: ReduceLROnPlateau reducing learning rate to 0.003958241641521454.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9174 - accuracy: 0.6023 - val_loss: 1.0598 - val_accuracy: 0.4940 - lr: 0.0049\n",
      "Epoch 236/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9920 - accuracy: 0.53 - ETA: 0s - loss: 0.9702 - accuracy: 0.55 - ETA: 0s - loss: 0.9683 - accuracy: 0.55 - ETA: 0s - loss: 0.9358 - accuracy: 0.58 - ETA: 0s - loss: 0.9237 - accuracy: 0.59 - ETA: 0s - loss: 0.9098 - accuracy: 0.60 - ETA: 0s - loss: 0.9042 - accuracy: 0.61 - ETA: 0s - loss: 0.9026 - accuracy: 0.61 - ETA: 0s - loss: 0.9024 - accuracy: 0.61 - ETA: 0s - loss: 0.9090 - accuracy: 0.60 - ETA: 0s - loss: 0.9029 - accuracy: 0.61 - ETA: 0s - loss: 0.8941 - accuracy: 0.62 - ETA: 0s - loss: 0.8777 - accuracy: 0.63 - ETA: 0s - loss: 0.8894 - accuracy: 0.62 - ETA: 0s - loss: 0.9086 - accuracy: 0.61 - ETA: 0s - loss: 0.9103 - accuracy: 0.60 - ETA: 0s - loss: 0.9151 - accuracy: 0.60 - ETA: 0s - loss: 0.9158 - accuracy: 0.60 - ETA: 0s - loss: 0.9171 - accuracy: 0.6034\n",
      "Epoch 00236: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9171 - accuracy: 0.6034 - val_loss: 1.0616 - val_accuracy: 0.4923 - lr: 0.0040\n",
      "Epoch 237/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.9929 - accuracy: 0.54 - ETA: 0s - loss: 0.9656 - accuracy: 0.55 - ETA: 0s - loss: 0.9613 - accuracy: 0.56 - ETA: 0s - loss: 0.9288 - accuracy: 0.59 - ETA: 0s - loss: 0.9188 - accuracy: 0.59 - ETA: 0s - loss: 0.9048 - accuracy: 0.61 - ETA: 0s - loss: 0.9008 - accuracy: 0.61 - ETA: 0s - loss: 0.8991 - accuracy: 0.61 - ETA: 0s - loss: 0.8994 - accuracy: 0.61 - ETA: 0s - loss: 0.9061 - accuracy: 0.60 - ETA: 0s - loss: 0.9004 - accuracy: 0.61 - ETA: 0s - loss: 0.8923 - accuracy: 0.62 - ETA: 0s - loss: 0.8762 - accuracy: 0.63 - ETA: 0s - loss: 0.8882 - accuracy: 0.62 - ETA: 0s - loss: 0.9073 - accuracy: 0.61 - ETA: 0s - loss: 0.9090 - accuracy: 0.61 - ETA: 0s - loss: 0.9139 - accuracy: 0.60 - ETA: 0s - loss: 0.9149 - accuracy: 0.6048\n",
      "Epoch 00237: val_loss did not improve from 0.99131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9166 - accuracy: 0.6033 - val_loss: 1.0686 - val_accuracy: 0.4914 - lr: 0.0040\n",
      "Epoch 238/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9937 - accuracy: 0.53 - ETA: 0s - loss: 0.9677 - accuracy: 0.55 - ETA: 0s - loss: 0.9653 - accuracy: 0.55 - ETA: 0s - loss: 0.9305 - accuracy: 0.58 - ETA: 0s - loss: 0.9196 - accuracy: 0.59 - ETA: 0s - loss: 0.9047 - accuracy: 0.60 - ETA: 0s - loss: 0.8991 - accuracy: 0.61 - ETA: 0s - loss: 0.8968 - accuracy: 0.61 - ETA: 0s - loss: 0.8967 - accuracy: 0.61 - ETA: 0s - loss: 0.9049 - accuracy: 0.60 - ETA: 0s - loss: 0.8998 - accuracy: 0.61 - ETA: 0s - loss: 0.8913 - accuracy: 0.62 - ETA: 0s - loss: 0.8749 - accuracy: 0.63 - ETA: 0s - loss: 0.8860 - accuracy: 0.62 - ETA: 0s - loss: 0.9049 - accuracy: 0.61 - ETA: 0s - loss: 0.9067 - accuracy: 0.61 - ETA: 0s - loss: 0.9116 - accuracy: 0.60 - ETA: 0s - loss: 0.9133 - accuracy: 0.60 - ETA: 0s - loss: 0.9153 - accuracy: 0.6032\n",
      "Epoch 00238: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9153 - accuracy: 0.6032 - val_loss: 1.0678 - val_accuracy: 0.4915 - lr: 0.0040\n",
      "Epoch 239/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9955 - accuracy: 0.53 - ETA: 0s - loss: 0.9741 - accuracy: 0.54 - ETA: 0s - loss: 0.9708 - accuracy: 0.55 - ETA: 0s - loss: 0.9369 - accuracy: 0.58 - ETA: 0s - loss: 0.9231 - accuracy: 0.59 - ETA: 0s - loss: 0.9085 - accuracy: 0.60 - ETA: 0s - loss: 0.9029 - accuracy: 0.61 - ETA: 0s - loss: 0.9009 - accuracy: 0.61 - ETA: 0s - loss: 0.9011 - accuracy: 0.61 - ETA: 0s - loss: 0.9094 - accuracy: 0.60 - ETA: 0s - loss: 0.9022 - accuracy: 0.61 - ETA: 0s - loss: 0.8941 - accuracy: 0.62 - ETA: 0s - loss: 0.8776 - accuracy: 0.63 - ETA: 0s - loss: 0.8893 - accuracy: 0.62 - ETA: 0s - loss: 0.9083 - accuracy: 0.61 - ETA: 0s - loss: 0.9089 - accuracy: 0.61 - ETA: 0s - loss: 0.9142 - accuracy: 0.60 - ETA: 0s - loss: 0.9149 - accuracy: 0.60 - ETA: 0s - loss: 0.9166 - accuracy: 0.6033\n",
      "Epoch 00239: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9166 - accuracy: 0.6033 - val_loss: 1.0637 - val_accuracy: 0.4906 - lr: 0.0040\n",
      "Epoch 240/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9983 - accuracy: 0.54 - ETA: 0s - loss: 0.9667 - accuracy: 0.56 - ETA: 0s - loss: 0.9627 - accuracy: 0.56 - ETA: 0s - loss: 0.9306 - accuracy: 0.59 - ETA: 0s - loss: 0.9181 - accuracy: 0.59 - ETA: 0s - loss: 0.9047 - accuracy: 0.61 - ETA: 0s - loss: 0.9002 - accuracy: 0.61 - ETA: 0s - loss: 0.8993 - accuracy: 0.61 - ETA: 0s - loss: 0.8985 - accuracy: 0.61 - ETA: 0s - loss: 0.9055 - accuracy: 0.61 - ETA: 0s - loss: 0.8993 - accuracy: 0.61 - ETA: 0s - loss: 0.8911 - accuracy: 0.62 - ETA: 0s - loss: 0.8750 - accuracy: 0.63 - ETA: 0s - loss: 0.8875 - accuracy: 0.62 - ETA: 0s - loss: 0.9067 - accuracy: 0.61 - ETA: 0s - loss: 0.9077 - accuracy: 0.61 - ETA: 0s - loss: 0.9127 - accuracy: 0.60 - ETA: 0s - loss: 0.9137 - accuracy: 0.60 - ETA: 0s - loss: 0.9157 - accuracy: 0.6046\n",
      "Epoch 00240: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9157 - accuracy: 0.6046 - val_loss: 1.0659 - val_accuracy: 0.4922 - lr: 0.0040\n",
      "Epoch 241/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9876 - accuracy: 0.54 - ETA: 0s - loss: 0.9616 - accuracy: 0.55 - ETA: 0s - loss: 0.9604 - accuracy: 0.56 - ETA: 0s - loss: 0.9265 - accuracy: 0.58 - ETA: 0s - loss: 0.9153 - accuracy: 0.59 - ETA: 0s - loss: 0.9022 - accuracy: 0.61 - ETA: 0s - loss: 0.8976 - accuracy: 0.61 - ETA: 0s - loss: 0.8957 - accuracy: 0.61 - ETA: 0s - loss: 0.8959 - accuracy: 0.61 - ETA: 0s - loss: 0.9036 - accuracy: 0.61 - ETA: 0s - loss: 0.8979 - accuracy: 0.61 - ETA: 0s - loss: 0.8903 - accuracy: 0.62 - ETA: 0s - loss: 0.8736 - accuracy: 0.63 - ETA: 0s - loss: 0.8859 - accuracy: 0.62 - ETA: 0s - loss: 0.9057 - accuracy: 0.61 - ETA: 0s - loss: 0.9069 - accuracy: 0.61 - ETA: 0s - loss: 0.9120 - accuracy: 0.60 - ETA: 0s - loss: 0.9134 - accuracy: 0.60 - ETA: 0s - loss: 0.9148 - accuracy: 0.6035\n",
      "Epoch 00241: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9148 - accuracy: 0.6035 - val_loss: 1.0678 - val_accuracy: 0.4925 - lr: 0.0040\n",
      "Epoch 242/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9941 - accuracy: 0.53 - ETA: 0s - loss: 0.9736 - accuracy: 0.55 - ETA: 0s - loss: 0.9713 - accuracy: 0.55 - ETA: 0s - loss: 0.9368 - accuracy: 0.58 - ETA: 0s - loss: 0.9235 - accuracy: 0.59 - ETA: 0s - loss: 0.9100 - accuracy: 0.60 - ETA: 0s - loss: 0.9056 - accuracy: 0.61 - ETA: 0s - loss: 0.9047 - accuracy: 0.61 - ETA: 0s - loss: 0.9039 - accuracy: 0.61 - ETA: 0s - loss: 0.9107 - accuracy: 0.60 - ETA: 0s - loss: 0.9042 - accuracy: 0.61 - ETA: 0s - loss: 0.8957 - accuracy: 0.62 - ETA: 0s - loss: 0.8789 - accuracy: 0.63 - ETA: 0s - loss: 0.8905 - accuracy: 0.62 - ETA: 0s - loss: 0.9096 - accuracy: 0.61 - ETA: 0s - loss: 0.9111 - accuracy: 0.60 - ETA: 0s - loss: 0.9160 - accuracy: 0.60 - ETA: 0s - loss: 0.9170 - accuracy: 0.60 - ETA: 0s - loss: 0.9188 - accuracy: 0.6024\n",
      "Epoch 00242: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9188 - accuracy: 0.6024 - val_loss: 1.0701 - val_accuracy: 0.4958 - lr: 0.0040\n",
      "Epoch 243/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9824 - accuracy: 0.54 - ETA: 0s - loss: 0.9633 - accuracy: 0.55 - ETA: 0s - loss: 0.9608 - accuracy: 0.56 - ETA: 0s - loss: 0.9284 - accuracy: 0.58 - ETA: 0s - loss: 0.9182 - accuracy: 0.59 - ETA: 0s - loss: 0.9047 - accuracy: 0.61 - ETA: 0s - loss: 0.9011 - accuracy: 0.61 - ETA: 0s - loss: 0.8993 - accuracy: 0.61 - ETA: 0s - loss: 0.8991 - accuracy: 0.61 - ETA: 0s - loss: 0.9076 - accuracy: 0.60 - ETA: 0s - loss: 0.9006 - accuracy: 0.61 - ETA: 0s - loss: 0.8925 - accuracy: 0.62 - ETA: 0s - loss: 0.8758 - accuracy: 0.63 - ETA: 0s - loss: 0.8874 - accuracy: 0.62 - ETA: 0s - loss: 0.9064 - accuracy: 0.61 - ETA: 0s - loss: 0.9087 - accuracy: 0.61 - ETA: 0s - loss: 0.9142 - accuracy: 0.60 - ETA: 0s - loss: 0.9152 - accuracy: 0.60 - ETA: 0s - loss: 0.9166 - accuracy: 0.6029\n",
      "Epoch 00243: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9166 - accuracy: 0.6029 - val_loss: 1.0664 - val_accuracy: 0.5013 - lr: 0.0040\n",
      "Epoch 244/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9965 - accuracy: 0.53 - ETA: 0s - loss: 0.9708 - accuracy: 0.55 - ETA: 0s - loss: 0.9702 - accuracy: 0.55 - ETA: 0s - loss: 0.9341 - accuracy: 0.58 - ETA: 0s - loss: 0.9231 - accuracy: 0.59 - ETA: 0s - loss: 0.9088 - accuracy: 0.60 - ETA: 0s - loss: 0.9037 - accuracy: 0.61 - ETA: 0s - loss: 0.9022 - accuracy: 0.61 - ETA: 0s - loss: 0.9022 - accuracy: 0.61 - ETA: 0s - loss: 0.9092 - accuracy: 0.60 - ETA: 0s - loss: 0.9019 - accuracy: 0.61 - ETA: 0s - loss: 0.8933 - accuracy: 0.62 - ETA: 0s - loss: 0.8768 - accuracy: 0.63 - ETA: 0s - loss: 0.8886 - accuracy: 0.62 - ETA: 0s - loss: 0.9073 - accuracy: 0.61 - ETA: 0s - loss: 0.9085 - accuracy: 0.60 - ETA: 0s - loss: 0.9137 - accuracy: 0.60 - ETA: 0s - loss: 0.9146 - accuracy: 0.60 - ETA: 0s - loss: 0.9158 - accuracy: 0.6026\n",
      "Epoch 00244: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9158 - accuracy: 0.6026 - val_loss: 1.0675 - val_accuracy: 0.4909 - lr: 0.0040\n",
      "Epoch 245/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9958 - accuracy: 0.53 - ETA: 0s - loss: 0.9712 - accuracy: 0.55 - ETA: 0s - loss: 0.9666 - accuracy: 0.55 - ETA: 0s - loss: 0.9330 - accuracy: 0.58 - ETA: 0s - loss: 0.9215 - accuracy: 0.59 - ETA: 0s - loss: 0.9072 - accuracy: 0.60 - ETA: 0s - loss: 0.9024 - accuracy: 0.61 - ETA: 0s - loss: 0.9012 - accuracy: 0.61 - ETA: 0s - loss: 0.9007 - accuracy: 0.61 - ETA: 0s - loss: 0.9071 - accuracy: 0.60 - ETA: 0s - loss: 0.9002 - accuracy: 0.61 - ETA: 0s - loss: 0.8923 - accuracy: 0.62 - ETA: 0s - loss: 0.8763 - accuracy: 0.63 - ETA: 0s - loss: 0.8883 - accuracy: 0.62 - ETA: 0s - loss: 0.9073 - accuracy: 0.60 - ETA: 0s - loss: 0.9090 - accuracy: 0.60 - ETA: 0s - loss: 0.9139 - accuracy: 0.60 - ETA: 0s - loss: 0.9149 - accuracy: 0.60 - ETA: 0s - loss: 0.9164 - accuracy: 0.6015\n",
      "Epoch 00245: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9164 - accuracy: 0.6015 - val_loss: 1.0686 - val_accuracy: 0.5013 - lr: 0.0040\n",
      "Epoch 246/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9885 - accuracy: 0.54 - ETA: 0s - loss: 0.9639 - accuracy: 0.55 - ETA: 0s - loss: 0.9628 - accuracy: 0.56 - ETA: 0s - loss: 0.9293 - accuracy: 0.58 - ETA: 0s - loss: 0.9189 - accuracy: 0.59 - ETA: 0s - loss: 0.9058 - accuracy: 0.61 - ETA: 0s - loss: 0.9009 - accuracy: 0.61 - ETA: 0s - loss: 0.9002 - accuracy: 0.61 - ETA: 0s - loss: 0.8996 - accuracy: 0.61 - ETA: 0s - loss: 0.9065 - accuracy: 0.60 - ETA: 0s - loss: 0.9002 - accuracy: 0.61 - ETA: 0s - loss: 0.8925 - accuracy: 0.62 - ETA: 0s - loss: 0.8758 - accuracy: 0.63 - ETA: 0s - loss: 0.8877 - accuracy: 0.62 - ETA: 0s - loss: 0.9064 - accuracy: 0.61 - ETA: 0s - loss: 0.9079 - accuracy: 0.61 - ETA: 0s - loss: 0.9136 - accuracy: 0.60 - ETA: 0s - loss: 0.9147 - accuracy: 0.60 - ETA: 0s - loss: 0.9162 - accuracy: 0.6045\n",
      "Epoch 00246: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9162 - accuracy: 0.6045 - val_loss: 1.0713 - val_accuracy: 0.4917 - lr: 0.0040\n",
      "Epoch 247/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0006 - accuracy: 0.53 - ETA: 0s - loss: 0.9675 - accuracy: 0.55 - ETA: 0s - loss: 0.9643 - accuracy: 0.56 - ETA: 0s - loss: 0.9329 - accuracy: 0.58 - ETA: 0s - loss: 0.9191 - accuracy: 0.59 - ETA: 0s - loss: 0.9048 - accuracy: 0.61 - ETA: 0s - loss: 0.9007 - accuracy: 0.61 - ETA: 0s - loss: 0.8989 - accuracy: 0.61 - ETA: 0s - loss: 0.8967 - accuracy: 0.61 - ETA: 0s - loss: 0.9052 - accuracy: 0.60 - ETA: 0s - loss: 0.8989 - accuracy: 0.61 - ETA: 0s - loss: 0.8909 - accuracy: 0.62 - ETA: 0s - loss: 0.8746 - accuracy: 0.63 - ETA: 0s - loss: 0.8862 - accuracy: 0.62 - ETA: 0s - loss: 0.9051 - accuracy: 0.61 - ETA: 0s - loss: 0.9072 - accuracy: 0.60 - ETA: 0s - loss: 0.9122 - accuracy: 0.60 - ETA: 0s - loss: 0.9137 - accuracy: 0.60 - ETA: 0s - loss: 0.9156 - accuracy: 0.6029\n",
      "Epoch 00247: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9156 - accuracy: 0.6029 - val_loss: 1.0661 - val_accuracy: 0.4941 - lr: 0.0040\n",
      "Epoch 248/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9919 - accuracy: 0.54 - ETA: 0s - loss: 0.9650 - accuracy: 0.55 - ETA: 0s - loss: 0.9608 - accuracy: 0.56 - ETA: 0s - loss: 0.9279 - accuracy: 0.58 - ETA: 0s - loss: 0.9185 - accuracy: 0.59 - ETA: 0s - loss: 0.9042 - accuracy: 0.61 - ETA: 0s - loss: 0.9004 - accuracy: 0.61 - ETA: 0s - loss: 0.8988 - accuracy: 0.61 - ETA: 0s - loss: 0.8980 - accuracy: 0.61 - ETA: 0s - loss: 0.9056 - accuracy: 0.60 - ETA: 0s - loss: 0.8993 - accuracy: 0.61 - ETA: 0s - loss: 0.8911 - accuracy: 0.62 - ETA: 0s - loss: 0.8750 - accuracy: 0.63 - ETA: 0s - loss: 0.8868 - accuracy: 0.62 - ETA: 0s - loss: 0.9052 - accuracy: 0.61 - ETA: 0s - loss: 0.9070 - accuracy: 0.61 - ETA: 0s - loss: 0.9121 - accuracy: 0.60 - ETA: 0s - loss: 0.9146 - accuracy: 0.6037\n",
      "Epoch 00248: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9146 - accuracy: 0.6037 - val_loss: 1.0668 - val_accuracy: 0.4951 - lr: 0.0040\n",
      "Epoch 249/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9878 - accuracy: 0.55 - ETA: 0s - loss: 0.9622 - accuracy: 0.56 - ETA: 0s - loss: 0.9605 - accuracy: 0.56 - ETA: 0s - loss: 0.9305 - accuracy: 0.58 - ETA: 0s - loss: 0.9207 - accuracy: 0.59 - ETA: 0s - loss: 0.9062 - accuracy: 0.60 - ETA: 0s - loss: 0.9009 - accuracy: 0.61 - ETA: 0s - loss: 0.9000 - accuracy: 0.61 - ETA: 0s - loss: 0.9004 - accuracy: 0.61 - ETA: 0s - loss: 0.9076 - accuracy: 0.60 - ETA: 0s - loss: 0.9007 - accuracy: 0.61 - ETA: 0s - loss: 0.8924 - accuracy: 0.62 - ETA: 0s - loss: 0.8762 - accuracy: 0.63 - ETA: 0s - loss: 0.8872 - accuracy: 0.62 - ETA: 0s - loss: 0.9055 - accuracy: 0.61 - ETA: 0s - loss: 0.9079 - accuracy: 0.60 - ETA: 0s - loss: 0.9131 - accuracy: 0.60 - ETA: 0s - loss: 0.9139 - accuracy: 0.60 - ETA: 0s - loss: 0.9160 - accuracy: 0.6023\n",
      "Epoch 00249: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00249: ReduceLROnPlateau reducing learning rate to 0.003166593238711357.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9160 - accuracy: 0.6023 - val_loss: 1.0698 - val_accuracy: 0.4935 - lr: 0.0040\n",
      "Epoch 250/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0025 - accuracy: 0.53 - ETA: 0s - loss: 0.9675 - accuracy: 0.55 - ETA: 0s - loss: 0.9635 - accuracy: 0.56 - ETA: 0s - loss: 0.9313 - accuracy: 0.58 - ETA: 0s - loss: 0.9198 - accuracy: 0.59 - ETA: 0s - loss: 0.9050 - accuracy: 0.60 - ETA: 0s - loss: 0.9006 - accuracy: 0.61 - ETA: 0s - loss: 0.8990 - accuracy: 0.61 - ETA: 0s - loss: 0.8976 - accuracy: 0.61 - ETA: 0s - loss: 0.9045 - accuracy: 0.60 - ETA: 0s - loss: 0.8979 - accuracy: 0.61 - ETA: 0s - loss: 0.8898 - accuracy: 0.62 - ETA: 0s - loss: 0.8735 - accuracy: 0.63 - ETA: 0s - loss: 0.8861 - accuracy: 0.62 - ETA: 0s - loss: 0.9049 - accuracy: 0.61 - ETA: 0s - loss: 0.9064 - accuracy: 0.61 - ETA: 0s - loss: 0.9117 - accuracy: 0.60 - ETA: 0s - loss: 0.9131 - accuracy: 0.60 - ETA: 0s - loss: 0.9143 - accuracy: 0.6036\n",
      "Epoch 00250: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9143 - accuracy: 0.6036 - val_loss: 1.0688 - val_accuracy: 0.4912 - lr: 0.0032\n",
      "Epoch 251/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9937 - accuracy: 0.54 - ETA: 0s - loss: 0.9657 - accuracy: 0.55 - ETA: 0s - loss: 0.9626 - accuracy: 0.56 - ETA: 0s - loss: 0.9316 - accuracy: 0.58 - ETA: 0s - loss: 0.9227 - accuracy: 0.59 - ETA: 0s - loss: 0.9083 - accuracy: 0.60 - ETA: 0s - loss: 0.9025 - accuracy: 0.61 - ETA: 0s - loss: 0.9003 - accuracy: 0.61 - ETA: 0s - loss: 0.8987 - accuracy: 0.61 - ETA: 0s - loss: 0.9057 - accuracy: 0.60 - ETA: 0s - loss: 0.8997 - accuracy: 0.61 - ETA: 0s - loss: 0.8915 - accuracy: 0.62 - ETA: 0s - loss: 0.8755 - accuracy: 0.63 - ETA: 0s - loss: 0.8877 - accuracy: 0.62 - ETA: 0s - loss: 0.9069 - accuracy: 0.61 - ETA: 0s - loss: 0.9082 - accuracy: 0.60 - ETA: 0s - loss: 0.9129 - accuracy: 0.60 - ETA: 0s - loss: 0.9142 - accuracy: 0.60 - ETA: 0s - loss: 0.9159 - accuracy: 0.6025\n",
      "Epoch 00251: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9159 - accuracy: 0.6025 - val_loss: 1.0771 - val_accuracy: 0.4866 - lr: 0.0032\n",
      "Epoch 252/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9888 - accuracy: 0.54 - ETA: 0s - loss: 0.9647 - accuracy: 0.55 - ETA: 0s - loss: 0.9609 - accuracy: 0.55 - ETA: 0s - loss: 0.9288 - accuracy: 0.58 - ETA: 0s - loss: 0.9168 - accuracy: 0.59 - ETA: 0s - loss: 0.9030 - accuracy: 0.60 - ETA: 0s - loss: 0.8983 - accuracy: 0.61 - ETA: 0s - loss: 0.8980 - accuracy: 0.61 - ETA: 0s - loss: 0.8970 - accuracy: 0.61 - ETA: 0s - loss: 0.9038 - accuracy: 0.60 - ETA: 0s - loss: 0.8986 - accuracy: 0.61 - ETA: 0s - loss: 0.8910 - accuracy: 0.62 - ETA: 0s - loss: 0.8744 - accuracy: 0.63 - ETA: 0s - loss: 0.8863 - accuracy: 0.62 - ETA: 0s - loss: 0.9052 - accuracy: 0.60 - ETA: 0s - loss: 0.9072 - accuracy: 0.60 - ETA: 0s - loss: 0.9120 - accuracy: 0.60 - ETA: 0s - loss: 0.9145 - accuracy: 0.6016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00252: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9145 - accuracy: 0.6016 - val_loss: 1.0754 - val_accuracy: 0.4870 - lr: 0.0032\n",
      "Epoch 253/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9942 - accuracy: 0.54 - ETA: 0s - loss: 0.9663 - accuracy: 0.55 - ETA: 0s - loss: 0.9635 - accuracy: 0.55 - ETA: 0s - loss: 0.9301 - accuracy: 0.58 - ETA: 0s - loss: 0.9185 - accuracy: 0.59 - ETA: 0s - loss: 0.9047 - accuracy: 0.61 - ETA: 0s - loss: 0.8997 - accuracy: 0.61 - ETA: 0s - loss: 0.8984 - accuracy: 0.61 - ETA: 0s - loss: 0.8986 - accuracy: 0.61 - ETA: 0s - loss: 0.9052 - accuracy: 0.60 - ETA: 0s - loss: 0.8985 - accuracy: 0.61 - ETA: 0s - loss: 0.8896 - accuracy: 0.62 - ETA: 0s - loss: 0.8737 - accuracy: 0.63 - ETA: 0s - loss: 0.8858 - accuracy: 0.62 - ETA: 0s - loss: 0.9046 - accuracy: 0.61 - ETA: 0s - loss: 0.9063 - accuracy: 0.61 - ETA: 0s - loss: 0.9114 - accuracy: 0.60 - ETA: 0s - loss: 0.9122 - accuracy: 0.60 - ETA: 0s - loss: 0.9133 - accuracy: 0.6042\n",
      "Epoch 00253: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9133 - accuracy: 0.6042 - val_loss: 1.0881 - val_accuracy: 0.4832 - lr: 0.0032\n",
      "Epoch 254/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9913 - accuracy: 0.54 - ETA: 0s - loss: 0.9677 - accuracy: 0.56 - ETA: 0s - loss: 0.9600 - accuracy: 0.56 - ETA: 0s - loss: 0.9289 - accuracy: 0.59 - ETA: 0s - loss: 0.9164 - accuracy: 0.60 - ETA: 0s - loss: 0.9027 - accuracy: 0.61 - ETA: 0s - loss: 0.8983 - accuracy: 0.61 - ETA: 0s - loss: 0.8972 - accuracy: 0.62 - ETA: 0s - loss: 0.8974 - accuracy: 0.61 - ETA: 0s - loss: 0.9054 - accuracy: 0.61 - ETA: 0s - loss: 0.8995 - accuracy: 0.61 - ETA: 0s - loss: 0.8918 - accuracy: 0.62 - ETA: 0s - loss: 0.8753 - accuracy: 0.63 - ETA: 0s - loss: 0.8874 - accuracy: 0.62 - ETA: 0s - loss: 0.9061 - accuracy: 0.61 - ETA: 0s - loss: 0.9077 - accuracy: 0.61 - ETA: 0s - loss: 0.9126 - accuracy: 0.60 - ETA: 0s - loss: 0.9133 - accuracy: 0.60 - ETA: 0s - loss: 0.9152 - accuracy: 0.6029\n",
      "Epoch 00254: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9152 - accuracy: 0.6029 - val_loss: 1.0835 - val_accuracy: 0.4865 - lr: 0.0032\n",
      "Epoch 255/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9978 - accuracy: 0.53 - ETA: 0s - loss: 0.9643 - accuracy: 0.55 - ETA: 0s - loss: 0.9617 - accuracy: 0.56 - ETA: 0s - loss: 0.9272 - accuracy: 0.58 - ETA: 0s - loss: 0.9179 - accuracy: 0.59 - ETA: 0s - loss: 0.9052 - accuracy: 0.60 - ETA: 0s - loss: 0.9002 - accuracy: 0.61 - ETA: 0s - loss: 0.8981 - accuracy: 0.61 - ETA: 0s - loss: 0.8980 - accuracy: 0.61 - ETA: 0s - loss: 0.9053 - accuracy: 0.60 - ETA: 0s - loss: 0.8992 - accuracy: 0.61 - ETA: 0s - loss: 0.8909 - accuracy: 0.62 - ETA: 0s - loss: 0.8745 - accuracy: 0.63 - ETA: 0s - loss: 0.8861 - accuracy: 0.62 - ETA: 0s - loss: 0.9043 - accuracy: 0.61 - ETA: 0s - loss: 0.9063 - accuracy: 0.61 - ETA: 0s - loss: 0.9115 - accuracy: 0.60 - ETA: 0s - loss: 0.9146 - accuracy: 0.6029\n",
      "Epoch 00255: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9146 - accuracy: 0.6029 - val_loss: 1.0712 - val_accuracy: 0.4899 - lr: 0.0032\n",
      "Epoch 256/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9983 - accuracy: 0.54 - ETA: 0s - loss: 0.9721 - accuracy: 0.55 - ETA: 0s - loss: 0.9674 - accuracy: 0.56 - ETA: 0s - loss: 0.9330 - accuracy: 0.58 - ETA: 0s - loss: 0.9204 - accuracy: 0.59 - ETA: 0s - loss: 0.9062 - accuracy: 0.61 - ETA: 0s - loss: 0.9010 - accuracy: 0.61 - ETA: 0s - loss: 0.8993 - accuracy: 0.61 - ETA: 0s - loss: 0.8990 - accuracy: 0.61 - ETA: 0s - loss: 0.9057 - accuracy: 0.60 - ETA: 0s - loss: 0.8989 - accuracy: 0.61 - ETA: 0s - loss: 0.8908 - accuracy: 0.62 - ETA: 0s - loss: 0.8746 - accuracy: 0.63 - ETA: 0s - loss: 0.8858 - accuracy: 0.62 - ETA: 0s - loss: 0.9040 - accuracy: 0.61 - ETA: 0s - loss: 0.9054 - accuracy: 0.61 - ETA: 0s - loss: 0.9106 - accuracy: 0.60 - ETA: 0s - loss: 0.9121 - accuracy: 0.60 - ETA: 0s - loss: 0.9142 - accuracy: 0.6040\n",
      "Epoch 00256: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9142 - accuracy: 0.6040 - val_loss: 1.0778 - val_accuracy: 0.4888 - lr: 0.0032\n",
      "Epoch 257/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9866 - accuracy: 0.54 - ETA: 0s - loss: 0.9612 - accuracy: 0.56 - ETA: 0s - loss: 0.9598 - accuracy: 0.56 - ETA: 0s - loss: 0.9266 - accuracy: 0.59 - ETA: 0s - loss: 0.9141 - accuracy: 0.60 - ETA: 0s - loss: 0.8999 - accuracy: 0.61 - ETA: 0s - loss: 0.8971 - accuracy: 0.61 - ETA: 0s - loss: 0.8958 - accuracy: 0.61 - ETA: 0s - loss: 0.8950 - accuracy: 0.61 - ETA: 0s - loss: 0.9038 - accuracy: 0.61 - ETA: 0s - loss: 0.8974 - accuracy: 0.61 - ETA: 0s - loss: 0.8894 - accuracy: 0.62 - ETA: 0s - loss: 0.8728 - accuracy: 0.63 - ETA: 0s - loss: 0.8850 - accuracy: 0.62 - ETA: 0s - loss: 0.9040 - accuracy: 0.61 - ETA: 0s - loss: 0.9056 - accuracy: 0.61 - ETA: 0s - loss: 0.9105 - accuracy: 0.60 - ETA: 0s - loss: 0.9123 - accuracy: 0.60 - ETA: 0s - loss: 0.9135 - accuracy: 0.6049\n",
      "Epoch 00257: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9135 - accuracy: 0.6049 - val_loss: 1.0764 - val_accuracy: 0.4917 - lr: 0.0032\n",
      "Epoch 258/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9947 - accuracy: 0.53 - ETA: 0s - loss: 0.9698 - accuracy: 0.55 - ETA: 0s - loss: 0.9664 - accuracy: 0.55 - ETA: 0s - loss: 0.9348 - accuracy: 0.58 - ETA: 0s - loss: 0.9216 - accuracy: 0.59 - ETA: 0s - loss: 0.9072 - accuracy: 0.60 - ETA: 0s - loss: 0.9018 - accuracy: 0.61 - ETA: 0s - loss: 0.9011 - accuracy: 0.61 - ETA: 0s - loss: 0.9005 - accuracy: 0.61 - ETA: 0s - loss: 0.9069 - accuracy: 0.60 - ETA: 0s - loss: 0.8996 - accuracy: 0.61 - ETA: 0s - loss: 0.8914 - accuracy: 0.62 - ETA: 0s - loss: 0.8749 - accuracy: 0.63 - ETA: 0s - loss: 0.8861 - accuracy: 0.62 - ETA: 0s - loss: 0.9045 - accuracy: 0.61 - ETA: 0s - loss: 0.9061 - accuracy: 0.61 - ETA: 0s - loss: 0.9108 - accuracy: 0.60 - ETA: 0s - loss: 0.9119 - accuracy: 0.60 - ETA: 0s - loss: 0.9135 - accuracy: 0.6056\n",
      "Epoch 00258: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9135 - accuracy: 0.6056 - val_loss: 1.0727 - val_accuracy: 0.4930 - lr: 0.0032\n",
      "Epoch 259/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9940 - accuracy: 0.54 - ETA: 0s - loss: 0.9606 - accuracy: 0.56 - ETA: 0s - loss: 0.9587 - accuracy: 0.56 - ETA: 0s - loss: 0.9254 - accuracy: 0.58 - ETA: 0s - loss: 0.9142 - accuracy: 0.59 - ETA: 0s - loss: 0.9016 - accuracy: 0.61 - ETA: 0s - loss: 0.8977 - accuracy: 0.61 - ETA: 0s - loss: 0.8963 - accuracy: 0.61 - ETA: 0s - loss: 0.8961 - accuracy: 0.61 - ETA: 0s - loss: 0.9021 - accuracy: 0.60 - ETA: 0s - loss: 0.8959 - accuracy: 0.61 - ETA: 0s - loss: 0.8885 - accuracy: 0.62 - ETA: 0s - loss: 0.8721 - accuracy: 0.63 - ETA: 0s - loss: 0.8838 - accuracy: 0.62 - ETA: 0s - loss: 0.9034 - accuracy: 0.61 - ETA: 0s - loss: 0.9054 - accuracy: 0.61 - ETA: 0s - loss: 0.9104 - accuracy: 0.60 - ETA: 0s - loss: 0.9116 - accuracy: 0.60 - ETA: 0s - loss: 0.9134 - accuracy: 0.6040\n",
      "Epoch 00259: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9134 - accuracy: 0.6040 - val_loss: 1.0691 - val_accuracy: 0.4920 - lr: 0.0032\n",
      "Epoch 260/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9931 - accuracy: 0.54 - ETA: 0s - loss: 0.9613 - accuracy: 0.56 - ETA: 0s - loss: 0.9608 - accuracy: 0.56 - ETA: 0s - loss: 0.9270 - accuracy: 0.58 - ETA: 0s - loss: 0.9153 - accuracy: 0.59 - ETA: 0s - loss: 0.9018 - accuracy: 0.61 - ETA: 0s - loss: 0.8964 - accuracy: 0.61 - ETA: 0s - loss: 0.8958 - accuracy: 0.61 - ETA: 0s - loss: 0.8958 - accuracy: 0.61 - ETA: 0s - loss: 0.9030 - accuracy: 0.61 - ETA: 0s - loss: 0.8957 - accuracy: 0.61 - ETA: 0s - loss: 0.8879 - accuracy: 0.62 - ETA: 0s - loss: 0.8718 - accuracy: 0.63 - ETA: 0s - loss: 0.8835 - accuracy: 0.62 - ETA: 0s - loss: 0.9021 - accuracy: 0.61 - ETA: 0s - loss: 0.9039 - accuracy: 0.61 - ETA: 0s - loss: 0.9094 - accuracy: 0.60 - ETA: 0s - loss: 0.9107 - accuracy: 0.60 - ETA: 0s - loss: 0.9122 - accuracy: 0.6049\n",
      "Epoch 00260: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9122 - accuracy: 0.6049 - val_loss: 1.0778 - val_accuracy: 0.4902 - lr: 0.0032\n",
      "Epoch 261/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9940 - accuracy: 0.54 - ETA: 0s - loss: 0.9662 - accuracy: 0.55 - ETA: 0s - loss: 0.9625 - accuracy: 0.56 - ETA: 0s - loss: 0.9315 - accuracy: 0.58 - ETA: 0s - loss: 0.9187 - accuracy: 0.59 - ETA: 0s - loss: 0.9038 - accuracy: 0.60 - ETA: 0s - loss: 0.8990 - accuracy: 0.61 - ETA: 0s - loss: 0.8972 - accuracy: 0.61 - ETA: 0s - loss: 0.8967 - accuracy: 0.61 - ETA: 0s - loss: 0.9034 - accuracy: 0.60 - ETA: 0s - loss: 0.8966 - accuracy: 0.61 - ETA: 0s - loss: 0.8887 - accuracy: 0.62 - ETA: 0s - loss: 0.8726 - accuracy: 0.63 - ETA: 0s - loss: 0.8836 - accuracy: 0.62 - ETA: 0s - loss: 0.9022 - accuracy: 0.61 - ETA: 0s - loss: 0.9044 - accuracy: 0.61 - ETA: 0s - loss: 0.9091 - accuracy: 0.60 - ETA: 0s - loss: 0.9107 - accuracy: 0.60 - ETA: 0s - loss: 0.9126 - accuracy: 0.6041\n",
      "Epoch 00261: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9126 - accuracy: 0.6041 - val_loss: 1.0283 - val_accuracy: 0.4919 - lr: 0.0032\n",
      "Epoch 262/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9882 - accuracy: 0.54 - ETA: 0s - loss: 0.9616 - accuracy: 0.55 - ETA: 0s - loss: 0.9558 - accuracy: 0.56 - ETA: 0s - loss: 0.9227 - accuracy: 0.59 - ETA: 0s - loss: 0.9118 - accuracy: 0.60 - ETA: 0s - loss: 0.8993 - accuracy: 0.61 - ETA: 0s - loss: 0.8944 - accuracy: 0.61 - ETA: 0s - loss: 0.8938 - accuracy: 0.62 - ETA: 0s - loss: 0.8936 - accuracy: 0.61 - ETA: 0s - loss: 0.9005 - accuracy: 0.61 - ETA: 0s - loss: 0.8945 - accuracy: 0.61 - ETA: 0s - loss: 0.8865 - accuracy: 0.62 - ETA: 0s - loss: 0.8694 - accuracy: 0.63 - ETA: 0s - loss: 0.8815 - accuracy: 0.62 - ETA: 0s - loss: 0.9015 - accuracy: 0.61 - ETA: 0s - loss: 0.9038 - accuracy: 0.61 - ETA: 0s - loss: 0.9089 - accuracy: 0.60 - ETA: 0s - loss: 0.9103 - accuracy: 0.60 - ETA: 0s - loss: 0.9116 - accuracy: 0.6047\n",
      "Epoch 00262: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9116 - accuracy: 0.6047 - val_loss: 1.0376 - val_accuracy: 0.4899 - lr: 0.0032\n",
      "Epoch 263/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9901 - accuracy: 0.53 - ETA: 0s - loss: 0.9651 - accuracy: 0.55 - ETA: 0s - loss: 0.9629 - accuracy: 0.55 - ETA: 0s - loss: 0.9262 - accuracy: 0.58 - ETA: 0s - loss: 0.9158 - accuracy: 0.59 - ETA: 0s - loss: 0.9024 - accuracy: 0.60 - ETA: 0s - loss: 0.8984 - accuracy: 0.61 - ETA: 0s - loss: 0.8980 - accuracy: 0.61 - ETA: 0s - loss: 0.8982 - accuracy: 0.61 - ETA: 0s - loss: 0.9052 - accuracy: 0.60 - ETA: 0s - loss: 0.8989 - accuracy: 0.61 - ETA: 0s - loss: 0.8910 - accuracy: 0.62 - ETA: 0s - loss: 0.8744 - accuracy: 0.63 - ETA: 0s - loss: 0.8863 - accuracy: 0.62 - ETA: 0s - loss: 0.9055 - accuracy: 0.61 - ETA: 0s - loss: 0.9070 - accuracy: 0.60 - ETA: 0s - loss: 0.9118 - accuracy: 0.60 - ETA: 0s - loss: 0.9124 - accuracy: 0.60 - ETA: 0s - loss: 0.9134 - accuracy: 0.6033\n",
      "Epoch 00263: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00263: ReduceLROnPlateau reducing learning rate to 0.00253327451646328.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9134 - accuracy: 0.6033 - val_loss: 1.0841 - val_accuracy: 0.4881 - lr: 0.0032\n",
      "Epoch 264/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9813 - accuracy: 0.54 - ETA: 0s - loss: 0.9546 - accuracy: 0.56 - ETA: 0s - loss: 0.9548 - accuracy: 0.56 - ETA: 0s - loss: 0.9229 - accuracy: 0.59 - ETA: 0s - loss: 0.9118 - accuracy: 0.60 - ETA: 0s - loss: 0.8992 - accuracy: 0.61 - ETA: 0s - loss: 0.8948 - accuracy: 0.61 - ETA: 0s - loss: 0.8940 - accuracy: 0.61 - ETA: 0s - loss: 0.8948 - accuracy: 0.61 - ETA: 0s - loss: 0.9015 - accuracy: 0.60 - ETA: 0s - loss: 0.8947 - accuracy: 0.61 - ETA: 0s - loss: 0.8866 - accuracy: 0.62 - ETA: 0s - loss: 0.8704 - accuracy: 0.63 - ETA: 0s - loss: 0.8821 - accuracy: 0.62 - ETA: 0s - loss: 0.9014 - accuracy: 0.61 - ETA: 0s - loss: 0.9029 - accuracy: 0.61 - ETA: 0s - loss: 0.9078 - accuracy: 0.60 - ETA: 0s - loss: 0.9090 - accuracy: 0.60 - ETA: 0s - loss: 0.9111 - accuracy: 0.6031\n",
      "Epoch 00264: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9111 - accuracy: 0.6031 - val_loss: 1.0756 - val_accuracy: 0.4938 - lr: 0.0025\n",
      "Epoch 265/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9797 - accuracy: 0.54 - ETA: 0s - loss: 0.9542 - accuracy: 0.55 - ETA: 0s - loss: 0.9524 - accuracy: 0.56 - ETA: 0s - loss: 0.9211 - accuracy: 0.58 - ETA: 0s - loss: 0.9116 - accuracy: 0.59 - ETA: 0s - loss: 0.8990 - accuracy: 0.60 - ETA: 0s - loss: 0.8945 - accuracy: 0.61 - ETA: 0s - loss: 0.8953 - accuracy: 0.61 - ETA: 0s - loss: 0.8949 - accuracy: 0.61 - ETA: 0s - loss: 0.9013 - accuracy: 0.60 - ETA: 0s - loss: 0.8944 - accuracy: 0.61 - ETA: 0s - loss: 0.8867 - accuracy: 0.62 - ETA: 0s - loss: 0.8705 - accuracy: 0.63 - ETA: 0s - loss: 0.8832 - accuracy: 0.62 - ETA: 0s - loss: 0.9017 - accuracy: 0.61 - ETA: 0s - loss: 0.9036 - accuracy: 0.61 - ETA: 0s - loss: 0.9086 - accuracy: 0.60 - ETA: 0s - loss: 0.9100 - accuracy: 0.60 - ETA: 0s - loss: 0.9113 - accuracy: 0.6040\n",
      "Epoch 00265: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9113 - accuracy: 0.6040 - val_loss: 1.0871 - val_accuracy: 0.4892 - lr: 0.0025\n",
      "Epoch 266/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9932 - accuracy: 0.54 - ETA: 0s - loss: 0.9607 - accuracy: 0.56 - ETA: 0s - loss: 0.9576 - accuracy: 0.56 - ETA: 0s - loss: 0.9259 - accuracy: 0.59 - ETA: 0s - loss: 0.9142 - accuracy: 0.60 - ETA: 0s - loss: 0.8999 - accuracy: 0.61 - ETA: 0s - loss: 0.8962 - accuracy: 0.61 - ETA: 0s - loss: 0.8951 - accuracy: 0.62 - ETA: 0s - loss: 0.8945 - accuracy: 0.61 - ETA: 0s - loss: 0.9013 - accuracy: 0.61 - ETA: 0s - loss: 0.8946 - accuracy: 0.61 - ETA: 0s - loss: 0.8871 - accuracy: 0.62 - ETA: 0s - loss: 0.8707 - accuracy: 0.64 - ETA: 0s - loss: 0.8820 - accuracy: 0.62 - ETA: 0s - loss: 0.9014 - accuracy: 0.61 - ETA: 0s - loss: 0.9032 - accuracy: 0.61 - ETA: 0s - loss: 0.9078 - accuracy: 0.60 - ETA: 0s - loss: 0.9096 - accuracy: 0.60 - ETA: 0s - loss: 0.9116 - accuracy: 0.6046\n",
      "Epoch 00266: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9116 - accuracy: 0.6046 - val_loss: 1.0321 - val_accuracy: 0.4928 - lr: 0.0025\n",
      "Epoch 267/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9969 - accuracy: 0.53 - ETA: 0s - loss: 0.9676 - accuracy: 0.55 - ETA: 0s - loss: 0.9609 - accuracy: 0.56 - ETA: 0s - loss: 0.9270 - accuracy: 0.58 - ETA: 0s - loss: 0.9158 - accuracy: 0.59 - ETA: 0s - loss: 0.9028 - accuracy: 0.61 - ETA: 0s - loss: 0.8975 - accuracy: 0.61 - ETA: 0s - loss: 0.8974 - accuracy: 0.61 - ETA: 0s - loss: 0.8974 - accuracy: 0.61 - ETA: 0s - loss: 0.9045 - accuracy: 0.60 - ETA: 0s - loss: 0.8986 - accuracy: 0.61 - ETA: 0s - loss: 0.8901 - accuracy: 0.62 - ETA: 0s - loss: 0.8731 - accuracy: 0.63 - ETA: 0s - loss: 0.8847 - accuracy: 0.62 - ETA: 0s - loss: 0.9036 - accuracy: 0.61 - ETA: 0s - loss: 0.9051 - accuracy: 0.61 - ETA: 0s - loss: 0.9104 - accuracy: 0.60 - ETA: 0s - loss: 0.9115 - accuracy: 0.60 - ETA: 0s - loss: 0.9130 - accuracy: 0.6034\n",
      "Epoch 00267: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9130 - accuracy: 0.6034 - val_loss: 1.0803 - val_accuracy: 0.4917 - lr: 0.0025\n",
      "Epoch 268/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0033 - accuracy: 0.53 - ETA: 0s - loss: 0.9700 - accuracy: 0.55 - ETA: 0s - loss: 0.9633 - accuracy: 0.56 - ETA: 0s - loss: 0.9272 - accuracy: 0.58 - ETA: 0s - loss: 0.9158 - accuracy: 0.59 - ETA: 0s - loss: 0.9022 - accuracy: 0.61 - ETA: 0s - loss: 0.8974 - accuracy: 0.61 - ETA: 0s - loss: 0.8966 - accuracy: 0.61 - ETA: 0s - loss: 0.8964 - accuracy: 0.61 - ETA: 0s - loss: 0.9036 - accuracy: 0.60 - ETA: 0s - loss: 0.8978 - accuracy: 0.61 - ETA: 0s - loss: 0.8898 - accuracy: 0.62 - ETA: 0s - loss: 0.8732 - accuracy: 0.63 - ETA: 0s - loss: 0.8831 - accuracy: 0.62 - ETA: 0s - loss: 0.9017 - accuracy: 0.61 - ETA: 0s - loss: 0.9032 - accuracy: 0.61 - ETA: 0s - loss: 0.9081 - accuracy: 0.60 - ETA: 0s - loss: 0.9095 - accuracy: 0.60 - ETA: 0s - loss: 0.9104 - accuracy: 0.6049\n",
      "Epoch 00268: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9104 - accuracy: 0.6049 - val_loss: 1.0816 - val_accuracy: 0.4946 - lr: 0.0025\n",
      "Epoch 269/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9933 - accuracy: 0.53 - ETA: 0s - loss: 0.9610 - accuracy: 0.55 - ETA: 0s - loss: 0.9598 - accuracy: 0.55 - ETA: 0s - loss: 0.9248 - accuracy: 0.58 - ETA: 0s - loss: 0.9124 - accuracy: 0.59 - ETA: 0s - loss: 0.8992 - accuracy: 0.61 - ETA: 0s - loss: 0.8957 - accuracy: 0.61 - ETA: 0s - loss: 0.8946 - accuracy: 0.61 - ETA: 0s - loss: 0.8942 - accuracy: 0.61 - ETA: 0s - loss: 0.9002 - accuracy: 0.61 - ETA: 0s - loss: 0.8943 - accuracy: 0.61 - ETA: 0s - loss: 0.8867 - accuracy: 0.62 - ETA: 0s - loss: 0.8705 - accuracy: 0.63 - ETA: 0s - loss: 0.8822 - accuracy: 0.62 - ETA: 0s - loss: 0.9013 - accuracy: 0.61 - ETA: 0s - loss: 0.9033 - accuracy: 0.61 - ETA: 0s - loss: 0.9080 - accuracy: 0.60 - ETA: 0s - loss: 0.9095 - accuracy: 0.60 - ETA: 0s - loss: 0.9110 - accuracy: 0.6046\n",
      "Epoch 00269: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9110 - accuracy: 0.6046 - val_loss: 1.0913 - val_accuracy: 0.4946 - lr: 0.0025\n",
      "Epoch 270/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9916 - accuracy: 0.54 - ETA: 0s - loss: 0.9546 - accuracy: 0.56 - ETA: 0s - loss: 0.9551 - accuracy: 0.56 - ETA: 0s - loss: 0.9211 - accuracy: 0.59 - ETA: 0s - loss: 0.9120 - accuracy: 0.59 - ETA: 0s - loss: 0.8994 - accuracy: 0.61 - ETA: 0s - loss: 0.8951 - accuracy: 0.61 - ETA: 0s - loss: 0.8942 - accuracy: 0.61 - ETA: 0s - loss: 0.8938 - accuracy: 0.61 - ETA: 0s - loss: 0.9007 - accuracy: 0.60 - ETA: 0s - loss: 0.8936 - accuracy: 0.61 - ETA: 0s - loss: 0.8862 - accuracy: 0.62 - ETA: 0s - loss: 0.8694 - accuracy: 0.63 - ETA: 0s - loss: 0.8821 - accuracy: 0.62 - ETA: 0s - loss: 0.9025 - accuracy: 0.61 - ETA: 0s - loss: 0.9038 - accuracy: 0.61 - ETA: 0s - loss: 0.9090 - accuracy: 0.60 - ETA: 0s - loss: 0.9095 - accuracy: 0.60 - ETA: 0s - loss: 0.9110 - accuracy: 0.6046\n",
      "Epoch 00270: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9110 - accuracy: 0.6046 - val_loss: 1.0915 - val_accuracy: 0.4936 - lr: 0.0025\n",
      "Epoch 271/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9910 - accuracy: 0.54 - ETA: 0s - loss: 0.9539 - accuracy: 0.56 - ETA: 0s - loss: 0.9512 - accuracy: 0.56 - ETA: 0s - loss: 0.9211 - accuracy: 0.59 - ETA: 0s - loss: 0.9128 - accuracy: 0.60 - ETA: 0s - loss: 0.8996 - accuracy: 0.61 - ETA: 0s - loss: 0.8954 - accuracy: 0.61 - ETA: 0s - loss: 0.8951 - accuracy: 0.62 - ETA: 0s - loss: 0.8948 - accuracy: 0.61 - ETA: 0s - loss: 0.9018 - accuracy: 0.60 - ETA: 0s - loss: 0.8956 - accuracy: 0.61 - ETA: 0s - loss: 0.8874 - accuracy: 0.62 - ETA: 0s - loss: 0.8706 - accuracy: 0.63 - ETA: 0s - loss: 0.8819 - accuracy: 0.62 - ETA: 0s - loss: 0.9010 - accuracy: 0.61 - ETA: 0s - loss: 0.9023 - accuracy: 0.61 - ETA: 0s - loss: 0.9084 - accuracy: 0.60 - ETA: 0s - loss: 0.9099 - accuracy: 0.6043\n",
      "Epoch 00271: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9099 - accuracy: 0.6043 - val_loss: 1.0910 - val_accuracy: 0.4910 - lr: 0.0025\n",
      "Epoch 272/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9944 - accuracy: 0.54 - ETA: 0s - loss: 0.9614 - accuracy: 0.56 - ETA: 0s - loss: 0.9603 - accuracy: 0.56 - ETA: 0s - loss: 0.9261 - accuracy: 0.59 - ETA: 0s - loss: 0.9160 - accuracy: 0.59 - ETA: 0s - loss: 0.9018 - accuracy: 0.61 - ETA: 0s - loss: 0.8973 - accuracy: 0.61 - ETA: 0s - loss: 0.8959 - accuracy: 0.61 - ETA: 0s - loss: 0.8957 - accuracy: 0.61 - ETA: 0s - loss: 0.9012 - accuracy: 0.61 - ETA: 0s - loss: 0.8956 - accuracy: 0.61 - ETA: 0s - loss: 0.8879 - accuracy: 0.62 - ETA: 0s - loss: 0.8716 - accuracy: 0.63 - ETA: 0s - loss: 0.8831 - accuracy: 0.62 - ETA: 0s - loss: 0.9012 - accuracy: 0.61 - ETA: 0s - loss: 0.9024 - accuracy: 0.61 - ETA: 0s - loss: 0.9070 - accuracy: 0.60 - ETA: 0s - loss: 0.9085 - accuracy: 0.60 - ETA: 0s - loss: 0.9097 - accuracy: 0.6050\n",
      "Epoch 00272: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9097 - accuracy: 0.6050 - val_loss: 1.0861 - val_accuracy: 0.4896 - lr: 0.0025\n",
      "Epoch 273/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9968 - accuracy: 0.54 - ETA: 0s - loss: 0.9652 - accuracy: 0.55 - ETA: 0s - loss: 0.9615 - accuracy: 0.56 - ETA: 0s - loss: 0.9250 - accuracy: 0.59 - ETA: 0s - loss: 0.9134 - accuracy: 0.60 - ETA: 0s - loss: 0.8999 - accuracy: 0.61 - ETA: 0s - loss: 0.8953 - accuracy: 0.61 - ETA: 0s - loss: 0.8935 - accuracy: 0.62 - ETA: 0s - loss: 0.8929 - accuracy: 0.61 - ETA: 0s - loss: 0.9003 - accuracy: 0.61 - ETA: 0s - loss: 0.8942 - accuracy: 0.61 - ETA: 0s - loss: 0.8862 - accuracy: 0.62 - ETA: 0s - loss: 0.8694 - accuracy: 0.64 - ETA: 0s - loss: 0.8814 - accuracy: 0.62 - ETA: 0s - loss: 0.9006 - accuracy: 0.61 - ETA: 0s - loss: 0.9021 - accuracy: 0.61 - ETA: 0s - loss: 0.9065 - accuracy: 0.60 - ETA: 0s - loss: 0.9078 - accuracy: 0.60 - ETA: 0s - loss: 0.9090 - accuracy: 0.6056\n",
      "Epoch 00273: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9090 - accuracy: 0.6056 - val_loss: 1.0365 - val_accuracy: 0.4984 - lr: 0.0025\n",
      "Epoch 274/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9924 - accuracy: 0.54 - ETA: 0s - loss: 0.9681 - accuracy: 0.55 - ETA: 0s - loss: 0.9601 - accuracy: 0.56 - ETA: 0s - loss: 0.9282 - accuracy: 0.58 - ETA: 0s - loss: 0.9150 - accuracy: 0.59 - ETA: 0s - loss: 0.9022 - accuracy: 0.61 - ETA: 0s - loss: 0.8982 - accuracy: 0.61 - ETA: 0s - loss: 0.8969 - accuracy: 0.61 - ETA: 0s - loss: 0.8970 - accuracy: 0.61 - ETA: 0s - loss: 0.9023 - accuracy: 0.60 - ETA: 0s - loss: 0.8956 - accuracy: 0.61 - ETA: 0s - loss: 0.8882 - accuracy: 0.62 - ETA: 0s - loss: 0.8715 - accuracy: 0.63 - ETA: 0s - loss: 0.8827 - accuracy: 0.62 - ETA: 0s - loss: 0.9012 - accuracy: 0.61 - ETA: 0s - loss: 0.9031 - accuracy: 0.61 - ETA: 0s - loss: 0.9081 - accuracy: 0.60 - ETA: 0s - loss: 0.9092 - accuracy: 0.60 - ETA: 0s - loss: 0.9103 - accuracy: 0.6031\n",
      "Epoch 00274: val_loss did not improve from 0.99131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9103 - accuracy: 0.6031 - val_loss: 1.0448 - val_accuracy: 0.4961 - lr: 0.0025\n",
      "Epoch 275/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.9980 - accuracy: 0.54 - ETA: 0s - loss: 0.9628 - accuracy: 0.56 - ETA: 0s - loss: 0.9587 - accuracy: 0.56 - ETA: 0s - loss: 0.9260 - accuracy: 0.59 - ETA: 0s - loss: 0.9152 - accuracy: 0.60 - ETA: 0s - loss: 0.9017 - accuracy: 0.61 - ETA: 0s - loss: 0.8969 - accuracy: 0.61 - ETA: 0s - loss: 0.8972 - accuracy: 0.61 - ETA: 0s - loss: 0.8979 - accuracy: 0.61 - ETA: 0s - loss: 0.9040 - accuracy: 0.60 - ETA: 0s - loss: 0.8980 - accuracy: 0.61 - ETA: 0s - loss: 0.8906 - accuracy: 0.62 - ETA: 0s - loss: 0.8741 - accuracy: 0.63 - ETA: 0s - loss: 0.8841 - accuracy: 0.62 - ETA: 0s - loss: 0.9023 - accuracy: 0.61 - ETA: 0s - loss: 0.9033 - accuracy: 0.61 - ETA: 0s - loss: 0.9080 - accuracy: 0.60 - ETA: 0s - loss: 0.9094 - accuracy: 0.6060\n",
      "Epoch 00275: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9106 - accuracy: 0.6047 - val_loss: 1.0972 - val_accuracy: 0.4888 - lr: 0.0025\n",
      "Epoch 276/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9894 - accuracy: 0.54 - ETA: 0s - loss: 0.9595 - accuracy: 0.56 - ETA: 0s - loss: 0.9569 - accuracy: 0.56 - ETA: 0s - loss: 0.9235 - accuracy: 0.59 - ETA: 0s - loss: 0.9140 - accuracy: 0.59 - ETA: 0s - loss: 0.9009 - accuracy: 0.61 - ETA: 0s - loss: 0.8967 - accuracy: 0.61 - ETA: 0s - loss: 0.8940 - accuracy: 0.61 - ETA: 0s - loss: 0.8936 - accuracy: 0.61 - ETA: 0s - loss: 0.9007 - accuracy: 0.61 - ETA: 0s - loss: 0.8953 - accuracy: 0.61 - ETA: 0s - loss: 0.8882 - accuracy: 0.62 - ETA: 0s - loss: 0.8716 - accuracy: 0.63 - ETA: 0s - loss: 0.8823 - accuracy: 0.62 - ETA: 0s - loss: 0.9015 - accuracy: 0.61 - ETA: 0s - loss: 0.9029 - accuracy: 0.61 - ETA: 0s - loss: 0.9073 - accuracy: 0.60 - ETA: 0s - loss: 0.9083 - accuracy: 0.60 - ETA: 0s - loss: 0.9094 - accuracy: 0.6048\n",
      "Epoch 00276: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9094 - accuracy: 0.6048 - val_loss: 1.0664 - val_accuracy: 0.4909 - lr: 0.0025\n",
      "Epoch 277/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9902 - accuracy: 0.54 - ETA: 0s - loss: 0.9572 - accuracy: 0.55 - ETA: 0s - loss: 0.9540 - accuracy: 0.56 - ETA: 0s - loss: 0.9205 - accuracy: 0.59 - ETA: 0s - loss: 0.9103 - accuracy: 0.59 - ETA: 0s - loss: 0.8974 - accuracy: 0.61 - ETA: 0s - loss: 0.8924 - accuracy: 0.61 - ETA: 0s - loss: 0.8916 - accuracy: 0.61 - ETA: 0s - loss: 0.8916 - accuracy: 0.61 - ETA: 0s - loss: 0.8977 - accuracy: 0.61 - ETA: 0s - loss: 0.8917 - accuracy: 0.61 - ETA: 0s - loss: 0.8842 - accuracy: 0.62 - ETA: 0s - loss: 0.8686 - accuracy: 0.64 - ETA: 0s - loss: 0.8792 - accuracy: 0.62 - ETA: 0s - loss: 0.8976 - accuracy: 0.61 - ETA: 0s - loss: 0.8998 - accuracy: 0.61 - ETA: 0s - loss: 0.9050 - accuracy: 0.60 - ETA: 0s - loss: 0.9058 - accuracy: 0.60 - ETA: 0s - loss: 0.9079 - accuracy: 0.6058\n",
      "Epoch 00277: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00277: ReduceLROnPlateau reducing learning rate to 0.002026619575917721.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9079 - accuracy: 0.6058 - val_loss: 1.0535 - val_accuracy: 0.4894 - lr: 0.0025\n",
      "Epoch 278/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9935 - accuracy: 0.54 - ETA: 0s - loss: 0.9547 - accuracy: 0.56 - ETA: 0s - loss: 0.9523 - accuracy: 0.56 - ETA: 0s - loss: 0.9204 - accuracy: 0.59 - ETA: 0s - loss: 0.9120 - accuracy: 0.59 - ETA: 0s - loss: 0.8944 - accuracy: 0.61 - ETA: 0s - loss: 0.8935 - accuracy: 0.61 - ETA: 0s - loss: 0.8924 - accuracy: 0.61 - ETA: 0s - loss: 0.8987 - accuracy: 0.60 - ETA: 0s - loss: 0.8927 - accuracy: 0.61 - ETA: 0s - loss: 0.8854 - accuracy: 0.62 - ETA: 0s - loss: 0.8683 - accuracy: 0.63 - ETA: 0s - loss: 0.8791 - accuracy: 0.62 - ETA: 0s - loss: 0.8983 - accuracy: 0.61 - ETA: 0s - loss: 0.9000 - accuracy: 0.61 - ETA: 0s - loss: 0.9048 - accuracy: 0.60 - ETA: 0s - loss: 0.9057 - accuracy: 0.60 - ETA: 0s - loss: 0.9076 - accuracy: 0.6060\n",
      "Epoch 00278: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9076 - accuracy: 0.6060 - val_loss: 1.0313 - val_accuracy: 0.4969 - lr: 0.0020\n",
      "Epoch 279/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9829 - accuracy: 0.54 - ETA: 0s - loss: 0.9532 - accuracy: 0.55 - ETA: 0s - loss: 0.9507 - accuracy: 0.56 - ETA: 0s - loss: 0.9192 - accuracy: 0.59 - ETA: 0s - loss: 0.9092 - accuracy: 0.60 - ETA: 0s - loss: 0.8975 - accuracy: 0.61 - ETA: 0s - loss: 0.8925 - accuracy: 0.61 - ETA: 0s - loss: 0.8924 - accuracy: 0.61 - ETA: 0s - loss: 0.8928 - accuracy: 0.61 - ETA: 0s - loss: 0.8997 - accuracy: 0.61 - ETA: 0s - loss: 0.8940 - accuracy: 0.61 - ETA: 0s - loss: 0.8864 - accuracy: 0.62 - ETA: 0s - loss: 0.8703 - accuracy: 0.63 - ETA: 0s - loss: 0.8812 - accuracy: 0.62 - ETA: 0s - loss: 0.8999 - accuracy: 0.61 - ETA: 0s - loss: 0.9018 - accuracy: 0.61 - ETA: 0s - loss: 0.9071 - accuracy: 0.60 - ETA: 0s - loss: 0.9084 - accuracy: 0.60 - ETA: 0s - loss: 0.9096 - accuracy: 0.6049\n",
      "Epoch 00279: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9096 - accuracy: 0.6049 - val_loss: 1.0352 - val_accuracy: 0.4976 - lr: 0.0020\n",
      "Epoch 280/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9830 - accuracy: 0.54 - ETA: 0s - loss: 0.9488 - accuracy: 0.56 - ETA: 0s - loss: 0.9526 - accuracy: 0.56 - ETA: 0s - loss: 0.9193 - accuracy: 0.59 - ETA: 0s - loss: 0.9107 - accuracy: 0.60 - ETA: 0s - loss: 0.8982 - accuracy: 0.61 - ETA: 0s - loss: 0.8937 - accuracy: 0.62 - ETA: 0s - loss: 0.8940 - accuracy: 0.62 - ETA: 0s - loss: 0.8940 - accuracy: 0.61 - ETA: 0s - loss: 0.9004 - accuracy: 0.61 - ETA: 0s - loss: 0.8939 - accuracy: 0.61 - ETA: 0s - loss: 0.8865 - accuracy: 0.62 - ETA: 0s - loss: 0.8696 - accuracy: 0.64 - ETA: 0s - loss: 0.8795 - accuracy: 0.62 - ETA: 0s - loss: 0.8985 - accuracy: 0.61 - ETA: 0s - loss: 0.9003 - accuracy: 0.61 - ETA: 0s - loss: 0.9051 - accuracy: 0.60 - ETA: 0s - loss: 0.9064 - accuracy: 0.60 - ETA: 0s - loss: 0.9076 - accuracy: 0.6053\n",
      "Epoch 00280: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9076 - accuracy: 0.6053 - val_loss: 1.0306 - val_accuracy: 0.4977 - lr: 0.0020\n",
      "Epoch 281/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9900 - accuracy: 0.54 - ETA: 0s - loss: 0.9566 - accuracy: 0.56 - ETA: 0s - loss: 0.9557 - accuracy: 0.56 - ETA: 0s - loss: 0.9233 - accuracy: 0.59 - ETA: 0s - loss: 0.9139 - accuracy: 0.59 - ETA: 0s - loss: 0.9000 - accuracy: 0.61 - ETA: 0s - loss: 0.8950 - accuracy: 0.61 - ETA: 0s - loss: 0.8938 - accuracy: 0.61 - ETA: 0s - loss: 0.8939 - accuracy: 0.61 - ETA: 0s - loss: 0.9002 - accuracy: 0.61 - ETA: 0s - loss: 0.8937 - accuracy: 0.61 - ETA: 0s - loss: 0.8861 - accuracy: 0.62 - ETA: 0s - loss: 0.8694 - accuracy: 0.63 - ETA: 0s - loss: 0.8802 - accuracy: 0.62 - ETA: 0s - loss: 0.8996 - accuracy: 0.61 - ETA: 0s - loss: 0.9012 - accuracy: 0.61 - ETA: 0s - loss: 0.9059 - accuracy: 0.60 - ETA: 0s - loss: 0.9079 - accuracy: 0.60 - ETA: 0s - loss: 0.9098 - accuracy: 0.6050\n",
      "Epoch 00281: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9098 - accuracy: 0.6050 - val_loss: 1.0234 - val_accuracy: 0.4987 - lr: 0.0020\n",
      "Epoch 282/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9917 - accuracy: 0.54 - ETA: 0s - loss: 0.9624 - accuracy: 0.55 - ETA: 0s - loss: 0.9591 - accuracy: 0.56 - ETA: 0s - loss: 0.9269 - accuracy: 0.58 - ETA: 0s - loss: 0.9159 - accuracy: 0.59 - ETA: 0s - loss: 0.9016 - accuracy: 0.61 - ETA: 0s - loss: 0.8971 - accuracy: 0.61 - ETA: 0s - loss: 0.8948 - accuracy: 0.61 - ETA: 0s - loss: 0.8931 - accuracy: 0.61 - ETA: 0s - loss: 0.8992 - accuracy: 0.60 - ETA: 0s - loss: 0.8931 - accuracy: 0.61 - ETA: 0s - loss: 0.8854 - accuracy: 0.62 - ETA: 0s - loss: 0.8687 - accuracy: 0.63 - ETA: 0s - loss: 0.8797 - accuracy: 0.62 - ETA: 0s - loss: 0.8983 - accuracy: 0.61 - ETA: 0s - loss: 0.8994 - accuracy: 0.61 - ETA: 0s - loss: 0.9048 - accuracy: 0.60 - ETA: 0s - loss: 0.9064 - accuracy: 0.60 - ETA: 0s - loss: 0.9078 - accuracy: 0.6044\n",
      "Epoch 00282: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9078 - accuracy: 0.6044 - val_loss: 1.0176 - val_accuracy: 0.5024 - lr: 0.0020\n",
      "Epoch 283/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9899 - accuracy: 0.54 - ETA: 0s - loss: 0.9545 - accuracy: 0.55 - ETA: 0s - loss: 0.9513 - accuracy: 0.56 - ETA: 0s - loss: 0.9203 - accuracy: 0.58 - ETA: 0s - loss: 0.9107 - accuracy: 0.59 - ETA: 0s - loss: 0.8962 - accuracy: 0.60 - ETA: 0s - loss: 0.8926 - accuracy: 0.61 - ETA: 0s - loss: 0.8923 - accuracy: 0.61 - ETA: 0s - loss: 0.8922 - accuracy: 0.61 - ETA: 0s - loss: 0.8983 - accuracy: 0.60 - ETA: 0s - loss: 0.8917 - accuracy: 0.61 - ETA: 0s - loss: 0.8848 - accuracy: 0.62 - ETA: 0s - loss: 0.8685 - accuracy: 0.63 - ETA: 0s - loss: 0.8790 - accuracy: 0.62 - ETA: 0s - loss: 0.8974 - accuracy: 0.61 - ETA: 0s - loss: 0.8989 - accuracy: 0.61 - ETA: 0s - loss: 0.9038 - accuracy: 0.60 - ETA: 0s - loss: 0.9051 - accuracy: 0.60 - ETA: 0s - loss: 0.9065 - accuracy: 0.6056\n",
      "Epoch 00283: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9065 - accuracy: 0.6056 - val_loss: 1.0274 - val_accuracy: 0.4930 - lr: 0.0020\n",
      "Epoch 284/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9874 - accuracy: 0.55 - ETA: 0s - loss: 0.9544 - accuracy: 0.56 - ETA: 0s - loss: 0.9485 - accuracy: 0.57 - ETA: 0s - loss: 0.9168 - accuracy: 0.59 - ETA: 0s - loss: 0.9076 - accuracy: 0.60 - ETA: 0s - loss: 0.8948 - accuracy: 0.61 - ETA: 0s - loss: 0.8913 - accuracy: 0.61 - ETA: 0s - loss: 0.8913 - accuracy: 0.61 - ETA: 0s - loss: 0.8915 - accuracy: 0.61 - ETA: 0s - loss: 0.8990 - accuracy: 0.61 - ETA: 0s - loss: 0.8921 - accuracy: 0.61 - ETA: 0s - loss: 0.8854 - accuracy: 0.62 - ETA: 0s - loss: 0.8685 - accuracy: 0.63 - ETA: 0s - loss: 0.8791 - accuracy: 0.62 - ETA: 0s - loss: 0.8979 - accuracy: 0.61 - ETA: 0s - loss: 0.8999 - accuracy: 0.61 - ETA: 0s - loss: 0.9052 - accuracy: 0.60 - ETA: 0s - loss: 0.9061 - accuracy: 0.60 - ETA: 0s - loss: 0.9070 - accuracy: 0.6062\n",
      "Epoch 00284: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9070 - accuracy: 0.6062 - val_loss: 1.0174 - val_accuracy: 0.4989 - lr: 0.0020\n",
      "Epoch 285/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9863 - accuracy: 0.54 - ETA: 0s - loss: 0.9603 - accuracy: 0.55 - ETA: 0s - loss: 0.9553 - accuracy: 0.56 - ETA: 0s - loss: 0.9214 - accuracy: 0.58 - ETA: 0s - loss: 0.9128 - accuracy: 0.59 - ETA: 0s - loss: 0.8989 - accuracy: 0.61 - ETA: 0s - loss: 0.8952 - accuracy: 0.61 - ETA: 0s - loss: 0.8938 - accuracy: 0.61 - ETA: 0s - loss: 0.8932 - accuracy: 0.61 - ETA: 0s - loss: 0.9000 - accuracy: 0.60 - ETA: 0s - loss: 0.8932 - accuracy: 0.61 - ETA: 0s - loss: 0.8860 - accuracy: 0.62 - ETA: 0s - loss: 0.8687 - accuracy: 0.63 - ETA: 0s - loss: 0.8789 - accuracy: 0.62 - ETA: 0s - loss: 0.8980 - accuracy: 0.61 - ETA: 0s - loss: 0.8998 - accuracy: 0.61 - ETA: 0s - loss: 0.9052 - accuracy: 0.60 - ETA: 0s - loss: 0.9065 - accuracy: 0.60 - ETA: 0s - loss: 0.9075 - accuracy: 0.6060\n",
      "Epoch 00285: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9075 - accuracy: 0.6060 - val_loss: 1.0589 - val_accuracy: 0.4958 - lr: 0.0020\n",
      "Epoch 286/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9885 - accuracy: 0.55 - ETA: 0s - loss: 0.9577 - accuracy: 0.56 - ETA: 0s - loss: 0.9558 - accuracy: 0.56 - ETA: 0s - loss: 0.9237 - accuracy: 0.59 - ETA: 0s - loss: 0.9137 - accuracy: 0.60 - ETA: 0s - loss: 0.9006 - accuracy: 0.61 - ETA: 0s - loss: 0.8964 - accuracy: 0.61 - ETA: 0s - loss: 0.8941 - accuracy: 0.62 - ETA: 0s - loss: 0.8940 - accuracy: 0.61 - ETA: 0s - loss: 0.9002 - accuracy: 0.61 - ETA: 0s - loss: 0.8935 - accuracy: 0.62 - ETA: 0s - loss: 0.8866 - accuracy: 0.62 - ETA: 0s - loss: 0.8694 - accuracy: 0.64 - ETA: 0s - loss: 0.8796 - accuracy: 0.63 - ETA: 0s - loss: 0.8981 - accuracy: 0.61 - ETA: 0s - loss: 0.9002 - accuracy: 0.61 - ETA: 0s - loss: 0.9049 - accuracy: 0.60 - ETA: 0s - loss: 0.9058 - accuracy: 0.60 - ETA: 0s - loss: 0.9072 - accuracy: 0.6070\n",
      "Epoch 00286: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9072 - accuracy: 0.6070 - val_loss: 1.0262 - val_accuracy: 0.5000 - lr: 0.0020\n",
      "Epoch 287/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9861 - accuracy: 0.54 - ETA: 0s - loss: 0.9563 - accuracy: 0.56 - ETA: 0s - loss: 0.9531 - accuracy: 0.56 - ETA: 0s - loss: 0.9192 - accuracy: 0.59 - ETA: 0s - loss: 0.9097 - accuracy: 0.59 - ETA: 0s - loss: 0.8964 - accuracy: 0.61 - ETA: 0s - loss: 0.8932 - accuracy: 0.61 - ETA: 0s - loss: 0.8926 - accuracy: 0.61 - ETA: 0s - loss: 0.8918 - accuracy: 0.61 - ETA: 0s - loss: 0.8985 - accuracy: 0.60 - ETA: 0s - loss: 0.8917 - accuracy: 0.61 - ETA: 0s - loss: 0.8843 - accuracy: 0.62 - ETA: 0s - loss: 0.8672 - accuracy: 0.63 - ETA: 0s - loss: 0.8776 - accuracy: 0.62 - ETA: 0s - loss: 0.8963 - accuracy: 0.61 - ETA: 0s - loss: 0.8981 - accuracy: 0.61 - ETA: 0s - loss: 0.9033 - accuracy: 0.60 - ETA: 0s - loss: 0.9050 - accuracy: 0.60 - ETA: 0s - loss: 0.9064 - accuracy: 0.6053\n",
      "Epoch 00287: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9064 - accuracy: 0.6053 - val_loss: 1.0157 - val_accuracy: 0.5024 - lr: 0.0020\n",
      "Epoch 288/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9890 - accuracy: 0.54 - ETA: 0s - loss: 0.9578 - accuracy: 0.55 - ETA: 0s - loss: 0.9506 - accuracy: 0.56 - ETA: 0s - loss: 0.9169 - accuracy: 0.59 - ETA: 0s - loss: 0.9099 - accuracy: 0.59 - ETA: 0s - loss: 0.8970 - accuracy: 0.61 - ETA: 0s - loss: 0.8919 - accuracy: 0.61 - ETA: 0s - loss: 0.8922 - accuracy: 0.62 - ETA: 0s - loss: 0.8935 - accuracy: 0.61 - ETA: 0s - loss: 0.8998 - accuracy: 0.61 - ETA: 0s - loss: 0.8935 - accuracy: 0.61 - ETA: 0s - loss: 0.8876 - accuracy: 0.62 - ETA: 0s - loss: 0.8711 - accuracy: 0.64 - ETA: 0s - loss: 0.8813 - accuracy: 0.62 - ETA: 0s - loss: 0.9002 - accuracy: 0.61 - ETA: 0s - loss: 0.9016 - accuracy: 0.61 - ETA: 0s - loss: 0.9062 - accuracy: 0.60 - ETA: 0s - loss: 0.9073 - accuracy: 0.60 - ETA: 0s - loss: 0.9087 - accuracy: 0.6063\n",
      "Epoch 00288: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9087 - accuracy: 0.6063 - val_loss: 1.0223 - val_accuracy: 0.4969 - lr: 0.0020\n",
      "Epoch 289/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9926 - accuracy: 0.53 - ETA: 0s - loss: 0.9503 - accuracy: 0.55 - ETA: 0s - loss: 0.9478 - accuracy: 0.56 - ETA: 0s - loss: 0.9180 - accuracy: 0.59 - ETA: 0s - loss: 0.9078 - accuracy: 0.60 - ETA: 0s - loss: 0.8954 - accuracy: 0.61 - ETA: 0s - loss: 0.8912 - accuracy: 0.61 - ETA: 0s - loss: 0.8895 - accuracy: 0.62 - ETA: 0s - loss: 0.8897 - accuracy: 0.61 - ETA: 0s - loss: 0.8962 - accuracy: 0.61 - ETA: 0s - loss: 0.8900 - accuracy: 0.61 - ETA: 0s - loss: 0.8832 - accuracy: 0.62 - ETA: 0s - loss: 0.8668 - accuracy: 0.63 - ETA: 0s - loss: 0.8787 - accuracy: 0.62 - ETA: 0s - loss: 0.8981 - accuracy: 0.61 - ETA: 0s - loss: 0.9002 - accuracy: 0.61 - ETA: 0s - loss: 0.9052 - accuracy: 0.60 - ETA: 0s - loss: 0.9061 - accuracy: 0.60 - ETA: 0s - loss: 0.9073 - accuracy: 0.6058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00289: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9073 - accuracy: 0.6058 - val_loss: 1.0245 - val_accuracy: 0.5024 - lr: 0.0020\n",
      "Epoch 290/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9913 - accuracy: 0.55 - ETA: 0s - loss: 0.9591 - accuracy: 0.56 - ETA: 0s - loss: 0.9558 - accuracy: 0.56 - ETA: 0s - loss: 0.9199 - accuracy: 0.59 - ETA: 0s - loss: 0.9119 - accuracy: 0.59 - ETA: 0s - loss: 0.8989 - accuracy: 0.61 - ETA: 0s - loss: 0.8958 - accuracy: 0.61 - ETA: 0s - loss: 0.8937 - accuracy: 0.61 - ETA: 0s - loss: 0.8940 - accuracy: 0.61 - ETA: 0s - loss: 0.8997 - accuracy: 0.61 - ETA: 0s - loss: 0.8932 - accuracy: 0.61 - ETA: 0s - loss: 0.8854 - accuracy: 0.62 - ETA: 0s - loss: 0.8688 - accuracy: 0.63 - ETA: 0s - loss: 0.8802 - accuracy: 0.62 - ETA: 0s - loss: 0.8998 - accuracy: 0.61 - ETA: 0s - loss: 0.9014 - accuracy: 0.61 - ETA: 0s - loss: 0.9066 - accuracy: 0.60 - ETA: 0s - loss: 0.9076 - accuracy: 0.60 - ETA: 0s - loss: 0.9086 - accuracy: 0.6050\n",
      "Epoch 00290: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9086 - accuracy: 0.6050 - val_loss: 1.0244 - val_accuracy: 0.5024 - lr: 0.0020\n",
      "Epoch 291/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9899 - accuracy: 0.54 - ETA: 0s - loss: 0.9608 - accuracy: 0.55 - ETA: 0s - loss: 0.9535 - accuracy: 0.56 - ETA: 0s - loss: 0.9229 - accuracy: 0.58 - ETA: 0s - loss: 0.9127 - accuracy: 0.59 - ETA: 0s - loss: 0.8983 - accuracy: 0.61 - ETA: 0s - loss: 0.8935 - accuracy: 0.61 - ETA: 0s - loss: 0.8917 - accuracy: 0.61 - ETA: 0s - loss: 0.8911 - accuracy: 0.61 - ETA: 0s - loss: 0.8976 - accuracy: 0.60 - ETA: 0s - loss: 0.8911 - accuracy: 0.61 - ETA: 0s - loss: 0.8841 - accuracy: 0.62 - ETA: 0s - loss: 0.8678 - accuracy: 0.63 - ETA: 0s - loss: 0.8796 - accuracy: 0.62 - ETA: 0s - loss: 0.8985 - accuracy: 0.61 - ETA: 0s - loss: 0.9004 - accuracy: 0.61 - ETA: 0s - loss: 0.9056 - accuracy: 0.60 - ETA: 0s - loss: 0.9065 - accuracy: 0.60 - ETA: 0s - loss: 0.9075 - accuracy: 0.6048\n",
      "Epoch 00291: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00291: ReduceLROnPlateau reducing learning rate to 0.0016212956979870796.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9075 - accuracy: 0.6048 - val_loss: 1.0271 - val_accuracy: 0.4977 - lr: 0.0020\n",
      "Epoch 292/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9923 - accuracy: 0.53 - ETA: 0s - loss: 0.9560 - accuracy: 0.55 - ETA: 0s - loss: 0.9559 - accuracy: 0.56 - ETA: 0s - loss: 0.9216 - accuracy: 0.58 - ETA: 0s - loss: 0.9108 - accuracy: 0.59 - ETA: 0s - loss: 0.8967 - accuracy: 0.61 - ETA: 0s - loss: 0.8932 - accuracy: 0.61 - ETA: 0s - loss: 0.8909 - accuracy: 0.61 - ETA: 0s - loss: 0.8924 - accuracy: 0.61 - ETA: 0s - loss: 0.8989 - accuracy: 0.60 - ETA: 0s - loss: 0.8924 - accuracy: 0.61 - ETA: 0s - loss: 0.8853 - accuracy: 0.62 - ETA: 0s - loss: 0.8686 - accuracy: 0.63 - ETA: 0s - loss: 0.8787 - accuracy: 0.62 - ETA: 0s - loss: 0.8974 - accuracy: 0.61 - ETA: 0s - loss: 0.8994 - accuracy: 0.61 - ETA: 0s - loss: 0.9039 - accuracy: 0.60 - ETA: 0s - loss: 0.9050 - accuracy: 0.60 - ETA: 0s - loss: 0.9068 - accuracy: 0.6048\n",
      "Epoch 00292: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9068 - accuracy: 0.6048 - val_loss: 1.0328 - val_accuracy: 0.5015 - lr: 0.0016\n",
      "Epoch 293/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9798 - accuracy: 0.54 - ETA: 0s - loss: 0.9531 - accuracy: 0.55 - ETA: 0s - loss: 0.9512 - accuracy: 0.56 - ETA: 0s - loss: 0.9194 - accuracy: 0.58 - ETA: 0s - loss: 0.9112 - accuracy: 0.59 - ETA: 0s - loss: 0.8970 - accuracy: 0.61 - ETA: 0s - loss: 0.8925 - accuracy: 0.61 - ETA: 0s - loss: 0.8919 - accuracy: 0.61 - ETA: 0s - loss: 0.8922 - accuracy: 0.61 - ETA: 0s - loss: 0.8979 - accuracy: 0.60 - ETA: 0s - loss: 0.8909 - accuracy: 0.61 - ETA: 0s - loss: 0.8840 - accuracy: 0.62 - ETA: 0s - loss: 0.8672 - accuracy: 0.63 - ETA: 0s - loss: 0.8777 - accuracy: 0.62 - ETA: 0s - loss: 0.8971 - accuracy: 0.61 - ETA: 0s - loss: 0.8991 - accuracy: 0.61 - ETA: 0s - loss: 0.9043 - accuracy: 0.60 - ETA: 0s - loss: 0.9055 - accuracy: 0.60 - ETA: 0s - loss: 0.9062 - accuracy: 0.6051\n",
      "Epoch 00293: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9062 - accuracy: 0.6051 - val_loss: 1.0476 - val_accuracy: 0.4925 - lr: 0.0016\n",
      "Epoch 294/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9850 - accuracy: 0.54 - ETA: 0s - loss: 0.9466 - accuracy: 0.56 - ETA: 0s - loss: 0.9462 - accuracy: 0.57 - ETA: 0s - loss: 0.9171 - accuracy: 0.59 - ETA: 0s - loss: 0.9090 - accuracy: 0.60 - ETA: 0s - loss: 0.8960 - accuracy: 0.61 - ETA: 0s - loss: 0.8917 - accuracy: 0.61 - ETA: 0s - loss: 0.8910 - accuracy: 0.61 - ETA: 0s - loss: 0.8898 - accuracy: 0.61 - ETA: 0s - loss: 0.8961 - accuracy: 0.61 - ETA: 0s - loss: 0.8895 - accuracy: 0.61 - ETA: 0s - loss: 0.8826 - accuracy: 0.62 - ETA: 0s - loss: 0.8658 - accuracy: 0.63 - ETA: 0s - loss: 0.8760 - accuracy: 0.62 - ETA: 0s - loss: 0.8941 - accuracy: 0.61 - ETA: 0s - loss: 0.8959 - accuracy: 0.61 - ETA: 0s - loss: 0.9014 - accuracy: 0.60 - ETA: 0s - loss: 0.9026 - accuracy: 0.60 - ETA: 0s - loss: 0.9038 - accuracy: 0.6070\n",
      "Epoch 00294: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9038 - accuracy: 0.6070 - val_loss: 1.0337 - val_accuracy: 0.5031 - lr: 0.0016\n",
      "Epoch 295/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9815 - accuracy: 0.53 - ETA: 0s - loss: 0.9516 - accuracy: 0.55 - ETA: 0s - loss: 0.9481 - accuracy: 0.55 - ETA: 0s - loss: 0.9180 - accuracy: 0.58 - ETA: 0s - loss: 0.9079 - accuracy: 0.59 - ETA: 0s - loss: 0.8951 - accuracy: 0.60 - ETA: 0s - loss: 0.8910 - accuracy: 0.61 - ETA: 0s - loss: 0.8902 - accuracy: 0.61 - ETA: 0s - loss: 0.8908 - accuracy: 0.61 - ETA: 0s - loss: 0.8960 - accuracy: 0.60 - ETA: 0s - loss: 0.8892 - accuracy: 0.61 - ETA: 0s - loss: 0.8820 - accuracy: 0.62 - ETA: 0s - loss: 0.8649 - accuracy: 0.63 - ETA: 0s - loss: 0.8753 - accuracy: 0.62 - ETA: 0s - loss: 0.8938 - accuracy: 0.61 - ETA: 0s - loss: 0.8959 - accuracy: 0.61 - ETA: 0s - loss: 0.9010 - accuracy: 0.60 - ETA: 0s - loss: 0.9024 - accuracy: 0.60 - ETA: 0s - loss: 0.9040 - accuracy: 0.6033\n",
      "Epoch 00295: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9040 - accuracy: 0.6033 - val_loss: 1.0346 - val_accuracy: 0.5028 - lr: 0.0016\n",
      "Epoch 296/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9882 - accuracy: 0.55 - ETA: 0s - loss: 0.9561 - accuracy: 0.56 - ETA: 0s - loss: 0.9543 - accuracy: 0.56 - ETA: 0s - loss: 0.9211 - accuracy: 0.59 - ETA: 0s - loss: 0.9130 - accuracy: 0.60 - ETA: 0s - loss: 0.8994 - accuracy: 0.61 - ETA: 0s - loss: 0.8943 - accuracy: 0.61 - ETA: 0s - loss: 0.8924 - accuracy: 0.61 - ETA: 0s - loss: 0.8926 - accuracy: 0.61 - ETA: 0s - loss: 0.8987 - accuracy: 0.61 - ETA: 0s - loss: 0.8922 - accuracy: 0.61 - ETA: 0s - loss: 0.8853 - accuracy: 0.62 - ETA: 0s - loss: 0.8681 - accuracy: 0.63 - ETA: 0s - loss: 0.8786 - accuracy: 0.62 - ETA: 0s - loss: 0.8980 - accuracy: 0.61 - ETA: 0s - loss: 0.8999 - accuracy: 0.61 - ETA: 0s - loss: 0.9048 - accuracy: 0.60 - ETA: 0s - loss: 0.9058 - accuracy: 0.60 - ETA: 0s - loss: 0.9070 - accuracy: 0.6057\n",
      "Epoch 00296: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9070 - accuracy: 0.6057 - val_loss: 1.0350 - val_accuracy: 0.4987 - lr: 0.0016\n",
      "Epoch 297/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9721 - accuracy: 0.54 - ETA: 0s - loss: 0.9432 - accuracy: 0.56 - ETA: 0s - loss: 0.9423 - accuracy: 0.56 - ETA: 0s - loss: 0.9134 - accuracy: 0.59 - ETA: 0s - loss: 0.9053 - accuracy: 0.59 - ETA: 0s - loss: 0.8938 - accuracy: 0.61 - ETA: 0s - loss: 0.8892 - accuracy: 0.61 - ETA: 0s - loss: 0.8898 - accuracy: 0.61 - ETA: 0s - loss: 0.8914 - accuracy: 0.61 - ETA: 0s - loss: 0.8976 - accuracy: 0.60 - ETA: 0s - loss: 0.8911 - accuracy: 0.61 - ETA: 0s - loss: 0.8851 - accuracy: 0.62 - ETA: 0s - loss: 0.8681 - accuracy: 0.63 - ETA: 0s - loss: 0.8780 - accuracy: 0.62 - ETA: 0s - loss: 0.8967 - accuracy: 0.61 - ETA: 0s - loss: 0.8984 - accuracy: 0.61 - ETA: 0s - loss: 0.9034 - accuracy: 0.60 - ETA: 0s - loss: 0.9048 - accuracy: 0.60 - ETA: 0s - loss: 0.9066 - accuracy: 0.6053\n",
      "Epoch 00297: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9066 - accuracy: 0.6053 - val_loss: 1.0418 - val_accuracy: 0.5002 - lr: 0.0016\n",
      "Epoch 298/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9898 - accuracy: 0.54 - ETA: 0s - loss: 0.9554 - accuracy: 0.56 - ETA: 0s - loss: 0.9500 - accuracy: 0.56 - ETA: 0s - loss: 0.9168 - accuracy: 0.59 - ETA: 0s - loss: 0.9068 - accuracy: 0.60 - ETA: 0s - loss: 0.8940 - accuracy: 0.61 - ETA: 0s - loss: 0.8895 - accuracy: 0.62 - ETA: 0s - loss: 0.8896 - accuracy: 0.62 - ETA: 0s - loss: 0.8894 - accuracy: 0.62 - ETA: 0s - loss: 0.8954 - accuracy: 0.61 - ETA: 0s - loss: 0.8895 - accuracy: 0.62 - ETA: 0s - loss: 0.8821 - accuracy: 0.62 - ETA: 0s - loss: 0.8655 - accuracy: 0.64 - ETA: 0s - loss: 0.8759 - accuracy: 0.63 - ETA: 0s - loss: 0.8953 - accuracy: 0.61 - ETA: 0s - loss: 0.8975 - accuracy: 0.61 - ETA: 0s - loss: 0.9023 - accuracy: 0.61 - ETA: 0s - loss: 0.9039 - accuracy: 0.60 - ETA: 0s - loss: 0.9051 - accuracy: 0.6075\n",
      "Epoch 00298: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9051 - accuracy: 0.6075 - val_loss: 1.0484 - val_accuracy: 0.4967 - lr: 0.0016\n",
      "Epoch 299/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9828 - accuracy: 0.55 - ETA: 0s - loss: 0.9469 - accuracy: 0.57 - ETA: 0s - loss: 0.9477 - accuracy: 0.57 - ETA: 0s - loss: 0.9183 - accuracy: 0.59 - ETA: 0s - loss: 0.9081 - accuracy: 0.60 - ETA: 0s - loss: 0.8947 - accuracy: 0.61 - ETA: 0s - loss: 0.8915 - accuracy: 0.62 - ETA: 0s - loss: 0.8909 - accuracy: 0.62 - ETA: 0s - loss: 0.8907 - accuracy: 0.62 - ETA: 0s - loss: 0.8980 - accuracy: 0.61 - ETA: 0s - loss: 0.8918 - accuracy: 0.61 - ETA: 0s - loss: 0.8847 - accuracy: 0.62 - ETA: 0s - loss: 0.8675 - accuracy: 0.64 - ETA: 0s - loss: 0.8780 - accuracy: 0.63 - ETA: 0s - loss: 0.8969 - accuracy: 0.61 - ETA: 0s - loss: 0.8984 - accuracy: 0.61 - ETA: 0s - loss: 0.9040 - accuracy: 0.60 - ETA: 0s - loss: 0.9052 - accuracy: 0.60 - ETA: 0s - loss: 0.9060 - accuracy: 0.6070\n",
      "Epoch 00299: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9060 - accuracy: 0.6070 - val_loss: 1.0401 - val_accuracy: 0.5003 - lr: 0.0016\n",
      "Epoch 300/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9797 - accuracy: 0.54 - ETA: 0s - loss: 0.9443 - accuracy: 0.56 - ETA: 0s - loss: 0.9454 - accuracy: 0.56 - ETA: 0s - loss: 0.9134 - accuracy: 0.59 - ETA: 0s - loss: 0.9036 - accuracy: 0.60 - ETA: 0s - loss: 0.8910 - accuracy: 0.61 - ETA: 0s - loss: 0.8873 - accuracy: 0.62 - ETA: 0s - loss: 0.8861 - accuracy: 0.62 - ETA: 0s - loss: 0.8862 - accuracy: 0.62 - ETA: 0s - loss: 0.8923 - accuracy: 0.61 - ETA: 0s - loss: 0.8860 - accuracy: 0.62 - ETA: 0s - loss: 0.8794 - accuracy: 0.62 - ETA: 0s - loss: 0.8627 - accuracy: 0.64 - ETA: 0s - loss: 0.8737 - accuracy: 0.63 - ETA: 0s - loss: 0.8920 - accuracy: 0.61 - ETA: 0s - loss: 0.8940 - accuracy: 0.61 - ETA: 0s - loss: 0.8993 - accuracy: 0.60 - ETA: 0s - loss: 0.9009 - accuracy: 0.60 - ETA: 0s - loss: 0.9025 - accuracy: 0.6076\n",
      "Epoch 00300: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9025 - accuracy: 0.6076 - val_loss: 1.0359 - val_accuracy: 0.4980 - lr: 0.0016\n",
      "Epoch 301/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9761 - accuracy: 0.55 - ETA: 0s - loss: 0.9466 - accuracy: 0.56 - ETA: 0s - loss: 0.9484 - accuracy: 0.56 - ETA: 0s - loss: 0.9148 - accuracy: 0.59 - ETA: 0s - loss: 0.9060 - accuracy: 0.60 - ETA: 0s - loss: 0.8931 - accuracy: 0.61 - ETA: 0s - loss: 0.8897 - accuracy: 0.62 - ETA: 0s - loss: 0.8866 - accuracy: 0.62 - ETA: 0s - loss: 0.8874 - accuracy: 0.62 - ETA: 0s - loss: 0.8941 - accuracy: 0.61 - ETA: 0s - loss: 0.8869 - accuracy: 0.62 - ETA: 0s - loss: 0.8801 - accuracy: 0.62 - ETA: 0s - loss: 0.8633 - accuracy: 0.64 - ETA: 0s - loss: 0.8741 - accuracy: 0.63 - ETA: 0s - loss: 0.8925 - accuracy: 0.61 - ETA: 0s - loss: 0.8949 - accuracy: 0.61 - ETA: 0s - loss: 0.8992 - accuracy: 0.60 - ETA: 0s - loss: 0.9000 - accuracy: 0.60 - ETA: 0s - loss: 0.9013 - accuracy: 0.6077\n",
      "Epoch 00301: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9013 - accuracy: 0.6077 - val_loss: 1.0306 - val_accuracy: 0.4946 - lr: 0.0016\n",
      "Epoch 302/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9823 - accuracy: 0.55 - ETA: 0s - loss: 0.9531 - accuracy: 0.56 - ETA: 0s - loss: 0.9506 - accuracy: 0.56 - ETA: 0s - loss: 0.9172 - accuracy: 0.59 - ETA: 0s - loss: 0.9095 - accuracy: 0.60 - ETA: 0s - loss: 0.8955 - accuracy: 0.61 - ETA: 0s - loss: 0.8901 - accuracy: 0.62 - ETA: 0s - loss: 0.8892 - accuracy: 0.62 - ETA: 0s - loss: 0.8905 - accuracy: 0.61 - ETA: 0s - loss: 0.8956 - accuracy: 0.61 - ETA: 0s - loss: 0.8888 - accuracy: 0.61 - ETA: 0s - loss: 0.8817 - accuracy: 0.62 - ETA: 0s - loss: 0.8643 - accuracy: 0.63 - ETA: 0s - loss: 0.8755 - accuracy: 0.62 - ETA: 0s - loss: 0.8946 - accuracy: 0.61 - ETA: 0s - loss: 0.8971 - accuracy: 0.61 - ETA: 0s - loss: 0.9022 - accuracy: 0.60 - ETA: 0s - loss: 0.9036 - accuracy: 0.60 - ETA: 0s - loss: 0.9044 - accuracy: 0.6054\n",
      "Epoch 00302: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9044 - accuracy: 0.6054 - val_loss: 1.0337 - val_accuracy: 0.4964 - lr: 0.0016\n",
      "Epoch 303/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9828 - accuracy: 0.54 - ETA: 0s - loss: 0.9487 - accuracy: 0.56 - ETA: 0s - loss: 0.9479 - accuracy: 0.56 - ETA: 0s - loss: 0.9161 - accuracy: 0.59 - ETA: 0s - loss: 0.9078 - accuracy: 0.59 - ETA: 0s - loss: 0.8937 - accuracy: 0.61 - ETA: 0s - loss: 0.8896 - accuracy: 0.61 - ETA: 0s - loss: 0.8891 - accuracy: 0.61 - ETA: 0s - loss: 0.8884 - accuracy: 0.61 - ETA: 0s - loss: 0.8941 - accuracy: 0.60 - ETA: 0s - loss: 0.8879 - accuracy: 0.61 - ETA: 0s - loss: 0.8813 - accuracy: 0.62 - ETA: 0s - loss: 0.8643 - accuracy: 0.63 - ETA: 0s - loss: 0.8751 - accuracy: 0.62 - ETA: 0s - loss: 0.8942 - accuracy: 0.61 - ETA: 0s - loss: 0.8956 - accuracy: 0.61 - ETA: 0s - loss: 0.9007 - accuracy: 0.60 - ETA: 0s - loss: 0.9016 - accuracy: 0.60 - ETA: 0s - loss: 0.9026 - accuracy: 0.6054\n",
      "Epoch 00303: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9026 - accuracy: 0.6054 - val_loss: 1.0317 - val_accuracy: 0.5026 - lr: 0.0016\n",
      "Epoch 304/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9931 - accuracy: 0.54 - ETA: 0s - loss: 0.9589 - accuracy: 0.55 - ETA: 0s - loss: 0.9557 - accuracy: 0.55 - ETA: 0s - loss: 0.9243 - accuracy: 0.58 - ETA: 0s - loss: 0.9122 - accuracy: 0.59 - ETA: 0s - loss: 0.8981 - accuracy: 0.60 - ETA: 0s - loss: 0.8927 - accuracy: 0.61 - ETA: 0s - loss: 0.8918 - accuracy: 0.61 - ETA: 0s - loss: 0.8916 - accuracy: 0.61 - ETA: 0s - loss: 0.8975 - accuracy: 0.60 - ETA: 0s - loss: 0.8907 - accuracy: 0.61 - ETA: 0s - loss: 0.8835 - accuracy: 0.62 - ETA: 0s - loss: 0.8663 - accuracy: 0.64 - ETA: 0s - loss: 0.8770 - accuracy: 0.62 - ETA: 0s - loss: 0.8954 - accuracy: 0.61 - ETA: 0s - loss: 0.8972 - accuracy: 0.61 - ETA: 0s - loss: 0.9021 - accuracy: 0.60 - ETA: 0s - loss: 0.9038 - accuracy: 0.60 - ETA: 0s - loss: 0.9045 - accuracy: 0.6077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00304: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9045 - accuracy: 0.6077 - val_loss: 1.0359 - val_accuracy: 0.4974 - lr: 0.0016\n",
      "Epoch 305/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9880 - accuracy: 0.54 - ETA: 0s - loss: 0.9518 - accuracy: 0.55 - ETA: 0s - loss: 0.9497 - accuracy: 0.56 - ETA: 0s - loss: 0.9211 - accuracy: 0.58 - ETA: 0s - loss: 0.9104 - accuracy: 0.59 - ETA: 0s - loss: 0.8970 - accuracy: 0.61 - ETA: 0s - loss: 0.8947 - accuracy: 0.61 - ETA: 0s - loss: 0.8922 - accuracy: 0.61 - ETA: 0s - loss: 0.8921 - accuracy: 0.61 - ETA: 0s - loss: 0.8972 - accuracy: 0.60 - ETA: 0s - loss: 0.8899 - accuracy: 0.61 - ETA: 0s - loss: 0.8823 - accuracy: 0.62 - ETA: 0s - loss: 0.8651 - accuracy: 0.64 - ETA: 0s - loss: 0.8759 - accuracy: 0.63 - ETA: 0s - loss: 0.8940 - accuracy: 0.61 - ETA: 0s - loss: 0.8959 - accuracy: 0.61 - ETA: 0s - loss: 0.9010 - accuracy: 0.60 - ETA: 0s - loss: 0.9025 - accuracy: 0.60 - ETA: 0s - loss: 0.9039 - accuracy: 0.6079\n",
      "Epoch 00305: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00305: ReduceLROnPlateau reducing learning rate to 0.0012970365583896638.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9039 - accuracy: 0.6079 - val_loss: 1.0403 - val_accuracy: 0.4958 - lr: 0.0016\n",
      "Epoch 306/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9802 - accuracy: 0.54 - ETA: 0s - loss: 0.9461 - accuracy: 0.55 - ETA: 0s - loss: 0.9456 - accuracy: 0.56 - ETA: 0s - loss: 0.9129 - accuracy: 0.58 - ETA: 0s - loss: 0.9065 - accuracy: 0.59 - ETA: 0s - loss: 0.8925 - accuracy: 0.61 - ETA: 0s - loss: 0.8894 - accuracy: 0.61 - ETA: 0s - loss: 0.8873 - accuracy: 0.61 - ETA: 0s - loss: 0.8882 - accuracy: 0.61 - ETA: 0s - loss: 0.8957 - accuracy: 0.60 - ETA: 0s - loss: 0.8886 - accuracy: 0.61 - ETA: 0s - loss: 0.8818 - accuracy: 0.62 - ETA: 0s - loss: 0.8648 - accuracy: 0.63 - ETA: 0s - loss: 0.8752 - accuracy: 0.62 - ETA: 0s - loss: 0.8940 - accuracy: 0.61 - ETA: 0s - loss: 0.8956 - accuracy: 0.61 - ETA: 0s - loss: 0.9013 - accuracy: 0.60 - ETA: 0s - loss: 0.9028 - accuracy: 0.60 - ETA: 0s - loss: 0.9042 - accuracy: 0.6061\n",
      "Epoch 00306: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9042 - accuracy: 0.6061 - val_loss: 1.0497 - val_accuracy: 0.4932 - lr: 0.0013\n",
      "Epoch 307/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9913 - accuracy: 0.54 - ETA: 0s - loss: 0.9571 - accuracy: 0.55 - ETA: 0s - loss: 0.9537 - accuracy: 0.56 - ETA: 0s - loss: 0.9216 - accuracy: 0.58 - ETA: 0s - loss: 0.9118 - accuracy: 0.59 - ETA: 0s - loss: 0.8986 - accuracy: 0.60 - ETA: 0s - loss: 0.8943 - accuracy: 0.61 - ETA: 0s - loss: 0.8915 - accuracy: 0.61 - ETA: 0s - loss: 0.8918 - accuracy: 0.61 - ETA: 0s - loss: 0.8969 - accuracy: 0.60 - ETA: 0s - loss: 0.8906 - accuracy: 0.61 - ETA: 0s - loss: 0.8833 - accuracy: 0.62 - ETA: 0s - loss: 0.8662 - accuracy: 0.63 - ETA: 0s - loss: 0.8769 - accuracy: 0.62 - ETA: 0s - loss: 0.8962 - accuracy: 0.61 - ETA: 0s - loss: 0.8979 - accuracy: 0.61 - ETA: 0s - loss: 0.9024 - accuracy: 0.60 - ETA: 0s - loss: 0.9034 - accuracy: 0.60 - ETA: 0s - loss: 0.9047 - accuracy: 0.6058\n",
      "Epoch 00307: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9047 - accuracy: 0.6058 - val_loss: 1.0401 - val_accuracy: 0.4972 - lr: 0.0013\n",
      "Epoch 308/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9742 - accuracy: 0.55 - ETA: 0s - loss: 0.9500 - accuracy: 0.56 - ETA: 0s - loss: 0.9452 - accuracy: 0.56 - ETA: 0s - loss: 0.9149 - accuracy: 0.59 - ETA: 0s - loss: 0.9075 - accuracy: 0.59 - ETA: 0s - loss: 0.8949 - accuracy: 0.61 - ETA: 0s - loss: 0.8908 - accuracy: 0.61 - ETA: 0s - loss: 0.8900 - accuracy: 0.61 - ETA: 0s - loss: 0.8909 - accuracy: 0.61 - ETA: 0s - loss: 0.8956 - accuracy: 0.60 - ETA: 0s - loss: 0.8884 - accuracy: 0.61 - ETA: 0s - loss: 0.8821 - accuracy: 0.62 - ETA: 0s - loss: 0.8654 - accuracy: 0.63 - ETA: 0s - loss: 0.8755 - accuracy: 0.62 - ETA: 0s - loss: 0.8939 - accuracy: 0.61 - ETA: 0s - loss: 0.8961 - accuracy: 0.61 - ETA: 0s - loss: 0.9010 - accuracy: 0.60 - ETA: 0s - loss: 0.9026 - accuracy: 0.60 - ETA: 0s - loss: 0.9040 - accuracy: 0.6064\n",
      "Epoch 00308: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9040 - accuracy: 0.6064 - val_loss: 1.0388 - val_accuracy: 0.4951 - lr: 0.0013\n",
      "Epoch 309/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9711 - accuracy: 0.54 - ETA: 0s - loss: 0.9428 - accuracy: 0.56 - ETA: 0s - loss: 0.9421 - accuracy: 0.56 - ETA: 0s - loss: 0.9120 - accuracy: 0.59 - ETA: 0s - loss: 0.9030 - accuracy: 0.60 - ETA: 0s - loss: 0.8910 - accuracy: 0.61 - ETA: 0s - loss: 0.8876 - accuracy: 0.61 - ETA: 0s - loss: 0.8872 - accuracy: 0.61 - ETA: 0s - loss: 0.8874 - accuracy: 0.61 - ETA: 0s - loss: 0.8923 - accuracy: 0.61 - ETA: 0s - loss: 0.8859 - accuracy: 0.61 - ETA: 0s - loss: 0.8795 - accuracy: 0.62 - ETA: 0s - loss: 0.8618 - accuracy: 0.64 - ETA: 0s - loss: 0.8720 - accuracy: 0.63 - ETA: 0s - loss: 0.8908 - accuracy: 0.61 - ETA: 0s - loss: 0.8931 - accuracy: 0.61 - ETA: 0s - loss: 0.8979 - accuracy: 0.60 - ETA: 0s - loss: 0.8996 - accuracy: 0.60 - ETA: 0s - loss: 0.9011 - accuracy: 0.6074\n",
      "Epoch 00309: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9011 - accuracy: 0.6074 - val_loss: 1.0336 - val_accuracy: 0.4976 - lr: 0.0013\n",
      "Epoch 310/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9827 - accuracy: 0.54 - ETA: 0s - loss: 0.9499 - accuracy: 0.56 - ETA: 0s - loss: 0.9490 - accuracy: 0.56 - ETA: 0s - loss: 0.9167 - accuracy: 0.59 - ETA: 0s - loss: 0.9074 - accuracy: 0.59 - ETA: 0s - loss: 0.8938 - accuracy: 0.61 - ETA: 0s - loss: 0.8907 - accuracy: 0.61 - ETA: 0s - loss: 0.8917 - accuracy: 0.61 - ETA: 0s - loss: 0.8917 - accuracy: 0.61 - ETA: 0s - loss: 0.8981 - accuracy: 0.61 - ETA: 0s - loss: 0.8914 - accuracy: 0.61 - ETA: 0s - loss: 0.8841 - accuracy: 0.62 - ETA: 0s - loss: 0.8669 - accuracy: 0.64 - ETA: 0s - loss: 0.8770 - accuracy: 0.63 - ETA: 0s - loss: 0.8947 - accuracy: 0.61 - ETA: 0s - loss: 0.8970 - accuracy: 0.61 - ETA: 0s - loss: 0.9022 - accuracy: 0.60 - ETA: 0s - loss: 0.9033 - accuracy: 0.60 - ETA: 0s - loss: 0.9041 - accuracy: 0.6085\n",
      "Epoch 00310: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9041 - accuracy: 0.6085 - val_loss: 1.0494 - val_accuracy: 0.4976 - lr: 0.0013\n",
      "Epoch 311/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9925 - accuracy: 0.54 - ETA: 0s - loss: 0.9547 - accuracy: 0.56 - ETA: 0s - loss: 0.9510 - accuracy: 0.56 - ETA: 0s - loss: 0.9173 - accuracy: 0.59 - ETA: 0s - loss: 0.9103 - accuracy: 0.59 - ETA: 0s - loss: 0.8962 - accuracy: 0.61 - ETA: 0s - loss: 0.8907 - accuracy: 0.61 - ETA: 0s - loss: 0.8895 - accuracy: 0.61 - ETA: 0s - loss: 0.8898 - accuracy: 0.61 - ETA: 0s - loss: 0.8958 - accuracy: 0.61 - ETA: 0s - loss: 0.8892 - accuracy: 0.61 - ETA: 0s - loss: 0.8819 - accuracy: 0.62 - ETA: 0s - loss: 0.8647 - accuracy: 0.64 - ETA: 0s - loss: 0.8761 - accuracy: 0.63 - ETA: 0s - loss: 0.8951 - accuracy: 0.61 - ETA: 0s - loss: 0.8973 - accuracy: 0.61 - ETA: 0s - loss: 0.9021 - accuracy: 0.60 - ETA: 0s - loss: 0.9038 - accuracy: 0.60 - ETA: 0s - loss: 0.9050 - accuracy: 0.6063\n",
      "Epoch 00311: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9050 - accuracy: 0.6063 - val_loss: 1.0479 - val_accuracy: 0.4943 - lr: 0.0013\n",
      "Epoch 312/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9810 - accuracy: 0.54 - ETA: 0s - loss: 0.9470 - accuracy: 0.56 - ETA: 0s - loss: 0.9442 - accuracy: 0.56 - ETA: 0s - loss: 0.9109 - accuracy: 0.59 - ETA: 0s - loss: 0.9039 - accuracy: 0.60 - ETA: 0s - loss: 0.8908 - accuracy: 0.61 - ETA: 0s - loss: 0.8878 - accuracy: 0.62 - ETA: 0s - loss: 0.8878 - accuracy: 0.62 - ETA: 0s - loss: 0.8887 - accuracy: 0.61 - ETA: 0s - loss: 0.8948 - accuracy: 0.61 - ETA: 0s - loss: 0.8879 - accuracy: 0.61 - ETA: 0s - loss: 0.8811 - accuracy: 0.62 - ETA: 0s - loss: 0.8639 - accuracy: 0.64 - ETA: 0s - loss: 0.8738 - accuracy: 0.63 - ETA: 0s - loss: 0.8916 - accuracy: 0.61 - ETA: 0s - loss: 0.8935 - accuracy: 0.61 - ETA: 0s - loss: 0.8992 - accuracy: 0.60 - ETA: 0s - loss: 0.9008 - accuracy: 0.60 - ETA: 0s - loss: 0.9022 - accuracy: 0.6069\n",
      "Epoch 00312: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9022 - accuracy: 0.6069 - val_loss: 1.0396 - val_accuracy: 0.4974 - lr: 0.0013\n",
      "Epoch 313/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9817 - accuracy: 0.54 - ETA: 0s - loss: 0.9474 - accuracy: 0.55 - ETA: 0s - loss: 0.9454 - accuracy: 0.56 - ETA: 0s - loss: 0.9148 - accuracy: 0.59 - ETA: 0s - loss: 0.9049 - accuracy: 0.60 - ETA: 0s - loss: 0.8920 - accuracy: 0.61 - ETA: 0s - loss: 0.8880 - accuracy: 0.61 - ETA: 0s - loss: 0.8873 - accuracy: 0.62 - ETA: 0s - loss: 0.8879 - accuracy: 0.61 - ETA: 0s - loss: 0.8929 - accuracy: 0.61 - ETA: 0s - loss: 0.8862 - accuracy: 0.62 - ETA: 0s - loss: 0.8811 - accuracy: 0.62 - ETA: 0s - loss: 0.8641 - accuracy: 0.64 - ETA: 0s - loss: 0.8747 - accuracy: 0.62 - ETA: 0s - loss: 0.8952 - accuracy: 0.61 - ETA: 0s - loss: 0.9007 - accuracy: 0.60 - ETA: 0s - loss: 0.9017 - accuracy: 0.60 - ETA: 0s - loss: 0.9027 - accuracy: 0.6069\n",
      "Epoch 00313: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.9027 - accuracy: 0.6069 - val_loss: 1.0318 - val_accuracy: 0.5015 - lr: 0.0013\n",
      "Epoch 314/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9833 - accuracy: 0.53 - ETA: 0s - loss: 0.9506 - accuracy: 0.56 - ETA: 0s - loss: 0.9486 - accuracy: 0.56 - ETA: 0s - loss: 0.9136 - accuracy: 0.59 - ETA: 0s - loss: 0.9049 - accuracy: 0.60 - ETA: 0s - loss: 0.8930 - accuracy: 0.61 - ETA: 0s - loss: 0.8877 - accuracy: 0.61 - ETA: 0s - loss: 0.8866 - accuracy: 0.62 - ETA: 0s - loss: 0.8870 - accuracy: 0.62 - ETA: 0s - loss: 0.8934 - accuracy: 0.61 - ETA: 0s - loss: 0.8876 - accuracy: 0.61 - ETA: 0s - loss: 0.8816 - accuracy: 0.62 - ETA: 0s - loss: 0.8648 - accuracy: 0.63 - ETA: 0s - loss: 0.8756 - accuracy: 0.62 - ETA: 0s - loss: 0.8949 - accuracy: 0.61 - ETA: 0s - loss: 0.8967 - accuracy: 0.61 - ETA: 0s - loss: 0.9019 - accuracy: 0.60 - ETA: 0s - loss: 0.9028 - accuracy: 0.60 - ETA: 0s - loss: 0.9041 - accuracy: 0.6057\n",
      "Epoch 00314: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9041 - accuracy: 0.6057 - val_loss: 1.0361 - val_accuracy: 0.4985 - lr: 0.0013\n",
      "Epoch 315/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9770 - accuracy: 0.55 - ETA: 0s - loss: 0.9437 - accuracy: 0.56 - ETA: 0s - loss: 0.9427 - accuracy: 0.57 - ETA: 0s - loss: 0.9122 - accuracy: 0.59 - ETA: 0s - loss: 0.9043 - accuracy: 0.60 - ETA: 0s - loss: 0.8912 - accuracy: 0.61 - ETA: 0s - loss: 0.8879 - accuracy: 0.62 - ETA: 0s - loss: 0.8864 - accuracy: 0.62 - ETA: 0s - loss: 0.8849 - accuracy: 0.62 - ETA: 0s - loss: 0.8915 - accuracy: 0.61 - ETA: 0s - loss: 0.8858 - accuracy: 0.62 - ETA: 0s - loss: 0.8787 - accuracy: 0.62 - ETA: 0s - loss: 0.8616 - accuracy: 0.64 - ETA: 0s - loss: 0.8896 - accuracy: 0.61 - ETA: 0s - loss: 0.8916 - accuracy: 0.61 - ETA: 0s - loss: 0.8972 - accuracy: 0.61 - ETA: 0s - loss: 0.8984 - accuracy: 0.61 - ETA: 0s - loss: 0.8999 - accuracy: 0.6094\n",
      "Epoch 00315: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8999 - accuracy: 0.6094 - val_loss: 1.0304 - val_accuracy: 0.5016 - lr: 0.0013\n",
      "Epoch 316/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9698 - accuracy: 0.55 - ETA: 0s - loss: 0.9398 - accuracy: 0.56 - ETA: 0s - loss: 0.9410 - accuracy: 0.56 - ETA: 0s - loss: 0.9123 - accuracy: 0.59 - ETA: 0s - loss: 0.9038 - accuracy: 0.60 - ETA: 0s - loss: 0.8914 - accuracy: 0.61 - ETA: 0s - loss: 0.8871 - accuracy: 0.61 - ETA: 0s - loss: 0.8859 - accuracy: 0.61 - ETA: 0s - loss: 0.8868 - accuracy: 0.61 - ETA: 0s - loss: 0.8928 - accuracy: 0.61 - ETA: 0s - loss: 0.8860 - accuracy: 0.61 - ETA: 0s - loss: 0.8790 - accuracy: 0.62 - ETA: 0s - loss: 0.8624 - accuracy: 0.63 - ETA: 0s - loss: 0.8730 - accuracy: 0.62 - ETA: 0s - loss: 0.8919 - accuracy: 0.61 - ETA: 0s - loss: 0.8940 - accuracy: 0.61 - ETA: 0s - loss: 0.8991 - accuracy: 0.60 - ETA: 0s - loss: 0.9002 - accuracy: 0.60 - ETA: 0s - loss: 0.9016 - accuracy: 0.6075\n",
      "Epoch 00316: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 77ms/step - loss: 0.9016 - accuracy: 0.6075 - val_loss: 1.0258 - val_accuracy: 0.4972 - lr: 0.0013\n",
      "Epoch 317/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9746 - accuracy: 0.53 - ETA: 0s - loss: 0.9479 - accuracy: 0.55 - ETA: 0s - loss: 0.9462 - accuracy: 0.56 - ETA: 0s - loss: 0.9152 - accuracy: 0.58 - ETA: 0s - loss: 0.9072 - accuracy: 0.59 - ETA: 0s - loss: 0.8945 - accuracy: 0.61 - ETA: 0s - loss: 0.8913 - accuracy: 0.61 - ETA: 0s - loss: 0.8883 - accuracy: 0.61 - ETA: 0s - loss: 0.8885 - accuracy: 0.61 - ETA: 0s - loss: 0.8950 - accuracy: 0.60 - ETA: 0s - loss: 0.8878 - accuracy: 0.61 - ETA: 0s - loss: 0.8805 - accuracy: 0.62 - ETA: 0s - loss: 0.8631 - accuracy: 0.63 - ETA: 0s - loss: 0.8739 - accuracy: 0.62 - ETA: 0s - loss: 0.8931 - accuracy: 0.61 - ETA: 0s - loss: 0.8955 - accuracy: 0.61 - ETA: 0s - loss: 0.9008 - accuracy: 0.60 - ETA: 0s - loss: 0.9022 - accuracy: 0.60 - ETA: 0s - loss: 0.9038 - accuracy: 0.6041\n",
      "Epoch 00317: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9038 - accuracy: 0.6041 - val_loss: 1.0252 - val_accuracy: 0.5011 - lr: 0.0013\n",
      "Epoch 318/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9847 - accuracy: 0.55 - ETA: 0s - loss: 0.9467 - accuracy: 0.56 - ETA: 0s - loss: 0.9487 - accuracy: 0.56 - ETA: 0s - loss: 0.9145 - accuracy: 0.59 - ETA: 0s - loss: 0.9052 - accuracy: 0.60 - ETA: 0s - loss: 0.8929 - accuracy: 0.61 - ETA: 0s - loss: 0.8880 - accuracy: 0.62 - ETA: 0s - loss: 0.8874 - accuracy: 0.62 - ETA: 0s - loss: 0.8870 - accuracy: 0.62 - ETA: 0s - loss: 0.8930 - accuracy: 0.61 - ETA: 0s - loss: 0.8861 - accuracy: 0.62 - ETA: 0s - loss: 0.8787 - accuracy: 0.62 - ETA: 0s - loss: 0.8620 - accuracy: 0.64 - ETA: 0s - loss: 0.8728 - accuracy: 0.63 - ETA: 0s - loss: 0.8919 - accuracy: 0.61 - ETA: 0s - loss: 0.8940 - accuracy: 0.61 - ETA: 0s - loss: 0.9000 - accuracy: 0.60 - ETA: 0s - loss: 0.9010 - accuracy: 0.60 - ETA: 0s - loss: 0.9027 - accuracy: 0.6077\n",
      "Epoch 00318: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9027 - accuracy: 0.6077 - val_loss: 1.0291 - val_accuracy: 0.5010 - lr: 0.0013\n",
      "Epoch 319/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9899 - accuracy: 0.54 - ETA: 0s - loss: 0.9504 - accuracy: 0.56 - ETA: 0s - loss: 0.9498 - accuracy: 0.56 - ETA: 0s - loss: 0.9164 - accuracy: 0.59 - ETA: 0s - loss: 0.9081 - accuracy: 0.60 - ETA: 0s - loss: 0.8949 - accuracy: 0.61 - ETA: 0s - loss: 0.8908 - accuracy: 0.61 - ETA: 0s - loss: 0.8902 - accuracy: 0.62 - ETA: 0s - loss: 0.8898 - accuracy: 0.61 - ETA: 0s - loss: 0.8950 - accuracy: 0.61 - ETA: 0s - loss: 0.8885 - accuracy: 0.61 - ETA: 0s - loss: 0.8810 - accuracy: 0.62 - ETA: 0s - loss: 0.8641 - accuracy: 0.64 - ETA: 0s - loss: 0.8743 - accuracy: 0.63 - ETA: 0s - loss: 0.8923 - accuracy: 0.61 - ETA: 0s - loss: 0.8941 - accuracy: 0.61 - ETA: 0s - loss: 0.8998 - accuracy: 0.60 - ETA: 0s - loss: 0.9012 - accuracy: 0.60 - ETA: 0s - loss: 0.9023 - accuracy: 0.6060\n",
      "Epoch 00319: val_loss did not improve from 0.99131\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00319: ReduceLROnPlateau reducing learning rate to 0.0010376292280852796.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9023 - accuracy: 0.6060 - val_loss: 1.0380 - val_accuracy: 0.5018 - lr: 0.0013\n",
      "Epoch 320/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9792 - accuracy: 0.55 - ETA: 0s - loss: 0.9459 - accuracy: 0.56 - ETA: 0s - loss: 0.9470 - accuracy: 0.56 - ETA: 0s - loss: 0.9145 - accuracy: 0.59 - ETA: 0s - loss: 0.9054 - accuracy: 0.60 - ETA: 0s - loss: 0.8923 - accuracy: 0.61 - ETA: 0s - loss: 0.8891 - accuracy: 0.61 - ETA: 0s - loss: 0.8874 - accuracy: 0.62 - ETA: 0s - loss: 0.8875 - accuracy: 0.62 - ETA: 0s - loss: 0.8929 - accuracy: 0.61 - ETA: 0s - loss: 0.8866 - accuracy: 0.62 - ETA: 0s - loss: 0.8801 - accuracy: 0.62 - ETA: 0s - loss: 0.8634 - accuracy: 0.64 - ETA: 0s - loss: 0.8745 - accuracy: 0.63 - ETA: 0s - loss: 0.8925 - accuracy: 0.61 - ETA: 0s - loss: 0.8942 - accuracy: 0.61 - ETA: 0s - loss: 0.8997 - accuracy: 0.60 - ETA: 0s - loss: 0.9013 - accuracy: 0.60 - ETA: 0s - loss: 0.9020 - accuracy: 0.6077\n",
      "Epoch 00320: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9020 - accuracy: 0.6077 - val_loss: 1.0270 - val_accuracy: 0.4949 - lr: 0.0010\n",
      "Epoch 321/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9836 - accuracy: 0.54 - ETA: 0s - loss: 0.9491 - accuracy: 0.55 - ETA: 0s - loss: 0.9502 - accuracy: 0.56 - ETA: 0s - loss: 0.9177 - accuracy: 0.58 - ETA: 0s - loss: 0.9080 - accuracy: 0.59 - ETA: 0s - loss: 0.8943 - accuracy: 0.60 - ETA: 0s - loss: 0.8891 - accuracy: 0.61 - ETA: 0s - loss: 0.8880 - accuracy: 0.61 - ETA: 0s - loss: 0.8872 - accuracy: 0.61 - ETA: 0s - loss: 0.8928 - accuracy: 0.60 - ETA: 0s - loss: 0.8860 - accuracy: 0.61 - ETA: 0s - loss: 0.8791 - accuracy: 0.62 - ETA: 0s - loss: 0.8623 - accuracy: 0.63 - ETA: 0s - loss: 0.8729 - accuracy: 0.62 - ETA: 0s - loss: 0.8915 - accuracy: 0.61 - ETA: 0s - loss: 0.8930 - accuracy: 0.61 - ETA: 0s - loss: 0.8987 - accuracy: 0.60 - ETA: 0s - loss: 0.8994 - accuracy: 0.60 - ETA: 0s - loss: 0.9007 - accuracy: 0.6056\n",
      "Epoch 00321: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9007 - accuracy: 0.6056 - val_loss: 1.0259 - val_accuracy: 0.5026 - lr: 0.0010\n",
      "Epoch 322/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9713 - accuracy: 0.54 - ETA: 0s - loss: 0.9424 - accuracy: 0.56 - ETA: 0s - loss: 0.9446 - accuracy: 0.56 - ETA: 0s - loss: 0.9117 - accuracy: 0.59 - ETA: 0s - loss: 0.9028 - accuracy: 0.60 - ETA: 0s - loss: 0.8907 - accuracy: 0.61 - ETA: 0s - loss: 0.8867 - accuracy: 0.61 - ETA: 0s - loss: 0.8863 - accuracy: 0.62 - ETA: 0s - loss: 0.8858 - accuracy: 0.62 - ETA: 0s - loss: 0.8923 - accuracy: 0.61 - ETA: 0s - loss: 0.8868 - accuracy: 0.61 - ETA: 0s - loss: 0.8802 - accuracy: 0.62 - ETA: 0s - loss: 0.8628 - accuracy: 0.63 - ETA: 0s - loss: 0.8729 - accuracy: 0.62 - ETA: 0s - loss: 0.8920 - accuracy: 0.61 - ETA: 0s - loss: 0.8937 - accuracy: 0.61 - ETA: 0s - loss: 0.8984 - accuracy: 0.60 - ETA: 0s - loss: 0.8989 - accuracy: 0.60 - ETA: 0s - loss: 0.9006 - accuracy: 0.6070\n",
      "Epoch 00322: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9006 - accuracy: 0.6070 - val_loss: 1.0315 - val_accuracy: 0.5007 - lr: 0.0010\n",
      "Epoch 323/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9847 - accuracy: 0.54 - ETA: 0s - loss: 0.9522 - accuracy: 0.56 - ETA: 0s - loss: 0.9503 - accuracy: 0.56 - ETA: 0s - loss: 0.9170 - accuracy: 0.59 - ETA: 0s - loss: 0.9080 - accuracy: 0.60 - ETA: 0s - loss: 0.8944 - accuracy: 0.61 - ETA: 0s - loss: 0.8898 - accuracy: 0.62 - ETA: 0s - loss: 0.8877 - accuracy: 0.62 - ETA: 0s - loss: 0.8887 - accuracy: 0.62 - ETA: 0s - loss: 0.8946 - accuracy: 0.61 - ETA: 0s - loss: 0.8882 - accuracy: 0.62 - ETA: 0s - loss: 0.8816 - accuracy: 0.62 - ETA: 0s - loss: 0.8644 - accuracy: 0.64 - ETA: 0s - loss: 0.8741 - accuracy: 0.62 - ETA: 0s - loss: 0.8918 - accuracy: 0.61 - ETA: 0s - loss: 0.8935 - accuracy: 0.61 - ETA: 0s - loss: 0.8984 - accuracy: 0.60 - ETA: 0s - loss: 0.8993 - accuracy: 0.60 - ETA: 0s - loss: 0.9003 - accuracy: 0.6071\n",
      "Epoch 00323: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9003 - accuracy: 0.6071 - val_loss: 1.0349 - val_accuracy: 0.4976 - lr: 0.0010\n",
      "Epoch 324/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9895 - accuracy: 0.53 - ETA: 0s - loss: 0.9533 - accuracy: 0.55 - ETA: 0s - loss: 0.9502 - accuracy: 0.56 - ETA: 0s - loss: 0.9188 - accuracy: 0.58 - ETA: 0s - loss: 0.9090 - accuracy: 0.59 - ETA: 0s - loss: 0.8957 - accuracy: 0.61 - ETA: 0s - loss: 0.8912 - accuracy: 0.61 - ETA: 0s - loss: 0.8904 - accuracy: 0.61 - ETA: 0s - loss: 0.8904 - accuracy: 0.61 - ETA: 0s - loss: 0.8954 - accuracy: 0.60 - ETA: 0s - loss: 0.8889 - accuracy: 0.61 - ETA: 0s - loss: 0.8827 - accuracy: 0.62 - ETA: 0s - loss: 0.8659 - accuracy: 0.63 - ETA: 0s - loss: 0.8757 - accuracy: 0.62 - ETA: 0s - loss: 0.8930 - accuracy: 0.61 - ETA: 0s - loss: 0.8949 - accuracy: 0.61 - ETA: 0s - loss: 0.9003 - accuracy: 0.60 - ETA: 0s - loss: 0.9020 - accuracy: 0.60 - ETA: 0s - loss: 0.9035 - accuracy: 0.6063\n",
      "Epoch 00324: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9035 - accuracy: 0.6063 - val_loss: 1.0400 - val_accuracy: 0.4964 - lr: 0.0010\n",
      "Epoch 325/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9816 - accuracy: 0.53 - ETA: 0s - loss: 0.9457 - accuracy: 0.56 - ETA: 0s - loss: 0.9461 - accuracy: 0.56 - ETA: 0s - loss: 0.9111 - accuracy: 0.59 - ETA: 0s - loss: 0.9038 - accuracy: 0.59 - ETA: 0s - loss: 0.8907 - accuracy: 0.61 - ETA: 0s - loss: 0.8871 - accuracy: 0.61 - ETA: 0s - loss: 0.8874 - accuracy: 0.61 - ETA: 0s - loss: 0.8868 - accuracy: 0.61 - ETA: 0s - loss: 0.8921 - accuracy: 0.60 - ETA: 0s - loss: 0.8856 - accuracy: 0.61 - ETA: 0s - loss: 0.8792 - accuracy: 0.62 - ETA: 0s - loss: 0.8619 - accuracy: 0.63 - ETA: 0s - loss: 0.8721 - accuracy: 0.62 - ETA: 0s - loss: 0.8897 - accuracy: 0.61 - ETA: 0s - loss: 0.8919 - accuracy: 0.61 - ETA: 0s - loss: 0.8971 - accuracy: 0.60 - ETA: 0s - loss: 0.8988 - accuracy: 0.60 - ETA: 0s - loss: 0.9004 - accuracy: 0.6072\n",
      "Epoch 00325: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9004 - accuracy: 0.6072 - val_loss: 1.0361 - val_accuracy: 0.4987 - lr: 0.0010\n",
      "Epoch 326/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9813 - accuracy: 0.54 - ETA: 0s - loss: 0.9520 - accuracy: 0.56 - ETA: 0s - loss: 0.9472 - accuracy: 0.56 - ETA: 0s - loss: 0.9142 - accuracy: 0.59 - ETA: 0s - loss: 0.9038 - accuracy: 0.60 - ETA: 0s - loss: 0.8900 - accuracy: 0.61 - ETA: 0s - loss: 0.8862 - accuracy: 0.61 - ETA: 0s - loss: 0.8850 - accuracy: 0.62 - ETA: 0s - loss: 0.8848 - accuracy: 0.61 - ETA: 0s - loss: 0.8900 - accuracy: 0.61 - ETA: 0s - loss: 0.8836 - accuracy: 0.61 - ETA: 0s - loss: 0.8774 - accuracy: 0.62 - ETA: 0s - loss: 0.8603 - accuracy: 0.64 - ETA: 0s - loss: 0.8708 - accuracy: 0.63 - ETA: 0s - loss: 0.8893 - accuracy: 0.61 - ETA: 0s - loss: 0.8913 - accuracy: 0.61 - ETA: 0s - loss: 0.8966 - accuracy: 0.60 - ETA: 0s - loss: 0.8975 - accuracy: 0.60 - ETA: 0s - loss: 0.8987 - accuracy: 0.6084\n",
      "Epoch 00326: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8987 - accuracy: 0.6084 - val_loss: 1.0320 - val_accuracy: 0.4990 - lr: 0.0010\n",
      "Epoch 327/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9702 - accuracy: 0.55 - ETA: 0s - loss: 0.9395 - accuracy: 0.56 - ETA: 0s - loss: 0.9402 - accuracy: 0.56 - ETA: 0s - loss: 0.9093 - accuracy: 0.59 - ETA: 0s - loss: 0.9019 - accuracy: 0.60 - ETA: 0s - loss: 0.8899 - accuracy: 0.61 - ETA: 0s - loss: 0.8867 - accuracy: 0.61 - ETA: 0s - loss: 0.8876 - accuracy: 0.61 - ETA: 0s - loss: 0.8888 - accuracy: 0.61 - ETA: 0s - loss: 0.8936 - accuracy: 0.60 - ETA: 0s - loss: 0.8871 - accuracy: 0.61 - ETA: 0s - loss: 0.8814 - accuracy: 0.62 - ETA: 0s - loss: 0.8646 - accuracy: 0.63 - ETA: 0s - loss: 0.8746 - accuracy: 0.62 - ETA: 0s - loss: 0.8937 - accuracy: 0.61 - ETA: 0s - loss: 0.8959 - accuracy: 0.61 - ETA: 0s - loss: 0.9013 - accuracy: 0.60 - ETA: 0s - loss: 0.9028 - accuracy: 0.60 - ETA: 0s - loss: 0.9033 - accuracy: 0.6065\n",
      "Epoch 00327: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9033 - accuracy: 0.6065 - val_loss: 1.0326 - val_accuracy: 0.5021 - lr: 0.0010\n",
      "Epoch 328/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9872 - accuracy: 0.54 - ETA: 0s - loss: 0.9430 - accuracy: 0.56 - ETA: 0s - loss: 0.9409 - accuracy: 0.56 - ETA: 0s - loss: 0.9081 - accuracy: 0.59 - ETA: 0s - loss: 0.8996 - accuracy: 0.60 - ETA: 0s - loss: 0.8878 - accuracy: 0.61 - ETA: 0s - loss: 0.8852 - accuracy: 0.61 - ETA: 0s - loss: 0.8842 - accuracy: 0.61 - ETA: 0s - loss: 0.8847 - accuracy: 0.61 - ETA: 0s - loss: 0.8900 - accuracy: 0.61 - ETA: 0s - loss: 0.8834 - accuracy: 0.61 - ETA: 0s - loss: 0.8769 - accuracy: 0.62 - ETA: 0s - loss: 0.8599 - accuracy: 0.64 - ETA: 0s - loss: 0.8707 - accuracy: 0.62 - ETA: 0s - loss: 0.8895 - accuracy: 0.61 - ETA: 0s - loss: 0.8918 - accuracy: 0.61 - ETA: 0s - loss: 0.8968 - accuracy: 0.60 - ETA: 0s - loss: 0.8980 - accuracy: 0.60 - ETA: 0s - loss: 0.8986 - accuracy: 0.6068\n",
      "Epoch 00328: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8986 - accuracy: 0.6068 - val_loss: 1.0368 - val_accuracy: 0.5011 - lr: 0.0010\n",
      "Epoch 329/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9747 - accuracy: 0.54 - ETA: 0s - loss: 0.9492 - accuracy: 0.56 - ETA: 0s - loss: 0.9416 - accuracy: 0.56 - ETA: 0s - loss: 0.9108 - accuracy: 0.59 - ETA: 0s - loss: 0.9020 - accuracy: 0.60 - ETA: 0s - loss: 0.8892 - accuracy: 0.61 - ETA: 0s - loss: 0.8860 - accuracy: 0.61 - ETA: 0s - loss: 0.8849 - accuracy: 0.61 - ETA: 0s - loss: 0.8847 - accuracy: 0.61 - ETA: 0s - loss: 0.8911 - accuracy: 0.61 - ETA: 0s - loss: 0.8860 - accuracy: 0.61 - ETA: 0s - loss: 0.8791 - accuracy: 0.62 - ETA: 0s - loss: 0.8614 - accuracy: 0.64 - ETA: 0s - loss: 0.8721 - accuracy: 0.62 - ETA: 0s - loss: 0.8906 - accuracy: 0.61 - ETA: 0s - loss: 0.8930 - accuracy: 0.61 - ETA: 0s - loss: 0.8979 - accuracy: 0.60 - ETA: 0s - loss: 0.8994 - accuracy: 0.60 - ETA: 0s - loss: 0.9013 - accuracy: 0.6065\n",
      "Epoch 00329: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9013 - accuracy: 0.6065 - val_loss: 1.0387 - val_accuracy: 0.4964 - lr: 0.0010\n",
      "Epoch 330/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9814 - accuracy: 0.54 - ETA: 0s - loss: 0.9444 - accuracy: 0.56 - ETA: 0s - loss: 0.9438 - accuracy: 0.56 - ETA: 0s - loss: 0.9101 - accuracy: 0.59 - ETA: 0s - loss: 0.9027 - accuracy: 0.60 - ETA: 0s - loss: 0.8903 - accuracy: 0.61 - ETA: 0s - loss: 0.8865 - accuracy: 0.61 - ETA: 0s - loss: 0.8856 - accuracy: 0.62 - ETA: 0s - loss: 0.8858 - accuracy: 0.61 - ETA: 0s - loss: 0.8923 - accuracy: 0.61 - ETA: 0s - loss: 0.8857 - accuracy: 0.61 - ETA: 0s - loss: 0.8793 - accuracy: 0.62 - ETA: 0s - loss: 0.8624 - accuracy: 0.63 - ETA: 0s - loss: 0.8722 - accuracy: 0.62 - ETA: 0s - loss: 0.8886 - accuracy: 0.61 - ETA: 0s - loss: 0.8904 - accuracy: 0.61 - ETA: 0s - loss: 0.8960 - accuracy: 0.60 - ETA: 0s - loss: 0.8981 - accuracy: 0.60 - ETA: 0s - loss: 0.8998 - accuracy: 0.6070\n",
      "Epoch 00330: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8998 - accuracy: 0.6070 - val_loss: 1.0402 - val_accuracy: 0.4984 - lr: 0.0010\n",
      "Epoch 331/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9721 - accuracy: 0.54 - ETA: 0s - loss: 0.9394 - accuracy: 0.56 - ETA: 0s - loss: 0.9397 - accuracy: 0.56 - ETA: 0s - loss: 0.9106 - accuracy: 0.59 - ETA: 0s - loss: 0.9018 - accuracy: 0.59 - ETA: 0s - loss: 0.8891 - accuracy: 0.61 - ETA: 0s - loss: 0.8850 - accuracy: 0.61 - ETA: 0s - loss: 0.8850 - accuracy: 0.61 - ETA: 0s - loss: 0.8851 - accuracy: 0.61 - ETA: 0s - loss: 0.8918 - accuracy: 0.60 - ETA: 0s - loss: 0.8850 - accuracy: 0.61 - ETA: 0s - loss: 0.8783 - accuracy: 0.62 - ETA: 0s - loss: 0.8608 - accuracy: 0.64 - ETA: 0s - loss: 0.8708 - accuracy: 0.62 - ETA: 0s - loss: 0.8897 - accuracy: 0.61 - ETA: 0s - loss: 0.8912 - accuracy: 0.61 - ETA: 0s - loss: 0.8963 - accuracy: 0.60 - ETA: 0s - loss: 0.8982 - accuracy: 0.60 - ETA: 0s - loss: 0.8996 - accuracy: 0.6065\n",
      "Epoch 00331: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8996 - accuracy: 0.6065 - val_loss: 1.0344 - val_accuracy: 0.4992 - lr: 0.0010\n",
      "Epoch 332/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9745 - accuracy: 0.54 - ETA: 0s - loss: 0.9404 - accuracy: 0.56 - ETA: 0s - loss: 0.9404 - accuracy: 0.56 - ETA: 0s - loss: 0.9083 - accuracy: 0.59 - ETA: 0s - loss: 0.8997 - accuracy: 0.60 - ETA: 0s - loss: 0.8870 - accuracy: 0.61 - ETA: 0s - loss: 0.8826 - accuracy: 0.61 - ETA: 0s - loss: 0.8823 - accuracy: 0.62 - ETA: 0s - loss: 0.8819 - accuracy: 0.62 - ETA: 0s - loss: 0.8870 - accuracy: 0.61 - ETA: 0s - loss: 0.8818 - accuracy: 0.62 - ETA: 0s - loss: 0.8760 - accuracy: 0.62 - ETA: 0s - loss: 0.8590 - accuracy: 0.64 - ETA: 0s - loss: 0.8688 - accuracy: 0.63 - ETA: 0s - loss: 0.8856 - accuracy: 0.61 - ETA: 0s - loss: 0.8875 - accuracy: 0.61 - ETA: 0s - loss: 0.8931 - accuracy: 0.61 - ETA: 0s - loss: 0.8944 - accuracy: 0.61 - ETA: 0s - loss: 0.8967 - accuracy: 0.6090\n",
      "Epoch 00332: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8967 - accuracy: 0.6090 - val_loss: 1.0319 - val_accuracy: 0.4987 - lr: 0.0010\n",
      "Epoch 333/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9714 - accuracy: 0.54 - ETA: 0s - loss: 0.9445 - accuracy: 0.56 - ETA: 0s - loss: 0.9454 - accuracy: 0.56 - ETA: 0s - loss: 0.9115 - accuracy: 0.59 - ETA: 0s - loss: 0.9036 - accuracy: 0.60 - ETA: 0s - loss: 0.8897 - accuracy: 0.61 - ETA: 0s - loss: 0.8849 - accuracy: 0.61 - ETA: 0s - loss: 0.8851 - accuracy: 0.62 - ETA: 0s - loss: 0.8843 - accuracy: 0.61 - ETA: 0s - loss: 0.8886 - accuracy: 0.61 - ETA: 0s - loss: 0.8822 - accuracy: 0.62 - ETA: 0s - loss: 0.8760 - accuracy: 0.62 - ETA: 0s - loss: 0.8584 - accuracy: 0.64 - ETA: 0s - loss: 0.8681 - accuracy: 0.63 - ETA: 0s - loss: 0.8864 - accuracy: 0.61 - ETA: 0s - loss: 0.8890 - accuracy: 0.61 - ETA: 0s - loss: 0.8947 - accuracy: 0.61 - ETA: 0s - loss: 0.8964 - accuracy: 0.61 - ETA: 0s - loss: 0.8983 - accuracy: 0.6086\n",
      "Epoch 00333: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00333: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8983 - accuracy: 0.6086 - val_loss: 1.0397 - val_accuracy: 0.4943 - lr: 0.0010\n",
      "Epoch 334/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9698 - accuracy: 0.54 - ETA: 0s - loss: 0.9380 - accuracy: 0.56 - ETA: 0s - loss: 0.9415 - accuracy: 0.56 - ETA: 0s - loss: 0.9107 - accuracy: 0.58 - ETA: 0s - loss: 0.9019 - accuracy: 0.59 - ETA: 0s - loss: 0.8891 - accuracy: 0.61 - ETA: 0s - loss: 0.8846 - accuracy: 0.61 - ETA: 0s - loss: 0.8840 - accuracy: 0.61 - ETA: 0s - loss: 0.8843 - accuracy: 0.61 - ETA: 0s - loss: 0.8894 - accuracy: 0.61 - ETA: 0s - loss: 0.8830 - accuracy: 0.61 - ETA: 0s - loss: 0.8763 - accuracy: 0.62 - ETA: 0s - loss: 0.8591 - accuracy: 0.64 - ETA: 0s - loss: 0.8706 - accuracy: 0.62 - ETA: 0s - loss: 0.8887 - accuracy: 0.61 - ETA: 0s - loss: 0.8913 - accuracy: 0.61 - ETA: 0s - loss: 0.8971 - accuracy: 0.60 - ETA: 0s - loss: 0.8993 - accuracy: 0.60 - ETA: 0s - loss: 0.9009 - accuracy: 0.6046\n",
      "Epoch 00334: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9009 - accuracy: 0.6046 - val_loss: 1.0441 - val_accuracy: 0.4915 - lr: 0.0010\n",
      "Epoch 335/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9568 - accuracy: 0.54 - ETA: 0s - loss: 0.9295 - accuracy: 0.56 - ETA: 0s - loss: 0.9337 - accuracy: 0.56 - ETA: 0s - loss: 0.9008 - accuracy: 0.59 - ETA: 0s - loss: 0.8936 - accuracy: 0.60 - ETA: 0s - loss: 0.8825 - accuracy: 0.61 - ETA: 0s - loss: 0.8791 - accuracy: 0.61 - ETA: 0s - loss: 0.8817 - accuracy: 0.61 - ETA: 0s - loss: 0.8827 - accuracy: 0.61 - ETA: 0s - loss: 0.8883 - accuracy: 0.60 - ETA: 0s - loss: 0.8826 - accuracy: 0.61 - ETA: 0s - loss: 0.8770 - accuracy: 0.62 - ETA: 0s - loss: 0.8602 - accuracy: 0.63 - ETA: 0s - loss: 0.8700 - accuracy: 0.62 - ETA: 0s - loss: 0.8869 - accuracy: 0.61 - ETA: 0s - loss: 0.8896 - accuracy: 0.61 - ETA: 0s - loss: 0.8949 - accuracy: 0.60 - ETA: 0s - loss: 0.8965 - accuracy: 0.60 - ETA: 0s - loss: 0.8972 - accuracy: 0.6058\n",
      "Epoch 00335: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8972 - accuracy: 0.6058 - val_loss: 1.0421 - val_accuracy: 0.4959 - lr: 0.0010\n",
      "Epoch 336/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9702 - accuracy: 0.53 - ETA: 0s - loss: 0.9372 - accuracy: 0.56 - ETA: 0s - loss: 0.9372 - accuracy: 0.56 - ETA: 0s - loss: 0.9097 - accuracy: 0.58 - ETA: 0s - loss: 0.9027 - accuracy: 0.59 - ETA: 0s - loss: 0.8906 - accuracy: 0.61 - ETA: 0s - loss: 0.8875 - accuracy: 0.61 - ETA: 0s - loss: 0.8878 - accuracy: 0.61 - ETA: 0s - loss: 0.8884 - accuracy: 0.61 - ETA: 0s - loss: 0.8939 - accuracy: 0.60 - ETA: 0s - loss: 0.8860 - accuracy: 0.61 - ETA: 0s - loss: 0.8795 - accuracy: 0.62 - ETA: 0s - loss: 0.8623 - accuracy: 0.63 - ETA: 0s - loss: 0.8720 - accuracy: 0.62 - ETA: 0s - loss: 0.8892 - accuracy: 0.61 - ETA: 0s - loss: 0.8917 - accuracy: 0.61 - ETA: 0s - loss: 0.8966 - accuracy: 0.60 - ETA: 0s - loss: 0.8980 - accuracy: 0.60 - ETA: 0s - loss: 0.8988 - accuracy: 0.6062\n",
      "Epoch 00336: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8988 - accuracy: 0.6062 - val_loss: 1.0361 - val_accuracy: 0.4958 - lr: 0.0010\n",
      "Epoch 337/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9678 - accuracy: 0.55 - ETA: 0s - loss: 0.9406 - accuracy: 0.56 - ETA: 0s - loss: 0.9395 - accuracy: 0.56 - ETA: 0s - loss: 0.9103 - accuracy: 0.59 - ETA: 0s - loss: 0.8996 - accuracy: 0.60 - ETA: 0s - loss: 0.8875 - accuracy: 0.61 - ETA: 0s - loss: 0.8840 - accuracy: 0.62 - ETA: 0s - loss: 0.8834 - accuracy: 0.62 - ETA: 0s - loss: 0.8847 - accuracy: 0.62 - ETA: 0s - loss: 0.8910 - accuracy: 0.61 - ETA: 0s - loss: 0.8847 - accuracy: 0.62 - ETA: 0s - loss: 0.8782 - accuracy: 0.62 - ETA: 0s - loss: 0.8613 - accuracy: 0.64 - ETA: 0s - loss: 0.8715 - accuracy: 0.63 - ETA: 0s - loss: 0.8883 - accuracy: 0.61 - ETA: 0s - loss: 0.8908 - accuracy: 0.61 - ETA: 0s - loss: 0.8963 - accuracy: 0.60 - ETA: 0s - loss: 0.8984 - accuracy: 0.60 - ETA: 0s - loss: 0.8996 - accuracy: 0.6079\n",
      "Epoch 00337: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8996 - accuracy: 0.6079 - val_loss: 1.0384 - val_accuracy: 0.4949 - lr: 0.0010\n",
      "Epoch 338/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9655 - accuracy: 0.54 - ETA: 0s - loss: 0.9394 - accuracy: 0.56 - ETA: 0s - loss: 0.9362 - accuracy: 0.56 - ETA: 0s - loss: 0.9047 - accuracy: 0.59 - ETA: 0s - loss: 0.8980 - accuracy: 0.60 - ETA: 0s - loss: 0.8865 - accuracy: 0.61 - ETA: 0s - loss: 0.8835 - accuracy: 0.61 - ETA: 0s - loss: 0.8838 - accuracy: 0.61 - ETA: 0s - loss: 0.8850 - accuracy: 0.61 - ETA: 0s - loss: 0.8911 - accuracy: 0.61 - ETA: 0s - loss: 0.8839 - accuracy: 0.61 - ETA: 0s - loss: 0.8773 - accuracy: 0.62 - ETA: 0s - loss: 0.8598 - accuracy: 0.64 - ETA: 0s - loss: 0.8700 - accuracy: 0.62 - ETA: 0s - loss: 0.8882 - accuracy: 0.61 - ETA: 0s - loss: 0.8900 - accuracy: 0.61 - ETA: 0s - loss: 0.8951 - accuracy: 0.60 - ETA: 0s - loss: 0.8966 - accuracy: 0.60 - ETA: 0s - loss: 0.8974 - accuracy: 0.6076\n",
      "Epoch 00338: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8974 - accuracy: 0.6076 - val_loss: 1.0392 - val_accuracy: 0.4909 - lr: 0.0010\n",
      "Epoch 339/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9679 - accuracy: 0.55 - ETA: 0s - loss: 0.9410 - accuracy: 0.56 - ETA: 0s - loss: 0.9375 - accuracy: 0.57 - ETA: 0s - loss: 0.9075 - accuracy: 0.59 - ETA: 0s - loss: 0.9004 - accuracy: 0.60 - ETA: 0s - loss: 0.8885 - accuracy: 0.61 - ETA: 0s - loss: 0.8844 - accuracy: 0.62 - ETA: 0s - loss: 0.8849 - accuracy: 0.62 - ETA: 0s - loss: 0.8853 - accuracy: 0.62 - ETA: 0s - loss: 0.8906 - accuracy: 0.61 - ETA: 0s - loss: 0.8836 - accuracy: 0.62 - ETA: 0s - loss: 0.8779 - accuracy: 0.62 - ETA: 0s - loss: 0.8606 - accuracy: 0.64 - ETA: 0s - loss: 0.8712 - accuracy: 0.63 - ETA: 0s - loss: 0.8899 - accuracy: 0.61 - ETA: 0s - loss: 0.8913 - accuracy: 0.61 - ETA: 0s - loss: 0.8964 - accuracy: 0.61 - ETA: 0s - loss: 0.8990 - accuracy: 0.6105\n",
      "Epoch 00339: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8990 - accuracy: 0.6105 - val_loss: 1.0454 - val_accuracy: 0.4845 - lr: 0.0010\n",
      "Epoch 340/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.9704 - accuracy: 0.54 - ETA: 0s - loss: 0.9404 - accuracy: 0.56 - ETA: 0s - loss: 0.9399 - accuracy: 0.56 - ETA: 0s - loss: 0.9092 - accuracy: 0.59 - ETA: 0s - loss: 0.9016 - accuracy: 0.60 - ETA: 0s - loss: 0.8896 - accuracy: 0.61 - ETA: 0s - loss: 0.8853 - accuracy: 0.61 - ETA: 0s - loss: 0.8844 - accuracy: 0.62 - ETA: 0s - loss: 0.8857 - accuracy: 0.61 - ETA: 0s - loss: 0.8925 - accuracy: 0.61 - ETA: 0s - loss: 0.8855 - accuracy: 0.61 - ETA: 0s - loss: 0.8792 - accuracy: 0.62 - ETA: 0s - loss: 0.8615 - accuracy: 0.64 - ETA: 0s - loss: 0.8719 - accuracy: 0.63 - ETA: 0s - loss: 0.8898 - accuracy: 0.61 - ETA: 0s - loss: 0.8921 - accuracy: 0.61 - ETA: 0s - loss: 0.8978 - accuracy: 0.61 - ETA: 0s - loss: 0.8991 - accuracy: 0.6101\n",
      "Epoch 00340: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9003 - accuracy: 0.6088 - val_loss: 1.0361 - val_accuracy: 0.4878 - lr: 0.0010\n",
      "Epoch 341/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9766 - accuracy: 0.54 - ETA: 0s - loss: 0.9465 - accuracy: 0.55 - ETA: 0s - loss: 0.9451 - accuracy: 0.56 - ETA: 0s - loss: 0.9143 - accuracy: 0.58 - ETA: 0s - loss: 0.9067 - accuracy: 0.59 - ETA: 0s - loss: 0.8949 - accuracy: 0.61 - ETA: 0s - loss: 0.8901 - accuracy: 0.61 - ETA: 0s - loss: 0.8911 - accuracy: 0.61 - ETA: 0s - loss: 0.8913 - accuracy: 0.61 - ETA: 0s - loss: 0.8958 - accuracy: 0.60 - ETA: 0s - loss: 0.8889 - accuracy: 0.61 - ETA: 0s - loss: 0.8822 - accuracy: 0.62 - ETA: 0s - loss: 0.8653 - accuracy: 0.63 - ETA: 0s - loss: 0.8741 - accuracy: 0.62 - ETA: 0s - loss: 0.8919 - accuracy: 0.61 - ETA: 0s - loss: 0.8937 - accuracy: 0.61 - ETA: 0s - loss: 0.8995 - accuracy: 0.60 - ETA: 0s - loss: 0.9004 - accuracy: 0.60 - ETA: 0s - loss: 0.9012 - accuracy: 0.6070\n",
      "Epoch 00341: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9012 - accuracy: 0.6070 - val_loss: 1.0405 - val_accuracy: 0.4822 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 342/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9887 - accuracy: 0.53 - ETA: 0s - loss: 0.9470 - accuracy: 0.55 - ETA: 0s - loss: 0.9465 - accuracy: 0.56 - ETA: 0s - loss: 0.9122 - accuracy: 0.58 - ETA: 0s - loss: 0.9048 - accuracy: 0.59 - ETA: 0s - loss: 0.8914 - accuracy: 0.61 - ETA: 0s - loss: 0.8878 - accuracy: 0.61 - ETA: 0s - loss: 0.8882 - accuracy: 0.61 - ETA: 0s - loss: 0.8874 - accuracy: 0.61 - ETA: 0s - loss: 0.8936 - accuracy: 0.60 - ETA: 0s - loss: 0.8877 - accuracy: 0.61 - ETA: 0s - loss: 0.8808 - accuracy: 0.62 - ETA: 0s - loss: 0.8636 - accuracy: 0.63 - ETA: 0s - loss: 0.8736 - accuracy: 0.62 - ETA: 0s - loss: 0.8916 - accuracy: 0.61 - ETA: 0s - loss: 0.8933 - accuracy: 0.61 - ETA: 0s - loss: 0.8983 - accuracy: 0.60 - ETA: 0s - loss: 0.8991 - accuracy: 0.60 - ETA: 0s - loss: 0.9002 - accuracy: 0.6067\n",
      "Epoch 00342: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.9002 - accuracy: 0.6067 - val_loss: 1.0424 - val_accuracy: 0.4866 - lr: 0.0010\n",
      "Epoch 343/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9616 - accuracy: 0.54 - ETA: 0s - loss: 0.9318 - accuracy: 0.56 - ETA: 0s - loss: 0.9345 - accuracy: 0.56 - ETA: 0s - loss: 0.9046 - accuracy: 0.59 - ETA: 0s - loss: 0.8992 - accuracy: 0.60 - ETA: 0s - loss: 0.8872 - accuracy: 0.61 - ETA: 0s - loss: 0.8838 - accuracy: 0.61 - ETA: 0s - loss: 0.8851 - accuracy: 0.61 - ETA: 0s - loss: 0.8841 - accuracy: 0.61 - ETA: 0s - loss: 0.8891 - accuracy: 0.61 - ETA: 0s - loss: 0.8828 - accuracy: 0.61 - ETA: 0s - loss: 0.8773 - accuracy: 0.62 - ETA: 0s - loss: 0.8603 - accuracy: 0.63 - ETA: 0s - loss: 0.8715 - accuracy: 0.62 - ETA: 0s - loss: 0.8883 - accuracy: 0.61 - ETA: 0s - loss: 0.8906 - accuracy: 0.61 - ETA: 0s - loss: 0.8960 - accuracy: 0.60 - ETA: 0s - loss: 0.8968 - accuracy: 0.60 - ETA: 0s - loss: 0.8977 - accuracy: 0.6061\n",
      "Epoch 00343: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8977 - accuracy: 0.6061 - val_loss: 1.0576 - val_accuracy: 0.4730 - lr: 0.0010\n",
      "Epoch 344/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9642 - accuracy: 0.53 - ETA: 0s - loss: 0.9380 - accuracy: 0.55 - ETA: 0s - loss: 0.9445 - accuracy: 0.56 - ETA: 0s - loss: 0.9104 - accuracy: 0.59 - ETA: 0s - loss: 0.9037 - accuracy: 0.59 - ETA: 0s - loss: 0.8924 - accuracy: 0.60 - ETA: 0s - loss: 0.8879 - accuracy: 0.61 - ETA: 0s - loss: 0.8879 - accuracy: 0.61 - ETA: 0s - loss: 0.8880 - accuracy: 0.61 - ETA: 0s - loss: 0.8934 - accuracy: 0.60 - ETA: 0s - loss: 0.8871 - accuracy: 0.61 - ETA: 0s - loss: 0.8807 - accuracy: 0.62 - ETA: 0s - loss: 0.8632 - accuracy: 0.63 - ETA: 0s - loss: 0.8730 - accuracy: 0.62 - ETA: 0s - loss: 0.8907 - accuracy: 0.61 - ETA: 0s - loss: 0.8927 - accuracy: 0.61 - ETA: 0s - loss: 0.8979 - accuracy: 0.60 - ETA: 0s - loss: 0.8987 - accuracy: 0.60 - ETA: 0s - loss: 0.8999 - accuracy: 0.6077\n",
      "Epoch 00344: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8999 - accuracy: 0.6077 - val_loss: 1.0497 - val_accuracy: 0.4840 - lr: 0.0010\n",
      "Epoch 345/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9524 - accuracy: 0.54 - ETA: 0s - loss: 0.9259 - accuracy: 0.57 - ETA: 0s - loss: 0.9309 - accuracy: 0.57 - ETA: 0s - loss: 0.9004 - accuracy: 0.59 - ETA: 0s - loss: 0.8939 - accuracy: 0.60 - ETA: 0s - loss: 0.8842 - accuracy: 0.61 - ETA: 0s - loss: 0.8802 - accuracy: 0.62 - ETA: 0s - loss: 0.8800 - accuracy: 0.62 - ETA: 0s - loss: 0.8809 - accuracy: 0.62 - ETA: 0s - loss: 0.8862 - accuracy: 0.61 - ETA: 0s - loss: 0.8803 - accuracy: 0.62 - ETA: 0s - loss: 0.8742 - accuracy: 0.62 - ETA: 0s - loss: 0.8578 - accuracy: 0.64 - ETA: 0s - loss: 0.8685 - accuracy: 0.63 - ETA: 0s - loss: 0.8871 - accuracy: 0.61 - ETA: 0s - loss: 0.8899 - accuracy: 0.61 - ETA: 0s - loss: 0.8950 - accuracy: 0.60 - ETA: 0s - loss: 0.8971 - accuracy: 0.60 - ETA: 0s - loss: 0.8981 - accuracy: 0.6084\n",
      "Epoch 00345: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8981 - accuracy: 0.6084 - val_loss: 1.0629 - val_accuracy: 0.4682 - lr: 0.0010\n",
      "Epoch 346/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9697 - accuracy: 0.54 - ETA: 0s - loss: 0.9344 - accuracy: 0.56 - ETA: 0s - loss: 0.9376 - accuracy: 0.56 - ETA: 0s - loss: 0.9063 - accuracy: 0.59 - ETA: 0s - loss: 0.9009 - accuracy: 0.60 - ETA: 0s - loss: 0.8884 - accuracy: 0.61 - ETA: 0s - loss: 0.8848 - accuracy: 0.61 - ETA: 0s - loss: 0.8844 - accuracy: 0.62 - ETA: 0s - loss: 0.8856 - accuracy: 0.61 - ETA: 0s - loss: 0.8912 - accuracy: 0.61 - ETA: 0s - loss: 0.8853 - accuracy: 0.61 - ETA: 0s - loss: 0.8790 - accuracy: 0.62 - ETA: 0s - loss: 0.8621 - accuracy: 0.63 - ETA: 0s - loss: 0.8720 - accuracy: 0.62 - ETA: 0s - loss: 0.8899 - accuracy: 0.61 - ETA: 0s - loss: 0.8920 - accuracy: 0.61 - ETA: 0s - loss: 0.8967 - accuracy: 0.60 - ETA: 0s - loss: 0.8985 - accuracy: 0.60 - ETA: 0s - loss: 0.8998 - accuracy: 0.6063\n",
      "Epoch 00346: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8998 - accuracy: 0.6063 - val_loss: 1.0493 - val_accuracy: 0.4783 - lr: 0.0010\n",
      "Epoch 347/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.9615 - accuracy: 0.54 - ETA: 0s - loss: 0.9327 - accuracy: 0.56 - ETA: 0s - loss: 0.9376 - accuracy: 0.56 - ETA: 0s - loss: 0.9052 - accuracy: 0.59 - ETA: 0s - loss: 0.8973 - accuracy: 0.60 - ETA: 0s - loss: 0.8851 - accuracy: 0.61 - ETA: 0s - loss: 0.8814 - accuracy: 0.61 - ETA: 0s - loss: 0.8815 - accuracy: 0.62 - ETA: 0s - loss: 0.8822 - accuracy: 0.61 - ETA: 0s - loss: 0.8878 - accuracy: 0.61 - ETA: 0s - loss: 0.8814 - accuracy: 0.61 - ETA: 0s - loss: 0.8760 - accuracy: 0.62 - ETA: 0s - loss: 0.8590 - accuracy: 0.64 - ETA: 0s - loss: 0.8680 - accuracy: 0.63 - ETA: 0s - loss: 0.8859 - accuracy: 0.61 - ETA: 0s - loss: 0.8883 - accuracy: 0.61 - ETA: 0s - loss: 0.8938 - accuracy: 0.60 - ETA: 0s - loss: 0.8957 - accuracy: 0.6093\n",
      "Epoch 00347: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00347: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8969 - accuracy: 0.6076 - val_loss: 1.0419 - val_accuracy: 0.4883 - lr: 0.0010\n",
      "Epoch 348/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.9650 - accuracy: 0.54 - ETA: 0s - loss: 0.9360 - accuracy: 0.56 - ETA: 0s - loss: 0.9369 - accuracy: 0.56 - ETA: 0s - loss: 0.9053 - accuracy: 0.59 - ETA: 0s - loss: 0.8997 - accuracy: 0.59 - ETA: 0s - loss: 0.8876 - accuracy: 0.61 - ETA: 0s - loss: 0.8845 - accuracy: 0.61 - ETA: 0s - loss: 0.8870 - accuracy: 0.61 - ETA: 0s - loss: 0.8879 - accuracy: 0.61 - ETA: 0s - loss: 0.8930 - accuracy: 0.60 - ETA: 0s - loss: 0.8865 - accuracy: 0.61 - ETA: 0s - loss: 0.8804 - accuracy: 0.62 - ETA: 0s - loss: 0.8630 - accuracy: 0.63 - ETA: 0s - loss: 0.8728 - accuracy: 0.62 - ETA: 0s - loss: 0.8900 - accuracy: 0.61 - ETA: 0s - loss: 0.8915 - accuracy: 0.61 - ETA: 0s - loss: 0.8968 - accuracy: 0.60 - ETA: 0s - loss: 0.8981 - accuracy: 0.6073\n",
      "Epoch 00348: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8996 - accuracy: 0.6060 - val_loss: 1.0427 - val_accuracy: 0.4822 - lr: 0.0010\n",
      "Epoch 349/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9668 - accuracy: 0.54 - ETA: 0s - loss: 0.9363 - accuracy: 0.56 - ETA: 0s - loss: 0.9370 - accuracy: 0.56 - ETA: 0s - loss: 0.9041 - accuracy: 0.59 - ETA: 0s - loss: 0.8958 - accuracy: 0.60 - ETA: 0s - loss: 0.8846 - accuracy: 0.61 - ETA: 0s - loss: 0.8816 - accuracy: 0.62 - ETA: 0s - loss: 0.8815 - accuracy: 0.62 - ETA: 0s - loss: 0.8828 - accuracy: 0.61 - ETA: 0s - loss: 0.8885 - accuracy: 0.61 - ETA: 0s - loss: 0.8826 - accuracy: 0.61 - ETA: 0s - loss: 0.8757 - accuracy: 0.62 - ETA: 0s - loss: 0.8587 - accuracy: 0.64 - ETA: 0s - loss: 0.8683 - accuracy: 0.62 - ETA: 0s - loss: 0.8880 - accuracy: 0.61 - ETA: 0s - loss: 0.8901 - accuracy: 0.61 - ETA: 0s - loss: 0.8963 - accuracy: 0.60 - ETA: 0s - loss: 0.8975 - accuracy: 0.60 - ETA: 0s - loss: 0.8984 - accuracy: 0.6067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00349: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8984 - accuracy: 0.6067 - val_loss: 1.0430 - val_accuracy: 0.4806 - lr: 0.0010\n",
      "Epoch 350/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9676 - accuracy: 0.54 - ETA: 0s - loss: 0.9365 - accuracy: 0.56 - ETA: 0s - loss: 0.9386 - accuracy: 0.56 - ETA: 0s - loss: 0.9074 - accuracy: 0.59 - ETA: 0s - loss: 0.8991 - accuracy: 0.59 - ETA: 0s - loss: 0.8879 - accuracy: 0.61 - ETA: 0s - loss: 0.8846 - accuracy: 0.61 - ETA: 0s - loss: 0.8836 - accuracy: 0.62 - ETA: 0s - loss: 0.8842 - accuracy: 0.61 - ETA: 0s - loss: 0.8900 - accuracy: 0.61 - ETA: 0s - loss: 0.8837 - accuracy: 0.62 - ETA: 0s - loss: 0.8775 - accuracy: 0.62 - ETA: 0s - loss: 0.8606 - accuracy: 0.64 - ETA: 0s - loss: 0.8709 - accuracy: 0.63 - ETA: 0s - loss: 0.8884 - accuracy: 0.61 - ETA: 0s - loss: 0.8901 - accuracy: 0.61 - ETA: 0s - loss: 0.8956 - accuracy: 0.61 - ETA: 0s - loss: 0.8966 - accuracy: 0.61 - ETA: 0s - loss: 0.8980 - accuracy: 0.6098\n",
      "Epoch 00350: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8980 - accuracy: 0.6098 - val_loss: 1.0359 - val_accuracy: 0.4834 - lr: 0.0010\n",
      "Epoch 351/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9616 - accuracy: 0.55 - ETA: 0s - loss: 0.9328 - accuracy: 0.56 - ETA: 0s - loss: 0.9380 - accuracy: 0.57 - ETA: 0s - loss: 0.9045 - accuracy: 0.59 - ETA: 0s - loss: 0.8965 - accuracy: 0.60 - ETA: 0s - loss: 0.8848 - accuracy: 0.61 - ETA: 0s - loss: 0.8826 - accuracy: 0.62 - ETA: 0s - loss: 0.8818 - accuracy: 0.62 - ETA: 0s - loss: 0.8828 - accuracy: 0.62 - ETA: 0s - loss: 0.8886 - accuracy: 0.61 - ETA: 0s - loss: 0.8820 - accuracy: 0.62 - ETA: 0s - loss: 0.8757 - accuracy: 0.62 - ETA: 0s - loss: 0.8590 - accuracy: 0.64 - ETA: 0s - loss: 0.8692 - accuracy: 0.63 - ETA: 0s - loss: 0.8869 - accuracy: 0.61 - ETA: 0s - loss: 0.8889 - accuracy: 0.61 - ETA: 0s - loss: 0.8944 - accuracy: 0.61 - ETA: 0s - loss: 0.8961 - accuracy: 0.61 - ETA: 0s - loss: 0.8978 - accuracy: 0.6087\n",
      "Epoch 00351: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8978 - accuracy: 0.6087 - val_loss: 1.0464 - val_accuracy: 0.4713 - lr: 0.0010\n",
      "Epoch 352/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9716 - accuracy: 0.55 - ETA: 0s - loss: 0.9425 - accuracy: 0.56 - ETA: 0s - loss: 0.9424 - accuracy: 0.56 - ETA: 0s - loss: 0.9100 - accuracy: 0.59 - ETA: 0s - loss: 0.8996 - accuracy: 0.60 - ETA: 0s - loss: 0.8871 - accuracy: 0.61 - ETA: 0s - loss: 0.8844 - accuracy: 0.61 - ETA: 0s - loss: 0.8838 - accuracy: 0.62 - ETA: 0s - loss: 0.8851 - accuracy: 0.61 - ETA: 0s - loss: 0.8909 - accuracy: 0.61 - ETA: 0s - loss: 0.8848 - accuracy: 0.61 - ETA: 0s - loss: 0.8780 - accuracy: 0.62 - ETA: 0s - loss: 0.8603 - accuracy: 0.64 - ETA: 0s - loss: 0.8695 - accuracy: 0.63 - ETA: 0s - loss: 0.8868 - accuracy: 0.61 - ETA: 0s - loss: 0.8887 - accuracy: 0.61 - ETA: 0s - loss: 0.8935 - accuracy: 0.61 - ETA: 0s - loss: 0.8951 - accuracy: 0.61 - ETA: 0s - loss: 0.8966 - accuracy: 0.6099\n",
      "Epoch 00352: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8966 - accuracy: 0.6099 - val_loss: 1.0510 - val_accuracy: 0.4686 - lr: 0.0010\n",
      "Epoch 353/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9569 - accuracy: 0.53 - ETA: 0s - loss: 0.9324 - accuracy: 0.55 - ETA: 0s - loss: 0.9326 - accuracy: 0.56 - ETA: 0s - loss: 0.9006 - accuracy: 0.59 - ETA: 0s - loss: 0.8940 - accuracy: 0.59 - ETA: 0s - loss: 0.8839 - accuracy: 0.61 - ETA: 0s - loss: 0.8813 - accuracy: 0.61 - ETA: 0s - loss: 0.8821 - accuracy: 0.61 - ETA: 0s - loss: 0.8835 - accuracy: 0.61 - ETA: 0s - loss: 0.8879 - accuracy: 0.60 - ETA: 0s - loss: 0.8827 - accuracy: 0.61 - ETA: 0s - loss: 0.8776 - accuracy: 0.62 - ETA: 0s - loss: 0.8603 - accuracy: 0.63 - ETA: 0s - loss: 0.8694 - accuracy: 0.62 - ETA: 0s - loss: 0.8883 - accuracy: 0.61 - ETA: 0s - loss: 0.8903 - accuracy: 0.61 - ETA: 0s - loss: 0.8962 - accuracy: 0.60 - ETA: 0s - loss: 0.8976 - accuracy: 0.60 - ETA: 0s - loss: 0.8988 - accuracy: 0.6065\n",
      "Epoch 00353: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8988 - accuracy: 0.6065 - val_loss: 1.0351 - val_accuracy: 0.4858 - lr: 0.0010\n",
      "Epoch 354/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9640 - accuracy: 0.54 - ETA: 0s - loss: 0.9389 - accuracy: 0.56 - ETA: 0s - loss: 0.9384 - accuracy: 0.56 - ETA: 0s - loss: 0.9043 - accuracy: 0.59 - ETA: 0s - loss: 0.8971 - accuracy: 0.60 - ETA: 0s - loss: 0.8862 - accuracy: 0.61 - ETA: 0s - loss: 0.8830 - accuracy: 0.62 - ETA: 0s - loss: 0.8824 - accuracy: 0.62 - ETA: 0s - loss: 0.8827 - accuracy: 0.62 - ETA: 0s - loss: 0.8886 - accuracy: 0.61 - ETA: 0s - loss: 0.8818 - accuracy: 0.62 - ETA: 0s - loss: 0.8759 - accuracy: 0.62 - ETA: 0s - loss: 0.8582 - accuracy: 0.64 - ETA: 0s - loss: 0.8687 - accuracy: 0.63 - ETA: 0s - loss: 0.8869 - accuracy: 0.61 - ETA: 0s - loss: 0.8889 - accuracy: 0.61 - ETA: 0s - loss: 0.8949 - accuracy: 0.60 - ETA: 0s - loss: 0.8966 - accuracy: 0.60 - ETA: 0s - loss: 0.8980 - accuracy: 0.6090\n",
      "Epoch 00354: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8980 - accuracy: 0.6090 - val_loss: 1.0354 - val_accuracy: 0.4858 - lr: 0.0010\n",
      "Epoch 355/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9627 - accuracy: 0.55 - ETA: 0s - loss: 0.9377 - accuracy: 0.56 - ETA: 0s - loss: 0.9365 - accuracy: 0.57 - ETA: 0s - loss: 0.9029 - accuracy: 0.59 - ETA: 0s - loss: 0.8953 - accuracy: 0.60 - ETA: 0s - loss: 0.8832 - accuracy: 0.61 - ETA: 0s - loss: 0.8812 - accuracy: 0.62 - ETA: 0s - loss: 0.8802 - accuracy: 0.62 - ETA: 0s - loss: 0.8822 - accuracy: 0.62 - ETA: 0s - loss: 0.8887 - accuracy: 0.61 - ETA: 0s - loss: 0.8822 - accuracy: 0.62 - ETA: 0s - loss: 0.8766 - accuracy: 0.62 - ETA: 0s - loss: 0.8593 - accuracy: 0.64 - ETA: 0s - loss: 0.8687 - accuracy: 0.63 - ETA: 0s - loss: 0.8862 - accuracy: 0.61 - ETA: 0s - loss: 0.8884 - accuracy: 0.61 - ETA: 0s - loss: 0.8934 - accuracy: 0.61 - ETA: 0s - loss: 0.8945 - accuracy: 0.61 - ETA: 0s - loss: 0.8963 - accuracy: 0.6094\n",
      "Epoch 00355: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8963 - accuracy: 0.6094 - val_loss: 1.0388 - val_accuracy: 0.4834 - lr: 0.0010\n",
      "Epoch 356/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9748 - accuracy: 0.53 - ETA: 0s - loss: 0.9367 - accuracy: 0.56 - ETA: 0s - loss: 0.9394 - accuracy: 0.56 - ETA: 0s - loss: 0.9069 - accuracy: 0.59 - ETA: 0s - loss: 0.8991 - accuracy: 0.59 - ETA: 0s - loss: 0.8864 - accuracy: 0.61 - ETA: 0s - loss: 0.8826 - accuracy: 0.61 - ETA: 0s - loss: 0.8820 - accuracy: 0.61 - ETA: 0s - loss: 0.8825 - accuracy: 0.61 - ETA: 0s - loss: 0.8884 - accuracy: 0.60 - ETA: 0s - loss: 0.8835 - accuracy: 0.61 - ETA: 0s - loss: 0.8759 - accuracy: 0.62 - ETA: 0s - loss: 0.8589 - accuracy: 0.63 - ETA: 0s - loss: 0.8689 - accuracy: 0.62 - ETA: 0s - loss: 0.8852 - accuracy: 0.61 - ETA: 0s - loss: 0.8880 - accuracy: 0.61 - ETA: 0s - loss: 0.8935 - accuracy: 0.60 - ETA: 0s - loss: 0.8950 - accuracy: 0.60 - ETA: 0s - loss: 0.8962 - accuracy: 0.6060\n",
      "Epoch 00356: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8962 - accuracy: 0.6060 - val_loss: 1.0452 - val_accuracy: 0.4813 - lr: 0.0010\n",
      "Epoch 357/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9704 - accuracy: 0.54 - ETA: 0s - loss: 0.9418 - accuracy: 0.56 - ETA: 0s - loss: 0.9430 - accuracy: 0.56 - ETA: 0s - loss: 0.9103 - accuracy: 0.59 - ETA: 0s - loss: 0.9029 - accuracy: 0.60 - ETA: 0s - loss: 0.8907 - accuracy: 0.61 - ETA: 0s - loss: 0.8852 - accuracy: 0.61 - ETA: 0s - loss: 0.8842 - accuracy: 0.62 - ETA: 0s - loss: 0.8841 - accuracy: 0.61 - ETA: 0s - loss: 0.8906 - accuracy: 0.61 - ETA: 0s - loss: 0.8841 - accuracy: 0.62 - ETA: 0s - loss: 0.8772 - accuracy: 0.62 - ETA: 0s - loss: 0.8598 - accuracy: 0.64 - ETA: 0s - loss: 0.8692 - accuracy: 0.62 - ETA: 0s - loss: 0.8866 - accuracy: 0.61 - ETA: 0s - loss: 0.8888 - accuracy: 0.61 - ETA: 0s - loss: 0.8948 - accuracy: 0.60 - ETA: 0s - loss: 0.8961 - accuracy: 0.61 - ETA: 0s - loss: 0.8975 - accuracy: 0.6084\n",
      "Epoch 00357: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8975 - accuracy: 0.6084 - val_loss: 1.0444 - val_accuracy: 0.4837 - lr: 0.0010\n",
      "Epoch 358/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9661 - accuracy: 0.54 - ETA: 0s - loss: 0.9403 - accuracy: 0.56 - ETA: 0s - loss: 0.9446 - accuracy: 0.56 - ETA: 0s - loss: 0.9129 - accuracy: 0.59 - ETA: 0s - loss: 0.9054 - accuracy: 0.59 - ETA: 0s - loss: 0.8941 - accuracy: 0.61 - ETA: 0s - loss: 0.8892 - accuracy: 0.61 - ETA: 0s - loss: 0.8881 - accuracy: 0.61 - ETA: 0s - loss: 0.8883 - accuracy: 0.61 - ETA: 0s - loss: 0.8937 - accuracy: 0.61 - ETA: 0s - loss: 0.8861 - accuracy: 0.61 - ETA: 0s - loss: 0.8791 - accuracy: 0.62 - ETA: 0s - loss: 0.8618 - accuracy: 0.64 - ETA: 0s - loss: 0.8709 - accuracy: 0.62 - ETA: 0s - loss: 0.8896 - accuracy: 0.61 - ETA: 0s - loss: 0.8919 - accuracy: 0.61 - ETA: 0s - loss: 0.8969 - accuracy: 0.60 - ETA: 0s - loss: 0.8983 - accuracy: 0.60 - ETA: 0s - loss: 0.8990 - accuracy: 0.6081\n",
      "Epoch 00358: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8990 - accuracy: 0.6081 - val_loss: 1.0403 - val_accuracy: 0.4865 - lr: 0.0010\n",
      "Epoch 359/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9680 - accuracy: 0.54 - ETA: 0s - loss: 0.9391 - accuracy: 0.56 - ETA: 0s - loss: 0.9405 - accuracy: 0.56 - ETA: 0s - loss: 0.9066 - accuracy: 0.59 - ETA: 0s - loss: 0.8964 - accuracy: 0.60 - ETA: 0s - loss: 0.8849 - accuracy: 0.61 - ETA: 0s - loss: 0.8817 - accuracy: 0.62 - ETA: 0s - loss: 0.8823 - accuracy: 0.62 - ETA: 0s - loss: 0.8825 - accuracy: 0.61 - ETA: 0s - loss: 0.8877 - accuracy: 0.61 - ETA: 0s - loss: 0.8815 - accuracy: 0.62 - ETA: 0s - loss: 0.8750 - accuracy: 0.62 - ETA: 0s - loss: 0.8575 - accuracy: 0.64 - ETA: 0s - loss: 0.8669 - accuracy: 0.63 - ETA: 0s - loss: 0.8833 - accuracy: 0.61 - ETA: 0s - loss: 0.8856 - accuracy: 0.61 - ETA: 0s - loss: 0.8909 - accuracy: 0.61 - ETA: 0s - loss: 0.8928 - accuracy: 0.61 - ETA: 0s - loss: 0.8946 - accuracy: 0.6090\n",
      "Epoch 00359: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8946 - accuracy: 0.6090 - val_loss: 1.0360 - val_accuracy: 0.4876 - lr: 0.0010\n",
      "Epoch 360/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9617 - accuracy: 0.54 - ETA: 0s - loss: 0.9337 - accuracy: 0.56 - ETA: 0s - loss: 0.9359 - accuracy: 0.56 - ETA: 0s - loss: 0.9043 - accuracy: 0.59 - ETA: 0s - loss: 0.8992 - accuracy: 0.59 - ETA: 0s - loss: 0.8874 - accuracy: 0.61 - ETA: 0s - loss: 0.8853 - accuracy: 0.61 - ETA: 0s - loss: 0.8849 - accuracy: 0.61 - ETA: 0s - loss: 0.8857 - accuracy: 0.61 - ETA: 0s - loss: 0.8904 - accuracy: 0.61 - ETA: 0s - loss: 0.8845 - accuracy: 0.61 - ETA: 0s - loss: 0.8778 - accuracy: 0.62 - ETA: 0s - loss: 0.8603 - accuracy: 0.63 - ETA: 0s - loss: 0.8697 - accuracy: 0.62 - ETA: 0s - loss: 0.8875 - accuracy: 0.61 - ETA: 0s - loss: 0.8896 - accuracy: 0.61 - ETA: 0s - loss: 0.8947 - accuracy: 0.60 - ETA: 0s - loss: 0.8964 - accuracy: 0.60 - ETA: 0s - loss: 0.8981 - accuracy: 0.6067\n",
      "Epoch 00360: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8981 - accuracy: 0.6067 - val_loss: 1.0375 - val_accuracy: 0.4818 - lr: 0.0010\n",
      "Epoch 361/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9543 - accuracy: 0.55 - ETA: 0s - loss: 0.9300 - accuracy: 0.56 - ETA: 0s - loss: 0.8982 - accuracy: 0.59 - ETA: 0s - loss: 0.8927 - accuracy: 0.60 - ETA: 0s - loss: 0.8818 - accuracy: 0.61 - ETA: 0s - loss: 0.8784 - accuracy: 0.61 - ETA: 0s - loss: 0.8797 - accuracy: 0.62 - ETA: 0s - loss: 0.8801 - accuracy: 0.61 - ETA: 0s - loss: 0.8873 - accuracy: 0.60 - ETA: 0s - loss: 0.8813 - accuracy: 0.61 - ETA: 0s - loss: 0.8749 - accuracy: 0.62 - ETA: 0s - loss: 0.8577 - accuracy: 0.63 - ETA: 0s - loss: 0.8678 - accuracy: 0.62 - ETA: 0s - loss: 0.8837 - accuracy: 0.61 - ETA: 0s - loss: 0.8863 - accuracy: 0.61 - ETA: 0s - loss: 0.8918 - accuracy: 0.61 - ETA: 0s - loss: 0.8936 - accuracy: 0.61 - ETA: 0s - loss: 0.8945 - accuracy: 0.6091\n",
      "Epoch 00361: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00361: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8945 - accuracy: 0.6091 - val_loss: 1.0472 - val_accuracy: 0.4770 - lr: 0.0010\n",
      "Epoch 362/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9629 - accuracy: 0.55 - ETA: 0s - loss: 0.9388 - accuracy: 0.56 - ETA: 0s - loss: 0.9407 - accuracy: 0.56 - ETA: 0s - loss: 0.9084 - accuracy: 0.59 - ETA: 0s - loss: 0.9001 - accuracy: 0.59 - ETA: 0s - loss: 0.8873 - accuracy: 0.61 - ETA: 0s - loss: 0.8841 - accuracy: 0.61 - ETA: 0s - loss: 0.8844 - accuracy: 0.61 - ETA: 0s - loss: 0.8851 - accuracy: 0.61 - ETA: 0s - loss: 0.8919 - accuracy: 0.60 - ETA: 0s - loss: 0.8852 - accuracy: 0.61 - ETA: 0s - loss: 0.8789 - accuracy: 0.62 - ETA: 0s - loss: 0.8608 - accuracy: 0.63 - ETA: 0s - loss: 0.8703 - accuracy: 0.62 - ETA: 0s - loss: 0.8872 - accuracy: 0.61 - ETA: 0s - loss: 0.8897 - accuracy: 0.61 - ETA: 0s - loss: 0.8941 - accuracy: 0.60 - ETA: 0s - loss: 0.8953 - accuracy: 0.60 - ETA: 0s - loss: 0.8960 - accuracy: 0.6077\n",
      "Epoch 00362: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8960 - accuracy: 0.6077 - val_loss: 1.0489 - val_accuracy: 0.4749 - lr: 0.0010\n",
      "Epoch 363/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9686 - accuracy: 0.54 - ETA: 0s - loss: 0.9412 - accuracy: 0.56 - ETA: 0s - loss: 0.9348 - accuracy: 0.56 - ETA: 0s - loss: 0.9045 - accuracy: 0.59 - ETA: 0s - loss: 0.8980 - accuracy: 0.60 - ETA: 0s - loss: 0.8851 - accuracy: 0.61 - ETA: 0s - loss: 0.8815 - accuracy: 0.61 - ETA: 0s - loss: 0.8803 - accuracy: 0.62 - ETA: 0s - loss: 0.8828 - accuracy: 0.61 - ETA: 0s - loss: 0.8882 - accuracy: 0.61 - ETA: 0s - loss: 0.8824 - accuracy: 0.61 - ETA: 0s - loss: 0.8763 - accuracy: 0.62 - ETA: 0s - loss: 0.8585 - accuracy: 0.64 - ETA: 0s - loss: 0.8674 - accuracy: 0.63 - ETA: 0s - loss: 0.8859 - accuracy: 0.61 - ETA: 0s - loss: 0.8879 - accuracy: 0.61 - ETA: 0s - loss: 0.8934 - accuracy: 0.61 - ETA: 0s - loss: 0.8949 - accuracy: 0.61 - ETA: 0s - loss: 0.8962 - accuracy: 0.6089\n",
      "Epoch 00363: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8962 - accuracy: 0.6089 - val_loss: 1.0346 - val_accuracy: 0.4822 - lr: 0.0010\n",
      "Epoch 364/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9629 - accuracy: 0.53 - ETA: 0s - loss: 0.9343 - accuracy: 0.56 - ETA: 0s - loss: 0.9390 - accuracy: 0.56 - ETA: 0s - loss: 0.9069 - accuracy: 0.59 - ETA: 0s - loss: 0.9002 - accuracy: 0.59 - ETA: 0s - loss: 0.8882 - accuracy: 0.61 - ETA: 0s - loss: 0.8851 - accuracy: 0.61 - ETA: 0s - loss: 0.8852 - accuracy: 0.62 - ETA: 0s - loss: 0.8859 - accuracy: 0.61 - ETA: 0s - loss: 0.8914 - accuracy: 0.61 - ETA: 0s - loss: 0.8854 - accuracy: 0.61 - ETA: 0s - loss: 0.8796 - accuracy: 0.62 - ETA: 0s - loss: 0.8621 - accuracy: 0.63 - ETA: 0s - loss: 0.8709 - accuracy: 0.62 - ETA: 0s - loss: 0.8884 - accuracy: 0.61 - ETA: 0s - loss: 0.8901 - accuracy: 0.61 - ETA: 0s - loss: 0.8952 - accuracy: 0.60 - ETA: 0s - loss: 0.8967 - accuracy: 0.60 - ETA: 0s - loss: 0.8981 - accuracy: 0.6072\n",
      "Epoch 00364: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8981 - accuracy: 0.6072 - val_loss: 1.0403 - val_accuracy: 0.4754 - lr: 0.0010\n",
      "Epoch 365/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9515 - accuracy: 0.54 - ETA: 0s - loss: 0.9315 - accuracy: 0.56 - ETA: 0s - loss: 0.9340 - accuracy: 0.56 - ETA: 0s - loss: 0.9037 - accuracy: 0.59 - ETA: 0s - loss: 0.8945 - accuracy: 0.60 - ETA: 0s - loss: 0.8840 - accuracy: 0.61 - ETA: 0s - loss: 0.8819 - accuracy: 0.61 - ETA: 0s - loss: 0.8814 - accuracy: 0.61 - ETA: 0s - loss: 0.8837 - accuracy: 0.61 - ETA: 0s - loss: 0.8893 - accuracy: 0.60 - ETA: 0s - loss: 0.8824 - accuracy: 0.61 - ETA: 0s - loss: 0.8756 - accuracy: 0.62 - ETA: 0s - loss: 0.8586 - accuracy: 0.63 - ETA: 0s - loss: 0.8676 - accuracy: 0.62 - ETA: 0s - loss: 0.8853 - accuracy: 0.61 - ETA: 0s - loss: 0.8876 - accuracy: 0.61 - ETA: 0s - loss: 0.8928 - accuracy: 0.60 - ETA: 0s - loss: 0.8941 - accuracy: 0.60 - ETA: 0s - loss: 0.8949 - accuracy: 0.6083\n",
      "Epoch 00365: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8949 - accuracy: 0.6083 - val_loss: 1.0463 - val_accuracy: 0.4775 - lr: 0.0010\n",
      "Epoch 366/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9702 - accuracy: 0.53 - ETA: 0s - loss: 0.9414 - accuracy: 0.55 - ETA: 0s - loss: 0.9403 - accuracy: 0.55 - ETA: 0s - loss: 0.9044 - accuracy: 0.58 - ETA: 0s - loss: 0.8991 - accuracy: 0.59 - ETA: 0s - loss: 0.8870 - accuracy: 0.60 - ETA: 0s - loss: 0.8833 - accuracy: 0.61 - ETA: 0s - loss: 0.8831 - accuracy: 0.61 - ETA: 0s - loss: 0.8837 - accuracy: 0.61 - ETA: 0s - loss: 0.8899 - accuracy: 0.60 - ETA: 0s - loss: 0.8837 - accuracy: 0.61 - ETA: 0s - loss: 0.8773 - accuracy: 0.62 - ETA: 0s - loss: 0.8594 - accuracy: 0.63 - ETA: 0s - loss: 0.8682 - accuracy: 0.62 - ETA: 0s - loss: 0.8858 - accuracy: 0.61 - ETA: 0s - loss: 0.8885 - accuracy: 0.61 - ETA: 0s - loss: 0.8937 - accuracy: 0.60 - ETA: 0s - loss: 0.8951 - accuracy: 0.60 - ETA: 0s - loss: 0.8968 - accuracy: 0.6071\n",
      "Epoch 00366: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8968 - accuracy: 0.6071 - val_loss: 1.0426 - val_accuracy: 0.4801 - lr: 0.0010\n",
      "Epoch 367/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9642 - accuracy: 0.55 - ETA: 0s - loss: 0.9359 - accuracy: 0.56 - ETA: 0s - loss: 0.9384 - accuracy: 0.56 - ETA: 0s - loss: 0.9090 - accuracy: 0.59 - ETA: 0s - loss: 0.9009 - accuracy: 0.59 - ETA: 0s - loss: 0.8888 - accuracy: 0.61 - ETA: 0s - loss: 0.8852 - accuracy: 0.61 - ETA: 0s - loss: 0.8840 - accuracy: 0.62 - ETA: 0s - loss: 0.8844 - accuracy: 0.61 - ETA: 0s - loss: 0.8889 - accuracy: 0.61 - ETA: 0s - loss: 0.8826 - accuracy: 0.62 - ETA: 0s - loss: 0.8759 - accuracy: 0.62 - ETA: 0s - loss: 0.8588 - accuracy: 0.64 - ETA: 0s - loss: 0.8689 - accuracy: 0.63 - ETA: 0s - loss: 0.8869 - accuracy: 0.61 - ETA: 0s - loss: 0.8884 - accuracy: 0.61 - ETA: 0s - loss: 0.8938 - accuracy: 0.61 - ETA: 0s - loss: 0.8948 - accuracy: 0.61 - ETA: 0s - loss: 0.8962 - accuracy: 0.6100\n",
      "Epoch 00367: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8962 - accuracy: 0.6100 - val_loss: 1.0357 - val_accuracy: 0.4868 - lr: 0.0010\n",
      "Epoch 368/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9692 - accuracy: 0.53 - ETA: 0s - loss: 0.9369 - accuracy: 0.56 - ETA: 0s - loss: 0.9358 - accuracy: 0.56 - ETA: 0s - loss: 0.9022 - accuracy: 0.59 - ETA: 0s - loss: 0.8963 - accuracy: 0.60 - ETA: 0s - loss: 0.8834 - accuracy: 0.61 - ETA: 0s - loss: 0.8792 - accuracy: 0.61 - ETA: 0s - loss: 0.8786 - accuracy: 0.62 - ETA: 0s - loss: 0.8800 - accuracy: 0.61 - ETA: 0s - loss: 0.8857 - accuracy: 0.61 - ETA: 0s - loss: 0.8794 - accuracy: 0.62 - ETA: 0s - loss: 0.8736 - accuracy: 0.62 - ETA: 0s - loss: 0.8561 - accuracy: 0.64 - ETA: 0s - loss: 0.8656 - accuracy: 0.63 - ETA: 0s - loss: 0.8828 - accuracy: 0.61 - ETA: 0s - loss: 0.8859 - accuracy: 0.61 - ETA: 0s - loss: 0.8911 - accuracy: 0.60 - ETA: 0s - loss: 0.8927 - accuracy: 0.60 - ETA: 0s - loss: 0.8940 - accuracy: 0.6084\n",
      "Epoch 00368: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8940 - accuracy: 0.6084 - val_loss: 1.0332 - val_accuracy: 0.4917 - lr: 0.0010\n",
      "Epoch 369/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9480 - accuracy: 0.54 - ETA: 0s - loss: 0.9286 - accuracy: 0.55 - ETA: 0s - loss: 0.9345 - accuracy: 0.56 - ETA: 0s - loss: 0.9016 - accuracy: 0.59 - ETA: 0s - loss: 0.8955 - accuracy: 0.59 - ETA: 0s - loss: 0.8839 - accuracy: 0.61 - ETA: 0s - loss: 0.8799 - accuracy: 0.61 - ETA: 0s - loss: 0.8815 - accuracy: 0.61 - ETA: 0s - loss: 0.8813 - accuracy: 0.61 - ETA: 0s - loss: 0.8870 - accuracy: 0.61 - ETA: 0s - loss: 0.8808 - accuracy: 0.61 - ETA: 0s - loss: 0.8751 - accuracy: 0.62 - ETA: 0s - loss: 0.8576 - accuracy: 0.64 - ETA: 0s - loss: 0.8671 - accuracy: 0.63 - ETA: 0s - loss: 0.8837 - accuracy: 0.61 - ETA: 0s - loss: 0.8856 - accuracy: 0.61 - ETA: 0s - loss: 0.8917 - accuracy: 0.61 - ETA: 0s - loss: 0.8931 - accuracy: 0.61 - ETA: 0s - loss: 0.8941 - accuracy: 0.6105\n",
      "Epoch 00369: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8941 - accuracy: 0.6105 - val_loss: 1.0379 - val_accuracy: 0.4852 - lr: 0.0010\n",
      "Epoch 370/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9673 - accuracy: 0.52 - ETA: 0s - loss: 0.9388 - accuracy: 0.55 - ETA: 0s - loss: 0.9381 - accuracy: 0.56 - ETA: 0s - loss: 0.9042 - accuracy: 0.59 - ETA: 0s - loss: 0.8989 - accuracy: 0.59 - ETA: 0s - loss: 0.8866 - accuracy: 0.61 - ETA: 0s - loss: 0.8830 - accuracy: 0.61 - ETA: 0s - loss: 0.8838 - accuracy: 0.61 - ETA: 0s - loss: 0.8845 - accuracy: 0.61 - ETA: 0s - loss: 0.8908 - accuracy: 0.60 - ETA: 0s - loss: 0.8853 - accuracy: 0.61 - ETA: 0s - loss: 0.8789 - accuracy: 0.62 - ETA: 0s - loss: 0.8622 - accuracy: 0.63 - ETA: 0s - loss: 0.8716 - accuracy: 0.62 - ETA: 0s - loss: 0.8887 - accuracy: 0.61 - ETA: 0s - loss: 0.8902 - accuracy: 0.61 - ETA: 0s - loss: 0.8956 - accuracy: 0.60 - ETA: 0s - loss: 0.8971 - accuracy: 0.60 - ETA: 0s - loss: 0.8981 - accuracy: 0.6066\n",
      "Epoch 00370: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8981 - accuracy: 0.6066 - val_loss: 1.0369 - val_accuracy: 0.4865 - lr: 0.0010\n",
      "Epoch 371/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9524 - accuracy: 0.54 - ETA: 0s - loss: 0.9329 - accuracy: 0.56 - ETA: 0s - loss: 0.9357 - accuracy: 0.56 - ETA: 0s - loss: 0.9038 - accuracy: 0.59 - ETA: 0s - loss: 0.8972 - accuracy: 0.60 - ETA: 0s - loss: 0.8843 - accuracy: 0.61 - ETA: 0s - loss: 0.8813 - accuracy: 0.62 - ETA: 0s - loss: 0.8815 - accuracy: 0.62 - ETA: 0s - loss: 0.8813 - accuracy: 0.61 - ETA: 0s - loss: 0.8862 - accuracy: 0.61 - ETA: 0s - loss: 0.8804 - accuracy: 0.62 - ETA: 0s - loss: 0.8736 - accuracy: 0.62 - ETA: 0s - loss: 0.8563 - accuracy: 0.64 - ETA: 0s - loss: 0.8666 - accuracy: 0.63 - ETA: 0s - loss: 0.8841 - accuracy: 0.61 - ETA: 0s - loss: 0.8864 - accuracy: 0.61 - ETA: 0s - loss: 0.8918 - accuracy: 0.60 - ETA: 0s - loss: 0.8932 - accuracy: 0.60 - ETA: 0s - loss: 0.8943 - accuracy: 0.6072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00371: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8943 - accuracy: 0.6072 - val_loss: 1.0291 - val_accuracy: 0.4935 - lr: 0.0010\n",
      "Epoch 372/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9449 - accuracy: 0.55 - ETA: 0s - loss: 0.9361 - accuracy: 0.56 - ETA: 0s - loss: 0.9372 - accuracy: 0.56 - ETA: 0s - loss: 0.9062 - accuracy: 0.59 - ETA: 0s - loss: 0.9005 - accuracy: 0.59 - ETA: 0s - loss: 0.8891 - accuracy: 0.61 - ETA: 0s - loss: 0.8852 - accuracy: 0.61 - ETA: 0s - loss: 0.8859 - accuracy: 0.61 - ETA: 0s - loss: 0.8864 - accuracy: 0.61 - ETA: 0s - loss: 0.8907 - accuracy: 0.61 - ETA: 0s - loss: 0.8839 - accuracy: 0.61 - ETA: 0s - loss: 0.8771 - accuracy: 0.62 - ETA: 0s - loss: 0.8595 - accuracy: 0.63 - ETA: 0s - loss: 0.8698 - accuracy: 0.62 - ETA: 0s - loss: 0.8868 - accuracy: 0.61 - ETA: 0s - loss: 0.8882 - accuracy: 0.61 - ETA: 0s - loss: 0.8941 - accuracy: 0.61 - ETA: 0s - loss: 0.8949 - accuracy: 0.61 - ETA: 0s - loss: 0.8958 - accuracy: 0.6090\n",
      "Epoch 00372: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8958 - accuracy: 0.6090 - val_loss: 1.0307 - val_accuracy: 0.4927 - lr: 0.0010\n",
      "Epoch 373/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9626 - accuracy: 0.54 - ETA: 0s - loss: 0.9391 - accuracy: 0.56 - ETA: 0s - loss: 0.9418 - accuracy: 0.56 - ETA: 0s - loss: 0.9128 - accuracy: 0.59 - ETA: 0s - loss: 0.9041 - accuracy: 0.60 - ETA: 0s - loss: 0.8900 - accuracy: 0.61 - ETA: 0s - loss: 0.8857 - accuracy: 0.61 - ETA: 0s - loss: 0.8842 - accuracy: 0.62 - ETA: 0s - loss: 0.8844 - accuracy: 0.61 - ETA: 0s - loss: 0.8902 - accuracy: 0.61 - ETA: 0s - loss: 0.8835 - accuracy: 0.61 - ETA: 0s - loss: 0.8772 - accuracy: 0.62 - ETA: 0s - loss: 0.8594 - accuracy: 0.64 - ETA: 0s - loss: 0.8694 - accuracy: 0.62 - ETA: 0s - loss: 0.8866 - accuracy: 0.61 - ETA: 0s - loss: 0.8884 - accuracy: 0.61 - ETA: 0s - loss: 0.8939 - accuracy: 0.60 - ETA: 0s - loss: 0.8949 - accuracy: 0.60 - ETA: 0s - loss: 0.8958 - accuracy: 0.6073\n",
      "Epoch 00373: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8958 - accuracy: 0.6073 - val_loss: 1.0350 - val_accuracy: 0.4915 - lr: 0.0010\n",
      "Epoch 374/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9633 - accuracy: 0.53 - ETA: 0s - loss: 0.9404 - accuracy: 0.55 - ETA: 0s - loss: 0.9394 - accuracy: 0.56 - ETA: 0s - loss: 0.9091 - accuracy: 0.58 - ETA: 0s - loss: 0.9002 - accuracy: 0.59 - ETA: 0s - loss: 0.8873 - accuracy: 0.60 - ETA: 0s - loss: 0.8837 - accuracy: 0.61 - ETA: 0s - loss: 0.8834 - accuracy: 0.61 - ETA: 0s - loss: 0.8836 - accuracy: 0.61 - ETA: 0s - loss: 0.8899 - accuracy: 0.60 - ETA: 0s - loss: 0.8829 - accuracy: 0.61 - ETA: 0s - loss: 0.8759 - accuracy: 0.62 - ETA: 0s - loss: 0.8582 - accuracy: 0.63 - ETA: 0s - loss: 0.8677 - accuracy: 0.62 - ETA: 0s - loss: 0.8845 - accuracy: 0.61 - ETA: 0s - loss: 0.8915 - accuracy: 0.60 - ETA: 0s - loss: 0.8925 - accuracy: 0.60 - ETA: 0s - loss: 0.8942 - accuracy: 0.6078\n",
      "Epoch 00374: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8942 - accuracy: 0.6078 - val_loss: 1.0446 - val_accuracy: 0.4808 - lr: 0.0010\n",
      "Epoch 375/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9504 - accuracy: 0.54 - ETA: 0s - loss: 0.9282 - accuracy: 0.56 - ETA: 0s - loss: 0.9333 - accuracy: 0.56 - ETA: 0s - loss: 0.9003 - accuracy: 0.59 - ETA: 0s - loss: 0.8950 - accuracy: 0.59 - ETA: 0s - loss: 0.8831 - accuracy: 0.61 - ETA: 0s - loss: 0.8786 - accuracy: 0.61 - ETA: 0s - loss: 0.8787 - accuracy: 0.62 - ETA: 0s - loss: 0.8788 - accuracy: 0.61 - ETA: 0s - loss: 0.8851 - accuracy: 0.61 - ETA: 0s - loss: 0.8800 - accuracy: 0.61 - ETA: 0s - loss: 0.8745 - accuracy: 0.62 - ETA: 0s - loss: 0.8567 - accuracy: 0.64 - ETA: 0s - loss: 0.8668 - accuracy: 0.62 - ETA: 0s - loss: 0.8845 - accuracy: 0.61 - ETA: 0s - loss: 0.8868 - accuracy: 0.61 - ETA: 0s - loss: 0.8924 - accuracy: 0.60 - ETA: 0s - loss: 0.8936 - accuracy: 0.60 - ETA: 0s - loss: 0.8946 - accuracy: 0.6075\n",
      "Epoch 00375: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00375: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8946 - accuracy: 0.6075 - val_loss: 1.0521 - val_accuracy: 0.4762 - lr: 0.0010\n",
      "Epoch 376/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9606 - accuracy: 0.55 - ETA: 0s - loss: 0.9332 - accuracy: 0.56 - ETA: 0s - loss: 0.9354 - accuracy: 0.56 - ETA: 0s - loss: 0.9062 - accuracy: 0.59 - ETA: 0s - loss: 0.8972 - accuracy: 0.60 - ETA: 0s - loss: 0.8856 - accuracy: 0.61 - ETA: 0s - loss: 0.8829 - accuracy: 0.61 - ETA: 0s - loss: 0.8822 - accuracy: 0.62 - ETA: 0s - loss: 0.8822 - accuracy: 0.61 - ETA: 0s - loss: 0.8881 - accuracy: 0.61 - ETA: 0s - loss: 0.8820 - accuracy: 0.62 - ETA: 0s - loss: 0.8759 - accuracy: 0.62 - ETA: 0s - loss: 0.8579 - accuracy: 0.64 - ETA: 0s - loss: 0.8673 - accuracy: 0.63 - ETA: 0s - loss: 0.8848 - accuracy: 0.61 - ETA: 0s - loss: 0.8862 - accuracy: 0.61 - ETA: 0s - loss: 0.8921 - accuracy: 0.61 - ETA: 0s - loss: 0.8935 - accuracy: 0.61 - ETA: 0s - loss: 0.8950 - accuracy: 0.6101\n",
      "Epoch 00376: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8950 - accuracy: 0.6101 - val_loss: 1.0535 - val_accuracy: 0.4731 - lr: 0.0010\n",
      "Epoch 377/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9459 - accuracy: 0.54 - ETA: 0s - loss: 0.9274 - accuracy: 0.56 - ETA: 0s - loss: 0.9288 - accuracy: 0.56 - ETA: 0s - loss: 0.9005 - accuracy: 0.59 - ETA: 0s - loss: 0.8964 - accuracy: 0.59 - ETA: 0s - loss: 0.8837 - accuracy: 0.61 - ETA: 0s - loss: 0.8809 - accuracy: 0.61 - ETA: 0s - loss: 0.8807 - accuracy: 0.62 - ETA: 0s - loss: 0.8813 - accuracy: 0.61 - ETA: 0s - loss: 0.8864 - accuracy: 0.61 - ETA: 0s - loss: 0.8795 - accuracy: 0.61 - ETA: 0s - loss: 0.8739 - accuracy: 0.62 - ETA: 0s - loss: 0.8564 - accuracy: 0.64 - ETA: 0s - loss: 0.8676 - accuracy: 0.62 - ETA: 0s - loss: 0.8855 - accuracy: 0.61 - ETA: 0s - loss: 0.8883 - accuracy: 0.61 - ETA: 0s - loss: 0.8938 - accuracy: 0.60 - ETA: 0s - loss: 0.8953 - accuracy: 0.60 - ETA: 0s - loss: 0.8965 - accuracy: 0.6084\n",
      "Epoch 00377: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8965 - accuracy: 0.6084 - val_loss: 1.0535 - val_accuracy: 0.4764 - lr: 0.0010\n",
      "Epoch 378/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9566 - accuracy: 0.53 - ETA: 0s - loss: 0.9333 - accuracy: 0.55 - ETA: 0s - loss: 0.9335 - accuracy: 0.56 - ETA: 0s - loss: 0.9000 - accuracy: 0.59 - ETA: 0s - loss: 0.8952 - accuracy: 0.59 - ETA: 0s - loss: 0.8845 - accuracy: 0.61 - ETA: 0s - loss: 0.8816 - accuracy: 0.61 - ETA: 0s - loss: 0.8809 - accuracy: 0.61 - ETA: 0s - loss: 0.8819 - accuracy: 0.61 - ETA: 0s - loss: 0.8866 - accuracy: 0.61 - ETA: 0s - loss: 0.8812 - accuracy: 0.61 - ETA: 0s - loss: 0.8741 - accuracy: 0.62 - ETA: 0s - loss: 0.8573 - accuracy: 0.64 - ETA: 0s - loss: 0.8670 - accuracy: 0.63 - ETA: 0s - loss: 0.8841 - accuracy: 0.61 - ETA: 0s - loss: 0.8865 - accuracy: 0.61 - ETA: 0s - loss: 0.8923 - accuracy: 0.61 - ETA: 0s - loss: 0.8937 - accuracy: 0.60 - ETA: 0s - loss: 0.8950 - accuracy: 0.6078\n",
      "Epoch 00378: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8950 - accuracy: 0.6078 - val_loss: 1.0537 - val_accuracy: 0.4739 - lr: 0.0010\n",
      "Epoch 379/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9586 - accuracy: 0.54 - ETA: 0s - loss: 0.9316 - accuracy: 0.56 - ETA: 0s - loss: 0.9365 - accuracy: 0.56 - ETA: 0s - loss: 0.9018 - accuracy: 0.59 - ETA: 0s - loss: 0.8950 - accuracy: 0.60 - ETA: 0s - loss: 0.8839 - accuracy: 0.61 - ETA: 0s - loss: 0.8806 - accuracy: 0.62 - ETA: 0s - loss: 0.8809 - accuracy: 0.62 - ETA: 0s - loss: 0.8812 - accuracy: 0.61 - ETA: 0s - loss: 0.8864 - accuracy: 0.61 - ETA: 0s - loss: 0.8800 - accuracy: 0.62 - ETA: 0s - loss: 0.8733 - accuracy: 0.62 - ETA: 0s - loss: 0.8558 - accuracy: 0.64 - ETA: 0s - loss: 0.8650 - accuracy: 0.63 - ETA: 0s - loss: 0.8837 - accuracy: 0.61 - ETA: 0s - loss: 0.8853 - accuracy: 0.61 - ETA: 0s - loss: 0.8911 - accuracy: 0.61 - ETA: 0s - loss: 0.8923 - accuracy: 0.61 - ETA: 0s - loss: 0.8938 - accuracy: 0.6109\n",
      "Epoch 00379: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8938 - accuracy: 0.6109 - val_loss: 1.0429 - val_accuracy: 0.4787 - lr: 0.0010\n",
      "Epoch 380/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9632 - accuracy: 0.53 - ETA: 0s - loss: 0.9359 - accuracy: 0.56 - ETA: 0s - loss: 0.9351 - accuracy: 0.56 - ETA: 0s - loss: 0.9037 - accuracy: 0.59 - ETA: 0s - loss: 0.8980 - accuracy: 0.60 - ETA: 0s - loss: 0.8857 - accuracy: 0.61 - ETA: 0s - loss: 0.8816 - accuracy: 0.62 - ETA: 0s - loss: 0.8824 - accuracy: 0.62 - ETA: 0s - loss: 0.8841 - accuracy: 0.61 - ETA: 0s - loss: 0.8894 - accuracy: 0.61 - ETA: 0s - loss: 0.8834 - accuracy: 0.61 - ETA: 0s - loss: 0.8782 - accuracy: 0.62 - ETA: 0s - loss: 0.8598 - accuracy: 0.64 - ETA: 0s - loss: 0.8694 - accuracy: 0.62 - ETA: 0s - loss: 0.8852 - accuracy: 0.61 - ETA: 0s - loss: 0.8872 - accuracy: 0.61 - ETA: 0s - loss: 0.8927 - accuracy: 0.60 - ETA: 0s - loss: 0.8945 - accuracy: 0.60 - ETA: 0s - loss: 0.8956 - accuracy: 0.6077\n",
      "Epoch 00380: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8956 - accuracy: 0.6077 - val_loss: 1.0388 - val_accuracy: 0.4824 - lr: 0.0010\n",
      "Epoch 381/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9376 - accuracy: 0.54 - ETA: 0s - loss: 0.9196 - accuracy: 0.56 - ETA: 0s - loss: 0.9271 - accuracy: 0.56 - ETA: 0s - loss: 0.8964 - accuracy: 0.59 - ETA: 0s - loss: 0.8922 - accuracy: 0.60 - ETA: 0s - loss: 0.8818 - accuracy: 0.61 - ETA: 0s - loss: 0.8793 - accuracy: 0.61 - ETA: 0s - loss: 0.8774 - accuracy: 0.62 - ETA: 0s - loss: 0.8787 - accuracy: 0.62 - ETA: 0s - loss: 0.8853 - accuracy: 0.61 - ETA: 0s - loss: 0.8792 - accuracy: 0.62 - ETA: 0s - loss: 0.8727 - accuracy: 0.62 - ETA: 0s - loss: 0.8560 - accuracy: 0.64 - ETA: 0s - loss: 0.8653 - accuracy: 0.63 - ETA: 0s - loss: 0.8822 - accuracy: 0.61 - ETA: 0s - loss: 0.8846 - accuracy: 0.61 - ETA: 0s - loss: 0.8904 - accuracy: 0.61 - ETA: 0s - loss: 0.8921 - accuracy: 0.61 - ETA: 0s - loss: 0.8933 - accuracy: 0.6108\n",
      "Epoch 00381: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8933 - accuracy: 0.6108 - val_loss: 1.0409 - val_accuracy: 0.4762 - lr: 0.0010\n",
      "Epoch 382/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9700 - accuracy: 0.54 - ETA: 0s - loss: 0.9365 - accuracy: 0.56 - ETA: 0s - loss: 0.9392 - accuracy: 0.56 - ETA: 0s - loss: 0.9051 - accuracy: 0.59 - ETA: 0s - loss: 0.8973 - accuracy: 0.59 - ETA: 0s - loss: 0.8850 - accuracy: 0.61 - ETA: 0s - loss: 0.8826 - accuracy: 0.61 - ETA: 0s - loss: 0.8823 - accuracy: 0.62 - ETA: 0s - loss: 0.8824 - accuracy: 0.61 - ETA: 0s - loss: 0.8871 - accuracy: 0.61 - ETA: 0s - loss: 0.8813 - accuracy: 0.61 - ETA: 0s - loss: 0.8758 - accuracy: 0.62 - ETA: 0s - loss: 0.8578 - accuracy: 0.63 - ETA: 0s - loss: 0.8667 - accuracy: 0.62 - ETA: 0s - loss: 0.8853 - accuracy: 0.61 - ETA: 0s - loss: 0.8910 - accuracy: 0.60 - ETA: 0s - loss: 0.8920 - accuracy: 0.60 - ETA: 0s - loss: 0.8929 - accuracy: 0.6085\n",
      "Epoch 00382: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8929 - accuracy: 0.6085 - val_loss: 1.0354 - val_accuracy: 0.4821 - lr: 0.0010\n",
      "Epoch 383/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9626 - accuracy: 0.54 - ETA: 0s - loss: 0.9329 - accuracy: 0.56 - ETA: 0s - loss: 0.9349 - accuracy: 0.56 - ETA: 0s - loss: 0.9013 - accuracy: 0.59 - ETA: 0s - loss: 0.8947 - accuracy: 0.60 - ETA: 0s - loss: 0.8829 - accuracy: 0.61 - ETA: 0s - loss: 0.8795 - accuracy: 0.61 - ETA: 0s - loss: 0.8791 - accuracy: 0.62 - ETA: 0s - loss: 0.8794 - accuracy: 0.61 - ETA: 0s - loss: 0.8857 - accuracy: 0.61 - ETA: 0s - loss: 0.8795 - accuracy: 0.62 - ETA: 0s - loss: 0.8731 - accuracy: 0.62 - ETA: 0s - loss: 0.8552 - accuracy: 0.64 - ETA: 0s - loss: 0.8650 - accuracy: 0.63 - ETA: 0s - loss: 0.8826 - accuracy: 0.61 - ETA: 0s - loss: 0.8850 - accuracy: 0.61 - ETA: 0s - loss: 0.8909 - accuracy: 0.61 - ETA: 0s - loss: 0.8927 - accuracy: 0.61 - ETA: 0s - loss: 0.8942 - accuracy: 0.6088\n",
      "Epoch 00383: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8942 - accuracy: 0.6088 - val_loss: 1.0378 - val_accuracy: 0.4818 - lr: 0.0010\n",
      "Epoch 384/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9433 - accuracy: 0.55 - ETA: 0s - loss: 0.9256 - accuracy: 0.56 - ETA: 0s - loss: 0.9313 - accuracy: 0.56 - ETA: 0s - loss: 0.8989 - accuracy: 0.59 - ETA: 0s - loss: 0.8922 - accuracy: 0.60 - ETA: 0s - loss: 0.8810 - accuracy: 0.61 - ETA: 0s - loss: 0.8775 - accuracy: 0.62 - ETA: 0s - loss: 0.8791 - accuracy: 0.62 - ETA: 0s - loss: 0.8801 - accuracy: 0.61 - ETA: 0s - loss: 0.8847 - accuracy: 0.61 - ETA: 0s - loss: 0.8776 - accuracy: 0.62 - ETA: 0s - loss: 0.8716 - accuracy: 0.62 - ETA: 0s - loss: 0.8540 - accuracy: 0.64 - ETA: 0s - loss: 0.8644 - accuracy: 0.63 - ETA: 0s - loss: 0.8802 - accuracy: 0.61 - ETA: 0s - loss: 0.8831 - accuracy: 0.61 - ETA: 0s - loss: 0.8894 - accuracy: 0.61 - ETA: 0s - loss: 0.8902 - accuracy: 0.61 - ETA: 0s - loss: 0.8912 - accuracy: 0.6097\n",
      "Epoch 00384: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8912 - accuracy: 0.6097 - val_loss: 1.0342 - val_accuracy: 0.4860 - lr: 0.0010\n",
      "Epoch 385/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9441 - accuracy: 0.54 - ETA: 0s - loss: 0.9319 - accuracy: 0.56 - ETA: 0s - loss: 0.9347 - accuracy: 0.56 - ETA: 0s - loss: 0.9009 - accuracy: 0.59 - ETA: 0s - loss: 0.8929 - accuracy: 0.59 - ETA: 0s - loss: 0.8811 - accuracy: 0.61 - ETA: 0s - loss: 0.8782 - accuracy: 0.61 - ETA: 0s - loss: 0.8798 - accuracy: 0.61 - ETA: 0s - loss: 0.8802 - accuracy: 0.61 - ETA: 0s - loss: 0.8848 - accuracy: 0.61 - ETA: 0s - loss: 0.8791 - accuracy: 0.61 - ETA: 0s - loss: 0.8729 - accuracy: 0.62 - ETA: 0s - loss: 0.8555 - accuracy: 0.63 - ETA: 0s - loss: 0.8666 - accuracy: 0.62 - ETA: 0s - loss: 0.8824 - accuracy: 0.61 - ETA: 0s - loss: 0.8852 - accuracy: 0.61 - ETA: 0s - loss: 0.8906 - accuracy: 0.60 - ETA: 0s - loss: 0.8926 - accuracy: 0.60 - ETA: 0s - loss: 0.8933 - accuracy: 0.6077\n",
      "Epoch 00385: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8933 - accuracy: 0.6077 - val_loss: 1.0265 - val_accuracy: 0.4917 - lr: 0.0010\n",
      "Epoch 386/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9576 - accuracy: 0.54 - ETA: 0s - loss: 0.9323 - accuracy: 0.56 - ETA: 0s - loss: 0.9376 - accuracy: 0.56 - ETA: 0s - loss: 0.9025 - accuracy: 0.59 - ETA: 0s - loss: 0.8974 - accuracy: 0.59 - ETA: 0s - loss: 0.8855 - accuracy: 0.61 - ETA: 0s - loss: 0.8813 - accuracy: 0.61 - ETA: 0s - loss: 0.8811 - accuracy: 0.61 - ETA: 0s - loss: 0.8819 - accuracy: 0.61 - ETA: 0s - loss: 0.8878 - accuracy: 0.60 - ETA: 0s - loss: 0.8816 - accuracy: 0.61 - ETA: 0s - loss: 0.8749 - accuracy: 0.62 - ETA: 0s - loss: 0.8571 - accuracy: 0.63 - ETA: 0s - loss: 0.8668 - accuracy: 0.62 - ETA: 0s - loss: 0.8824 - accuracy: 0.61 - ETA: 0s - loss: 0.8848 - accuracy: 0.61 - ETA: 0s - loss: 0.8904 - accuracy: 0.60 - ETA: 0s - loss: 0.8916 - accuracy: 0.60 - ETA: 0s - loss: 0.8925 - accuracy: 0.6074\n",
      "Epoch 00386: val_loss did not improve from 0.99131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8925 - accuracy: 0.6074 - val_loss: 1.0209 - val_accuracy: 0.4930 - lr: 0.0010\n",
      "Epoch 387/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9529 - accuracy: 0.54 - ETA: 0s - loss: 0.9303 - accuracy: 0.56 - ETA: 0s - loss: 0.9317 - accuracy: 0.56 - ETA: 0s - loss: 0.8992 - accuracy: 0.59 - ETA: 0s - loss: 0.8938 - accuracy: 0.60 - ETA: 0s - loss: 0.8822 - accuracy: 0.61 - ETA: 0s - loss: 0.8800 - accuracy: 0.61 - ETA: 0s - loss: 0.8800 - accuracy: 0.62 - ETA: 0s - loss: 0.8808 - accuracy: 0.61 - ETA: 0s - loss: 0.8861 - accuracy: 0.61 - ETA: 0s - loss: 0.8788 - accuracy: 0.62 - ETA: 0s - loss: 0.8729 - accuracy: 0.62 - ETA: 0s - loss: 0.8556 - accuracy: 0.64 - ETA: 0s - loss: 0.8645 - accuracy: 0.63 - ETA: 0s - loss: 0.8807 - accuracy: 0.61 - ETA: 0s - loss: 0.8829 - accuracy: 0.61 - ETA: 0s - loss: 0.8892 - accuracy: 0.61 - ETA: 0s - loss: 0.8904 - accuracy: 0.61 - ETA: 0s - loss: 0.8917 - accuracy: 0.6097\n",
      "Epoch 00387: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8917 - accuracy: 0.6097 - val_loss: 1.0172 - val_accuracy: 0.4976 - lr: 0.0010\n",
      "Epoch 388/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9609 - accuracy: 0.52 - ETA: 0s - loss: 0.9388 - accuracy: 0.55 - ETA: 0s - loss: 0.9432 - accuracy: 0.55 - ETA: 0s - loss: 0.9094 - accuracy: 0.58 - ETA: 0s - loss: 0.9016 - accuracy: 0.59 - ETA: 0s - loss: 0.8879 - accuracy: 0.60 - ETA: 0s - loss: 0.8859 - accuracy: 0.61 - ETA: 0s - loss: 0.8845 - accuracy: 0.61 - ETA: 0s - loss: 0.8852 - accuracy: 0.61 - ETA: 0s - loss: 0.8891 - accuracy: 0.60 - ETA: 0s - loss: 0.8827 - accuracy: 0.61 - ETA: 0s - loss: 0.8766 - accuracy: 0.62 - ETA: 0s - loss: 0.8585 - accuracy: 0.63 - ETA: 0s - loss: 0.8676 - accuracy: 0.62 - ETA: 0s - loss: 0.8857 - accuracy: 0.61 - ETA: 0s - loss: 0.8915 - accuracy: 0.60 - ETA: 0s - loss: 0.8929 - accuracy: 0.60 - ETA: 0s - loss: 0.8946 - accuracy: 0.6060\n",
      "Epoch 00388: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8946 - accuracy: 0.6060 - val_loss: 1.0174 - val_accuracy: 0.4943 - lr: 0.0010\n",
      "Epoch 389/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9659 - accuracy: 0.54 - ETA: 0s - loss: 0.9302 - accuracy: 0.56 - ETA: 0s - loss: 0.9345 - accuracy: 0.56 - ETA: 0s - loss: 0.9007 - accuracy: 0.59 - ETA: 0s - loss: 0.8954 - accuracy: 0.60 - ETA: 0s - loss: 0.8839 - accuracy: 0.61 - ETA: 0s - loss: 0.8803 - accuracy: 0.61 - ETA: 0s - loss: 0.8796 - accuracy: 0.62 - ETA: 0s - loss: 0.8811 - accuracy: 0.62 - ETA: 0s - loss: 0.8883 - accuracy: 0.61 - ETA: 0s - loss: 0.8818 - accuracy: 0.62 - ETA: 0s - loss: 0.8759 - accuracy: 0.62 - ETA: 0s - loss: 0.8582 - accuracy: 0.64 - ETA: 0s - loss: 0.8682 - accuracy: 0.62 - ETA: 0s - loss: 0.8848 - accuracy: 0.61 - ETA: 0s - loss: 0.8875 - accuracy: 0.61 - ETA: 0s - loss: 0.8929 - accuracy: 0.60 - ETA: 0s - loss: 0.8938 - accuracy: 0.60 - ETA: 0s - loss: 0.8953 - accuracy: 0.6094\n",
      "Epoch 00389: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00389: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8953 - accuracy: 0.6094 - val_loss: 1.0178 - val_accuracy: 0.4989 - lr: 0.0010\n",
      "Epoch 390/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9662 - accuracy: 0.54 - ETA: 0s - loss: 0.9322 - accuracy: 0.56 - ETA: 0s - loss: 0.9348 - accuracy: 0.56 - ETA: 0s - loss: 0.9042 - accuracy: 0.59 - ETA: 0s - loss: 0.8990 - accuracy: 0.60 - ETA: 0s - loss: 0.8869 - accuracy: 0.61 - ETA: 0s - loss: 0.8836 - accuracy: 0.61 - ETA: 0s - loss: 0.8844 - accuracy: 0.61 - ETA: 0s - loss: 0.8845 - accuracy: 0.61 - ETA: 0s - loss: 0.8882 - accuracy: 0.61 - ETA: 0s - loss: 0.8819 - accuracy: 0.61 - ETA: 0s - loss: 0.8758 - accuracy: 0.62 - ETA: 0s - loss: 0.8579 - accuracy: 0.64 - ETA: 0s - loss: 0.8665 - accuracy: 0.63 - ETA: 0s - loss: 0.8820 - accuracy: 0.61 - ETA: 0s - loss: 0.8838 - accuracy: 0.61 - ETA: 0s - loss: 0.8888 - accuracy: 0.61 - ETA: 0s - loss: 0.8902 - accuracy: 0.61 - ETA: 0s - loss: 0.8916 - accuracy: 0.6107\n",
      "Epoch 00390: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8916 - accuracy: 0.6107 - val_loss: 1.0338 - val_accuracy: 0.4915 - lr: 0.0010\n",
      "Epoch 391/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9527 - accuracy: 0.54 - ETA: 0s - loss: 0.9302 - accuracy: 0.56 - ETA: 0s - loss: 0.9334 - accuracy: 0.56 - ETA: 0s - loss: 0.9002 - accuracy: 0.59 - ETA: 0s - loss: 0.8956 - accuracy: 0.59 - ETA: 0s - loss: 0.8835 - accuracy: 0.61 - ETA: 0s - loss: 0.8802 - accuracy: 0.61 - ETA: 0s - loss: 0.8795 - accuracy: 0.61 - ETA: 0s - loss: 0.8805 - accuracy: 0.61 - ETA: 0s - loss: 0.8856 - accuracy: 0.61 - ETA: 0s - loss: 0.8792 - accuracy: 0.61 - ETA: 0s - loss: 0.8730 - accuracy: 0.62 - ETA: 0s - loss: 0.8563 - accuracy: 0.64 - ETA: 0s - loss: 0.8652 - accuracy: 0.63 - ETA: 0s - loss: 0.8820 - accuracy: 0.61 - ETA: 0s - loss: 0.8845 - accuracy: 0.61 - ETA: 0s - loss: 0.8906 - accuracy: 0.61 - ETA: 0s - loss: 0.8920 - accuracy: 0.61 - ETA: 0s - loss: 0.8933 - accuracy: 0.6085\n",
      "Epoch 00391: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8933 - accuracy: 0.6085 - val_loss: 1.0295 - val_accuracy: 0.4876 - lr: 0.0010\n",
      "Epoch 392/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9464 - accuracy: 0.56 - ETA: 0s - loss: 0.9317 - accuracy: 0.56 - ETA: 0s - loss: 0.9344 - accuracy: 0.56 - ETA: 0s - loss: 0.9012 - accuracy: 0.59 - ETA: 0s - loss: 0.8954 - accuracy: 0.60 - ETA: 0s - loss: 0.8852 - accuracy: 0.61 - ETA: 0s - loss: 0.8821 - accuracy: 0.61 - ETA: 0s - loss: 0.8810 - accuracy: 0.62 - ETA: 0s - loss: 0.8817 - accuracy: 0.61 - ETA: 0s - loss: 0.8878 - accuracy: 0.61 - ETA: 0s - loss: 0.8822 - accuracy: 0.62 - ETA: 0s - loss: 0.8753 - accuracy: 0.62 - ETA: 0s - loss: 0.8576 - accuracy: 0.64 - ETA: 0s - loss: 0.8666 - accuracy: 0.63 - ETA: 0s - loss: 0.8833 - accuracy: 0.61 - ETA: 0s - loss: 0.8852 - accuracy: 0.61 - ETA: 0s - loss: 0.8909 - accuracy: 0.61 - ETA: 0s - loss: 0.8920 - accuracy: 0.61 - ETA: 0s - loss: 0.8932 - accuracy: 0.6105\n",
      "Epoch 00392: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8932 - accuracy: 0.6105 - val_loss: 1.0253 - val_accuracy: 0.4914 - lr: 0.0010\n",
      "Epoch 393/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9556 - accuracy: 0.54 - ETA: 0s - loss: 0.9298 - accuracy: 0.56 - ETA: 0s - loss: 0.9331 - accuracy: 0.56 - ETA: 0s - loss: 0.8997 - accuracy: 0.59 - ETA: 0s - loss: 0.8971 - accuracy: 0.60 - ETA: 0s - loss: 0.8852 - accuracy: 0.61 - ETA: 0s - loss: 0.8828 - accuracy: 0.61 - ETA: 0s - loss: 0.8816 - accuracy: 0.62 - ETA: 0s - loss: 0.8822 - accuracy: 0.62 - ETA: 0s - loss: 0.8885 - accuracy: 0.61 - ETA: 0s - loss: 0.8825 - accuracy: 0.62 - ETA: 0s - loss: 0.8766 - accuracy: 0.62 - ETA: 0s - loss: 0.8588 - accuracy: 0.64 - ETA: 0s - loss: 0.8679 - accuracy: 0.63 - ETA: 0s - loss: 0.8837 - accuracy: 0.61 - ETA: 0s - loss: 0.8859 - accuracy: 0.61 - ETA: 0s - loss: 0.8919 - accuracy: 0.61 - ETA: 0s - loss: 0.8931 - accuracy: 0.61 - ETA: 0s - loss: 0.8951 - accuracy: 0.6091\n",
      "Epoch 00393: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8951 - accuracy: 0.6091 - val_loss: 1.0298 - val_accuracy: 0.4855 - lr: 0.0010\n",
      "Epoch 394/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9417 - accuracy: 0.55 - ETA: 0s - loss: 0.9199 - accuracy: 0.56 - ETA: 0s - loss: 0.9238 - accuracy: 0.56 - ETA: 0s - loss: 0.8948 - accuracy: 0.59 - ETA: 0s - loss: 0.8893 - accuracy: 0.60 - ETA: 0s - loss: 0.8795 - accuracy: 0.61 - ETA: 0s - loss: 0.8769 - accuracy: 0.62 - ETA: 0s - loss: 0.8764 - accuracy: 0.62 - ETA: 0s - loss: 0.8781 - accuracy: 0.62 - ETA: 0s - loss: 0.8843 - accuracy: 0.61 - ETA: 0s - loss: 0.8783 - accuracy: 0.62 - ETA: 0s - loss: 0.8720 - accuracy: 0.62 - ETA: 0s - loss: 0.8546 - accuracy: 0.64 - ETA: 0s - loss: 0.8638 - accuracy: 0.63 - ETA: 0s - loss: 0.8809 - accuracy: 0.61 - ETA: 0s - loss: 0.8832 - accuracy: 0.61 - ETA: 0s - loss: 0.8888 - accuracy: 0.61 - ETA: 0s - loss: 0.8903 - accuracy: 0.61 - ETA: 0s - loss: 0.8919 - accuracy: 0.6094\n",
      "Epoch 00394: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8919 - accuracy: 0.6094 - val_loss: 1.0316 - val_accuracy: 0.4844 - lr: 0.0010\n",
      "Epoch 395/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9577 - accuracy: 0.53 - ETA: 0s - loss: 0.9325 - accuracy: 0.55 - ETA: 0s - loss: 0.9333 - accuracy: 0.56 - ETA: 0s - loss: 0.9005 - accuracy: 0.59 - ETA: 0s - loss: 0.8941 - accuracy: 0.60 - ETA: 0s - loss: 0.8824 - accuracy: 0.61 - ETA: 0s - loss: 0.8781 - accuracy: 0.61 - ETA: 0s - loss: 0.8782 - accuracy: 0.61 - ETA: 0s - loss: 0.8795 - accuracy: 0.61 - ETA: 0s - loss: 0.8847 - accuracy: 0.61 - ETA: 0s - loss: 0.8791 - accuracy: 0.61 - ETA: 0s - loss: 0.8731 - accuracy: 0.62 - ETA: 0s - loss: 0.8558 - accuracy: 0.63 - ETA: 0s - loss: 0.8644 - accuracy: 0.62 - ETA: 0s - loss: 0.8807 - accuracy: 0.61 - ETA: 0s - loss: 0.8833 - accuracy: 0.61 - ETA: 0s - loss: 0.8893 - accuracy: 0.60 - ETA: 0s - loss: 0.8904 - accuracy: 0.60 - ETA: 0s - loss: 0.8914 - accuracy: 0.6068\n",
      "Epoch 00395: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8914 - accuracy: 0.6068 - val_loss: 1.0306 - val_accuracy: 0.4839 - lr: 0.0010\n",
      "Epoch 396/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9471 - accuracy: 0.54 - ETA: 0s - loss: 0.9315 - accuracy: 0.56 - ETA: 0s - loss: 0.9346 - accuracy: 0.56 - ETA: 0s - loss: 0.9039 - accuracy: 0.59 - ETA: 0s - loss: 0.8964 - accuracy: 0.59 - ETA: 0s - loss: 0.8849 - accuracy: 0.61 - ETA: 0s - loss: 0.8833 - accuracy: 0.61 - ETA: 0s - loss: 0.8830 - accuracy: 0.61 - ETA: 0s - loss: 0.8848 - accuracy: 0.61 - ETA: 0s - loss: 0.8900 - accuracy: 0.60 - ETA: 0s - loss: 0.8842 - accuracy: 0.61 - ETA: 0s - loss: 0.8774 - accuracy: 0.62 - ETA: 0s - loss: 0.8596 - accuracy: 0.63 - ETA: 0s - loss: 0.8691 - accuracy: 0.62 - ETA: 0s - loss: 0.8856 - accuracy: 0.61 - ETA: 0s - loss: 0.8878 - accuracy: 0.61 - ETA: 0s - loss: 0.8923 - accuracy: 0.60 - ETA: 0s - loss: 0.8937 - accuracy: 0.60 - ETA: 0s - loss: 0.8947 - accuracy: 0.6080\n",
      "Epoch 00396: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8947 - accuracy: 0.6080 - val_loss: 1.0227 - val_accuracy: 0.4920 - lr: 0.0010\n",
      "Epoch 397/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9602 - accuracy: 0.54 - ETA: 0s - loss: 0.9361 - accuracy: 0.56 - ETA: 0s - loss: 0.9358 - accuracy: 0.56 - ETA: 0s - loss: 0.9019 - accuracy: 0.59 - ETA: 0s - loss: 0.8967 - accuracy: 0.59 - ETA: 0s - loss: 0.8850 - accuracy: 0.61 - ETA: 0s - loss: 0.8814 - accuracy: 0.61 - ETA: 0s - loss: 0.8810 - accuracy: 0.61 - ETA: 0s - loss: 0.8822 - accuracy: 0.61 - ETA: 0s - loss: 0.8876 - accuracy: 0.60 - ETA: 0s - loss: 0.8818 - accuracy: 0.61 - ETA: 0s - loss: 0.8755 - accuracy: 0.62 - ETA: 0s - loss: 0.8580 - accuracy: 0.63 - ETA: 0s - loss: 0.8679 - accuracy: 0.62 - ETA: 0s - loss: 0.8826 - accuracy: 0.61 - ETA: 0s - loss: 0.8848 - accuracy: 0.61 - ETA: 0s - loss: 0.8901 - accuracy: 0.60 - ETA: 0s - loss: 0.8916 - accuracy: 0.60 - ETA: 0s - loss: 0.8928 - accuracy: 0.6075\n",
      "Epoch 00397: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8928 - accuracy: 0.6075 - val_loss: 1.0339 - val_accuracy: 0.4827 - lr: 0.0010\n",
      "Epoch 398/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9608 - accuracy: 0.53 - ETA: 0s - loss: 0.9348 - accuracy: 0.55 - ETA: 0s - loss: 0.9374 - accuracy: 0.55 - ETA: 0s - loss: 0.9040 - accuracy: 0.58 - ETA: 0s - loss: 0.8986 - accuracy: 0.59 - ETA: 0s - loss: 0.8871 - accuracy: 0.60 - ETA: 0s - loss: 0.8837 - accuracy: 0.61 - ETA: 0s - loss: 0.8846 - accuracy: 0.61 - ETA: 0s - loss: 0.8849 - accuracy: 0.61 - ETA: 0s - loss: 0.8903 - accuracy: 0.60 - ETA: 0s - loss: 0.8784 - accuracy: 0.62 - ETA: 0s - loss: 0.8606 - accuracy: 0.63 - ETA: 0s - loss: 0.8696 - accuracy: 0.62 - ETA: 0s - loss: 0.8861 - accuracy: 0.61 - ETA: 0s - loss: 0.8881 - accuracy: 0.61 - ETA: 0s - loss: 0.8939 - accuracy: 0.60 - ETA: 0s - loss: 0.8948 - accuracy: 0.60 - ETA: 0s - loss: 0.8960 - accuracy: 0.6079\n",
      "Epoch 00398: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8960 - accuracy: 0.6079 - val_loss: 1.0371 - val_accuracy: 0.4795 - lr: 0.0010\n",
      "Epoch 399/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9507 - accuracy: 0.54 - ETA: 0s - loss: 0.9306 - accuracy: 0.56 - ETA: 0s - loss: 0.9372 - accuracy: 0.56 - ETA: 0s - loss: 0.9018 - accuracy: 0.59 - ETA: 0s - loss: 0.8945 - accuracy: 0.59 - ETA: 0s - loss: 0.8821 - accuracy: 0.61 - ETA: 0s - loss: 0.8789 - accuracy: 0.61 - ETA: 0s - loss: 0.8775 - accuracy: 0.61 - ETA: 0s - loss: 0.8776 - accuracy: 0.61 - ETA: 0s - loss: 0.8829 - accuracy: 0.61 - ETA: 0s - loss: 0.8767 - accuracy: 0.62 - ETA: 0s - loss: 0.8702 - accuracy: 0.62 - ETA: 0s - loss: 0.8526 - accuracy: 0.64 - ETA: 0s - loss: 0.8616 - accuracy: 0.63 - ETA: 0s - loss: 0.8777 - accuracy: 0.61 - ETA: 0s - loss: 0.8797 - accuracy: 0.61 - ETA: 0s - loss: 0.8850 - accuracy: 0.61 - ETA: 0s - loss: 0.8863 - accuracy: 0.61 - ETA: 0s - loss: 0.8880 - accuracy: 0.6107\n",
      "Epoch 00399: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8880 - accuracy: 0.6107 - val_loss: 1.0309 - val_accuracy: 0.4834 - lr: 0.0010\n",
      "Epoch 400/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9627 - accuracy: 0.54 - ETA: 0s - loss: 0.9345 - accuracy: 0.56 - ETA: 0s - loss: 0.9375 - accuracy: 0.56 - ETA: 0s - loss: 0.9026 - accuracy: 0.59 - ETA: 0s - loss: 0.8968 - accuracy: 0.60 - ETA: 0s - loss: 0.8857 - accuracy: 0.61 - ETA: 0s - loss: 0.8823 - accuracy: 0.61 - ETA: 0s - loss: 0.8804 - accuracy: 0.61 - ETA: 0s - loss: 0.8813 - accuracy: 0.61 - ETA: 0s - loss: 0.8879 - accuracy: 0.60 - ETA: 0s - loss: 0.8819 - accuracy: 0.61 - ETA: 0s - loss: 0.8753 - accuracy: 0.62 - ETA: 0s - loss: 0.8577 - accuracy: 0.63 - ETA: 0s - loss: 0.8663 - accuracy: 0.62 - ETA: 0s - loss: 0.8830 - accuracy: 0.61 - ETA: 0s - loss: 0.8860 - accuracy: 0.61 - ETA: 0s - loss: 0.8912 - accuracy: 0.60 - ETA: 0s - loss: 0.8927 - accuracy: 0.60 - ETA: 0s - loss: 0.8937 - accuracy: 0.6060\n",
      "Epoch 00400: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8937 - accuracy: 0.6060 - val_loss: 1.0278 - val_accuracy: 0.4891 - lr: 0.0010\n",
      "Epoch 401/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9373 - accuracy: 0.55 - ETA: 0s - loss: 0.9208 - accuracy: 0.56 - ETA: 0s - loss: 0.9253 - accuracy: 0.56 - ETA: 0s - loss: 0.8916 - accuracy: 0.59 - ETA: 0s - loss: 0.8883 - accuracy: 0.60 - ETA: 0s - loss: 0.8779 - accuracy: 0.61 - ETA: 0s - loss: 0.8766 - accuracy: 0.61 - ETA: 0s - loss: 0.8765 - accuracy: 0.62 - ETA: 0s - loss: 0.8771 - accuracy: 0.61 - ETA: 0s - loss: 0.8831 - accuracy: 0.61 - ETA: 0s - loss: 0.8767 - accuracy: 0.62 - ETA: 0s - loss: 0.8711 - accuracy: 0.62 - ETA: 0s - loss: 0.8537 - accuracy: 0.64 - ETA: 0s - loss: 0.8804 - accuracy: 0.61 - ETA: 0s - loss: 0.8830 - accuracy: 0.61 - ETA: 0s - loss: 0.8887 - accuracy: 0.61 - ETA: 0s - loss: 0.8906 - accuracy: 0.61 - ETA: 0s - loss: 0.8918 - accuracy: 0.6092\n",
      "Epoch 00401: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8918 - accuracy: 0.6092 - val_loss: 1.0292 - val_accuracy: 0.4881 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 402/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9560 - accuracy: 0.55 - ETA: 0s - loss: 0.9271 - accuracy: 0.56 - ETA: 0s - loss: 0.9295 - accuracy: 0.57 - ETA: 0s - loss: 0.8978 - accuracy: 0.59 - ETA: 0s - loss: 0.8927 - accuracy: 0.60 - ETA: 0s - loss: 0.8816 - accuracy: 0.61 - ETA: 0s - loss: 0.8786 - accuracy: 0.62 - ETA: 0s - loss: 0.8774 - accuracy: 0.62 - ETA: 0s - loss: 0.8775 - accuracy: 0.62 - ETA: 0s - loss: 0.8847 - accuracy: 0.61 - ETA: 0s - loss: 0.8781 - accuracy: 0.62 - ETA: 0s - loss: 0.8716 - accuracy: 0.63 - ETA: 0s - loss: 0.8542 - accuracy: 0.64 - ETA: 0s - loss: 0.8622 - accuracy: 0.63 - ETA: 0s - loss: 0.8802 - accuracy: 0.62 - ETA: 0s - loss: 0.8829 - accuracy: 0.61 - ETA: 0s - loss: 0.8887 - accuracy: 0.61 - ETA: 0s - loss: 0.8903 - accuracy: 0.61 - ETA: 0s - loss: 0.8923 - accuracy: 0.6124\n",
      "Epoch 00402: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8923 - accuracy: 0.6124 - val_loss: 1.0285 - val_accuracy: 0.4866 - lr: 0.0010\n",
      "Epoch 403/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9508 - accuracy: 0.55 - ETA: 0s - loss: 0.9245 - accuracy: 0.56 - ETA: 0s - loss: 0.9297 - accuracy: 0.56 - ETA: 0s - loss: 0.8966 - accuracy: 0.59 - ETA: 0s - loss: 0.8917 - accuracy: 0.60 - ETA: 0s - loss: 0.8803 - accuracy: 0.61 - ETA: 0s - loss: 0.8784 - accuracy: 0.61 - ETA: 0s - loss: 0.8783 - accuracy: 0.62 - ETA: 0s - loss: 0.8782 - accuracy: 0.62 - ETA: 0s - loss: 0.8838 - accuracy: 0.61 - ETA: 0s - loss: 0.8779 - accuracy: 0.62 - ETA: 0s - loss: 0.8719 - accuracy: 0.62 - ETA: 0s - loss: 0.8535 - accuracy: 0.64 - ETA: 0s - loss: 0.8635 - accuracy: 0.63 - ETA: 0s - loss: 0.8814 - accuracy: 0.61 - ETA: 0s - loss: 0.8829 - accuracy: 0.61 - ETA: 0s - loss: 0.8884 - accuracy: 0.61 - ETA: 0s - loss: 0.8900 - accuracy: 0.61 - ETA: 0s - loss: 0.8913 - accuracy: 0.6104\n",
      "Epoch 00403: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00403: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8913 - accuracy: 0.6104 - val_loss: 1.0313 - val_accuracy: 0.4837 - lr: 0.0010\n",
      "Epoch 404/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9633 - accuracy: 0.53 - ETA: 0s - loss: 0.9372 - accuracy: 0.55 - ETA: 0s - loss: 0.9380 - accuracy: 0.56 - ETA: 0s - loss: 0.9035 - accuracy: 0.59 - ETA: 0s - loss: 0.8946 - accuracy: 0.60 - ETA: 0s - loss: 0.8833 - accuracy: 0.61 - ETA: 0s - loss: 0.8801 - accuracy: 0.61 - ETA: 0s - loss: 0.8805 - accuracy: 0.62 - ETA: 0s - loss: 0.8816 - accuracy: 0.62 - ETA: 0s - loss: 0.8855 - accuracy: 0.61 - ETA: 0s - loss: 0.8796 - accuracy: 0.62 - ETA: 0s - loss: 0.8732 - accuracy: 0.62 - ETA: 0s - loss: 0.8559 - accuracy: 0.64 - ETA: 0s - loss: 0.8655 - accuracy: 0.62 - ETA: 0s - loss: 0.8805 - accuracy: 0.61 - ETA: 0s - loss: 0.8828 - accuracy: 0.61 - ETA: 0s - loss: 0.8888 - accuracy: 0.60 - ETA: 0s - loss: 0.8899 - accuracy: 0.60 - ETA: 0s - loss: 0.8912 - accuracy: 0.6084\n",
      "Epoch 00404: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8912 - accuracy: 0.6084 - val_loss: 1.0326 - val_accuracy: 0.4811 - lr: 0.0010\n",
      "Epoch 405/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9620 - accuracy: 0.53 - ETA: 0s - loss: 0.9389 - accuracy: 0.56 - ETA: 0s - loss: 0.9375 - accuracy: 0.56 - ETA: 0s - loss: 0.9036 - accuracy: 0.59 - ETA: 0s - loss: 0.8981 - accuracy: 0.60 - ETA: 0s - loss: 0.8875 - accuracy: 0.61 - ETA: 0s - loss: 0.8828 - accuracy: 0.61 - ETA: 0s - loss: 0.8825 - accuracy: 0.61 - ETA: 0s - loss: 0.8826 - accuracy: 0.61 - ETA: 0s - loss: 0.8887 - accuracy: 0.60 - ETA: 0s - loss: 0.8837 - accuracy: 0.61 - ETA: 0s - loss: 0.8761 - accuracy: 0.62 - ETA: 0s - loss: 0.8584 - accuracy: 0.63 - ETA: 0s - loss: 0.8664 - accuracy: 0.62 - ETA: 0s - loss: 0.8825 - accuracy: 0.61 - ETA: 0s - loss: 0.8839 - accuracy: 0.61 - ETA: 0s - loss: 0.8897 - accuracy: 0.60 - ETA: 0s - loss: 0.8900 - accuracy: 0.60 - ETA: 0s - loss: 0.8918 - accuracy: 0.6085\n",
      "Epoch 00405: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8918 - accuracy: 0.6085 - val_loss: 1.0433 - val_accuracy: 0.4720 - lr: 0.0010\n",
      "Epoch 406/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9696 - accuracy: 0.53 - ETA: 0s - loss: 0.9425 - accuracy: 0.55 - ETA: 0s - loss: 0.9407 - accuracy: 0.56 - ETA: 0s - loss: 0.9085 - accuracy: 0.59 - ETA: 0s - loss: 0.9011 - accuracy: 0.60 - ETA: 0s - loss: 0.8890 - accuracy: 0.61 - ETA: 0s - loss: 0.8846 - accuracy: 0.61 - ETA: 0s - loss: 0.8847 - accuracy: 0.62 - ETA: 0s - loss: 0.8848 - accuracy: 0.61 - ETA: 0s - loss: 0.8904 - accuracy: 0.60 - ETA: 0s - loss: 0.8842 - accuracy: 0.61 - ETA: 0s - loss: 0.8768 - accuracy: 0.62 - ETA: 0s - loss: 0.8582 - accuracy: 0.63 - ETA: 0s - loss: 0.8662 - accuracy: 0.62 - ETA: 0s - loss: 0.8822 - accuracy: 0.61 - ETA: 0s - loss: 0.8849 - accuracy: 0.61 - ETA: 0s - loss: 0.8903 - accuracy: 0.60 - ETA: 0s - loss: 0.8916 - accuracy: 0.60 - ETA: 0s - loss: 0.8928 - accuracy: 0.6085\n",
      "Epoch 00406: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8928 - accuracy: 0.6085 - val_loss: 1.0463 - val_accuracy: 0.4690 - lr: 0.0010\n",
      "Epoch 407/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9557 - accuracy: 0.54 - ETA: 0s - loss: 0.9329 - accuracy: 0.56 - ETA: 0s - loss: 0.9368 - accuracy: 0.56 - ETA: 0s - loss: 0.9028 - accuracy: 0.59 - ETA: 0s - loss: 0.8981 - accuracy: 0.60 - ETA: 0s - loss: 0.8860 - accuracy: 0.61 - ETA: 0s - loss: 0.8837 - accuracy: 0.61 - ETA: 0s - loss: 0.8838 - accuracy: 0.62 - ETA: 0s - loss: 0.8841 - accuracy: 0.62 - ETA: 0s - loss: 0.8892 - accuracy: 0.61 - ETA: 0s - loss: 0.8817 - accuracy: 0.62 - ETA: 0s - loss: 0.8752 - accuracy: 0.62 - ETA: 0s - loss: 0.8572 - accuracy: 0.64 - ETA: 0s - loss: 0.8665 - accuracy: 0.63 - ETA: 0s - loss: 0.8832 - accuracy: 0.61 - ETA: 0s - loss: 0.8855 - accuracy: 0.61 - ETA: 0s - loss: 0.8910 - accuracy: 0.61 - ETA: 0s - loss: 0.8928 - accuracy: 0.61 - ETA: 0s - loss: 0.8941 - accuracy: 0.6106\n",
      "Epoch 00407: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8941 - accuracy: 0.6106 - val_loss: 1.0459 - val_accuracy: 0.4743 - lr: 0.0010\n",
      "Epoch 408/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9451 - accuracy: 0.53 - ETA: 0s - loss: 0.9320 - accuracy: 0.55 - ETA: 0s - loss: 0.9348 - accuracy: 0.56 - ETA: 0s - loss: 0.9002 - accuracy: 0.58 - ETA: 0s - loss: 0.8930 - accuracy: 0.59 - ETA: 0s - loss: 0.8825 - accuracy: 0.61 - ETA: 0s - loss: 0.8800 - accuracy: 0.61 - ETA: 0s - loss: 0.8794 - accuracy: 0.61 - ETA: 0s - loss: 0.8816 - accuracy: 0.61 - ETA: 0s - loss: 0.8872 - accuracy: 0.60 - ETA: 0s - loss: 0.8811 - accuracy: 0.61 - ETA: 0s - loss: 0.8748 - accuracy: 0.62 - ETA: 0s - loss: 0.8573 - accuracy: 0.63 - ETA: 0s - loss: 0.8657 - accuracy: 0.62 - ETA: 0s - loss: 0.8808 - accuracy: 0.61 - ETA: 0s - loss: 0.8831 - accuracy: 0.61 - ETA: 0s - loss: 0.8890 - accuracy: 0.60 - ETA: 0s - loss: 0.8909 - accuracy: 0.60 - ETA: 0s - loss: 0.8916 - accuracy: 0.6072\n",
      "Epoch 00408: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8916 - accuracy: 0.6072 - val_loss: 1.0502 - val_accuracy: 0.4674 - lr: 0.0010\n",
      "Epoch 409/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9553 - accuracy: 0.55 - ETA: 0s - loss: 0.9310 - accuracy: 0.57 - ETA: 0s - loss: 0.9348 - accuracy: 0.56 - ETA: 0s - loss: 0.9044 - accuracy: 0.59 - ETA: 0s - loss: 0.8989 - accuracy: 0.60 - ETA: 0s - loss: 0.8871 - accuracy: 0.61 - ETA: 0s - loss: 0.8839 - accuracy: 0.61 - ETA: 0s - loss: 0.8827 - accuracy: 0.62 - ETA: 0s - loss: 0.8833 - accuracy: 0.61 - ETA: 0s - loss: 0.8868 - accuracy: 0.61 - ETA: 0s - loss: 0.8805 - accuracy: 0.62 - ETA: 0s - loss: 0.8740 - accuracy: 0.62 - ETA: 0s - loss: 0.8559 - accuracy: 0.64 - ETA: 0s - loss: 0.8648 - accuracy: 0.63 - ETA: 0s - loss: 0.8804 - accuracy: 0.61 - ETA: 0s - loss: 0.8825 - accuracy: 0.61 - ETA: 0s - loss: 0.8877 - accuracy: 0.61 - ETA: 0s - loss: 0.8888 - accuracy: 0.61 - ETA: 0s - loss: 0.8910 - accuracy: 0.6091\n",
      "Epoch 00409: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8910 - accuracy: 0.6091 - val_loss: 1.0392 - val_accuracy: 0.4791 - lr: 0.0010\n",
      "Epoch 410/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9543 - accuracy: 0.54 - ETA: 0s - loss: 0.9260 - accuracy: 0.56 - ETA: 0s - loss: 0.9328 - accuracy: 0.56 - ETA: 0s - loss: 0.8981 - accuracy: 0.59 - ETA: 0s - loss: 0.8914 - accuracy: 0.60 - ETA: 0s - loss: 0.8810 - accuracy: 0.61 - ETA: 0s - loss: 0.8782 - accuracy: 0.61 - ETA: 0s - loss: 0.8774 - accuracy: 0.62 - ETA: 0s - loss: 0.8778 - accuracy: 0.62 - ETA: 0s - loss: 0.8830 - accuracy: 0.61 - ETA: 0s - loss: 0.8767 - accuracy: 0.62 - ETA: 0s - loss: 0.8704 - accuracy: 0.62 - ETA: 0s - loss: 0.8528 - accuracy: 0.64 - ETA: 0s - loss: 0.8624 - accuracy: 0.63 - ETA: 0s - loss: 0.8783 - accuracy: 0.62 - ETA: 0s - loss: 0.8800 - accuracy: 0.61 - ETA: 0s - loss: 0.8861 - accuracy: 0.61 - ETA: 0s - loss: 0.8882 - accuracy: 0.61 - ETA: 0s - loss: 0.8894 - accuracy: 0.6114\n",
      "Epoch 00410: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8894 - accuracy: 0.6114 - val_loss: 1.0396 - val_accuracy: 0.4855 - lr: 0.0010\n",
      "Epoch 411/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9402 - accuracy: 0.54 - ETA: 0s - loss: 0.9376 - accuracy: 0.55 - ETA: 0s - loss: 0.9381 - accuracy: 0.56 - ETA: 0s - loss: 0.9020 - accuracy: 0.59 - ETA: 0s - loss: 0.8937 - accuracy: 0.60 - ETA: 0s - loss: 0.8832 - accuracy: 0.61 - ETA: 0s - loss: 0.8812 - accuracy: 0.61 - ETA: 0s - loss: 0.8794 - accuracy: 0.61 - ETA: 0s - loss: 0.8825 - accuracy: 0.61 - ETA: 0s - loss: 0.8871 - accuracy: 0.61 - ETA: 0s - loss: 0.8811 - accuracy: 0.61 - ETA: 0s - loss: 0.8758 - accuracy: 0.62 - ETA: 0s - loss: 0.8581 - accuracy: 0.63 - ETA: 0s - loss: 0.8650 - accuracy: 0.63 - ETA: 0s - loss: 0.8800 - accuracy: 0.61 - ETA: 0s - loss: 0.8823 - accuracy: 0.61 - ETA: 0s - loss: 0.8874 - accuracy: 0.61 - ETA: 0s - loss: 0.8893 - accuracy: 0.61 - ETA: 0s - loss: 0.8916 - accuracy: 0.6098\n",
      "Epoch 00411: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8916 - accuracy: 0.6098 - val_loss: 1.0388 - val_accuracy: 0.4850 - lr: 0.0010\n",
      "Epoch 412/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9622 - accuracy: 0.54 - ETA: 0s - loss: 0.9411 - accuracy: 0.56 - ETA: 0s - loss: 0.9361 - accuracy: 0.56 - ETA: 0s - loss: 0.9040 - accuracy: 0.59 - ETA: 0s - loss: 0.8966 - accuracy: 0.60 - ETA: 0s - loss: 0.8848 - accuracy: 0.61 - ETA: 0s - loss: 0.8808 - accuracy: 0.62 - ETA: 0s - loss: 0.8814 - accuracy: 0.62 - ETA: 0s - loss: 0.8803 - accuracy: 0.61 - ETA: 0s - loss: 0.8855 - accuracy: 0.61 - ETA: 0s - loss: 0.8800 - accuracy: 0.61 - ETA: 0s - loss: 0.8733 - accuracy: 0.62 - ETA: 0s - loss: 0.8555 - accuracy: 0.64 - ETA: 0s - loss: 0.8642 - accuracy: 0.63 - ETA: 0s - loss: 0.8826 - accuracy: 0.61 - ETA: 0s - loss: 0.8881 - accuracy: 0.61 - ETA: 0s - loss: 0.8891 - accuracy: 0.61 - ETA: 0s - loss: 0.8903 - accuracy: 0.6093\n",
      "Epoch 00412: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8903 - accuracy: 0.6093 - val_loss: 1.0535 - val_accuracy: 0.4723 - lr: 0.0010\n",
      "Epoch 413/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9372 - accuracy: 0.55 - ETA: 0s - loss: 0.9213 - accuracy: 0.57 - ETA: 0s - loss: 0.9286 - accuracy: 0.57 - ETA: 0s - loss: 0.8959 - accuracy: 0.59 - ETA: 0s - loss: 0.8914 - accuracy: 0.60 - ETA: 0s - loss: 0.8791 - accuracy: 0.61 - ETA: 0s - loss: 0.8770 - accuracy: 0.62 - ETA: 0s - loss: 0.8762 - accuracy: 0.62 - ETA: 0s - loss: 0.8766 - accuracy: 0.62 - ETA: 0s - loss: 0.8812 - accuracy: 0.61 - ETA: 0s - loss: 0.8754 - accuracy: 0.62 - ETA: 0s - loss: 0.8690 - accuracy: 0.63 - ETA: 0s - loss: 0.8519 - accuracy: 0.64 - ETA: 0s - loss: 0.8611 - accuracy: 0.63 - ETA: 0s - loss: 0.8758 - accuracy: 0.62 - ETA: 0s - loss: 0.8785 - accuracy: 0.61 - ETA: 0s - loss: 0.8843 - accuracy: 0.61 - ETA: 0s - loss: 0.8854 - accuracy: 0.61 - ETA: 0s - loss: 0.8872 - accuracy: 0.6111\n",
      "Epoch 00413: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8872 - accuracy: 0.6111 - val_loss: 1.0468 - val_accuracy: 0.4775 - lr: 0.0010\n",
      "Epoch 414/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9479 - accuracy: 0.54 - ETA: 0s - loss: 0.9234 - accuracy: 0.56 - ETA: 0s - loss: 0.9250 - accuracy: 0.56 - ETA: 0s - loss: 0.8937 - accuracy: 0.59 - ETA: 0s - loss: 0.8888 - accuracy: 0.60 - ETA: 0s - loss: 0.8785 - accuracy: 0.61 - ETA: 0s - loss: 0.8761 - accuracy: 0.61 - ETA: 0s - loss: 0.8766 - accuracy: 0.61 - ETA: 0s - loss: 0.8771 - accuracy: 0.61 - ETA: 0s - loss: 0.8824 - accuracy: 0.61 - ETA: 0s - loss: 0.8761 - accuracy: 0.61 - ETA: 0s - loss: 0.8702 - accuracy: 0.62 - ETA: 0s - loss: 0.8530 - accuracy: 0.64 - ETA: 0s - loss: 0.8621 - accuracy: 0.63 - ETA: 0s - loss: 0.8769 - accuracy: 0.61 - ETA: 0s - loss: 0.8796 - accuracy: 0.61 - ETA: 0s - loss: 0.8849 - accuracy: 0.61 - ETA: 0s - loss: 0.8865 - accuracy: 0.61 - ETA: 0s - loss: 0.8884 - accuracy: 0.6106\n",
      "Epoch 00414: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8884 - accuracy: 0.6106 - val_loss: 1.0376 - val_accuracy: 0.4842 - lr: 0.0010\n",
      "Epoch 415/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9514 - accuracy: 0.54 - ETA: 0s - loss: 0.9265 - accuracy: 0.56 - ETA: 0s - loss: 0.9283 - accuracy: 0.56 - ETA: 0s - loss: 0.8961 - accuracy: 0.59 - ETA: 0s - loss: 0.8904 - accuracy: 0.60 - ETA: 0s - loss: 0.8808 - accuracy: 0.61 - ETA: 0s - loss: 0.8784 - accuracy: 0.62 - ETA: 0s - loss: 0.8788 - accuracy: 0.62 - ETA: 0s - loss: 0.8785 - accuracy: 0.62 - ETA: 0s - loss: 0.8845 - accuracy: 0.61 - ETA: 0s - loss: 0.8779 - accuracy: 0.62 - ETA: 0s - loss: 0.8717 - accuracy: 0.62 - ETA: 0s - loss: 0.8544 - accuracy: 0.64 - ETA: 0s - loss: 0.8626 - accuracy: 0.63 - ETA: 0s - loss: 0.8786 - accuracy: 0.61 - ETA: 0s - loss: 0.8809 - accuracy: 0.61 - ETA: 0s - loss: 0.8863 - accuracy: 0.61 - ETA: 0s - loss: 0.8874 - accuracy: 0.61 - ETA: 0s - loss: 0.8887 - accuracy: 0.6094\n",
      "Epoch 00415: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8887 - accuracy: 0.6094 - val_loss: 1.0512 - val_accuracy: 0.4739 - lr: 0.0010\n",
      "Epoch 416/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9417 - accuracy: 0.54 - ETA: 0s - loss: 0.9256 - accuracy: 0.56 - ETA: 0s - loss: 0.9293 - accuracy: 0.56 - ETA: 0s - loss: 0.8943 - accuracy: 0.59 - ETA: 0s - loss: 0.8890 - accuracy: 0.60 - ETA: 0s - loss: 0.8777 - accuracy: 0.61 - ETA: 0s - loss: 0.8745 - accuracy: 0.62 - ETA: 0s - loss: 0.8752 - accuracy: 0.62 - ETA: 0s - loss: 0.8771 - accuracy: 0.62 - ETA: 0s - loss: 0.8836 - accuracy: 0.61 - ETA: 0s - loss: 0.8780 - accuracy: 0.62 - ETA: 0s - loss: 0.8710 - accuracy: 0.62 - ETA: 0s - loss: 0.8540 - accuracy: 0.64 - ETA: 0s - loss: 0.8635 - accuracy: 0.63 - ETA: 0s - loss: 0.8796 - accuracy: 0.61 - ETA: 0s - loss: 0.8816 - accuracy: 0.61 - ETA: 0s - loss: 0.8866 - accuracy: 0.61 - ETA: 0s - loss: 0.8881 - accuracy: 0.61 - ETA: 0s - loss: 0.8890 - accuracy: 0.6106\n",
      "Epoch 00416: val_loss did not improve from 0.99131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8890 - accuracy: 0.6106 - val_loss: 1.0585 - val_accuracy: 0.4689 - lr: 0.0010\n",
      "Epoch 417/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9310 - accuracy: 0.54 - ETA: 0s - loss: 0.9143 - accuracy: 0.56 - ETA: 0s - loss: 0.9263 - accuracy: 0.56 - ETA: 0s - loss: 0.8948 - accuracy: 0.59 - ETA: 0s - loss: 0.8891 - accuracy: 0.60 - ETA: 0s - loss: 0.8780 - accuracy: 0.61 - ETA: 0s - loss: 0.8758 - accuracy: 0.61 - ETA: 0s - loss: 0.8766 - accuracy: 0.61 - ETA: 0s - loss: 0.8779 - accuracy: 0.61 - ETA: 0s - loss: 0.8830 - accuracy: 0.61 - ETA: 0s - loss: 0.8773 - accuracy: 0.61 - ETA: 0s - loss: 0.8722 - accuracy: 0.62 - ETA: 0s - loss: 0.8551 - accuracy: 0.63 - ETA: 0s - loss: 0.8640 - accuracy: 0.62 - ETA: 0s - loss: 0.8782 - accuracy: 0.61 - ETA: 0s - loss: 0.8804 - accuracy: 0.61 - ETA: 0s - loss: 0.8859 - accuracy: 0.61 - ETA: 0s - loss: 0.8879 - accuracy: 0.60 - ETA: 0s - loss: 0.8897 - accuracy: 0.6083\n",
      "Epoch 00417: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00417: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8897 - accuracy: 0.6083 - val_loss: 1.0607 - val_accuracy: 0.4656 - lr: 0.0010\n",
      "Epoch 418/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9457 - accuracy: 0.54 - ETA: 0s - loss: 0.9224 - accuracy: 0.56 - ETA: 0s - loss: 0.9314 - accuracy: 0.56 - ETA: 0s - loss: 0.8998 - accuracy: 0.59 - ETA: 0s - loss: 0.8937 - accuracy: 0.59 - ETA: 0s - loss: 0.8825 - accuracy: 0.61 - ETA: 0s - loss: 0.8793 - accuracy: 0.61 - ETA: 0s - loss: 0.8791 - accuracy: 0.61 - ETA: 0s - loss: 0.8797 - accuracy: 0.61 - ETA: 0s - loss: 0.8837 - accuracy: 0.61 - ETA: 0s - loss: 0.8786 - accuracy: 0.61 - ETA: 0s - loss: 0.8726 - accuracy: 0.62 - ETA: 0s - loss: 0.8552 - accuracy: 0.63 - ETA: 0s - loss: 0.8640 - accuracy: 0.62 - ETA: 0s - loss: 0.8788 - accuracy: 0.61 - ETA: 0s - loss: 0.8810 - accuracy: 0.61 - ETA: 0s - loss: 0.8870 - accuracy: 0.61 - ETA: 0s - loss: 0.8882 - accuracy: 0.61 - ETA: 0s - loss: 0.8893 - accuracy: 0.6097\n",
      "Epoch 00418: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8893 - accuracy: 0.6097 - val_loss: 1.0583 - val_accuracy: 0.4673 - lr: 0.0010\n",
      "Epoch 419/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9401 - accuracy: 0.54 - ETA: 0s - loss: 0.9198 - accuracy: 0.56 - ETA: 0s - loss: 0.9281 - accuracy: 0.56 - ETA: 0s - loss: 0.8980 - accuracy: 0.58 - ETA: 0s - loss: 0.8940 - accuracy: 0.59 - ETA: 0s - loss: 0.8832 - accuracy: 0.61 - ETA: 0s - loss: 0.8796 - accuracy: 0.61 - ETA: 0s - loss: 0.8787 - accuracy: 0.61 - ETA: 0s - loss: 0.8787 - accuracy: 0.61 - ETA: 0s - loss: 0.8837 - accuracy: 0.61 - ETA: 0s - loss: 0.8784 - accuracy: 0.62 - ETA: 0s - loss: 0.8725 - accuracy: 0.62 - ETA: 0s - loss: 0.8550 - accuracy: 0.63 - ETA: 0s - loss: 0.8630 - accuracy: 0.62 - ETA: 0s - loss: 0.8792 - accuracy: 0.61 - ETA: 0s - loss: 0.8809 - accuracy: 0.61 - ETA: 0s - loss: 0.8867 - accuracy: 0.60 - ETA: 0s - loss: 0.8874 - accuracy: 0.60 - ETA: 0s - loss: 0.8889 - accuracy: 0.6077\n",
      "Epoch 00419: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8889 - accuracy: 0.6077 - val_loss: 1.0526 - val_accuracy: 0.4682 - lr: 0.0010\n",
      "Epoch 420/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9454 - accuracy: 0.55 - ETA: 0s - loss: 0.9220 - accuracy: 0.57 - ETA: 0s - loss: 0.9278 - accuracy: 0.57 - ETA: 0s - loss: 0.8965 - accuracy: 0.59 - ETA: 0s - loss: 0.8912 - accuracy: 0.60 - ETA: 0s - loss: 0.8815 - accuracy: 0.61 - ETA: 0s - loss: 0.8785 - accuracy: 0.62 - ETA: 0s - loss: 0.8773 - accuracy: 0.62 - ETA: 0s - loss: 0.8779 - accuracy: 0.62 - ETA: 0s - loss: 0.8834 - accuracy: 0.61 - ETA: 0s - loss: 0.8771 - accuracy: 0.62 - ETA: 0s - loss: 0.8706 - accuracy: 0.62 - ETA: 0s - loss: 0.8534 - accuracy: 0.64 - ETA: 0s - loss: 0.8630 - accuracy: 0.63 - ETA: 0s - loss: 0.8782 - accuracy: 0.61 - ETA: 0s - loss: 0.8803 - accuracy: 0.61 - ETA: 0s - loss: 0.8858 - accuracy: 0.61 - ETA: 0s - loss: 0.8872 - accuracy: 0.61 - ETA: 0s - loss: 0.8897 - accuracy: 0.6101\n",
      "Epoch 00420: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8897 - accuracy: 0.6101 - val_loss: 1.0510 - val_accuracy: 0.4744 - lr: 0.0010\n",
      "Epoch 421/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9604 - accuracy: 0.54 - ETA: 0s - loss: 0.9371 - accuracy: 0.55 - ETA: 0s - loss: 0.9360 - accuracy: 0.56 - ETA: 0s - loss: 0.9005 - accuracy: 0.59 - ETA: 0s - loss: 0.8938 - accuracy: 0.59 - ETA: 0s - loss: 0.8812 - accuracy: 0.61 - ETA: 0s - loss: 0.8777 - accuracy: 0.61 - ETA: 0s - loss: 0.8776 - accuracy: 0.61 - ETA: 0s - loss: 0.8783 - accuracy: 0.61 - ETA: 0s - loss: 0.8838 - accuracy: 0.61 - ETA: 0s - loss: 0.8776 - accuracy: 0.61 - ETA: 0s - loss: 0.8717 - accuracy: 0.62 - ETA: 0s - loss: 0.8541 - accuracy: 0.63 - ETA: 0s - loss: 0.8632 - accuracy: 0.63 - ETA: 0s - loss: 0.8790 - accuracy: 0.61 - ETA: 0s - loss: 0.8809 - accuracy: 0.61 - ETA: 0s - loss: 0.8858 - accuracy: 0.61 - ETA: 0s - loss: 0.8867 - accuracy: 0.61 - ETA: 0s - loss: 0.8881 - accuracy: 0.6111\n",
      "Epoch 00421: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8881 - accuracy: 0.6111 - val_loss: 1.0533 - val_accuracy: 0.4721 - lr: 0.0010\n",
      "Epoch 422/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9667 - accuracy: 0.53 - ETA: 0s - loss: 0.9368 - accuracy: 0.56 - ETA: 0s - loss: 0.9392 - accuracy: 0.56 - ETA: 0s - loss: 0.9030 - accuracy: 0.58 - ETA: 0s - loss: 0.8952 - accuracy: 0.59 - ETA: 0s - loss: 0.8841 - accuracy: 0.61 - ETA: 0s - loss: 0.8801 - accuracy: 0.61 - ETA: 0s - loss: 0.8807 - accuracy: 0.61 - ETA: 0s - loss: 0.8803 - accuracy: 0.61 - ETA: 0s - loss: 0.8843 - accuracy: 0.60 - ETA: 0s - loss: 0.8787 - accuracy: 0.61 - ETA: 0s - loss: 0.8724 - accuracy: 0.62 - ETA: 0s - loss: 0.8548 - accuracy: 0.63 - ETA: 0s - loss: 0.8637 - accuracy: 0.62 - ETA: 0s - loss: 0.8804 - accuracy: 0.61 - ETA: 0s - loss: 0.8834 - accuracy: 0.61 - ETA: 0s - loss: 0.8892 - accuracy: 0.60 - ETA: 0s - loss: 0.8902 - accuracy: 0.60 - ETA: 0s - loss: 0.8911 - accuracy: 0.6070\n",
      "Epoch 00422: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8911 - accuracy: 0.6070 - val_loss: 1.0396 - val_accuracy: 0.4796 - lr: 0.0010\n",
      "Epoch 423/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9706 - accuracy: 0.54 - ETA: 0s - loss: 0.9288 - accuracy: 0.56 - ETA: 0s - loss: 0.9319 - accuracy: 0.56 - ETA: 0s - loss: 0.9003 - accuracy: 0.59 - ETA: 0s - loss: 0.8945 - accuracy: 0.60 - ETA: 0s - loss: 0.8831 - accuracy: 0.61 - ETA: 0s - loss: 0.8797 - accuracy: 0.61 - ETA: 0s - loss: 0.8799 - accuracy: 0.61 - ETA: 0s - loss: 0.8804 - accuracy: 0.61 - ETA: 0s - loss: 0.8859 - accuracy: 0.60 - ETA: 0s - loss: 0.8794 - accuracy: 0.61 - ETA: 0s - loss: 0.8727 - accuracy: 0.62 - ETA: 0s - loss: 0.8550 - accuracy: 0.63 - ETA: 0s - loss: 0.8637 - accuracy: 0.62 - ETA: 0s - loss: 0.8801 - accuracy: 0.61 - ETA: 0s - loss: 0.8825 - accuracy: 0.61 - ETA: 0s - loss: 0.8884 - accuracy: 0.61 - ETA: 0s - loss: 0.8892 - accuracy: 0.61 - ETA: 0s - loss: 0.8912 - accuracy: 0.6089\n",
      "Epoch 00423: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8912 - accuracy: 0.6089 - val_loss: 1.0342 - val_accuracy: 0.4835 - lr: 0.0010\n",
      "Epoch 424/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9446 - accuracy: 0.52 - ETA: 0s - loss: 0.9213 - accuracy: 0.56 - ETA: 0s - loss: 0.9286 - accuracy: 0.56 - ETA: 0s - loss: 0.8950 - accuracy: 0.59 - ETA: 0s - loss: 0.8895 - accuracy: 0.60 - ETA: 0s - loss: 0.8790 - accuracy: 0.61 - ETA: 0s - loss: 0.8758 - accuracy: 0.62 - ETA: 0s - loss: 0.8749 - accuracy: 0.62 - ETA: 0s - loss: 0.8773 - accuracy: 0.61 - ETA: 0s - loss: 0.8823 - accuracy: 0.61 - ETA: 0s - loss: 0.8765 - accuracy: 0.62 - ETA: 0s - loss: 0.8697 - accuracy: 0.62 - ETA: 0s - loss: 0.8522 - accuracy: 0.64 - ETA: 0s - loss: 0.8609 - accuracy: 0.63 - ETA: 0s - loss: 0.8772 - accuracy: 0.61 - ETA: 0s - loss: 0.8798 - accuracy: 0.61 - ETA: 0s - loss: 0.8853 - accuracy: 0.61 - ETA: 0s - loss: 0.8869 - accuracy: 0.61 - ETA: 0s - loss: 0.8886 - accuracy: 0.6108\n",
      "Epoch 00424: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8886 - accuracy: 0.6108 - val_loss: 1.0461 - val_accuracy: 0.4757 - lr: 0.0010\n",
      "Epoch 425/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9292 - accuracy: 0.54 - ETA: 0s - loss: 0.9169 - accuracy: 0.56 - ETA: 0s - loss: 0.9243 - accuracy: 0.56 - ETA: 0s - loss: 0.8943 - accuracy: 0.59 - ETA: 0s - loss: 0.8907 - accuracy: 0.60 - ETA: 0s - loss: 0.8792 - accuracy: 0.61 - ETA: 0s - loss: 0.8763 - accuracy: 0.62 - ETA: 0s - loss: 0.8749 - accuracy: 0.62 - ETA: 0s - loss: 0.8762 - accuracy: 0.62 - ETA: 0s - loss: 0.8821 - accuracy: 0.61 - ETA: 0s - loss: 0.8768 - accuracy: 0.62 - ETA: 0s - loss: 0.8702 - accuracy: 0.62 - ETA: 0s - loss: 0.8526 - accuracy: 0.64 - ETA: 0s - loss: 0.8622 - accuracy: 0.63 - ETA: 0s - loss: 0.8777 - accuracy: 0.61 - ETA: 0s - loss: 0.8798 - accuracy: 0.61 - ETA: 0s - loss: 0.8847 - accuracy: 0.61 - ETA: 0s - loss: 0.8866 - accuracy: 0.61 - ETA: 0s - loss: 0.8886 - accuracy: 0.6100\n",
      "Epoch 00425: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8886 - accuracy: 0.6100 - val_loss: 1.0547 - val_accuracy: 0.4739 - lr: 0.0010\n",
      "Epoch 426/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9430 - accuracy: 0.54 - ETA: 0s - loss: 0.9169 - accuracy: 0.57 - ETA: 0s - loss: 0.9261 - accuracy: 0.57 - ETA: 0s - loss: 0.8953 - accuracy: 0.59 - ETA: 0s - loss: 0.8918 - accuracy: 0.60 - ETA: 0s - loss: 0.8810 - accuracy: 0.61 - ETA: 0s - loss: 0.8793 - accuracy: 0.61 - ETA: 0s - loss: 0.8783 - accuracy: 0.62 - ETA: 0s - loss: 0.8810 - accuracy: 0.61 - ETA: 0s - loss: 0.8863 - accuracy: 0.61 - ETA: 0s - loss: 0.8801 - accuracy: 0.61 - ETA: 0s - loss: 0.8727 - accuracy: 0.62 - ETA: 0s - loss: 0.8553 - accuracy: 0.64 - ETA: 0s - loss: 0.8633 - accuracy: 0.63 - ETA: 0s - loss: 0.8802 - accuracy: 0.61 - ETA: 0s - loss: 0.8820 - accuracy: 0.61 - ETA: 0s - loss: 0.8871 - accuracy: 0.61 - ETA: 0s - loss: 0.8885 - accuracy: 0.61 - ETA: 0s - loss: 0.8898 - accuracy: 0.6097\n",
      "Epoch 00426: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8898 - accuracy: 0.6097 - val_loss: 1.0524 - val_accuracy: 0.4761 - lr: 0.0010\n",
      "Epoch 427/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9410 - accuracy: 0.55 - ETA: 0s - loss: 0.9242 - accuracy: 0.56 - ETA: 0s - loss: 0.9267 - accuracy: 0.57 - ETA: 0s - loss: 0.8960 - accuracy: 0.59 - ETA: 0s - loss: 0.8902 - accuracy: 0.60 - ETA: 0s - loss: 0.8800 - accuracy: 0.61 - ETA: 0s - loss: 0.8773 - accuracy: 0.62 - ETA: 0s - loss: 0.8789 - accuracy: 0.62 - ETA: 0s - loss: 0.8792 - accuracy: 0.62 - ETA: 0s - loss: 0.8847 - accuracy: 0.61 - ETA: 0s - loss: 0.8783 - accuracy: 0.61 - ETA: 0s - loss: 0.8718 - accuracy: 0.62 - ETA: 0s - loss: 0.8547 - accuracy: 0.63 - ETA: 0s - loss: 0.8624 - accuracy: 0.63 - ETA: 0s - loss: 0.8791 - accuracy: 0.61 - ETA: 0s - loss: 0.8813 - accuracy: 0.61 - ETA: 0s - loss: 0.8874 - accuracy: 0.61 - ETA: 0s - loss: 0.8884 - accuracy: 0.61 - ETA: 0s - loss: 0.8896 - accuracy: 0.6104\n",
      "Epoch 00427: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8896 - accuracy: 0.6104 - val_loss: 1.0351 - val_accuracy: 0.4848 - lr: 0.0010\n",
      "Epoch 428/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9466 - accuracy: 0.54 - ETA: 0s - loss: 0.9208 - accuracy: 0.56 - ETA: 0s - loss: 0.9234 - accuracy: 0.57 - ETA: 0s - loss: 0.8933 - accuracy: 0.59 - ETA: 0s - loss: 0.8880 - accuracy: 0.60 - ETA: 0s - loss: 0.8794 - accuracy: 0.61 - ETA: 0s - loss: 0.8770 - accuracy: 0.61 - ETA: 0s - loss: 0.8771 - accuracy: 0.62 - ETA: 0s - loss: 0.8774 - accuracy: 0.61 - ETA: 0s - loss: 0.8842 - accuracy: 0.61 - ETA: 0s - loss: 0.8786 - accuracy: 0.62 - ETA: 0s - loss: 0.8720 - accuracy: 0.62 - ETA: 0s - loss: 0.8536 - accuracy: 0.64 - ETA: 0s - loss: 0.8626 - accuracy: 0.63 - ETA: 0s - loss: 0.8790 - accuracy: 0.61 - ETA: 0s - loss: 0.8808 - accuracy: 0.61 - ETA: 0s - loss: 0.8863 - accuracy: 0.61 - ETA: 0s - loss: 0.8878 - accuracy: 0.61 - ETA: 0s - loss: 0.8890 - accuracy: 0.6111\n",
      "Epoch 00428: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8890 - accuracy: 0.6111 - val_loss: 1.0430 - val_accuracy: 0.4778 - lr: 0.0010\n",
      "Epoch 429/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9467 - accuracy: 0.54 - ETA: 0s - loss: 0.9191 - accuracy: 0.56 - ETA: 0s - loss: 0.9222 - accuracy: 0.56 - ETA: 0s - loss: 0.8920 - accuracy: 0.59 - ETA: 0s - loss: 0.8867 - accuracy: 0.60 - ETA: 0s - loss: 0.8759 - accuracy: 0.61 - ETA: 0s - loss: 0.8728 - accuracy: 0.62 - ETA: 0s - loss: 0.8731 - accuracy: 0.62 - ETA: 0s - loss: 0.8744 - accuracy: 0.61 - ETA: 0s - loss: 0.8802 - accuracy: 0.61 - ETA: 0s - loss: 0.8740 - accuracy: 0.62 - ETA: 0s - loss: 0.8673 - accuracy: 0.62 - ETA: 0s - loss: 0.8504 - accuracy: 0.64 - ETA: 0s - loss: 0.8588 - accuracy: 0.63 - ETA: 0s - loss: 0.8741 - accuracy: 0.61 - ETA: 0s - loss: 0.8775 - accuracy: 0.61 - ETA: 0s - loss: 0.8828 - accuracy: 0.61 - ETA: 0s - loss: 0.8840 - accuracy: 0.61 - ETA: 0s - loss: 0.8852 - accuracy: 0.6107\n",
      "Epoch 00429: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8852 - accuracy: 0.6107 - val_loss: 1.0374 - val_accuracy: 0.4826 - lr: 0.0010\n",
      "Epoch 430/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9368 - accuracy: 0.55 - ETA: 0s - loss: 0.9167 - accuracy: 0.57 - ETA: 0s - loss: 0.9239 - accuracy: 0.57 - ETA: 0s - loss: 0.8944 - accuracy: 0.59 - ETA: 0s - loss: 0.8906 - accuracy: 0.60 - ETA: 0s - loss: 0.8810 - accuracy: 0.61 - ETA: 0s - loss: 0.8784 - accuracy: 0.61 - ETA: 0s - loss: 0.8785 - accuracy: 0.62 - ETA: 0s - loss: 0.8794 - accuracy: 0.61 - ETA: 0s - loss: 0.8838 - accuracy: 0.61 - ETA: 0s - loss: 0.8776 - accuracy: 0.61 - ETA: 0s - loss: 0.8705 - accuracy: 0.62 - ETA: 0s - loss: 0.8533 - accuracy: 0.64 - ETA: 0s - loss: 0.8632 - accuracy: 0.63 - ETA: 0s - loss: 0.8792 - accuracy: 0.61 - ETA: 0s - loss: 0.8812 - accuracy: 0.61 - ETA: 0s - loss: 0.8877 - accuracy: 0.60 - ETA: 0s - loss: 0.8893 - accuracy: 0.61 - ETA: 0s - loss: 0.8906 - accuracy: 0.6094\n",
      "Epoch 00430: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8906 - accuracy: 0.6094 - val_loss: 1.0432 - val_accuracy: 0.4780 - lr: 0.0010\n",
      "Epoch 431/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9443 - accuracy: 0.53 - ETA: 0s - loss: 0.9290 - accuracy: 0.55 - ETA: 0s - loss: 0.9279 - accuracy: 0.56 - ETA: 0s - loss: 0.8963 - accuracy: 0.59 - ETA: 0s - loss: 0.8915 - accuracy: 0.59 - ETA: 0s - loss: 0.8818 - accuracy: 0.61 - ETA: 0s - loss: 0.8783 - accuracy: 0.61 - ETA: 0s - loss: 0.8782 - accuracy: 0.61 - ETA: 0s - loss: 0.8790 - accuracy: 0.61 - ETA: 0s - loss: 0.8839 - accuracy: 0.61 - ETA: 0s - loss: 0.8775 - accuracy: 0.61 - ETA: 0s - loss: 0.8715 - accuracy: 0.62 - ETA: 0s - loss: 0.8542 - accuracy: 0.63 - ETA: 0s - loss: 0.8646 - accuracy: 0.62 - ETA: 0s - loss: 0.8784 - accuracy: 0.61 - ETA: 0s - loss: 0.8810 - accuracy: 0.61 - ETA: 0s - loss: 0.8868 - accuracy: 0.61 - ETA: 0s - loss: 0.8880 - accuracy: 0.61 - ETA: 0s - loss: 0.8891 - accuracy: 0.6097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00431: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00431: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8891 - accuracy: 0.6097 - val_loss: 1.0366 - val_accuracy: 0.4818 - lr: 0.0010\n",
      "Epoch 432/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9439 - accuracy: 0.56 - ETA: 0s - loss: 0.9195 - accuracy: 0.57 - ETA: 0s - loss: 0.9274 - accuracy: 0.56 - ETA: 0s - loss: 0.8950 - accuracy: 0.59 - ETA: 0s - loss: 0.8908 - accuracy: 0.60 - ETA: 0s - loss: 0.8791 - accuracy: 0.61 - ETA: 0s - loss: 0.8772 - accuracy: 0.61 - ETA: 0s - loss: 0.8760 - accuracy: 0.62 - ETA: 0s - loss: 0.8781 - accuracy: 0.61 - ETA: 0s - loss: 0.8843 - accuracy: 0.61 - ETA: 0s - loss: 0.8771 - accuracy: 0.62 - ETA: 0s - loss: 0.8717 - accuracy: 0.62 - ETA: 0s - loss: 0.8542 - accuracy: 0.64 - ETA: 0s - loss: 0.8622 - accuracy: 0.63 - ETA: 0s - loss: 0.8768 - accuracy: 0.61 - ETA: 0s - loss: 0.8792 - accuracy: 0.61 - ETA: 0s - loss: 0.8853 - accuracy: 0.60 - ETA: 0s - loss: 0.8863 - accuracy: 0.60 - ETA: 0s - loss: 0.8878 - accuracy: 0.6081\n",
      "Epoch 00432: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8878 - accuracy: 0.6081 - val_loss: 1.0372 - val_accuracy: 0.4860 - lr: 0.0010\n",
      "Epoch 433/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9644 - accuracy: 0.52 - ETA: 0s - loss: 0.9446 - accuracy: 0.54 - ETA: 0s - loss: 0.9403 - accuracy: 0.55 - ETA: 0s - loss: 0.9064 - accuracy: 0.58 - ETA: 0s - loss: 0.8990 - accuracy: 0.59 - ETA: 0s - loss: 0.8871 - accuracy: 0.60 - ETA: 0s - loss: 0.8831 - accuracy: 0.61 - ETA: 0s - loss: 0.8814 - accuracy: 0.61 - ETA: 0s - loss: 0.8827 - accuracy: 0.61 - ETA: 0s - loss: 0.8869 - accuracy: 0.60 - ETA: 0s - loss: 0.8807 - accuracy: 0.61 - ETA: 0s - loss: 0.8739 - accuracy: 0.62 - ETA: 0s - loss: 0.8560 - accuracy: 0.64 - ETA: 0s - loss: 0.8642 - accuracy: 0.63 - ETA: 0s - loss: 0.8801 - accuracy: 0.61 - ETA: 0s - loss: 0.8826 - accuracy: 0.61 - ETA: 0s - loss: 0.8882 - accuracy: 0.61 - ETA: 0s - loss: 0.8892 - accuracy: 0.61 - ETA: 0s - loss: 0.8901 - accuracy: 0.6107\n",
      "Epoch 00433: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8901 - accuracy: 0.6107 - val_loss: 1.0337 - val_accuracy: 0.4845 - lr: 0.0010\n",
      "Epoch 434/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9534 - accuracy: 0.54 - ETA: 0s - loss: 0.9255 - accuracy: 0.56 - ETA: 0s - loss: 0.9314 - accuracy: 0.56 - ETA: 0s - loss: 0.8965 - accuracy: 0.59 - ETA: 0s - loss: 0.8926 - accuracy: 0.59 - ETA: 0s - loss: 0.8817 - accuracy: 0.61 - ETA: 0s - loss: 0.8782 - accuracy: 0.61 - ETA: 0s - loss: 0.8782 - accuracy: 0.61 - ETA: 0s - loss: 0.8793 - accuracy: 0.61 - ETA: 0s - loss: 0.8841 - accuracy: 0.61 - ETA: 0s - loss: 0.8777 - accuracy: 0.61 - ETA: 0s - loss: 0.8713 - accuracy: 0.62 - ETA: 0s - loss: 0.8535 - accuracy: 0.64 - ETA: 0s - loss: 0.8625 - accuracy: 0.63 - ETA: 0s - loss: 0.8781 - accuracy: 0.61 - ETA: 0s - loss: 0.8812 - accuracy: 0.61 - ETA: 0s - loss: 0.8860 - accuracy: 0.61 - ETA: 0s - loss: 0.8878 - accuracy: 0.61 - ETA: 0s - loss: 0.8889 - accuracy: 0.6101\n",
      "Epoch 00434: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8889 - accuracy: 0.6101 - val_loss: 1.0420 - val_accuracy: 0.4848 - lr: 0.0010\n",
      "Epoch 435/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9342 - accuracy: 0.54 - ETA: 0s - loss: 0.9208 - accuracy: 0.56 - ETA: 0s - loss: 0.9266 - accuracy: 0.56 - ETA: 0s - loss: 0.8955 - accuracy: 0.59 - ETA: 0s - loss: 0.8897 - accuracy: 0.60 - ETA: 0s - loss: 0.8783 - accuracy: 0.61 - ETA: 0s - loss: 0.8756 - accuracy: 0.61 - ETA: 0s - loss: 0.8753 - accuracy: 0.62 - ETA: 0s - loss: 0.8750 - accuracy: 0.61 - ETA: 0s - loss: 0.8793 - accuracy: 0.61 - ETA: 0s - loss: 0.8734 - accuracy: 0.62 - ETA: 0s - loss: 0.8670 - accuracy: 0.62 - ETA: 0s - loss: 0.8496 - accuracy: 0.64 - ETA: 0s - loss: 0.8585 - accuracy: 0.63 - ETA: 0s - loss: 0.8744 - accuracy: 0.61 - ETA: 0s - loss: 0.8767 - accuracy: 0.61 - ETA: 0s - loss: 0.8825 - accuracy: 0.61 - ETA: 0s - loss: 0.8841 - accuracy: 0.61 - ETA: 0s - loss: 0.8861 - accuracy: 0.6106\n",
      "Epoch 00435: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8861 - accuracy: 0.6106 - val_loss: 1.0426 - val_accuracy: 0.4824 - lr: 0.0010\n",
      "Epoch 436/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9421 - accuracy: 0.52 - ETA: 0s - loss: 0.9201 - accuracy: 0.55 - ETA: 0s - loss: 0.9217 - accuracy: 0.56 - ETA: 0s - loss: 0.8917 - accuracy: 0.58 - ETA: 0s - loss: 0.8876 - accuracy: 0.59 - ETA: 0s - loss: 0.8768 - accuracy: 0.61 - ETA: 0s - loss: 0.8744 - accuracy: 0.61 - ETA: 0s - loss: 0.8754 - accuracy: 0.61 - ETA: 0s - loss: 0.8761 - accuracy: 0.61 - ETA: 0s - loss: 0.8818 - accuracy: 0.60 - ETA: 0s - loss: 0.8759 - accuracy: 0.61 - ETA: 0s - loss: 0.8700 - accuracy: 0.62 - ETA: 0s - loss: 0.8522 - accuracy: 0.63 - ETA: 0s - loss: 0.8606 - accuracy: 0.62 - ETA: 0s - loss: 0.8778 - accuracy: 0.61 - ETA: 0s - loss: 0.8801 - accuracy: 0.61 - ETA: 0s - loss: 0.8844 - accuracy: 0.61 - ETA: 0s - loss: 0.8856 - accuracy: 0.61 - ETA: 0s - loss: 0.8873 - accuracy: 0.6097\n",
      "Epoch 00436: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8873 - accuracy: 0.6097 - val_loss: 1.0509 - val_accuracy: 0.4736 - lr: 0.0010\n",
      "Epoch 437/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9462 - accuracy: 0.54 - ETA: 0s - loss: 0.9221 - accuracy: 0.56 - ETA: 0s - loss: 0.9296 - accuracy: 0.56 - ETA: 0s - loss: 0.8964 - accuracy: 0.59 - ETA: 0s - loss: 0.8904 - accuracy: 0.60 - ETA: 0s - loss: 0.8794 - accuracy: 0.61 - ETA: 0s - loss: 0.8769 - accuracy: 0.62 - ETA: 0s - loss: 0.8773 - accuracy: 0.62 - ETA: 0s - loss: 0.8773 - accuracy: 0.62 - ETA: 0s - loss: 0.8819 - accuracy: 0.61 - ETA: 0s - loss: 0.8757 - accuracy: 0.61 - ETA: 0s - loss: 0.8700 - accuracy: 0.62 - ETA: 0s - loss: 0.8525 - accuracy: 0.64 - ETA: 0s - loss: 0.8614 - accuracy: 0.63 - ETA: 0s - loss: 0.8764 - accuracy: 0.61 - ETA: 0s - loss: 0.8791 - accuracy: 0.61 - ETA: 0s - loss: 0.8848 - accuracy: 0.61 - ETA: 0s - loss: 0.8855 - accuracy: 0.61 - ETA: 0s - loss: 0.8870 - accuracy: 0.6103\n",
      "Epoch 00437: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8870 - accuracy: 0.6103 - val_loss: 1.0506 - val_accuracy: 0.4717 - lr: 0.0010\n",
      "Epoch 438/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9474 - accuracy: 0.54 - ETA: 0s - loss: 0.9239 - accuracy: 0.56 - ETA: 0s - loss: 0.9305 - accuracy: 0.56 - ETA: 0s - loss: 0.9012 - accuracy: 0.59 - ETA: 0s - loss: 0.8985 - accuracy: 0.59 - ETA: 0s - loss: 0.8874 - accuracy: 0.61 - ETA: 0s - loss: 0.8826 - accuracy: 0.61 - ETA: 0s - loss: 0.8810 - accuracy: 0.61 - ETA: 0s - loss: 0.8824 - accuracy: 0.61 - ETA: 0s - loss: 0.8858 - accuracy: 0.60 - ETA: 0s - loss: 0.8810 - accuracy: 0.61 - ETA: 0s - loss: 0.8751 - accuracy: 0.62 - ETA: 0s - loss: 0.8577 - accuracy: 0.63 - ETA: 0s - loss: 0.8652 - accuracy: 0.62 - ETA: 0s - loss: 0.8786 - accuracy: 0.61 - ETA: 0s - loss: 0.8805 - accuracy: 0.61 - ETA: 0s - loss: 0.8858 - accuracy: 0.60 - ETA: 0s - loss: 0.8872 - accuracy: 0.60 - ETA: 0s - loss: 0.8889 - accuracy: 0.6080\n",
      "Epoch 00438: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8889 - accuracy: 0.6080 - val_loss: 1.0394 - val_accuracy: 0.4793 - lr: 0.0010\n",
      "Epoch 439/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9411 - accuracy: 0.53 - ETA: 0s - loss: 0.9211 - accuracy: 0.56 - ETA: 0s - loss: 0.9302 - accuracy: 0.56 - ETA: 0s - loss: 0.8984 - accuracy: 0.59 - ETA: 0s - loss: 0.8916 - accuracy: 0.59 - ETA: 0s - loss: 0.8785 - accuracy: 0.61 - ETA: 0s - loss: 0.8754 - accuracy: 0.61 - ETA: 0s - loss: 0.8753 - accuracy: 0.61 - ETA: 0s - loss: 0.8751 - accuracy: 0.61 - ETA: 0s - loss: 0.8806 - accuracy: 0.61 - ETA: 0s - loss: 0.8749 - accuracy: 0.62 - ETA: 0s - loss: 0.8697 - accuracy: 0.62 - ETA: 0s - loss: 0.8522 - accuracy: 0.64 - ETA: 0s - loss: 0.8593 - accuracy: 0.63 - ETA: 0s - loss: 0.8756 - accuracy: 0.61 - ETA: 0s - loss: 0.8780 - accuracy: 0.61 - ETA: 0s - loss: 0.8833 - accuracy: 0.61 - ETA: 0s - loss: 0.8842 - accuracy: 0.61 - ETA: 0s - loss: 0.8860 - accuracy: 0.6106\n",
      "Epoch 00439: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8860 - accuracy: 0.6106 - val_loss: 1.0394 - val_accuracy: 0.4793 - lr: 0.0010\n",
      "Epoch 440/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9511 - accuracy: 0.54 - ETA: 0s - loss: 0.9290 - accuracy: 0.56 - ETA: 0s - loss: 0.9322 - accuracy: 0.56 - ETA: 0s - loss: 0.9005 - accuracy: 0.59 - ETA: 0s - loss: 0.8953 - accuracy: 0.60 - ETA: 0s - loss: 0.8835 - accuracy: 0.61 - ETA: 0s - loss: 0.8797 - accuracy: 0.61 - ETA: 0s - loss: 0.8797 - accuracy: 0.62 - ETA: 0s - loss: 0.8808 - accuracy: 0.61 - ETA: 0s - loss: 0.8862 - accuracy: 0.61 - ETA: 0s - loss: 0.8797 - accuracy: 0.61 - ETA: 0s - loss: 0.8726 - accuracy: 0.62 - ETA: 0s - loss: 0.8544 - accuracy: 0.64 - ETA: 0s - loss: 0.8628 - accuracy: 0.63 - ETA: 0s - loss: 0.8771 - accuracy: 0.61 - ETA: 0s - loss: 0.8796 - accuracy: 0.61 - ETA: 0s - loss: 0.8848 - accuracy: 0.61 - ETA: 0s - loss: 0.8869 - accuracy: 0.61 - ETA: 0s - loss: 0.8882 - accuracy: 0.6110\n",
      "Epoch 00440: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8882 - accuracy: 0.6110 - val_loss: 1.0471 - val_accuracy: 0.4736 - lr: 0.0010\n",
      "Epoch 441/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9315 - accuracy: 0.55 - ETA: 0s - loss: 0.9206 - accuracy: 0.56 - ETA: 0s - loss: 0.9256 - accuracy: 0.56 - ETA: 0s - loss: 0.8944 - accuracy: 0.59 - ETA: 0s - loss: 0.8891 - accuracy: 0.60 - ETA: 0s - loss: 0.8773 - accuracy: 0.61 - ETA: 0s - loss: 0.8740 - accuracy: 0.62 - ETA: 0s - loss: 0.8735 - accuracy: 0.62 - ETA: 0s - loss: 0.8747 - accuracy: 0.62 - ETA: 0s - loss: 0.8801 - accuracy: 0.61 - ETA: 0s - loss: 0.8745 - accuracy: 0.61 - ETA: 0s - loss: 0.8689 - accuracy: 0.62 - ETA: 0s - loss: 0.8512 - accuracy: 0.63 - ETA: 0s - loss: 0.8601 - accuracy: 0.63 - ETA: 0s - loss: 0.8752 - accuracy: 0.61 - ETA: 0s - loss: 0.8777 - accuracy: 0.61 - ETA: 0s - loss: 0.8840 - accuracy: 0.60 - ETA: 0s - loss: 0.8854 - accuracy: 0.61 - ETA: 0s - loss: 0.8870 - accuracy: 0.6087\n",
      "Epoch 00441: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8870 - accuracy: 0.6087 - val_loss: 1.0361 - val_accuracy: 0.4829 - lr: 0.0010\n",
      "Epoch 442/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9162 - accuracy: 0.55 - ETA: 0s - loss: 0.9060 - accuracy: 0.57 - ETA: 0s - loss: 0.9148 - accuracy: 0.57 - ETA: 0s - loss: 0.8876 - accuracy: 0.59 - ETA: 0s - loss: 0.8845 - accuracy: 0.60 - ETA: 0s - loss: 0.8743 - accuracy: 0.61 - ETA: 0s - loss: 0.8724 - accuracy: 0.62 - ETA: 0s - loss: 0.8721 - accuracy: 0.62 - ETA: 0s - loss: 0.8743 - accuracy: 0.62 - ETA: 0s - loss: 0.8805 - accuracy: 0.61 - ETA: 0s - loss: 0.8743 - accuracy: 0.62 - ETA: 0s - loss: 0.8689 - accuracy: 0.62 - ETA: 0s - loss: 0.8516 - accuracy: 0.64 - ETA: 0s - loss: 0.8602 - accuracy: 0.63 - ETA: 0s - loss: 0.8754 - accuracy: 0.62 - ETA: 0s - loss: 0.8774 - accuracy: 0.61 - ETA: 0s - loss: 0.8821 - accuracy: 0.61 - ETA: 0s - loss: 0.8845 - accuracy: 0.61 - ETA: 0s - loss: 0.8853 - accuracy: 0.6136\n",
      "Epoch 00442: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8853 - accuracy: 0.6136 - val_loss: 1.0416 - val_accuracy: 0.4793 - lr: 0.0010\n",
      "Epoch 443/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9457 - accuracy: 0.53 - ETA: 0s - loss: 0.9229 - accuracy: 0.56 - ETA: 0s - loss: 0.9310 - accuracy: 0.56 - ETA: 0s - loss: 0.8990 - accuracy: 0.58 - ETA: 0s - loss: 0.8933 - accuracy: 0.59 - ETA: 0s - loss: 0.8814 - accuracy: 0.61 - ETA: 0s - loss: 0.8779 - accuracy: 0.61 - ETA: 0s - loss: 0.8779 - accuracy: 0.61 - ETA: 0s - loss: 0.8788 - accuracy: 0.61 - ETA: 0s - loss: 0.8829 - accuracy: 0.60 - ETA: 0s - loss: 0.8769 - accuracy: 0.61 - ETA: 0s - loss: 0.8707 - accuracy: 0.62 - ETA: 0s - loss: 0.8533 - accuracy: 0.63 - ETA: 0s - loss: 0.8614 - accuracy: 0.63 - ETA: 0s - loss: 0.8770 - accuracy: 0.61 - ETA: 0s - loss: 0.8790 - accuracy: 0.61 - ETA: 0s - loss: 0.8843 - accuracy: 0.61 - ETA: 0s - loss: 0.8855 - accuracy: 0.61 - ETA: 0s - loss: 0.8873 - accuracy: 0.6086\n",
      "Epoch 00443: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8873 - accuracy: 0.6086 - val_loss: 1.0459 - val_accuracy: 0.4778 - lr: 0.0010\n",
      "Epoch 444/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9468 - accuracy: 0.53 - ETA: 0s - loss: 0.9241 - accuracy: 0.56 - ETA: 0s - loss: 0.9257 - accuracy: 0.56 - ETA: 0s - loss: 0.8940 - accuracy: 0.59 - ETA: 0s - loss: 0.8892 - accuracy: 0.60 - ETA: 0s - loss: 0.8767 - accuracy: 0.61 - ETA: 0s - loss: 0.8750 - accuracy: 0.61 - ETA: 0s - loss: 0.8743 - accuracy: 0.61 - ETA: 0s - loss: 0.8744 - accuracy: 0.61 - ETA: 0s - loss: 0.8797 - accuracy: 0.61 - ETA: 0s - loss: 0.8738 - accuracy: 0.62 - ETA: 0s - loss: 0.8676 - accuracy: 0.62 - ETA: 0s - loss: 0.8500 - accuracy: 0.64 - ETA: 0s - loss: 0.8592 - accuracy: 0.63 - ETA: 0s - loss: 0.8758 - accuracy: 0.61 - ETA: 0s - loss: 0.8784 - accuracy: 0.61 - ETA: 0s - loss: 0.8843 - accuracy: 0.61 - ETA: 0s - loss: 0.8854 - accuracy: 0.61 - ETA: 0s - loss: 0.8864 - accuracy: 0.6100\n",
      "Epoch 00444: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8864 - accuracy: 0.6100 - val_loss: 1.0498 - val_accuracy: 0.4801 - lr: 0.0010\n",
      "Epoch 445/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9397 - accuracy: 0.53 - ETA: 0s - loss: 0.9272 - accuracy: 0.55 - ETA: 0s - loss: 0.9300 - accuracy: 0.55 - ETA: 0s - loss: 0.8980 - accuracy: 0.58 - ETA: 0s - loss: 0.8937 - accuracy: 0.59 - ETA: 0s - loss: 0.8814 - accuracy: 0.61 - ETA: 0s - loss: 0.8793 - accuracy: 0.61 - ETA: 0s - loss: 0.8803 - accuracy: 0.61 - ETA: 0s - loss: 0.8814 - accuracy: 0.61 - ETA: 0s - loss: 0.8850 - accuracy: 0.60 - ETA: 0s - loss: 0.8783 - accuracy: 0.61 - ETA: 0s - loss: 0.8708 - accuracy: 0.62 - ETA: 0s - loss: 0.8532 - accuracy: 0.63 - ETA: 0s - loss: 0.8616 - accuracy: 0.62 - ETA: 0s - loss: 0.8784 - accuracy: 0.61 - ETA: 0s - loss: 0.8802 - accuracy: 0.61 - ETA: 0s - loss: 0.8861 - accuracy: 0.60 - ETA: 0s - loss: 0.8873 - accuracy: 0.60 - ETA: 0s - loss: 0.8889 - accuracy: 0.6084\n",
      "Epoch 00445: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00445: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8889 - accuracy: 0.6084 - val_loss: 1.0640 - val_accuracy: 0.4717 - lr: 0.0010\n",
      "Epoch 446/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9348 - accuracy: 0.53 - ETA: 0s - loss: 0.9155 - accuracy: 0.56 - ETA: 0s - loss: 0.9247 - accuracy: 0.56 - ETA: 0s - loss: 0.8940 - accuracy: 0.59 - ETA: 0s - loss: 0.8907 - accuracy: 0.59 - ETA: 0s - loss: 0.8797 - accuracy: 0.61 - ETA: 0s - loss: 0.8778 - accuracy: 0.61 - ETA: 0s - loss: 0.8778 - accuracy: 0.61 - ETA: 0s - loss: 0.8779 - accuracy: 0.61 - ETA: 0s - loss: 0.8804 - accuracy: 0.60 - ETA: 0s - loss: 0.8751 - accuracy: 0.61 - ETA: 0s - loss: 0.8688 - accuracy: 0.62 - ETA: 0s - loss: 0.8511 - accuracy: 0.63 - ETA: 0s - loss: 0.8599 - accuracy: 0.62 - ETA: 0s - loss: 0.8746 - accuracy: 0.61 - ETA: 0s - loss: 0.8767 - accuracy: 0.61 - ETA: 0s - loss: 0.8824 - accuracy: 0.60 - ETA: 0s - loss: 0.8839 - accuracy: 0.60 - ETA: 0s - loss: 0.8852 - accuracy: 0.6082\n",
      "Epoch 00446: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8852 - accuracy: 0.6082 - val_loss: 1.0773 - val_accuracy: 0.4627 - lr: 0.0010\n",
      "Epoch 447/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9351 - accuracy: 0.54 - ETA: 0s - loss: 0.9172 - accuracy: 0.56 - ETA: 0s - loss: 0.9237 - accuracy: 0.56 - ETA: 0s - loss: 0.8922 - accuracy: 0.59 - ETA: 0s - loss: 0.8907 - accuracy: 0.59 - ETA: 0s - loss: 0.8774 - accuracy: 0.61 - ETA: 0s - loss: 0.8751 - accuracy: 0.61 - ETA: 0s - loss: 0.8748 - accuracy: 0.62 - ETA: 0s - loss: 0.8750 - accuracy: 0.62 - ETA: 0s - loss: 0.8803 - accuracy: 0.61 - ETA: 0s - loss: 0.8740 - accuracy: 0.62 - ETA: 0s - loss: 0.8676 - accuracy: 0.62 - ETA: 0s - loss: 0.8507 - accuracy: 0.64 - ETA: 0s - loss: 0.8583 - accuracy: 0.63 - ETA: 0s - loss: 0.8733 - accuracy: 0.61 - ETA: 0s - loss: 0.8752 - accuracy: 0.61 - ETA: 0s - loss: 0.8820 - accuracy: 0.61 - ETA: 0s - loss: 0.8835 - accuracy: 0.61 - ETA: 0s - loss: 0.8848 - accuracy: 0.6101\n",
      "Epoch 00447: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8848 - accuracy: 0.6101 - val_loss: 1.0611 - val_accuracy: 0.4664 - lr: 0.0010\n",
      "Epoch 448/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9383 - accuracy: 0.54 - ETA: 0s - loss: 0.9160 - accuracy: 0.56 - ETA: 0s - loss: 0.9185 - accuracy: 0.56 - ETA: 0s - loss: 0.8882 - accuracy: 0.59 - ETA: 0s - loss: 0.8823 - accuracy: 0.60 - ETA: 0s - loss: 0.8722 - accuracy: 0.61 - ETA: 0s - loss: 0.8708 - accuracy: 0.62 - ETA: 0s - loss: 0.8722 - accuracy: 0.62 - ETA: 0s - loss: 0.8723 - accuracy: 0.61 - ETA: 0s - loss: 0.8771 - accuracy: 0.61 - ETA: 0s - loss: 0.8720 - accuracy: 0.62 - ETA: 0s - loss: 0.8656 - accuracy: 0.62 - ETA: 0s - loss: 0.8487 - accuracy: 0.64 - ETA: 0s - loss: 0.8572 - accuracy: 0.63 - ETA: 0s - loss: 0.8716 - accuracy: 0.61 - ETA: 0s - loss: 0.8746 - accuracy: 0.61 - ETA: 0s - loss: 0.8804 - accuracy: 0.61 - ETA: 0s - loss: 0.8819 - accuracy: 0.61 - ETA: 0s - loss: 0.8831 - accuracy: 0.6102\n",
      "Epoch 00448: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8831 - accuracy: 0.6102 - val_loss: 1.0609 - val_accuracy: 0.4666 - lr: 0.0010\n",
      "Epoch 449/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9404 - accuracy: 0.55 - ETA: 0s - loss: 0.9191 - accuracy: 0.56 - ETA: 0s - loss: 0.9227 - accuracy: 0.57 - ETA: 0s - loss: 0.8908 - accuracy: 0.59 - ETA: 0s - loss: 0.8888 - accuracy: 0.60 - ETA: 0s - loss: 0.8771 - accuracy: 0.61 - ETA: 0s - loss: 0.8744 - accuracy: 0.62 - ETA: 0s - loss: 0.8749 - accuracy: 0.62 - ETA: 0s - loss: 0.8761 - accuracy: 0.62 - ETA: 0s - loss: 0.8793 - accuracy: 0.61 - ETA: 0s - loss: 0.8739 - accuracy: 0.62 - ETA: 0s - loss: 0.8670 - accuracy: 0.62 - ETA: 0s - loss: 0.8496 - accuracy: 0.64 - ETA: 0s - loss: 0.8583 - accuracy: 0.63 - ETA: 0s - loss: 0.8717 - accuracy: 0.62 - ETA: 0s - loss: 0.8740 - accuracy: 0.61 - ETA: 0s - loss: 0.8796 - accuracy: 0.61 - ETA: 0s - loss: 0.8810 - accuracy: 0.61 - ETA: 0s - loss: 0.8829 - accuracy: 0.6131\n",
      "Epoch 00449: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8829 - accuracy: 0.6131 - val_loss: 1.0633 - val_accuracy: 0.4661 - lr: 0.0010\n",
      "Epoch 450/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9332 - accuracy: 0.54 - ETA: 0s - loss: 0.9165 - accuracy: 0.56 - ETA: 0s - loss: 0.9216 - accuracy: 0.56 - ETA: 0s - loss: 0.8892 - accuracy: 0.59 - ETA: 0s - loss: 0.8849 - accuracy: 0.60 - ETA: 0s - loss: 0.8735 - accuracy: 0.61 - ETA: 0s - loss: 0.8706 - accuracy: 0.62 - ETA: 0s - loss: 0.8694 - accuracy: 0.62 - ETA: 0s - loss: 0.8706 - accuracy: 0.62 - ETA: 0s - loss: 0.8764 - accuracy: 0.61 - ETA: 0s - loss: 0.8704 - accuracy: 0.62 - ETA: 0s - loss: 0.8641 - accuracy: 0.63 - ETA: 0s - loss: 0.8475 - accuracy: 0.64 - ETA: 0s - loss: 0.8555 - accuracy: 0.63 - ETA: 0s - loss: 0.8707 - accuracy: 0.62 - ETA: 0s - loss: 0.8730 - accuracy: 0.61 - ETA: 0s - loss: 0.8794 - accuracy: 0.61 - ETA: 0s - loss: 0.8808 - accuracy: 0.61 - ETA: 0s - loss: 0.8826 - accuracy: 0.6116\n",
      "Epoch 00450: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8826 - accuracy: 0.6116 - val_loss: 1.0722 - val_accuracy: 0.4575 - lr: 0.0010\n",
      "Epoch 451/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9126 - accuracy: 0.56 - ETA: 0s - loss: 0.9008 - accuracy: 0.57 - ETA: 0s - loss: 0.9128 - accuracy: 0.57 - ETA: 0s - loss: 0.8862 - accuracy: 0.60 - ETA: 0s - loss: 0.8832 - accuracy: 0.60 - ETA: 0s - loss: 0.8740 - accuracy: 0.61 - ETA: 0s - loss: 0.8715 - accuracy: 0.62 - ETA: 0s - loss: 0.8716 - accuracy: 0.62 - ETA: 0s - loss: 0.8733 - accuracy: 0.62 - ETA: 0s - loss: 0.8775 - accuracy: 0.61 - ETA: 0s - loss: 0.8720 - accuracy: 0.62 - ETA: 0s - loss: 0.8662 - accuracy: 0.62 - ETA: 0s - loss: 0.8486 - accuracy: 0.64 - ETA: 0s - loss: 0.8566 - accuracy: 0.63 - ETA: 0s - loss: 0.8725 - accuracy: 0.62 - ETA: 0s - loss: 0.8746 - accuracy: 0.61 - ETA: 0s - loss: 0.8798 - accuracy: 0.61 - ETA: 0s - loss: 0.8811 - accuracy: 0.61 - ETA: 0s - loss: 0.8833 - accuracy: 0.6127\n",
      "Epoch 00451: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8833 - accuracy: 0.6127 - val_loss: 1.0749 - val_accuracy: 0.4542 - lr: 0.0010\n",
      "Epoch 452/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9358 - accuracy: 0.54 - ETA: 0s - loss: 0.9209 - accuracy: 0.56 - ETA: 0s - loss: 0.9258 - accuracy: 0.56 - ETA: 0s - loss: 0.8907 - accuracy: 0.59 - ETA: 0s - loss: 0.8868 - accuracy: 0.60 - ETA: 0s - loss: 0.8767 - accuracy: 0.61 - ETA: 0s - loss: 0.8748 - accuracy: 0.61 - ETA: 0s - loss: 0.8742 - accuracy: 0.62 - ETA: 0s - loss: 0.8747 - accuracy: 0.61 - ETA: 0s - loss: 0.8793 - accuracy: 0.60 - ETA: 0s - loss: 0.8736 - accuracy: 0.61 - ETA: 0s - loss: 0.8667 - accuracy: 0.62 - ETA: 0s - loss: 0.8487 - accuracy: 0.64 - ETA: 0s - loss: 0.8571 - accuracy: 0.63 - ETA: 0s - loss: 0.8720 - accuracy: 0.61 - ETA: 0s - loss: 0.8746 - accuracy: 0.61 - ETA: 0s - loss: 0.8810 - accuracy: 0.61 - ETA: 0s - loss: 0.8827 - accuracy: 0.60 - ETA: 0s - loss: 0.8848 - accuracy: 0.6084\n",
      "Epoch 00452: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8848 - accuracy: 0.6084 - val_loss: 1.0788 - val_accuracy: 0.4531 - lr: 0.0010\n",
      "Epoch 453/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9435 - accuracy: 0.54 - ETA: 0s - loss: 0.9238 - accuracy: 0.56 - ETA: 0s - loss: 0.9330 - accuracy: 0.56 - ETA: 0s - loss: 0.9005 - accuracy: 0.59 - ETA: 0s - loss: 0.8947 - accuracy: 0.59 - ETA: 0s - loss: 0.8831 - accuracy: 0.61 - ETA: 0s - loss: 0.8801 - accuracy: 0.61 - ETA: 0s - loss: 0.8783 - accuracy: 0.61 - ETA: 0s - loss: 0.8776 - accuracy: 0.61 - ETA: 0s - loss: 0.8833 - accuracy: 0.60 - ETA: 0s - loss: 0.8776 - accuracy: 0.61 - ETA: 0s - loss: 0.8709 - accuracy: 0.62 - ETA: 0s - loss: 0.8531 - accuracy: 0.63 - ETA: 0s - loss: 0.8606 - accuracy: 0.63 - ETA: 0s - loss: 0.8763 - accuracy: 0.61 - ETA: 0s - loss: 0.8787 - accuracy: 0.61 - ETA: 0s - loss: 0.8841 - accuracy: 0.61 - ETA: 0s - loss: 0.8855 - accuracy: 0.61 - ETA: 0s - loss: 0.8868 - accuracy: 0.6104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00453: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8868 - accuracy: 0.6104 - val_loss: 1.0716 - val_accuracy: 0.4601 - lr: 0.0010\n",
      "Epoch 454/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9516 - accuracy: 0.52 - ETA: 0s - loss: 0.9192 - accuracy: 0.55 - ETA: 0s - loss: 0.9248 - accuracy: 0.56 - ETA: 0s - loss: 0.8927 - accuracy: 0.59 - ETA: 0s - loss: 0.8878 - accuracy: 0.59 - ETA: 0s - loss: 0.8781 - accuracy: 0.61 - ETA: 0s - loss: 0.8769 - accuracy: 0.61 - ETA: 0s - loss: 0.8760 - accuracy: 0.61 - ETA: 0s - loss: 0.8760 - accuracy: 0.61 - ETA: 0s - loss: 0.8814 - accuracy: 0.60 - ETA: 0s - loss: 0.8755 - accuracy: 0.61 - ETA: 0s - loss: 0.8703 - accuracy: 0.62 - ETA: 0s - loss: 0.8527 - accuracy: 0.63 - ETA: 0s - loss: 0.8609 - accuracy: 0.62 - ETA: 0s - loss: 0.8762 - accuracy: 0.61 - ETA: 0s - loss: 0.8789 - accuracy: 0.61 - ETA: 0s - loss: 0.8836 - accuracy: 0.60 - ETA: 0s - loss: 0.8856 - accuracy: 0.60 - ETA: 0s - loss: 0.8873 - accuracy: 0.6087\n",
      "Epoch 00454: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8873 - accuracy: 0.6087 - val_loss: 1.0707 - val_accuracy: 0.4552 - lr: 0.0010\n",
      "Epoch 455/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9461 - accuracy: 0.54 - ETA: 0s - loss: 0.9230 - accuracy: 0.56 - ETA: 0s - loss: 0.9249 - accuracy: 0.56 - ETA: 0s - loss: 0.8951 - accuracy: 0.59 - ETA: 0s - loss: 0.8900 - accuracy: 0.59 - ETA: 0s - loss: 0.8809 - accuracy: 0.61 - ETA: 0s - loss: 0.8768 - accuracy: 0.61 - ETA: 0s - loss: 0.8763 - accuracy: 0.61 - ETA: 0s - loss: 0.8777 - accuracy: 0.61 - ETA: 0s - loss: 0.8827 - accuracy: 0.60 - ETA: 0s - loss: 0.8774 - accuracy: 0.61 - ETA: 0s - loss: 0.8714 - accuracy: 0.62 - ETA: 0s - loss: 0.8537 - accuracy: 0.63 - ETA: 0s - loss: 0.8625 - accuracy: 0.62 - ETA: 0s - loss: 0.8786 - accuracy: 0.61 - ETA: 0s - loss: 0.8810 - accuracy: 0.61 - ETA: 0s - loss: 0.8863 - accuracy: 0.61 - ETA: 0s - loss: 0.8878 - accuracy: 0.61 - ETA: 0s - loss: 0.8889 - accuracy: 0.6097\n",
      "Epoch 00455: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8889 - accuracy: 0.6097 - val_loss: 1.0584 - val_accuracy: 0.4702 - lr: 0.0010\n",
      "Epoch 456/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9256 - accuracy: 0.54 - ETA: 0s - loss: 0.9136 - accuracy: 0.56 - ETA: 0s - loss: 0.9212 - accuracy: 0.56 - ETA: 0s - loss: 0.8936 - accuracy: 0.59 - ETA: 0s - loss: 0.8917 - accuracy: 0.59 - ETA: 0s - loss: 0.8796 - accuracy: 0.61 - ETA: 0s - loss: 0.8761 - accuracy: 0.61 - ETA: 0s - loss: 0.8755 - accuracy: 0.61 - ETA: 0s - loss: 0.8752 - accuracy: 0.61 - ETA: 0s - loss: 0.8804 - accuracy: 0.60 - ETA: 0s - loss: 0.8748 - accuracy: 0.61 - ETA: 0s - loss: 0.8685 - accuracy: 0.62 - ETA: 0s - loss: 0.8514 - accuracy: 0.63 - ETA: 0s - loss: 0.8600 - accuracy: 0.62 - ETA: 0s - loss: 0.8744 - accuracy: 0.61 - ETA: 0s - loss: 0.8764 - accuracy: 0.61 - ETA: 0s - loss: 0.8829 - accuracy: 0.60 - ETA: 0s - loss: 0.8840 - accuracy: 0.60 - ETA: 0s - loss: 0.8855 - accuracy: 0.6086\n",
      "Epoch 00456: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8855 - accuracy: 0.6086 - val_loss: 1.0461 - val_accuracy: 0.4761 - lr: 0.0010\n",
      "Epoch 457/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9230 - accuracy: 0.54 - ETA: 0s - loss: 0.9211 - accuracy: 0.56 - ETA: 0s - loss: 0.9268 - accuracy: 0.56 - ETA: 0s - loss: 0.8991 - accuracy: 0.59 - ETA: 0s - loss: 0.8971 - accuracy: 0.59 - ETA: 0s - loss: 0.8849 - accuracy: 0.61 - ETA: 0s - loss: 0.8816 - accuracy: 0.61 - ETA: 0s - loss: 0.8828 - accuracy: 0.61 - ETA: 0s - loss: 0.8812 - accuracy: 0.61 - ETA: 0s - loss: 0.8860 - accuracy: 0.61 - ETA: 0s - loss: 0.8796 - accuracy: 0.61 - ETA: 0s - loss: 0.8733 - accuracy: 0.62 - ETA: 0s - loss: 0.8547 - accuracy: 0.64 - ETA: 0s - loss: 0.8627 - accuracy: 0.63 - ETA: 0s - loss: 0.8776 - accuracy: 0.61 - ETA: 0s - loss: 0.8807 - accuracy: 0.61 - ETA: 0s - loss: 0.8869 - accuracy: 0.61 - ETA: 0s - loss: 0.8887 - accuracy: 0.61 - ETA: 0s - loss: 0.8899 - accuracy: 0.6099\n",
      "Epoch 00457: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8899 - accuracy: 0.6099 - val_loss: 1.0412 - val_accuracy: 0.4814 - lr: 0.0010\n",
      "Epoch 458/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9131 - accuracy: 0.55 - ETA: 0s - loss: 0.9032 - accuracy: 0.57 - ETA: 0s - loss: 0.9110 - accuracy: 0.57 - ETA: 0s - loss: 0.8828 - accuracy: 0.59 - ETA: 0s - loss: 0.8818 - accuracy: 0.60 - ETA: 0s - loss: 0.8717 - accuracy: 0.61 - ETA: 0s - loss: 0.8699 - accuracy: 0.61 - ETA: 0s - loss: 0.8701 - accuracy: 0.62 - ETA: 0s - loss: 0.8718 - accuracy: 0.62 - ETA: 0s - loss: 0.8778 - accuracy: 0.61 - ETA: 0s - loss: 0.8725 - accuracy: 0.62 - ETA: 0s - loss: 0.8660 - accuracy: 0.62 - ETA: 0s - loss: 0.8488 - accuracy: 0.64 - ETA: 0s - loss: 0.8578 - accuracy: 0.63 - ETA: 0s - loss: 0.8729 - accuracy: 0.61 - ETA: 0s - loss: 0.8752 - accuracy: 0.61 - ETA: 0s - loss: 0.8811 - accuracy: 0.61 - ETA: 0s - loss: 0.8833 - accuracy: 0.61 - ETA: 0s - loss: 0.8851 - accuracy: 0.6107\n",
      "Epoch 00458: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8851 - accuracy: 0.6107 - val_loss: 1.0371 - val_accuracy: 0.4848 - lr: 0.0010\n",
      "Epoch 459/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9370 - accuracy: 0.54 - ETA: 0s - loss: 0.9123 - accuracy: 0.56 - ETA: 0s - loss: 0.9195 - accuracy: 0.57 - ETA: 0s - loss: 0.8905 - accuracy: 0.59 - ETA: 0s - loss: 0.8869 - accuracy: 0.60 - ETA: 0s - loss: 0.8750 - accuracy: 0.61 - ETA: 0s - loss: 0.8725 - accuracy: 0.62 - ETA: 0s - loss: 0.8728 - accuracy: 0.62 - ETA: 0s - loss: 0.8736 - accuracy: 0.62 - ETA: 0s - loss: 0.8781 - accuracy: 0.61 - ETA: 0s - loss: 0.8717 - accuracy: 0.62 - ETA: 0s - loss: 0.8665 - accuracy: 0.62 - ETA: 0s - loss: 0.8493 - accuracy: 0.64 - ETA: 0s - loss: 0.8589 - accuracy: 0.63 - ETA: 0s - loss: 0.8725 - accuracy: 0.61 - ETA: 0s - loss: 0.8752 - accuracy: 0.61 - ETA: 0s - loss: 0.8805 - accuracy: 0.61 - ETA: 0s - loss: 0.8815 - accuracy: 0.61 - ETA: 0s - loss: 0.8831 - accuracy: 0.6123\n",
      "Epoch 00459: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00459: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8831 - accuracy: 0.6123 - val_loss: 1.0465 - val_accuracy: 0.4774 - lr: 0.0010\n",
      "Epoch 460/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9308 - accuracy: 0.54 - ETA: 0s - loss: 0.9205 - accuracy: 0.56 - ETA: 0s - loss: 0.9247 - accuracy: 0.56 - ETA: 0s - loss: 0.8927 - accuracy: 0.59 - ETA: 0s - loss: 0.8910 - accuracy: 0.60 - ETA: 0s - loss: 0.8791 - accuracy: 0.61 - ETA: 0s - loss: 0.8761 - accuracy: 0.61 - ETA: 0s - loss: 0.8751 - accuracy: 0.62 - ETA: 0s - loss: 0.8760 - accuracy: 0.61 - ETA: 0s - loss: 0.8806 - accuracy: 0.61 - ETA: 0s - loss: 0.8751 - accuracy: 0.62 - ETA: 0s - loss: 0.8679 - accuracy: 0.62 - ETA: 0s - loss: 0.8503 - accuracy: 0.64 - ETA: 0s - loss: 0.8589 - accuracy: 0.63 - ETA: 0s - loss: 0.8739 - accuracy: 0.61 - ETA: 0s - loss: 0.8765 - accuracy: 0.61 - ETA: 0s - loss: 0.8822 - accuracy: 0.61 - ETA: 0s - loss: 0.8836 - accuracy: 0.61 - ETA: 0s - loss: 0.8850 - accuracy: 0.6099\n",
      "Epoch 00460: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8850 - accuracy: 0.6099 - val_loss: 1.0428 - val_accuracy: 0.4809 - lr: 0.0010\n",
      "Epoch 461/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9300 - accuracy: 0.54 - ETA: 0s - loss: 0.9130 - accuracy: 0.56 - ETA: 0s - loss: 0.9173 - accuracy: 0.57 - ETA: 0s - loss: 0.8883 - accuracy: 0.59 - ETA: 0s - loss: 0.8855 - accuracy: 0.60 - ETA: 0s - loss: 0.8750 - accuracy: 0.61 - ETA: 0s - loss: 0.8720 - accuracy: 0.62 - ETA: 0s - loss: 0.8727 - accuracy: 0.62 - ETA: 0s - loss: 0.8743 - accuracy: 0.61 - ETA: 0s - loss: 0.8806 - accuracy: 0.61 - ETA: 0s - loss: 0.8754 - accuracy: 0.61 - ETA: 0s - loss: 0.8698 - accuracy: 0.62 - ETA: 0s - loss: 0.8517 - accuracy: 0.63 - ETA: 0s - loss: 0.8589 - accuracy: 0.63 - ETA: 0s - loss: 0.8752 - accuracy: 0.61 - ETA: 0s - loss: 0.8786 - accuracy: 0.61 - ETA: 0s - loss: 0.8836 - accuracy: 0.60 - ETA: 0s - loss: 0.8853 - accuracy: 0.60 - ETA: 0s - loss: 0.8865 - accuracy: 0.6083\n",
      "Epoch 00461: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8865 - accuracy: 0.6083 - val_loss: 1.0562 - val_accuracy: 0.4702 - lr: 0.0010\n",
      "Epoch 462/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9314 - accuracy: 0.55 - ETA: 0s - loss: 0.9098 - accuracy: 0.57 - ETA: 0s - loss: 0.9216 - accuracy: 0.57 - ETA: 0s - loss: 0.8894 - accuracy: 0.60 - ETA: 0s - loss: 0.8844 - accuracy: 0.60 - ETA: 0s - loss: 0.8737 - accuracy: 0.62 - ETA: 0s - loss: 0.8730 - accuracy: 0.62 - ETA: 0s - loss: 0.8726 - accuracy: 0.62 - ETA: 0s - loss: 0.8734 - accuracy: 0.62 - ETA: 0s - loss: 0.8792 - accuracy: 0.61 - ETA: 0s - loss: 0.8731 - accuracy: 0.62 - ETA: 0s - loss: 0.8666 - accuracy: 0.62 - ETA: 0s - loss: 0.8493 - accuracy: 0.64 - ETA: 0s - loss: 0.8586 - accuracy: 0.63 - ETA: 0s - loss: 0.8733 - accuracy: 0.61 - ETA: 0s - loss: 0.8747 - accuracy: 0.61 - ETA: 0s - loss: 0.8802 - accuracy: 0.61 - ETA: 0s - loss: 0.8819 - accuracy: 0.61 - ETA: 0s - loss: 0.8826 - accuracy: 0.6105\n",
      "Epoch 00462: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8826 - accuracy: 0.6105 - val_loss: 1.0588 - val_accuracy: 0.4707 - lr: 0.0010\n",
      "Epoch 463/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9426 - accuracy: 0.54 - ETA: 0s - loss: 0.9140 - accuracy: 0.56 - ETA: 0s - loss: 0.9199 - accuracy: 0.57 - ETA: 0s - loss: 0.8875 - accuracy: 0.59 - ETA: 0s - loss: 0.8840 - accuracy: 0.60 - ETA: 0s - loss: 0.8738 - accuracy: 0.61 - ETA: 0s - loss: 0.8711 - accuracy: 0.62 - ETA: 0s - loss: 0.8704 - accuracy: 0.62 - ETA: 0s - loss: 0.8729 - accuracy: 0.61 - ETA: 0s - loss: 0.8796 - accuracy: 0.61 - ETA: 0s - loss: 0.8747 - accuracy: 0.61 - ETA: 0s - loss: 0.8690 - accuracy: 0.62 - ETA: 0s - loss: 0.8507 - accuracy: 0.63 - ETA: 0s - loss: 0.8593 - accuracy: 0.62 - ETA: 0s - loss: 0.8742 - accuracy: 0.61 - ETA: 0s - loss: 0.8770 - accuracy: 0.61 - ETA: 0s - loss: 0.8820 - accuracy: 0.60 - ETA: 0s - loss: 0.8831 - accuracy: 0.60 - ETA: 0s - loss: 0.8842 - accuracy: 0.6082\n",
      "Epoch 00463: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8842 - accuracy: 0.6082 - val_loss: 1.0448 - val_accuracy: 0.4783 - lr: 0.0010\n",
      "Epoch 464/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9228 - accuracy: 0.55 - ETA: 0s - loss: 0.9103 - accuracy: 0.57 - ETA: 0s - loss: 0.9202 - accuracy: 0.57 - ETA: 0s - loss: 0.8897 - accuracy: 0.60 - ETA: 0s - loss: 0.8861 - accuracy: 0.60 - ETA: 0s - loss: 0.8753 - accuracy: 0.62 - ETA: 0s - loss: 0.8721 - accuracy: 0.62 - ETA: 0s - loss: 0.8726 - accuracy: 0.62 - ETA: 0s - loss: 0.8733 - accuracy: 0.62 - ETA: 0s - loss: 0.8786 - accuracy: 0.61 - ETA: 0s - loss: 0.8738 - accuracy: 0.62 - ETA: 0s - loss: 0.8688 - accuracy: 0.62 - ETA: 0s - loss: 0.8515 - accuracy: 0.64 - ETA: 0s - loss: 0.8590 - accuracy: 0.63 - ETA: 0s - loss: 0.8754 - accuracy: 0.61 - ETA: 0s - loss: 0.8774 - accuracy: 0.61 - ETA: 0s - loss: 0.8823 - accuracy: 0.61 - ETA: 0s - loss: 0.8838 - accuracy: 0.61 - ETA: 0s - loss: 0.8845 - accuracy: 0.6112\n",
      "Epoch 00464: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8845 - accuracy: 0.6112 - val_loss: 1.0532 - val_accuracy: 0.4738 - lr: 0.0010\n",
      "Epoch 465/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.9342 - accuracy: 0.54 - ETA: 0s - loss: 0.9169 - accuracy: 0.56 - ETA: 0s - loss: 0.8927 - accuracy: 0.59 - ETA: 0s - loss: 0.8868 - accuracy: 0.60 - ETA: 0s - loss: 0.8759 - accuracy: 0.61 - ETA: 0s - loss: 0.8736 - accuracy: 0.62 - ETA: 0s - loss: 0.8734 - accuracy: 0.62 - ETA: 0s - loss: 0.8756 - accuracy: 0.61 - ETA: 0s - loss: 0.8809 - accuracy: 0.61 - ETA: 0s - loss: 0.8749 - accuracy: 0.62 - ETA: 0s - loss: 0.8692 - accuracy: 0.62 - ETA: 0s - loss: 0.8516 - accuracy: 0.64 - ETA: 0s - loss: 0.8597 - accuracy: 0.63 - ETA: 0s - loss: 0.8757 - accuracy: 0.61 - ETA: 0s - loss: 0.8782 - accuracy: 0.61 - ETA: 0s - loss: 0.8829 - accuracy: 0.61 - ETA: 0s - loss: 0.8840 - accuracy: 0.6128\n",
      "Epoch 00465: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8854 - accuracy: 0.6116 - val_loss: 1.0498 - val_accuracy: 0.4744 - lr: 0.0010\n",
      "Epoch 466/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9489 - accuracy: 0.53 - ETA: 0s - loss: 0.9214 - accuracy: 0.56 - ETA: 0s - loss: 0.9199 - accuracy: 0.57 - ETA: 0s - loss: 0.8903 - accuracy: 0.59 - ETA: 0s - loss: 0.8854 - accuracy: 0.60 - ETA: 0s - loss: 0.8743 - accuracy: 0.61 - ETA: 0s - loss: 0.8732 - accuracy: 0.62 - ETA: 0s - loss: 0.8728 - accuracy: 0.62 - ETA: 0s - loss: 0.8722 - accuracy: 0.62 - ETA: 0s - loss: 0.8781 - accuracy: 0.61 - ETA: 0s - loss: 0.8737 - accuracy: 0.62 - ETA: 0s - loss: 0.8674 - accuracy: 0.62 - ETA: 0s - loss: 0.8499 - accuracy: 0.64 - ETA: 0s - loss: 0.8577 - accuracy: 0.63 - ETA: 0s - loss: 0.8738 - accuracy: 0.61 - ETA: 0s - loss: 0.8760 - accuracy: 0.61 - ETA: 0s - loss: 0.8807 - accuracy: 0.61 - ETA: 0s - loss: 0.8819 - accuracy: 0.61 - ETA: 0s - loss: 0.8836 - accuracy: 0.6102\n",
      "Epoch 00466: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8836 - accuracy: 0.6102 - val_loss: 1.0425 - val_accuracy: 0.4798 - lr: 0.0010\n",
      "Epoch 467/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9170 - accuracy: 0.54 - ETA: 0s - loss: 0.9000 - accuracy: 0.57 - ETA: 0s - loss: 0.9109 - accuracy: 0.57 - ETA: 0s - loss: 0.8799 - accuracy: 0.59 - ETA: 0s - loss: 0.8783 - accuracy: 0.60 - ETA: 0s - loss: 0.8690 - accuracy: 0.61 - ETA: 0s - loss: 0.8686 - accuracy: 0.61 - ETA: 0s - loss: 0.8688 - accuracy: 0.62 - ETA: 0s - loss: 0.8691 - accuracy: 0.61 - ETA: 0s - loss: 0.8745 - accuracy: 0.61 - ETA: 0s - loss: 0.8691 - accuracy: 0.61 - ETA: 0s - loss: 0.8629 - accuracy: 0.62 - ETA: 0s - loss: 0.8449 - accuracy: 0.64 - ETA: 0s - loss: 0.8528 - accuracy: 0.63 - ETA: 0s - loss: 0.8688 - accuracy: 0.62 - ETA: 0s - loss: 0.8718 - accuracy: 0.61 - ETA: 0s - loss: 0.8779 - accuracy: 0.61 - ETA: 0s - loss: 0.8794 - accuracy: 0.61 - ETA: 0s - loss: 0.8815 - accuracy: 0.6124\n",
      "Epoch 00467: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8815 - accuracy: 0.6124 - val_loss: 1.0528 - val_accuracy: 0.4751 - lr: 0.0010\n",
      "Epoch 468/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9365 - accuracy: 0.55 - ETA: 0s - loss: 0.9137 - accuracy: 0.57 - ETA: 0s - loss: 0.9205 - accuracy: 0.57 - ETA: 0s - loss: 0.8888 - accuracy: 0.59 - ETA: 0s - loss: 0.8862 - accuracy: 0.60 - ETA: 0s - loss: 0.8756 - accuracy: 0.61 - ETA: 0s - loss: 0.8734 - accuracy: 0.62 - ETA: 0s - loss: 0.8742 - accuracy: 0.62 - ETA: 0s - loss: 0.8745 - accuracy: 0.61 - ETA: 0s - loss: 0.8814 - accuracy: 0.61 - ETA: 0s - loss: 0.8758 - accuracy: 0.61 - ETA: 0s - loss: 0.8689 - accuracy: 0.62 - ETA: 0s - loss: 0.8517 - accuracy: 0.64 - ETA: 0s - loss: 0.8587 - accuracy: 0.63 - ETA: 0s - loss: 0.8727 - accuracy: 0.62 - ETA: 0s - loss: 0.8750 - accuracy: 0.61 - ETA: 0s - loss: 0.8801 - accuracy: 0.61 - ETA: 0s - loss: 0.8814 - accuracy: 0.61 - ETA: 0s - loss: 0.8824 - accuracy: 0.6138\n",
      "Epoch 00468: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8824 - accuracy: 0.6138 - val_loss: 1.0565 - val_accuracy: 0.4739 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 469/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9380 - accuracy: 0.54 - ETA: 0s - loss: 0.9163 - accuracy: 0.56 - ETA: 0s - loss: 0.9195 - accuracy: 0.57 - ETA: 0s - loss: 0.8884 - accuracy: 0.59 - ETA: 0s - loss: 0.8846 - accuracy: 0.60 - ETA: 0s - loss: 0.8753 - accuracy: 0.61 - ETA: 0s - loss: 0.8718 - accuracy: 0.62 - ETA: 0s - loss: 0.8726 - accuracy: 0.62 - ETA: 0s - loss: 0.8732 - accuracy: 0.62 - ETA: 0s - loss: 0.8776 - accuracy: 0.61 - ETA: 0s - loss: 0.8721 - accuracy: 0.62 - ETA: 0s - loss: 0.8672 - accuracy: 0.62 - ETA: 0s - loss: 0.8500 - accuracy: 0.64 - ETA: 0s - loss: 0.8601 - accuracy: 0.63 - ETA: 0s - loss: 0.8754 - accuracy: 0.61 - ETA: 0s - loss: 0.8779 - accuracy: 0.61 - ETA: 0s - loss: 0.8833 - accuracy: 0.61 - ETA: 0s - loss: 0.8847 - accuracy: 0.61 - ETA: 0s - loss: 0.8859 - accuracy: 0.6104\n",
      "Epoch 00469: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8859 - accuracy: 0.6104 - val_loss: 1.0581 - val_accuracy: 0.4765 - lr: 0.0010\n",
      "Epoch 470/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9330 - accuracy: 0.55 - ETA: 0s - loss: 0.9087 - accuracy: 0.56 - ETA: 0s - loss: 0.9139 - accuracy: 0.57 - ETA: 0s - loss: 0.8869 - accuracy: 0.59 - ETA: 0s - loss: 0.8816 - accuracy: 0.60 - ETA: 0s - loss: 0.8727 - accuracy: 0.61 - ETA: 0s - loss: 0.8707 - accuracy: 0.61 - ETA: 0s - loss: 0.8724 - accuracy: 0.62 - ETA: 0s - loss: 0.8744 - accuracy: 0.62 - ETA: 0s - loss: 0.8788 - accuracy: 0.61 - ETA: 0s - loss: 0.8732 - accuracy: 0.62 - ETA: 0s - loss: 0.8668 - accuracy: 0.62 - ETA: 0s - loss: 0.8491 - accuracy: 0.64 - ETA: 0s - loss: 0.8573 - accuracy: 0.63 - ETA: 0s - loss: 0.8740 - accuracy: 0.61 - ETA: 0s - loss: 0.8769 - accuracy: 0.61 - ETA: 0s - loss: 0.8831 - accuracy: 0.61 - ETA: 0s - loss: 0.8841 - accuracy: 0.61 - ETA: 0s - loss: 0.8860 - accuracy: 0.6111\n",
      "Epoch 00470: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8860 - accuracy: 0.6111 - val_loss: 1.0514 - val_accuracy: 0.4844 - lr: 0.0010\n",
      "Epoch 471/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9502 - accuracy: 0.55 - ETA: 0s - loss: 0.9201 - accuracy: 0.57 - ETA: 0s - loss: 0.9240 - accuracy: 0.57 - ETA: 0s - loss: 0.8919 - accuracy: 0.59 - ETA: 0s - loss: 0.8867 - accuracy: 0.60 - ETA: 0s - loss: 0.8766 - accuracy: 0.61 - ETA: 0s - loss: 0.8729 - accuracy: 0.62 - ETA: 0s - loss: 0.8726 - accuracy: 0.62 - ETA: 0s - loss: 0.8730 - accuracy: 0.62 - ETA: 0s - loss: 0.8781 - accuracy: 0.61 - ETA: 0s - loss: 0.8720 - accuracy: 0.62 - ETA: 0s - loss: 0.8661 - accuracy: 0.62 - ETA: 0s - loss: 0.8487 - accuracy: 0.64 - ETA: 0s - loss: 0.8556 - accuracy: 0.63 - ETA: 0s - loss: 0.8708 - accuracy: 0.62 - ETA: 0s - loss: 0.8732 - accuracy: 0.61 - ETA: 0s - loss: 0.8784 - accuracy: 0.61 - ETA: 0s - loss: 0.8800 - accuracy: 0.61 - ETA: 0s - loss: 0.8817 - accuracy: 0.6127\n",
      "Epoch 00471: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8817 - accuracy: 0.6127 - val_loss: 1.0517 - val_accuracy: 0.4795 - lr: 0.0010\n",
      "Epoch 472/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9313 - accuracy: 0.54 - ETA: 0s - loss: 0.9147 - accuracy: 0.56 - ETA: 0s - loss: 0.9223 - accuracy: 0.56 - ETA: 0s - loss: 0.8894 - accuracy: 0.59 - ETA: 0s - loss: 0.8845 - accuracy: 0.60 - ETA: 0s - loss: 0.8756 - accuracy: 0.61 - ETA: 0s - loss: 0.8735 - accuracy: 0.61 - ETA: 0s - loss: 0.8729 - accuracy: 0.61 - ETA: 0s - loss: 0.8720 - accuracy: 0.61 - ETA: 0s - loss: 0.8776 - accuracy: 0.61 - ETA: 0s - loss: 0.8726 - accuracy: 0.61 - ETA: 0s - loss: 0.8660 - accuracy: 0.62 - ETA: 0s - loss: 0.8497 - accuracy: 0.63 - ETA: 0s - loss: 0.8583 - accuracy: 0.62 - ETA: 0s - loss: 0.8731 - accuracy: 0.61 - ETA: 0s - loss: 0.8756 - accuracy: 0.61 - ETA: 0s - loss: 0.8809 - accuracy: 0.61 - ETA: 0s - loss: 0.8825 - accuracy: 0.61 - ETA: 0s - loss: 0.8832 - accuracy: 0.6096\n",
      "Epoch 00472: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8832 - accuracy: 0.6096 - val_loss: 1.0442 - val_accuracy: 0.4804 - lr: 0.0010\n",
      "Epoch 473/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9395 - accuracy: 0.54 - ETA: 0s - loss: 0.9162 - accuracy: 0.56 - ETA: 0s - loss: 0.9193 - accuracy: 0.57 - ETA: 0s - loss: 0.8882 - accuracy: 0.59 - ETA: 0s - loss: 0.8878 - accuracy: 0.60 - ETA: 0s - loss: 0.8779 - accuracy: 0.61 - ETA: 0s - loss: 0.8758 - accuracy: 0.61 - ETA: 0s - loss: 0.8744 - accuracy: 0.62 - ETA: 0s - loss: 0.8744 - accuracy: 0.61 - ETA: 0s - loss: 0.8801 - accuracy: 0.61 - ETA: 0s - loss: 0.8756 - accuracy: 0.61 - ETA: 0s - loss: 0.8686 - accuracy: 0.62 - ETA: 0s - loss: 0.8508 - accuracy: 0.63 - ETA: 0s - loss: 0.8598 - accuracy: 0.63 - ETA: 0s - loss: 0.8740 - accuracy: 0.61 - ETA: 0s - loss: 0.8762 - accuracy: 0.61 - ETA: 0s - loss: 0.8818 - accuracy: 0.61 - ETA: 0s - loss: 0.8829 - accuracy: 0.61 - ETA: 0s - loss: 0.8843 - accuracy: 0.6114\n",
      "Epoch 00473: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00473: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8843 - accuracy: 0.6114 - val_loss: 1.0507 - val_accuracy: 0.4791 - lr: 0.0010\n",
      "Epoch 474/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9379 - accuracy: 0.55 - ETA: 0s - loss: 0.9133 - accuracy: 0.57 - ETA: 0s - loss: 0.9179 - accuracy: 0.57 - ETA: 0s - loss: 0.8847 - accuracy: 0.59 - ETA: 0s - loss: 0.8818 - accuracy: 0.60 - ETA: 0s - loss: 0.8738 - accuracy: 0.61 - ETA: 0s - loss: 0.8707 - accuracy: 0.62 - ETA: 0s - loss: 0.8691 - accuracy: 0.62 - ETA: 0s - loss: 0.8708 - accuracy: 0.62 - ETA: 0s - loss: 0.8762 - accuracy: 0.61 - ETA: 0s - loss: 0.8725 - accuracy: 0.62 - ETA: 0s - loss: 0.8668 - accuracy: 0.62 - ETA: 0s - loss: 0.8485 - accuracy: 0.64 - ETA: 0s - loss: 0.8559 - accuracy: 0.63 - ETA: 0s - loss: 0.8747 - accuracy: 0.61 - ETA: 0s - loss: 0.8797 - accuracy: 0.61 - ETA: 0s - loss: 0.8805 - accuracy: 0.61 - ETA: 0s - loss: 0.8820 - accuracy: 0.6138\n",
      "Epoch 00474: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8820 - accuracy: 0.6138 - val_loss: 1.0610 - val_accuracy: 0.4718 - lr: 0.0010\n",
      "Epoch 475/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9469 - accuracy: 0.55 - ETA: 0s - loss: 0.9187 - accuracy: 0.56 - ETA: 0s - loss: 0.9261 - accuracy: 0.57 - ETA: 0s - loss: 0.8947 - accuracy: 0.59 - ETA: 0s - loss: 0.8888 - accuracy: 0.60 - ETA: 0s - loss: 0.8785 - accuracy: 0.61 - ETA: 0s - loss: 0.8760 - accuracy: 0.62 - ETA: 0s - loss: 0.8750 - accuracy: 0.62 - ETA: 0s - loss: 0.8759 - accuracy: 0.62 - ETA: 0s - loss: 0.8798 - accuracy: 0.61 - ETA: 0s - loss: 0.8744 - accuracy: 0.62 - ETA: 0s - loss: 0.8676 - accuracy: 0.62 - ETA: 0s - loss: 0.8500 - accuracy: 0.64 - ETA: 0s - loss: 0.8572 - accuracy: 0.63 - ETA: 0s - loss: 0.8716 - accuracy: 0.62 - ETA: 0s - loss: 0.8737 - accuracy: 0.61 - ETA: 0s - loss: 0.8800 - accuracy: 0.61 - ETA: 0s - loss: 0.8820 - accuracy: 0.61 - ETA: 0s - loss: 0.8838 - accuracy: 0.6125\n",
      "Epoch 00475: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8838 - accuracy: 0.6125 - val_loss: 1.0553 - val_accuracy: 0.4778 - lr: 0.0010\n",
      "Epoch 476/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9202 - accuracy: 0.55 - ETA: 0s - loss: 0.9096 - accuracy: 0.56 - ETA: 0s - loss: 0.9172 - accuracy: 0.57 - ETA: 0s - loss: 0.8861 - accuracy: 0.59 - ETA: 0s - loss: 0.8830 - accuracy: 0.60 - ETA: 0s - loss: 0.8734 - accuracy: 0.61 - ETA: 0s - loss: 0.8708 - accuracy: 0.62 - ETA: 0s - loss: 0.8696 - accuracy: 0.62 - ETA: 0s - loss: 0.8705 - accuracy: 0.62 - ETA: 0s - loss: 0.8753 - accuracy: 0.61 - ETA: 0s - loss: 0.8704 - accuracy: 0.62 - ETA: 0s - loss: 0.8647 - accuracy: 0.62 - ETA: 0s - loss: 0.8554 - accuracy: 0.63 - ETA: 0s - loss: 0.8724 - accuracy: 0.61 - ETA: 0s - loss: 0.8751 - accuracy: 0.61 - ETA: 0s - loss: 0.8803 - accuracy: 0.61 - ETA: 0s - loss: 0.8819 - accuracy: 0.61 - ETA: 0s - loss: 0.8831 - accuracy: 0.6116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00476: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8831 - accuracy: 0.6116 - val_loss: 1.0464 - val_accuracy: 0.4821 - lr: 0.0010\n",
      "Epoch 477/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9232 - accuracy: 0.55 - ETA: 0s - loss: 0.9084 - accuracy: 0.57 - ETA: 0s - loss: 0.9144 - accuracy: 0.57 - ETA: 0s - loss: 0.8869 - accuracy: 0.59 - ETA: 0s - loss: 0.8832 - accuracy: 0.60 - ETA: 0s - loss: 0.8738 - accuracy: 0.61 - ETA: 0s - loss: 0.8709 - accuracy: 0.62 - ETA: 0s - loss: 0.8690 - accuracy: 0.62 - ETA: 0s - loss: 0.8722 - accuracy: 0.62 - ETA: 0s - loss: 0.8764 - accuracy: 0.61 - ETA: 0s - loss: 0.8718 - accuracy: 0.62 - ETA: 0s - loss: 0.8664 - accuracy: 0.62 - ETA: 0s - loss: 0.8493 - accuracy: 0.64 - ETA: 0s - loss: 0.8577 - accuracy: 0.63 - ETA: 0s - loss: 0.8733 - accuracy: 0.61 - ETA: 0s - loss: 0.8758 - accuracy: 0.61 - ETA: 0s - loss: 0.8809 - accuracy: 0.61 - ETA: 0s - loss: 0.8820 - accuracy: 0.61 - ETA: 0s - loss: 0.8831 - accuracy: 0.6113\n",
      "Epoch 00477: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8831 - accuracy: 0.6113 - val_loss: 1.0394 - val_accuracy: 0.4865 - lr: 0.0010\n",
      "Epoch 478/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9465 - accuracy: 0.55 - ETA: 0s - loss: 0.9165 - accuracy: 0.57 - ETA: 0s - loss: 0.9224 - accuracy: 0.57 - ETA: 0s - loss: 0.8894 - accuracy: 0.60 - ETA: 0s - loss: 0.8860 - accuracy: 0.60 - ETA: 0s - loss: 0.8772 - accuracy: 0.61 - ETA: 0s - loss: 0.8750 - accuracy: 0.62 - ETA: 0s - loss: 0.8750 - accuracy: 0.62 - ETA: 0s - loss: 0.8763 - accuracy: 0.62 - ETA: 0s - loss: 0.8814 - accuracy: 0.61 - ETA: 0s - loss: 0.8753 - accuracy: 0.62 - ETA: 0s - loss: 0.8686 - accuracy: 0.62 - ETA: 0s - loss: 0.8508 - accuracy: 0.64 - ETA: 0s - loss: 0.8721 - accuracy: 0.62 - ETA: 0s - loss: 0.8745 - accuracy: 0.61 - ETA: 0s - loss: 0.8801 - accuracy: 0.61 - ETA: 0s - loss: 0.8815 - accuracy: 0.61 - ETA: 0s - loss: 0.8830 - accuracy: 0.6138\n",
      "Epoch 00478: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8830 - accuracy: 0.6138 - val_loss: 1.0409 - val_accuracy: 0.4845 - lr: 0.0010\n",
      "Epoch 479/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9318 - accuracy: 0.53 - ETA: 0s - loss: 0.9148 - accuracy: 0.55 - ETA: 0s - loss: 0.9241 - accuracy: 0.56 - ETA: 0s - loss: 0.8902 - accuracy: 0.59 - ETA: 0s - loss: 0.8843 - accuracy: 0.59 - ETA: 0s - loss: 0.8750 - accuracy: 0.61 - ETA: 0s - loss: 0.8720 - accuracy: 0.61 - ETA: 0s - loss: 0.8709 - accuracy: 0.61 - ETA: 0s - loss: 0.8717 - accuracy: 0.61 - ETA: 0s - loss: 0.8762 - accuracy: 0.61 - ETA: 0s - loss: 0.8700 - accuracy: 0.61 - ETA: 0s - loss: 0.8643 - accuracy: 0.62 - ETA: 0s - loss: 0.8470 - accuracy: 0.64 - ETA: 0s - loss: 0.8559 - accuracy: 0.63 - ETA: 0s - loss: 0.8719 - accuracy: 0.61 - ETA: 0s - loss: 0.8742 - accuracy: 0.61 - ETA: 0s - loss: 0.8797 - accuracy: 0.61 - ETA: 0s - loss: 0.8811 - accuracy: 0.61 - ETA: 0s - loss: 0.8823 - accuracy: 0.6105\n",
      "Epoch 00479: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8823 - accuracy: 0.6105 - val_loss: 1.0466 - val_accuracy: 0.4889 - lr: 0.0010\n",
      "Epoch 480/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9313 - accuracy: 0.54 - ETA: 0s - loss: 0.9052 - accuracy: 0.56 - ETA: 0s - loss: 0.9168 - accuracy: 0.57 - ETA: 0s - loss: 0.8864 - accuracy: 0.59 - ETA: 0s - loss: 0.8830 - accuracy: 0.60 - ETA: 0s - loss: 0.8736 - accuracy: 0.61 - ETA: 0s - loss: 0.8726 - accuracy: 0.61 - ETA: 0s - loss: 0.8721 - accuracy: 0.61 - ETA: 0s - loss: 0.8726 - accuracy: 0.61 - ETA: 0s - loss: 0.8798 - accuracy: 0.61 - ETA: 0s - loss: 0.8743 - accuracy: 0.61 - ETA: 0s - loss: 0.8677 - accuracy: 0.62 - ETA: 0s - loss: 0.8500 - accuracy: 0.64 - ETA: 0s - loss: 0.8572 - accuracy: 0.63 - ETA: 0s - loss: 0.8728 - accuracy: 0.61 - ETA: 0s - loss: 0.8748 - accuracy: 0.61 - ETA: 0s - loss: 0.8801 - accuracy: 0.61 - ETA: 0s - loss: 0.8819 - accuracy: 0.61 - ETA: 0s - loss: 0.8835 - accuracy: 0.6118\n",
      "Epoch 00480: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8835 - accuracy: 0.6118 - val_loss: 1.0427 - val_accuracy: 0.4906 - lr: 0.0010\n",
      "Epoch 481/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9446 - accuracy: 0.53 - ETA: 0s - loss: 0.9251 - accuracy: 0.56 - ETA: 0s - loss: 0.9283 - accuracy: 0.56 - ETA: 0s - loss: 0.8970 - accuracy: 0.59 - ETA: 0s - loss: 0.8919 - accuracy: 0.60 - ETA: 0s - loss: 0.8804 - accuracy: 0.61 - ETA: 0s - loss: 0.8778 - accuracy: 0.61 - ETA: 0s - loss: 0.8764 - accuracy: 0.61 - ETA: 0s - loss: 0.8763 - accuracy: 0.61 - ETA: 0s - loss: 0.8827 - accuracy: 0.60 - ETA: 0s - loss: 0.8766 - accuracy: 0.61 - ETA: 0s - loss: 0.8693 - accuracy: 0.62 - ETA: 0s - loss: 0.8514 - accuracy: 0.63 - ETA: 0s - loss: 0.8608 - accuracy: 0.62 - ETA: 0s - loss: 0.8768 - accuracy: 0.61 - ETA: 0s - loss: 0.8786 - accuracy: 0.61 - ETA: 0s - loss: 0.8837 - accuracy: 0.61 - ETA: 0s - loss: 0.8851 - accuracy: 0.61 - ETA: 0s - loss: 0.8864 - accuracy: 0.6093\n",
      "Epoch 00481: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8864 - accuracy: 0.6093 - val_loss: 1.0283 - val_accuracy: 0.4888 - lr: 0.0010\n",
      "Epoch 482/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9426 - accuracy: 0.53 - ETA: 0s - loss: 0.9155 - accuracy: 0.56 - ETA: 0s - loss: 0.9183 - accuracy: 0.57 - ETA: 0s - loss: 0.8877 - accuracy: 0.59 - ETA: 0s - loss: 0.8845 - accuracy: 0.60 - ETA: 0s - loss: 0.8754 - accuracy: 0.61 - ETA: 0s - loss: 0.8744 - accuracy: 0.61 - ETA: 0s - loss: 0.8740 - accuracy: 0.62 - ETA: 0s - loss: 0.8754 - accuracy: 0.61 - ETA: 0s - loss: 0.8821 - accuracy: 0.60 - ETA: 0s - loss: 0.8762 - accuracy: 0.61 - ETA: 0s - loss: 0.8680 - accuracy: 0.62 - ETA: 0s - loss: 0.8501 - accuracy: 0.63 - ETA: 0s - loss: 0.8583 - accuracy: 0.63 - ETA: 0s - loss: 0.8727 - accuracy: 0.61 - ETA: 0s - loss: 0.8760 - accuracy: 0.61 - ETA: 0s - loss: 0.8822 - accuracy: 0.61 - ETA: 0s - loss: 0.8831 - accuracy: 0.61 - ETA: 0s - loss: 0.8846 - accuracy: 0.6108\n",
      "Epoch 00482: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8846 - accuracy: 0.6108 - val_loss: 1.0422 - val_accuracy: 0.4816 - lr: 0.0010\n",
      "Epoch 483/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.9367 - accuracy: 0.54 - ETA: 0s - loss: 0.9133 - accuracy: 0.56 - ETA: 0s - loss: 0.9191 - accuracy: 0.56 - ETA: 0s - loss: 0.8888 - accuracy: 0.59 - ETA: 0s - loss: 0.8852 - accuracy: 0.60 - ETA: 0s - loss: 0.8741 - accuracy: 0.61 - ETA: 0s - loss: 0.8714 - accuracy: 0.61 - ETA: 0s - loss: 0.8719 - accuracy: 0.62 - ETA: 0s - loss: 0.8728 - accuracy: 0.61 - ETA: 0s - loss: 0.8785 - accuracy: 0.60 - ETA: 0s - loss: 0.8730 - accuracy: 0.61 - ETA: 0s - loss: 0.8661 - accuracy: 0.62 - ETA: 0s - loss: 0.8492 - accuracy: 0.63 - ETA: 0s - loss: 0.8576 - accuracy: 0.62 - ETA: 0s - loss: 0.8715 - accuracy: 0.61 - ETA: 0s - loss: 0.8736 - accuracy: 0.61 - ETA: 0s - loss: 0.8786 - accuracy: 0.61 - ETA: 0s - loss: 0.8798 - accuracy: 0.6117\n",
      "Epoch 00483: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8815 - accuracy: 0.6103 - val_loss: 1.0553 - val_accuracy: 0.4736 - lr: 0.0010\n",
      "Epoch 484/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9316 - accuracy: 0.55 - ETA: 0s - loss: 0.9138 - accuracy: 0.57 - ETA: 0s - loss: 0.9202 - accuracy: 0.57 - ETA: 0s - loss: 0.8905 - accuracy: 0.59 - ETA: 0s - loss: 0.8878 - accuracy: 0.60 - ETA: 0s - loss: 0.8763 - accuracy: 0.61 - ETA: 0s - loss: 0.8738 - accuracy: 0.61 - ETA: 0s - loss: 0.8706 - accuracy: 0.62 - ETA: 0s - loss: 0.8705 - accuracy: 0.62 - ETA: 0s - loss: 0.8763 - accuracy: 0.61 - ETA: 0s - loss: 0.8709 - accuracy: 0.62 - ETA: 0s - loss: 0.8651 - accuracy: 0.62 - ETA: 0s - loss: 0.8480 - accuracy: 0.64 - ETA: 0s - loss: 0.8560 - accuracy: 0.63 - ETA: 0s - loss: 0.8704 - accuracy: 0.62 - ETA: 0s - loss: 0.8728 - accuracy: 0.61 - ETA: 0s - loss: 0.8783 - accuracy: 0.61 - ETA: 0s - loss: 0.8802 - accuracy: 0.61 - ETA: 0s - loss: 0.8819 - accuracy: 0.6127\n",
      "Epoch 00484: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8819 - accuracy: 0.6127 - val_loss: 1.0538 - val_accuracy: 0.4741 - lr: 0.0010\n",
      "Epoch 485/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9384 - accuracy: 0.55 - ETA: 0s - loss: 0.9111 - accuracy: 0.57 - ETA: 0s - loss: 0.9225 - accuracy: 0.57 - ETA: 0s - loss: 0.8898 - accuracy: 0.60 - ETA: 0s - loss: 0.8852 - accuracy: 0.60 - ETA: 0s - loss: 0.8749 - accuracy: 0.61 - ETA: 0s - loss: 0.8717 - accuracy: 0.62 - ETA: 0s - loss: 0.8708 - accuracy: 0.62 - ETA: 0s - loss: 0.8716 - accuracy: 0.62 - ETA: 0s - loss: 0.8785 - accuracy: 0.61 - ETA: 0s - loss: 0.8730 - accuracy: 0.62 - ETA: 0s - loss: 0.8663 - accuracy: 0.63 - ETA: 0s - loss: 0.8481 - accuracy: 0.64 - ETA: 0s - loss: 0.8549 - accuracy: 0.63 - ETA: 0s - loss: 0.8714 - accuracy: 0.62 - ETA: 0s - loss: 0.8739 - accuracy: 0.61 - ETA: 0s - loss: 0.8797 - accuracy: 0.61 - ETA: 0s - loss: 0.8805 - accuracy: 0.61 - ETA: 0s - loss: 0.8819 - accuracy: 0.6137\n",
      "Epoch 00485: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8819 - accuracy: 0.6137 - val_loss: 1.0524 - val_accuracy: 0.4762 - lr: 0.0010\n",
      "Epoch 486/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9350 - accuracy: 0.53 - ETA: 0s - loss: 0.9130 - accuracy: 0.56 - ETA: 0s - loss: 0.9210 - accuracy: 0.57 - ETA: 0s - loss: 0.8905 - accuracy: 0.59 - ETA: 0s - loss: 0.8858 - accuracy: 0.60 - ETA: 0s - loss: 0.8760 - accuracy: 0.61 - ETA: 0s - loss: 0.8717 - accuracy: 0.61 - ETA: 0s - loss: 0.8722 - accuracy: 0.62 - ETA: 0s - loss: 0.8733 - accuracy: 0.61 - ETA: 0s - loss: 0.8784 - accuracy: 0.61 - ETA: 0s - loss: 0.8728 - accuracy: 0.61 - ETA: 0s - loss: 0.8659 - accuracy: 0.62 - ETA: 0s - loss: 0.8487 - accuracy: 0.63 - ETA: 0s - loss: 0.8567 - accuracy: 0.63 - ETA: 0s - loss: 0.8704 - accuracy: 0.61 - ETA: 0s - loss: 0.8728 - accuracy: 0.61 - ETA: 0s - loss: 0.8783 - accuracy: 0.61 - ETA: 0s - loss: 0.8801 - accuracy: 0.61 - ETA: 0s - loss: 0.8817 - accuracy: 0.6124\n",
      "Epoch 00486: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8817 - accuracy: 0.6124 - val_loss: 1.0701 - val_accuracy: 0.4642 - lr: 0.0010\n",
      "Epoch 487/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9368 - accuracy: 0.53 - ETA: 0s - loss: 0.9134 - accuracy: 0.56 - ETA: 0s - loss: 0.9194 - accuracy: 0.56 - ETA: 0s - loss: 0.8842 - accuracy: 0.59 - ETA: 0s - loss: 0.8800 - accuracy: 0.60 - ETA: 0s - loss: 0.8710 - accuracy: 0.61 - ETA: 0s - loss: 0.8699 - accuracy: 0.62 - ETA: 0s - loss: 0.8690 - accuracy: 0.62 - ETA: 0s - loss: 0.8693 - accuracy: 0.62 - ETA: 0s - loss: 0.8749 - accuracy: 0.61 - ETA: 0s - loss: 0.8693 - accuracy: 0.62 - ETA: 0s - loss: 0.8637 - accuracy: 0.63 - ETA: 0s - loss: 0.8460 - accuracy: 0.64 - ETA: 0s - loss: 0.8560 - accuracy: 0.63 - ETA: 0s - loss: 0.8732 - accuracy: 0.62 - ETA: 0s - loss: 0.8749 - accuracy: 0.61 - ETA: 0s - loss: 0.8797 - accuracy: 0.61 - ETA: 0s - loss: 0.8808 - accuracy: 0.61 - ETA: 0s - loss: 0.8816 - accuracy: 0.6142\n",
      "Epoch 00487: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00487: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8816 - accuracy: 0.6142 - val_loss: 1.0716 - val_accuracy: 0.4664 - lr: 0.0010\n",
      "Epoch 488/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9327 - accuracy: 0.53 - ETA: 0s - loss: 0.9133 - accuracy: 0.56 - ETA: 0s - loss: 0.9215 - accuracy: 0.56 - ETA: 0s - loss: 0.8881 - accuracy: 0.59 - ETA: 0s - loss: 0.8839 - accuracy: 0.59 - ETA: 0s - loss: 0.8734 - accuracy: 0.61 - ETA: 0s - loss: 0.8705 - accuracy: 0.61 - ETA: 0s - loss: 0.8688 - accuracy: 0.62 - ETA: 0s - loss: 0.8703 - accuracy: 0.62 - ETA: 0s - loss: 0.8769 - accuracy: 0.61 - ETA: 0s - loss: 0.8703 - accuracy: 0.62 - ETA: 0s - loss: 0.8645 - accuracy: 0.62 - ETA: 0s - loss: 0.8477 - accuracy: 0.64 - ETA: 0s - loss: 0.8564 - accuracy: 0.63 - ETA: 0s - loss: 0.8717 - accuracy: 0.61 - ETA: 0s - loss: 0.8739 - accuracy: 0.61 - ETA: 0s - loss: 0.8797 - accuracy: 0.61 - ETA: 0s - loss: 0.8814 - accuracy: 0.61 - ETA: 0s - loss: 0.8821 - accuracy: 0.6121\n",
      "Epoch 00488: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8821 - accuracy: 0.6121 - val_loss: 1.0633 - val_accuracy: 0.4767 - lr: 0.0010\n",
      "Epoch 489/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9327 - accuracy: 0.55 - ETA: 0s - loss: 0.9078 - accuracy: 0.57 - ETA: 0s - loss: 0.9136 - accuracy: 0.58 - ETA: 0s - loss: 0.8846 - accuracy: 0.60 - ETA: 0s - loss: 0.8820 - accuracy: 0.60 - ETA: 0s - loss: 0.8728 - accuracy: 0.61 - ETA: 0s - loss: 0.8723 - accuracy: 0.62 - ETA: 0s - loss: 0.8716 - accuracy: 0.62 - ETA: 0s - loss: 0.8730 - accuracy: 0.62 - ETA: 0s - loss: 0.8795 - accuracy: 0.61 - ETA: 0s - loss: 0.8740 - accuracy: 0.62 - ETA: 0s - loss: 0.8674 - accuracy: 0.62 - ETA: 0s - loss: 0.8496 - accuracy: 0.64 - ETA: 0s - loss: 0.8571 - accuracy: 0.63 - ETA: 0s - loss: 0.8719 - accuracy: 0.61 - ETA: 0s - loss: 0.8800 - accuracy: 0.61 - ETA: 0s - loss: 0.8806 - accuracy: 0.61 - ETA: 0s - loss: 0.8823 - accuracy: 0.6119\n",
      "Epoch 00489: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8823 - accuracy: 0.6119 - val_loss: 1.0488 - val_accuracy: 0.4831 - lr: 0.0010\n",
      "Epoch 490/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9176 - accuracy: 0.56 - ETA: 0s - loss: 0.9052 - accuracy: 0.57 - ETA: 0s - loss: 0.9150 - accuracy: 0.57 - ETA: 0s - loss: 0.8849 - accuracy: 0.59 - ETA: 0s - loss: 0.8804 - accuracy: 0.60 - ETA: 0s - loss: 0.8718 - accuracy: 0.61 - ETA: 0s - loss: 0.8688 - accuracy: 0.62 - ETA: 0s - loss: 0.8680 - accuracy: 0.62 - ETA: 0s - loss: 0.8695 - accuracy: 0.62 - ETA: 0s - loss: 0.8753 - accuracy: 0.61 - ETA: 0s - loss: 0.8696 - accuracy: 0.62 - ETA: 0s - loss: 0.8637 - accuracy: 0.62 - ETA: 0s - loss: 0.8463 - accuracy: 0.64 - ETA: 0s - loss: 0.8546 - accuracy: 0.63 - ETA: 0s - loss: 0.8685 - accuracy: 0.62 - ETA: 0s - loss: 0.8715 - accuracy: 0.61 - ETA: 0s - loss: 0.8776 - accuracy: 0.61 - ETA: 0s - loss: 0.8784 - accuracy: 0.61 - ETA: 0s - loss: 0.8804 - accuracy: 0.6127\n",
      "Epoch 00490: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8804 - accuracy: 0.6127 - val_loss: 1.0547 - val_accuracy: 0.4769 - lr: 0.0010\n",
      "Epoch 491/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9224 - accuracy: 0.53 - ETA: 0s - loss: 0.9012 - accuracy: 0.56 - ETA: 0s - loss: 0.9126 - accuracy: 0.56 - ETA: 0s - loss: 0.8814 - accuracy: 0.59 - ETA: 0s - loss: 0.8789 - accuracy: 0.60 - ETA: 0s - loss: 0.8707 - accuracy: 0.61 - ETA: 0s - loss: 0.8680 - accuracy: 0.61 - ETA: 0s - loss: 0.8699 - accuracy: 0.61 - ETA: 0s - loss: 0.8713 - accuracy: 0.61 - ETA: 0s - loss: 0.8768 - accuracy: 0.60 - ETA: 0s - loss: 0.8711 - accuracy: 0.61 - ETA: 0s - loss: 0.8643 - accuracy: 0.62 - ETA: 0s - loss: 0.8557 - accuracy: 0.63 - ETA: 0s - loss: 0.8713 - accuracy: 0.61 - ETA: 0s - loss: 0.8732 - accuracy: 0.61 - ETA: 0s - loss: 0.8790 - accuracy: 0.61 - ETA: 0s - loss: 0.8809 - accuracy: 0.61 - ETA: 0s - loss: 0.8823 - accuracy: 0.6107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00491: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8823 - accuracy: 0.6107 - val_loss: 1.0586 - val_accuracy: 0.4721 - lr: 0.0010\n",
      "Epoch 492/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9482 - accuracy: 0.54 - ETA: 0s - loss: 0.9174 - accuracy: 0.56 - ETA: 0s - loss: 0.9212 - accuracy: 0.56 - ETA: 0s - loss: 0.8897 - accuracy: 0.59 - ETA: 0s - loss: 0.8852 - accuracy: 0.60 - ETA: 0s - loss: 0.8745 - accuracy: 0.61 - ETA: 0s - loss: 0.8732 - accuracy: 0.61 - ETA: 0s - loss: 0.8730 - accuracy: 0.61 - ETA: 0s - loss: 0.8744 - accuracy: 0.61 - ETA: 0s - loss: 0.8806 - accuracy: 0.60 - ETA: 0s - loss: 0.8745 - accuracy: 0.61 - ETA: 0s - loss: 0.8679 - accuracy: 0.62 - ETA: 0s - loss: 0.8495 - accuracy: 0.63 - ETA: 0s - loss: 0.8576 - accuracy: 0.63 - ETA: 0s - loss: 0.8722 - accuracy: 0.61 - ETA: 0s - loss: 0.8741 - accuracy: 0.61 - ETA: 0s - loss: 0.8801 - accuracy: 0.61 - ETA: 0s - loss: 0.8811 - accuracy: 0.61 - ETA: 0s - loss: 0.8829 - accuracy: 0.6108\n",
      "Epoch 00492: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8829 - accuracy: 0.6108 - val_loss: 1.0460 - val_accuracy: 0.4814 - lr: 0.0010\n",
      "Epoch 493/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9338 - accuracy: 0.54 - ETA: 0s - loss: 0.9046 - accuracy: 0.57 - ETA: 0s - loss: 0.9165 - accuracy: 0.57 - ETA: 0s - loss: 0.8838 - accuracy: 0.59 - ETA: 0s - loss: 0.8799 - accuracy: 0.60 - ETA: 0s - loss: 0.8703 - accuracy: 0.61 - ETA: 0s - loss: 0.8690 - accuracy: 0.62 - ETA: 0s - loss: 0.8688 - accuracy: 0.62 - ETA: 0s - loss: 0.8702 - accuracy: 0.62 - ETA: 0s - loss: 0.8761 - accuracy: 0.61 - ETA: 0s - loss: 0.8703 - accuracy: 0.62 - ETA: 0s - loss: 0.8652 - accuracy: 0.62 - ETA: 0s - loss: 0.8469 - accuracy: 0.64 - ETA: 0s - loss: 0.8551 - accuracy: 0.63 - ETA: 0s - loss: 0.8716 - accuracy: 0.61 - ETA: 0s - loss: 0.8738 - accuracy: 0.61 - ETA: 0s - loss: 0.8790 - accuracy: 0.61 - ETA: 0s - loss: 0.8802 - accuracy: 0.61 - ETA: 0s - loss: 0.8817 - accuracy: 0.6121\n",
      "Epoch 00493: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8817 - accuracy: 0.6121 - val_loss: 1.0487 - val_accuracy: 0.4774 - lr: 0.0010\n",
      "Epoch 494/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9422 - accuracy: 0.54 - ETA: 0s - loss: 0.9108 - accuracy: 0.56 - ETA: 0s - loss: 0.9185 - accuracy: 0.57 - ETA: 0s - loss: 0.8866 - accuracy: 0.59 - ETA: 0s - loss: 0.8828 - accuracy: 0.60 - ETA: 0s - loss: 0.8731 - accuracy: 0.61 - ETA: 0s - loss: 0.8697 - accuracy: 0.62 - ETA: 0s - loss: 0.8698 - accuracy: 0.62 - ETA: 0s - loss: 0.8707 - accuracy: 0.62 - ETA: 0s - loss: 0.8758 - accuracy: 0.61 - ETA: 0s - loss: 0.8705 - accuracy: 0.62 - ETA: 0s - loss: 0.8635 - accuracy: 0.62 - ETA: 0s - loss: 0.8463 - accuracy: 0.64 - ETA: 0s - loss: 0.8536 - accuracy: 0.63 - ETA: 0s - loss: 0.8713 - accuracy: 0.61 - ETA: 0s - loss: 0.8735 - accuracy: 0.61 - ETA: 0s - loss: 0.8797 - accuracy: 0.61 - ETA: 0s - loss: 0.8815 - accuracy: 0.61 - ETA: 0s - loss: 0.8831 - accuracy: 0.6124\n",
      "Epoch 00494: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8831 - accuracy: 0.6124 - val_loss: 1.0444 - val_accuracy: 0.4806 - lr: 0.0010\n",
      "Epoch 495/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9387 - accuracy: 0.54 - ETA: 0s - loss: 0.9094 - accuracy: 0.57 - ETA: 0s - loss: 0.9156 - accuracy: 0.57 - ETA: 0s - loss: 0.8832 - accuracy: 0.60 - ETA: 0s - loss: 0.8796 - accuracy: 0.60 - ETA: 0s - loss: 0.8705 - accuracy: 0.61 - ETA: 0s - loss: 0.8669 - accuracy: 0.62 - ETA: 0s - loss: 0.8680 - accuracy: 0.62 - ETA: 0s - loss: 0.8688 - accuracy: 0.62 - ETA: 0s - loss: 0.8745 - accuracy: 0.61 - ETA: 0s - loss: 0.8688 - accuracy: 0.62 - ETA: 0s - loss: 0.8629 - accuracy: 0.63 - ETA: 0s - loss: 0.8449 - accuracy: 0.64 - ETA: 0s - loss: 0.8536 - accuracy: 0.63 - ETA: 0s - loss: 0.8718 - accuracy: 0.62 - ETA: 0s - loss: 0.8745 - accuracy: 0.61 - ETA: 0s - loss: 0.8795 - accuracy: 0.61 - ETA: 0s - loss: 0.8806 - accuracy: 0.61 - ETA: 0s - loss: 0.8822 - accuracy: 0.6127\n",
      "Epoch 00495: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8822 - accuracy: 0.6127 - val_loss: 1.0426 - val_accuracy: 0.4847 - lr: 0.0010\n",
      "Epoch 496/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9311 - accuracy: 0.53 - ETA: 0s - loss: 0.9123 - accuracy: 0.55 - ETA: 0s - loss: 0.9169 - accuracy: 0.56 - ETA: 0s - loss: 0.8853 - accuracy: 0.59 - ETA: 0s - loss: 0.8807 - accuracy: 0.60 - ETA: 0s - loss: 0.8706 - accuracy: 0.61 - ETA: 0s - loss: 0.8690 - accuracy: 0.62 - ETA: 0s - loss: 0.8682 - accuracy: 0.62 - ETA: 0s - loss: 0.8694 - accuracy: 0.62 - ETA: 0s - loss: 0.8751 - accuracy: 0.61 - ETA: 0s - loss: 0.8699 - accuracy: 0.62 - ETA: 0s - loss: 0.8638 - accuracy: 0.62 - ETA: 0s - loss: 0.8459 - accuracy: 0.64 - ETA: 0s - loss: 0.8531 - accuracy: 0.63 - ETA: 0s - loss: 0.8679 - accuracy: 0.62 - ETA: 0s - loss: 0.8703 - accuracy: 0.62 - ETA: 0s - loss: 0.8762 - accuracy: 0.61 - ETA: 0s - loss: 0.8777 - accuracy: 0.61 - ETA: 0s - loss: 0.8793 - accuracy: 0.6149\n",
      "Epoch 00496: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8793 - accuracy: 0.6149 - val_loss: 1.0602 - val_accuracy: 0.4754 - lr: 0.0010\n",
      "Epoch 497/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9303 - accuracy: 0.55 - ETA: 0s - loss: 0.9050 - accuracy: 0.57 - ETA: 0s - loss: 0.9167 - accuracy: 0.57 - ETA: 0s - loss: 0.8871 - accuracy: 0.60 - ETA: 0s - loss: 0.8844 - accuracy: 0.60 - ETA: 0s - loss: 0.8756 - accuracy: 0.61 - ETA: 0s - loss: 0.8737 - accuracy: 0.62 - ETA: 0s - loss: 0.8729 - accuracy: 0.62 - ETA: 0s - loss: 0.8748 - accuracy: 0.62 - ETA: 0s - loss: 0.8795 - accuracy: 0.61 - ETA: 0s - loss: 0.8738 - accuracy: 0.62 - ETA: 0s - loss: 0.8668 - accuracy: 0.62 - ETA: 0s - loss: 0.8496 - accuracy: 0.64 - ETA: 0s - loss: 0.8575 - accuracy: 0.63 - ETA: 0s - loss: 0.8713 - accuracy: 0.62 - ETA: 0s - loss: 0.8741 - accuracy: 0.62 - ETA: 0s - loss: 0.8797 - accuracy: 0.61 - ETA: 0s - loss: 0.8804 - accuracy: 0.61 - ETA: 0s - loss: 0.8816 - accuracy: 0.6157\n",
      "Epoch 00497: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8816 - accuracy: 0.6157 - val_loss: 1.0763 - val_accuracy: 0.4673 - lr: 0.0010\n",
      "Epoch 498/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.9326 - accuracy: 0.55 - ETA: 0s - loss: 0.9119 - accuracy: 0.57 - ETA: 0s - loss: 0.9217 - accuracy: 0.57 - ETA: 0s - loss: 0.8913 - accuracy: 0.59 - ETA: 0s - loss: 0.8856 - accuracy: 0.60 - ETA: 0s - loss: 0.8762 - accuracy: 0.61 - ETA: 0s - loss: 0.8734 - accuracy: 0.62 - ETA: 0s - loss: 0.8723 - accuracy: 0.62 - ETA: 0s - loss: 0.8740 - accuracy: 0.62 - ETA: 0s - loss: 0.8789 - accuracy: 0.61 - ETA: 0s - loss: 0.8733 - accuracy: 0.62 - ETA: 0s - loss: 0.8671 - accuracy: 0.62 - ETA: 0s - loss: 0.8492 - accuracy: 0.64 - ETA: 0s - loss: 0.8577 - accuracy: 0.63 - ETA: 0s - loss: 0.8731 - accuracy: 0.61 - ETA: 0s - loss: 0.8752 - accuracy: 0.61 - ETA: 0s - loss: 0.8808 - accuracy: 0.61 - ETA: 0s - loss: 0.8819 - accuracy: 0.6127\n",
      "Epoch 00498: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8829 - accuracy: 0.6118 - val_loss: 1.0633 - val_accuracy: 0.4703 - lr: 0.0010\n",
      "Epoch 499/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9309 - accuracy: 0.54 - ETA: 0s - loss: 0.9068 - accuracy: 0.56 - ETA: 0s - loss: 0.9164 - accuracy: 0.57 - ETA: 0s - loss: 0.8891 - accuracy: 0.59 - ETA: 0s - loss: 0.8858 - accuracy: 0.60 - ETA: 0s - loss: 0.8741 - accuracy: 0.61 - ETA: 0s - loss: 0.8705 - accuracy: 0.62 - ETA: 0s - loss: 0.8707 - accuracy: 0.62 - ETA: 0s - loss: 0.8716 - accuracy: 0.62 - ETA: 0s - loss: 0.8774 - accuracy: 0.61 - ETA: 0s - loss: 0.8721 - accuracy: 0.62 - ETA: 0s - loss: 0.8648 - accuracy: 0.62 - ETA: 0s - loss: 0.8469 - accuracy: 0.64 - ETA: 0s - loss: 0.8538 - accuracy: 0.63 - ETA: 0s - loss: 0.8686 - accuracy: 0.62 - ETA: 0s - loss: 0.8709 - accuracy: 0.62 - ETA: 0s - loss: 0.8766 - accuracy: 0.61 - ETA: 0s - loss: 0.8777 - accuracy: 0.61 - ETA: 0s - loss: 0.8793 - accuracy: 0.6151\n",
      "Epoch 00499: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8793 - accuracy: 0.6151 - val_loss: 1.0492 - val_accuracy: 0.4785 - lr: 0.0010\n",
      "Epoch 500/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9337 - accuracy: 0.55 - ETA: 0s - loss: 0.9101 - accuracy: 0.56 - ETA: 0s - loss: 0.9163 - accuracy: 0.57 - ETA: 0s - loss: 0.8858 - accuracy: 0.59 - ETA: 0s - loss: 0.8829 - accuracy: 0.60 - ETA: 0s - loss: 0.8728 - accuracy: 0.61 - ETA: 0s - loss: 0.8712 - accuracy: 0.61 - ETA: 0s - loss: 0.8696 - accuracy: 0.62 - ETA: 0s - loss: 0.8695 - accuracy: 0.62 - ETA: 0s - loss: 0.8766 - accuracy: 0.61 - ETA: 0s - loss: 0.8713 - accuracy: 0.62 - ETA: 0s - loss: 0.8640 - accuracy: 0.62 - ETA: 0s - loss: 0.8463 - accuracy: 0.64 - ETA: 0s - loss: 0.8546 - accuracy: 0.63 - ETA: 0s - loss: 0.8684 - accuracy: 0.61 - ETA: 0s - loss: 0.8710 - accuracy: 0.61 - ETA: 0s - loss: 0.8771 - accuracy: 0.61 - ETA: 0s - loss: 0.8786 - accuracy: 0.61 - ETA: 0s - loss: 0.8806 - accuracy: 0.6116\n",
      "Epoch 00500: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8806 - accuracy: 0.6116 - val_loss: 1.0615 - val_accuracy: 0.4734 - lr: 0.0010\n",
      "Epoch 501/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9347 - accuracy: 0.55 - ETA: 0s - loss: 0.9090 - accuracy: 0.57 - ETA: 0s - loss: 0.9117 - accuracy: 0.57 - ETA: 0s - loss: 0.8831 - accuracy: 0.60 - ETA: 0s - loss: 0.8810 - accuracy: 0.60 - ETA: 0s - loss: 0.8713 - accuracy: 0.61 - ETA: 0s - loss: 0.8695 - accuracy: 0.62 - ETA: 0s - loss: 0.8686 - accuracy: 0.62 - ETA: 0s - loss: 0.8711 - accuracy: 0.62 - ETA: 0s - loss: 0.8750 - accuracy: 0.61 - ETA: 0s - loss: 0.8694 - accuracy: 0.62 - ETA: 0s - loss: 0.8636 - accuracy: 0.62 - ETA: 0s - loss: 0.8463 - accuracy: 0.64 - ETA: 0s - loss: 0.8557 - accuracy: 0.63 - ETA: 0s - loss: 0.8692 - accuracy: 0.62 - ETA: 0s - loss: 0.8718 - accuracy: 0.61 - ETA: 0s - loss: 0.8776 - accuracy: 0.61 - ETA: 0s - loss: 0.8797 - accuracy: 0.61 - ETA: 0s - loss: 0.8816 - accuracy: 0.6125\n",
      "Epoch 00501: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00501: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8816 - accuracy: 0.6125 - val_loss: 1.0445 - val_accuracy: 0.4842 - lr: 0.0010\n",
      "Epoch 502/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9245 - accuracy: 0.55 - ETA: 0s - loss: 0.9068 - accuracy: 0.57 - ETA: 0s - loss: 0.9139 - accuracy: 0.57 - ETA: 0s - loss: 0.8823 - accuracy: 0.59 - ETA: 0s - loss: 0.8793 - accuracy: 0.60 - ETA: 0s - loss: 0.8695 - accuracy: 0.61 - ETA: 0s - loss: 0.8667 - accuracy: 0.62 - ETA: 0s - loss: 0.8667 - accuracy: 0.62 - ETA: 0s - loss: 0.8670 - accuracy: 0.62 - ETA: 0s - loss: 0.8741 - accuracy: 0.61 - ETA: 0s - loss: 0.8692 - accuracy: 0.62 - ETA: 0s - loss: 0.8627 - accuracy: 0.62 - ETA: 0s - loss: 0.8449 - accuracy: 0.64 - ETA: 0s - loss: 0.8527 - accuracy: 0.63 - ETA: 0s - loss: 0.8686 - accuracy: 0.62 - ETA: 0s - loss: 0.8719 - accuracy: 0.61 - ETA: 0s - loss: 0.8766 - accuracy: 0.61 - ETA: 0s - loss: 0.8782 - accuracy: 0.61 - ETA: 0s - loss: 0.8792 - accuracy: 0.6136\n",
      "Epoch 00502: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8792 - accuracy: 0.6136 - val_loss: 1.0462 - val_accuracy: 0.4827 - lr: 0.0010\n",
      "Epoch 503/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9461 - accuracy: 0.51 - ETA: 0s - loss: 0.9124 - accuracy: 0.55 - ETA: 0s - loss: 0.9197 - accuracy: 0.56 - ETA: 0s - loss: 0.8874 - accuracy: 0.59 - ETA: 0s - loss: 0.8822 - accuracy: 0.59 - ETA: 0s - loss: 0.8729 - accuracy: 0.61 - ETA: 0s - loss: 0.8714 - accuracy: 0.61 - ETA: 0s - loss: 0.8720 - accuracy: 0.61 - ETA: 0s - loss: 0.8718 - accuracy: 0.61 - ETA: 0s - loss: 0.8772 - accuracy: 0.61 - ETA: 0s - loss: 0.8714 - accuracy: 0.61 - ETA: 0s - loss: 0.8645 - accuracy: 0.62 - ETA: 0s - loss: 0.8472 - accuracy: 0.63 - ETA: 0s - loss: 0.8562 - accuracy: 0.63 - ETA: 0s - loss: 0.8715 - accuracy: 0.61 - ETA: 0s - loss: 0.8742 - accuracy: 0.61 - ETA: 0s - loss: 0.8797 - accuracy: 0.60 - ETA: 0s - loss: 0.8813 - accuracy: 0.60 - ETA: 0s - loss: 0.8826 - accuracy: 0.6087\n",
      "Epoch 00503: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8826 - accuracy: 0.6087 - val_loss: 1.0427 - val_accuracy: 0.4834 - lr: 0.0010\n",
      "Epoch 504/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9462 - accuracy: 0.54 - ETA: 0s - loss: 0.9121 - accuracy: 0.57 - ETA: 0s - loss: 0.9187 - accuracy: 0.57 - ETA: 0s - loss: 0.8880 - accuracy: 0.59 - ETA: 0s - loss: 0.8853 - accuracy: 0.60 - ETA: 0s - loss: 0.8766 - accuracy: 0.61 - ETA: 0s - loss: 0.8724 - accuracy: 0.61 - ETA: 0s - loss: 0.8729 - accuracy: 0.62 - ETA: 0s - loss: 0.8740 - accuracy: 0.62 - ETA: 0s - loss: 0.8784 - accuracy: 0.61 - ETA: 0s - loss: 0.8728 - accuracy: 0.62 - ETA: 0s - loss: 0.8658 - accuracy: 0.62 - ETA: 0s - loss: 0.8480 - accuracy: 0.64 - ETA: 0s - loss: 0.8555 - accuracy: 0.63 - ETA: 0s - loss: 0.8706 - accuracy: 0.62 - ETA: 0s - loss: 0.8731 - accuracy: 0.61 - ETA: 0s - loss: 0.8785 - accuracy: 0.61 - ETA: 0s - loss: 0.8802 - accuracy: 0.61 - ETA: 0s - loss: 0.8815 - accuracy: 0.6123\n",
      "Epoch 00504: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8815 - accuracy: 0.6123 - val_loss: 1.0426 - val_accuracy: 0.4811 - lr: 0.0010\n",
      "Epoch 505/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9510 - accuracy: 0.55 - ETA: 0s - loss: 0.9173 - accuracy: 0.57 - ETA: 0s - loss: 0.9223 - accuracy: 0.57 - ETA: 0s - loss: 0.8884 - accuracy: 0.59 - ETA: 0s - loss: 0.8855 - accuracy: 0.60 - ETA: 0s - loss: 0.8767 - accuracy: 0.61 - ETA: 0s - loss: 0.8742 - accuracy: 0.61 - ETA: 0s - loss: 0.8727 - accuracy: 0.62 - ETA: 0s - loss: 0.8730 - accuracy: 0.62 - ETA: 0s - loss: 0.8785 - accuracy: 0.61 - ETA: 0s - loss: 0.8727 - accuracy: 0.62 - ETA: 0s - loss: 0.8654 - accuracy: 0.63 - ETA: 0s - loss: 0.8476 - accuracy: 0.64 - ETA: 0s - loss: 0.8570 - accuracy: 0.63 - ETA: 0s - loss: 0.8714 - accuracy: 0.61 - ETA: 0s - loss: 0.8735 - accuracy: 0.61 - ETA: 0s - loss: 0.8793 - accuracy: 0.61 - ETA: 0s - loss: 0.8807 - accuracy: 0.61 - ETA: 0s - loss: 0.8826 - accuracy: 0.6123\n",
      "Epoch 00505: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8826 - accuracy: 0.6123 - val_loss: 1.0621 - val_accuracy: 0.4839 - lr: 0.0010\n",
      "Epoch 506/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9314 - accuracy: 0.55 - ETA: 0s - loss: 0.9051 - accuracy: 0.57 - ETA: 0s - loss: 0.9132 - accuracy: 0.57 - ETA: 0s - loss: 0.8848 - accuracy: 0.59 - ETA: 0s - loss: 0.8822 - accuracy: 0.60 - ETA: 0s - loss: 0.8725 - accuracy: 0.61 - ETA: 0s - loss: 0.8697 - accuracy: 0.62 - ETA: 0s - loss: 0.8700 - accuracy: 0.62 - ETA: 0s - loss: 0.8707 - accuracy: 0.61 - ETA: 0s - loss: 0.8771 - accuracy: 0.61 - ETA: 0s - loss: 0.8712 - accuracy: 0.61 - ETA: 0s - loss: 0.8645 - accuracy: 0.62 - ETA: 0s - loss: 0.8469 - accuracy: 0.64 - ETA: 0s - loss: 0.8551 - accuracy: 0.63 - ETA: 0s - loss: 0.8698 - accuracy: 0.62 - ETA: 0s - loss: 0.8722 - accuracy: 0.61 - ETA: 0s - loss: 0.8774 - accuracy: 0.61 - ETA: 0s - loss: 0.8792 - accuracy: 0.61 - ETA: 0s - loss: 0.8813 - accuracy: 0.6128\n",
      "Epoch 00506: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8813 - accuracy: 0.6128 - val_loss: 1.0555 - val_accuracy: 0.4847 - lr: 0.0010\n",
      "Epoch 507/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9339 - accuracy: 0.54 - ETA: 0s - loss: 0.9096 - accuracy: 0.56 - ETA: 0s - loss: 0.9199 - accuracy: 0.56 - ETA: 0s - loss: 0.8900 - accuracy: 0.59 - ETA: 0s - loss: 0.8863 - accuracy: 0.60 - ETA: 0s - loss: 0.8775 - accuracy: 0.61 - ETA: 0s - loss: 0.8752 - accuracy: 0.61 - ETA: 0s - loss: 0.8728 - accuracy: 0.62 - ETA: 0s - loss: 0.8728 - accuracy: 0.61 - ETA: 0s - loss: 0.8761 - accuracy: 0.61 - ETA: 0s - loss: 0.8698 - accuracy: 0.62 - ETA: 0s - loss: 0.8633 - accuracy: 0.62 - ETA: 0s - loss: 0.8458 - accuracy: 0.64 - ETA: 0s - loss: 0.8539 - accuracy: 0.63 - ETA: 0s - loss: 0.8683 - accuracy: 0.61 - ETA: 0s - loss: 0.8705 - accuracy: 0.61 - ETA: 0s - loss: 0.8767 - accuracy: 0.61 - ETA: 0s - loss: 0.8779 - accuracy: 0.61 - ETA: 0s - loss: 0.8800 - accuracy: 0.6125\n",
      "Epoch 00507: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8800 - accuracy: 0.6125 - val_loss: 1.0499 - val_accuracy: 0.4844 - lr: 0.0010\n",
      "Epoch 508/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9369 - accuracy: 0.54 - ETA: 0s - loss: 0.9125 - accuracy: 0.56 - ETA: 0s - loss: 0.9201 - accuracy: 0.57 - ETA: 0s - loss: 0.8871 - accuracy: 0.59 - ETA: 0s - loss: 0.8842 - accuracy: 0.60 - ETA: 0s - loss: 0.8751 - accuracy: 0.61 - ETA: 0s - loss: 0.8728 - accuracy: 0.62 - ETA: 0s - loss: 0.8731 - accuracy: 0.62 - ETA: 0s - loss: 0.8738 - accuracy: 0.62 - ETA: 0s - loss: 0.8797 - accuracy: 0.61 - ETA: 0s - loss: 0.8748 - accuracy: 0.62 - ETA: 0s - loss: 0.8692 - accuracy: 0.62 - ETA: 0s - loss: 0.8511 - accuracy: 0.63 - ETA: 0s - loss: 0.8582 - accuracy: 0.63 - ETA: 0s - loss: 0.8730 - accuracy: 0.61 - ETA: 0s - loss: 0.8758 - accuracy: 0.61 - ETA: 0s - loss: 0.8814 - accuracy: 0.61 - ETA: 0s - loss: 0.8815 - accuracy: 0.61 - ETA: 0s - loss: 0.8828 - accuracy: 0.6128\n",
      "Epoch 00508: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8828 - accuracy: 0.6128 - val_loss: 1.0432 - val_accuracy: 0.4879 - lr: 0.0010\n",
      "Epoch 509/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9354 - accuracy: 0.54 - ETA: 0s - loss: 0.9083 - accuracy: 0.56 - ETA: 0s - loss: 0.9181 - accuracy: 0.56 - ETA: 0s - loss: 0.8868 - accuracy: 0.59 - ETA: 0s - loss: 0.8834 - accuracy: 0.60 - ETA: 0s - loss: 0.8725 - accuracy: 0.61 - ETA: 0s - loss: 0.8707 - accuracy: 0.61 - ETA: 0s - loss: 0.8702 - accuracy: 0.62 - ETA: 0s - loss: 0.8714 - accuracy: 0.61 - ETA: 0s - loss: 0.8759 - accuracy: 0.61 - ETA: 0s - loss: 0.8713 - accuracy: 0.62 - ETA: 0s - loss: 0.8648 - accuracy: 0.62 - ETA: 0s - loss: 0.8470 - accuracy: 0.64 - ETA: 0s - loss: 0.8552 - accuracy: 0.63 - ETA: 0s - loss: 0.8681 - accuracy: 0.62 - ETA: 0s - loss: 0.8709 - accuracy: 0.61 - ETA: 0s - loss: 0.8767 - accuracy: 0.61 - ETA: 0s - loss: 0.8779 - accuracy: 0.61 - ETA: 0s - loss: 0.8795 - accuracy: 0.6137\n",
      "Epoch 00509: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8795 - accuracy: 0.6137 - val_loss: 1.0570 - val_accuracy: 0.4834 - lr: 0.0010\n",
      "Epoch 510/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9433 - accuracy: 0.53 - ETA: 0s - loss: 0.9154 - accuracy: 0.56 - ETA: 0s - loss: 0.9253 - accuracy: 0.57 - ETA: 0s - loss: 0.8916 - accuracy: 0.60 - ETA: 0s - loss: 0.8889 - accuracy: 0.60 - ETA: 0s - loss: 0.8788 - accuracy: 0.61 - ETA: 0s - loss: 0.8744 - accuracy: 0.62 - ETA: 0s - loss: 0.8741 - accuracy: 0.62 - ETA: 0s - loss: 0.8756 - accuracy: 0.62 - ETA: 0s - loss: 0.8809 - accuracy: 0.61 - ETA: 0s - loss: 0.8742 - accuracy: 0.62 - ETA: 0s - loss: 0.8668 - accuracy: 0.62 - ETA: 0s - loss: 0.8495 - accuracy: 0.64 - ETA: 0s - loss: 0.8574 - accuracy: 0.63 - ETA: 0s - loss: 0.8709 - accuracy: 0.62 - ETA: 0s - loss: 0.8734 - accuracy: 0.61 - ETA: 0s - loss: 0.8790 - accuracy: 0.61 - ETA: 0s - loss: 0.8806 - accuracy: 0.61 - ETA: 0s - loss: 0.8821 - accuracy: 0.6134\n",
      "Epoch 00510: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8821 - accuracy: 0.6134 - val_loss: 1.0568 - val_accuracy: 0.4821 - lr: 0.0010\n",
      "Epoch 511/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9334 - accuracy: 0.53 - ETA: 0s - loss: 0.9066 - accuracy: 0.56 - ETA: 0s - loss: 0.9135 - accuracy: 0.56 - ETA: 0s - loss: 0.8808 - accuracy: 0.59 - ETA: 0s - loss: 0.8774 - accuracy: 0.60 - ETA: 0s - loss: 0.8686 - accuracy: 0.61 - ETA: 0s - loss: 0.8662 - accuracy: 0.61 - ETA: 0s - loss: 0.8651 - accuracy: 0.62 - ETA: 0s - loss: 0.8659 - accuracy: 0.61 - ETA: 0s - loss: 0.8720 - accuracy: 0.61 - ETA: 0s - loss: 0.8663 - accuracy: 0.62 - ETA: 0s - loss: 0.8602 - accuracy: 0.62 - ETA: 0s - loss: 0.8425 - accuracy: 0.64 - ETA: 0s - loss: 0.8487 - accuracy: 0.63 - ETA: 0s - loss: 0.8634 - accuracy: 0.62 - ETA: 0s - loss: 0.8667 - accuracy: 0.61 - ETA: 0s - loss: 0.8726 - accuracy: 0.61 - ETA: 0s - loss: 0.8747 - accuracy: 0.61 - ETA: 0s - loss: 0.8760 - accuracy: 0.6133\n",
      "Epoch 00511: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8760 - accuracy: 0.6133 - val_loss: 1.0467 - val_accuracy: 0.4853 - lr: 0.0010\n",
      "Epoch 512/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9324 - accuracy: 0.53 - ETA: 0s - loss: 0.9069 - accuracy: 0.57 - ETA: 0s - loss: 0.9139 - accuracy: 0.57 - ETA: 0s - loss: 0.8833 - accuracy: 0.59 - ETA: 0s - loss: 0.8807 - accuracy: 0.60 - ETA: 0s - loss: 0.8716 - accuracy: 0.61 - ETA: 0s - loss: 0.8698 - accuracy: 0.61 - ETA: 0s - loss: 0.8691 - accuracy: 0.62 - ETA: 0s - loss: 0.8702 - accuracy: 0.61 - ETA: 0s - loss: 0.8757 - accuracy: 0.61 - ETA: 0s - loss: 0.8696 - accuracy: 0.62 - ETA: 0s - loss: 0.8630 - accuracy: 0.62 - ETA: 0s - loss: 0.8453 - accuracy: 0.64 - ETA: 0s - loss: 0.8526 - accuracy: 0.63 - ETA: 0s - loss: 0.8678 - accuracy: 0.62 - ETA: 0s - loss: 0.8704 - accuracy: 0.61 - ETA: 0s - loss: 0.8757 - accuracy: 0.61 - ETA: 0s - loss: 0.8782 - accuracy: 0.61 - ETA: 0s - loss: 0.8791 - accuracy: 0.6131\n",
      "Epoch 00512: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8791 - accuracy: 0.6131 - val_loss: 1.0532 - val_accuracy: 0.4847 - lr: 0.0010\n",
      "Epoch 513/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9244 - accuracy: 0.54 - ETA: 0s - loss: 0.9040 - accuracy: 0.57 - ETA: 0s - loss: 0.9162 - accuracy: 0.57 - ETA: 0s - loss: 0.8825 - accuracy: 0.60 - ETA: 0s - loss: 0.8787 - accuracy: 0.60 - ETA: 0s - loss: 0.8710 - accuracy: 0.61 - ETA: 0s - loss: 0.8689 - accuracy: 0.62 - ETA: 0s - loss: 0.8679 - accuracy: 0.62 - ETA: 0s - loss: 0.8703 - accuracy: 0.61 - ETA: 0s - loss: 0.8750 - accuracy: 0.61 - ETA: 0s - loss: 0.8692 - accuracy: 0.62 - ETA: 0s - loss: 0.8632 - accuracy: 0.62 - ETA: 0s - loss: 0.8458 - accuracy: 0.64 - ETA: 0s - loss: 0.8533 - accuracy: 0.63 - ETA: 0s - loss: 0.8647 - accuracy: 0.62 - ETA: 0s - loss: 0.8671 - accuracy: 0.62 - ETA: 0s - loss: 0.8726 - accuracy: 0.61 - ETA: 0s - loss: 0.8749 - accuracy: 0.61 - ETA: 0s - loss: 0.8767 - accuracy: 0.6148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00513: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8767 - accuracy: 0.6148 - val_loss: 1.0538 - val_accuracy: 0.4780 - lr: 0.0010\n",
      "Epoch 514/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9458 - accuracy: 0.52 - ETA: 0s - loss: 0.9088 - accuracy: 0.56 - ETA: 0s - loss: 0.9170 - accuracy: 0.57 - ETA: 0s - loss: 0.8857 - accuracy: 0.59 - ETA: 0s - loss: 0.8817 - accuracy: 0.60 - ETA: 0s - loss: 0.8733 - accuracy: 0.61 - ETA: 0s - loss: 0.8698 - accuracy: 0.62 - ETA: 0s - loss: 0.8700 - accuracy: 0.62 - ETA: 0s - loss: 0.8713 - accuracy: 0.61 - ETA: 0s - loss: 0.8756 - accuracy: 0.61 - ETA: 0s - loss: 0.8699 - accuracy: 0.62 - ETA: 0s - loss: 0.8637 - accuracy: 0.62 - ETA: 0s - loss: 0.8460 - accuracy: 0.64 - ETA: 0s - loss: 0.8537 - accuracy: 0.63 - ETA: 0s - loss: 0.8681 - accuracy: 0.62 - ETA: 0s - loss: 0.8700 - accuracy: 0.61 - ETA: 0s - loss: 0.8759 - accuracy: 0.61 - ETA: 0s - loss: 0.8779 - accuracy: 0.61 - ETA: 0s - loss: 0.8797 - accuracy: 0.6141\n",
      "Epoch 00514: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8797 - accuracy: 0.6141 - val_loss: 1.0489 - val_accuracy: 0.4855 - lr: 0.0010\n",
      "Epoch 515/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9196 - accuracy: 0.55 - ETA: 0s - loss: 0.9000 - accuracy: 0.57 - ETA: 0s - loss: 0.9056 - accuracy: 0.58 - ETA: 0s - loss: 0.8770 - accuracy: 0.60 - ETA: 0s - loss: 0.8729 - accuracy: 0.60 - ETA: 0s - loss: 0.8656 - accuracy: 0.61 - ETA: 0s - loss: 0.8636 - accuracy: 0.62 - ETA: 0s - loss: 0.8659 - accuracy: 0.62 - ETA: 0s - loss: 0.8670 - accuracy: 0.62 - ETA: 0s - loss: 0.8726 - accuracy: 0.61 - ETA: 0s - loss: 0.8681 - accuracy: 0.62 - ETA: 0s - loss: 0.8617 - accuracy: 0.62 - ETA: 0s - loss: 0.8442 - accuracy: 0.64 - ETA: 0s - loss: 0.8509 - accuracy: 0.63 - ETA: 0s - loss: 0.8663 - accuracy: 0.62 - ETA: 0s - loss: 0.8692 - accuracy: 0.62 - ETA: 0s - loss: 0.8749 - accuracy: 0.61 - ETA: 0s - loss: 0.8769 - accuracy: 0.61 - ETA: 0s - loss: 0.8776 - accuracy: 0.6172\n",
      "Epoch 00515: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00515: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8776 - accuracy: 0.6172 - val_loss: 1.0601 - val_accuracy: 0.4777 - lr: 0.0010\n",
      "Epoch 516/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.9458 - accuracy: 0.54 - ETA: 0s - loss: 0.9123 - accuracy: 0.57 - ETA: 0s - loss: 0.9206 - accuracy: 0.57 - ETA: 0s - loss: 0.8870 - accuracy: 0.59 - ETA: 0s - loss: 0.8831 - accuracy: 0.60 - ETA: 0s - loss: 0.8735 - accuracy: 0.61 - ETA: 0s - loss: 0.8715 - accuracy: 0.62 - ETA: 0s - loss: 0.8694 - accuracy: 0.62 - ETA: 0s - loss: 0.8687 - accuracy: 0.62 - ETA: 0s - loss: 0.8737 - accuracy: 0.61 - ETA: 0s - loss: 0.8685 - accuracy: 0.62 - ETA: 0s - loss: 0.8618 - accuracy: 0.63 - ETA: 0s - loss: 0.8435 - accuracy: 0.64 - ETA: 0s - loss: 0.8516 - accuracy: 0.63 - ETA: 0s - loss: 0.8671 - accuracy: 0.62 - ETA: 0s - loss: 0.8691 - accuracy: 0.62 - ETA: 0s - loss: 0.8751 - accuracy: 0.61 - ETA: 0s - loss: 0.8769 - accuracy: 0.6166\n",
      "Epoch 00516: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8784 - accuracy: 0.6148 - val_loss: 1.0645 - val_accuracy: 0.4780 - lr: 0.0010\n",
      "Epoch 517/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9312 - accuracy: 0.52 - ETA: 0s - loss: 0.9101 - accuracy: 0.55 - ETA: 0s - loss: 0.9218 - accuracy: 0.55 - ETA: 0s - loss: 0.8903 - accuracy: 0.58 - ETA: 0s - loss: 0.8846 - accuracy: 0.59 - ETA: 0s - loss: 0.8731 - accuracy: 0.60 - ETA: 0s - loss: 0.8705 - accuracy: 0.61 - ETA: 0s - loss: 0.8692 - accuracy: 0.61 - ETA: 0s - loss: 0.8701 - accuracy: 0.61 - ETA: 0s - loss: 0.8758 - accuracy: 0.60 - ETA: 0s - loss: 0.8709 - accuracy: 0.61 - ETA: 0s - loss: 0.8649 - accuracy: 0.62 - ETA: 0s - loss: 0.8474 - accuracy: 0.63 - ETA: 0s - loss: 0.8539 - accuracy: 0.63 - ETA: 0s - loss: 0.8676 - accuracy: 0.61 - ETA: 0s - loss: 0.8706 - accuracy: 0.61 - ETA: 0s - loss: 0.8759 - accuracy: 0.61 - ETA: 0s - loss: 0.8772 - accuracy: 0.61 - ETA: 0s - loss: 0.8785 - accuracy: 0.6107\n",
      "Epoch 00517: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8785 - accuracy: 0.6107 - val_loss: 1.0683 - val_accuracy: 0.4754 - lr: 0.0010\n",
      "Epoch 518/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9192 - accuracy: 0.56 - ETA: 0s - loss: 0.9003 - accuracy: 0.57 - ETA: 0s - loss: 0.9167 - accuracy: 0.56 - ETA: 0s - loss: 0.8858 - accuracy: 0.59 - ETA: 0s - loss: 0.8841 - accuracy: 0.60 - ETA: 0s - loss: 0.8732 - accuracy: 0.61 - ETA: 0s - loss: 0.8696 - accuracy: 0.62 - ETA: 0s - loss: 0.8686 - accuracy: 0.62 - ETA: 0s - loss: 0.8692 - accuracy: 0.62 - ETA: 0s - loss: 0.8759 - accuracy: 0.61 - ETA: 0s - loss: 0.8710 - accuracy: 0.62 - ETA: 0s - loss: 0.8652 - accuracy: 0.62 - ETA: 0s - loss: 0.8468 - accuracy: 0.64 - ETA: 0s - loss: 0.8708 - accuracy: 0.62 - ETA: 0s - loss: 0.8727 - accuracy: 0.61 - ETA: 0s - loss: 0.8785 - accuracy: 0.61 - ETA: 0s - loss: 0.8801 - accuracy: 0.61 - ETA: 0s - loss: 0.8813 - accuracy: 0.6146\n",
      "Epoch 00518: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8813 - accuracy: 0.6146 - val_loss: 1.0606 - val_accuracy: 0.4803 - lr: 0.0010\n",
      "Epoch 519/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9156 - accuracy: 0.54 - ETA: 0s - loss: 0.8957 - accuracy: 0.57 - ETA: 0s - loss: 0.9033 - accuracy: 0.57 - ETA: 0s - loss: 0.8761 - accuracy: 0.59 - ETA: 0s - loss: 0.8750 - accuracy: 0.60 - ETA: 0s - loss: 0.8664 - accuracy: 0.61 - ETA: 0s - loss: 0.8635 - accuracy: 0.62 - ETA: 0s - loss: 0.8659 - accuracy: 0.62 - ETA: 0s - loss: 0.8676 - accuracy: 0.62 - ETA: 0s - loss: 0.8741 - accuracy: 0.61 - ETA: 0s - loss: 0.8697 - accuracy: 0.62 - ETA: 0s - loss: 0.8642 - accuracy: 0.62 - ETA: 0s - loss: 0.8465 - accuracy: 0.64 - ETA: 0s - loss: 0.8549 - accuracy: 0.63 - ETA: 0s - loss: 0.8692 - accuracy: 0.61 - ETA: 0s - loss: 0.8711 - accuracy: 0.61 - ETA: 0s - loss: 0.8764 - accuracy: 0.61 - ETA: 0s - loss: 0.8779 - accuracy: 0.61 - ETA: 0s - loss: 0.8791 - accuracy: 0.6120\n",
      "Epoch 00519: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8791 - accuracy: 0.6120 - val_loss: 1.0653 - val_accuracy: 0.4819 - lr: 0.0010\n",
      "Epoch 520/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9198 - accuracy: 0.54 - ETA: 0s - loss: 0.8999 - accuracy: 0.56 - ETA: 0s - loss: 0.9093 - accuracy: 0.56 - ETA: 0s - loss: 0.8790 - accuracy: 0.59 - ETA: 0s - loss: 0.8762 - accuracy: 0.60 - ETA: 0s - loss: 0.8669 - accuracy: 0.61 - ETA: 0s - loss: 0.8641 - accuracy: 0.61 - ETA: 0s - loss: 0.8641 - accuracy: 0.62 - ETA: 0s - loss: 0.8677 - accuracy: 0.61 - ETA: 0s - loss: 0.8726 - accuracy: 0.61 - ETA: 0s - loss: 0.8685 - accuracy: 0.62 - ETA: 0s - loss: 0.8621 - accuracy: 0.62 - ETA: 0s - loss: 0.8448 - accuracy: 0.64 - ETA: 0s - loss: 0.8535 - accuracy: 0.63 - ETA: 0s - loss: 0.8653 - accuracy: 0.62 - ETA: 0s - loss: 0.8669 - accuracy: 0.62 - ETA: 0s - loss: 0.8724 - accuracy: 0.61 - ETA: 0s - loss: 0.8746 - accuracy: 0.61 - ETA: 0s - loss: 0.8766 - accuracy: 0.6148\n",
      "Epoch 00520: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8766 - accuracy: 0.6148 - val_loss: 1.0675 - val_accuracy: 0.4809 - lr: 0.0010\n",
      "Epoch 521/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9258 - accuracy: 0.54 - ETA: 0s - loss: 0.9014 - accuracy: 0.56 - ETA: 0s - loss: 0.9119 - accuracy: 0.56 - ETA: 0s - loss: 0.8807 - accuracy: 0.59 - ETA: 0s - loss: 0.8784 - accuracy: 0.60 - ETA: 0s - loss: 0.8686 - accuracy: 0.61 - ETA: 0s - loss: 0.8679 - accuracy: 0.61 - ETA: 0s - loss: 0.8659 - accuracy: 0.62 - ETA: 0s - loss: 0.8676 - accuracy: 0.62 - ETA: 0s - loss: 0.8735 - accuracy: 0.61 - ETA: 0s - loss: 0.8674 - accuracy: 0.62 - ETA: 0s - loss: 0.8611 - accuracy: 0.62 - ETA: 0s - loss: 0.8434 - accuracy: 0.64 - ETA: 0s - loss: 0.8515 - accuracy: 0.63 - ETA: 0s - loss: 0.8662 - accuracy: 0.62 - ETA: 0s - loss: 0.8690 - accuracy: 0.61 - ETA: 0s - loss: 0.8747 - accuracy: 0.61 - ETA: 0s - loss: 0.8754 - accuracy: 0.61 - ETA: 0s - loss: 0.8771 - accuracy: 0.6134\n",
      "Epoch 00521: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8771 - accuracy: 0.6134 - val_loss: 1.0702 - val_accuracy: 0.4790 - lr: 0.0010\n",
      "Epoch 522/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9432 - accuracy: 0.55 - ETA: 0s - loss: 0.9074 - accuracy: 0.57 - ETA: 0s - loss: 0.9223 - accuracy: 0.57 - ETA: 0s - loss: 0.8903 - accuracy: 0.60 - ETA: 0s - loss: 0.8847 - accuracy: 0.60 - ETA: 0s - loss: 0.8733 - accuracy: 0.61 - ETA: 0s - loss: 0.8714 - accuracy: 0.62 - ETA: 0s - loss: 0.8700 - accuracy: 0.62 - ETA: 0s - loss: 0.8715 - accuracy: 0.62 - ETA: 0s - loss: 0.8783 - accuracy: 0.61 - ETA: 0s - loss: 0.8731 - accuracy: 0.62 - ETA: 0s - loss: 0.8653 - accuracy: 0.62 - ETA: 0s - loss: 0.8475 - accuracy: 0.64 - ETA: 0s - loss: 0.8547 - accuracy: 0.63 - ETA: 0s - loss: 0.8684 - accuracy: 0.62 - ETA: 0s - loss: 0.8705 - accuracy: 0.62 - ETA: 0s - loss: 0.8761 - accuracy: 0.61 - ETA: 0s - loss: 0.8775 - accuracy: 0.61 - ETA: 0s - loss: 0.8794 - accuracy: 0.6145\n",
      "Epoch 00522: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8794 - accuracy: 0.6145 - val_loss: 1.0688 - val_accuracy: 0.4809 - lr: 0.0010\n",
      "Epoch 523/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9273 - accuracy: 0.53 - ETA: 0s - loss: 0.9033 - accuracy: 0.56 - ETA: 0s - loss: 0.9137 - accuracy: 0.56 - ETA: 0s - loss: 0.8840 - accuracy: 0.59 - ETA: 0s - loss: 0.8799 - accuracy: 0.60 - ETA: 0s - loss: 0.8709 - accuracy: 0.61 - ETA: 0s - loss: 0.8680 - accuracy: 0.61 - ETA: 0s - loss: 0.8674 - accuracy: 0.62 - ETA: 0s - loss: 0.8681 - accuracy: 0.61 - ETA: 0s - loss: 0.8738 - accuracy: 0.61 - ETA: 0s - loss: 0.8681 - accuracy: 0.61 - ETA: 0s - loss: 0.8625 - accuracy: 0.62 - ETA: 0s - loss: 0.8449 - accuracy: 0.63 - ETA: 0s - loss: 0.8520 - accuracy: 0.63 - ETA: 0s - loss: 0.8665 - accuracy: 0.61 - ETA: 0s - loss: 0.8690 - accuracy: 0.61 - ETA: 0s - loss: 0.8744 - accuracy: 0.61 - ETA: 0s - loss: 0.8756 - accuracy: 0.61 - ETA: 0s - loss: 0.8774 - accuracy: 0.6111\n",
      "Epoch 00523: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8774 - accuracy: 0.6111 - val_loss: 1.0549 - val_accuracy: 0.4868 - lr: 0.0010\n",
      "Epoch 524/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9166 - accuracy: 0.55 - ETA: 0s - loss: 0.8949 - accuracy: 0.57 - ETA: 0s - loss: 0.9064 - accuracy: 0.57 - ETA: 0s - loss: 0.8735 - accuracy: 0.59 - ETA: 0s - loss: 0.8715 - accuracy: 0.60 - ETA: 0s - loss: 0.8634 - accuracy: 0.61 - ETA: 0s - loss: 0.8617 - accuracy: 0.62 - ETA: 0s - loss: 0.8642 - accuracy: 0.62 - ETA: 0s - loss: 0.8649 - accuracy: 0.62 - ETA: 0s - loss: 0.8712 - accuracy: 0.61 - ETA: 0s - loss: 0.8653 - accuracy: 0.61 - ETA: 0s - loss: 0.8590 - accuracy: 0.62 - ETA: 0s - loss: 0.8418 - accuracy: 0.64 - ETA: 0s - loss: 0.8492 - accuracy: 0.63 - ETA: 0s - loss: 0.8652 - accuracy: 0.62 - ETA: 0s - loss: 0.8680 - accuracy: 0.61 - ETA: 0s - loss: 0.8737 - accuracy: 0.61 - ETA: 0s - loss: 0.8756 - accuracy: 0.61 - ETA: 0s - loss: 0.8770 - accuracy: 0.6143\n",
      "Epoch 00524: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8770 - accuracy: 0.6143 - val_loss: 1.0517 - val_accuracy: 0.4917 - lr: 0.0010\n",
      "Epoch 525/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9272 - accuracy: 0.55 - ETA: 0s - loss: 0.8963 - accuracy: 0.57 - ETA: 0s - loss: 0.9075 - accuracy: 0.57 - ETA: 0s - loss: 0.8785 - accuracy: 0.60 - ETA: 0s - loss: 0.8744 - accuracy: 0.60 - ETA: 0s - loss: 0.8656 - accuracy: 0.62 - ETA: 0s - loss: 0.8643 - accuracy: 0.62 - ETA: 0s - loss: 0.8653 - accuracy: 0.62 - ETA: 0s - loss: 0.8667 - accuracy: 0.62 - ETA: 0s - loss: 0.8716 - accuracy: 0.61 - ETA: 0s - loss: 0.8662 - accuracy: 0.62 - ETA: 0s - loss: 0.8600 - accuracy: 0.63 - ETA: 0s - loss: 0.8426 - accuracy: 0.64 - ETA: 0s - loss: 0.8496 - accuracy: 0.63 - ETA: 0s - loss: 0.8634 - accuracy: 0.62 - ETA: 0s - loss: 0.8657 - accuracy: 0.62 - ETA: 0s - loss: 0.8716 - accuracy: 0.61 - ETA: 0s - loss: 0.8732 - accuracy: 0.61 - ETA: 0s - loss: 0.8747 - accuracy: 0.6180\n",
      "Epoch 00525: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8747 - accuracy: 0.6180 - val_loss: 1.0600 - val_accuracy: 0.4876 - lr: 0.0010\n",
      "Epoch 526/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9187 - accuracy: 0.55 - ETA: 0s - loss: 0.8909 - accuracy: 0.57 - ETA: 0s - loss: 0.9051 - accuracy: 0.57 - ETA: 0s - loss: 0.8777 - accuracy: 0.59 - ETA: 0s - loss: 0.8780 - accuracy: 0.60 - ETA: 0s - loss: 0.8696 - accuracy: 0.61 - ETA: 0s - loss: 0.8660 - accuracy: 0.62 - ETA: 0s - loss: 0.8657 - accuracy: 0.62 - ETA: 0s - loss: 0.8671 - accuracy: 0.62 - ETA: 0s - loss: 0.8726 - accuracy: 0.61 - ETA: 0s - loss: 0.8672 - accuracy: 0.62 - ETA: 0s - loss: 0.8605 - accuracy: 0.63 - ETA: 0s - loss: 0.8421 - accuracy: 0.64 - ETA: 0s - loss: 0.8486 - accuracy: 0.63 - ETA: 0s - loss: 0.8633 - accuracy: 0.62 - ETA: 0s - loss: 0.8657 - accuracy: 0.62 - ETA: 0s - loss: 0.8706 - accuracy: 0.61 - ETA: 0s - loss: 0.8730 - accuracy: 0.61 - ETA: 0s - loss: 0.8753 - accuracy: 0.6180\n",
      "Epoch 00526: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8753 - accuracy: 0.6180 - val_loss: 1.0613 - val_accuracy: 0.4873 - lr: 0.0010\n",
      "Epoch 527/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9147 - accuracy: 0.55 - ETA: 0s - loss: 0.8953 - accuracy: 0.57 - ETA: 0s - loss: 0.9037 - accuracy: 0.57 - ETA: 0s - loss: 0.8728 - accuracy: 0.60 - ETA: 0s - loss: 0.8717 - accuracy: 0.61 - ETA: 0s - loss: 0.8634 - accuracy: 0.62 - ETA: 0s - loss: 0.8625 - accuracy: 0.62 - ETA: 0s - loss: 0.8621 - accuracy: 0.62 - ETA: 0s - loss: 0.8639 - accuracy: 0.62 - ETA: 0s - loss: 0.8694 - accuracy: 0.61 - ETA: 0s - loss: 0.8656 - accuracy: 0.62 - ETA: 0s - loss: 0.8591 - accuracy: 0.63 - ETA: 0s - loss: 0.8413 - accuracy: 0.64 - ETA: 0s - loss: 0.8488 - accuracy: 0.63 - ETA: 0s - loss: 0.8631 - accuracy: 0.62 - ETA: 0s - loss: 0.8660 - accuracy: 0.62 - ETA: 0s - loss: 0.8714 - accuracy: 0.61 - ETA: 0s - loss: 0.8734 - accuracy: 0.61 - ETA: 0s - loss: 0.8749 - accuracy: 0.6164\n",
      "Epoch 00527: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8749 - accuracy: 0.6164 - val_loss: 1.0618 - val_accuracy: 0.4855 - lr: 0.0010\n",
      "Epoch 528/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9072 - accuracy: 0.57 - ETA: 0s - loss: 0.8971 - accuracy: 0.58 - ETA: 0s - loss: 0.9119 - accuracy: 0.58 - ETA: 0s - loss: 0.8807 - accuracy: 0.60 - ETA: 0s - loss: 0.8772 - accuracy: 0.61 - ETA: 0s - loss: 0.8685 - accuracy: 0.62 - ETA: 0s - loss: 0.8676 - accuracy: 0.62 - ETA: 0s - loss: 0.8678 - accuracy: 0.62 - ETA: 0s - loss: 0.8687 - accuracy: 0.62 - ETA: 0s - loss: 0.8731 - accuracy: 0.61 - ETA: 0s - loss: 0.8670 - accuracy: 0.62 - ETA: 0s - loss: 0.8601 - accuracy: 0.63 - ETA: 0s - loss: 0.8422 - accuracy: 0.64 - ETA: 0s - loss: 0.8497 - accuracy: 0.63 - ETA: 0s - loss: 0.8629 - accuracy: 0.62 - ETA: 0s - loss: 0.8656 - accuracy: 0.62 - ETA: 0s - loss: 0.8713 - accuracy: 0.61 - ETA: 0s - loss: 0.8726 - accuracy: 0.61 - ETA: 0s - loss: 0.8749 - accuracy: 0.6168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00528: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8749 - accuracy: 0.6168 - val_loss: 1.0626 - val_accuracy: 0.4858 - lr: 0.0010\n",
      "Epoch 529/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9368 - accuracy: 0.53 - ETA: 0s - loss: 0.9045 - accuracy: 0.56 - ETA: 0s - loss: 0.9176 - accuracy: 0.56 - ETA: 0s - loss: 0.8852 - accuracy: 0.59 - ETA: 0s - loss: 0.8809 - accuracy: 0.60 - ETA: 0s - loss: 0.8703 - accuracy: 0.61 - ETA: 0s - loss: 0.8685 - accuracy: 0.61 - ETA: 0s - loss: 0.8680 - accuracy: 0.62 - ETA: 0s - loss: 0.8685 - accuracy: 0.62 - ETA: 0s - loss: 0.8751 - accuracy: 0.61 - ETA: 0s - loss: 0.8706 - accuracy: 0.61 - ETA: 0s - loss: 0.8657 - accuracy: 0.62 - ETA: 0s - loss: 0.8482 - accuracy: 0.63 - ETA: 0s - loss: 0.8564 - accuracy: 0.63 - ETA: 0s - loss: 0.8704 - accuracy: 0.62 - ETA: 0s - loss: 0.8722 - accuracy: 0.61 - ETA: 0s - loss: 0.8778 - accuracy: 0.61 - ETA: 0s - loss: 0.8786 - accuracy: 0.61 - ETA: 0s - loss: 0.8805 - accuracy: 0.6125\n",
      "Epoch 00529: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00529: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8805 - accuracy: 0.6125 - val_loss: 1.0669 - val_accuracy: 0.4852 - lr: 0.0010\n",
      "Epoch 530/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.9229 - accuracy: 0.56 - ETA: 0s - loss: 0.9043 - accuracy: 0.57 - ETA: 0s - loss: 0.9146 - accuracy: 0.58 - ETA: 0s - loss: 0.8823 - accuracy: 0.60 - ETA: 0s - loss: 0.8799 - accuracy: 0.60 - ETA: 0s - loss: 0.8719 - accuracy: 0.62 - ETA: 0s - loss: 0.8680 - accuracy: 0.62 - ETA: 0s - loss: 0.8670 - accuracy: 0.62 - ETA: 0s - loss: 0.8688 - accuracy: 0.62 - ETA: 0s - loss: 0.8733 - accuracy: 0.61 - ETA: 0s - loss: 0.8684 - accuracy: 0.62 - ETA: 0s - loss: 0.8622 - accuracy: 0.62 - ETA: 0s - loss: 0.8446 - accuracy: 0.64 - ETA: 0s - loss: 0.8525 - accuracy: 0.63 - ETA: 0s - loss: 0.8664 - accuracy: 0.62 - ETA: 0s - loss: 0.8682 - accuracy: 0.61 - ETA: 0s - loss: 0.8728 - accuracy: 0.61 - ETA: 0s - loss: 0.8747 - accuracy: 0.6155\n",
      "Epoch 00530: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8762 - accuracy: 0.6142 - val_loss: 1.0483 - val_accuracy: 0.4901 - lr: 0.0010\n",
      "Epoch 531/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9288 - accuracy: 0.55 - ETA: 0s - loss: 0.9001 - accuracy: 0.57 - ETA: 0s - loss: 0.9100 - accuracy: 0.57 - ETA: 0s - loss: 0.8777 - accuracy: 0.60 - ETA: 0s - loss: 0.8757 - accuracy: 0.60 - ETA: 0s - loss: 0.8662 - accuracy: 0.62 - ETA: 0s - loss: 0.8644 - accuracy: 0.62 - ETA: 0s - loss: 0.8643 - accuracy: 0.62 - ETA: 0s - loss: 0.8674 - accuracy: 0.62 - ETA: 0s - loss: 0.8730 - accuracy: 0.61 - ETA: 0s - loss: 0.8677 - accuracy: 0.62 - ETA: 0s - loss: 0.8613 - accuracy: 0.62 - ETA: 0s - loss: 0.8437 - accuracy: 0.64 - ETA: 0s - loss: 0.8509 - accuracy: 0.63 - ETA: 0s - loss: 0.8644 - accuracy: 0.62 - ETA: 0s - loss: 0.8671 - accuracy: 0.61 - ETA: 0s - loss: 0.8728 - accuracy: 0.61 - ETA: 0s - loss: 0.8738 - accuracy: 0.61 - ETA: 0s - loss: 0.8754 - accuracy: 0.6127\n",
      "Epoch 00531: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8754 - accuracy: 0.6127 - val_loss: 1.0693 - val_accuracy: 0.4765 - lr: 0.0010\n",
      "Epoch 532/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9425 - accuracy: 0.55 - ETA: 0s - loss: 0.9066 - accuracy: 0.57 - ETA: 0s - loss: 0.9136 - accuracy: 0.57 - ETA: 0s - loss: 0.8793 - accuracy: 0.60 - ETA: 0s - loss: 0.8790 - accuracy: 0.60 - ETA: 0s - loss: 0.8719 - accuracy: 0.61 - ETA: 0s - loss: 0.8692 - accuracy: 0.62 - ETA: 0s - loss: 0.8671 - accuracy: 0.62 - ETA: 0s - loss: 0.8678 - accuracy: 0.62 - ETA: 0s - loss: 0.8732 - accuracy: 0.61 - ETA: 0s - loss: 0.8687 - accuracy: 0.62 - ETA: 0s - loss: 0.8619 - accuracy: 0.63 - ETA: 0s - loss: 0.8449 - accuracy: 0.64 - ETA: 0s - loss: 0.8519 - accuracy: 0.63 - ETA: 0s - loss: 0.8664 - accuracy: 0.62 - ETA: 0s - loss: 0.8682 - accuracy: 0.62 - ETA: 0s - loss: 0.8743 - accuracy: 0.61 - ETA: 0s - loss: 0.8755 - accuracy: 0.61 - ETA: 0s - loss: 0.8766 - accuracy: 0.6161\n",
      "Epoch 00532: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8766 - accuracy: 0.6161 - val_loss: 1.0763 - val_accuracy: 0.4739 - lr: 0.0010\n",
      "Epoch 533/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9116 - accuracy: 0.55 - ETA: 0s - loss: 0.9001 - accuracy: 0.57 - ETA: 0s - loss: 0.9120 - accuracy: 0.57 - ETA: 0s - loss: 0.8806 - accuracy: 0.60 - ETA: 0s - loss: 0.8785 - accuracy: 0.60 - ETA: 0s - loss: 0.8682 - accuracy: 0.61 - ETA: 0s - loss: 0.8652 - accuracy: 0.62 - ETA: 0s - loss: 0.8642 - accuracy: 0.62 - ETA: 0s - loss: 0.8673 - accuracy: 0.62 - ETA: 0s - loss: 0.8723 - accuracy: 0.61 - ETA: 0s - loss: 0.8674 - accuracy: 0.62 - ETA: 0s - loss: 0.8616 - accuracy: 0.62 - ETA: 0s - loss: 0.8443 - accuracy: 0.64 - ETA: 0s - loss: 0.8521 - accuracy: 0.63 - ETA: 0s - loss: 0.8669 - accuracy: 0.62 - ETA: 0s - loss: 0.8694 - accuracy: 0.61 - ETA: 0s - loss: 0.8767 - accuracy: 0.61 - ETA: 0s - loss: 0.8776 - accuracy: 0.6152\n",
      "Epoch 00533: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8776 - accuracy: 0.6152 - val_loss: 1.0775 - val_accuracy: 0.4692 - lr: 0.0010\n",
      "Epoch 534/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9188 - accuracy: 0.56 - ETA: 0s - loss: 0.8904 - accuracy: 0.58 - ETA: 0s - loss: 0.9057 - accuracy: 0.58 - ETA: 0s - loss: 0.8778 - accuracy: 0.60 - ETA: 0s - loss: 0.8775 - accuracy: 0.61 - ETA: 0s - loss: 0.8687 - accuracy: 0.62 - ETA: 0s - loss: 0.8665 - accuracy: 0.62 - ETA: 0s - loss: 0.8647 - accuracy: 0.62 - ETA: 0s - loss: 0.8662 - accuracy: 0.62 - ETA: 0s - loss: 0.8706 - accuracy: 0.61 - ETA: 0s - loss: 0.8669 - accuracy: 0.62 - ETA: 0s - loss: 0.8603 - accuracy: 0.63 - ETA: 0s - loss: 0.8423 - accuracy: 0.64 - ETA: 0s - loss: 0.8503 - accuracy: 0.63 - ETA: 0s - loss: 0.8656 - accuracy: 0.62 - ETA: 0s - loss: 0.8682 - accuracy: 0.62 - ETA: 0s - loss: 0.8740 - accuracy: 0.61 - ETA: 0s - loss: 0.8749 - accuracy: 0.61 - ETA: 0s - loss: 0.8769 - accuracy: 0.6158\n",
      "Epoch 00534: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8769 - accuracy: 0.6158 - val_loss: 1.0740 - val_accuracy: 0.4715 - lr: 0.0010\n",
      "Epoch 535/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9157 - accuracy: 0.53 - ETA: 0s - loss: 0.9019 - accuracy: 0.56 - ETA: 0s - loss: 0.9110 - accuracy: 0.57 - ETA: 0s - loss: 0.8781 - accuracy: 0.59 - ETA: 0s - loss: 0.8748 - accuracy: 0.60 - ETA: 0s - loss: 0.8654 - accuracy: 0.61 - ETA: 0s - loss: 0.8627 - accuracy: 0.62 - ETA: 0s - loss: 0.8639 - accuracy: 0.62 - ETA: 0s - loss: 0.8642 - accuracy: 0.62 - ETA: 0s - loss: 0.8706 - accuracy: 0.61 - ETA: 0s - loss: 0.8658 - accuracy: 0.62 - ETA: 0s - loss: 0.8587 - accuracy: 0.62 - ETA: 0s - loss: 0.8419 - accuracy: 0.64 - ETA: 0s - loss: 0.8506 - accuracy: 0.63 - ETA: 0s - loss: 0.8631 - accuracy: 0.62 - ETA: 0s - loss: 0.8652 - accuracy: 0.61 - ETA: 0s - loss: 0.8710 - accuracy: 0.61 - ETA: 0s - loss: 0.8736 - accuracy: 0.61 - ETA: 0s - loss: 0.8748 - accuracy: 0.6142\n",
      "Epoch 00535: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8748 - accuracy: 0.6142 - val_loss: 1.0740 - val_accuracy: 0.4743 - lr: 0.0010\n",
      "Epoch 536/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9144 - accuracy: 0.55 - ETA: 0s - loss: 0.9025 - accuracy: 0.57 - ETA: 0s - loss: 0.9103 - accuracy: 0.57 - ETA: 0s - loss: 0.8810 - accuracy: 0.60 - ETA: 0s - loss: 0.8794 - accuracy: 0.60 - ETA: 0s - loss: 0.8695 - accuracy: 0.61 - ETA: 0s - loss: 0.8682 - accuracy: 0.62 - ETA: 0s - loss: 0.8672 - accuracy: 0.62 - ETA: 0s - loss: 0.8687 - accuracy: 0.62 - ETA: 0s - loss: 0.8731 - accuracy: 0.61 - ETA: 0s - loss: 0.8676 - accuracy: 0.62 - ETA: 0s - loss: 0.8606 - accuracy: 0.62 - ETA: 0s - loss: 0.8430 - accuracy: 0.64 - ETA: 0s - loss: 0.8505 - accuracy: 0.63 - ETA: 0s - loss: 0.8641 - accuracy: 0.62 - ETA: 0s - loss: 0.8669 - accuracy: 0.61 - ETA: 0s - loss: 0.8722 - accuracy: 0.61 - ETA: 0s - loss: 0.8746 - accuracy: 0.61 - ETA: 0s - loss: 0.8761 - accuracy: 0.6134\n",
      "Epoch 00536: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8761 - accuracy: 0.6134 - val_loss: 1.0735 - val_accuracy: 0.4756 - lr: 0.0010\n",
      "Epoch 537/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.9298 - accuracy: 0.53 - ETA: 0s - loss: 0.9043 - accuracy: 0.56 - ETA: 0s - loss: 0.9125 - accuracy: 0.56 - ETA: 0s - loss: 0.8810 - accuracy: 0.59 - ETA: 0s - loss: 0.8771 - accuracy: 0.60 - ETA: 0s - loss: 0.8669 - accuracy: 0.61 - ETA: 0s - loss: 0.8667 - accuracy: 0.61 - ETA: 0s - loss: 0.8682 - accuracy: 0.61 - ETA: 0s - loss: 0.8672 - accuracy: 0.61 - ETA: 0s - loss: 0.8734 - accuracy: 0.60 - ETA: 0s - loss: 0.8694 - accuracy: 0.61 - ETA: 0s - loss: 0.8628 - accuracy: 0.62 - ETA: 0s - loss: 0.8447 - accuracy: 0.63 - ETA: 0s - loss: 0.8518 - accuracy: 0.63 - ETA: 0s - loss: 0.8648 - accuracy: 0.62 - ETA: 0s - loss: 0.8674 - accuracy: 0.61 - ETA: 0s - loss: 0.8729 - accuracy: 0.61 - ETA: 0s - loss: 0.8739 - accuracy: 0.6150\n",
      "Epoch 00537: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8755 - accuracy: 0.6136 - val_loss: 1.0694 - val_accuracy: 0.4767 - lr: 0.0010\n",
      "Epoch 538/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9410 - accuracy: 0.53 - ETA: 0s - loss: 0.9103 - accuracy: 0.56 - ETA: 0s - loss: 0.9162 - accuracy: 0.56 - ETA: 0s - loss: 0.8818 - accuracy: 0.59 - ETA: 0s - loss: 0.8806 - accuracy: 0.59 - ETA: 0s - loss: 0.8706 - accuracy: 0.61 - ETA: 0s - loss: 0.8662 - accuracy: 0.61 - ETA: 0s - loss: 0.8655 - accuracy: 0.61 - ETA: 0s - loss: 0.8660 - accuracy: 0.61 - ETA: 0s - loss: 0.8714 - accuracy: 0.61 - ETA: 0s - loss: 0.8655 - accuracy: 0.62 - ETA: 0s - loss: 0.8609 - accuracy: 0.62 - ETA: 0s - loss: 0.8432 - accuracy: 0.64 - ETA: 0s - loss: 0.8511 - accuracy: 0.63 - ETA: 0s - loss: 0.8651 - accuracy: 0.62 - ETA: 0s - loss: 0.8676 - accuracy: 0.62 - ETA: 0s - loss: 0.8736 - accuracy: 0.61 - ETA: 0s - loss: 0.8752 - accuracy: 0.61 - ETA: 0s - loss: 0.8761 - accuracy: 0.6155\n",
      "Epoch 00538: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8761 - accuracy: 0.6155 - val_loss: 1.0730 - val_accuracy: 0.4764 - lr: 0.0010\n",
      "Epoch 539/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9360 - accuracy: 0.54 - ETA: 0s - loss: 0.9060 - accuracy: 0.57 - ETA: 0s - loss: 0.9166 - accuracy: 0.56 - ETA: 0s - loss: 0.8827 - accuracy: 0.59 - ETA: 0s - loss: 0.8796 - accuracy: 0.60 - ETA: 0s - loss: 0.8688 - accuracy: 0.61 - ETA: 0s - loss: 0.8659 - accuracy: 0.62 - ETA: 0s - loss: 0.8654 - accuracy: 0.62 - ETA: 0s - loss: 0.8648 - accuracy: 0.62 - ETA: 0s - loss: 0.8708 - accuracy: 0.61 - ETA: 0s - loss: 0.8669 - accuracy: 0.62 - ETA: 0s - loss: 0.8601 - accuracy: 0.62 - ETA: 0s - loss: 0.8423 - accuracy: 0.64 - ETA: 0s - loss: 0.8509 - accuracy: 0.63 - ETA: 0s - loss: 0.8631 - accuracy: 0.62 - ETA: 0s - loss: 0.8660 - accuracy: 0.61 - ETA: 0s - loss: 0.8710 - accuracy: 0.61 - ETA: 0s - loss: 0.8722 - accuracy: 0.61 - ETA: 0s - loss: 0.8743 - accuracy: 0.6127\n",
      "Epoch 00539: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8743 - accuracy: 0.6127 - val_loss: 1.0604 - val_accuracy: 0.4844 - lr: 0.0010\n",
      "Epoch 540/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9208 - accuracy: 0.53 - ETA: 0s - loss: 0.9032 - accuracy: 0.56 - ETA: 0s - loss: 0.9145 - accuracy: 0.56 - ETA: 0s - loss: 0.8796 - accuracy: 0.59 - ETA: 0s - loss: 0.8744 - accuracy: 0.60 - ETA: 0s - loss: 0.8676 - accuracy: 0.61 - ETA: 0s - loss: 0.8656 - accuracy: 0.62 - ETA: 0s - loss: 0.8641 - accuracy: 0.62 - ETA: 0s - loss: 0.8662 - accuracy: 0.62 - ETA: 0s - loss: 0.8708 - accuracy: 0.61 - ETA: 0s - loss: 0.8663 - accuracy: 0.62 - ETA: 0s - loss: 0.8597 - accuracy: 0.62 - ETA: 0s - loss: 0.8424 - accuracy: 0.64 - ETA: 0s - loss: 0.8513 - accuracy: 0.63 - ETA: 0s - loss: 0.8651 - accuracy: 0.62 - ETA: 0s - loss: 0.8676 - accuracy: 0.62 - ETA: 0s - loss: 0.8732 - accuracy: 0.61 - ETA: 0s - loss: 0.8744 - accuracy: 0.61 - ETA: 0s - loss: 0.8762 - accuracy: 0.6161\n",
      "Epoch 00540: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8762 - accuracy: 0.6161 - val_loss: 1.0556 - val_accuracy: 0.4884 - lr: 0.0010\n",
      "Epoch 541/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9113 - accuracy: 0.55 - ETA: 0s - loss: 0.8965 - accuracy: 0.57 - ETA: 0s - loss: 0.9031 - accuracy: 0.57 - ETA: 0s - loss: 0.8765 - accuracy: 0.59 - ETA: 0s - loss: 0.8730 - accuracy: 0.60 - ETA: 0s - loss: 0.8655 - accuracy: 0.61 - ETA: 0s - loss: 0.8639 - accuracy: 0.61 - ETA: 0s - loss: 0.8629 - accuracy: 0.62 - ETA: 0s - loss: 0.8639 - accuracy: 0.62 - ETA: 0s - loss: 0.8696 - accuracy: 0.61 - ETA: 0s - loss: 0.8651 - accuracy: 0.62 - ETA: 0s - loss: 0.8583 - accuracy: 0.62 - ETA: 0s - loss: 0.8408 - accuracy: 0.64 - ETA: 0s - loss: 0.8493 - accuracy: 0.63 - ETA: 0s - loss: 0.8638 - accuracy: 0.62 - ETA: 0s - loss: 0.8659 - accuracy: 0.61 - ETA: 0s - loss: 0.8729 - accuracy: 0.61 - ETA: 0s - loss: 0.8750 - accuracy: 0.6133\n",
      "Epoch 00541: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8750 - accuracy: 0.6133 - val_loss: 1.0599 - val_accuracy: 0.4840 - lr: 0.0010\n",
      "Epoch 542/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9174 - accuracy: 0.56 - ETA: 0s - loss: 0.8927 - accuracy: 0.58 - ETA: 0s - loss: 0.9052 - accuracy: 0.57 - ETA: 0s - loss: 0.8730 - accuracy: 0.60 - ETA: 0s - loss: 0.8726 - accuracy: 0.60 - ETA: 0s - loss: 0.8647 - accuracy: 0.62 - ETA: 0s - loss: 0.8622 - accuracy: 0.62 - ETA: 0s - loss: 0.8638 - accuracy: 0.62 - ETA: 0s - loss: 0.8638 - accuracy: 0.62 - ETA: 0s - loss: 0.8687 - accuracy: 0.61 - ETA: 0s - loss: 0.8642 - accuracy: 0.62 - ETA: 0s - loss: 0.8589 - accuracy: 0.62 - ETA: 0s - loss: 0.8411 - accuracy: 0.64 - ETA: 0s - loss: 0.8477 - accuracy: 0.63 - ETA: 0s - loss: 0.8634 - accuracy: 0.62 - ETA: 0s - loss: 0.8660 - accuracy: 0.62 - ETA: 0s - loss: 0.8727 - accuracy: 0.61 - ETA: 0s - loss: 0.8743 - accuracy: 0.61 - ETA: 0s - loss: 0.8768 - accuracy: 0.6149\n",
      "Epoch 00542: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8768 - accuracy: 0.6149 - val_loss: 1.0640 - val_accuracy: 0.4826 - lr: 0.0010\n",
      "Epoch 543/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9025 - accuracy: 0.56 - ETA: 0s - loss: 0.8856 - accuracy: 0.58 - ETA: 0s - loss: 0.8987 - accuracy: 0.58 - ETA: 0s - loss: 0.8723 - accuracy: 0.60 - ETA: 0s - loss: 0.8705 - accuracy: 0.60 - ETA: 0s - loss: 0.8614 - accuracy: 0.62 - ETA: 0s - loss: 0.8590 - accuracy: 0.62 - ETA: 0s - loss: 0.8604 - accuracy: 0.62 - ETA: 0s - loss: 0.8629 - accuracy: 0.62 - ETA: 0s - loss: 0.8694 - accuracy: 0.61 - ETA: 0s - loss: 0.8654 - accuracy: 0.62 - ETA: 0s - loss: 0.8590 - accuracy: 0.62 - ETA: 0s - loss: 0.8417 - accuracy: 0.64 - ETA: 0s - loss: 0.8491 - accuracy: 0.63 - ETA: 0s - loss: 0.8629 - accuracy: 0.62 - ETA: 0s - loss: 0.8660 - accuracy: 0.62 - ETA: 0s - loss: 0.8714 - accuracy: 0.61 - ETA: 0s - loss: 0.8736 - accuracy: 0.61 - ETA: 0s - loss: 0.8748 - accuracy: 0.6165\n",
      "Epoch 00543: val_loss did not improve from 0.99131\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00543: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8748 - accuracy: 0.6165 - val_loss: 1.0487 - val_accuracy: 0.4888 - lr: 0.0010\n",
      "Epoch 544/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9414 - accuracy: 0.55 - ETA: 0s - loss: 0.9107 - accuracy: 0.57 - ETA: 0s - loss: 0.9202 - accuracy: 0.57 - ETA: 0s - loss: 0.8890 - accuracy: 0.60 - ETA: 0s - loss: 0.8852 - accuracy: 0.60 - ETA: 0s - loss: 0.8767 - accuracy: 0.61 - ETA: 0s - loss: 0.8714 - accuracy: 0.62 - ETA: 0s - loss: 0.8698 - accuracy: 0.62 - ETA: 0s - loss: 0.8715 - accuracy: 0.62 - ETA: 0s - loss: 0.8772 - accuracy: 0.61 - ETA: 0s - loss: 0.8720 - accuracy: 0.62 - ETA: 0s - loss: 0.8660 - accuracy: 0.62 - ETA: 0s - loss: 0.8476 - accuracy: 0.64 - ETA: 0s - loss: 0.8545 - accuracy: 0.63 - ETA: 0s - loss: 0.8661 - accuracy: 0.62 - ETA: 0s - loss: 0.8688 - accuracy: 0.62 - ETA: 0s - loss: 0.8749 - accuracy: 0.61 - ETA: 0s - loss: 0.8774 - accuracy: 0.6176\n",
      "Epoch 00544: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8774 - accuracy: 0.6176 - val_loss: 1.0537 - val_accuracy: 0.4879 - lr: 0.0010\n",
      "Epoch 545/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9246 - accuracy: 0.52 - ETA: 0s - loss: 0.8946 - accuracy: 0.56 - ETA: 0s - loss: 0.9051 - accuracy: 0.56 - ETA: 0s - loss: 0.8768 - accuracy: 0.59 - ETA: 0s - loss: 0.8731 - accuracy: 0.60 - ETA: 0s - loss: 0.8651 - accuracy: 0.61 - ETA: 0s - loss: 0.8641 - accuracy: 0.61 - ETA: 0s - loss: 0.8619 - accuracy: 0.62 - ETA: 0s - loss: 0.8634 - accuracy: 0.61 - ETA: 0s - loss: 0.8682 - accuracy: 0.61 - ETA: 0s - loss: 0.8630 - accuracy: 0.62 - ETA: 0s - loss: 0.8569 - accuracy: 0.62 - ETA: 0s - loss: 0.8398 - accuracy: 0.63 - ETA: 0s - loss: 0.8465 - accuracy: 0.63 - ETA: 0s - loss: 0.8587 - accuracy: 0.62 - ETA: 0s - loss: 0.8671 - accuracy: 0.61 - ETA: 0s - loss: 0.8695 - accuracy: 0.61 - ETA: 0s - loss: 0.8717 - accuracy: 0.6151\n",
      "Epoch 00545: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8717 - accuracy: 0.6151 - val_loss: 1.0628 - val_accuracy: 0.4832 - lr: 0.0010\n",
      "Epoch 546/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9246 - accuracy: 0.56 - ETA: 0s - loss: 0.8930 - accuracy: 0.58 - ETA: 0s - loss: 0.9095 - accuracy: 0.58 - ETA: 0s - loss: 0.8772 - accuracy: 0.60 - ETA: 0s - loss: 0.8761 - accuracy: 0.61 - ETA: 0s - loss: 0.8670 - accuracy: 0.62 - ETA: 0s - loss: 0.8661 - accuracy: 0.62 - ETA: 0s - loss: 0.8647 - accuracy: 0.62 - ETA: 0s - loss: 0.8666 - accuracy: 0.62 - ETA: 0s - loss: 0.8721 - accuracy: 0.61 - ETA: 0s - loss: 0.8673 - accuracy: 0.62 - ETA: 0s - loss: 0.8607 - accuracy: 0.63 - ETA: 0s - loss: 0.8433 - accuracy: 0.64 - ETA: 0s - loss: 0.8503 - accuracy: 0.63 - ETA: 0s - loss: 0.8639 - accuracy: 0.62 - ETA: 0s - loss: 0.8668 - accuracy: 0.62 - ETA: 0s - loss: 0.8723 - accuracy: 0.61 - ETA: 0s - loss: 0.8736 - accuracy: 0.61 - ETA: 0s - loss: 0.8750 - accuracy: 0.6176\n",
      "Epoch 00546: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8750 - accuracy: 0.6176 - val_loss: 1.0691 - val_accuracy: 0.4829 - lr: 0.0010\n",
      "Epoch 547/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9321 - accuracy: 0.54 - ETA: 0s - loss: 0.9074 - accuracy: 0.57 - ETA: 0s - loss: 0.9151 - accuracy: 0.57 - ETA: 0s - loss: 0.8804 - accuracy: 0.60 - ETA: 0s - loss: 0.8781 - accuracy: 0.60 - ETA: 0s - loss: 0.8682 - accuracy: 0.61 - ETA: 0s - loss: 0.8664 - accuracy: 0.62 - ETA: 0s - loss: 0.8656 - accuracy: 0.62 - ETA: 0s - loss: 0.8662 - accuracy: 0.62 - ETA: 0s - loss: 0.8720 - accuracy: 0.61 - ETA: 0s - loss: 0.8679 - accuracy: 0.62 - ETA: 0s - loss: 0.8622 - accuracy: 0.62 - ETA: 0s - loss: 0.8437 - accuracy: 0.64 - ETA: 0s - loss: 0.8513 - accuracy: 0.63 - ETA: 0s - loss: 0.8652 - accuracy: 0.62 - ETA: 0s - loss: 0.8678 - accuracy: 0.62 - ETA: 0s - loss: 0.8733 - accuracy: 0.61 - ETA: 0s - loss: 0.8752 - accuracy: 0.61 - ETA: 0s - loss: 0.8771 - accuracy: 0.6161\n",
      "Epoch 00547: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8771 - accuracy: 0.6161 - val_loss: 1.0612 - val_accuracy: 0.4853 - lr: 0.0010\n",
      "Epoch 548/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9202 - accuracy: 0.55 - ETA: 0s - loss: 0.8969 - accuracy: 0.57 - ETA: 0s - loss: 0.9099 - accuracy: 0.57 - ETA: 0s - loss: 0.8788 - accuracy: 0.59 - ETA: 0s - loss: 0.8755 - accuracy: 0.60 - ETA: 0s - loss: 0.8677 - accuracy: 0.61 - ETA: 0s - loss: 0.8654 - accuracy: 0.62 - ETA: 0s - loss: 0.8660 - accuracy: 0.62 - ETA: 0s - loss: 0.8669 - accuracy: 0.62 - ETA: 0s - loss: 0.8710 - accuracy: 0.61 - ETA: 0s - loss: 0.8663 - accuracy: 0.62 - ETA: 0s - loss: 0.8594 - accuracy: 0.62 - ETA: 0s - loss: 0.8418 - accuracy: 0.64 - ETA: 0s - loss: 0.8501 - accuracy: 0.63 - ETA: 0s - loss: 0.8629 - accuracy: 0.62 - ETA: 0s - loss: 0.8656 - accuracy: 0.62 - ETA: 0s - loss: 0.8707 - accuracy: 0.61 - ETA: 0s - loss: 0.8718 - accuracy: 0.61 - ETA: 0s - loss: 0.8737 - accuracy: 0.6162\n",
      "Epoch 00548: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8737 - accuracy: 0.6162 - val_loss: 1.0712 - val_accuracy: 0.4834 - lr: 0.0010\n",
      "Epoch 549/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9344 - accuracy: 0.54 - ETA: 0s - loss: 0.9038 - accuracy: 0.57 - ETA: 0s - loss: 0.9157 - accuracy: 0.56 - ETA: 0s - loss: 0.8838 - accuracy: 0.59 - ETA: 0s - loss: 0.8805 - accuracy: 0.60 - ETA: 0s - loss: 0.8706 - accuracy: 0.61 - ETA: 0s - loss: 0.8686 - accuracy: 0.61 - ETA: 0s - loss: 0.8677 - accuracy: 0.62 - ETA: 0s - loss: 0.8704 - accuracy: 0.62 - ETA: 0s - loss: 0.8753 - accuracy: 0.61 - ETA: 0s - loss: 0.8713 - accuracy: 0.61 - ETA: 0s - loss: 0.8655 - accuracy: 0.62 - ETA: 0s - loss: 0.8476 - accuracy: 0.64 - ETA: 0s - loss: 0.8555 - accuracy: 0.63 - ETA: 0s - loss: 0.8718 - accuracy: 0.62 - ETA: 0s - loss: 0.8746 - accuracy: 0.61 - ETA: 0s - loss: 0.8798 - accuracy: 0.61 - ETA: 0s - loss: 0.8826 - accuracy: 0.6130\n",
      "Epoch 00549: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8826 - accuracy: 0.6130 - val_loss: 1.0797 - val_accuracy: 0.4798 - lr: 0.0010\n",
      "Epoch 550/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9335 - accuracy: 0.55 - ETA: 0s - loss: 0.8992 - accuracy: 0.58 - ETA: 0s - loss: 0.9090 - accuracy: 0.58 - ETA: 0s - loss: 0.8780 - accuracy: 0.60 - ETA: 0s - loss: 0.8780 - accuracy: 0.61 - ETA: 0s - loss: 0.8691 - accuracy: 0.62 - ETA: 0s - loss: 0.8666 - accuracy: 0.62 - ETA: 0s - loss: 0.8659 - accuracy: 0.62 - ETA: 0s - loss: 0.8679 - accuracy: 0.62 - ETA: 0s - loss: 0.8728 - accuracy: 0.61 - ETA: 0s - loss: 0.8679 - accuracy: 0.62 - ETA: 0s - loss: 0.8607 - accuracy: 0.63 - ETA: 0s - loss: 0.8425 - accuracy: 0.64 - ETA: 0s - loss: 0.8504 - accuracy: 0.63 - ETA: 0s - loss: 0.8630 - accuracy: 0.62 - ETA: 0s - loss: 0.8662 - accuracy: 0.62 - ETA: 0s - loss: 0.8715 - accuracy: 0.61 - ETA: 0s - loss: 0.8724 - accuracy: 0.62 - ETA: 0s - loss: 0.8737 - accuracy: 0.6188\n",
      "Epoch 00550: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8737 - accuracy: 0.6188 - val_loss: 1.0925 - val_accuracy: 0.4736 - lr: 0.0010\n",
      "Epoch 551/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9271 - accuracy: 0.54 - ETA: 0s - loss: 0.8976 - accuracy: 0.56 - ETA: 0s - loss: 0.9153 - accuracy: 0.57 - ETA: 0s - loss: 0.8857 - accuracy: 0.59 - ETA: 0s - loss: 0.8829 - accuracy: 0.60 - ETA: 0s - loss: 0.8726 - accuracy: 0.61 - ETA: 0s - loss: 0.8713 - accuracy: 0.61 - ETA: 0s - loss: 0.8708 - accuracy: 0.62 - ETA: 0s - loss: 0.8738 - accuracy: 0.61 - ETA: 0s - loss: 0.8778 - accuracy: 0.60 - ETA: 0s - loss: 0.8720 - accuracy: 0.61 - ETA: 0s - loss: 0.8653 - accuracy: 0.62 - ETA: 0s - loss: 0.8472 - accuracy: 0.63 - ETA: 0s - loss: 0.8537 - accuracy: 0.63 - ETA: 0s - loss: 0.8677 - accuracy: 0.61 - ETA: 0s - loss: 0.8702 - accuracy: 0.61 - ETA: 0s - loss: 0.8759 - accuracy: 0.61 - ETA: 0s - loss: 0.8770 - accuracy: 0.61 - ETA: 0s - loss: 0.8782 - accuracy: 0.6121\n",
      "Epoch 00551: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8782 - accuracy: 0.6121 - val_loss: 1.0922 - val_accuracy: 0.4723 - lr: 0.0010\n",
      "Epoch 552/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9236 - accuracy: 0.54 - ETA: 0s - loss: 0.8958 - accuracy: 0.57 - ETA: 0s - loss: 0.9041 - accuracy: 0.57 - ETA: 0s - loss: 0.8748 - accuracy: 0.60 - ETA: 0s - loss: 0.8732 - accuracy: 0.61 - ETA: 0s - loss: 0.8668 - accuracy: 0.62 - ETA: 0s - loss: 0.8656 - accuracy: 0.62 - ETA: 0s - loss: 0.8642 - accuracy: 0.62 - ETA: 0s - loss: 0.8660 - accuracy: 0.62 - ETA: 0s - loss: 0.8720 - accuracy: 0.61 - ETA: 0s - loss: 0.8673 - accuracy: 0.62 - ETA: 0s - loss: 0.8599 - accuracy: 0.62 - ETA: 0s - loss: 0.8421 - accuracy: 0.64 - ETA: 0s - loss: 0.8484 - accuracy: 0.63 - ETA: 0s - loss: 0.8632 - accuracy: 0.62 - ETA: 0s - loss: 0.8660 - accuracy: 0.62 - ETA: 0s - loss: 0.8716 - accuracy: 0.61 - ETA: 0s - loss: 0.8730 - accuracy: 0.61 - ETA: 0s - loss: 0.8736 - accuracy: 0.6165\n",
      "Epoch 00552: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8736 - accuracy: 0.6165 - val_loss: 1.0803 - val_accuracy: 0.4826 - lr: 0.0010\n",
      "Epoch 553/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9303 - accuracy: 0.55 - ETA: 0s - loss: 0.8967 - accuracy: 0.57 - ETA: 0s - loss: 0.9108 - accuracy: 0.57 - ETA: 0s - loss: 0.8804 - accuracy: 0.59 - ETA: 0s - loss: 0.8779 - accuracy: 0.60 - ETA: 0s - loss: 0.8692 - accuracy: 0.61 - ETA: 0s - loss: 0.8682 - accuracy: 0.62 - ETA: 0s - loss: 0.8681 - accuracy: 0.62 - ETA: 0s - loss: 0.8693 - accuracy: 0.61 - ETA: 0s - loss: 0.8759 - accuracy: 0.61 - ETA: 0s - loss: 0.8698 - accuracy: 0.62 - ETA: 0s - loss: 0.8632 - accuracy: 0.62 - ETA: 0s - loss: 0.8450 - accuracy: 0.64 - ETA: 0s - loss: 0.8528 - accuracy: 0.63 - ETA: 0s - loss: 0.8650 - accuracy: 0.62 - ETA: 0s - loss: 0.8676 - accuracy: 0.61 - ETA: 0s - loss: 0.8723 - accuracy: 0.61 - ETA: 0s - loss: 0.8741 - accuracy: 0.61 - ETA: 0s - loss: 0.8754 - accuracy: 0.6137\n",
      "Epoch 00553: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8754 - accuracy: 0.6137 - val_loss: 1.0731 - val_accuracy: 0.4837 - lr: 0.0010\n",
      "Epoch 554/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9223 - accuracy: 0.53 - ETA: 0s - loss: 0.8964 - accuracy: 0.56 - ETA: 0s - loss: 0.9059 - accuracy: 0.57 - ETA: 0s - loss: 0.8761 - accuracy: 0.59 - ETA: 0s - loss: 0.8735 - accuracy: 0.60 - ETA: 0s - loss: 0.8648 - accuracy: 0.61 - ETA: 0s - loss: 0.8640 - accuracy: 0.62 - ETA: 0s - loss: 0.8642 - accuracy: 0.62 - ETA: 0s - loss: 0.8667 - accuracy: 0.62 - ETA: 0s - loss: 0.8715 - accuracy: 0.61 - ETA: 0s - loss: 0.8665 - accuracy: 0.62 - ETA: 0s - loss: 0.8606 - accuracy: 0.62 - ETA: 0s - loss: 0.8425 - accuracy: 0.64 - ETA: 0s - loss: 0.8480 - accuracy: 0.63 - ETA: 0s - loss: 0.8614 - accuracy: 0.62 - ETA: 0s - loss: 0.8646 - accuracy: 0.62 - ETA: 0s - loss: 0.8710 - accuracy: 0.61 - ETA: 0s - loss: 0.8723 - accuracy: 0.61 - ETA: 0s - loss: 0.8738 - accuracy: 0.6182\n",
      "Epoch 00554: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8738 - accuracy: 0.6182 - val_loss: 1.0752 - val_accuracy: 0.4816 - lr: 0.0010\n",
      "Epoch 555/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9396 - accuracy: 0.54 - ETA: 0s - loss: 0.9107 - accuracy: 0.57 - ETA: 0s - loss: 0.9165 - accuracy: 0.57 - ETA: 0s - loss: 0.8852 - accuracy: 0.60 - ETA: 0s - loss: 0.8740 - accuracy: 0.61 - ETA: 0s - loss: 0.8714 - accuracy: 0.62 - ETA: 0s - loss: 0.8697 - accuracy: 0.62 - ETA: 0s - loss: 0.8698 - accuracy: 0.62 - ETA: 0s - loss: 0.8747 - accuracy: 0.61 - ETA: 0s - loss: 0.8699 - accuracy: 0.62 - ETA: 0s - loss: 0.8624 - accuracy: 0.62 - ETA: 0s - loss: 0.8447 - accuracy: 0.64 - ETA: 0s - loss: 0.8531 - accuracy: 0.63 - ETA: 0s - loss: 0.8674 - accuracy: 0.62 - ETA: 0s - loss: 0.8702 - accuracy: 0.61 - ETA: 0s - loss: 0.8755 - accuracy: 0.61 - ETA: 0s - loss: 0.8767 - accuracy: 0.61 - ETA: 0s - loss: 0.8785 - accuracy: 0.6121\n",
      "Epoch 00555: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8785 - accuracy: 0.6121 - val_loss: 1.0772 - val_accuracy: 0.4790 - lr: 0.0010\n",
      "Epoch 556/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.9098 - accuracy: 0.54 - ETA: 0s - loss: 0.8873 - accuracy: 0.57 - ETA: 0s - loss: 0.8965 - accuracy: 0.57 - ETA: 0s - loss: 0.8702 - accuracy: 0.60 - ETA: 0s - loss: 0.8725 - accuracy: 0.60 - ETA: 0s - loss: 0.8634 - accuracy: 0.61 - ETA: 0s - loss: 0.8637 - accuracy: 0.62 - ETA: 0s - loss: 0.8645 - accuracy: 0.62 - ETA: 0s - loss: 0.8656 - accuracy: 0.62 - ETA: 0s - loss: 0.8707 - accuracy: 0.61 - ETA: 0s - loss: 0.8648 - accuracy: 0.62 - ETA: 0s - loss: 0.8592 - accuracy: 0.62 - ETA: 0s - loss: 0.8418 - accuracy: 0.64 - ETA: 0s - loss: 0.8490 - accuracy: 0.63 - ETA: 0s - loss: 0.8602 - accuracy: 0.62 - ETA: 0s - loss: 0.8633 - accuracy: 0.62 - ETA: 0s - loss: 0.8692 - accuracy: 0.61 - ETA: 0s - loss: 0.8714 - accuracy: 0.6198\n",
      "Epoch 00556: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8731 - accuracy: 0.6185 - val_loss: 1.0847 - val_accuracy: 0.4754 - lr: 0.0010\n",
      "Epoch 557/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9092 - accuracy: 0.56 - ETA: 0s - loss: 0.8949 - accuracy: 0.58 - ETA: 0s - loss: 0.9064 - accuracy: 0.57 - ETA: 0s - loss: 0.8755 - accuracy: 0.60 - ETA: 0s - loss: 0.8763 - accuracy: 0.60 - ETA: 0s - loss: 0.8675 - accuracy: 0.61 - ETA: 0s - loss: 0.8646 - accuracy: 0.62 - ETA: 0s - loss: 0.8639 - accuracy: 0.62 - ETA: 0s - loss: 0.8673 - accuracy: 0.62 - ETA: 0s - loss: 0.8725 - accuracy: 0.61 - ETA: 0s - loss: 0.8674 - accuracy: 0.62 - ETA: 0s - loss: 0.8615 - accuracy: 0.62 - ETA: 0s - loss: 0.8434 - accuracy: 0.64 - ETA: 0s - loss: 0.8516 - accuracy: 0.63 - ETA: 0s - loss: 0.8646 - accuracy: 0.61 - ETA: 0s - loss: 0.8674 - accuracy: 0.61 - ETA: 0s - loss: 0.8731 - accuracy: 0.61 - ETA: 0s - loss: 0.8744 - accuracy: 0.61 - ETA: 0s - loss: 0.8757 - accuracy: 0.6121\n",
      "Epoch 00557: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00557: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8757 - accuracy: 0.6121 - val_loss: 1.0758 - val_accuracy: 0.4783 - lr: 0.0010\n",
      "Epoch 558/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9163 - accuracy: 0.55 - ETA: 0s - loss: 0.8972 - accuracy: 0.57 - ETA: 0s - loss: 0.9102 - accuracy: 0.57 - ETA: 0s - loss: 0.8781 - accuracy: 0.59 - ETA: 0s - loss: 0.8769 - accuracy: 0.60 - ETA: 0s - loss: 0.8675 - accuracy: 0.61 - ETA: 0s - loss: 0.8636 - accuracy: 0.62 - ETA: 0s - loss: 0.8629 - accuracy: 0.62 - ETA: 0s - loss: 0.8649 - accuracy: 0.62 - ETA: 0s - loss: 0.8687 - accuracy: 0.61 - ETA: 0s - loss: 0.8637 - accuracy: 0.62 - ETA: 0s - loss: 0.8566 - accuracy: 0.63 - ETA: 0s - loss: 0.8387 - accuracy: 0.64 - ETA: 0s - loss: 0.8455 - accuracy: 0.63 - ETA: 0s - loss: 0.8597 - accuracy: 0.62 - ETA: 0s - loss: 0.8630 - accuracy: 0.62 - ETA: 0s - loss: 0.8683 - accuracy: 0.61 - ETA: 0s - loss: 0.8694 - accuracy: 0.61 - ETA: 0s - loss: 0.8713 - accuracy: 0.6176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00558: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8713 - accuracy: 0.6176 - val_loss: 1.0674 - val_accuracy: 0.4871 - lr: 0.0010\n",
      "Epoch 559/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9219 - accuracy: 0.54 - ETA: 0s - loss: 0.9079 - accuracy: 0.56 - ETA: 0s - loss: 0.9144 - accuracy: 0.56 - ETA: 0s - loss: 0.8807 - accuracy: 0.59 - ETA: 0s - loss: 0.8774 - accuracy: 0.60 - ETA: 0s - loss: 0.8689 - accuracy: 0.61 - ETA: 0s - loss: 0.8667 - accuracy: 0.62 - ETA: 0s - loss: 0.8664 - accuracy: 0.62 - ETA: 0s - loss: 0.8678 - accuracy: 0.61 - ETA: 0s - loss: 0.8719 - accuracy: 0.61 - ETA: 0s - loss: 0.8672 - accuracy: 0.61 - ETA: 0s - loss: 0.8599 - accuracy: 0.62 - ETA: 0s - loss: 0.8420 - accuracy: 0.64 - ETA: 0s - loss: 0.8490 - accuracy: 0.63 - ETA: 0s - loss: 0.8617 - accuracy: 0.62 - ETA: 0s - loss: 0.8710 - accuracy: 0.61 - ETA: 0s - loss: 0.8728 - accuracy: 0.61 - ETA: 0s - loss: 0.8749 - accuracy: 0.6139\n",
      "Epoch 00559: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8749 - accuracy: 0.6139 - val_loss: 1.0625 - val_accuracy: 0.4871 - lr: 0.0010\n",
      "Epoch 560/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9136 - accuracy: 0.53 - ETA: 0s - loss: 0.8885 - accuracy: 0.56 - ETA: 0s - loss: 0.9019 - accuracy: 0.56 - ETA: 0s - loss: 0.8704 - accuracy: 0.59 - ETA: 0s - loss: 0.8712 - accuracy: 0.60 - ETA: 0s - loss: 0.8616 - accuracy: 0.61 - ETA: 0s - loss: 0.8615 - accuracy: 0.62 - ETA: 0s - loss: 0.8616 - accuracy: 0.62 - ETA: 0s - loss: 0.8682 - accuracy: 0.61 - ETA: 0s - loss: 0.8634 - accuracy: 0.62 - ETA: 0s - loss: 0.8581 - accuracy: 0.62 - ETA: 0s - loss: 0.8403 - accuracy: 0.64 - ETA: 0s - loss: 0.8470 - accuracy: 0.63 - ETA: 0s - loss: 0.8604 - accuracy: 0.62 - ETA: 0s - loss: 0.8630 - accuracy: 0.61 - ETA: 0s - loss: 0.8690 - accuracy: 0.61 - ETA: 0s - loss: 0.8705 - accuracy: 0.61 - ETA: 0s - loss: 0.8724 - accuracy: 0.6141\n",
      "Epoch 00560: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8724 - accuracy: 0.6141 - val_loss: 1.0581 - val_accuracy: 0.4920 - lr: 0.0010\n",
      "Epoch 561/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9172 - accuracy: 0.54 - ETA: 0s - loss: 0.8928 - accuracy: 0.57 - ETA: 0s - loss: 0.9111 - accuracy: 0.57 - ETA: 0s - loss: 0.8770 - accuracy: 0.59 - ETA: 0s - loss: 0.8776 - accuracy: 0.60 - ETA: 0s - loss: 0.8684 - accuracy: 0.61 - ETA: 0s - loss: 0.8639 - accuracy: 0.62 - ETA: 0s - loss: 0.8645 - accuracy: 0.62 - ETA: 0s - loss: 0.8642 - accuracy: 0.62 - ETA: 0s - loss: 0.8702 - accuracy: 0.61 - ETA: 0s - loss: 0.8661 - accuracy: 0.62 - ETA: 0s - loss: 0.8600 - accuracy: 0.62 - ETA: 0s - loss: 0.8421 - accuracy: 0.64 - ETA: 0s - loss: 0.8480 - accuracy: 0.63 - ETA: 0s - loss: 0.8619 - accuracy: 0.62 - ETA: 0s - loss: 0.8704 - accuracy: 0.61 - ETA: 0s - loss: 0.8712 - accuracy: 0.61 - ETA: 0s - loss: 0.8726 - accuracy: 0.6175\n",
      "Epoch 00561: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8726 - accuracy: 0.6175 - val_loss: 1.0713 - val_accuracy: 0.4834 - lr: 0.0010\n",
      "Epoch 562/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9253 - accuracy: 0.53 - ETA: 0s - loss: 0.8977 - accuracy: 0.57 - ETA: 0s - loss: 0.9073 - accuracy: 0.57 - ETA: 0s - loss: 0.8744 - accuracy: 0.59 - ETA: 0s - loss: 0.8739 - accuracy: 0.60 - ETA: 0s - loss: 0.8656 - accuracy: 0.61 - ETA: 0s - loss: 0.8632 - accuracy: 0.62 - ETA: 0s - loss: 0.8637 - accuracy: 0.62 - ETA: 0s - loss: 0.8654 - accuracy: 0.62 - ETA: 0s - loss: 0.8717 - accuracy: 0.61 - ETA: 0s - loss: 0.8673 - accuracy: 0.62 - ETA: 0s - loss: 0.8609 - accuracy: 0.62 - ETA: 0s - loss: 0.8432 - accuracy: 0.64 - ETA: 0s - loss: 0.8500 - accuracy: 0.63 - ETA: 0s - loss: 0.8630 - accuracy: 0.62 - ETA: 0s - loss: 0.8660 - accuracy: 0.62 - ETA: 0s - loss: 0.8714 - accuracy: 0.61 - ETA: 0s - loss: 0.8729 - accuracy: 0.61 - ETA: 0s - loss: 0.8745 - accuracy: 0.6153\n",
      "Epoch 00562: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8745 - accuracy: 0.6153 - val_loss: 1.0633 - val_accuracy: 0.4850 - lr: 0.0010\n",
      "Epoch 563/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9172 - accuracy: 0.56 - ETA: 0s - loss: 0.8896 - accuracy: 0.58 - ETA: 0s - loss: 0.9044 - accuracy: 0.58 - ETA: 0s - loss: 0.8757 - accuracy: 0.60 - ETA: 0s - loss: 0.8739 - accuracy: 0.61 - ETA: 0s - loss: 0.8648 - accuracy: 0.62 - ETA: 0s - loss: 0.8652 - accuracy: 0.62 - ETA: 0s - loss: 0.8650 - accuracy: 0.62 - ETA: 0s - loss: 0.8658 - accuracy: 0.62 - ETA: 0s - loss: 0.8712 - accuracy: 0.61 - ETA: 0s - loss: 0.8667 - accuracy: 0.62 - ETA: 0s - loss: 0.8608 - accuracy: 0.63 - ETA: 0s - loss: 0.8424 - accuracy: 0.64 - ETA: 0s - loss: 0.8493 - accuracy: 0.63 - ETA: 0s - loss: 0.8627 - accuracy: 0.62 - ETA: 0s - loss: 0.8646 - accuracy: 0.62 - ETA: 0s - loss: 0.8702 - accuracy: 0.61 - ETA: 0s - loss: 0.8717 - accuracy: 0.61 - ETA: 0s - loss: 0.8732 - accuracy: 0.6172\n",
      "Epoch 00563: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8732 - accuracy: 0.6172 - val_loss: 1.0558 - val_accuracy: 0.4932 - lr: 0.0010\n",
      "Epoch 564/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9374 - accuracy: 0.55 - ETA: 0s - loss: 0.9100 - accuracy: 0.57 - ETA: 0s - loss: 0.9138 - accuracy: 0.58 - ETA: 0s - loss: 0.8806 - accuracy: 0.60 - ETA: 0s - loss: 0.8785 - accuracy: 0.60 - ETA: 0s - loss: 0.8685 - accuracy: 0.62 - ETA: 0s - loss: 0.8651 - accuracy: 0.62 - ETA: 0s - loss: 0.8649 - accuracy: 0.62 - ETA: 0s - loss: 0.8670 - accuracy: 0.62 - ETA: 0s - loss: 0.8718 - accuracy: 0.61 - ETA: 0s - loss: 0.8668 - accuracy: 0.62 - ETA: 0s - loss: 0.8598 - accuracy: 0.62 - ETA: 0s - loss: 0.8422 - accuracy: 0.64 - ETA: 0s - loss: 0.8488 - accuracy: 0.63 - ETA: 0s - loss: 0.8607 - accuracy: 0.62 - ETA: 0s - loss: 0.8629 - accuracy: 0.62 - ETA: 0s - loss: 0.8688 - accuracy: 0.61 - ETA: 0s - loss: 0.8723 - accuracy: 0.6169\n",
      "Epoch 00564: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8723 - accuracy: 0.6169 - val_loss: 1.0568 - val_accuracy: 0.4940 - lr: 0.0010\n",
      "Epoch 565/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9246 - accuracy: 0.55 - ETA: 0s - loss: 0.8950 - accuracy: 0.57 - ETA: 0s - loss: 0.9089 - accuracy: 0.58 - ETA: 0s - loss: 0.8760 - accuracy: 0.60 - ETA: 0s - loss: 0.8753 - accuracy: 0.60 - ETA: 0s - loss: 0.8675 - accuracy: 0.62 - ETA: 0s - loss: 0.8654 - accuracy: 0.62 - ETA: 0s - loss: 0.8641 - accuracy: 0.62 - ETA: 0s - loss: 0.8647 - accuracy: 0.62 - ETA: 0s - loss: 0.8679 - accuracy: 0.61 - ETA: 0s - loss: 0.8639 - accuracy: 0.62 - ETA: 0s - loss: 0.8563 - accuracy: 0.63 - ETA: 0s - loss: 0.8389 - accuracy: 0.64 - ETA: 0s - loss: 0.8456 - accuracy: 0.63 - ETA: 0s - loss: 0.8592 - accuracy: 0.62 - ETA: 0s - loss: 0.8617 - accuracy: 0.62 - ETA: 0s - loss: 0.8674 - accuracy: 0.61 - ETA: 0s - loss: 0.8700 - accuracy: 0.61 - ETA: 0s - loss: 0.8713 - accuracy: 0.6178\n",
      "Epoch 00565: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8713 - accuracy: 0.6178 - val_loss: 1.0614 - val_accuracy: 0.4925 - lr: 0.0010\n",
      "Epoch 566/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.9124 - accuracy: 0.55 - ETA: 0s - loss: 0.8891 - accuracy: 0.58 - ETA: 0s - loss: 0.9026 - accuracy: 0.58 - ETA: 0s - loss: 0.8716 - accuracy: 0.60 - ETA: 0s - loss: 0.8717 - accuracy: 0.61 - ETA: 0s - loss: 0.8640 - accuracy: 0.62 - ETA: 0s - loss: 0.8622 - accuracy: 0.62 - ETA: 0s - loss: 0.8617 - accuracy: 0.62 - ETA: 0s - loss: 0.8629 - accuracy: 0.62 - ETA: 0s - loss: 0.8697 - accuracy: 0.61 - ETA: 0s - loss: 0.8647 - accuracy: 0.62 - ETA: 0s - loss: 0.8586 - accuracy: 0.63 - ETA: 0s - loss: 0.8413 - accuracy: 0.64 - ETA: 0s - loss: 0.8475 - accuracy: 0.63 - ETA: 0s - loss: 0.8613 - accuracy: 0.62 - ETA: 0s - loss: 0.8638 - accuracy: 0.62 - ETA: 0s - loss: 0.8692 - accuracy: 0.61 - ETA: 0s - loss: 0.8707 - accuracy: 0.6188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00566: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8720 - accuracy: 0.6177 - val_loss: 1.0690 - val_accuracy: 0.4852 - lr: 0.0010\n",
      "Epoch 567/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9485 - accuracy: 0.51 - ETA: 0s - loss: 0.9081 - accuracy: 0.56 - ETA: 0s - loss: 0.9206 - accuracy: 0.56 - ETA: 0s - loss: 0.8846 - accuracy: 0.59 - ETA: 0s - loss: 0.8818 - accuracy: 0.60 - ETA: 0s - loss: 0.8709 - accuracy: 0.61 - ETA: 0s - loss: 0.8669 - accuracy: 0.61 - ETA: 0s - loss: 0.8658 - accuracy: 0.62 - ETA: 0s - loss: 0.8664 - accuracy: 0.62 - ETA: 0s - loss: 0.8722 - accuracy: 0.61 - ETA: 0s - loss: 0.8676 - accuracy: 0.61 - ETA: 0s - loss: 0.8607 - accuracy: 0.62 - ETA: 0s - loss: 0.8429 - accuracy: 0.64 - ETA: 0s - loss: 0.8508 - accuracy: 0.63 - ETA: 0s - loss: 0.8636 - accuracy: 0.62 - ETA: 0s - loss: 0.8713 - accuracy: 0.61 - ETA: 0s - loss: 0.8729 - accuracy: 0.61 - ETA: 0s - loss: 0.8745 - accuracy: 0.6157\n",
      "Epoch 00567: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8745 - accuracy: 0.6157 - val_loss: 1.0666 - val_accuracy: 0.4839 - lr: 0.0010\n",
      "Epoch 568/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9032 - accuracy: 0.57 - ETA: 0s - loss: 0.8891 - accuracy: 0.58 - ETA: 0s - loss: 0.9010 - accuracy: 0.58 - ETA: 0s - loss: 0.8724 - accuracy: 0.60 - ETA: 0s - loss: 0.8708 - accuracy: 0.61 - ETA: 0s - loss: 0.8621 - accuracy: 0.62 - ETA: 0s - loss: 0.8592 - accuracy: 0.62 - ETA: 0s - loss: 0.8583 - accuracy: 0.62 - ETA: 0s - loss: 0.8604 - accuracy: 0.62 - ETA: 0s - loss: 0.8667 - accuracy: 0.61 - ETA: 0s - loss: 0.8608 - accuracy: 0.62 - ETA: 0s - loss: 0.8546 - accuracy: 0.63 - ETA: 0s - loss: 0.8370 - accuracy: 0.64 - ETA: 0s - loss: 0.8451 - accuracy: 0.63 - ETA: 0s - loss: 0.8617 - accuracy: 0.62 - ETA: 0s - loss: 0.8673 - accuracy: 0.61 - ETA: 0s - loss: 0.8687 - accuracy: 0.61 - ETA: 0s - loss: 0.8703 - accuracy: 0.6176\n",
      "Epoch 00568: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8703 - accuracy: 0.6176 - val_loss: 1.0727 - val_accuracy: 0.4824 - lr: 0.0010\n",
      "Epoch 569/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9056 - accuracy: 0.55 - ETA: 0s - loss: 0.8854 - accuracy: 0.58 - ETA: 0s - loss: 0.8996 - accuracy: 0.58 - ETA: 0s - loss: 0.8703 - accuracy: 0.60 - ETA: 0s - loss: 0.8713 - accuracy: 0.60 - ETA: 0s - loss: 0.8620 - accuracy: 0.61 - ETA: 0s - loss: 0.8608 - accuracy: 0.62 - ETA: 0s - loss: 0.8613 - accuracy: 0.62 - ETA: 0s - loss: 0.8627 - accuracy: 0.62 - ETA: 0s - loss: 0.8662 - accuracy: 0.61 - ETA: 0s - loss: 0.8617 - accuracy: 0.62 - ETA: 0s - loss: 0.8555 - accuracy: 0.63 - ETA: 0s - loss: 0.8383 - accuracy: 0.64 - ETA: 0s - loss: 0.8460 - accuracy: 0.63 - ETA: 0s - loss: 0.8592 - accuracy: 0.62 - ETA: 0s - loss: 0.8621 - accuracy: 0.62 - ETA: 0s - loss: 0.8669 - accuracy: 0.61 - ETA: 0s - loss: 0.8686 - accuracy: 0.62 - ETA: 0s - loss: 0.8702 - accuracy: 0.6182\n",
      "Epoch 00569: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8702 - accuracy: 0.6182 - val_loss: 1.0671 - val_accuracy: 0.4832 - lr: 0.0010\n",
      "Epoch 570/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9181 - accuracy: 0.54 - ETA: 0s - loss: 0.8954 - accuracy: 0.57 - ETA: 0s - loss: 0.9080 - accuracy: 0.57 - ETA: 0s - loss: 0.8743 - accuracy: 0.60 - ETA: 0s - loss: 0.8724 - accuracy: 0.60 - ETA: 0s - loss: 0.8639 - accuracy: 0.61 - ETA: 0s - loss: 0.8626 - accuracy: 0.62 - ETA: 0s - loss: 0.8625 - accuracy: 0.62 - ETA: 0s - loss: 0.8639 - accuracy: 0.62 - ETA: 0s - loss: 0.8687 - accuracy: 0.61 - ETA: 0s - loss: 0.8640 - accuracy: 0.62 - ETA: 0s - loss: 0.8585 - accuracy: 0.62 - ETA: 0s - loss: 0.8407 - accuracy: 0.64 - ETA: 0s - loss: 0.8478 - accuracy: 0.63 - ETA: 0s - loss: 0.8594 - accuracy: 0.62 - ETA: 0s - loss: 0.8616 - accuracy: 0.62 - ETA: 0s - loss: 0.8673 - accuracy: 0.61 - ETA: 0s - loss: 0.8701 - accuracy: 0.61 - ETA: 0s - loss: 0.8713 - accuracy: 0.6156\n",
      "Epoch 00570: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8713 - accuracy: 0.6156 - val_loss: 1.0694 - val_accuracy: 0.4862 - lr: 0.0010\n",
      "Epoch 571/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9016 - accuracy: 0.56 - ETA: 0s - loss: 0.8879 - accuracy: 0.57 - ETA: 0s - loss: 0.9008 - accuracy: 0.58 - ETA: 0s - loss: 0.8731 - accuracy: 0.60 - ETA: 0s - loss: 0.8730 - accuracy: 0.60 - ETA: 0s - loss: 0.8625 - accuracy: 0.62 - ETA: 0s - loss: 0.8600 - accuracy: 0.62 - ETA: 0s - loss: 0.8595 - accuracy: 0.62 - ETA: 0s - loss: 0.8604 - accuracy: 0.62 - ETA: 0s - loss: 0.8668 - accuracy: 0.61 - ETA: 0s - loss: 0.8628 - accuracy: 0.62 - ETA: 0s - loss: 0.8565 - accuracy: 0.62 - ETA: 0s - loss: 0.8395 - accuracy: 0.64 - ETA: 0s - loss: 0.8456 - accuracy: 0.63 - ETA: 0s - loss: 0.8604 - accuracy: 0.62 - ETA: 0s - loss: 0.8632 - accuracy: 0.62 - ETA: 0s - loss: 0.8690 - accuracy: 0.61 - ETA: 0s - loss: 0.8705 - accuracy: 0.61 - ETA: 0s - loss: 0.8727 - accuracy: 0.6177\n",
      "Epoch 00571: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00571: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8727 - accuracy: 0.6177 - val_loss: 1.0682 - val_accuracy: 0.4847 - lr: 0.0010\n",
      "Epoch 572/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9101 - accuracy: 0.55 - ETA: 0s - loss: 0.8867 - accuracy: 0.58 - ETA: 0s - loss: 0.8971 - accuracy: 0.58 - ETA: 0s - loss: 0.8718 - accuracy: 0.60 - ETA: 0s - loss: 0.8715 - accuracy: 0.60 - ETA: 0s - loss: 0.8643 - accuracy: 0.62 - ETA: 0s - loss: 0.8630 - accuracy: 0.62 - ETA: 0s - loss: 0.8623 - accuracy: 0.62 - ETA: 0s - loss: 0.8651 - accuracy: 0.62 - ETA: 0s - loss: 0.8713 - accuracy: 0.61 - ETA: 0s - loss: 0.8666 - accuracy: 0.62 - ETA: 0s - loss: 0.8601 - accuracy: 0.63 - ETA: 0s - loss: 0.8425 - accuracy: 0.64 - ETA: 0s - loss: 0.8506 - accuracy: 0.63 - ETA: 0s - loss: 0.8658 - accuracy: 0.62 - ETA: 0s - loss: 0.8710 - accuracy: 0.61 - ETA: 0s - loss: 0.8722 - accuracy: 0.61 - ETA: 0s - loss: 0.8736 - accuracy: 0.6185\n",
      "Epoch 00572: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8736 - accuracy: 0.6185 - val_loss: 1.0671 - val_accuracy: 0.4870 - lr: 0.0010\n",
      "Epoch 573/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9218 - accuracy: 0.56 - ETA: 0s - loss: 0.8920 - accuracy: 0.58 - ETA: 0s - loss: 0.9059 - accuracy: 0.58 - ETA: 0s - loss: 0.8767 - accuracy: 0.60 - ETA: 0s - loss: 0.8757 - accuracy: 0.61 - ETA: 0s - loss: 0.8666 - accuracy: 0.62 - ETA: 0s - loss: 0.8652 - accuracy: 0.62 - ETA: 0s - loss: 0.8642 - accuracy: 0.62 - ETA: 0s - loss: 0.8667 - accuracy: 0.62 - ETA: 0s - loss: 0.8728 - accuracy: 0.61 - ETA: 0s - loss: 0.8674 - accuracy: 0.62 - ETA: 0s - loss: 0.8613 - accuracy: 0.63 - ETA: 0s - loss: 0.8434 - accuracy: 0.64 - ETA: 0s - loss: 0.8499 - accuracy: 0.63 - ETA: 0s - loss: 0.8639 - accuracy: 0.62 - ETA: 0s - loss: 0.8671 - accuracy: 0.62 - ETA: 0s - loss: 0.8728 - accuracy: 0.61 - ETA: 0s - loss: 0.8746 - accuracy: 0.61 - ETA: 0s - loss: 0.8761 - accuracy: 0.6175\n",
      "Epoch 00573: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8761 - accuracy: 0.6175 - val_loss: 1.0583 - val_accuracy: 0.4935 - lr: 0.0010\n",
      "Epoch 574/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9190 - accuracy: 0.55 - ETA: 0s - loss: 0.8929 - accuracy: 0.58 - ETA: 0s - loss: 0.9032 - accuracy: 0.58 - ETA: 0s - loss: 0.8760 - accuracy: 0.60 - ETA: 0s - loss: 0.8761 - accuracy: 0.60 - ETA: 0s - loss: 0.8673 - accuracy: 0.61 - ETA: 0s - loss: 0.8657 - accuracy: 0.62 - ETA: 0s - loss: 0.8649 - accuracy: 0.62 - ETA: 0s - loss: 0.8664 - accuracy: 0.62 - ETA: 0s - loss: 0.8710 - accuracy: 0.61 - ETA: 0s - loss: 0.8657 - accuracy: 0.62 - ETA: 0s - loss: 0.8590 - accuracy: 0.63 - ETA: 0s - loss: 0.8410 - accuracy: 0.64 - ETA: 0s - loss: 0.8617 - accuracy: 0.62 - ETA: 0s - loss: 0.8649 - accuracy: 0.62 - ETA: 0s - loss: 0.8699 - accuracy: 0.61 - ETA: 0s - loss: 0.8711 - accuracy: 0.61 - ETA: 0s - loss: 0.8727 - accuracy: 0.6169\n",
      "Epoch 00574: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8727 - accuracy: 0.6169 - val_loss: 1.0596 - val_accuracy: 0.4943 - lr: 0.0010\n",
      "Epoch 575/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9025 - accuracy: 0.54 - ETA: 0s - loss: 0.8911 - accuracy: 0.57 - ETA: 0s - loss: 0.9035 - accuracy: 0.57 - ETA: 0s - loss: 0.8740 - accuracy: 0.60 - ETA: 0s - loss: 0.8720 - accuracy: 0.60 - ETA: 0s - loss: 0.8630 - accuracy: 0.61 - ETA: 0s - loss: 0.8612 - accuracy: 0.62 - ETA: 0s - loss: 0.8605 - accuracy: 0.62 - ETA: 0s - loss: 0.8624 - accuracy: 0.62 - ETA: 0s - loss: 0.8674 - accuracy: 0.61 - ETA: 0s - loss: 0.8623 - accuracy: 0.62 - ETA: 0s - loss: 0.8561 - accuracy: 0.62 - ETA: 0s - loss: 0.8382 - accuracy: 0.64 - ETA: 0s - loss: 0.8473 - accuracy: 0.63 - ETA: 0s - loss: 0.8615 - accuracy: 0.62 - ETA: 0s - loss: 0.8640 - accuracy: 0.61 - ETA: 0s - loss: 0.8696 - accuracy: 0.61 - ETA: 0s - loss: 0.8707 - accuracy: 0.61 - ETA: 0s - loss: 0.8721 - accuracy: 0.6149\n",
      "Epoch 00575: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8721 - accuracy: 0.6149 - val_loss: 1.0531 - val_accuracy: 0.4949 - lr: 0.0010\n",
      "Epoch 576/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9103 - accuracy: 0.53 - ETA: 0s - loss: 0.8871 - accuracy: 0.57 - ETA: 0s - loss: 0.8977 - accuracy: 0.57 - ETA: 0s - loss: 0.8716 - accuracy: 0.60 - ETA: 0s - loss: 0.8701 - accuracy: 0.60 - ETA: 0s - loss: 0.8620 - accuracy: 0.61 - ETA: 0s - loss: 0.8597 - accuracy: 0.62 - ETA: 0s - loss: 0.8579 - accuracy: 0.62 - ETA: 0s - loss: 0.8599 - accuracy: 0.62 - ETA: 0s - loss: 0.8661 - accuracy: 0.61 - ETA: 0s - loss: 0.8614 - accuracy: 0.62 - ETA: 0s - loss: 0.8549 - accuracy: 0.63 - ETA: 0s - loss: 0.8374 - accuracy: 0.64 - ETA: 0s - loss: 0.8457 - accuracy: 0.63 - ETA: 0s - loss: 0.8578 - accuracy: 0.62 - ETA: 0s - loss: 0.8598 - accuracy: 0.62 - ETA: 0s - loss: 0.8667 - accuracy: 0.62 - ETA: 0s - loss: 0.8681 - accuracy: 0.6188\n",
      "Epoch 00576: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8681 - accuracy: 0.6188 - val_loss: 1.0531 - val_accuracy: 0.4966 - lr: 0.0010\n",
      "Epoch 577/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9233 - accuracy: 0.54 - ETA: 0s - loss: 0.8946 - accuracy: 0.57 - ETA: 0s - loss: 0.9023 - accuracy: 0.57 - ETA: 0s - loss: 0.8708 - accuracy: 0.60 - ETA: 0s - loss: 0.8682 - accuracy: 0.60 - ETA: 0s - loss: 0.8605 - accuracy: 0.61 - ETA: 0s - loss: 0.8603 - accuracy: 0.61 - ETA: 0s - loss: 0.8599 - accuracy: 0.62 - ETA: 0s - loss: 0.8602 - accuracy: 0.62 - ETA: 0s - loss: 0.8657 - accuracy: 0.61 - ETA: 0s - loss: 0.8614 - accuracy: 0.62 - ETA: 0s - loss: 0.8550 - accuracy: 0.63 - ETA: 0s - loss: 0.8377 - accuracy: 0.64 - ETA: 0s - loss: 0.8437 - accuracy: 0.63 - ETA: 0s - loss: 0.8580 - accuracy: 0.62 - ETA: 0s - loss: 0.8603 - accuracy: 0.62 - ETA: 0s - loss: 0.8663 - accuracy: 0.61 - ETA: 0s - loss: 0.8690 - accuracy: 0.6188\n",
      "Epoch 00577: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8690 - accuracy: 0.6188 - val_loss: 1.0551 - val_accuracy: 0.4930 - lr: 0.0010\n",
      "Epoch 578/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9296 - accuracy: 0.55 - ETA: 0s - loss: 0.8966 - accuracy: 0.58 - ETA: 0s - loss: 0.9058 - accuracy: 0.58 - ETA: 0s - loss: 0.8757 - accuracy: 0.60 - ETA: 0s - loss: 0.8741 - accuracy: 0.61 - ETA: 0s - loss: 0.8659 - accuracy: 0.62 - ETA: 0s - loss: 0.8627 - accuracy: 0.62 - ETA: 0s - loss: 0.8633 - accuracy: 0.62 - ETA: 0s - loss: 0.8630 - accuracy: 0.62 - ETA: 0s - loss: 0.8665 - accuracy: 0.61 - ETA: 0s - loss: 0.8615 - accuracy: 0.62 - ETA: 0s - loss: 0.8550 - accuracy: 0.63 - ETA: 0s - loss: 0.8375 - accuracy: 0.64 - ETA: 0s - loss: 0.8460 - accuracy: 0.63 - ETA: 0s - loss: 0.8585 - accuracy: 0.62 - ETA: 0s - loss: 0.8611 - accuracy: 0.62 - ETA: 0s - loss: 0.8663 - accuracy: 0.62 - ETA: 0s - loss: 0.8685 - accuracy: 0.62 - ETA: 0s - loss: 0.8705 - accuracy: 0.6200\n",
      "Epoch 00578: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8705 - accuracy: 0.6200 - val_loss: 1.0661 - val_accuracy: 0.4902 - lr: 0.0010\n",
      "Epoch 579/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9191 - accuracy: 0.55 - ETA: 0s - loss: 0.8906 - accuracy: 0.58 - ETA: 0s - loss: 0.9035 - accuracy: 0.58 - ETA: 0s - loss: 0.8758 - accuracy: 0.60 - ETA: 0s - loss: 0.8729 - accuracy: 0.60 - ETA: 0s - loss: 0.8655 - accuracy: 0.61 - ETA: 0s - loss: 0.8640 - accuracy: 0.62 - ETA: 0s - loss: 0.8632 - accuracy: 0.62 - ETA: 0s - loss: 0.8636 - accuracy: 0.62 - ETA: 0s - loss: 0.8695 - accuracy: 0.61 - ETA: 0s - loss: 0.8652 - accuracy: 0.62 - ETA: 0s - loss: 0.8591 - accuracy: 0.62 - ETA: 0s - loss: 0.8414 - accuracy: 0.64 - ETA: 0s - loss: 0.8496 - accuracy: 0.63 - ETA: 0s - loss: 0.8617 - accuracy: 0.62 - ETA: 0s - loss: 0.8645 - accuracy: 0.62 - ETA: 0s - loss: 0.8703 - accuracy: 0.61 - ETA: 0s - loss: 0.8722 - accuracy: 0.61 - ETA: 0s - loss: 0.8735 - accuracy: 0.6179\n",
      "Epoch 00579: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8735 - accuracy: 0.6179 - val_loss: 1.0610 - val_accuracy: 0.4940 - lr: 0.0010\n",
      "Epoch 580/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9331 - accuracy: 0.53 - ETA: 0s - loss: 0.9005 - accuracy: 0.56 - ETA: 0s - loss: 0.9046 - accuracy: 0.57 - ETA: 0s - loss: 0.8749 - accuracy: 0.59 - ETA: 0s - loss: 0.8738 - accuracy: 0.60 - ETA: 0s - loss: 0.8653 - accuracy: 0.61 - ETA: 0s - loss: 0.8633 - accuracy: 0.62 - ETA: 0s - loss: 0.8625 - accuracy: 0.62 - ETA: 0s - loss: 0.8634 - accuracy: 0.62 - ETA: 0s - loss: 0.8693 - accuracy: 0.61 - ETA: 0s - loss: 0.8650 - accuracy: 0.62 - ETA: 0s - loss: 0.8580 - accuracy: 0.62 - ETA: 0s - loss: 0.8402 - accuracy: 0.64 - ETA: 0s - loss: 0.8476 - accuracy: 0.63 - ETA: 0s - loss: 0.8600 - accuracy: 0.62 - ETA: 0s - loss: 0.8632 - accuracy: 0.62 - ETA: 0s - loss: 0.8691 - accuracy: 0.61 - ETA: 0s - loss: 0.8699 - accuracy: 0.62 - ETA: 0s - loss: 0.8712 - accuracy: 0.6191\n",
      "Epoch 00580: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8712 - accuracy: 0.6191 - val_loss: 1.0597 - val_accuracy: 0.4935 - lr: 0.0010\n",
      "Epoch 581/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9394 - accuracy: 0.53 - ETA: 0s - loss: 0.9019 - accuracy: 0.56 - ETA: 0s - loss: 0.9071 - accuracy: 0.57 - ETA: 0s - loss: 0.8743 - accuracy: 0.59 - ETA: 0s - loss: 0.8736 - accuracy: 0.60 - ETA: 0s - loss: 0.8645 - accuracy: 0.61 - ETA: 0s - loss: 0.8625 - accuracy: 0.62 - ETA: 0s - loss: 0.8640 - accuracy: 0.62 - ETA: 0s - loss: 0.8654 - accuracy: 0.62 - ETA: 0s - loss: 0.8723 - accuracy: 0.61 - ETA: 0s - loss: 0.8677 - accuracy: 0.62 - ETA: 0s - loss: 0.8623 - accuracy: 0.62 - ETA: 0s - loss: 0.8437 - accuracy: 0.63 - ETA: 0s - loss: 0.8515 - accuracy: 0.63 - ETA: 0s - loss: 0.8630 - accuracy: 0.62 - ETA: 0s - loss: 0.8662 - accuracy: 0.61 - ETA: 0s - loss: 0.8716 - accuracy: 0.61 - ETA: 0s - loss: 0.8727 - accuracy: 0.61 - ETA: 0s - loss: 0.8742 - accuracy: 0.6148\n",
      "Epoch 00581: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8742 - accuracy: 0.6148 - val_loss: 1.0585 - val_accuracy: 0.4948 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 582/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.8997 - accuracy: 0.56 - ETA: 0s - loss: 0.8807 - accuracy: 0.58 - ETA: 0s - loss: 0.8953 - accuracy: 0.58 - ETA: 0s - loss: 0.8685 - accuracy: 0.60 - ETA: 0s - loss: 0.8683 - accuracy: 0.61 - ETA: 0s - loss: 0.8608 - accuracy: 0.62 - ETA: 0s - loss: 0.8587 - accuracy: 0.62 - ETA: 0s - loss: 0.8584 - accuracy: 0.62 - ETA: 0s - loss: 0.8598 - accuracy: 0.62 - ETA: 0s - loss: 0.8659 - accuracy: 0.61 - ETA: 0s - loss: 0.8617 - accuracy: 0.62 - ETA: 0s - loss: 0.8557 - accuracy: 0.63 - ETA: 0s - loss: 0.8382 - accuracy: 0.64 - ETA: 0s - loss: 0.8434 - accuracy: 0.63 - ETA: 0s - loss: 0.8572 - accuracy: 0.62 - ETA: 0s - loss: 0.8606 - accuracy: 0.62 - ETA: 0s - loss: 0.8665 - accuracy: 0.61 - ETA: 0s - loss: 0.8686 - accuracy: 0.6187\n",
      "Epoch 00582: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8707 - accuracy: 0.6171 - val_loss: 1.0604 - val_accuracy: 0.4948 - lr: 0.0010\n",
      "Epoch 583/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9044 - accuracy: 0.56 - ETA: 0s - loss: 0.8880 - accuracy: 0.58 - ETA: 0s - loss: 0.8992 - accuracy: 0.58 - ETA: 0s - loss: 0.8699 - accuracy: 0.60 - ETA: 0s - loss: 0.8685 - accuracy: 0.60 - ETA: 0s - loss: 0.8607 - accuracy: 0.62 - ETA: 0s - loss: 0.8599 - accuracy: 0.62 - ETA: 0s - loss: 0.8595 - accuracy: 0.62 - ETA: 0s - loss: 0.8597 - accuracy: 0.62 - ETA: 0s - loss: 0.8669 - accuracy: 0.61 - ETA: 0s - loss: 0.8629 - accuracy: 0.62 - ETA: 0s - loss: 0.8565 - accuracy: 0.62 - ETA: 0s - loss: 0.8382 - accuracy: 0.64 - ETA: 0s - loss: 0.8449 - accuracy: 0.63 - ETA: 0s - loss: 0.8597 - accuracy: 0.62 - ETA: 0s - loss: 0.8632 - accuracy: 0.62 - ETA: 0s - loss: 0.8681 - accuracy: 0.62 - ETA: 0s - loss: 0.8695 - accuracy: 0.62 - ETA: 0s - loss: 0.8717 - accuracy: 0.6195\n",
      "Epoch 00583: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8717 - accuracy: 0.6195 - val_loss: 1.0606 - val_accuracy: 0.4935 - lr: 0.0010\n",
      "Epoch 584/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9292 - accuracy: 0.54 - ETA: 0s - loss: 0.9017 - accuracy: 0.57 - ETA: 0s - loss: 0.9100 - accuracy: 0.57 - ETA: 0s - loss: 0.8769 - accuracy: 0.60 - ETA: 0s - loss: 0.8733 - accuracy: 0.60 - ETA: 0s - loss: 0.8648 - accuracy: 0.62 - ETA: 0s - loss: 0.8621 - accuracy: 0.62 - ETA: 0s - loss: 0.8624 - accuracy: 0.62 - ETA: 0s - loss: 0.8647 - accuracy: 0.62 - ETA: 0s - loss: 0.8709 - accuracy: 0.61 - ETA: 0s - loss: 0.8655 - accuracy: 0.62 - ETA: 0s - loss: 0.8591 - accuracy: 0.62 - ETA: 0s - loss: 0.8413 - accuracy: 0.64 - ETA: 0s - loss: 0.8493 - accuracy: 0.63 - ETA: 0s - loss: 0.8628 - accuracy: 0.62 - ETA: 0s - loss: 0.8650 - accuracy: 0.62 - ETA: 0s - loss: 0.8710 - accuracy: 0.61 - ETA: 0s - loss: 0.8721 - accuracy: 0.61 - ETA: 0s - loss: 0.8737 - accuracy: 0.6163\n",
      "Epoch 00584: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8737 - accuracy: 0.6163 - val_loss: 1.0658 - val_accuracy: 0.4878 - lr: 0.0010\n",
      "Epoch 585/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9215 - accuracy: 0.54 - ETA: 0s - loss: 0.8953 - accuracy: 0.57 - ETA: 0s - loss: 0.9046 - accuracy: 0.57 - ETA: 0s - loss: 0.8743 - accuracy: 0.60 - ETA: 0s - loss: 0.8737 - accuracy: 0.60 - ETA: 0s - loss: 0.8640 - accuracy: 0.62 - ETA: 0s - loss: 0.8617 - accuracy: 0.62 - ETA: 0s - loss: 0.8628 - accuracy: 0.62 - ETA: 0s - loss: 0.8649 - accuracy: 0.62 - ETA: 0s - loss: 0.8709 - accuracy: 0.61 - ETA: 0s - loss: 0.8657 - accuracy: 0.62 - ETA: 0s - loss: 0.8597 - accuracy: 0.62 - ETA: 0s - loss: 0.8411 - accuracy: 0.64 - ETA: 0s - loss: 0.8479 - accuracy: 0.63 - ETA: 0s - loss: 0.8637 - accuracy: 0.62 - ETA: 0s - loss: 0.8691 - accuracy: 0.61 - ETA: 0s - loss: 0.8704 - accuracy: 0.61 - ETA: 0s - loss: 0.8721 - accuracy: 0.6173\n",
      "Epoch 00585: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00585: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8721 - accuracy: 0.6173 - val_loss: 1.0629 - val_accuracy: 0.4891 - lr: 0.0010\n",
      "Epoch 586/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9091 - accuracy: 0.54 - ETA: 0s - loss: 0.8860 - accuracy: 0.57 - ETA: 0s - loss: 0.8989 - accuracy: 0.57 - ETA: 0s - loss: 0.8703 - accuracy: 0.59 - ETA: 0s - loss: 0.8693 - accuracy: 0.60 - ETA: 0s - loss: 0.8629 - accuracy: 0.61 - ETA: 0s - loss: 0.8602 - accuracy: 0.62 - ETA: 0s - loss: 0.8584 - accuracy: 0.62 - ETA: 0s - loss: 0.8615 - accuracy: 0.62 - ETA: 0s - loss: 0.8661 - accuracy: 0.61 - ETA: 0s - loss: 0.8613 - accuracy: 0.62 - ETA: 0s - loss: 0.8547 - accuracy: 0.63 - ETA: 0s - loss: 0.8369 - accuracy: 0.64 - ETA: 0s - loss: 0.8435 - accuracy: 0.63 - ETA: 0s - loss: 0.8580 - accuracy: 0.62 - ETA: 0s - loss: 0.8610 - accuracy: 0.62 - ETA: 0s - loss: 0.8663 - accuracy: 0.61 - ETA: 0s - loss: 0.8678 - accuracy: 0.61 - ETA: 0s - loss: 0.8691 - accuracy: 0.6176\n",
      "Epoch 00586: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8691 - accuracy: 0.6176 - val_loss: 1.0667 - val_accuracy: 0.4866 - lr: 0.0010\n",
      "Epoch 587/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9075 - accuracy: 0.55 - ETA: 0s - loss: 0.8850 - accuracy: 0.58 - ETA: 0s - loss: 0.8956 - accuracy: 0.58 - ETA: 0s - loss: 0.8656 - accuracy: 0.60 - ETA: 0s - loss: 0.8673 - accuracy: 0.60 - ETA: 0s - loss: 0.8599 - accuracy: 0.61 - ETA: 0s - loss: 0.8595 - accuracy: 0.62 - ETA: 0s - loss: 0.8572 - accuracy: 0.62 - ETA: 0s - loss: 0.8595 - accuracy: 0.62 - ETA: 0s - loss: 0.8646 - accuracy: 0.61 - ETA: 0s - loss: 0.8605 - accuracy: 0.62 - ETA: 0s - loss: 0.8538 - accuracy: 0.62 - ETA: 0s - loss: 0.8363 - accuracy: 0.64 - ETA: 0s - loss: 0.8451 - accuracy: 0.63 - ETA: 0s - loss: 0.8581 - accuracy: 0.62 - ETA: 0s - loss: 0.8617 - accuracy: 0.62 - ETA: 0s - loss: 0.8672 - accuracy: 0.61 - ETA: 0s - loss: 0.8692 - accuracy: 0.61 - ETA: 0s - loss: 0.8707 - accuracy: 0.6161\n",
      "Epoch 00587: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8707 - accuracy: 0.6161 - val_loss: 1.0710 - val_accuracy: 0.4819 - lr: 0.0010\n",
      "Epoch 588/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9059 - accuracy: 0.56 - ETA: 0s - loss: 0.8825 - accuracy: 0.58 - ETA: 0s - loss: 0.8975 - accuracy: 0.58 - ETA: 0s - loss: 0.8681 - accuracy: 0.60 - ETA: 0s - loss: 0.8670 - accuracy: 0.61 - ETA: 0s - loss: 0.8604 - accuracy: 0.62 - ETA: 0s - loss: 0.8580 - accuracy: 0.62 - ETA: 0s - loss: 0.8578 - accuracy: 0.62 - ETA: 0s - loss: 0.8610 - accuracy: 0.62 - ETA: 0s - loss: 0.8645 - accuracy: 0.61 - ETA: 0s - loss: 0.8609 - accuracy: 0.62 - ETA: 0s - loss: 0.8543 - accuracy: 0.63 - ETA: 0s - loss: 0.8365 - accuracy: 0.64 - ETA: 0s - loss: 0.8593 - accuracy: 0.62 - ETA: 0s - loss: 0.8625 - accuracy: 0.62 - ETA: 0s - loss: 0.8683 - accuracy: 0.62 - ETA: 0s - loss: 0.8695 - accuracy: 0.62 - ETA: 0s - loss: 0.8715 - accuracy: 0.6188\n",
      "Epoch 00588: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8715 - accuracy: 0.6188 - val_loss: 1.0706 - val_accuracy: 0.4857 - lr: 0.0010\n",
      "Epoch 589/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9085 - accuracy: 0.54 - ETA: 0s - loss: 0.8929 - accuracy: 0.57 - ETA: 0s - loss: 0.9030 - accuracy: 0.57 - ETA: 0s - loss: 0.8715 - accuracy: 0.59 - ETA: 0s - loss: 0.8719 - accuracy: 0.60 - ETA: 0s - loss: 0.8625 - accuracy: 0.61 - ETA: 0s - loss: 0.8598 - accuracy: 0.62 - ETA: 0s - loss: 0.8597 - accuracy: 0.62 - ETA: 0s - loss: 0.8614 - accuracy: 0.62 - ETA: 0s - loss: 0.8677 - accuracy: 0.61 - ETA: 0s - loss: 0.8634 - accuracy: 0.62 - ETA: 0s - loss: 0.8563 - accuracy: 0.63 - ETA: 0s - loss: 0.8382 - accuracy: 0.64 - ETA: 0s - loss: 0.8463 - accuracy: 0.63 - ETA: 0s - loss: 0.8585 - accuracy: 0.62 - ETA: 0s - loss: 0.8614 - accuracy: 0.62 - ETA: 0s - loss: 0.8670 - accuracy: 0.62 - ETA: 0s - loss: 0.8682 - accuracy: 0.62 - ETA: 0s - loss: 0.8700 - accuracy: 0.6205\n",
      "Epoch 00589: val_loss did not improve from 0.99131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8700 - accuracy: 0.6205 - val_loss: 1.0745 - val_accuracy: 0.4852 - lr: 0.0010\n",
      "Epoch 590/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9185 - accuracy: 0.54 - ETA: 0s - loss: 0.8945 - accuracy: 0.56 - ETA: 0s - loss: 0.9002 - accuracy: 0.57 - ETA: 0s - loss: 0.8714 - accuracy: 0.60 - ETA: 0s - loss: 0.8701 - accuracy: 0.60 - ETA: 0s - loss: 0.8623 - accuracy: 0.61 - ETA: 0s - loss: 0.8601 - accuracy: 0.62 - ETA: 0s - loss: 0.8597 - accuracy: 0.62 - ETA: 0s - loss: 0.8622 - accuracy: 0.62 - ETA: 0s - loss: 0.8677 - accuracy: 0.61 - ETA: 0s - loss: 0.8643 - accuracy: 0.61 - ETA: 0s - loss: 0.8576 - accuracy: 0.62 - ETA: 0s - loss: 0.8394 - accuracy: 0.63 - ETA: 0s - loss: 0.8471 - accuracy: 0.63 - ETA: 0s - loss: 0.8635 - accuracy: 0.61 - ETA: 0s - loss: 0.8688 - accuracy: 0.61 - ETA: 0s - loss: 0.8703 - accuracy: 0.61 - ETA: 0s - loss: 0.8717 - accuracy: 0.6127\n",
      "Epoch 00590: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8717 - accuracy: 0.6127 - val_loss: 1.0766 - val_accuracy: 0.4847 - lr: 0.0010\n",
      "Epoch 591/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9096 - accuracy: 0.54 - ETA: 0s - loss: 0.8888 - accuracy: 0.57 - ETA: 0s - loss: 0.8957 - accuracy: 0.57 - ETA: 0s - loss: 0.8704 - accuracy: 0.60 - ETA: 0s - loss: 0.8678 - accuracy: 0.60 - ETA: 0s - loss: 0.8611 - accuracy: 0.61 - ETA: 0s - loss: 0.8598 - accuracy: 0.62 - ETA: 0s - loss: 0.8606 - accuracy: 0.61 - ETA: 0s - loss: 0.8633 - accuracy: 0.61 - ETA: 0s - loss: 0.8679 - accuracy: 0.60 - ETA: 0s - loss: 0.8639 - accuracy: 0.61 - ETA: 0s - loss: 0.8574 - accuracy: 0.62 - ETA: 0s - loss: 0.8390 - accuracy: 0.63 - ETA: 0s - loss: 0.8437 - accuracy: 0.63 - ETA: 0s - loss: 0.8570 - accuracy: 0.62 - ETA: 0s - loss: 0.8602 - accuracy: 0.61 - ETA: 0s - loss: 0.8685 - accuracy: 0.61 - ETA: 0s - loss: 0.8703 - accuracy: 0.6140\n",
      "Epoch 00591: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8703 - accuracy: 0.6140 - val_loss: 1.0824 - val_accuracy: 0.4837 - lr: 0.0010\n",
      "Epoch 592/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9093 - accuracy: 0.55 - ETA: 0s - loss: 0.8898 - accuracy: 0.58 - ETA: 0s - loss: 0.9031 - accuracy: 0.58 - ETA: 0s - loss: 0.8703 - accuracy: 0.60 - ETA: 0s - loss: 0.8700 - accuracy: 0.61 - ETA: 0s - loss: 0.8604 - accuracy: 0.62 - ETA: 0s - loss: 0.8581 - accuracy: 0.62 - ETA: 0s - loss: 0.8580 - accuracy: 0.62 - ETA: 0s - loss: 0.8596 - accuracy: 0.62 - ETA: 0s - loss: 0.8657 - accuracy: 0.62 - ETA: 0s - loss: 0.8623 - accuracy: 0.62 - ETA: 0s - loss: 0.8558 - accuracy: 0.63 - ETA: 0s - loss: 0.8373 - accuracy: 0.64 - ETA: 0s - loss: 0.8435 - accuracy: 0.64 - ETA: 0s - loss: 0.8576 - accuracy: 0.62 - ETA: 0s - loss: 0.8606 - accuracy: 0.62 - ETA: 0s - loss: 0.8664 - accuracy: 0.62 - ETA: 0s - loss: 0.8675 - accuracy: 0.62 - ETA: 0s - loss: 0.8688 - accuracy: 0.6201\n",
      "Epoch 00592: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8688 - accuracy: 0.6201 - val_loss: 1.0770 - val_accuracy: 0.4834 - lr: 0.0010\n",
      "Epoch 593/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9026 - accuracy: 0.57 - ETA: 0s - loss: 0.8848 - accuracy: 0.58 - ETA: 0s - loss: 0.8987 - accuracy: 0.58 - ETA: 0s - loss: 0.8695 - accuracy: 0.60 - ETA: 0s - loss: 0.8698 - accuracy: 0.61 - ETA: 0s - loss: 0.8618 - accuracy: 0.62 - ETA: 0s - loss: 0.8596 - accuracy: 0.62 - ETA: 0s - loss: 0.8611 - accuracy: 0.62 - ETA: 0s - loss: 0.8631 - accuracy: 0.62 - ETA: 0s - loss: 0.8696 - accuracy: 0.61 - ETA: 0s - loss: 0.8641 - accuracy: 0.62 - ETA: 0s - loss: 0.8566 - accuracy: 0.63 - ETA: 0s - loss: 0.8383 - accuracy: 0.64 - ETA: 0s - loss: 0.8460 - accuracy: 0.63 - ETA: 0s - loss: 0.8584 - accuracy: 0.62 - ETA: 0s - loss: 0.8612 - accuracy: 0.62 - ETA: 0s - loss: 0.8670 - accuracy: 0.61 - ETA: 0s - loss: 0.8685 - accuracy: 0.62 - ETA: 0s - loss: 0.8697 - accuracy: 0.6185\n",
      "Epoch 00593: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8697 - accuracy: 0.6185 - val_loss: 1.0761 - val_accuracy: 0.4852 - lr: 0.0010\n",
      "Epoch 594/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9138 - accuracy: 0.55 - ETA: 0s - loss: 0.8880 - accuracy: 0.58 - ETA: 0s - loss: 0.9055 - accuracy: 0.58 - ETA: 0s - loss: 0.8746 - accuracy: 0.60 - ETA: 0s - loss: 0.8731 - accuracy: 0.60 - ETA: 0s - loss: 0.8648 - accuracy: 0.61 - ETA: 0s - loss: 0.8618 - accuracy: 0.62 - ETA: 0s - loss: 0.8616 - accuracy: 0.62 - ETA: 0s - loss: 0.8634 - accuracy: 0.62 - ETA: 0s - loss: 0.8701 - accuracy: 0.61 - ETA: 0s - loss: 0.8654 - accuracy: 0.62 - ETA: 0s - loss: 0.8581 - accuracy: 0.63 - ETA: 0s - loss: 0.8400 - accuracy: 0.64 - ETA: 0s - loss: 0.8469 - accuracy: 0.63 - ETA: 0s - loss: 0.8586 - accuracy: 0.62 - ETA: 0s - loss: 0.8615 - accuracy: 0.62 - ETA: 0s - loss: 0.8673 - accuracy: 0.62 - ETA: 0s - loss: 0.8686 - accuracy: 0.62 - ETA: 0s - loss: 0.8698 - accuracy: 0.6197\n",
      "Epoch 00594: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8698 - accuracy: 0.6197 - val_loss: 1.0784 - val_accuracy: 0.4818 - lr: 0.0010\n",
      "Epoch 595/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9186 - accuracy: 0.55 - ETA: 0s - loss: 0.8855 - accuracy: 0.58 - ETA: 0s - loss: 0.8989 - accuracy: 0.58 - ETA: 0s - loss: 0.8704 - accuracy: 0.60 - ETA: 0s - loss: 0.8680 - accuracy: 0.61 - ETA: 0s - loss: 0.8603 - accuracy: 0.62 - ETA: 0s - loss: 0.8589 - accuracy: 0.62 - ETA: 0s - loss: 0.8589 - accuracy: 0.62 - ETA: 0s - loss: 0.8613 - accuracy: 0.62 - ETA: 0s - loss: 0.8674 - accuracy: 0.61 - ETA: 0s - loss: 0.8643 - accuracy: 0.62 - ETA: 0s - loss: 0.8578 - accuracy: 0.63 - ETA: 0s - loss: 0.8403 - accuracy: 0.64 - ETA: 0s - loss: 0.8483 - accuracy: 0.63 - ETA: 0s - loss: 0.8613 - accuracy: 0.62 - ETA: 0s - loss: 0.8641 - accuracy: 0.62 - ETA: 0s - loss: 0.8689 - accuracy: 0.62 - ETA: 0s - loss: 0.8718 - accuracy: 0.62 - ETA: 0s - loss: 0.8724 - accuracy: 0.6202\n",
      "Epoch 00595: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8724 - accuracy: 0.6202 - val_loss: 1.0670 - val_accuracy: 0.4860 - lr: 0.0010\n",
      "Epoch 596/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9246 - accuracy: 0.53 - ETA: 0s - loss: 0.8967 - accuracy: 0.56 - ETA: 0s - loss: 0.9027 - accuracy: 0.57 - ETA: 0s - loss: 0.8722 - accuracy: 0.59 - ETA: 0s - loss: 0.8696 - accuracy: 0.60 - ETA: 0s - loss: 0.8628 - accuracy: 0.61 - ETA: 0s - loss: 0.8589 - accuracy: 0.62 - ETA: 0s - loss: 0.8589 - accuracy: 0.62 - ETA: 0s - loss: 0.8608 - accuracy: 0.62 - ETA: 0s - loss: 0.8661 - accuracy: 0.61 - ETA: 0s - loss: 0.8615 - accuracy: 0.62 - ETA: 0s - loss: 0.8553 - accuracy: 0.62 - ETA: 0s - loss: 0.8374 - accuracy: 0.64 - ETA: 0s - loss: 0.8447 - accuracy: 0.63 - ETA: 0s - loss: 0.8577 - accuracy: 0.62 - ETA: 0s - loss: 0.8603 - accuracy: 0.62 - ETA: 0s - loss: 0.8669 - accuracy: 0.61 - ETA: 0s - loss: 0.8690 - accuracy: 0.61 - ETA: 0s - loss: 0.8706 - accuracy: 0.6161\n",
      "Epoch 00596: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8706 - accuracy: 0.6161 - val_loss: 1.0622 - val_accuracy: 0.4896 - lr: 0.0010\n",
      "Epoch 597/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9027 - accuracy: 0.54 - ETA: 0s - loss: 0.8842 - accuracy: 0.57 - ETA: 0s - loss: 0.8973 - accuracy: 0.57 - ETA: 0s - loss: 0.8678 - accuracy: 0.60 - ETA: 0s - loss: 0.8690 - accuracy: 0.60 - ETA: 0s - loss: 0.8586 - accuracy: 0.62 - ETA: 0s - loss: 0.8587 - accuracy: 0.62 - ETA: 0s - loss: 0.8595 - accuracy: 0.62 - ETA: 0s - loss: 0.8663 - accuracy: 0.61 - ETA: 0s - loss: 0.8615 - accuracy: 0.62 - ETA: 0s - loss: 0.8543 - accuracy: 0.62 - ETA: 0s - loss: 0.8364 - accuracy: 0.64 - ETA: 0s - loss: 0.8434 - accuracy: 0.63 - ETA: 0s - loss: 0.8566 - accuracy: 0.62 - ETA: 0s - loss: 0.8602 - accuracy: 0.62 - ETA: 0s - loss: 0.8661 - accuracy: 0.61 - ETA: 0s - loss: 0.8684 - accuracy: 0.61 - ETA: 0s - loss: 0.8710 - accuracy: 0.6171\n",
      "Epoch 00597: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8710 - accuracy: 0.6171 - val_loss: 1.0601 - val_accuracy: 0.4923 - lr: 0.0010\n",
      "Epoch 598/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.9462 - accuracy: 0.54 - ETA: 0s - loss: 0.9032 - accuracy: 0.57 - ETA: 0s - loss: 0.9120 - accuracy: 0.57 - ETA: 0s - loss: 0.8774 - accuracy: 0.60 - ETA: 0s - loss: 0.8758 - accuracy: 0.60 - ETA: 0s - loss: 0.8667 - accuracy: 0.61 - ETA: 0s - loss: 0.8616 - accuracy: 0.62 - ETA: 0s - loss: 0.8611 - accuracy: 0.62 - ETA: 0s - loss: 0.8617 - accuracy: 0.62 - ETA: 0s - loss: 0.8672 - accuracy: 0.61 - ETA: 0s - loss: 0.8615 - accuracy: 0.62 - ETA: 0s - loss: 0.8548 - accuracy: 0.63 - ETA: 0s - loss: 0.8375 - accuracy: 0.64 - ETA: 0s - loss: 0.8447 - accuracy: 0.63 - ETA: 0s - loss: 0.8579 - accuracy: 0.62 - ETA: 0s - loss: 0.8604 - accuracy: 0.62 - ETA: 0s - loss: 0.8668 - accuracy: 0.61 - ETA: 0s - loss: 0.8684 - accuracy: 0.6199\n",
      "Epoch 00598: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8700 - accuracy: 0.6187 - val_loss: 1.0633 - val_accuracy: 0.4907 - lr: 0.0010\n",
      "Epoch 599/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9041 - accuracy: 0.54 - ETA: 0s - loss: 0.8766 - accuracy: 0.57 - ETA: 0s - loss: 0.8938 - accuracy: 0.57 - ETA: 0s - loss: 0.8645 - accuracy: 0.60 - ETA: 0s - loss: 0.8637 - accuracy: 0.61 - ETA: 0s - loss: 0.8567 - accuracy: 0.62 - ETA: 0s - loss: 0.8557 - accuracy: 0.62 - ETA: 0s - loss: 0.8552 - accuracy: 0.62 - ETA: 0s - loss: 0.8578 - accuracy: 0.62 - ETA: 0s - loss: 0.8640 - accuracy: 0.61 - ETA: 0s - loss: 0.8592 - accuracy: 0.62 - ETA: 0s - loss: 0.8534 - accuracy: 0.62 - ETA: 0s - loss: 0.8356 - accuracy: 0.64 - ETA: 0s - loss: 0.8427 - accuracy: 0.63 - ETA: 0s - loss: 0.8550 - accuracy: 0.62 - ETA: 0s - loss: 0.8577 - accuracy: 0.62 - ETA: 0s - loss: 0.8632 - accuracy: 0.62 - ETA: 0s - loss: 0.8651 - accuracy: 0.62 - ETA: 0s - loss: 0.8667 - accuracy: 0.6202\n",
      "Epoch 00599: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00599: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8667 - accuracy: 0.6202 - val_loss: 1.0628 - val_accuracy: 0.4928 - lr: 0.0010\n",
      "Epoch 600/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9152 - accuracy: 0.54 - ETA: 0s - loss: 0.8957 - accuracy: 0.56 - ETA: 0s - loss: 0.9051 - accuracy: 0.57 - ETA: 0s - loss: 0.8757 - accuracy: 0.59 - ETA: 0s - loss: 0.8740 - accuracy: 0.60 - ETA: 0s - loss: 0.8672 - accuracy: 0.61 - ETA: 0s - loss: 0.8651 - accuracy: 0.61 - ETA: 0s - loss: 0.8628 - accuracy: 0.62 - ETA: 0s - loss: 0.8691 - accuracy: 0.61 - ETA: 0s - loss: 0.8745 - accuracy: 0.60 - ETA: 0s - loss: 0.8684 - accuracy: 0.61 - ETA: 0s - loss: 0.8632 - accuracy: 0.62 - ETA: 0s - loss: 0.8448 - accuracy: 0.63 - ETA: 0s - loss: 0.8524 - accuracy: 0.63 - ETA: 0s - loss: 0.8648 - accuracy: 0.61 - ETA: 0s - loss: 0.8675 - accuracy: 0.61 - ETA: 0s - loss: 0.8737 - accuracy: 0.61 - ETA: 0s - loss: 0.8751 - accuracy: 0.61 - ETA: 0s - loss: 0.8762 - accuracy: 0.6125\n",
      "Epoch 00600: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8762 - accuracy: 0.6125 - val_loss: 1.0709 - val_accuracy: 0.4847 - lr: 0.0010\n",
      "Epoch 601/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9273 - accuracy: 0.55 - ETA: 0s - loss: 0.8985 - accuracy: 0.57 - ETA: 0s - loss: 0.9073 - accuracy: 0.58 - ETA: 0s - loss: 0.8736 - accuracy: 0.60 - ETA: 0s - loss: 0.8724 - accuracy: 0.61 - ETA: 0s - loss: 0.8623 - accuracy: 0.62 - ETA: 0s - loss: 0.8583 - accuracy: 0.62 - ETA: 0s - loss: 0.8588 - accuracy: 0.62 - ETA: 0s - loss: 0.8604 - accuracy: 0.62 - ETA: 0s - loss: 0.8653 - accuracy: 0.61 - ETA: 0s - loss: 0.8607 - accuracy: 0.62 - ETA: 0s - loss: 0.8551 - accuracy: 0.63 - ETA: 0s - loss: 0.8369 - accuracy: 0.64 - ETA: 0s - loss: 0.8429 - accuracy: 0.64 - ETA: 0s - loss: 0.8553 - accuracy: 0.62 - ETA: 0s - loss: 0.8586 - accuracy: 0.62 - ETA: 0s - loss: 0.8652 - accuracy: 0.62 - ETA: 0s - loss: 0.8675 - accuracy: 0.62 - ETA: 0s - loss: 0.8696 - accuracy: 0.6209\n",
      "Epoch 00601: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8696 - accuracy: 0.6209 - val_loss: 1.0674 - val_accuracy: 0.4896 - lr: 0.0010\n",
      "Epoch 602/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9044 - accuracy: 0.54 - ETA: 0s - loss: 0.8764 - accuracy: 0.57 - ETA: 0s - loss: 0.8970 - accuracy: 0.57 - ETA: 0s - loss: 0.8671 - accuracy: 0.60 - ETA: 0s - loss: 0.8660 - accuracy: 0.60 - ETA: 0s - loss: 0.8592 - accuracy: 0.61 - ETA: 0s - loss: 0.8564 - accuracy: 0.62 - ETA: 0s - loss: 0.8575 - accuracy: 0.62 - ETA: 0s - loss: 0.8599 - accuracy: 0.62 - ETA: 0s - loss: 0.8641 - accuracy: 0.61 - ETA: 0s - loss: 0.8594 - accuracy: 0.62 - ETA: 0s - loss: 0.8535 - accuracy: 0.63 - ETA: 0s - loss: 0.8356 - accuracy: 0.64 - ETA: 0s - loss: 0.8436 - accuracy: 0.64 - ETA: 0s - loss: 0.8582 - accuracy: 0.62 - ETA: 0s - loss: 0.8604 - accuracy: 0.62 - ETA: 0s - loss: 0.8662 - accuracy: 0.61 - ETA: 0s - loss: 0.8684 - accuracy: 0.61 - ETA: 0s - loss: 0.8708 - accuracy: 0.6177\n",
      "Epoch 00602: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8708 - accuracy: 0.6177 - val_loss: 1.0698 - val_accuracy: 0.4868 - lr: 0.0010\n",
      "Epoch 603/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9380 - accuracy: 0.51 - ETA: 0s - loss: 0.9054 - accuracy: 0.55 - ETA: 0s - loss: 0.9126 - accuracy: 0.56 - ETA: 0s - loss: 0.8783 - accuracy: 0.59 - ETA: 0s - loss: 0.8773 - accuracy: 0.60 - ETA: 0s - loss: 0.8677 - accuracy: 0.61 - ETA: 0s - loss: 0.8642 - accuracy: 0.61 - ETA: 0s - loss: 0.8627 - accuracy: 0.62 - ETA: 0s - loss: 0.8644 - accuracy: 0.62 - ETA: 0s - loss: 0.8689 - accuracy: 0.61 - ETA: 0s - loss: 0.8643 - accuracy: 0.62 - ETA: 0s - loss: 0.8569 - accuracy: 0.62 - ETA: 0s - loss: 0.8386 - accuracy: 0.64 - ETA: 0s - loss: 0.8452 - accuracy: 0.63 - ETA: 0s - loss: 0.8592 - accuracy: 0.62 - ETA: 0s - loss: 0.8624 - accuracy: 0.62 - ETA: 0s - loss: 0.8685 - accuracy: 0.61 - ETA: 0s - loss: 0.8702 - accuracy: 0.61 - ETA: 0s - loss: 0.8722 - accuracy: 0.6177\n",
      "Epoch 00603: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8722 - accuracy: 0.6177 - val_loss: 1.0679 - val_accuracy: 0.4857 - lr: 0.0010\n",
      "Epoch 604/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9394 - accuracy: 0.53 - ETA: 0s - loss: 0.8962 - accuracy: 0.57 - ETA: 0s - loss: 0.9054 - accuracy: 0.57 - ETA: 0s - loss: 0.8741 - accuracy: 0.59 - ETA: 0s - loss: 0.8713 - accuracy: 0.60 - ETA: 0s - loss: 0.8632 - accuracy: 0.61 - ETA: 0s - loss: 0.8611 - accuracy: 0.62 - ETA: 0s - loss: 0.8585 - accuracy: 0.62 - ETA: 0s - loss: 0.8604 - accuracy: 0.62 - ETA: 0s - loss: 0.8667 - accuracy: 0.61 - ETA: 0s - loss: 0.8620 - accuracy: 0.62 - ETA: 0s - loss: 0.8566 - accuracy: 0.62 - ETA: 0s - loss: 0.8391 - accuracy: 0.64 - ETA: 0s - loss: 0.8471 - accuracy: 0.63 - ETA: 0s - loss: 0.8598 - accuracy: 0.62 - ETA: 0s - loss: 0.8629 - accuracy: 0.62 - ETA: 0s - loss: 0.8681 - accuracy: 0.61 - ETA: 0s - loss: 0.8702 - accuracy: 0.61 - ETA: 0s - loss: 0.8721 - accuracy: 0.6160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00604: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8721 - accuracy: 0.6160 - val_loss: 1.0635 - val_accuracy: 0.4871 - lr: 0.0010\n",
      "Epoch 605/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9057 - accuracy: 0.54 - ETA: 0s - loss: 0.8830 - accuracy: 0.57 - ETA: 0s - loss: 0.8959 - accuracy: 0.57 - ETA: 0s - loss: 0.8680 - accuracy: 0.60 - ETA: 0s - loss: 0.8666 - accuracy: 0.60 - ETA: 0s - loss: 0.8583 - accuracy: 0.62 - ETA: 0s - loss: 0.8580 - accuracy: 0.62 - ETA: 0s - loss: 0.8578 - accuracy: 0.62 - ETA: 0s - loss: 0.8605 - accuracy: 0.62 - ETA: 0s - loss: 0.8656 - accuracy: 0.61 - ETA: 0s - loss: 0.8611 - accuracy: 0.62 - ETA: 0s - loss: 0.8572 - accuracy: 0.63 - ETA: 0s - loss: 0.8395 - accuracy: 0.64 - ETA: 0s - loss: 0.8452 - accuracy: 0.63 - ETA: 0s - loss: 0.8577 - accuracy: 0.62 - ETA: 0s - loss: 0.8602 - accuracy: 0.62 - ETA: 0s - loss: 0.8654 - accuracy: 0.62 - ETA: 0s - loss: 0.8670 - accuracy: 0.62 - ETA: 0s - loss: 0.8691 - accuracy: 0.6209\n",
      "Epoch 00605: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8691 - accuracy: 0.6209 - val_loss: 1.0587 - val_accuracy: 0.4902 - lr: 0.0010\n",
      "Epoch 606/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9170 - accuracy: 0.57 - ETA: 0s - loss: 0.8912 - accuracy: 0.59 - ETA: 0s - loss: 0.9050 - accuracy: 0.58 - ETA: 0s - loss: 0.8739 - accuracy: 0.60 - ETA: 0s - loss: 0.8721 - accuracy: 0.61 - ETA: 0s - loss: 0.8634 - accuracy: 0.62 - ETA: 0s - loss: 0.8632 - accuracy: 0.62 - ETA: 0s - loss: 0.8642 - accuracy: 0.62 - ETA: 0s - loss: 0.8676 - accuracy: 0.61 - ETA: 0s - loss: 0.8645 - accuracy: 0.62 - ETA: 0s - loss: 0.8581 - accuracy: 0.63 - ETA: 0s - loss: 0.8403 - accuracy: 0.64 - ETA: 0s - loss: 0.8474 - accuracy: 0.63 - ETA: 0s - loss: 0.8587 - accuracy: 0.62 - ETA: 0s - loss: 0.8608 - accuracy: 0.62 - ETA: 0s - loss: 0.8666 - accuracy: 0.61 - ETA: 0s - loss: 0.8689 - accuracy: 0.61 - ETA: 0s - loss: 0.8705 - accuracy: 0.6185\n",
      "Epoch 00606: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8705 - accuracy: 0.6185 - val_loss: 1.0496 - val_accuracy: 0.4943 - lr: 0.0010\n",
      "Epoch 607/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9032 - accuracy: 0.56 - ETA: 0s - loss: 0.8801 - accuracy: 0.58 - ETA: 0s - loss: 0.8908 - accuracy: 0.58 - ETA: 0s - loss: 0.8629 - accuracy: 0.61 - ETA: 0s - loss: 0.8631 - accuracy: 0.61 - ETA: 0s - loss: 0.8561 - accuracy: 0.62 - ETA: 0s - loss: 0.8552 - accuracy: 0.62 - ETA: 0s - loss: 0.8575 - accuracy: 0.62 - ETA: 0s - loss: 0.8600 - accuracy: 0.62 - ETA: 0s - loss: 0.8650 - accuracy: 0.61 - ETA: 0s - loss: 0.8614 - accuracy: 0.62 - ETA: 0s - loss: 0.8549 - accuracy: 0.63 - ETA: 0s - loss: 0.8370 - accuracy: 0.64 - ETA: 0s - loss: 0.8446 - accuracy: 0.63 - ETA: 0s - loss: 0.8560 - accuracy: 0.62 - ETA: 0s - loss: 0.8588 - accuracy: 0.62 - ETA: 0s - loss: 0.8645 - accuracy: 0.61 - ETA: 0s - loss: 0.8662 - accuracy: 0.61 - ETA: 0s - loss: 0.8668 - accuracy: 0.6188\n",
      "Epoch 00607: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8668 - accuracy: 0.6188 - val_loss: 1.0459 - val_accuracy: 0.4979 - lr: 0.0010\n",
      "Epoch 608/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9132 - accuracy: 0.55 - ETA: 0s - loss: 0.8892 - accuracy: 0.58 - ETA: 0s - loss: 0.8937 - accuracy: 0.58 - ETA: 0s - loss: 0.8655 - accuracy: 0.60 - ETA: 0s - loss: 0.8668 - accuracy: 0.61 - ETA: 0s - loss: 0.8584 - accuracy: 0.62 - ETA: 0s - loss: 0.8563 - accuracy: 0.62 - ETA: 0s - loss: 0.8562 - accuracy: 0.62 - ETA: 0s - loss: 0.8568 - accuracy: 0.62 - ETA: 0s - loss: 0.8645 - accuracy: 0.61 - ETA: 0s - loss: 0.8604 - accuracy: 0.62 - ETA: 0s - loss: 0.8542 - accuracy: 0.62 - ETA: 0s - loss: 0.8365 - accuracy: 0.64 - ETA: 0s - loss: 0.8432 - accuracy: 0.63 - ETA: 0s - loss: 0.8553 - accuracy: 0.62 - ETA: 0s - loss: 0.8643 - accuracy: 0.61 - ETA: 0s - loss: 0.8664 - accuracy: 0.61 - ETA: 0s - loss: 0.8686 - accuracy: 0.6178\n",
      "Epoch 00608: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8686 - accuracy: 0.6178 - val_loss: 1.0533 - val_accuracy: 0.4961 - lr: 0.0010\n",
      "Epoch 609/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9036 - accuracy: 0.56 - ETA: 0s - loss: 0.8916 - accuracy: 0.58 - ETA: 0s - loss: 0.9005 - accuracy: 0.58 - ETA: 0s - loss: 0.8707 - accuracy: 0.60 - ETA: 0s - loss: 0.8711 - accuracy: 0.61 - ETA: 0s - loss: 0.8620 - accuracy: 0.62 - ETA: 0s - loss: 0.8588 - accuracy: 0.62 - ETA: 0s - loss: 0.8573 - accuracy: 0.62 - ETA: 0s - loss: 0.8609 - accuracy: 0.62 - ETA: 0s - loss: 0.8660 - accuracy: 0.61 - ETA: 0s - loss: 0.8616 - accuracy: 0.62 - ETA: 0s - loss: 0.8551 - accuracy: 0.63 - ETA: 0s - loss: 0.8437 - accuracy: 0.64 - ETA: 0s - loss: 0.8552 - accuracy: 0.62 - ETA: 0s - loss: 0.8586 - accuracy: 0.62 - ETA: 0s - loss: 0.8641 - accuracy: 0.62 - ETA: 0s - loss: 0.8660 - accuracy: 0.62 - ETA: 0s - loss: 0.8673 - accuracy: 0.6192\n",
      "Epoch 00609: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8673 - accuracy: 0.6192 - val_loss: 1.0519 - val_accuracy: 0.4941 - lr: 0.0010\n",
      "Epoch 610/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8987 - accuracy: 0.55 - ETA: 0s - loss: 0.8809 - accuracy: 0.58 - ETA: 0s - loss: 0.8912 - accuracy: 0.58 - ETA: 0s - loss: 0.8643 - accuracy: 0.60 - ETA: 0s - loss: 0.8653 - accuracy: 0.60 - ETA: 0s - loss: 0.8580 - accuracy: 0.61 - ETA: 0s - loss: 0.8553 - accuracy: 0.62 - ETA: 0s - loss: 0.8559 - accuracy: 0.62 - ETA: 0s - loss: 0.8578 - accuracy: 0.62 - ETA: 0s - loss: 0.8623 - accuracy: 0.61 - ETA: 0s - loss: 0.8586 - accuracy: 0.62 - ETA: 0s - loss: 0.8523 - accuracy: 0.63 - ETA: 0s - loss: 0.8340 - accuracy: 0.64 - ETA: 0s - loss: 0.8401 - accuracy: 0.64 - ETA: 0s - loss: 0.8529 - accuracy: 0.62 - ETA: 0s - loss: 0.8560 - accuracy: 0.62 - ETA: 0s - loss: 0.8621 - accuracy: 0.62 - ETA: 0s - loss: 0.8640 - accuracy: 0.62 - ETA: 0s - loss: 0.8653 - accuracy: 0.6205\n",
      "Epoch 00610: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8653 - accuracy: 0.6205 - val_loss: 1.0575 - val_accuracy: 0.4940 - lr: 0.0010\n",
      "Epoch 611/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9160 - accuracy: 0.54 - ETA: 0s - loss: 0.8952 - accuracy: 0.57 - ETA: 0s - loss: 0.9061 - accuracy: 0.58 - ETA: 0s - loss: 0.8750 - accuracy: 0.60 - ETA: 0s - loss: 0.8737 - accuracy: 0.61 - ETA: 0s - loss: 0.8642 - accuracy: 0.62 - ETA: 0s - loss: 0.8607 - accuracy: 0.62 - ETA: 0s - loss: 0.8594 - accuracy: 0.62 - ETA: 0s - loss: 0.8614 - accuracy: 0.62 - ETA: 0s - loss: 0.8677 - accuracy: 0.61 - ETA: 0s - loss: 0.8622 - accuracy: 0.62 - ETA: 0s - loss: 0.8565 - accuracy: 0.63 - ETA: 0s - loss: 0.8384 - accuracy: 0.64 - ETA: 0s - loss: 0.8445 - accuracy: 0.64 - ETA: 0s - loss: 0.8568 - accuracy: 0.62 - ETA: 0s - loss: 0.8602 - accuracy: 0.62 - ETA: 0s - loss: 0.8650 - accuracy: 0.62 - ETA: 0s - loss: 0.8670 - accuracy: 0.62 - ETA: 0s - loss: 0.8687 - accuracy: 0.6212\n",
      "Epoch 00611: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8687 - accuracy: 0.6212 - val_loss: 1.0567 - val_accuracy: 0.4922 - lr: 0.0010\n",
      "Epoch 612/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9048 - accuracy: 0.58 - ETA: 0s - loss: 0.8794 - accuracy: 0.59 - ETA: 0s - loss: 0.8930 - accuracy: 0.58 - ETA: 0s - loss: 0.8669 - accuracy: 0.60 - ETA: 0s - loss: 0.8683 - accuracy: 0.61 - ETA: 0s - loss: 0.8607 - accuracy: 0.62 - ETA: 0s - loss: 0.8582 - accuracy: 0.62 - ETA: 0s - loss: 0.8571 - accuracy: 0.62 - ETA: 0s - loss: 0.8593 - accuracy: 0.62 - ETA: 0s - loss: 0.8679 - accuracy: 0.61 - ETA: 0s - loss: 0.8620 - accuracy: 0.62 - ETA: 0s - loss: 0.8560 - accuracy: 0.62 - ETA: 0s - loss: 0.8381 - accuracy: 0.64 - ETA: 0s - loss: 0.8453 - accuracy: 0.63 - ETA: 0s - loss: 0.8613 - accuracy: 0.62 - ETA: 0s - loss: 0.8680 - accuracy: 0.61 - ETA: 0s - loss: 0.8700 - accuracy: 0.61 - ETA: 0s - loss: 0.8713 - accuracy: 0.6162\n",
      "Epoch 00612: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8713 - accuracy: 0.6162 - val_loss: 1.0567 - val_accuracy: 0.4940 - lr: 0.0010\n",
      "Epoch 613/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9114 - accuracy: 0.53 - ETA: 0s - loss: 0.8815 - accuracy: 0.57 - ETA: 0s - loss: 0.8985 - accuracy: 0.57 - ETA: 0s - loss: 0.8666 - accuracy: 0.60 - ETA: 0s - loss: 0.8655 - accuracy: 0.60 - ETA: 0s - loss: 0.8584 - accuracy: 0.62 - ETA: 0s - loss: 0.8566 - accuracy: 0.62 - ETA: 0s - loss: 0.8562 - accuracy: 0.62 - ETA: 0s - loss: 0.8567 - accuracy: 0.62 - ETA: 0s - loss: 0.8618 - accuracy: 0.61 - ETA: 0s - loss: 0.8572 - accuracy: 0.62 - ETA: 0s - loss: 0.8524 - accuracy: 0.63 - ETA: 0s - loss: 0.8343 - accuracy: 0.64 - ETA: 0s - loss: 0.8408 - accuracy: 0.64 - ETA: 0s - loss: 0.8546 - accuracy: 0.62 - ETA: 0s - loss: 0.8574 - accuracy: 0.62 - ETA: 0s - loss: 0.8629 - accuracy: 0.62 - ETA: 0s - loss: 0.8661 - accuracy: 0.62 - ETA: 0s - loss: 0.8669 - accuracy: 0.6198\n",
      "Epoch 00613: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00613: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8669 - accuracy: 0.6198 - val_loss: 1.0587 - val_accuracy: 0.4925 - lr: 0.0010\n",
      "Epoch 614/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9246 - accuracy: 0.53 - ETA: 0s - loss: 0.8944 - accuracy: 0.56 - ETA: 0s - loss: 0.9019 - accuracy: 0.57 - ETA: 0s - loss: 0.8704 - accuracy: 0.60 - ETA: 0s - loss: 0.8692 - accuracy: 0.60 - ETA: 0s - loss: 0.8600 - accuracy: 0.61 - ETA: 0s - loss: 0.8583 - accuracy: 0.62 - ETA: 0s - loss: 0.8583 - accuracy: 0.62 - ETA: 0s - loss: 0.8603 - accuracy: 0.62 - ETA: 0s - loss: 0.8657 - accuracy: 0.61 - ETA: 0s - loss: 0.8612 - accuracy: 0.62 - ETA: 0s - loss: 0.8578 - accuracy: 0.62 - ETA: 0s - loss: 0.8393 - accuracy: 0.64 - ETA: 0s - loss: 0.8462 - accuracy: 0.63 - ETA: 0s - loss: 0.8598 - accuracy: 0.62 - ETA: 0s - loss: 0.8624 - accuracy: 0.62 - ETA: 0s - loss: 0.8679 - accuracy: 0.61 - ETA: 0s - loss: 0.8705 - accuracy: 0.6167\n",
      "Epoch 00614: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8705 - accuracy: 0.6167 - val_loss: 1.0688 - val_accuracy: 0.4879 - lr: 0.0010\n",
      "Epoch 615/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9302 - accuracy: 0.54 - ETA: 0s - loss: 0.9034 - accuracy: 0.57 - ETA: 0s - loss: 0.9117 - accuracy: 0.57 - ETA: 0s - loss: 0.8782 - accuracy: 0.60 - ETA: 0s - loss: 0.8766 - accuracy: 0.60 - ETA: 0s - loss: 0.8667 - accuracy: 0.61 - ETA: 0s - loss: 0.8652 - accuracy: 0.62 - ETA: 0s - loss: 0.8651 - accuracy: 0.62 - ETA: 0s - loss: 0.8671 - accuracy: 0.62 - ETA: 0s - loss: 0.8724 - accuracy: 0.61 - ETA: 0s - loss: 0.8666 - accuracy: 0.62 - ETA: 0s - loss: 0.8596 - accuracy: 0.62 - ETA: 0s - loss: 0.8470 - accuracy: 0.63 - ETA: 0s - loss: 0.8611 - accuracy: 0.62 - ETA: 0s - loss: 0.8633 - accuracy: 0.62 - ETA: 0s - loss: 0.8692 - accuracy: 0.61 - ETA: 0s - loss: 0.8706 - accuracy: 0.61 - ETA: 0s - loss: 0.8724 - accuracy: 0.6165\n",
      "Epoch 00615: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8724 - accuracy: 0.6165 - val_loss: 1.0588 - val_accuracy: 0.4892 - lr: 0.0010\n",
      "Epoch 616/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9266 - accuracy: 0.53 - ETA: 0s - loss: 0.8871 - accuracy: 0.57 - ETA: 0s - loss: 0.8985 - accuracy: 0.57 - ETA: 0s - loss: 0.8684 - accuracy: 0.60 - ETA: 0s - loss: 0.8665 - accuracy: 0.60 - ETA: 0s - loss: 0.8585 - accuracy: 0.62 - ETA: 0s - loss: 0.8555 - accuracy: 0.62 - ETA: 0s - loss: 0.8556 - accuracy: 0.62 - ETA: 0s - loss: 0.8587 - accuracy: 0.62 - ETA: 0s - loss: 0.8650 - accuracy: 0.61 - ETA: 0s - loss: 0.8598 - accuracy: 0.62 - ETA: 0s - loss: 0.8533 - accuracy: 0.63 - ETA: 0s - loss: 0.8348 - accuracy: 0.64 - ETA: 0s - loss: 0.8423 - accuracy: 0.64 - ETA: 0s - loss: 0.8547 - accuracy: 0.62 - ETA: 0s - loss: 0.8569 - accuracy: 0.62 - ETA: 0s - loss: 0.8625 - accuracy: 0.62 - ETA: 0s - loss: 0.8654 - accuracy: 0.62 - ETA: 0s - loss: 0.8670 - accuracy: 0.6200\n",
      "Epoch 00616: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8670 - accuracy: 0.6200 - val_loss: 1.0645 - val_accuracy: 0.4928 - lr: 0.0010\n",
      "Epoch 617/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9111 - accuracy: 0.57 - ETA: 0s - loss: 0.8833 - accuracy: 0.60 - ETA: 0s - loss: 0.8996 - accuracy: 0.58 - ETA: 0s - loss: 0.8713 - accuracy: 0.60 - ETA: 0s - loss: 0.8684 - accuracy: 0.61 - ETA: 0s - loss: 0.8617 - accuracy: 0.62 - ETA: 0s - loss: 0.8588 - accuracy: 0.62 - ETA: 0s - loss: 0.8585 - accuracy: 0.62 - ETA: 0s - loss: 0.8616 - accuracy: 0.62 - ETA: 0s - loss: 0.8682 - accuracy: 0.61 - ETA: 0s - loss: 0.8629 - accuracy: 0.62 - ETA: 0s - loss: 0.8571 - accuracy: 0.62 - ETA: 0s - loss: 0.8391 - accuracy: 0.64 - ETA: 0s - loss: 0.8448 - accuracy: 0.63 - ETA: 0s - loss: 0.8562 - accuracy: 0.62 - ETA: 0s - loss: 0.8583 - accuracy: 0.62 - ETA: 0s - loss: 0.8642 - accuracy: 0.61 - ETA: 0s - loss: 0.8662 - accuracy: 0.62 - ETA: 0s - loss: 0.8678 - accuracy: 0.6188\n",
      "Epoch 00617: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8678 - accuracy: 0.6188 - val_loss: 1.0805 - val_accuracy: 0.4842 - lr: 0.0010\n",
      "Epoch 618/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.9009 - accuracy: 0.56 - ETA: 0s - loss: 0.8822 - accuracy: 0.58 - ETA: 0s - loss: 0.8955 - accuracy: 0.57 - ETA: 0s - loss: 0.8636 - accuracy: 0.60 - ETA: 0s - loss: 0.8645 - accuracy: 0.60 - ETA: 0s - loss: 0.8570 - accuracy: 0.62 - ETA: 0s - loss: 0.8532 - accuracy: 0.62 - ETA: 0s - loss: 0.8533 - accuracy: 0.62 - ETA: 0s - loss: 0.8562 - accuracy: 0.62 - ETA: 0s - loss: 0.8620 - accuracy: 0.61 - ETA: 0s - loss: 0.8572 - accuracy: 0.62 - ETA: 0s - loss: 0.8538 - accuracy: 0.62 - ETA: 0s - loss: 0.8359 - accuracy: 0.64 - ETA: 0s - loss: 0.8431 - accuracy: 0.63 - ETA: 0s - loss: 0.8567 - accuracy: 0.62 - ETA: 0s - loss: 0.8594 - accuracy: 0.62 - ETA: 0s - loss: 0.8654 - accuracy: 0.62 - ETA: 0s - loss: 0.8676 - accuracy: 0.6200\n",
      "Epoch 00618: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8692 - accuracy: 0.6183 - val_loss: 1.0749 - val_accuracy: 0.4837 - lr: 0.0010\n",
      "Epoch 619/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9146 - accuracy: 0.55 - ETA: 0s - loss: 0.8887 - accuracy: 0.58 - ETA: 0s - loss: 0.9012 - accuracy: 0.58 - ETA: 0s - loss: 0.8706 - accuracy: 0.60 - ETA: 0s - loss: 0.8705 - accuracy: 0.61 - ETA: 0s - loss: 0.8620 - accuracy: 0.62 - ETA: 0s - loss: 0.8585 - accuracy: 0.62 - ETA: 0s - loss: 0.8599 - accuracy: 0.62 - ETA: 0s - loss: 0.8622 - accuracy: 0.62 - ETA: 0s - loss: 0.8676 - accuracy: 0.61 - ETA: 0s - loss: 0.8633 - accuracy: 0.62 - ETA: 0s - loss: 0.8385 - accuracy: 0.64 - ETA: 0s - loss: 0.8447 - accuracy: 0.64 - ETA: 0s - loss: 0.8580 - accuracy: 0.62 - ETA: 0s - loss: 0.8604 - accuracy: 0.62 - ETA: 0s - loss: 0.8659 - accuracy: 0.62 - ETA: 0s - loss: 0.8674 - accuracy: 0.62 - ETA: 0s - loss: 0.8686 - accuracy: 0.6211\n",
      "Epoch 00619: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8686 - accuracy: 0.6211 - val_loss: 1.0777 - val_accuracy: 0.4809 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 620/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.9101 - accuracy: 0.55 - ETA: 0s - loss: 0.8817 - accuracy: 0.58 - ETA: 0s - loss: 0.9014 - accuracy: 0.57 - ETA: 0s - loss: 0.8708 - accuracy: 0.60 - ETA: 0s - loss: 0.8726 - accuracy: 0.60 - ETA: 0s - loss: 0.8644 - accuracy: 0.61 - ETA: 0s - loss: 0.8612 - accuracy: 0.62 - ETA: 0s - loss: 0.8600 - accuracy: 0.62 - ETA: 0s - loss: 0.8621 - accuracy: 0.62 - ETA: 0s - loss: 0.8670 - accuracy: 0.61 - ETA: 0s - loss: 0.8631 - accuracy: 0.62 - ETA: 0s - loss: 0.8568 - accuracy: 0.62 - ETA: 0s - loss: 0.8387 - accuracy: 0.64 - ETA: 0s - loss: 0.8445 - accuracy: 0.63 - ETA: 0s - loss: 0.8575 - accuracy: 0.62 - ETA: 0s - loss: 0.8613 - accuracy: 0.62 - ETA: 0s - loss: 0.8674 - accuracy: 0.61 - ETA: 0s - loss: 0.8688 - accuracy: 0.6195\n",
      "Epoch 00620: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8700 - accuracy: 0.6180 - val_loss: 1.0859 - val_accuracy: 0.4811 - lr: 0.0010\n",
      "Epoch 621/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9191 - accuracy: 0.53 - ETA: 0s - loss: 0.8967 - accuracy: 0.56 - ETA: 0s - loss: 0.9053 - accuracy: 0.57 - ETA: 0s - loss: 0.8722 - accuracy: 0.60 - ETA: 0s - loss: 0.8709 - accuracy: 0.60 - ETA: 0s - loss: 0.8631 - accuracy: 0.61 - ETA: 0s - loss: 0.8620 - accuracy: 0.62 - ETA: 0s - loss: 0.8609 - accuracy: 0.62 - ETA: 0s - loss: 0.8625 - accuracy: 0.62 - ETA: 0s - loss: 0.8672 - accuracy: 0.61 - ETA: 0s - loss: 0.8627 - accuracy: 0.62 - ETA: 0s - loss: 0.8558 - accuracy: 0.62 - ETA: 0s - loss: 0.8376 - accuracy: 0.64 - ETA: 0s - loss: 0.8446 - accuracy: 0.63 - ETA: 0s - loss: 0.8560 - accuracy: 0.62 - ETA: 0s - loss: 0.8586 - accuracy: 0.62 - ETA: 0s - loss: 0.8640 - accuracy: 0.61 - ETA: 0s - loss: 0.8665 - accuracy: 0.61 - ETA: 0s - loss: 0.8685 - accuracy: 0.6154\n",
      "Epoch 00621: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8685 - accuracy: 0.6154 - val_loss: 1.0839 - val_accuracy: 0.4796 - lr: 0.0010\n",
      "Epoch 622/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9231 - accuracy: 0.55 - ETA: 0s - loss: 0.8850 - accuracy: 0.59 - ETA: 0s - loss: 0.8918 - accuracy: 0.59 - ETA: 0s - loss: 0.8661 - accuracy: 0.61 - ETA: 0s - loss: 0.8650 - accuracy: 0.61 - ETA: 0s - loss: 0.8583 - accuracy: 0.62 - ETA: 0s - loss: 0.8568 - accuracy: 0.62 - ETA: 0s - loss: 0.8564 - accuracy: 0.62 - ETA: 0s - loss: 0.8586 - accuracy: 0.62 - ETA: 0s - loss: 0.8638 - accuracy: 0.61 - ETA: 0s - loss: 0.8578 - accuracy: 0.62 - ETA: 0s - loss: 0.8519 - accuracy: 0.63 - ETA: 0s - loss: 0.8338 - accuracy: 0.64 - ETA: 0s - loss: 0.8409 - accuracy: 0.63 - ETA: 0s - loss: 0.8527 - accuracy: 0.62 - ETA: 0s - loss: 0.8560 - accuracy: 0.62 - ETA: 0s - loss: 0.8617 - accuracy: 0.62 - ETA: 0s - loss: 0.8641 - accuracy: 0.62 - ETA: 0s - loss: 0.8658 - accuracy: 0.6198\n",
      "Epoch 00622: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8658 - accuracy: 0.6198 - val_loss: 1.0760 - val_accuracy: 0.4862 - lr: 0.0010\n",
      "Epoch 623/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9055 - accuracy: 0.56 - ETA: 0s - loss: 0.8798 - accuracy: 0.59 - ETA: 0s - loss: 0.8935 - accuracy: 0.58 - ETA: 0s - loss: 0.8640 - accuracy: 0.61 - ETA: 0s - loss: 0.8623 - accuracy: 0.61 - ETA: 0s - loss: 0.8569 - accuracy: 0.62 - ETA: 0s - loss: 0.8553 - accuracy: 0.62 - ETA: 0s - loss: 0.8546 - accuracy: 0.63 - ETA: 0s - loss: 0.8569 - accuracy: 0.62 - ETA: 0s - loss: 0.8630 - accuracy: 0.61 - ETA: 0s - loss: 0.8577 - accuracy: 0.62 - ETA: 0s - loss: 0.8521 - accuracy: 0.63 - ETA: 0s - loss: 0.8341 - accuracy: 0.64 - ETA: 0s - loss: 0.8412 - accuracy: 0.64 - ETA: 0s - loss: 0.8531 - accuracy: 0.62 - ETA: 0s - loss: 0.8561 - accuracy: 0.62 - ETA: 0s - loss: 0.8625 - accuracy: 0.62 - ETA: 0s - loss: 0.8644 - accuracy: 0.62 - ETA: 0s - loss: 0.8665 - accuracy: 0.6210\n",
      "Epoch 00623: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8665 - accuracy: 0.6210 - val_loss: 1.0624 - val_accuracy: 0.4902 - lr: 0.0010\n",
      "Epoch 624/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9151 - accuracy: 0.56 - ETA: 0s - loss: 0.8861 - accuracy: 0.59 - ETA: 0s - loss: 0.9009 - accuracy: 0.58 - ETA: 0s - loss: 0.8731 - accuracy: 0.61 - ETA: 0s - loss: 0.8733 - accuracy: 0.61 - ETA: 0s - loss: 0.8645 - accuracy: 0.62 - ETA: 0s - loss: 0.8607 - accuracy: 0.62 - ETA: 0s - loss: 0.8601 - accuracy: 0.62 - ETA: 0s - loss: 0.8622 - accuracy: 0.62 - ETA: 0s - loss: 0.8682 - accuracy: 0.61 - ETA: 0s - loss: 0.8633 - accuracy: 0.62 - ETA: 0s - loss: 0.8561 - accuracy: 0.62 - ETA: 0s - loss: 0.8377 - accuracy: 0.64 - ETA: 0s - loss: 0.8452 - accuracy: 0.63 - ETA: 0s - loss: 0.8574 - accuracy: 0.62 - ETA: 0s - loss: 0.8607 - accuracy: 0.62 - ETA: 0s - loss: 0.8665 - accuracy: 0.61 - ETA: 0s - loss: 0.8684 - accuracy: 0.61 - ETA: 0s - loss: 0.8698 - accuracy: 0.6184\n",
      "Epoch 00624: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8698 - accuracy: 0.6184 - val_loss: 1.0714 - val_accuracy: 0.4847 - lr: 0.0010\n",
      "Epoch 625/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9099 - accuracy: 0.54 - ETA: 0s - loss: 0.8799 - accuracy: 0.58 - ETA: 0s - loss: 0.8941 - accuracy: 0.58 - ETA: 0s - loss: 0.8654 - accuracy: 0.60 - ETA: 0s - loss: 0.8663 - accuracy: 0.60 - ETA: 0s - loss: 0.8576 - accuracy: 0.62 - ETA: 0s - loss: 0.8553 - accuracy: 0.62 - ETA: 0s - loss: 0.8560 - accuracy: 0.62 - ETA: 0s - loss: 0.8573 - accuracy: 0.62 - ETA: 0s - loss: 0.8633 - accuracy: 0.61 - ETA: 0s - loss: 0.8592 - accuracy: 0.62 - ETA: 0s - loss: 0.8523 - accuracy: 0.63 - ETA: 0s - loss: 0.8337 - accuracy: 0.64 - ETA: 0s - loss: 0.8400 - accuracy: 0.64 - ETA: 0s - loss: 0.8532 - accuracy: 0.62 - ETA: 0s - loss: 0.8562 - accuracy: 0.62 - ETA: 0s - loss: 0.8624 - accuracy: 0.62 - ETA: 0s - loss: 0.8646 - accuracy: 0.62 - ETA: 0s - loss: 0.8662 - accuracy: 0.6202\n",
      "Epoch 00625: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8662 - accuracy: 0.6202 - val_loss: 1.0684 - val_accuracy: 0.4896 - lr: 0.0010\n",
      "Epoch 626/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9104 - accuracy: 0.56 - ETA: 0s - loss: 0.8840 - accuracy: 0.59 - ETA: 0s - loss: 0.8953 - accuracy: 0.59 - ETA: 0s - loss: 0.8660 - accuracy: 0.61 - ETA: 0s - loss: 0.8657 - accuracy: 0.61 - ETA: 0s - loss: 0.8597 - accuracy: 0.62 - ETA: 0s - loss: 0.8570 - accuracy: 0.62 - ETA: 0s - loss: 0.8563 - accuracy: 0.63 - ETA: 0s - loss: 0.8582 - accuracy: 0.62 - ETA: 0s - loss: 0.8627 - accuracy: 0.61 - ETA: 0s - loss: 0.8578 - accuracy: 0.62 - ETA: 0s - loss: 0.8521 - accuracy: 0.63 - ETA: 0s - loss: 0.8335 - accuracy: 0.64 - ETA: 0s - loss: 0.8399 - accuracy: 0.64 - ETA: 0s - loss: 0.8517 - accuracy: 0.62 - ETA: 0s - loss: 0.8548 - accuracy: 0.62 - ETA: 0s - loss: 0.8606 - accuracy: 0.62 - ETA: 0s - loss: 0.8630 - accuracy: 0.62 - ETA: 0s - loss: 0.8646 - accuracy: 0.6195\n",
      "Epoch 00626: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8646 - accuracy: 0.6195 - val_loss: 1.0755 - val_accuracy: 0.4866 - lr: 0.0010\n",
      "Epoch 627/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9095 - accuracy: 0.54 - ETA: 0s - loss: 0.8830 - accuracy: 0.58 - ETA: 0s - loss: 0.9016 - accuracy: 0.58 - ETA: 0s - loss: 0.8716 - accuracy: 0.60 - ETA: 0s - loss: 0.8710 - accuracy: 0.60 - ETA: 0s - loss: 0.8615 - accuracy: 0.62 - ETA: 0s - loss: 0.8575 - accuracy: 0.62 - ETA: 0s - loss: 0.8575 - accuracy: 0.62 - ETA: 0s - loss: 0.8594 - accuracy: 0.62 - ETA: 0s - loss: 0.8636 - accuracy: 0.62 - ETA: 0s - loss: 0.8526 - accuracy: 0.63 - ETA: 0s - loss: 0.8354 - accuracy: 0.64 - ETA: 0s - loss: 0.8397 - accuracy: 0.64 - ETA: 0s - loss: 0.8537 - accuracy: 0.63 - ETA: 0s - loss: 0.8567 - accuracy: 0.62 - ETA: 0s - loss: 0.8619 - accuracy: 0.62 - ETA: 0s - loss: 0.8635 - accuracy: 0.62 - ETA: 0s - loss: 0.8658 - accuracy: 0.6231\n",
      "Epoch 00627: val_loss did not improve from 0.99131\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00627: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8658 - accuracy: 0.6231 - val_loss: 1.0759 - val_accuracy: 0.4855 - lr: 0.0010\n",
      "Epoch 628/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.9176 - accuracy: 0.54 - ETA: 0s - loss: 0.8975 - accuracy: 0.57 - ETA: 0s - loss: 0.9034 - accuracy: 0.57 - ETA: 0s - loss: 0.8708 - accuracy: 0.60 - ETA: 0s - loss: 0.8725 - accuracy: 0.60 - ETA: 0s - loss: 0.8637 - accuracy: 0.62 - ETA: 0s - loss: 0.8599 - accuracy: 0.62 - ETA: 0s - loss: 0.8596 - accuracy: 0.62 - ETA: 0s - loss: 0.8608 - accuracy: 0.62 - ETA: 0s - loss: 0.8651 - accuracy: 0.61 - ETA: 0s - loss: 0.8604 - accuracy: 0.62 - ETA: 0s - loss: 0.8547 - accuracy: 0.63 - ETA: 0s - loss: 0.8366 - accuracy: 0.64 - ETA: 0s - loss: 0.8439 - accuracy: 0.64 - ETA: 0s - loss: 0.8571 - accuracy: 0.62 - ETA: 0s - loss: 0.8592 - accuracy: 0.62 - ETA: 0s - loss: 0.8648 - accuracy: 0.62 - ETA: 0s - loss: 0.8668 - accuracy: 0.6221\n",
      "Epoch 00628: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8680 - accuracy: 0.6214 - val_loss: 1.0681 - val_accuracy: 0.4852 - lr: 0.0010\n",
      "Epoch 629/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9211 - accuracy: 0.54 - ETA: 0s - loss: 0.8907 - accuracy: 0.57 - ETA: 0s - loss: 0.9070 - accuracy: 0.57 - ETA: 0s - loss: 0.8766 - accuracy: 0.60 - ETA: 0s - loss: 0.8728 - accuracy: 0.60 - ETA: 0s - loss: 0.8632 - accuracy: 0.62 - ETA: 0s - loss: 0.8606 - accuracy: 0.62 - ETA: 0s - loss: 0.8606 - accuracy: 0.62 - ETA: 0s - loss: 0.8626 - accuracy: 0.62 - ETA: 0s - loss: 0.8680 - accuracy: 0.61 - ETA: 0s - loss: 0.8629 - accuracy: 0.62 - ETA: 0s - loss: 0.8569 - accuracy: 0.63 - ETA: 0s - loss: 0.8393 - accuracy: 0.64 - ETA: 0s - loss: 0.8443 - accuracy: 0.64 - ETA: 0s - loss: 0.8578 - accuracy: 0.62 - ETA: 0s - loss: 0.8606 - accuracy: 0.62 - ETA: 0s - loss: 0.8656 - accuracy: 0.62 - ETA: 0s - loss: 0.8671 - accuracy: 0.62 - ETA: 0s - loss: 0.8686 - accuracy: 0.6198\n",
      "Epoch 00629: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8686 - accuracy: 0.6198 - val_loss: 1.0689 - val_accuracy: 0.4857 - lr: 0.0010\n",
      "Epoch 630/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9253 - accuracy: 0.54 - ETA: 0s - loss: 0.8904 - accuracy: 0.57 - ETA: 0s - loss: 0.8981 - accuracy: 0.57 - ETA: 0s - loss: 0.8691 - accuracy: 0.60 - ETA: 0s - loss: 0.8680 - accuracy: 0.60 - ETA: 0s - loss: 0.8598 - accuracy: 0.62 - ETA: 0s - loss: 0.8557 - accuracy: 0.62 - ETA: 0s - loss: 0.8556 - accuracy: 0.62 - ETA: 0s - loss: 0.8587 - accuracy: 0.62 - ETA: 0s - loss: 0.8643 - accuracy: 0.61 - ETA: 0s - loss: 0.8585 - accuracy: 0.62 - ETA: 0s - loss: 0.8525 - accuracy: 0.63 - ETA: 0s - loss: 0.8341 - accuracy: 0.64 - ETA: 0s - loss: 0.8392 - accuracy: 0.64 - ETA: 0s - loss: 0.8529 - accuracy: 0.63 - ETA: 0s - loss: 0.8563 - accuracy: 0.62 - ETA: 0s - loss: 0.8622 - accuracy: 0.62 - ETA: 0s - loss: 0.8645 - accuracy: 0.62 - ETA: 0s - loss: 0.8657 - accuracy: 0.6214\n",
      "Epoch 00630: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8657 - accuracy: 0.6214 - val_loss: 1.0492 - val_accuracy: 0.4919 - lr: 0.0010\n",
      "Epoch 631/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9087 - accuracy: 0.55 - ETA: 0s - loss: 0.8805 - accuracy: 0.58 - ETA: 0s - loss: 0.8942 - accuracy: 0.58 - ETA: 0s - loss: 0.8645 - accuracy: 0.60 - ETA: 0s - loss: 0.8640 - accuracy: 0.61 - ETA: 0s - loss: 0.8561 - accuracy: 0.62 - ETA: 0s - loss: 0.8553 - accuracy: 0.62 - ETA: 0s - loss: 0.8547 - accuracy: 0.62 - ETA: 0s - loss: 0.8575 - accuracy: 0.62 - ETA: 0s - loss: 0.8642 - accuracy: 0.61 - ETA: 0s - loss: 0.8596 - accuracy: 0.62 - ETA: 0s - loss: 0.8552 - accuracy: 0.62 - ETA: 0s - loss: 0.8372 - accuracy: 0.64 - ETA: 0s - loss: 0.8440 - accuracy: 0.63 - ETA: 0s - loss: 0.8566 - accuracy: 0.62 - ETA: 0s - loss: 0.8591 - accuracy: 0.62 - ETA: 0s - loss: 0.8655 - accuracy: 0.61 - ETA: 0s - loss: 0.8672 - accuracy: 0.61 - ETA: 0s - loss: 0.8677 - accuracy: 0.6187\n",
      "Epoch 00631: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8677 - accuracy: 0.6187 - val_loss: 1.0511 - val_accuracy: 0.4966 - lr: 0.0010\n",
      "Epoch 632/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9057 - accuracy: 0.55 - ETA: 0s - loss: 0.8843 - accuracy: 0.58 - ETA: 0s - loss: 0.8951 - accuracy: 0.58 - ETA: 0s - loss: 0.8663 - accuracy: 0.60 - ETA: 0s - loss: 0.8650 - accuracy: 0.60 - ETA: 0s - loss: 0.8564 - accuracy: 0.62 - ETA: 0s - loss: 0.8535 - accuracy: 0.62 - ETA: 0s - loss: 0.8540 - accuracy: 0.62 - ETA: 0s - loss: 0.8557 - accuracy: 0.62 - ETA: 0s - loss: 0.8628 - accuracy: 0.61 - ETA: 0s - loss: 0.8585 - accuracy: 0.62 - ETA: 0s - loss: 0.8530 - accuracy: 0.63 - ETA: 0s - loss: 0.8354 - accuracy: 0.64 - ETA: 0s - loss: 0.8418 - accuracy: 0.63 - ETA: 0s - loss: 0.8555 - accuracy: 0.62 - ETA: 0s - loss: 0.8585 - accuracy: 0.62 - ETA: 0s - loss: 0.8640 - accuracy: 0.62 - ETA: 0s - loss: 0.8654 - accuracy: 0.62 - ETA: 0s - loss: 0.8668 - accuracy: 0.6181\n",
      "Epoch 00632: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8668 - accuracy: 0.6181 - val_loss: 1.0572 - val_accuracy: 0.4936 - lr: 0.0010\n",
      "Epoch 633/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8940 - accuracy: 0.56 - ETA: 0s - loss: 0.8785 - accuracy: 0.58 - ETA: 0s - loss: 0.8905 - accuracy: 0.58 - ETA: 0s - loss: 0.8630 - accuracy: 0.60 - ETA: 0s - loss: 0.8609 - accuracy: 0.60 - ETA: 0s - loss: 0.8562 - accuracy: 0.62 - ETA: 0s - loss: 0.8550 - accuracy: 0.62 - ETA: 0s - loss: 0.8550 - accuracy: 0.62 - ETA: 0s - loss: 0.8576 - accuracy: 0.62 - ETA: 0s - loss: 0.8617 - accuracy: 0.61 - ETA: 0s - loss: 0.8567 - accuracy: 0.62 - ETA: 0s - loss: 0.8496 - accuracy: 0.63 - ETA: 0s - loss: 0.8310 - accuracy: 0.64 - ETA: 0s - loss: 0.8370 - accuracy: 0.64 - ETA: 0s - loss: 0.8496 - accuracy: 0.63 - ETA: 0s - loss: 0.8525 - accuracy: 0.62 - ETA: 0s - loss: 0.8587 - accuracy: 0.62 - ETA: 0s - loss: 0.8614 - accuracy: 0.62 - ETA: 0s - loss: 0.8627 - accuracy: 0.6230\n",
      "Epoch 00633: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8627 - accuracy: 0.6230 - val_loss: 1.0512 - val_accuracy: 0.4959 - lr: 0.0010\n",
      "Epoch 634/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.9162 - accuracy: 0.53 - ETA: 0s - loss: 0.8929 - accuracy: 0.56 - ETA: 0s - loss: 0.9023 - accuracy: 0.56 - ETA: 0s - loss: 0.8741 - accuracy: 0.59 - ETA: 0s - loss: 0.8726 - accuracy: 0.60 - ETA: 0s - loss: 0.8639 - accuracy: 0.61 - ETA: 0s - loss: 0.8612 - accuracy: 0.61 - ETA: 0s - loss: 0.8603 - accuracy: 0.62 - ETA: 0s - loss: 0.8629 - accuracy: 0.61 - ETA: 0s - loss: 0.8683 - accuracy: 0.61 - ETA: 0s - loss: 0.8634 - accuracy: 0.62 - ETA: 0s - loss: 0.8568 - accuracy: 0.62 - ETA: 0s - loss: 0.8383 - accuracy: 0.64 - ETA: 0s - loss: 0.8436 - accuracy: 0.63 - ETA: 0s - loss: 0.8554 - accuracy: 0.62 - ETA: 0s - loss: 0.8587 - accuracy: 0.62 - ETA: 0s - loss: 0.8652 - accuracy: 0.61 - ETA: 0s - loss: 0.8669 - accuracy: 0.6202\n",
      "Epoch 00634: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8681 - accuracy: 0.6194 - val_loss: 1.0427 - val_accuracy: 0.5023 - lr: 0.0010\n",
      "Epoch 635/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9237 - accuracy: 0.55 - ETA: 0s - loss: 0.8908 - accuracy: 0.58 - ETA: 0s - loss: 0.8986 - accuracy: 0.58 - ETA: 0s - loss: 0.8667 - accuracy: 0.60 - ETA: 0s - loss: 0.8652 - accuracy: 0.61 - ETA: 0s - loss: 0.8575 - accuracy: 0.62 - ETA: 0s - loss: 0.8535 - accuracy: 0.62 - ETA: 0s - loss: 0.8544 - accuracy: 0.62 - ETA: 0s - loss: 0.8568 - accuracy: 0.62 - ETA: 0s - loss: 0.8632 - accuracy: 0.61 - ETA: 0s - loss: 0.8578 - accuracy: 0.62 - ETA: 0s - loss: 0.8507 - accuracy: 0.63 - ETA: 0s - loss: 0.8329 - accuracy: 0.64 - ETA: 0s - loss: 0.8401 - accuracy: 0.63 - ETA: 0s - loss: 0.8530 - accuracy: 0.62 - ETA: 0s - loss: 0.8553 - accuracy: 0.62 - ETA: 0s - loss: 0.8606 - accuracy: 0.62 - ETA: 0s - loss: 0.8626 - accuracy: 0.62 - ETA: 0s - loss: 0.8642 - accuracy: 0.6193\n",
      "Epoch 00635: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8642 - accuracy: 0.6193 - val_loss: 1.0490 - val_accuracy: 0.4980 - lr: 0.0010\n",
      "Epoch 636/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9478 - accuracy: 0.53 - ETA: 0s - loss: 0.9035 - accuracy: 0.57 - ETA: 0s - loss: 0.9083 - accuracy: 0.57 - ETA: 0s - loss: 0.8736 - accuracy: 0.60 - ETA: 0s - loss: 0.8692 - accuracy: 0.60 - ETA: 0s - loss: 0.8612 - accuracy: 0.62 - ETA: 0s - loss: 0.8578 - accuracy: 0.62 - ETA: 0s - loss: 0.8564 - accuracy: 0.62 - ETA: 0s - loss: 0.8664 - accuracy: 0.61 - ETA: 0s - loss: 0.8608 - accuracy: 0.62 - ETA: 0s - loss: 0.8551 - accuracy: 0.62 - ETA: 0s - loss: 0.8373 - accuracy: 0.64 - ETA: 0s - loss: 0.8425 - accuracy: 0.63 - ETA: 0s - loss: 0.8566 - accuracy: 0.62 - ETA: 0s - loss: 0.8594 - accuracy: 0.62 - ETA: 0s - loss: 0.8656 - accuracy: 0.61 - ETA: 0s - loss: 0.8676 - accuracy: 0.61 - ETA: 0s - loss: 0.8688 - accuracy: 0.6165\n",
      "Epoch 00636: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8688 - accuracy: 0.6165 - val_loss: 1.0511 - val_accuracy: 0.4984 - lr: 0.0010\n",
      "Epoch 637/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9033 - accuracy: 0.56 - ETA: 0s - loss: 0.8777 - accuracy: 0.59 - ETA: 0s - loss: 0.8924 - accuracy: 0.58 - ETA: 0s - loss: 0.8619 - accuracy: 0.61 - ETA: 0s - loss: 0.8660 - accuracy: 0.61 - ETA: 0s - loss: 0.8574 - accuracy: 0.62 - ETA: 0s - loss: 0.8547 - accuracy: 0.62 - ETA: 0s - loss: 0.8543 - accuracy: 0.63 - ETA: 0s - loss: 0.8568 - accuracy: 0.62 - ETA: 0s - loss: 0.8622 - accuracy: 0.62 - ETA: 0s - loss: 0.8573 - accuracy: 0.62 - ETA: 0s - loss: 0.8505 - accuracy: 0.63 - ETA: 0s - loss: 0.8327 - accuracy: 0.64 - ETA: 0s - loss: 0.8392 - accuracy: 0.64 - ETA: 0s - loss: 0.8526 - accuracy: 0.63 - ETA: 0s - loss: 0.8555 - accuracy: 0.62 - ETA: 0s - loss: 0.8613 - accuracy: 0.62 - ETA: 0s - loss: 0.8630 - accuracy: 0.62 - ETA: 0s - loss: 0.8642 - accuracy: 0.6222\n",
      "Epoch 00637: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8642 - accuracy: 0.6222 - val_loss: 1.0554 - val_accuracy: 0.4953 - lr: 0.0010\n",
      "Epoch 638/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9232 - accuracy: 0.52 - ETA: 0s - loss: 0.8970 - accuracy: 0.56 - ETA: 0s - loss: 0.9031 - accuracy: 0.57 - ETA: 0s - loss: 0.8713 - accuracy: 0.59 - ETA: 0s - loss: 0.8677 - accuracy: 0.60 - ETA: 0s - loss: 0.8588 - accuracy: 0.61 - ETA: 0s - loss: 0.8559 - accuracy: 0.62 - ETA: 0s - loss: 0.8549 - accuracy: 0.62 - ETA: 0s - loss: 0.8565 - accuracy: 0.62 - ETA: 0s - loss: 0.8619 - accuracy: 0.61 - ETA: 0s - loss: 0.8581 - accuracy: 0.62 - ETA: 0s - loss: 0.8523 - accuracy: 0.62 - ETA: 0s - loss: 0.8334 - accuracy: 0.64 - ETA: 0s - loss: 0.8400 - accuracy: 0.64 - ETA: 0s - loss: 0.8516 - accuracy: 0.62 - ETA: 0s - loss: 0.8552 - accuracy: 0.62 - ETA: 0s - loss: 0.8630 - accuracy: 0.62 - ETA: 0s - loss: 0.8647 - accuracy: 0.6200\n",
      "Epoch 00638: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8647 - accuracy: 0.6200 - val_loss: 1.0732 - val_accuracy: 0.4860 - lr: 0.0010\n",
      "Epoch 639/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9014 - accuracy: 0.56 - ETA: 0s - loss: 0.8742 - accuracy: 0.60 - ETA: 0s - loss: 0.8868 - accuracy: 0.59 - ETA: 0s - loss: 0.8580 - accuracy: 0.61 - ETA: 0s - loss: 0.8613 - accuracy: 0.61 - ETA: 0s - loss: 0.8532 - accuracy: 0.62 - ETA: 0s - loss: 0.8514 - accuracy: 0.63 - ETA: 0s - loss: 0.8520 - accuracy: 0.63 - ETA: 0s - loss: 0.8538 - accuracy: 0.62 - ETA: 0s - loss: 0.8591 - accuracy: 0.62 - ETA: 0s - loss: 0.8549 - accuracy: 0.63 - ETA: 0s - loss: 0.8484 - accuracy: 0.63 - ETA: 0s - loss: 0.8311 - accuracy: 0.64 - ETA: 0s - loss: 0.8360 - accuracy: 0.64 - ETA: 0s - loss: 0.8489 - accuracy: 0.63 - ETA: 0s - loss: 0.8520 - accuracy: 0.63 - ETA: 0s - loss: 0.8578 - accuracy: 0.62 - ETA: 0s - loss: 0.8602 - accuracy: 0.62 - ETA: 0s - loss: 0.8620 - accuracy: 0.6247\n",
      "Epoch 00639: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8620 - accuracy: 0.6247 - val_loss: 1.0648 - val_accuracy: 0.4904 - lr: 0.0010\n",
      "Epoch 640/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9263 - accuracy: 0.52 - ETA: 0s - loss: 0.8947 - accuracy: 0.56 - ETA: 0s - loss: 0.8994 - accuracy: 0.57 - ETA: 0s - loss: 0.8701 - accuracy: 0.59 - ETA: 0s - loss: 0.8719 - accuracy: 0.60 - ETA: 0s - loss: 0.8626 - accuracy: 0.61 - ETA: 0s - loss: 0.8600 - accuracy: 0.62 - ETA: 0s - loss: 0.8584 - accuracy: 0.62 - ETA: 0s - loss: 0.8595 - accuracy: 0.62 - ETA: 0s - loss: 0.8643 - accuracy: 0.61 - ETA: 0s - loss: 0.8586 - accuracy: 0.62 - ETA: 0s - loss: 0.8521 - accuracy: 0.63 - ETA: 0s - loss: 0.8343 - accuracy: 0.64 - ETA: 0s - loss: 0.8384 - accuracy: 0.64 - ETA: 0s - loss: 0.8516 - accuracy: 0.62 - ETA: 0s - loss: 0.8602 - accuracy: 0.62 - ETA: 0s - loss: 0.8622 - accuracy: 0.62 - ETA: 0s - loss: 0.8645 - accuracy: 0.6199\n",
      "Epoch 00640: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8645 - accuracy: 0.6199 - val_loss: 1.0586 - val_accuracy: 0.4954 - lr: 0.0010\n",
      "Epoch 641/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9199 - accuracy: 0.54 - ETA: 0s - loss: 0.8914 - accuracy: 0.57 - ETA: 0s - loss: 0.9016 - accuracy: 0.57 - ETA: 0s - loss: 0.8697 - accuracy: 0.60 - ETA: 0s - loss: 0.8708 - accuracy: 0.60 - ETA: 0s - loss: 0.8598 - accuracy: 0.61 - ETA: 0s - loss: 0.8564 - accuracy: 0.62 - ETA: 0s - loss: 0.8554 - accuracy: 0.62 - ETA: 0s - loss: 0.8566 - accuracy: 0.62 - ETA: 0s - loss: 0.8618 - accuracy: 0.62 - ETA: 0s - loss: 0.8567 - accuracy: 0.62 - ETA: 0s - loss: 0.8517 - accuracy: 0.63 - ETA: 0s - loss: 0.8338 - accuracy: 0.64 - ETA: 0s - loss: 0.8406 - accuracy: 0.64 - ETA: 0s - loss: 0.8569 - accuracy: 0.62 - ETA: 0s - loss: 0.8623 - accuracy: 0.62 - ETA: 0s - loss: 0.8645 - accuracy: 0.62 - ETA: 0s - loss: 0.8658 - accuracy: 0.6203\n",
      "Epoch 00641: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00641: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8658 - accuracy: 0.6203 - val_loss: 1.0530 - val_accuracy: 0.4967 - lr: 0.0010\n",
      "Epoch 642/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9242 - accuracy: 0.55 - ETA: 0s - loss: 0.8852 - accuracy: 0.58 - ETA: 0s - loss: 0.8958 - accuracy: 0.58 - ETA: 0s - loss: 0.8637 - accuracy: 0.61 - ETA: 0s - loss: 0.8660 - accuracy: 0.61 - ETA: 0s - loss: 0.8593 - accuracy: 0.62 - ETA: 0s - loss: 0.8569 - accuracy: 0.62 - ETA: 0s - loss: 0.8564 - accuracy: 0.63 - ETA: 0s - loss: 0.8600 - accuracy: 0.62 - ETA: 0s - loss: 0.8596 - accuracy: 0.62 - ETA: 0s - loss: 0.8522 - accuracy: 0.63 - ETA: 0s - loss: 0.8336 - accuracy: 0.64 - ETA: 0s - loss: 0.8404 - accuracy: 0.64 - ETA: 0s - loss: 0.8514 - accuracy: 0.62 - ETA: 0s - loss: 0.8541 - accuracy: 0.62 - ETA: 0s - loss: 0.8600 - accuracy: 0.62 - ETA: 0s - loss: 0.8617 - accuracy: 0.62 - ETA: 0s - loss: 0.8636 - accuracy: 0.6213\n",
      "Epoch 00642: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8636 - accuracy: 0.6213 - val_loss: 1.0550 - val_accuracy: 0.4972 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 643/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9243 - accuracy: 0.55 - ETA: 0s - loss: 0.8818 - accuracy: 0.58 - ETA: 0s - loss: 0.8939 - accuracy: 0.58 - ETA: 0s - loss: 0.8629 - accuracy: 0.60 - ETA: 0s - loss: 0.8632 - accuracy: 0.61 - ETA: 0s - loss: 0.8541 - accuracy: 0.62 - ETA: 0s - loss: 0.8542 - accuracy: 0.62 - ETA: 0s - loss: 0.8539 - accuracy: 0.62 - ETA: 0s - loss: 0.8566 - accuracy: 0.62 - ETA: 0s - loss: 0.8612 - accuracy: 0.61 - ETA: 0s - loss: 0.8576 - accuracy: 0.62 - ETA: 0s - loss: 0.8512 - accuracy: 0.63 - ETA: 0s - loss: 0.8334 - accuracy: 0.64 - ETA: 0s - loss: 0.8390 - accuracy: 0.63 - ETA: 0s - loss: 0.8525 - accuracy: 0.62 - ETA: 0s - loss: 0.8561 - accuracy: 0.62 - ETA: 0s - loss: 0.8620 - accuracy: 0.62 - ETA: 0s - loss: 0.8641 - accuracy: 0.62 - ETA: 0s - loss: 0.8659 - accuracy: 0.6197\n",
      "Epoch 00643: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8659 - accuracy: 0.6197 - val_loss: 1.0610 - val_accuracy: 0.4927 - lr: 0.0010\n",
      "Epoch 644/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.9206 - accuracy: 0.53 - ETA: 0s - loss: 0.8835 - accuracy: 0.58 - ETA: 0s - loss: 0.8944 - accuracy: 0.58 - ETA: 0s - loss: 0.8657 - accuracy: 0.60 - ETA: 0s - loss: 0.8689 - accuracy: 0.61 - ETA: 0s - loss: 0.8609 - accuracy: 0.62 - ETA: 0s - loss: 0.8584 - accuracy: 0.62 - ETA: 0s - loss: 0.8557 - accuracy: 0.62 - ETA: 0s - loss: 0.8568 - accuracy: 0.62 - ETA: 0s - loss: 0.8624 - accuracy: 0.61 - ETA: 0s - loss: 0.8583 - accuracy: 0.62 - ETA: 0s - loss: 0.8507 - accuracy: 0.63 - ETA: 0s - loss: 0.8327 - accuracy: 0.64 - ETA: 0s - loss: 0.8421 - accuracy: 0.63 - ETA: 0s - loss: 0.8571 - accuracy: 0.62 - ETA: 0s - loss: 0.8599 - accuracy: 0.62 - ETA: 0s - loss: 0.8641 - accuracy: 0.61 - ETA: 0s - loss: 0.8658 - accuracy: 0.6190\n",
      "Epoch 00644: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8677 - accuracy: 0.6178 - val_loss: 1.0659 - val_accuracy: 0.4946 - lr: 0.0010\n",
      "Epoch 645/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9226 - accuracy: 0.54 - ETA: 0s - loss: 0.8913 - accuracy: 0.57 - ETA: 0s - loss: 0.8981 - accuracy: 0.57 - ETA: 0s - loss: 0.8682 - accuracy: 0.60 - ETA: 0s - loss: 0.8691 - accuracy: 0.60 - ETA: 0s - loss: 0.8616 - accuracy: 0.61 - ETA: 0s - loss: 0.8592 - accuracy: 0.62 - ETA: 0s - loss: 0.8582 - accuracy: 0.62 - ETA: 0s - loss: 0.8599 - accuracy: 0.62 - ETA: 0s - loss: 0.8643 - accuracy: 0.61 - ETA: 0s - loss: 0.8607 - accuracy: 0.62 - ETA: 0s - loss: 0.8554 - accuracy: 0.62 - ETA: 0s - loss: 0.8373 - accuracy: 0.64 - ETA: 0s - loss: 0.8449 - accuracy: 0.63 - ETA: 0s - loss: 0.8573 - accuracy: 0.62 - ETA: 0s - loss: 0.8599 - accuracy: 0.62 - ETA: 0s - loss: 0.8660 - accuracy: 0.61 - ETA: 0s - loss: 0.8674 - accuracy: 0.61 - ETA: 0s - loss: 0.8690 - accuracy: 0.6187\n",
      "Epoch 00645: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8690 - accuracy: 0.6187 - val_loss: 1.0828 - val_accuracy: 0.4865 - lr: 0.0010\n",
      "Epoch 646/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9108 - accuracy: 0.54 - ETA: 0s - loss: 0.8796 - accuracy: 0.58 - ETA: 0s - loss: 0.8875 - accuracy: 0.59 - ETA: 0s - loss: 0.8583 - accuracy: 0.61 - ETA: 0s - loss: 0.8585 - accuracy: 0.61 - ETA: 0s - loss: 0.8517 - accuracy: 0.62 - ETA: 0s - loss: 0.8514 - accuracy: 0.63 - ETA: 0s - loss: 0.8515 - accuracy: 0.63 - ETA: 0s - loss: 0.8549 - accuracy: 0.63 - ETA: 0s - loss: 0.8623 - accuracy: 0.62 - ETA: 0s - loss: 0.8499 - accuracy: 0.63 - ETA: 0s - loss: 0.8318 - accuracy: 0.65 - ETA: 0s - loss: 0.8381 - accuracy: 0.64 - ETA: 0s - loss: 0.8495 - accuracy: 0.63 - ETA: 0s - loss: 0.8529 - accuracy: 0.63 - ETA: 0s - loss: 0.8583 - accuracy: 0.62 - ETA: 0s - loss: 0.8600 - accuracy: 0.62 - ETA: 0s - loss: 0.8620 - accuracy: 0.6266\n",
      "Epoch 00646: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8620 - accuracy: 0.6266 - val_loss: 1.0842 - val_accuracy: 0.4845 - lr: 0.0010\n",
      "Epoch 647/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9153 - accuracy: 0.54 - ETA: 0s - loss: 0.8872 - accuracy: 0.57 - ETA: 0s - loss: 0.8977 - accuracy: 0.58 - ETA: 0s - loss: 0.8679 - accuracy: 0.60 - ETA: 0s - loss: 0.8666 - accuracy: 0.61 - ETA: 0s - loss: 0.8577 - accuracy: 0.62 - ETA: 0s - loss: 0.8564 - accuracy: 0.62 - ETA: 0s - loss: 0.8558 - accuracy: 0.62 - ETA: 0s - loss: 0.8579 - accuracy: 0.62 - ETA: 0s - loss: 0.8632 - accuracy: 0.61 - ETA: 0s - loss: 0.8588 - accuracy: 0.62 - ETA: 0s - loss: 0.8523 - accuracy: 0.63 - ETA: 0s - loss: 0.8347 - accuracy: 0.64 - ETA: 0s - loss: 0.8412 - accuracy: 0.64 - ETA: 0s - loss: 0.8528 - accuracy: 0.63 - ETA: 0s - loss: 0.8552 - accuracy: 0.62 - ETA: 0s - loss: 0.8613 - accuracy: 0.62 - ETA: 0s - loss: 0.8630 - accuracy: 0.62 - ETA: 0s - loss: 0.8643 - accuracy: 0.6215\n",
      "Epoch 00647: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8643 - accuracy: 0.6215 - val_loss: 1.0666 - val_accuracy: 0.4915 - lr: 0.0010\n",
      "Epoch 648/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9113 - accuracy: 0.55 - ETA: 0s - loss: 0.8834 - accuracy: 0.59 - ETA: 0s - loss: 0.8964 - accuracy: 0.59 - ETA: 0s - loss: 0.8662 - accuracy: 0.61 - ETA: 0s - loss: 0.8653 - accuracy: 0.61 - ETA: 0s - loss: 0.8571 - accuracy: 0.63 - ETA: 0s - loss: 0.8546 - accuracy: 0.63 - ETA: 0s - loss: 0.8541 - accuracy: 0.63 - ETA: 0s - loss: 0.8558 - accuracy: 0.63 - ETA: 0s - loss: 0.8612 - accuracy: 0.62 - ETA: 0s - loss: 0.8564 - accuracy: 0.63 - ETA: 0s - loss: 0.8500 - accuracy: 0.63 - ETA: 0s - loss: 0.8329 - accuracy: 0.65 - ETA: 0s - loss: 0.8387 - accuracy: 0.64 - ETA: 0s - loss: 0.8493 - accuracy: 0.63 - ETA: 0s - loss: 0.8525 - accuracy: 0.63 - ETA: 0s - loss: 0.8589 - accuracy: 0.63 - ETA: 0s - loss: 0.8605 - accuracy: 0.63 - ETA: 0s - loss: 0.8630 - accuracy: 0.6285\n",
      "Epoch 00648: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8630 - accuracy: 0.6285 - val_loss: 1.0692 - val_accuracy: 0.4907 - lr: 0.0010\n",
      "Epoch 649/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9188 - accuracy: 0.53 - ETA: 0s - loss: 0.8879 - accuracy: 0.58 - ETA: 0s - loss: 0.8979 - accuracy: 0.58 - ETA: 0s - loss: 0.8661 - accuracy: 0.60 - ETA: 0s - loss: 0.8667 - accuracy: 0.61 - ETA: 0s - loss: 0.8579 - accuracy: 0.62 - ETA: 0s - loss: 0.8554 - accuracy: 0.62 - ETA: 0s - loss: 0.8543 - accuracy: 0.62 - ETA: 0s - loss: 0.8567 - accuracy: 0.62 - ETA: 0s - loss: 0.8630 - accuracy: 0.62 - ETA: 0s - loss: 0.8592 - accuracy: 0.62 - ETA: 0s - loss: 0.8520 - accuracy: 0.63 - ETA: 0s - loss: 0.8340 - accuracy: 0.64 - ETA: 0s - loss: 0.8389 - accuracy: 0.64 - ETA: 0s - loss: 0.8506 - accuracy: 0.63 - ETA: 0s - loss: 0.8536 - accuracy: 0.63 - ETA: 0s - loss: 0.8598 - accuracy: 0.62 - ETA: 0s - loss: 0.8630 - accuracy: 0.6247\n",
      "Epoch 00649: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8630 - accuracy: 0.6247 - val_loss: 1.0749 - val_accuracy: 0.4894 - lr: 0.0010\n",
      "Epoch 650/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8905 - accuracy: 0.54 - ETA: 0s - loss: 0.8719 - accuracy: 0.57 - ETA: 0s - loss: 0.8638 - accuracy: 0.60 - ETA: 0s - loss: 0.8644 - accuracy: 0.60 - ETA: 0s - loss: 0.8562 - accuracy: 0.62 - ETA: 0s - loss: 0.8543 - accuracy: 0.62 - ETA: 0s - loss: 0.8551 - accuracy: 0.62 - ETA: 0s - loss: 0.8581 - accuracy: 0.62 - ETA: 0s - loss: 0.8631 - accuracy: 0.61 - ETA: 0s - loss: 0.8599 - accuracy: 0.62 - ETA: 0s - loss: 0.8533 - accuracy: 0.63 - ETA: 0s - loss: 0.8352 - accuracy: 0.64 - ETA: 0s - loss: 0.8403 - accuracy: 0.64 - ETA: 0s - loss: 0.8523 - accuracy: 0.63 - ETA: 0s - loss: 0.8543 - accuracy: 0.62 - ETA: 0s - loss: 0.8613 - accuracy: 0.62 - ETA: 0s - loss: 0.8624 - accuracy: 0.62 - ETA: 0s - loss: 0.8643 - accuracy: 0.6231\n",
      "Epoch 00650: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8643 - accuracy: 0.6231 - val_loss: 1.0695 - val_accuracy: 0.4902 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 651/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9038 - accuracy: 0.56 - ETA: 0s - loss: 0.8799 - accuracy: 0.58 - ETA: 0s - loss: 0.8934 - accuracy: 0.58 - ETA: 0s - loss: 0.8640 - accuracy: 0.61 - ETA: 0s - loss: 0.8633 - accuracy: 0.61 - ETA: 0s - loss: 0.8559 - accuracy: 0.62 - ETA: 0s - loss: 0.8545 - accuracy: 0.62 - ETA: 0s - loss: 0.8547 - accuracy: 0.63 - ETA: 0s - loss: 0.8557 - accuracy: 0.63 - ETA: 0s - loss: 0.8595 - accuracy: 0.62 - ETA: 0s - loss: 0.8552 - accuracy: 0.63 - ETA: 0s - loss: 0.8491 - accuracy: 0.63 - ETA: 0s - loss: 0.8313 - accuracy: 0.65 - ETA: 0s - loss: 0.8373 - accuracy: 0.64 - ETA: 0s - loss: 0.8488 - accuracy: 0.63 - ETA: 0s - loss: 0.8516 - accuracy: 0.63 - ETA: 0s - loss: 0.8574 - accuracy: 0.62 - ETA: 0s - loss: 0.8588 - accuracy: 0.62 - ETA: 0s - loss: 0.8603 - accuracy: 0.6250\n",
      "Epoch 00651: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8603 - accuracy: 0.6250 - val_loss: 1.0649 - val_accuracy: 0.4902 - lr: 0.0010\n",
      "Epoch 652/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9148 - accuracy: 0.56 - ETA: 0s - loss: 0.8887 - accuracy: 0.59 - ETA: 0s - loss: 0.8974 - accuracy: 0.59 - ETA: 0s - loss: 0.8667 - accuracy: 0.61 - ETA: 0s - loss: 0.8664 - accuracy: 0.61 - ETA: 0s - loss: 0.8606 - accuracy: 0.62 - ETA: 0s - loss: 0.8579 - accuracy: 0.63 - ETA: 0s - loss: 0.8579 - accuracy: 0.63 - ETA: 0s - loss: 0.8597 - accuracy: 0.62 - ETA: 0s - loss: 0.8660 - accuracy: 0.62 - ETA: 0s - loss: 0.8604 - accuracy: 0.62 - ETA: 0s - loss: 0.8532 - accuracy: 0.63 - ETA: 0s - loss: 0.8347 - accuracy: 0.64 - ETA: 0s - loss: 0.8401 - accuracy: 0.64 - ETA: 0s - loss: 0.8521 - accuracy: 0.63 - ETA: 0s - loss: 0.8543 - accuracy: 0.62 - ETA: 0s - loss: 0.8609 - accuracy: 0.62 - ETA: 0s - loss: 0.8627 - accuracy: 0.62 - ETA: 0s - loss: 0.8644 - accuracy: 0.6239\n",
      "Epoch 00652: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8644 - accuracy: 0.6239 - val_loss: 1.0696 - val_accuracy: 0.4878 - lr: 0.0010\n",
      "Epoch 653/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9052 - accuracy: 0.55 - ETA: 0s - loss: 0.8792 - accuracy: 0.59 - ETA: 0s - loss: 0.8937 - accuracy: 0.58 - ETA: 0s - loss: 0.8643 - accuracy: 0.61 - ETA: 0s - loss: 0.8652 - accuracy: 0.61 - ETA: 0s - loss: 0.8570 - accuracy: 0.62 - ETA: 0s - loss: 0.8531 - accuracy: 0.62 - ETA: 0s - loss: 0.8518 - accuracy: 0.62 - ETA: 0s - loss: 0.8526 - accuracy: 0.62 - ETA: 0s - loss: 0.8598 - accuracy: 0.62 - ETA: 0s - loss: 0.8563 - accuracy: 0.62 - ETA: 0s - loss: 0.8515 - accuracy: 0.63 - ETA: 0s - loss: 0.8339 - accuracy: 0.64 - ETA: 0s - loss: 0.8406 - accuracy: 0.64 - ETA: 0s - loss: 0.8526 - accuracy: 0.63 - ETA: 0s - loss: 0.8554 - accuracy: 0.62 - ETA: 0s - loss: 0.8612 - accuracy: 0.62 - ETA: 0s - loss: 0.8625 - accuracy: 0.62 - ETA: 0s - loss: 0.8631 - accuracy: 0.6230\n",
      "Epoch 00653: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8631 - accuracy: 0.6230 - val_loss: 1.0685 - val_accuracy: 0.4912 - lr: 0.0010\n",
      "Epoch 654/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9215 - accuracy: 0.53 - ETA: 0s - loss: 0.8839 - accuracy: 0.57 - ETA: 0s - loss: 0.8932 - accuracy: 0.58 - ETA: 0s - loss: 0.8663 - accuracy: 0.60 - ETA: 0s - loss: 0.8676 - accuracy: 0.61 - ETA: 0s - loss: 0.8574 - accuracy: 0.62 - ETA: 0s - loss: 0.8546 - accuracy: 0.62 - ETA: 0s - loss: 0.8531 - accuracy: 0.62 - ETA: 0s - loss: 0.8561 - accuracy: 0.62 - ETA: 0s - loss: 0.8614 - accuracy: 0.62 - ETA: 0s - loss: 0.8496 - accuracy: 0.63 - ETA: 0s - loss: 0.8314 - accuracy: 0.65 - ETA: 0s - loss: 0.8379 - accuracy: 0.64 - ETA: 0s - loss: 0.8486 - accuracy: 0.63 - ETA: 0s - loss: 0.8529 - accuracy: 0.63 - ETA: 0s - loss: 0.8587 - accuracy: 0.62 - ETA: 0s - loss: 0.8606 - accuracy: 0.62 - ETA: 0s - loss: 0.8626 - accuracy: 0.6246\n",
      "Epoch 00654: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8626 - accuracy: 0.6246 - val_loss: 1.0588 - val_accuracy: 0.4969 - lr: 0.0010\n",
      "Epoch 655/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9219 - accuracy: 0.54 - ETA: 0s - loss: 0.8921 - accuracy: 0.58 - ETA: 0s - loss: 0.8989 - accuracy: 0.58 - ETA: 0s - loss: 0.8701 - accuracy: 0.60 - ETA: 0s - loss: 0.8690 - accuracy: 0.61 - ETA: 0s - loss: 0.8585 - accuracy: 0.62 - ETA: 0s - loss: 0.8550 - accuracy: 0.62 - ETA: 0s - loss: 0.8527 - accuracy: 0.62 - ETA: 0s - loss: 0.8554 - accuracy: 0.62 - ETA: 0s - loss: 0.8622 - accuracy: 0.61 - ETA: 0s - loss: 0.8577 - accuracy: 0.62 - ETA: 0s - loss: 0.8517 - accuracy: 0.63 - ETA: 0s - loss: 0.8336 - accuracy: 0.64 - ETA: 0s - loss: 0.8405 - accuracy: 0.63 - ETA: 0s - loss: 0.8527 - accuracy: 0.62 - ETA: 0s - loss: 0.8554 - accuracy: 0.62 - ETA: 0s - loss: 0.8613 - accuracy: 0.61 - ETA: 0s - loss: 0.8648 - accuracy: 0.6190\n",
      "Epoch 00655: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00655: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8648 - accuracy: 0.6190 - val_loss: 1.0495 - val_accuracy: 0.5020 - lr: 0.0010\n",
      "Epoch 656/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8817 - accuracy: 0.58 - ETA: 0s - loss: 0.8623 - accuracy: 0.61 - ETA: 0s - loss: 0.8765 - accuracy: 0.60 - ETA: 0s - loss: 0.8560 - accuracy: 0.61 - ETA: 0s - loss: 0.8581 - accuracy: 0.62 - ETA: 0s - loss: 0.8530 - accuracy: 0.63 - ETA: 0s - loss: 0.8513 - accuracy: 0.63 - ETA: 0s - loss: 0.8509 - accuracy: 0.63 - ETA: 0s - loss: 0.8537 - accuracy: 0.63 - ETA: 0s - loss: 0.8582 - accuracy: 0.62 - ETA: 0s - loss: 0.8536 - accuracy: 0.63 - ETA: 0s - loss: 0.8481 - accuracy: 0.63 - ETA: 0s - loss: 0.8303 - accuracy: 0.65 - ETA: 0s - loss: 0.8377 - accuracy: 0.64 - ETA: 0s - loss: 0.8516 - accuracy: 0.63 - ETA: 0s - loss: 0.8546 - accuracy: 0.63 - ETA: 0s - loss: 0.8606 - accuracy: 0.62 - ETA: 0s - loss: 0.8623 - accuracy: 0.62 - ETA: 0s - loss: 0.8638 - accuracy: 0.6246\n",
      "Epoch 00656: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8638 - accuracy: 0.6246 - val_loss: 1.0520 - val_accuracy: 0.5011 - lr: 0.0010\n",
      "Epoch 657/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9286 - accuracy: 0.52 - ETA: 0s - loss: 0.8902 - accuracy: 0.57 - ETA: 0s - loss: 0.8972 - accuracy: 0.57 - ETA: 0s - loss: 0.8679 - accuracy: 0.59 - ETA: 0s - loss: 0.8711 - accuracy: 0.60 - ETA: 0s - loss: 0.8624 - accuracy: 0.61 - ETA: 0s - loss: 0.8579 - accuracy: 0.62 - ETA: 0s - loss: 0.8557 - accuracy: 0.62 - ETA: 0s - loss: 0.8579 - accuracy: 0.62 - ETA: 0s - loss: 0.8623 - accuracy: 0.61 - ETA: 0s - loss: 0.8580 - accuracy: 0.62 - ETA: 0s - loss: 0.8511 - accuracy: 0.63 - ETA: 0s - loss: 0.8326 - accuracy: 0.64 - ETA: 0s - loss: 0.8381 - accuracy: 0.64 - ETA: 0s - loss: 0.8495 - accuracy: 0.62 - ETA: 0s - loss: 0.8528 - accuracy: 0.62 - ETA: 0s - loss: 0.8607 - accuracy: 0.62 - ETA: 0s - loss: 0.8630 - accuracy: 0.6196\n",
      "Epoch 00657: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8630 - accuracy: 0.6196 - val_loss: 1.0540 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 658/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9097 - accuracy: 0.53 - ETA: 0s - loss: 0.8770 - accuracy: 0.57 - ETA: 0s - loss: 0.8929 - accuracy: 0.58 - ETA: 0s - loss: 0.8629 - accuracy: 0.60 - ETA: 0s - loss: 0.8639 - accuracy: 0.61 - ETA: 0s - loss: 0.8571 - accuracy: 0.62 - ETA: 0s - loss: 0.8539 - accuracy: 0.62 - ETA: 0s - loss: 0.8544 - accuracy: 0.62 - ETA: 0s - loss: 0.8574 - accuracy: 0.62 - ETA: 0s - loss: 0.8641 - accuracy: 0.61 - ETA: 0s - loss: 0.8594 - accuracy: 0.62 - ETA: 0s - loss: 0.8523 - accuracy: 0.63 - ETA: 0s - loss: 0.8336 - accuracy: 0.64 - ETA: 0s - loss: 0.8396 - accuracy: 0.64 - ETA: 0s - loss: 0.8518 - accuracy: 0.63 - ETA: 0s - loss: 0.8552 - accuracy: 0.62 - ETA: 0s - loss: 0.8610 - accuracy: 0.62 - ETA: 0s - loss: 0.8626 - accuracy: 0.62 - ETA: 0s - loss: 0.8637 - accuracy: 0.6232\n",
      "Epoch 00658: val_loss did not improve from 0.99131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8637 - accuracy: 0.6232 - val_loss: 1.0534 - val_accuracy: 0.5011 - lr: 0.0010\n",
      "Epoch 659/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9170 - accuracy: 0.53 - ETA: 0s - loss: 0.8762 - accuracy: 0.58 - ETA: 0s - loss: 0.8862 - accuracy: 0.58 - ETA: 0s - loss: 0.8579 - accuracy: 0.60 - ETA: 0s - loss: 0.8582 - accuracy: 0.61 - ETA: 0s - loss: 0.8527 - accuracy: 0.62 - ETA: 0s - loss: 0.8504 - accuracy: 0.62 - ETA: 0s - loss: 0.8491 - accuracy: 0.62 - ETA: 0s - loss: 0.8513 - accuracy: 0.62 - ETA: 0s - loss: 0.8571 - accuracy: 0.61 - ETA: 0s - loss: 0.8519 - accuracy: 0.62 - ETA: 0s - loss: 0.8460 - accuracy: 0.63 - ETA: 0s - loss: 0.8281 - accuracy: 0.64 - ETA: 0s - loss: 0.8352 - accuracy: 0.63 - ETA: 0s - loss: 0.8468 - accuracy: 0.63 - ETA: 0s - loss: 0.8500 - accuracy: 0.62 - ETA: 0s - loss: 0.8559 - accuracy: 0.62 - ETA: 0s - loss: 0.8578 - accuracy: 0.62 - ETA: 0s - loss: 0.8599 - accuracy: 0.6223\n",
      "Epoch 00659: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8599 - accuracy: 0.6223 - val_loss: 1.0620 - val_accuracy: 0.4940 - lr: 0.0010\n",
      "Epoch 660/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9198 - accuracy: 0.56 - ETA: 0s - loss: 0.8793 - accuracy: 0.60 - ETA: 0s - loss: 0.8928 - accuracy: 0.59 - ETA: 0s - loss: 0.8634 - accuracy: 0.61 - ETA: 0s - loss: 0.8652 - accuracy: 0.61 - ETA: 0s - loss: 0.8572 - accuracy: 0.62 - ETA: 0s - loss: 0.8549 - accuracy: 0.63 - ETA: 0s - loss: 0.8535 - accuracy: 0.63 - ETA: 0s - loss: 0.8565 - accuracy: 0.62 - ETA: 0s - loss: 0.8628 - accuracy: 0.61 - ETA: 0s - loss: 0.8586 - accuracy: 0.62 - ETA: 0s - loss: 0.8521 - accuracy: 0.63 - ETA: 0s - loss: 0.8343 - accuracy: 0.64 - ETA: 0s - loss: 0.8402 - accuracy: 0.64 - ETA: 0s - loss: 0.8519 - accuracy: 0.62 - ETA: 0s - loss: 0.8562 - accuracy: 0.62 - ETA: 0s - loss: 0.8616 - accuracy: 0.62 - ETA: 0s - loss: 0.8633 - accuracy: 0.62 - ETA: 0s - loss: 0.8650 - accuracy: 0.6198\n",
      "Epoch 00660: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8650 - accuracy: 0.6198 - val_loss: 1.0679 - val_accuracy: 0.4904 - lr: 0.0010\n",
      "Epoch 661/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9017 - accuracy: 0.56 - ETA: 0s - loss: 0.8720 - accuracy: 0.59 - ETA: 0s - loss: 0.8872 - accuracy: 0.59 - ETA: 0s - loss: 0.8609 - accuracy: 0.61 - ETA: 0s - loss: 0.8605 - accuracy: 0.61 - ETA: 0s - loss: 0.8520 - accuracy: 0.62 - ETA: 0s - loss: 0.8522 - accuracy: 0.62 - ETA: 0s - loss: 0.8506 - accuracy: 0.63 - ETA: 0s - loss: 0.8543 - accuracy: 0.62 - ETA: 0s - loss: 0.8606 - accuracy: 0.62 - ETA: 0s - loss: 0.8565 - accuracy: 0.63 - ETA: 0s - loss: 0.8500 - accuracy: 0.63 - ETA: 0s - loss: 0.8317 - accuracy: 0.64 - ETA: 0s - loss: 0.8392 - accuracy: 0.64 - ETA: 0s - loss: 0.8544 - accuracy: 0.62 - ETA: 0s - loss: 0.8604 - accuracy: 0.62 - ETA: 0s - loss: 0.8622 - accuracy: 0.62 - ETA: 0s - loss: 0.8634 - accuracy: 0.6246\n",
      "Epoch 00661: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8634 - accuracy: 0.6246 - val_loss: 1.0598 - val_accuracy: 0.4932 - lr: 0.0010\n",
      "Epoch 662/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9126 - accuracy: 0.56 - ETA: 0s - loss: 0.8774 - accuracy: 0.59 - ETA: 0s - loss: 0.8931 - accuracy: 0.58 - ETA: 0s - loss: 0.8638 - accuracy: 0.61 - ETA: 0s - loss: 0.8645 - accuracy: 0.61 - ETA: 0s - loss: 0.8583 - accuracy: 0.62 - ETA: 0s - loss: 0.8540 - accuracy: 0.62 - ETA: 0s - loss: 0.8530 - accuracy: 0.63 - ETA: 0s - loss: 0.8543 - accuracy: 0.62 - ETA: 0s - loss: 0.8593 - accuracy: 0.62 - ETA: 0s - loss: 0.8551 - accuracy: 0.62 - ETA: 0s - loss: 0.8481 - accuracy: 0.63 - ETA: 0s - loss: 0.8296 - accuracy: 0.64 - ETA: 0s - loss: 0.8370 - accuracy: 0.64 - ETA: 0s - loss: 0.8492 - accuracy: 0.63 - ETA: 0s - loss: 0.8531 - accuracy: 0.62 - ETA: 0s - loss: 0.8592 - accuracy: 0.62 - ETA: 0s - loss: 0.8616 - accuracy: 0.62 - ETA: 0s - loss: 0.8622 - accuracy: 0.6247\n",
      "Epoch 00662: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8622 - accuracy: 0.6247 - val_loss: 1.0560 - val_accuracy: 0.4953 - lr: 0.0010\n",
      "Epoch 663/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8860 - accuracy: 0.56 - ETA: 0s - loss: 0.8754 - accuracy: 0.59 - ETA: 0s - loss: 0.8845 - accuracy: 0.59 - ETA: 0s - loss: 0.8573 - accuracy: 0.61 - ETA: 0s - loss: 0.8564 - accuracy: 0.61 - ETA: 0s - loss: 0.8502 - accuracy: 0.62 - ETA: 0s - loss: 0.8480 - accuracy: 0.63 - ETA: 0s - loss: 0.8472 - accuracy: 0.63 - ETA: 0s - loss: 0.8513 - accuracy: 0.62 - ETA: 0s - loss: 0.8569 - accuracy: 0.62 - ETA: 0s - loss: 0.8525 - accuracy: 0.62 - ETA: 0s - loss: 0.8457 - accuracy: 0.63 - ETA: 0s - loss: 0.8274 - accuracy: 0.65 - ETA: 0s - loss: 0.8357 - accuracy: 0.64 - ETA: 0s - loss: 0.8470 - accuracy: 0.63 - ETA: 0s - loss: 0.8502 - accuracy: 0.62 - ETA: 0s - loss: 0.8558 - accuracy: 0.62 - ETA: 0s - loss: 0.8574 - accuracy: 0.62 - ETA: 0s - loss: 0.8587 - accuracy: 0.6233\n",
      "Epoch 00663: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8587 - accuracy: 0.6233 - val_loss: 1.0537 - val_accuracy: 0.5011 - lr: 0.0010\n",
      "Epoch 664/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9162 - accuracy: 0.54 - ETA: 0s - loss: 0.8845 - accuracy: 0.57 - ETA: 0s - loss: 0.8938 - accuracy: 0.58 - ETA: 0s - loss: 0.8634 - accuracy: 0.60 - ETA: 0s - loss: 0.8611 - accuracy: 0.61 - ETA: 0s - loss: 0.8544 - accuracy: 0.62 - ETA: 0s - loss: 0.8527 - accuracy: 0.62 - ETA: 0s - loss: 0.8530 - accuracy: 0.62 - ETA: 0s - loss: 0.8538 - accuracy: 0.62 - ETA: 0s - loss: 0.8592 - accuracy: 0.62 - ETA: 0s - loss: 0.8551 - accuracy: 0.62 - ETA: 0s - loss: 0.8499 - accuracy: 0.63 - ETA: 0s - loss: 0.8317 - accuracy: 0.64 - ETA: 0s - loss: 0.8379 - accuracy: 0.64 - ETA: 0s - loss: 0.8495 - accuracy: 0.63 - ETA: 0s - loss: 0.8519 - accuracy: 0.63 - ETA: 0s - loss: 0.8582 - accuracy: 0.62 - ETA: 0s - loss: 0.8601 - accuracy: 0.62 - ETA: 0s - loss: 0.8618 - accuracy: 0.6254\n",
      "Epoch 00664: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8618 - accuracy: 0.6254 - val_loss: 1.0656 - val_accuracy: 0.4927 - lr: 0.0010\n",
      "Epoch 665/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8887 - accuracy: 0.55 - ETA: 0s - loss: 0.8734 - accuracy: 0.58 - ETA: 0s - loss: 0.8874 - accuracy: 0.58 - ETA: 0s - loss: 0.8596 - accuracy: 0.61 - ETA: 0s - loss: 0.8572 - accuracy: 0.61 - ETA: 0s - loss: 0.8503 - accuracy: 0.62 - ETA: 0s - loss: 0.8474 - accuracy: 0.62 - ETA: 0s - loss: 0.8480 - accuracy: 0.63 - ETA: 0s - loss: 0.8511 - accuracy: 0.62 - ETA: 0s - loss: 0.8584 - accuracy: 0.62 - ETA: 0s - loss: 0.8547 - accuracy: 0.62 - ETA: 0s - loss: 0.8474 - accuracy: 0.63 - ETA: 0s - loss: 0.8294 - accuracy: 0.64 - ETA: 0s - loss: 0.8364 - accuracy: 0.64 - ETA: 0s - loss: 0.8488 - accuracy: 0.63 - ETA: 0s - loss: 0.8524 - accuracy: 0.62 - ETA: 0s - loss: 0.8583 - accuracy: 0.62 - ETA: 0s - loss: 0.8601 - accuracy: 0.62 - ETA: 0s - loss: 0.8616 - accuracy: 0.6219\n",
      "Epoch 00665: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8616 - accuracy: 0.6219 - val_loss: 1.0796 - val_accuracy: 0.4902 - lr: 0.0010\n",
      "Epoch 666/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9080 - accuracy: 0.54 - ETA: 0s - loss: 0.8869 - accuracy: 0.58 - ETA: 0s - loss: 0.8997 - accuracy: 0.58 - ETA: 0s - loss: 0.8665 - accuracy: 0.60 - ETA: 0s - loss: 0.8658 - accuracy: 0.61 - ETA: 0s - loss: 0.8560 - accuracy: 0.62 - ETA: 0s - loss: 0.8536 - accuracy: 0.62 - ETA: 0s - loss: 0.8534 - accuracy: 0.62 - ETA: 0s - loss: 0.8556 - accuracy: 0.62 - ETA: 0s - loss: 0.8614 - accuracy: 0.61 - ETA: 0s - loss: 0.8568 - accuracy: 0.62 - ETA: 0s - loss: 0.8514 - accuracy: 0.63 - ETA: 0s - loss: 0.8339 - accuracy: 0.64 - ETA: 0s - loss: 0.8404 - accuracy: 0.64 - ETA: 0s - loss: 0.8527 - accuracy: 0.63 - ETA: 0s - loss: 0.8553 - accuracy: 0.62 - ETA: 0s - loss: 0.8607 - accuracy: 0.62 - ETA: 0s - loss: 0.8623 - accuracy: 0.62 - ETA: 0s - loss: 0.8635 - accuracy: 0.6230\n",
      "Epoch 00666: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8635 - accuracy: 0.6230 - val_loss: 1.0814 - val_accuracy: 0.4858 - lr: 0.0010\n",
      "Epoch 667/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.9113 - accuracy: 0.53 - ETA: 0s - loss: 0.8771 - accuracy: 0.57 - ETA: 0s - loss: 0.8900 - accuracy: 0.57 - ETA: 0s - loss: 0.8611 - accuracy: 0.60 - ETA: 0s - loss: 0.8618 - accuracy: 0.60 - ETA: 0s - loss: 0.8523 - accuracy: 0.62 - ETA: 0s - loss: 0.8504 - accuracy: 0.62 - ETA: 0s - loss: 0.8504 - accuracy: 0.62 - ETA: 0s - loss: 0.8535 - accuracy: 0.62 - ETA: 0s - loss: 0.8605 - accuracy: 0.61 - ETA: 0s - loss: 0.8557 - accuracy: 0.62 - ETA: 0s - loss: 0.8493 - accuracy: 0.63 - ETA: 0s - loss: 0.8310 - accuracy: 0.64 - ETA: 0s - loss: 0.8373 - accuracy: 0.64 - ETA: 0s - loss: 0.8491 - accuracy: 0.62 - ETA: 0s - loss: 0.8532 - accuracy: 0.62 - ETA: 0s - loss: 0.8601 - accuracy: 0.62 - ETA: 0s - loss: 0.8625 - accuracy: 0.6230\n",
      "Epoch 00667: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8646 - accuracy: 0.6215 - val_loss: 1.0878 - val_accuracy: 0.4831 - lr: 0.0010\n",
      "Epoch 668/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9005 - accuracy: 0.57 - ETA: 0s - loss: 0.8870 - accuracy: 0.58 - ETA: 0s - loss: 0.8995 - accuracy: 0.57 - ETA: 0s - loss: 0.8709 - accuracy: 0.60 - ETA: 0s - loss: 0.8705 - accuracy: 0.60 - ETA: 0s - loss: 0.8620 - accuracy: 0.61 - ETA: 0s - loss: 0.8582 - accuracy: 0.62 - ETA: 0s - loss: 0.8575 - accuracy: 0.62 - ETA: 0s - loss: 0.8587 - accuracy: 0.62 - ETA: 0s - loss: 0.8636 - accuracy: 0.61 - ETA: 0s - loss: 0.8597 - accuracy: 0.62 - ETA: 0s - loss: 0.8543 - accuracy: 0.62 - ETA: 0s - loss: 0.8363 - accuracy: 0.64 - ETA: 0s - loss: 0.8409 - accuracy: 0.64 - ETA: 0s - loss: 0.8516 - accuracy: 0.63 - ETA: 0s - loss: 0.8553 - accuracy: 0.62 - ETA: 0s - loss: 0.8605 - accuracy: 0.62 - ETA: 0s - loss: 0.8621 - accuracy: 0.62 - ETA: 0s - loss: 0.8632 - accuracy: 0.6222\n",
      "Epoch 00668: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8632 - accuracy: 0.6222 - val_loss: 1.0772 - val_accuracy: 0.4889 - lr: 0.0010\n",
      "Epoch 669/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8980 - accuracy: 0.55 - ETA: 0s - loss: 0.8739 - accuracy: 0.59 - ETA: 0s - loss: 0.8878 - accuracy: 0.59 - ETA: 0s - loss: 0.8595 - accuracy: 0.61 - ETA: 0s - loss: 0.8589 - accuracy: 0.61 - ETA: 0s - loss: 0.8497 - accuracy: 0.62 - ETA: 0s - loss: 0.8478 - accuracy: 0.63 - ETA: 0s - loss: 0.8495 - accuracy: 0.62 - ETA: 0s - loss: 0.8512 - accuracy: 0.62 - ETA: 0s - loss: 0.8591 - accuracy: 0.61 - ETA: 0s - loss: 0.8537 - accuracy: 0.62 - ETA: 0s - loss: 0.8475 - accuracy: 0.63 - ETA: 0s - loss: 0.8296 - accuracy: 0.64 - ETA: 0s - loss: 0.8355 - accuracy: 0.64 - ETA: 0s - loss: 0.8480 - accuracy: 0.62 - ETA: 0s - loss: 0.8510 - accuracy: 0.62 - ETA: 0s - loss: 0.8570 - accuracy: 0.62 - ETA: 0s - loss: 0.8593 - accuracy: 0.62 - ETA: 0s - loss: 0.8604 - accuracy: 0.6219\n",
      "Epoch 00669: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00669: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8604 - accuracy: 0.6219 - val_loss: 1.0653 - val_accuracy: 0.4932 - lr: 0.0010\n",
      "Epoch 670/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9250 - accuracy: 0.55 - ETA: 0s - loss: 0.8891 - accuracy: 0.59 - ETA: 0s - loss: 0.8969 - accuracy: 0.59 - ETA: 0s - loss: 0.8637 - accuracy: 0.61 - ETA: 0s - loss: 0.8635 - accuracy: 0.61 - ETA: 0s - loss: 0.8561 - accuracy: 0.62 - ETA: 0s - loss: 0.8544 - accuracy: 0.63 - ETA: 0s - loss: 0.8529 - accuracy: 0.63 - ETA: 0s - loss: 0.8554 - accuracy: 0.62 - ETA: 0s - loss: 0.8620 - accuracy: 0.62 - ETA: 0s - loss: 0.8568 - accuracy: 0.62 - ETA: 0s - loss: 0.8505 - accuracy: 0.63 - ETA: 0s - loss: 0.8321 - accuracy: 0.64 - ETA: 0s - loss: 0.8379 - accuracy: 0.64 - ETA: 0s - loss: 0.8494 - accuracy: 0.63 - ETA: 0s - loss: 0.8532 - accuracy: 0.62 - ETA: 0s - loss: 0.8590 - accuracy: 0.62 - ETA: 0s - loss: 0.8604 - accuracy: 0.62 - ETA: 0s - loss: 0.8616 - accuracy: 0.6236\n",
      "Epoch 00670: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8616 - accuracy: 0.6236 - val_loss: 1.0740 - val_accuracy: 0.4914 - lr: 0.0010\n",
      "Epoch 671/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9108 - accuracy: 0.55 - ETA: 0s - loss: 0.8927 - accuracy: 0.58 - ETA: 0s - loss: 0.9045 - accuracy: 0.58 - ETA: 0s - loss: 0.8710 - accuracy: 0.60 - ETA: 0s - loss: 0.8692 - accuracy: 0.61 - ETA: 0s - loss: 0.8608 - accuracy: 0.62 - ETA: 0s - loss: 0.8575 - accuracy: 0.62 - ETA: 0s - loss: 0.8569 - accuracy: 0.62 - ETA: 0s - loss: 0.8584 - accuracy: 0.62 - ETA: 0s - loss: 0.8638 - accuracy: 0.62 - ETA: 0s - loss: 0.8587 - accuracy: 0.62 - ETA: 0s - loss: 0.8513 - accuracy: 0.63 - ETA: 0s - loss: 0.8331 - accuracy: 0.64 - ETA: 0s - loss: 0.8397 - accuracy: 0.64 - ETA: 0s - loss: 0.8516 - accuracy: 0.63 - ETA: 0s - loss: 0.8543 - accuracy: 0.62 - ETA: 0s - loss: 0.8603 - accuracy: 0.62 - ETA: 0s - loss: 0.8619 - accuracy: 0.62 - ETA: 0s - loss: 0.8634 - accuracy: 0.6232\n",
      "Epoch 00671: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8634 - accuracy: 0.6232 - val_loss: 1.0726 - val_accuracy: 0.4906 - lr: 0.0010\n",
      "Epoch 672/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8988 - accuracy: 0.58 - ETA: 0s - loss: 0.8782 - accuracy: 0.60 - ETA: 0s - loss: 0.8882 - accuracy: 0.60 - ETA: 0s - loss: 0.8601 - accuracy: 0.62 - ETA: 0s - loss: 0.8644 - accuracy: 0.62 - ETA: 0s - loss: 0.8545 - accuracy: 0.62 - ETA: 0s - loss: 0.8526 - accuracy: 0.63 - ETA: 0s - loss: 0.8538 - accuracy: 0.63 - ETA: 0s - loss: 0.8548 - accuracy: 0.63 - ETA: 0s - loss: 0.8596 - accuracy: 0.62 - ETA: 0s - loss: 0.8557 - accuracy: 0.63 - ETA: 0s - loss: 0.8491 - accuracy: 0.63 - ETA: 0s - loss: 0.8311 - accuracy: 0.65 - ETA: 0s - loss: 0.8388 - accuracy: 0.64 - ETA: 0s - loss: 0.8495 - accuracy: 0.63 - ETA: 0s - loss: 0.8526 - accuracy: 0.62 - ETA: 0s - loss: 0.8581 - accuracy: 0.62 - ETA: 0s - loss: 0.8599 - accuracy: 0.62 - ETA: 0s - loss: 0.8615 - accuracy: 0.6244\n",
      "Epoch 00672: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8615 - accuracy: 0.6244 - val_loss: 1.0628 - val_accuracy: 0.4946 - lr: 0.0010\n",
      "Epoch 673/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9059 - accuracy: 0.57 - ETA: 0s - loss: 0.8774 - accuracy: 0.60 - ETA: 0s - loss: 0.8851 - accuracy: 0.59 - ETA: 0s - loss: 0.8553 - accuracy: 0.61 - ETA: 0s - loss: 0.8602 - accuracy: 0.61 - ETA: 0s - loss: 0.8510 - accuracy: 0.62 - ETA: 0s - loss: 0.8505 - accuracy: 0.62 - ETA: 0s - loss: 0.8497 - accuracy: 0.63 - ETA: 0s - loss: 0.8504 - accuracy: 0.63 - ETA: 0s - loss: 0.8569 - accuracy: 0.62 - ETA: 0s - loss: 0.8533 - accuracy: 0.62 - ETA: 0s - loss: 0.8460 - accuracy: 0.63 - ETA: 0s - loss: 0.8283 - accuracy: 0.64 - ETA: 0s - loss: 0.8334 - accuracy: 0.64 - ETA: 0s - loss: 0.8463 - accuracy: 0.63 - ETA: 0s - loss: 0.8498 - accuracy: 0.63 - ETA: 0s - loss: 0.8551 - accuracy: 0.62 - ETA: 0s - loss: 0.8574 - accuracy: 0.62 - ETA: 0s - loss: 0.8596 - accuracy: 0.6240\n",
      "Epoch 00673: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8596 - accuracy: 0.6240 - val_loss: 1.0649 - val_accuracy: 0.4972 - lr: 0.0010\n",
      "Epoch 674/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9098 - accuracy: 0.56 - ETA: 0s - loss: 0.8807 - accuracy: 0.59 - ETA: 0s - loss: 0.8926 - accuracy: 0.59 - ETA: 0s - loss: 0.8651 - accuracy: 0.61 - ETA: 0s - loss: 0.8654 - accuracy: 0.61 - ETA: 0s - loss: 0.8582 - accuracy: 0.62 - ETA: 0s - loss: 0.8570 - accuracy: 0.62 - ETA: 0s - loss: 0.8563 - accuracy: 0.63 - ETA: 0s - loss: 0.8572 - accuracy: 0.62 - ETA: 0s - loss: 0.8636 - accuracy: 0.62 - ETA: 0s - loss: 0.8592 - accuracy: 0.62 - ETA: 0s - loss: 0.8525 - accuracy: 0.63 - ETA: 0s - loss: 0.8343 - accuracy: 0.64 - ETA: 0s - loss: 0.8405 - accuracy: 0.64 - ETA: 0s - loss: 0.8506 - accuracy: 0.63 - ETA: 0s - loss: 0.8533 - accuracy: 0.63 - ETA: 0s - loss: 0.8597 - accuracy: 0.62 - ETA: 0s - loss: 0.8606 - accuracy: 0.62 - ETA: 0s - loss: 0.8620 - accuracy: 0.6256\n",
      "Epoch 00674: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8620 - accuracy: 0.6256 - val_loss: 1.0826 - val_accuracy: 0.4878 - lr: 0.0010\n",
      "Epoch 675/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9309 - accuracy: 0.54 - ETA: 0s - loss: 0.8971 - accuracy: 0.57 - ETA: 0s - loss: 0.9085 - accuracy: 0.58 - ETA: 0s - loss: 0.8770 - accuracy: 0.60 - ETA: 0s - loss: 0.8769 - accuracy: 0.60 - ETA: 0s - loss: 0.8655 - accuracy: 0.61 - ETA: 0s - loss: 0.8624 - accuracy: 0.62 - ETA: 0s - loss: 0.8617 - accuracy: 0.62 - ETA: 0s - loss: 0.8637 - accuracy: 0.62 - ETA: 0s - loss: 0.8689 - accuracy: 0.61 - ETA: 0s - loss: 0.8634 - accuracy: 0.62 - ETA: 0s - loss: 0.8562 - accuracy: 0.63 - ETA: 0s - loss: 0.8373 - accuracy: 0.64 - ETA: 0s - loss: 0.8424 - accuracy: 0.64 - ETA: 0s - loss: 0.8535 - accuracy: 0.63 - ETA: 0s - loss: 0.8621 - accuracy: 0.62 - ETA: 0s - loss: 0.8636 - accuracy: 0.62 - ETA: 0s - loss: 0.8650 - accuracy: 0.6244\n",
      "Epoch 00675: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8650 - accuracy: 0.6244 - val_loss: 1.0736 - val_accuracy: 0.4894 - lr: 0.0010\n",
      "Epoch 676/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9239 - accuracy: 0.53 - ETA: 0s - loss: 0.8796 - accuracy: 0.58 - ETA: 0s - loss: 0.8900 - accuracy: 0.58 - ETA: 0s - loss: 0.8613 - accuracy: 0.60 - ETA: 0s - loss: 0.8635 - accuracy: 0.61 - ETA: 0s - loss: 0.8577 - accuracy: 0.62 - ETA: 0s - loss: 0.8557 - accuracy: 0.62 - ETA: 0s - loss: 0.8539 - accuracy: 0.62 - ETA: 0s - loss: 0.8568 - accuracy: 0.62 - ETA: 0s - loss: 0.8610 - accuracy: 0.61 - ETA: 0s - loss: 0.8559 - accuracy: 0.62 - ETA: 0s - loss: 0.8504 - accuracy: 0.63 - ETA: 0s - loss: 0.8324 - accuracy: 0.64 - ETA: 0s - loss: 0.8370 - accuracy: 0.64 - ETA: 0s - loss: 0.8496 - accuracy: 0.62 - ETA: 0s - loss: 0.8528 - accuracy: 0.62 - ETA: 0s - loss: 0.8590 - accuracy: 0.62 - ETA: 0s - loss: 0.8619 - accuracy: 0.62 - ETA: 0s - loss: 0.8639 - accuracy: 0.6197\n",
      "Epoch 00676: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8639 - accuracy: 0.6197 - val_loss: 1.0758 - val_accuracy: 0.4906 - lr: 0.0010\n",
      "Epoch 677/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8919 - accuracy: 0.56 - ETA: 0s - loss: 0.8690 - accuracy: 0.59 - ETA: 0s - loss: 0.8836 - accuracy: 0.59 - ETA: 0s - loss: 0.8548 - accuracy: 0.61 - ETA: 0s - loss: 0.8578 - accuracy: 0.61 - ETA: 0s - loss: 0.8521 - accuracy: 0.62 - ETA: 0s - loss: 0.8503 - accuracy: 0.62 - ETA: 0s - loss: 0.8493 - accuracy: 0.63 - ETA: 0s - loss: 0.8512 - accuracy: 0.62 - ETA: 0s - loss: 0.8571 - accuracy: 0.62 - ETA: 0s - loss: 0.8528 - accuracy: 0.62 - ETA: 0s - loss: 0.8469 - accuracy: 0.63 - ETA: 0s - loss: 0.8288 - accuracy: 0.64 - ETA: 0s - loss: 0.8361 - accuracy: 0.64 - ETA: 0s - loss: 0.8477 - accuracy: 0.63 - ETA: 0s - loss: 0.8511 - accuracy: 0.62 - ETA: 0s - loss: 0.8578 - accuracy: 0.62 - ETA: 0s - loss: 0.8595 - accuracy: 0.62 - ETA: 0s - loss: 0.8607 - accuracy: 0.6232\n",
      "Epoch 00677: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8607 - accuracy: 0.6232 - val_loss: 1.0772 - val_accuracy: 0.4899 - lr: 0.0010\n",
      "Epoch 678/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8993 - accuracy: 0.55 - ETA: 0s - loss: 0.8740 - accuracy: 0.59 - ETA: 0s - loss: 0.8906 - accuracy: 0.58 - ETA: 0s - loss: 0.8601 - accuracy: 0.61 - ETA: 0s - loss: 0.8607 - accuracy: 0.61 - ETA: 0s - loss: 0.8509 - accuracy: 0.62 - ETA: 0s - loss: 0.8495 - accuracy: 0.63 - ETA: 0s - loss: 0.8495 - accuracy: 0.63 - ETA: 0s - loss: 0.8524 - accuracy: 0.63 - ETA: 0s - loss: 0.8578 - accuracy: 0.62 - ETA: 0s - loss: 0.8532 - accuracy: 0.62 - ETA: 0s - loss: 0.8469 - accuracy: 0.63 - ETA: 0s - loss: 0.8280 - accuracy: 0.64 - ETA: 0s - loss: 0.8350 - accuracy: 0.64 - ETA: 0s - loss: 0.8473 - accuracy: 0.63 - ETA: 0s - loss: 0.8500 - accuracy: 0.63 - ETA: 0s - loss: 0.8552 - accuracy: 0.62 - ETA: 0s - loss: 0.8570 - accuracy: 0.62 - ETA: 0s - loss: 0.8586 - accuracy: 0.6253\n",
      "Epoch 00678: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8586 - accuracy: 0.6253 - val_loss: 1.0770 - val_accuracy: 0.4876 - lr: 0.0010\n",
      "Epoch 679/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8888 - accuracy: 0.56 - ETA: 0s - loss: 0.8662 - accuracy: 0.58 - ETA: 0s - loss: 0.8729 - accuracy: 0.59 - ETA: 0s - loss: 0.8477 - accuracy: 0.61 - ETA: 0s - loss: 0.8493 - accuracy: 0.61 - ETA: 0s - loss: 0.8439 - accuracy: 0.62 - ETA: 0s - loss: 0.8452 - accuracy: 0.63 - ETA: 0s - loss: 0.8470 - accuracy: 0.63 - ETA: 0s - loss: 0.8509 - accuracy: 0.62 - ETA: 0s - loss: 0.8559 - accuracy: 0.62 - ETA: 0s - loss: 0.8507 - accuracy: 0.62 - ETA: 0s - loss: 0.8451 - accuracy: 0.63 - ETA: 0s - loss: 0.8271 - accuracy: 0.64 - ETA: 0s - loss: 0.8339 - accuracy: 0.64 - ETA: 0s - loss: 0.8455 - accuracy: 0.63 - ETA: 0s - loss: 0.8498 - accuracy: 0.62 - ETA: 0s - loss: 0.8562 - accuracy: 0.62 - ETA: 0s - loss: 0.8584 - accuracy: 0.62 - ETA: 0s - loss: 0.8600 - accuracy: 0.6230\n",
      "Epoch 00679: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8600 - accuracy: 0.6230 - val_loss: 1.0784 - val_accuracy: 0.4866 - lr: 0.0010\n",
      "Epoch 680/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.8919 - accuracy: 0.58 - ETA: 0s - loss: 0.8705 - accuracy: 0.59 - ETA: 0s - loss: 0.8830 - accuracy: 0.59 - ETA: 0s - loss: 0.8573 - accuracy: 0.61 - ETA: 0s - loss: 0.8616 - accuracy: 0.61 - ETA: 0s - loss: 0.8543 - accuracy: 0.62 - ETA: 0s - loss: 0.8520 - accuracy: 0.62 - ETA: 0s - loss: 0.8525 - accuracy: 0.63 - ETA: 0s - loss: 0.8539 - accuracy: 0.62 - ETA: 0s - loss: 0.8589 - accuracy: 0.62 - ETA: 0s - loss: 0.8549 - accuracy: 0.63 - ETA: 0s - loss: 0.8472 - accuracy: 0.63 - ETA: 0s - loss: 0.8290 - accuracy: 0.65 - ETA: 0s - loss: 0.8350 - accuracy: 0.64 - ETA: 0s - loss: 0.8464 - accuracy: 0.63 - ETA: 0s - loss: 0.8487 - accuracy: 0.63 - ETA: 0s - loss: 0.8560 - accuracy: 0.62 - ETA: 0s - loss: 0.8580 - accuracy: 0.6296\n",
      "Epoch 00680: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8597 - accuracy: 0.6277 - val_loss: 1.0708 - val_accuracy: 0.4884 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 681/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9049 - accuracy: 0.56 - ETA: 0s - loss: 0.8815 - accuracy: 0.59 - ETA: 0s - loss: 0.8949 - accuracy: 0.59 - ETA: 0s - loss: 0.8644 - accuracy: 0.61 - ETA: 0s - loss: 0.8650 - accuracy: 0.61 - ETA: 0s - loss: 0.8585 - accuracy: 0.62 - ETA: 0s - loss: 0.8551 - accuracy: 0.63 - ETA: 0s - loss: 0.8552 - accuracy: 0.63 - ETA: 0s - loss: 0.8560 - accuracy: 0.62 - ETA: 0s - loss: 0.8612 - accuracy: 0.62 - ETA: 0s - loss: 0.8563 - accuracy: 0.62 - ETA: 0s - loss: 0.8495 - accuracy: 0.63 - ETA: 0s - loss: 0.8309 - accuracy: 0.64 - ETA: 0s - loss: 0.8357 - accuracy: 0.64 - ETA: 0s - loss: 0.8461 - accuracy: 0.63 - ETA: 0s - loss: 0.8488 - accuracy: 0.63 - ETA: 0s - loss: 0.8557 - accuracy: 0.62 - ETA: 0s - loss: 0.8568 - accuracy: 0.62 - ETA: 0s - loss: 0.8584 - accuracy: 0.6261\n",
      "Epoch 00681: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8584 - accuracy: 0.6261 - val_loss: 1.0591 - val_accuracy: 0.4949 - lr: 0.0010\n",
      "Epoch 682/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8921 - accuracy: 0.56 - ETA: 0s - loss: 0.8659 - accuracy: 0.60 - ETA: 0s - loss: 0.8813 - accuracy: 0.59 - ETA: 0s - loss: 0.8550 - accuracy: 0.61 - ETA: 0s - loss: 0.8547 - accuracy: 0.62 - ETA: 0s - loss: 0.8480 - accuracy: 0.63 - ETA: 0s - loss: 0.8457 - accuracy: 0.63 - ETA: 0s - loss: 0.8469 - accuracy: 0.63 - ETA: 0s - loss: 0.8495 - accuracy: 0.63 - ETA: 0s - loss: 0.8554 - accuracy: 0.62 - ETA: 0s - loss: 0.8518 - accuracy: 0.63 - ETA: 0s - loss: 0.8463 - accuracy: 0.63 - ETA: 0s - loss: 0.8284 - accuracy: 0.65 - ETA: 0s - loss: 0.8336 - accuracy: 0.64 - ETA: 0s - loss: 0.8455 - accuracy: 0.63 - ETA: 0s - loss: 0.8485 - accuracy: 0.63 - ETA: 0s - loss: 0.8555 - accuracy: 0.62 - ETA: 0s - loss: 0.8577 - accuracy: 0.62 - ETA: 0s - loss: 0.8589 - accuracy: 0.6273\n",
      "Epoch 00682: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8589 - accuracy: 0.6273 - val_loss: 1.0675 - val_accuracy: 0.4941 - lr: 0.0010\n",
      "Epoch 683/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9070 - accuracy: 0.53 - ETA: 0s - loss: 0.8793 - accuracy: 0.58 - ETA: 0s - loss: 0.8918 - accuracy: 0.59 - ETA: 0s - loss: 0.8652 - accuracy: 0.61 - ETA: 0s - loss: 0.8655 - accuracy: 0.61 - ETA: 0s - loss: 0.8576 - accuracy: 0.62 - ETA: 0s - loss: 0.8548 - accuracy: 0.62 - ETA: 0s - loss: 0.8548 - accuracy: 0.63 - ETA: 0s - loss: 0.8576 - accuracy: 0.63 - ETA: 0s - loss: 0.8630 - accuracy: 0.62 - ETA: 0s - loss: 0.8579 - accuracy: 0.63 - ETA: 0s - loss: 0.8515 - accuracy: 0.63 - ETA: 0s - loss: 0.8323 - accuracy: 0.64 - ETA: 0s - loss: 0.8383 - accuracy: 0.64 - ETA: 0s - loss: 0.8510 - accuracy: 0.63 - ETA: 0s - loss: 0.8543 - accuracy: 0.62 - ETA: 0s - loss: 0.8601 - accuracy: 0.62 - ETA: 0s - loss: 0.8624 - accuracy: 0.62 - ETA: 0s - loss: 0.8634 - accuracy: 0.6249\n",
      "Epoch 00683: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00683: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8634 - accuracy: 0.6249 - val_loss: 1.0705 - val_accuracy: 0.4938 - lr: 0.0010\n",
      "Epoch 684/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9219 - accuracy: 0.54 - ETA: 0s - loss: 0.8795 - accuracy: 0.58 - ETA: 0s - loss: 0.8944 - accuracy: 0.58 - ETA: 0s - loss: 0.8647 - accuracy: 0.60 - ETA: 0s - loss: 0.8658 - accuracy: 0.61 - ETA: 0s - loss: 0.8577 - accuracy: 0.62 - ETA: 0s - loss: 0.8533 - accuracy: 0.62 - ETA: 0s - loss: 0.8522 - accuracy: 0.63 - ETA: 0s - loss: 0.8558 - accuracy: 0.62 - ETA: 0s - loss: 0.8611 - accuracy: 0.62 - ETA: 0s - loss: 0.8561 - accuracy: 0.63 - ETA: 0s - loss: 0.8499 - accuracy: 0.63 - ETA: 0s - loss: 0.8325 - accuracy: 0.64 - ETA: 0s - loss: 0.8378 - accuracy: 0.64 - ETA: 0s - loss: 0.8486 - accuracy: 0.63 - ETA: 0s - loss: 0.8520 - accuracy: 0.63 - ETA: 0s - loss: 0.8578 - accuracy: 0.62 - ETA: 0s - loss: 0.8603 - accuracy: 0.6249\n",
      "Epoch 00684: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8603 - accuracy: 0.6249 - val_loss: 1.0792 - val_accuracy: 0.4891 - lr: 0.0010\n",
      "Epoch 685/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8958 - accuracy: 0.58 - ETA: 0s - loss: 0.8791 - accuracy: 0.59 - ETA: 0s - loss: 0.8871 - accuracy: 0.59 - ETA: 0s - loss: 0.8587 - accuracy: 0.61 - ETA: 0s - loss: 0.8594 - accuracy: 0.62 - ETA: 0s - loss: 0.8531 - accuracy: 0.63 - ETA: 0s - loss: 0.8509 - accuracy: 0.63 - ETA: 0s - loss: 0.8494 - accuracy: 0.63 - ETA: 0s - loss: 0.8508 - accuracy: 0.63 - ETA: 0s - loss: 0.8557 - accuracy: 0.62 - ETA: 0s - loss: 0.8512 - accuracy: 0.63 - ETA: 0s - loss: 0.8447 - accuracy: 0.63 - ETA: 0s - loss: 0.8270 - accuracy: 0.65 - ETA: 0s - loss: 0.8340 - accuracy: 0.64 - ETA: 0s - loss: 0.8459 - accuracy: 0.63 - ETA: 0s - loss: 0.8486 - accuracy: 0.63 - ETA: 0s - loss: 0.8567 - accuracy: 0.62 - ETA: 0s - loss: 0.8587 - accuracy: 0.6252\n",
      "Epoch 00685: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8587 - accuracy: 0.6252 - val_loss: 1.0798 - val_accuracy: 0.4886 - lr: 0.0010\n",
      "Epoch 686/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9077 - accuracy: 0.55 - ETA: 0s - loss: 0.8753 - accuracy: 0.58 - ETA: 0s - loss: 0.8824 - accuracy: 0.59 - ETA: 0s - loss: 0.8531 - accuracy: 0.61 - ETA: 0s - loss: 0.8544 - accuracy: 0.61 - ETA: 0s - loss: 0.8480 - accuracy: 0.62 - ETA: 0s - loss: 0.8478 - accuracy: 0.63 - ETA: 0s - loss: 0.8458 - accuracy: 0.63 - ETA: 0s - loss: 0.8474 - accuracy: 0.63 - ETA: 0s - loss: 0.8531 - accuracy: 0.62 - ETA: 0s - loss: 0.8497 - accuracy: 0.62 - ETA: 0s - loss: 0.8420 - accuracy: 0.63 - ETA: 0s - loss: 0.8238 - accuracy: 0.65 - ETA: 0s - loss: 0.8299 - accuracy: 0.64 - ETA: 0s - loss: 0.8425 - accuracy: 0.63 - ETA: 0s - loss: 0.8454 - accuracy: 0.63 - ETA: 0s - loss: 0.8521 - accuracy: 0.62 - ETA: 0s - loss: 0.8540 - accuracy: 0.62 - ETA: 0s - loss: 0.8550 - accuracy: 0.6253\n",
      "Epoch 00686: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8550 - accuracy: 0.6253 - val_loss: 1.0657 - val_accuracy: 0.4949 - lr: 0.0010\n",
      "Epoch 687/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9093 - accuracy: 0.54 - ETA: 0s - loss: 0.8786 - accuracy: 0.58 - ETA: 0s - loss: 0.8905 - accuracy: 0.58 - ETA: 0s - loss: 0.8591 - accuracy: 0.60 - ETA: 0s - loss: 0.8592 - accuracy: 0.61 - ETA: 0s - loss: 0.8514 - accuracy: 0.62 - ETA: 0s - loss: 0.8483 - accuracy: 0.62 - ETA: 0s - loss: 0.8476 - accuracy: 0.62 - ETA: 0s - loss: 0.8517 - accuracy: 0.62 - ETA: 0s - loss: 0.8577 - accuracy: 0.62 - ETA: 0s - loss: 0.8535 - accuracy: 0.62 - ETA: 0s - loss: 0.8477 - accuracy: 0.63 - ETA: 0s - loss: 0.8292 - accuracy: 0.64 - ETA: 0s - loss: 0.8342 - accuracy: 0.64 - ETA: 0s - loss: 0.8463 - accuracy: 0.63 - ETA: 0s - loss: 0.8497 - accuracy: 0.63 - ETA: 0s - loss: 0.8559 - accuracy: 0.62 - ETA: 0s - loss: 0.8578 - accuracy: 0.62 - ETA: 0s - loss: 0.8592 - accuracy: 0.6256\n",
      "Epoch 00687: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8592 - accuracy: 0.6256 - val_loss: 1.0710 - val_accuracy: 0.4907 - lr: 0.0010\n",
      "Epoch 688/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8880 - accuracy: 0.55 - ETA: 0s - loss: 0.8658 - accuracy: 0.60 - ETA: 0s - loss: 0.8815 - accuracy: 0.59 - ETA: 0s - loss: 0.8546 - accuracy: 0.61 - ETA: 0s - loss: 0.8565 - accuracy: 0.61 - ETA: 0s - loss: 0.8503 - accuracy: 0.62 - ETA: 0s - loss: 0.8483 - accuracy: 0.63 - ETA: 0s - loss: 0.8500 - accuracy: 0.63 - ETA: 0s - loss: 0.8524 - accuracy: 0.63 - ETA: 0s - loss: 0.8578 - accuracy: 0.62 - ETA: 0s - loss: 0.8528 - accuracy: 0.63 - ETA: 0s - loss: 0.8463 - accuracy: 0.63 - ETA: 0s - loss: 0.8288 - accuracy: 0.65 - ETA: 0s - loss: 0.8343 - accuracy: 0.64 - ETA: 0s - loss: 0.8468 - accuracy: 0.63 - ETA: 0s - loss: 0.8501 - accuracy: 0.63 - ETA: 0s - loss: 0.8562 - accuracy: 0.62 - ETA: 0s - loss: 0.8601 - accuracy: 0.6240\n",
      "Epoch 00688: val_loss did not improve from 0.99131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8601 - accuracy: 0.6240 - val_loss: 1.0725 - val_accuracy: 0.4901 - lr: 0.0010\n",
      "Epoch 689/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9023 - accuracy: 0.55 - ETA: 0s - loss: 0.8734 - accuracy: 0.60 - ETA: 0s - loss: 0.8758 - accuracy: 0.59 - ETA: 0s - loss: 0.8489 - accuracy: 0.61 - ETA: 0s - loss: 0.8500 - accuracy: 0.62 - ETA: 0s - loss: 0.8447 - accuracy: 0.63 - ETA: 0s - loss: 0.8416 - accuracy: 0.63 - ETA: 0s - loss: 0.8420 - accuracy: 0.63 - ETA: 0s - loss: 0.8457 - accuracy: 0.63 - ETA: 0s - loss: 0.8499 - accuracy: 0.62 - ETA: 0s - loss: 0.8469 - accuracy: 0.63 - ETA: 0s - loss: 0.8410 - accuracy: 0.63 - ETA: 0s - loss: 0.8232 - accuracy: 0.65 - ETA: 0s - loss: 0.8301 - accuracy: 0.64 - ETA: 0s - loss: 0.8430 - accuracy: 0.63 - ETA: 0s - loss: 0.8461 - accuracy: 0.63 - ETA: 0s - loss: 0.8530 - accuracy: 0.62 - ETA: 0s - loss: 0.8540 - accuracy: 0.62 - ETA: 0s - loss: 0.8557 - accuracy: 0.6272\n",
      "Epoch 00689: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8557 - accuracy: 0.6272 - val_loss: 1.0775 - val_accuracy: 0.4904 - lr: 0.0010\n",
      "Epoch 690/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9050 - accuracy: 0.56 - ETA: 0s - loss: 0.8776 - accuracy: 0.59 - ETA: 0s - loss: 0.8872 - accuracy: 0.58 - ETA: 0s - loss: 0.8584 - accuracy: 0.61 - ETA: 0s - loss: 0.8595 - accuracy: 0.61 - ETA: 0s - loss: 0.8518 - accuracy: 0.62 - ETA: 0s - loss: 0.8480 - accuracy: 0.62 - ETA: 0s - loss: 0.8473 - accuracy: 0.63 - ETA: 0s - loss: 0.8484 - accuracy: 0.62 - ETA: 0s - loss: 0.8546 - accuracy: 0.62 - ETA: 0s - loss: 0.8503 - accuracy: 0.62 - ETA: 0s - loss: 0.8443 - accuracy: 0.63 - ETA: 0s - loss: 0.8267 - accuracy: 0.64 - ETA: 0s - loss: 0.8323 - accuracy: 0.64 - ETA: 0s - loss: 0.8449 - accuracy: 0.63 - ETA: 0s - loss: 0.8482 - accuracy: 0.63 - ETA: 0s - loss: 0.8541 - accuracy: 0.62 - ETA: 0s - loss: 0.8567 - accuracy: 0.62 - ETA: 0s - loss: 0.8585 - accuracy: 0.6245\n",
      "Epoch 00690: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8585 - accuracy: 0.6245 - val_loss: 1.0775 - val_accuracy: 0.4914 - lr: 0.0010\n",
      "Epoch 691/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9029 - accuracy: 0.57 - ETA: 0s - loss: 0.8685 - accuracy: 0.61 - ETA: 0s - loss: 0.8790 - accuracy: 0.60 - ETA: 0s - loss: 0.8531 - accuracy: 0.62 - ETA: 0s - loss: 0.8559 - accuracy: 0.62 - ETA: 0s - loss: 0.8488 - accuracy: 0.63 - ETA: 0s - loss: 0.8463 - accuracy: 0.63 - ETA: 0s - loss: 0.8459 - accuracy: 0.63 - ETA: 0s - loss: 0.8469 - accuracy: 0.63 - ETA: 0s - loss: 0.8522 - accuracy: 0.62 - ETA: 0s - loss: 0.8481 - accuracy: 0.63 - ETA: 0s - loss: 0.8427 - accuracy: 0.64 - ETA: 0s - loss: 0.8249 - accuracy: 0.65 - ETA: 0s - loss: 0.8315 - accuracy: 0.64 - ETA: 0s - loss: 0.8431 - accuracy: 0.63 - ETA: 0s - loss: 0.8454 - accuracy: 0.63 - ETA: 0s - loss: 0.8526 - accuracy: 0.62 - ETA: 0s - loss: 0.8546 - accuracy: 0.62 - ETA: 0s - loss: 0.8562 - accuracy: 0.6264\n",
      "Epoch 00691: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8562 - accuracy: 0.6264 - val_loss: 1.0681 - val_accuracy: 0.4928 - lr: 0.0010\n",
      "Epoch 692/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9098 - accuracy: 0.56 - ETA: 0s - loss: 0.8667 - accuracy: 0.60 - ETA: 0s - loss: 0.8784 - accuracy: 0.60 - ETA: 0s - loss: 0.8492 - accuracy: 0.62 - ETA: 0s - loss: 0.8559 - accuracy: 0.62 - ETA: 0s - loss: 0.8483 - accuracy: 0.63 - ETA: 0s - loss: 0.8459 - accuracy: 0.63 - ETA: 0s - loss: 0.8459 - accuracy: 0.63 - ETA: 0s - loss: 0.8495 - accuracy: 0.63 - ETA: 0s - loss: 0.8567 - accuracy: 0.62 - ETA: 0s - loss: 0.8530 - accuracy: 0.63 - ETA: 0s - loss: 0.8475 - accuracy: 0.64 - ETA: 0s - loss: 0.8292 - accuracy: 0.65 - ETA: 0s - loss: 0.8362 - accuracy: 0.64 - ETA: 0s - loss: 0.8471 - accuracy: 0.63 - ETA: 0s - loss: 0.8503 - accuracy: 0.63 - ETA: 0s - loss: 0.8560 - accuracy: 0.62 - ETA: 0s - loss: 0.8578 - accuracy: 0.63 - ETA: 0s - loss: 0.8588 - accuracy: 0.6288\n",
      "Epoch 00692: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8588 - accuracy: 0.6288 - val_loss: 1.0701 - val_accuracy: 0.4925 - lr: 0.0010\n",
      "Epoch 693/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9085 - accuracy: 0.56 - ETA: 0s - loss: 0.8816 - accuracy: 0.59 - ETA: 0s - loss: 0.8915 - accuracy: 0.59 - ETA: 0s - loss: 0.8616 - accuracy: 0.61 - ETA: 0s - loss: 0.8617 - accuracy: 0.61 - ETA: 0s - loss: 0.8552 - accuracy: 0.62 - ETA: 0s - loss: 0.8541 - accuracy: 0.63 - ETA: 0s - loss: 0.8526 - accuracy: 0.63 - ETA: 0s - loss: 0.8540 - accuracy: 0.63 - ETA: 0s - loss: 0.8589 - accuracy: 0.62 - ETA: 0s - loss: 0.8532 - accuracy: 0.63 - ETA: 0s - loss: 0.8474 - accuracy: 0.63 - ETA: 0s - loss: 0.8291 - accuracy: 0.65 - ETA: 0s - loss: 0.8354 - accuracy: 0.64 - ETA: 0s - loss: 0.8463 - accuracy: 0.63 - ETA: 0s - loss: 0.8498 - accuracy: 0.63 - ETA: 0s - loss: 0.8550 - accuracy: 0.63 - ETA: 0s - loss: 0.8567 - accuracy: 0.63 - ETA: 0s - loss: 0.8580 - accuracy: 0.6290\n",
      "Epoch 00693: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8580 - accuracy: 0.6290 - val_loss: 1.0649 - val_accuracy: 0.4951 - lr: 0.0010\n",
      "Epoch 694/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9237 - accuracy: 0.53 - ETA: 0s - loss: 0.8960 - accuracy: 0.57 - ETA: 0s - loss: 0.9046 - accuracy: 0.57 - ETA: 0s - loss: 0.8707 - accuracy: 0.60 - ETA: 0s - loss: 0.8657 - accuracy: 0.61 - ETA: 0s - loss: 0.8567 - accuracy: 0.62 - ETA: 0s - loss: 0.8539 - accuracy: 0.62 - ETA: 0s - loss: 0.8552 - accuracy: 0.62 - ETA: 0s - loss: 0.8572 - accuracy: 0.62 - ETA: 0s - loss: 0.8619 - accuracy: 0.61 - ETA: 0s - loss: 0.8576 - accuracy: 0.62 - ETA: 0s - loss: 0.8505 - accuracy: 0.63 - ETA: 0s - loss: 0.8325 - accuracy: 0.64 - ETA: 0s - loss: 0.8385 - accuracy: 0.64 - ETA: 0s - loss: 0.8474 - accuracy: 0.63 - ETA: 0s - loss: 0.8505 - accuracy: 0.62 - ETA: 0s - loss: 0.8570 - accuracy: 0.62 - ETA: 0s - loss: 0.8585 - accuracy: 0.62 - ETA: 0s - loss: 0.8595 - accuracy: 0.6221\n",
      "Epoch 00694: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8595 - accuracy: 0.6221 - val_loss: 1.0644 - val_accuracy: 0.4943 - lr: 0.0010\n",
      "Epoch 695/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9047 - accuracy: 0.53 - ETA: 0s - loss: 0.8722 - accuracy: 0.58 - ETA: 0s - loss: 0.8880 - accuracy: 0.59 - ETA: 0s - loss: 0.8587 - accuracy: 0.61 - ETA: 0s - loss: 0.8590 - accuracy: 0.61 - ETA: 0s - loss: 0.8525 - accuracy: 0.62 - ETA: 0s - loss: 0.8488 - accuracy: 0.63 - ETA: 0s - loss: 0.8475 - accuracy: 0.63 - ETA: 0s - loss: 0.8498 - accuracy: 0.63 - ETA: 0s - loss: 0.8556 - accuracy: 0.62 - ETA: 0s - loss: 0.8514 - accuracy: 0.63 - ETA: 0s - loss: 0.8448 - accuracy: 0.63 - ETA: 0s - loss: 0.8266 - accuracy: 0.64 - ETA: 0s - loss: 0.8321 - accuracy: 0.64 - ETA: 0s - loss: 0.8435 - accuracy: 0.63 - ETA: 0s - loss: 0.8468 - accuracy: 0.63 - ETA: 0s - loss: 0.8527 - accuracy: 0.62 - ETA: 0s - loss: 0.8550 - accuracy: 0.62 - ETA: 0s - loss: 0.8565 - accuracy: 0.6269\n",
      "Epoch 00695: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8565 - accuracy: 0.6269 - val_loss: 1.0600 - val_accuracy: 0.4977 - lr: 0.0010\n",
      "Epoch 696/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9104 - accuracy: 0.54 - ETA: 0s - loss: 0.8817 - accuracy: 0.57 - ETA: 0s - loss: 0.8927 - accuracy: 0.58 - ETA: 0s - loss: 0.8615 - accuracy: 0.61 - ETA: 0s - loss: 0.8628 - accuracy: 0.61 - ETA: 0s - loss: 0.8543 - accuracy: 0.62 - ETA: 0s - loss: 0.8492 - accuracy: 0.63 - ETA: 0s - loss: 0.8498 - accuracy: 0.63 - ETA: 0s - loss: 0.8510 - accuracy: 0.63 - ETA: 0s - loss: 0.8573 - accuracy: 0.62 - ETA: 0s - loss: 0.8528 - accuracy: 0.63 - ETA: 0s - loss: 0.8464 - accuracy: 0.63 - ETA: 0s - loss: 0.8279 - accuracy: 0.65 - ETA: 0s - loss: 0.8358 - accuracy: 0.64 - ETA: 0s - loss: 0.8456 - accuracy: 0.63 - ETA: 0s - loss: 0.8487 - accuracy: 0.63 - ETA: 0s - loss: 0.8540 - accuracy: 0.62 - ETA: 0s - loss: 0.8564 - accuracy: 0.62 - ETA: 0s - loss: 0.8590 - accuracy: 0.6246\n",
      "Epoch 00696: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8590 - accuracy: 0.6246 - val_loss: 1.0533 - val_accuracy: 0.4984 - lr: 0.0010\n",
      "Epoch 697/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9240 - accuracy: 0.53 - ETA: 0s - loss: 0.8820 - accuracy: 0.58 - ETA: 0s - loss: 0.8876 - accuracy: 0.59 - ETA: 0s - loss: 0.8579 - accuracy: 0.61 - ETA: 0s - loss: 0.8600 - accuracy: 0.61 - ETA: 0s - loss: 0.8526 - accuracy: 0.62 - ETA: 0s - loss: 0.8516 - accuracy: 0.62 - ETA: 0s - loss: 0.8511 - accuracy: 0.62 - ETA: 0s - loss: 0.8533 - accuracy: 0.62 - ETA: 0s - loss: 0.8580 - accuracy: 0.62 - ETA: 0s - loss: 0.8524 - accuracy: 0.62 - ETA: 0s - loss: 0.8454 - accuracy: 0.63 - ETA: 0s - loss: 0.8272 - accuracy: 0.64 - ETA: 0s - loss: 0.8342 - accuracy: 0.64 - ETA: 0s - loss: 0.8440 - accuracy: 0.63 - ETA: 0s - loss: 0.8470 - accuracy: 0.63 - ETA: 0s - loss: 0.8529 - accuracy: 0.62 - ETA: 0s - loss: 0.8570 - accuracy: 0.6242\n",
      "Epoch 00697: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00697: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8570 - accuracy: 0.6242 - val_loss: 1.0586 - val_accuracy: 0.4963 - lr: 0.0010\n",
      "Epoch 698/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8895 - accuracy: 0.56 - ETA: 0s - loss: 0.8728 - accuracy: 0.59 - ETA: 0s - loss: 0.8846 - accuracy: 0.59 - ETA: 0s - loss: 0.8581 - accuracy: 0.61 - ETA: 0s - loss: 0.8577 - accuracy: 0.61 - ETA: 0s - loss: 0.8502 - accuracy: 0.62 - ETA: 0s - loss: 0.8484 - accuracy: 0.63 - ETA: 0s - loss: 0.8490 - accuracy: 0.63 - ETA: 0s - loss: 0.8503 - accuracy: 0.62 - ETA: 0s - loss: 0.8560 - accuracy: 0.62 - ETA: 0s - loss: 0.8527 - accuracy: 0.63 - ETA: 0s - loss: 0.8465 - accuracy: 0.63 - ETA: 0s - loss: 0.8286 - accuracy: 0.65 - ETA: 0s - loss: 0.8349 - accuracy: 0.64 - ETA: 0s - loss: 0.8465 - accuracy: 0.63 - ETA: 0s - loss: 0.8506 - accuracy: 0.63 - ETA: 0s - loss: 0.8572 - accuracy: 0.62 - ETA: 0s - loss: 0.8582 - accuracy: 0.62 - ETA: 0s - loss: 0.8593 - accuracy: 0.6249\n",
      "Epoch 00698: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8593 - accuracy: 0.6249 - val_loss: 1.0667 - val_accuracy: 0.4927 - lr: 0.0010\n",
      "Epoch 699/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9062 - accuracy: 0.55 - ETA: 0s - loss: 0.8828 - accuracy: 0.58 - ETA: 0s - loss: 0.8891 - accuracy: 0.59 - ETA: 0s - loss: 0.8603 - accuracy: 0.61 - ETA: 0s - loss: 0.8587 - accuracy: 0.61 - ETA: 0s - loss: 0.8509 - accuracy: 0.62 - ETA: 0s - loss: 0.8492 - accuracy: 0.63 - ETA: 0s - loss: 0.8486 - accuracy: 0.63 - ETA: 0s - loss: 0.8517 - accuracy: 0.62 - ETA: 0s - loss: 0.8578 - accuracy: 0.62 - ETA: 0s - loss: 0.8533 - accuracy: 0.62 - ETA: 0s - loss: 0.8465 - accuracy: 0.63 - ETA: 0s - loss: 0.8289 - accuracy: 0.64 - ETA: 0s - loss: 0.8358 - accuracy: 0.64 - ETA: 0s - loss: 0.8455 - accuracy: 0.63 - ETA: 0s - loss: 0.8486 - accuracy: 0.63 - ETA: 0s - loss: 0.8539 - accuracy: 0.62 - ETA: 0s - loss: 0.8554 - accuracy: 0.62 - ETA: 0s - loss: 0.8575 - accuracy: 0.6273\n",
      "Epoch 00699: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8575 - accuracy: 0.6273 - val_loss: 1.0698 - val_accuracy: 0.4917 - lr: 0.0010\n",
      "Epoch 700/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8988 - accuracy: 0.55 - ETA: 0s - loss: 0.8709 - accuracy: 0.58 - ETA: 0s - loss: 0.8801 - accuracy: 0.58 - ETA: 0s - loss: 0.8519 - accuracy: 0.61 - ETA: 0s - loss: 0.8533 - accuracy: 0.61 - ETA: 0s - loss: 0.8473 - accuracy: 0.62 - ETA: 0s - loss: 0.8444 - accuracy: 0.63 - ETA: 0s - loss: 0.8444 - accuracy: 0.63 - ETA: 0s - loss: 0.8478 - accuracy: 0.63 - ETA: 0s - loss: 0.8530 - accuracy: 0.62 - ETA: 0s - loss: 0.8479 - accuracy: 0.63 - ETA: 0s - loss: 0.8412 - accuracy: 0.63 - ETA: 0s - loss: 0.8236 - accuracy: 0.65 - ETA: 0s - loss: 0.8305 - accuracy: 0.64 - ETA: 0s - loss: 0.8435 - accuracy: 0.63 - ETA: 0s - loss: 0.8483 - accuracy: 0.63 - ETA: 0s - loss: 0.8545 - accuracy: 0.62 - ETA: 0s - loss: 0.8564 - accuracy: 0.62 - ETA: 0s - loss: 0.8585 - accuracy: 0.6263\n",
      "Epoch 00700: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8585 - accuracy: 0.6263 - val_loss: 1.0844 - val_accuracy: 0.4834 - lr: 0.0010\n",
      "Epoch 701/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8922 - accuracy: 0.57 - ETA: 0s - loss: 0.8650 - accuracy: 0.60 - ETA: 0s - loss: 0.8832 - accuracy: 0.59 - ETA: 0s - loss: 0.8550 - accuracy: 0.61 - ETA: 0s - loss: 0.8583 - accuracy: 0.61 - ETA: 0s - loss: 0.8500 - accuracy: 0.63 - ETA: 0s - loss: 0.8476 - accuracy: 0.63 - ETA: 0s - loss: 0.8463 - accuracy: 0.63 - ETA: 0s - loss: 0.8494 - accuracy: 0.63 - ETA: 0s - loss: 0.8524 - accuracy: 0.62 - ETA: 0s - loss: 0.8480 - accuracy: 0.63 - ETA: 0s - loss: 0.8414 - accuracy: 0.63 - ETA: 0s - loss: 0.8232 - accuracy: 0.65 - ETA: 0s - loss: 0.8312 - accuracy: 0.64 - ETA: 0s - loss: 0.8434 - accuracy: 0.63 - ETA: 0s - loss: 0.8466 - accuracy: 0.63 - ETA: 0s - loss: 0.8529 - accuracy: 0.62 - ETA: 0s - loss: 0.8551 - accuracy: 0.62 - ETA: 0s - loss: 0.8568 - accuracy: 0.6265\n",
      "Epoch 00701: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8568 - accuracy: 0.6265 - val_loss: 1.0878 - val_accuracy: 0.4813 - lr: 0.0010\n",
      "Epoch 702/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8978 - accuracy: 0.55 - ETA: 0s - loss: 0.8685 - accuracy: 0.58 - ETA: 0s - loss: 0.8857 - accuracy: 0.58 - ETA: 0s - loss: 0.8563 - accuracy: 0.61 - ETA: 0s - loss: 0.8562 - accuracy: 0.61 - ETA: 0s - loss: 0.8491 - accuracy: 0.62 - ETA: 0s - loss: 0.8487 - accuracy: 0.62 - ETA: 0s - loss: 0.8480 - accuracy: 0.62 - ETA: 0s - loss: 0.8518 - accuracy: 0.62 - ETA: 0s - loss: 0.8570 - accuracy: 0.61 - ETA: 0s - loss: 0.8528 - accuracy: 0.62 - ETA: 0s - loss: 0.8469 - accuracy: 0.63 - ETA: 0s - loss: 0.8282 - accuracy: 0.64 - ETA: 0s - loss: 0.8343 - accuracy: 0.64 - ETA: 0s - loss: 0.8473 - accuracy: 0.62 - ETA: 0s - loss: 0.8506 - accuracy: 0.62 - ETA: 0s - loss: 0.8570 - accuracy: 0.62 - ETA: 0s - loss: 0.8591 - accuracy: 0.62 - ETA: 0s - loss: 0.8603 - accuracy: 0.6200\n",
      "Epoch 00702: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8603 - accuracy: 0.6200 - val_loss: 1.0853 - val_accuracy: 0.4829 - lr: 0.0010\n",
      "Epoch 703/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8941 - accuracy: 0.57 - ETA: 0s - loss: 0.8702 - accuracy: 0.61 - ETA: 0s - loss: 0.8877 - accuracy: 0.59 - ETA: 0s - loss: 0.8602 - accuracy: 0.61 - ETA: 0s - loss: 0.8606 - accuracy: 0.61 - ETA: 0s - loss: 0.8535 - accuracy: 0.62 - ETA: 0s - loss: 0.8503 - accuracy: 0.63 - ETA: 0s - loss: 0.8509 - accuracy: 0.63 - ETA: 0s - loss: 0.8537 - accuracy: 0.63 - ETA: 0s - loss: 0.8602 - accuracy: 0.62 - ETA: 0s - loss: 0.8499 - accuracy: 0.63 - ETA: 0s - loss: 0.8311 - accuracy: 0.64 - ETA: 0s - loss: 0.8364 - accuracy: 0.64 - ETA: 0s - loss: 0.8473 - accuracy: 0.63 - ETA: 0s - loss: 0.8512 - accuracy: 0.63 - ETA: 0s - loss: 0.8567 - accuracy: 0.62 - ETA: 0s - loss: 0.8585 - accuracy: 0.62 - ETA: 0s - loss: 0.8596 - accuracy: 0.6265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00703: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8596 - accuracy: 0.6265 - val_loss: 1.0718 - val_accuracy: 0.4920 - lr: 0.0010\n",
      "Epoch 704/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8757 - accuracy: 0.54 - ETA: 0s - loss: 0.8529 - accuracy: 0.58 - ETA: 0s - loss: 0.8717 - accuracy: 0.58 - ETA: 0s - loss: 0.8466 - accuracy: 0.60 - ETA: 0s - loss: 0.8483 - accuracy: 0.61 - ETA: 0s - loss: 0.8424 - accuracy: 0.62 - ETA: 0s - loss: 0.8402 - accuracy: 0.62 - ETA: 0s - loss: 0.8391 - accuracy: 0.63 - ETA: 0s - loss: 0.8416 - accuracy: 0.63 - ETA: 0s - loss: 0.8481 - accuracy: 0.62 - ETA: 0s - loss: 0.8439 - accuracy: 0.63 - ETA: 0s - loss: 0.8385 - accuracy: 0.63 - ETA: 0s - loss: 0.8209 - accuracy: 0.65 - ETA: 0s - loss: 0.8278 - accuracy: 0.64 - ETA: 0s - loss: 0.8401 - accuracy: 0.63 - ETA: 0s - loss: 0.8439 - accuracy: 0.63 - ETA: 0s - loss: 0.8506 - accuracy: 0.62 - ETA: 0s - loss: 0.8529 - accuracy: 0.62 - ETA: 0s - loss: 0.8538 - accuracy: 0.6253\n",
      "Epoch 00704: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8538 - accuracy: 0.6253 - val_loss: 1.0754 - val_accuracy: 0.4894 - lr: 0.0010\n",
      "Epoch 705/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9115 - accuracy: 0.54 - ETA: 0s - loss: 0.8710 - accuracy: 0.59 - ETA: 0s - loss: 0.8776 - accuracy: 0.59 - ETA: 0s - loss: 0.8516 - accuracy: 0.61 - ETA: 0s - loss: 0.8553 - accuracy: 0.62 - ETA: 0s - loss: 0.8495 - accuracy: 0.63 - ETA: 0s - loss: 0.8461 - accuracy: 0.63 - ETA: 0s - loss: 0.8461 - accuracy: 0.63 - ETA: 0s - loss: 0.8496 - accuracy: 0.63 - ETA: 0s - loss: 0.8550 - accuracy: 0.62 - ETA: 0s - loss: 0.8514 - accuracy: 0.63 - ETA: 0s - loss: 0.8435 - accuracy: 0.63 - ETA: 0s - loss: 0.8255 - accuracy: 0.65 - ETA: 0s - loss: 0.8328 - accuracy: 0.64 - ETA: 0s - loss: 0.8430 - accuracy: 0.63 - ETA: 0s - loss: 0.8456 - accuracy: 0.63 - ETA: 0s - loss: 0.8518 - accuracy: 0.62 - ETA: 0s - loss: 0.8534 - accuracy: 0.63 - ETA: 0s - loss: 0.8549 - accuracy: 0.6286\n",
      "Epoch 00705: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8549 - accuracy: 0.6286 - val_loss: 1.0691 - val_accuracy: 0.4919 - lr: 0.0010\n",
      "Epoch 706/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9312 - accuracy: 0.54 - ETA: 0s - loss: 0.8807 - accuracy: 0.58 - ETA: 0s - loss: 0.8904 - accuracy: 0.58 - ETA: 0s - loss: 0.8619 - accuracy: 0.60 - ETA: 0s - loss: 0.8626 - accuracy: 0.61 - ETA: 0s - loss: 0.8534 - accuracy: 0.62 - ETA: 0s - loss: 0.8499 - accuracy: 0.62 - ETA: 0s - loss: 0.8491 - accuracy: 0.62 - ETA: 0s - loss: 0.8520 - accuracy: 0.62 - ETA: 0s - loss: 0.8590 - accuracy: 0.61 - ETA: 0s - loss: 0.8551 - accuracy: 0.62 - ETA: 0s - loss: 0.8505 - accuracy: 0.62 - ETA: 0s - loss: 0.8320 - accuracy: 0.64 - ETA: 0s - loss: 0.8378 - accuracy: 0.63 - ETA: 0s - loss: 0.8487 - accuracy: 0.62 - ETA: 0s - loss: 0.8514 - accuracy: 0.62 - ETA: 0s - loss: 0.8586 - accuracy: 0.62 - ETA: 0s - loss: 0.8603 - accuracy: 0.62 - ETA: 0s - loss: 0.8613 - accuracy: 0.6215\n",
      "Epoch 00706: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8613 - accuracy: 0.6215 - val_loss: 1.0848 - val_accuracy: 0.4866 - lr: 0.0010\n",
      "Epoch 707/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9042 - accuracy: 0.56 - ETA: 0s - loss: 0.8765 - accuracy: 0.59 - ETA: 0s - loss: 0.8845 - accuracy: 0.59 - ETA: 0s - loss: 0.8567 - accuracy: 0.61 - ETA: 0s - loss: 0.8593 - accuracy: 0.61 - ETA: 0s - loss: 0.8526 - accuracy: 0.62 - ETA: 0s - loss: 0.8495 - accuracy: 0.63 - ETA: 0s - loss: 0.8485 - accuracy: 0.63 - ETA: 0s - loss: 0.8516 - accuracy: 0.63 - ETA: 0s - loss: 0.8585 - accuracy: 0.62 - ETA: 0s - loss: 0.8543 - accuracy: 0.63 - ETA: 0s - loss: 0.8463 - accuracy: 0.63 - ETA: 0s - loss: 0.8283 - accuracy: 0.65 - ETA: 0s - loss: 0.8339 - accuracy: 0.64 - ETA: 0s - loss: 0.8475 - accuracy: 0.63 - ETA: 0s - loss: 0.8504 - accuracy: 0.63 - ETA: 0s - loss: 0.8568 - accuracy: 0.62 - ETA: 0s - loss: 0.8587 - accuracy: 0.62 - ETA: 0s - loss: 0.8602 - accuracy: 0.6272\n",
      "Epoch 00707: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8602 - accuracy: 0.6272 - val_loss: 1.0791 - val_accuracy: 0.4862 - lr: 0.0010\n",
      "Epoch 708/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8884 - accuracy: 0.56 - ETA: 0s - loss: 0.8544 - accuracy: 0.60 - ETA: 0s - loss: 0.8717 - accuracy: 0.59 - ETA: 0s - loss: 0.8482 - accuracy: 0.61 - ETA: 0s - loss: 0.8496 - accuracy: 0.61 - ETA: 0s - loss: 0.8420 - accuracy: 0.63 - ETA: 0s - loss: 0.8402 - accuracy: 0.63 - ETA: 0s - loss: 0.8396 - accuracy: 0.63 - ETA: 0s - loss: 0.8418 - accuracy: 0.63 - ETA: 0s - loss: 0.8486 - accuracy: 0.62 - ETA: 0s - loss: 0.8445 - accuracy: 0.63 - ETA: 0s - loss: 0.8381 - accuracy: 0.63 - ETA: 0s - loss: 0.8206 - accuracy: 0.65 - ETA: 0s - loss: 0.8272 - accuracy: 0.64 - ETA: 0s - loss: 0.8393 - accuracy: 0.63 - ETA: 0s - loss: 0.8426 - accuracy: 0.63 - ETA: 0s - loss: 0.8488 - accuracy: 0.62 - ETA: 0s - loss: 0.8513 - accuracy: 0.62 - ETA: 0s - loss: 0.8530 - accuracy: 0.6259\n",
      "Epoch 00708: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8530 - accuracy: 0.6259 - val_loss: 1.0764 - val_accuracy: 0.4884 - lr: 0.0010\n",
      "Epoch 709/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9047 - accuracy: 0.56 - ETA: 0s - loss: 0.8824 - accuracy: 0.58 - ETA: 0s - loss: 0.8927 - accuracy: 0.59 - ETA: 0s - loss: 0.8624 - accuracy: 0.61 - ETA: 0s - loss: 0.8644 - accuracy: 0.61 - ETA: 0s - loss: 0.8554 - accuracy: 0.62 - ETA: 0s - loss: 0.8509 - accuracy: 0.63 - ETA: 0s - loss: 0.8504 - accuracy: 0.63 - ETA: 0s - loss: 0.8521 - accuracy: 0.63 - ETA: 0s - loss: 0.8576 - accuracy: 0.62 - ETA: 0s - loss: 0.8526 - accuracy: 0.63 - ETA: 0s - loss: 0.8459 - accuracy: 0.63 - ETA: 0s - loss: 0.8277 - accuracy: 0.65 - ETA: 0s - loss: 0.8341 - accuracy: 0.64 - ETA: 0s - loss: 0.8465 - accuracy: 0.63 - ETA: 0s - loss: 0.8502 - accuracy: 0.63 - ETA: 0s - loss: 0.8560 - accuracy: 0.62 - ETA: 0s - loss: 0.8577 - accuracy: 0.62 - ETA: 0s - loss: 0.8590 - accuracy: 0.6277\n",
      "Epoch 00709: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8590 - accuracy: 0.6277 - val_loss: 1.0682 - val_accuracy: 0.4932 - lr: 0.0010\n",
      "Epoch 710/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9037 - accuracy: 0.54 - ETA: 0s - loss: 0.8683 - accuracy: 0.58 - ETA: 0s - loss: 0.8851 - accuracy: 0.59 - ETA: 0s - loss: 0.8559 - accuracy: 0.61 - ETA: 0s - loss: 0.8542 - accuracy: 0.61 - ETA: 0s - loss: 0.8476 - accuracy: 0.62 - ETA: 0s - loss: 0.8458 - accuracy: 0.62 - ETA: 0s - loss: 0.8474 - accuracy: 0.62 - ETA: 0s - loss: 0.8494 - accuracy: 0.62 - ETA: 0s - loss: 0.8549 - accuracy: 0.62 - ETA: 0s - loss: 0.8506 - accuracy: 0.62 - ETA: 0s - loss: 0.8442 - accuracy: 0.63 - ETA: 0s - loss: 0.8263 - accuracy: 0.64 - ETA: 0s - loss: 0.8315 - accuracy: 0.64 - ETA: 0s - loss: 0.8420 - accuracy: 0.63 - ETA: 0s - loss: 0.8454 - accuracy: 0.63 - ETA: 0s - loss: 0.8526 - accuracy: 0.62 - ETA: 0s - loss: 0.8547 - accuracy: 0.62 - ETA: 0s - loss: 0.8562 - accuracy: 0.6249\n",
      "Epoch 00710: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8562 - accuracy: 0.6249 - val_loss: 1.0617 - val_accuracy: 0.5003 - lr: 0.0010\n",
      "Epoch 711/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9029 - accuracy: 0.54 - ETA: 0s - loss: 0.8742 - accuracy: 0.59 - ETA: 0s - loss: 0.8874 - accuracy: 0.58 - ETA: 0s - loss: 0.8582 - accuracy: 0.60 - ETA: 0s - loss: 0.8592 - accuracy: 0.61 - ETA: 0s - loss: 0.8505 - accuracy: 0.62 - ETA: 0s - loss: 0.8473 - accuracy: 0.62 - ETA: 0s - loss: 0.8483 - accuracy: 0.62 - ETA: 0s - loss: 0.8496 - accuracy: 0.62 - ETA: 0s - loss: 0.8566 - accuracy: 0.61 - ETA: 0s - loss: 0.8512 - accuracy: 0.62 - ETA: 0s - loss: 0.8440 - accuracy: 0.63 - ETA: 0s - loss: 0.8256 - accuracy: 0.64 - ETA: 0s - loss: 0.8312 - accuracy: 0.64 - ETA: 0s - loss: 0.8415 - accuracy: 0.63 - ETA: 0s - loss: 0.8453 - accuracy: 0.63 - ETA: 0s - loss: 0.8511 - accuracy: 0.62 - ETA: 0s - loss: 0.8538 - accuracy: 0.62 - ETA: 0s - loss: 0.8557 - accuracy: 0.6278\n",
      "Epoch 00711: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00711: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8557 - accuracy: 0.6278 - val_loss: 1.0527 - val_accuracy: 0.5005 - lr: 0.0010\n",
      "Epoch 712/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8865 - accuracy: 0.59 - ETA: 0s - loss: 0.8622 - accuracy: 0.60 - ETA: 0s - loss: 0.8842 - accuracy: 0.59 - ETA: 0s - loss: 0.8550 - accuracy: 0.61 - ETA: 0s - loss: 0.8562 - accuracy: 0.62 - ETA: 0s - loss: 0.8480 - accuracy: 0.63 - ETA: 0s - loss: 0.8452 - accuracy: 0.63 - ETA: 0s - loss: 0.8446 - accuracy: 0.63 - ETA: 0s - loss: 0.8473 - accuracy: 0.63 - ETA: 0s - loss: 0.8550 - accuracy: 0.62 - ETA: 0s - loss: 0.8495 - accuracy: 0.63 - ETA: 0s - loss: 0.8428 - accuracy: 0.64 - ETA: 0s - loss: 0.8238 - accuracy: 0.65 - ETA: 0s - loss: 0.8308 - accuracy: 0.64 - ETA: 0s - loss: 0.8420 - accuracy: 0.63 - ETA: 0s - loss: 0.8459 - accuracy: 0.63 - ETA: 0s - loss: 0.8516 - accuracy: 0.63 - ETA: 0s - loss: 0.8529 - accuracy: 0.63 - ETA: 0s - loss: 0.8541 - accuracy: 0.6290\n",
      "Epoch 00712: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8541 - accuracy: 0.6290 - val_loss: 1.0531 - val_accuracy: 0.5002 - lr: 0.0010\n",
      "Epoch 713/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9038 - accuracy: 0.57 - ETA: 0s - loss: 0.8664 - accuracy: 0.59 - ETA: 0s - loss: 0.8756 - accuracy: 0.59 - ETA: 0s - loss: 0.8464 - accuracy: 0.61 - ETA: 0s - loss: 0.8496 - accuracy: 0.61 - ETA: 0s - loss: 0.8444 - accuracy: 0.62 - ETA: 0s - loss: 0.8434 - accuracy: 0.63 - ETA: 0s - loss: 0.8441 - accuracy: 0.63 - ETA: 0s - loss: 0.8456 - accuracy: 0.63 - ETA: 0s - loss: 0.8531 - accuracy: 0.62 - ETA: 0s - loss: 0.8497 - accuracy: 0.63 - ETA: 0s - loss: 0.8429 - accuracy: 0.63 - ETA: 0s - loss: 0.8247 - accuracy: 0.65 - ETA: 0s - loss: 0.8293 - accuracy: 0.64 - ETA: 0s - loss: 0.8410 - accuracy: 0.63 - ETA: 0s - loss: 0.8452 - accuracy: 0.63 - ETA: 0s - loss: 0.8501 - accuracy: 0.63 - ETA: 0s - loss: 0.8525 - accuracy: 0.63 - ETA: 0s - loss: 0.8538 - accuracy: 0.6289\n",
      "Epoch 00713: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8538 - accuracy: 0.6289 - val_loss: 1.0550 - val_accuracy: 0.4959 - lr: 0.0010\n",
      "Epoch 714/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9115 - accuracy: 0.55 - ETA: 0s - loss: 0.8686 - accuracy: 0.59 - ETA: 0s - loss: 0.8775 - accuracy: 0.60 - ETA: 0s - loss: 0.8511 - accuracy: 0.62 - ETA: 0s - loss: 0.8536 - accuracy: 0.62 - ETA: 0s - loss: 0.8463 - accuracy: 0.63 - ETA: 0s - loss: 0.8438 - accuracy: 0.63 - ETA: 0s - loss: 0.8456 - accuracy: 0.63 - ETA: 0s - loss: 0.8474 - accuracy: 0.63 - ETA: 0s - loss: 0.8538 - accuracy: 0.62 - ETA: 0s - loss: 0.8485 - accuracy: 0.63 - ETA: 0s - loss: 0.8413 - accuracy: 0.63 - ETA: 0s - loss: 0.8233 - accuracy: 0.65 - ETA: 0s - loss: 0.8288 - accuracy: 0.64 - ETA: 0s - loss: 0.8401 - accuracy: 0.63 - ETA: 0s - loss: 0.8439 - accuracy: 0.63 - ETA: 0s - loss: 0.8501 - accuracy: 0.62 - ETA: 0s - loss: 0.8523 - accuracy: 0.62 - ETA: 0s - loss: 0.8541 - accuracy: 0.6269\n",
      "Epoch 00714: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8541 - accuracy: 0.6269 - val_loss: 1.0496 - val_accuracy: 0.4985 - lr: 0.0010\n",
      "Epoch 715/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9103 - accuracy: 0.56 - ETA: 0s - loss: 0.8846 - accuracy: 0.60 - ETA: 0s - loss: 0.8972 - accuracy: 0.59 - ETA: 0s - loss: 0.8638 - accuracy: 0.61 - ETA: 0s - loss: 0.8648 - accuracy: 0.61 - ETA: 0s - loss: 0.8556 - accuracy: 0.62 - ETA: 0s - loss: 0.8528 - accuracy: 0.63 - ETA: 0s - loss: 0.8517 - accuracy: 0.63 - ETA: 0s - loss: 0.8532 - accuracy: 0.63 - ETA: 0s - loss: 0.8565 - accuracy: 0.62 - ETA: 0s - loss: 0.8517 - accuracy: 0.63 - ETA: 0s - loss: 0.8460 - accuracy: 0.63 - ETA: 0s - loss: 0.8285 - accuracy: 0.65 - ETA: 0s - loss: 0.8340 - accuracy: 0.64 - ETA: 0s - loss: 0.8467 - accuracy: 0.63 - ETA: 0s - loss: 0.8494 - accuracy: 0.63 - ETA: 0s - loss: 0.8557 - accuracy: 0.62 - ETA: 0s - loss: 0.8583 - accuracy: 0.62 - ETA: 0s - loss: 0.8595 - accuracy: 0.6250\n",
      "Epoch 00715: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8595 - accuracy: 0.6250 - val_loss: 1.0513 - val_accuracy: 0.4967 - lr: 0.0010\n",
      "Epoch 716/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9087 - accuracy: 0.54 - ETA: 0s - loss: 0.8702 - accuracy: 0.59 - ETA: 0s - loss: 0.8742 - accuracy: 0.59 - ETA: 0s - loss: 0.8484 - accuracy: 0.61 - ETA: 0s - loss: 0.8530 - accuracy: 0.61 - ETA: 0s - loss: 0.8485 - accuracy: 0.62 - ETA: 0s - loss: 0.8457 - accuracy: 0.63 - ETA: 0s - loss: 0.8450 - accuracy: 0.63 - ETA: 0s - loss: 0.8483 - accuracy: 0.63 - ETA: 0s - loss: 0.8557 - accuracy: 0.62 - ETA: 0s - loss: 0.8504 - accuracy: 0.63 - ETA: 0s - loss: 0.8441 - accuracy: 0.63 - ETA: 0s - loss: 0.8257 - accuracy: 0.65 - ETA: 0s - loss: 0.8334 - accuracy: 0.64 - ETA: 0s - loss: 0.8455 - accuracy: 0.63 - ETA: 0s - loss: 0.8491 - accuracy: 0.62 - ETA: 0s - loss: 0.8553 - accuracy: 0.62 - ETA: 0s - loss: 0.8570 - accuracy: 0.62 - ETA: 0s - loss: 0.8581 - accuracy: 0.6251\n",
      "Epoch 00716: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8581 - accuracy: 0.6251 - val_loss: 1.0670 - val_accuracy: 0.4888 - lr: 0.0010\n",
      "Epoch 717/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8869 - accuracy: 0.58 - ETA: 0s - loss: 0.8520 - accuracy: 0.61 - ETA: 0s - loss: 0.8723 - accuracy: 0.60 - ETA: 0s - loss: 0.8512 - accuracy: 0.62 - ETA: 0s - loss: 0.8498 - accuracy: 0.62 - ETA: 0s - loss: 0.8441 - accuracy: 0.63 - ETA: 0s - loss: 0.8431 - accuracy: 0.63 - ETA: 0s - loss: 0.8452 - accuracy: 0.63 - ETA: 0s - loss: 0.8469 - accuracy: 0.63 - ETA: 0s - loss: 0.8538 - accuracy: 0.62 - ETA: 0s - loss: 0.8497 - accuracy: 0.63 - ETA: 0s - loss: 0.8437 - accuracy: 0.63 - ETA: 0s - loss: 0.8254 - accuracy: 0.65 - ETA: 0s - loss: 0.8305 - accuracy: 0.64 - ETA: 0s - loss: 0.8417 - accuracy: 0.63 - ETA: 0s - loss: 0.8449 - accuracy: 0.63 - ETA: 0s - loss: 0.8513 - accuracy: 0.62 - ETA: 0s - loss: 0.8538 - accuracy: 0.62 - ETA: 0s - loss: 0.8560 - accuracy: 0.6274\n",
      "Epoch 00717: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8560 - accuracy: 0.6274 - val_loss: 1.0706 - val_accuracy: 0.4863 - lr: 0.0010\n",
      "Epoch 718/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9022 - accuracy: 0.57 - ETA: 0s - loss: 0.8683 - accuracy: 0.61 - ETA: 0s - loss: 0.8845 - accuracy: 0.60 - ETA: 0s - loss: 0.8551 - accuracy: 0.62 - ETA: 0s - loss: 0.8576 - accuracy: 0.62 - ETA: 0s - loss: 0.8487 - accuracy: 0.63 - ETA: 0s - loss: 0.8467 - accuracy: 0.63 - ETA: 0s - loss: 0.8456 - accuracy: 0.63 - ETA: 0s - loss: 0.8473 - accuracy: 0.63 - ETA: 0s - loss: 0.8522 - accuracy: 0.63 - ETA: 0s - loss: 0.8482 - accuracy: 0.63 - ETA: 0s - loss: 0.8425 - accuracy: 0.64 - ETA: 0s - loss: 0.8249 - accuracy: 0.65 - ETA: 0s - loss: 0.8298 - accuracy: 0.65 - ETA: 0s - loss: 0.8419 - accuracy: 0.64 - ETA: 0s - loss: 0.8449 - accuracy: 0.63 - ETA: 0s - loss: 0.8509 - accuracy: 0.63 - ETA: 0s - loss: 0.8557 - accuracy: 0.6317\n",
      "Epoch 00718: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8557 - accuracy: 0.6317 - val_loss: 1.0646 - val_accuracy: 0.4922 - lr: 0.0010\n",
      "Epoch 719/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9104 - accuracy: 0.53 - ETA: 0s - loss: 0.8755 - accuracy: 0.59 - ETA: 0s - loss: 0.8839 - accuracy: 0.59 - ETA: 0s - loss: 0.8535 - accuracy: 0.61 - ETA: 0s - loss: 0.8508 - accuracy: 0.62 - ETA: 0s - loss: 0.8444 - accuracy: 0.62 - ETA: 0s - loss: 0.8417 - accuracy: 0.63 - ETA: 0s - loss: 0.8448 - accuracy: 0.63 - ETA: 0s - loss: 0.8519 - accuracy: 0.62 - ETA: 0s - loss: 0.8483 - accuracy: 0.63 - ETA: 0s - loss: 0.8419 - accuracy: 0.64 - ETA: 0s - loss: 0.8246 - accuracy: 0.65 - ETA: 0s - loss: 0.8301 - accuracy: 0.65 - ETA: 0s - loss: 0.8422 - accuracy: 0.63 - ETA: 0s - loss: 0.8451 - accuracy: 0.63 - ETA: 0s - loss: 0.8516 - accuracy: 0.62 - ETA: 0s - loss: 0.8539 - accuracy: 0.62 - ETA: 0s - loss: 0.8555 - accuracy: 0.6283\n",
      "Epoch 00719: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8555 - accuracy: 0.6283 - val_loss: 1.0622 - val_accuracy: 0.4922 - lr: 0.0010\n",
      "Epoch 720/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9165 - accuracy: 0.55 - ETA: 0s - loss: 0.8761 - accuracy: 0.60 - ETA: 0s - loss: 0.8853 - accuracy: 0.60 - ETA: 0s - loss: 0.8570 - accuracy: 0.62 - ETA: 0s - loss: 0.8569 - accuracy: 0.62 - ETA: 0s - loss: 0.8506 - accuracy: 0.63 - ETA: 0s - loss: 0.8468 - accuracy: 0.63 - ETA: 0s - loss: 0.8458 - accuracy: 0.63 - ETA: 0s - loss: 0.8477 - accuracy: 0.63 - ETA: 0s - loss: 0.8529 - accuracy: 0.62 - ETA: 0s - loss: 0.8494 - accuracy: 0.63 - ETA: 0s - loss: 0.8432 - accuracy: 0.64 - ETA: 0s - loss: 0.8249 - accuracy: 0.65 - ETA: 0s - loss: 0.8298 - accuracy: 0.64 - ETA: 0s - loss: 0.8417 - accuracy: 0.63 - ETA: 0s - loss: 0.8441 - accuracy: 0.63 - ETA: 0s - loss: 0.8515 - accuracy: 0.63 - ETA: 0s - loss: 0.8537 - accuracy: 0.63 - ETA: 0s - loss: 0.8554 - accuracy: 0.6296\n",
      "Epoch 00720: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8554 - accuracy: 0.6296 - val_loss: 1.0570 - val_accuracy: 0.4951 - lr: 0.0010\n",
      "Epoch 721/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9140 - accuracy: 0.55 - ETA: 0s - loss: 0.8760 - accuracy: 0.59 - ETA: 0s - loss: 0.8828 - accuracy: 0.59 - ETA: 0s - loss: 0.8529 - accuracy: 0.61 - ETA: 0s - loss: 0.8549 - accuracy: 0.61 - ETA: 0s - loss: 0.8478 - accuracy: 0.62 - ETA: 0s - loss: 0.8467 - accuracy: 0.63 - ETA: 0s - loss: 0.8476 - accuracy: 0.63 - ETA: 0s - loss: 0.8499 - accuracy: 0.63 - ETA: 0s - loss: 0.8550 - accuracy: 0.62 - ETA: 0s - loss: 0.8500 - accuracy: 0.63 - ETA: 0s - loss: 0.8431 - accuracy: 0.63 - ETA: 0s - loss: 0.8253 - accuracy: 0.65 - ETA: 0s - loss: 0.8300 - accuracy: 0.64 - ETA: 0s - loss: 0.8411 - accuracy: 0.63 - ETA: 0s - loss: 0.8446 - accuracy: 0.63 - ETA: 0s - loss: 0.8510 - accuracy: 0.62 - ETA: 0s - loss: 0.8535 - accuracy: 0.62 - ETA: 0s - loss: 0.8548 - accuracy: 0.6283\n",
      "Epoch 00721: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8548 - accuracy: 0.6283 - val_loss: 1.0589 - val_accuracy: 0.4956 - lr: 0.0010\n",
      "Epoch 722/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9104 - accuracy: 0.56 - ETA: 0s - loss: 0.8746 - accuracy: 0.59 - ETA: 0s - loss: 0.8909 - accuracy: 0.59 - ETA: 0s - loss: 0.8606 - accuracy: 0.61 - ETA: 0s - loss: 0.8599 - accuracy: 0.61 - ETA: 0s - loss: 0.8521 - accuracy: 0.62 - ETA: 0s - loss: 0.8491 - accuracy: 0.63 - ETA: 0s - loss: 0.8487 - accuracy: 0.63 - ETA: 0s - loss: 0.8508 - accuracy: 0.63 - ETA: 0s - loss: 0.8574 - accuracy: 0.62 - ETA: 0s - loss: 0.8521 - accuracy: 0.63 - ETA: 0s - loss: 0.8461 - accuracy: 0.63 - ETA: 0s - loss: 0.8278 - accuracy: 0.65 - ETA: 0s - loss: 0.8340 - accuracy: 0.64 - ETA: 0s - loss: 0.8462 - accuracy: 0.63 - ETA: 0s - loss: 0.8483 - accuracy: 0.63 - ETA: 0s - loss: 0.8535 - accuracy: 0.62 - ETA: 0s - loss: 0.8563 - accuracy: 0.62 - ETA: 0s - loss: 0.8591 - accuracy: 0.6255\n",
      "Epoch 00722: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8591 - accuracy: 0.6255 - val_loss: 1.0616 - val_accuracy: 0.4930 - lr: 0.0010\n",
      "Epoch 723/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9017 - accuracy: 0.56 - ETA: 0s - loss: 0.8653 - accuracy: 0.60 - ETA: 0s - loss: 0.8831 - accuracy: 0.59 - ETA: 0s - loss: 0.8571 - accuracy: 0.61 - ETA: 0s - loss: 0.8595 - accuracy: 0.61 - ETA: 0s - loss: 0.8528 - accuracy: 0.62 - ETA: 0s - loss: 0.8495 - accuracy: 0.63 - ETA: 0s - loss: 0.8475 - accuracy: 0.63 - ETA: 0s - loss: 0.8490 - accuracy: 0.63 - ETA: 0s - loss: 0.8554 - accuracy: 0.62 - ETA: 0s - loss: 0.8510 - accuracy: 0.63 - ETA: 0s - loss: 0.8443 - accuracy: 0.63 - ETA: 0s - loss: 0.8264 - accuracy: 0.65 - ETA: 0s - loss: 0.8327 - accuracy: 0.64 - ETA: 0s - loss: 0.8429 - accuracy: 0.63 - ETA: 0s - loss: 0.8465 - accuracy: 0.63 - ETA: 0s - loss: 0.8520 - accuracy: 0.62 - ETA: 0s - loss: 0.8529 - accuracy: 0.63 - ETA: 0s - loss: 0.8547 - accuracy: 0.6293\n",
      "Epoch 00723: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8547 - accuracy: 0.6293 - val_loss: 1.0752 - val_accuracy: 0.4826 - lr: 0.0010\n",
      "Epoch 724/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8978 - accuracy: 0.56 - ETA: 0s - loss: 0.8595 - accuracy: 0.60 - ETA: 0s - loss: 0.8688 - accuracy: 0.60 - ETA: 0s - loss: 0.8433 - accuracy: 0.62 - ETA: 0s - loss: 0.8471 - accuracy: 0.62 - ETA: 0s - loss: 0.8427 - accuracy: 0.63 - ETA: 0s - loss: 0.8413 - accuracy: 0.63 - ETA: 0s - loss: 0.8400 - accuracy: 0.63 - ETA: 0s - loss: 0.8440 - accuracy: 0.63 - ETA: 0s - loss: 0.8494 - accuracy: 0.62 - ETA: 0s - loss: 0.8448 - accuracy: 0.63 - ETA: 0s - loss: 0.8387 - accuracy: 0.63 - ETA: 0s - loss: 0.8207 - accuracy: 0.65 - ETA: 0s - loss: 0.8271 - accuracy: 0.64 - ETA: 0s - loss: 0.8389 - accuracy: 0.63 - ETA: 0s - loss: 0.8427 - accuracy: 0.63 - ETA: 0s - loss: 0.8492 - accuracy: 0.62 - ETA: 0s - loss: 0.8513 - accuracy: 0.62 - ETA: 0s - loss: 0.8538 - accuracy: 0.6271\n",
      "Epoch 00724: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8538 - accuracy: 0.6271 - val_loss: 1.0689 - val_accuracy: 0.4879 - lr: 0.0010\n",
      "Epoch 725/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9034 - accuracy: 0.56 - ETA: 0s - loss: 0.8661 - accuracy: 0.60 - ETA: 0s - loss: 0.8789 - accuracy: 0.59 - ETA: 0s - loss: 0.8511 - accuracy: 0.61 - ETA: 0s - loss: 0.8544 - accuracy: 0.62 - ETA: 0s - loss: 0.8472 - accuracy: 0.63 - ETA: 0s - loss: 0.8460 - accuracy: 0.63 - ETA: 0s - loss: 0.8448 - accuracy: 0.63 - ETA: 0s - loss: 0.8463 - accuracy: 0.63 - ETA: 0s - loss: 0.8546 - accuracy: 0.62 - ETA: 0s - loss: 0.8501 - accuracy: 0.63 - ETA: 0s - loss: 0.8439 - accuracy: 0.63 - ETA: 0s - loss: 0.8256 - accuracy: 0.65 - ETA: 0s - loss: 0.8311 - accuracy: 0.64 - ETA: 0s - loss: 0.8417 - accuracy: 0.63 - ETA: 0s - loss: 0.8454 - accuracy: 0.63 - ETA: 0s - loss: 0.8523 - accuracy: 0.62 - ETA: 0s - loss: 0.8546 - accuracy: 0.62 - ETA: 0s - loss: 0.8567 - accuracy: 0.6268\n",
      "Epoch 00725: val_loss did not improve from 0.99131\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00725: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8567 - accuracy: 0.6268 - val_loss: 1.0698 - val_accuracy: 0.4883 - lr: 0.0010\n",
      "Epoch 726/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9253 - accuracy: 0.53 - ETA: 0s - loss: 0.8774 - accuracy: 0.58 - ETA: 0s - loss: 0.8882 - accuracy: 0.58 - ETA: 0s - loss: 0.8578 - accuracy: 0.60 - ETA: 0s - loss: 0.8562 - accuracy: 0.61 - ETA: 0s - loss: 0.8487 - accuracy: 0.62 - ETA: 0s - loss: 0.8440 - accuracy: 0.62 - ETA: 0s - loss: 0.8452 - accuracy: 0.63 - ETA: 0s - loss: 0.8482 - accuracy: 0.62 - ETA: 0s - loss: 0.8541 - accuracy: 0.62 - ETA: 0s - loss: 0.8491 - accuracy: 0.63 - ETA: 0s - loss: 0.8422 - accuracy: 0.63 - ETA: 0s - loss: 0.8241 - accuracy: 0.65 - ETA: 0s - loss: 0.8302 - accuracy: 0.64 - ETA: 0s - loss: 0.8448 - accuracy: 0.63 - ETA: 0s - loss: 0.8505 - accuracy: 0.62 - ETA: 0s - loss: 0.8529 - accuracy: 0.62 - ETA: 0s - loss: 0.8552 - accuracy: 0.6285\n",
      "Epoch 00726: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8552 - accuracy: 0.6285 - val_loss: 1.0683 - val_accuracy: 0.4907 - lr: 0.0010\n",
      "Epoch 727/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8967 - accuracy: 0.57 - ETA: 0s - loss: 0.8764 - accuracy: 0.59 - ETA: 0s - loss: 0.8884 - accuracy: 0.59 - ETA: 0s - loss: 0.8586 - accuracy: 0.61 - ETA: 0s - loss: 0.8600 - accuracy: 0.61 - ETA: 0s - loss: 0.8518 - accuracy: 0.62 - ETA: 0s - loss: 0.8507 - accuracy: 0.63 - ETA: 0s - loss: 0.8503 - accuracy: 0.63 - ETA: 0s - loss: 0.8516 - accuracy: 0.63 - ETA: 0s - loss: 0.8568 - accuracy: 0.62 - ETA: 0s - loss: 0.8525 - accuracy: 0.63 - ETA: 0s - loss: 0.8459 - accuracy: 0.63 - ETA: 0s - loss: 0.8273 - accuracy: 0.65 - ETA: 0s - loss: 0.8428 - accuracy: 0.63 - ETA: 0s - loss: 0.8475 - accuracy: 0.63 - ETA: 0s - loss: 0.8545 - accuracy: 0.62 - ETA: 0s - loss: 0.8566 - accuracy: 0.62 - ETA: 0s - loss: 0.8582 - accuracy: 0.6261\n",
      "Epoch 00727: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8582 - accuracy: 0.6261 - val_loss: 1.0581 - val_accuracy: 0.4888 - lr: 0.0010\n",
      "Epoch 728/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9122 - accuracy: 0.55 - ETA: 0s - loss: 0.8790 - accuracy: 0.59 - ETA: 0s - loss: 0.8946 - accuracy: 0.59 - ETA: 0s - loss: 0.8651 - accuracy: 0.61 - ETA: 0s - loss: 0.8647 - accuracy: 0.61 - ETA: 0s - loss: 0.8576 - accuracy: 0.62 - ETA: 0s - loss: 0.8532 - accuracy: 0.63 - ETA: 0s - loss: 0.8519 - accuracy: 0.63 - ETA: 0s - loss: 0.8550 - accuracy: 0.63 - ETA: 0s - loss: 0.8598 - accuracy: 0.62 - ETA: 0s - loss: 0.8539 - accuracy: 0.63 - ETA: 0s - loss: 0.8461 - accuracy: 0.63 - ETA: 0s - loss: 0.8274 - accuracy: 0.65 - ETA: 0s - loss: 0.8335 - accuracy: 0.64 - ETA: 0s - loss: 0.8434 - accuracy: 0.63 - ETA: 0s - loss: 0.8523 - accuracy: 0.63 - ETA: 0s - loss: 0.8547 - accuracy: 0.62 - ETA: 0s - loss: 0.8567 - accuracy: 0.6270\n",
      "Epoch 00728: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8567 - accuracy: 0.6270 - val_loss: 1.0584 - val_accuracy: 0.4927 - lr: 0.0010\n",
      "Epoch 729/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9014 - accuracy: 0.55 - ETA: 0s - loss: 0.8719 - accuracy: 0.59 - ETA: 0s - loss: 0.8804 - accuracy: 0.59 - ETA: 0s - loss: 0.8529 - accuracy: 0.61 - ETA: 0s - loss: 0.8550 - accuracy: 0.61 - ETA: 0s - loss: 0.8487 - accuracy: 0.62 - ETA: 0s - loss: 0.8456 - accuracy: 0.63 - ETA: 0s - loss: 0.8450 - accuracy: 0.63 - ETA: 0s - loss: 0.8456 - accuracy: 0.63 - ETA: 0s - loss: 0.8529 - accuracy: 0.62 - ETA: 0s - loss: 0.8482 - accuracy: 0.63 - ETA: 0s - loss: 0.8417 - accuracy: 0.63 - ETA: 0s - loss: 0.8234 - accuracy: 0.65 - ETA: 0s - loss: 0.8276 - accuracy: 0.64 - ETA: 0s - loss: 0.8375 - accuracy: 0.63 - ETA: 0s - loss: 0.8413 - accuracy: 0.63 - ETA: 0s - loss: 0.8471 - accuracy: 0.63 - ETA: 0s - loss: 0.8501 - accuracy: 0.63 - ETA: 0s - loss: 0.8518 - accuracy: 0.6284\n",
      "Epoch 00729: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8518 - accuracy: 0.6284 - val_loss: 1.0647 - val_accuracy: 0.4870 - lr: 0.0010\n",
      "Epoch 730/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9092 - accuracy: 0.57 - ETA: 0s - loss: 0.8698 - accuracy: 0.60 - ETA: 0s - loss: 0.8764 - accuracy: 0.60 - ETA: 0s - loss: 0.8486 - accuracy: 0.61 - ETA: 0s - loss: 0.8521 - accuracy: 0.62 - ETA: 0s - loss: 0.8451 - accuracy: 0.63 - ETA: 0s - loss: 0.8442 - accuracy: 0.63 - ETA: 0s - loss: 0.8428 - accuracy: 0.63 - ETA: 0s - loss: 0.8451 - accuracy: 0.63 - ETA: 0s - loss: 0.8505 - accuracy: 0.62 - ETA: 0s - loss: 0.8464 - accuracy: 0.63 - ETA: 0s - loss: 0.8400 - accuracy: 0.64 - ETA: 0s - loss: 0.8219 - accuracy: 0.65 - ETA: 0s - loss: 0.8279 - accuracy: 0.64 - ETA: 0s - loss: 0.8401 - accuracy: 0.63 - ETA: 0s - loss: 0.8435 - accuracy: 0.63 - ETA: 0s - loss: 0.8487 - accuracy: 0.63 - ETA: 0s - loss: 0.8537 - accuracy: 0.6287\n",
      "Epoch 00730: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8537 - accuracy: 0.6287 - val_loss: 1.0654 - val_accuracy: 0.4884 - lr: 0.0010\n",
      "Epoch 731/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9259 - accuracy: 0.55 - ETA: 0s - loss: 0.8838 - accuracy: 0.59 - ETA: 0s - loss: 0.8829 - accuracy: 0.59 - ETA: 0s - loss: 0.8554 - accuracy: 0.61 - ETA: 0s - loss: 0.8560 - accuracy: 0.62 - ETA: 0s - loss: 0.8472 - accuracy: 0.63 - ETA: 0s - loss: 0.8460 - accuracy: 0.63 - ETA: 0s - loss: 0.8457 - accuracy: 0.63 - ETA: 0s - loss: 0.8476 - accuracy: 0.63 - ETA: 0s - loss: 0.8547 - accuracy: 0.62 - ETA: 0s - loss: 0.8503 - accuracy: 0.63 - ETA: 0s - loss: 0.8442 - accuracy: 0.63 - ETA: 0s - loss: 0.8258 - accuracy: 0.65 - ETA: 0s - loss: 0.8313 - accuracy: 0.64 - ETA: 0s - loss: 0.8422 - accuracy: 0.63 - ETA: 0s - loss: 0.8521 - accuracy: 0.62 - ETA: 0s - loss: 0.8543 - accuracy: 0.62 - ETA: 0s - loss: 0.8558 - accuracy: 0.6271\n",
      "Epoch 00731: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8558 - accuracy: 0.6271 - val_loss: 1.0632 - val_accuracy: 0.4901 - lr: 0.0010\n",
      "Epoch 732/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.8991 - accuracy: 0.56 - ETA: 0s - loss: 0.8723 - accuracy: 0.59 - ETA: 0s - loss: 0.8837 - accuracy: 0.59 - ETA: 0s - loss: 0.8545 - accuracy: 0.61 - ETA: 0s - loss: 0.8585 - accuracy: 0.61 - ETA: 0s - loss: 0.8515 - accuracy: 0.62 - ETA: 0s - loss: 0.8474 - accuracy: 0.63 - ETA: 0s - loss: 0.8460 - accuracy: 0.63 - ETA: 0s - loss: 0.8482 - accuracy: 0.63 - ETA: 0s - loss: 0.8544 - accuracy: 0.62 - ETA: 0s - loss: 0.8499 - accuracy: 0.63 - ETA: 0s - loss: 0.8431 - accuracy: 0.63 - ETA: 0s - loss: 0.8253 - accuracy: 0.65 - ETA: 0s - loss: 0.8323 - accuracy: 0.64 - ETA: 0s - loss: 0.8462 - accuracy: 0.63 - ETA: 0s - loss: 0.8495 - accuracy: 0.63 - ETA: 0s - loss: 0.8547 - accuracy: 0.62 - ETA: 0s - loss: 0.8568 - accuracy: 0.6298\n",
      "Epoch 00732: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8578 - accuracy: 0.6283 - val_loss: 1.0676 - val_accuracy: 0.4878 - lr: 0.0010\n",
      "Epoch 733/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9174 - accuracy: 0.55 - ETA: 0s - loss: 0.8754 - accuracy: 0.59 - ETA: 0s - loss: 0.8823 - accuracy: 0.59 - ETA: 0s - loss: 0.8549 - accuracy: 0.61 - ETA: 0s - loss: 0.8557 - accuracy: 0.61 - ETA: 0s - loss: 0.8472 - accuracy: 0.62 - ETA: 0s - loss: 0.8473 - accuracy: 0.63 - ETA: 0s - loss: 0.8474 - accuracy: 0.63 - ETA: 0s - loss: 0.8495 - accuracy: 0.63 - ETA: 0s - loss: 0.8552 - accuracy: 0.62 - ETA: 0s - loss: 0.8503 - accuracy: 0.63 - ETA: 0s - loss: 0.8435 - accuracy: 0.63 - ETA: 0s - loss: 0.8249 - accuracy: 0.65 - ETA: 0s - loss: 0.8292 - accuracy: 0.64 - ETA: 0s - loss: 0.8383 - accuracy: 0.63 - ETA: 0s - loss: 0.8416 - accuracy: 0.63 - ETA: 0s - loss: 0.8486 - accuracy: 0.63 - ETA: 0s - loss: 0.8509 - accuracy: 0.63 - ETA: 0s - loss: 0.8520 - accuracy: 0.6310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00733: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8520 - accuracy: 0.6310 - val_loss: 1.0582 - val_accuracy: 0.4933 - lr: 0.0010\n",
      "Epoch 734/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9030 - accuracy: 0.55 - ETA: 0s - loss: 0.8716 - accuracy: 0.59 - ETA: 0s - loss: 0.8827 - accuracy: 0.60 - ETA: 0s - loss: 0.8537 - accuracy: 0.61 - ETA: 0s - loss: 0.8571 - accuracy: 0.62 - ETA: 0s - loss: 0.8508 - accuracy: 0.63 - ETA: 0s - loss: 0.8498 - accuracy: 0.63 - ETA: 0s - loss: 0.8490 - accuracy: 0.63 - ETA: 0s - loss: 0.8501 - accuracy: 0.63 - ETA: 0s - loss: 0.8564 - accuracy: 0.62 - ETA: 0s - loss: 0.8510 - accuracy: 0.63 - ETA: 0s - loss: 0.8441 - accuracy: 0.63 - ETA: 0s - loss: 0.8256 - accuracy: 0.65 - ETA: 0s - loss: 0.8305 - accuracy: 0.64 - ETA: 0s - loss: 0.8412 - accuracy: 0.63 - ETA: 0s - loss: 0.8445 - accuracy: 0.63 - ETA: 0s - loss: 0.8504 - accuracy: 0.63 - ETA: 0s - loss: 0.8520 - accuracy: 0.63 - ETA: 0s - loss: 0.8533 - accuracy: 0.6285\n",
      "Epoch 00734: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8533 - accuracy: 0.6285 - val_loss: 1.0548 - val_accuracy: 0.4941 - lr: 0.0010\n",
      "Epoch 735/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.9074 - accuracy: 0.55 - ETA: 0s - loss: 0.8776 - accuracy: 0.59 - ETA: 0s - loss: 0.8916 - accuracy: 0.59 - ETA: 0s - loss: 0.8612 - accuracy: 0.61 - ETA: 0s - loss: 0.8605 - accuracy: 0.61 - ETA: 0s - loss: 0.8517 - accuracy: 0.62 - ETA: 0s - loss: 0.8487 - accuracy: 0.63 - ETA: 0s - loss: 0.8467 - accuracy: 0.63 - ETA: 0s - loss: 0.8481 - accuracy: 0.63 - ETA: 0s - loss: 0.8540 - accuracy: 0.62 - ETA: 0s - loss: 0.8495 - accuracy: 0.63 - ETA: 0s - loss: 0.8423 - accuracy: 0.63 - ETA: 0s - loss: 0.8240 - accuracy: 0.65 - ETA: 0s - loss: 0.8277 - accuracy: 0.65 - ETA: 0s - loss: 0.8384 - accuracy: 0.64 - ETA: 0s - loss: 0.8415 - accuracy: 0.63 - ETA: 0s - loss: 0.8483 - accuracy: 0.63 - ETA: 0s - loss: 0.8506 - accuracy: 0.6321\n",
      "Epoch 00735: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8518 - accuracy: 0.6295 - val_loss: 1.0669 - val_accuracy: 0.4826 - lr: 0.0010\n",
      "Epoch 736/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9206 - accuracy: 0.53 - ETA: 0s - loss: 0.8698 - accuracy: 0.59 - ETA: 0s - loss: 0.8812 - accuracy: 0.59 - ETA: 0s - loss: 0.8527 - accuracy: 0.61 - ETA: 0s - loss: 0.8581 - accuracy: 0.61 - ETA: 0s - loss: 0.8509 - accuracy: 0.62 - ETA: 0s - loss: 0.8490 - accuracy: 0.62 - ETA: 0s - loss: 0.8469 - accuracy: 0.62 - ETA: 0s - loss: 0.8486 - accuracy: 0.62 - ETA: 0s - loss: 0.8543 - accuracy: 0.62 - ETA: 0s - loss: 0.8493 - accuracy: 0.62 - ETA: 0s - loss: 0.8423 - accuracy: 0.63 - ETA: 0s - loss: 0.8235 - accuracy: 0.64 - ETA: 0s - loss: 0.8300 - accuracy: 0.64 - ETA: 0s - loss: 0.8424 - accuracy: 0.63 - ETA: 0s - loss: 0.8455 - accuracy: 0.63 - ETA: 0s - loss: 0.8533 - accuracy: 0.62 - ETA: 0s - loss: 0.8544 - accuracy: 0.6249\n",
      "Epoch 00736: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8544 - accuracy: 0.6249 - val_loss: 1.0642 - val_accuracy: 0.4857 - lr: 0.0010\n",
      "Epoch 737/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9106 - accuracy: 0.54 - ETA: 0s - loss: 0.8736 - accuracy: 0.59 - ETA: 0s - loss: 0.8853 - accuracy: 0.59 - ETA: 0s - loss: 0.8565 - accuracy: 0.61 - ETA: 0s - loss: 0.8575 - accuracy: 0.61 - ETA: 0s - loss: 0.8509 - accuracy: 0.62 - ETA: 0s - loss: 0.8496 - accuracy: 0.63 - ETA: 0s - loss: 0.8522 - accuracy: 0.62 - ETA: 0s - loss: 0.8552 - accuracy: 0.62 - ETA: 0s - loss: 0.8607 - accuracy: 0.61 - ETA: 0s - loss: 0.8556 - accuracy: 0.62 - ETA: 0s - loss: 0.8482 - accuracy: 0.63 - ETA: 0s - loss: 0.8294 - accuracy: 0.64 - ETA: 0s - loss: 0.8356 - accuracy: 0.64 - ETA: 0s - loss: 0.8511 - accuracy: 0.62 - ETA: 0s - loss: 0.8567 - accuracy: 0.62 - ETA: 0s - loss: 0.8588 - accuracy: 0.62 - ETA: 0s - loss: 0.8604 - accuracy: 0.6229\n",
      "Epoch 00737: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8604 - accuracy: 0.6229 - val_loss: 1.0573 - val_accuracy: 0.4967 - lr: 0.0010\n",
      "Epoch 738/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9084 - accuracy: 0.57 - ETA: 0s - loss: 0.8598 - accuracy: 0.61 - ETA: 0s - loss: 0.8754 - accuracy: 0.60 - ETA: 0s - loss: 0.8499 - accuracy: 0.62 - ETA: 0s - loss: 0.8515 - accuracy: 0.62 - ETA: 0s - loss: 0.8438 - accuracy: 0.63 - ETA: 0s - loss: 0.8423 - accuracy: 0.63 - ETA: 0s - loss: 0.8437 - accuracy: 0.63 - ETA: 0s - loss: 0.8462 - accuracy: 0.63 - ETA: 0s - loss: 0.8511 - accuracy: 0.62 - ETA: 0s - loss: 0.8465 - accuracy: 0.63 - ETA: 0s - loss: 0.8409 - accuracy: 0.64 - ETA: 0s - loss: 0.8228 - accuracy: 0.65 - ETA: 0s - loss: 0.8278 - accuracy: 0.64 - ETA: 0s - loss: 0.8396 - accuracy: 0.63 - ETA: 0s - loss: 0.8428 - accuracy: 0.63 - ETA: 0s - loss: 0.8492 - accuracy: 0.63 - ETA: 0s - loss: 0.8517 - accuracy: 0.63 - ETA: 0s - loss: 0.8526 - accuracy: 0.6292\n",
      "Epoch 00738: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8526 - accuracy: 0.6292 - val_loss: 1.0512 - val_accuracy: 0.4966 - lr: 0.0010\n",
      "Epoch 739/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8820 - accuracy: 0.59 - ETA: 0s - loss: 0.8601 - accuracy: 0.62 - ETA: 0s - loss: 0.8710 - accuracy: 0.61 - ETA: 0s - loss: 0.8455 - accuracy: 0.63 - ETA: 0s - loss: 0.8471 - accuracy: 0.63 - ETA: 0s - loss: 0.8410 - accuracy: 0.63 - ETA: 0s - loss: 0.8390 - accuracy: 0.64 - ETA: 0s - loss: 0.8371 - accuracy: 0.64 - ETA: 0s - loss: 0.8412 - accuracy: 0.63 - ETA: 0s - loss: 0.8475 - accuracy: 0.62 - ETA: 0s - loss: 0.8436 - accuracy: 0.63 - ETA: 0s - loss: 0.8385 - accuracy: 0.63 - ETA: 0s - loss: 0.8211 - accuracy: 0.65 - ETA: 0s - loss: 0.8253 - accuracy: 0.64 - ETA: 0s - loss: 0.8348 - accuracy: 0.63 - ETA: 0s - loss: 0.8390 - accuracy: 0.63 - ETA: 0s - loss: 0.8450 - accuracy: 0.63 - ETA: 0s - loss: 0.8470 - accuracy: 0.63 - ETA: 0s - loss: 0.8485 - accuracy: 0.6309\n",
      "Epoch 00739: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00739: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8485 - accuracy: 0.6309 - val_loss: 1.0607 - val_accuracy: 0.4889 - lr: 0.0010\n",
      "Epoch 740/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8935 - accuracy: 0.57 - ETA: 0s - loss: 0.8628 - accuracy: 0.60 - ETA: 0s - loss: 0.8776 - accuracy: 0.60 - ETA: 0s - loss: 0.8489 - accuracy: 0.61 - ETA: 0s - loss: 0.8501 - accuracy: 0.62 - ETA: 0s - loss: 0.8438 - accuracy: 0.63 - ETA: 0s - loss: 0.8401 - accuracy: 0.63 - ETA: 0s - loss: 0.8407 - accuracy: 0.63 - ETA: 0s - loss: 0.8448 - accuracy: 0.63 - ETA: 0s - loss: 0.8513 - accuracy: 0.62 - ETA: 0s - loss: 0.8461 - accuracy: 0.63 - ETA: 0s - loss: 0.8407 - accuracy: 0.63 - ETA: 0s - loss: 0.8223 - accuracy: 0.65 - ETA: 0s - loss: 0.8296 - accuracy: 0.64 - ETA: 0s - loss: 0.8415 - accuracy: 0.63 - ETA: 0s - loss: 0.8442 - accuracy: 0.63 - ETA: 0s - loss: 0.8509 - accuracy: 0.63 - ETA: 0s - loss: 0.8525 - accuracy: 0.63 - ETA: 0s - loss: 0.8542 - accuracy: 0.6304\n",
      "Epoch 00740: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8542 - accuracy: 0.6304 - val_loss: 1.0561 - val_accuracy: 0.4948 - lr: 0.0010\n",
      "Epoch 741/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9108 - accuracy: 0.54 - ETA: 0s - loss: 0.8705 - accuracy: 0.59 - ETA: 0s - loss: 0.8795 - accuracy: 0.59 - ETA: 0s - loss: 0.8524 - accuracy: 0.61 - ETA: 0s - loss: 0.8522 - accuracy: 0.62 - ETA: 0s - loss: 0.8433 - accuracy: 0.63 - ETA: 0s - loss: 0.8405 - accuracy: 0.63 - ETA: 0s - loss: 0.8465 - accuracy: 0.63 - ETA: 0s - loss: 0.8507 - accuracy: 0.62 - ETA: 0s - loss: 0.8586 - accuracy: 0.61 - ETA: 0s - loss: 0.8536 - accuracy: 0.62 - ETA: 0s - loss: 0.8467 - accuracy: 0.63 - ETA: 0s - loss: 0.8279 - accuracy: 0.64 - ETA: 0s - loss: 0.8336 - accuracy: 0.64 - ETA: 0s - loss: 0.8460 - accuracy: 0.62 - ETA: 0s - loss: 0.8486 - accuracy: 0.62 - ETA: 0s - loss: 0.8540 - accuracy: 0.62 - ETA: 0s - loss: 0.8559 - accuracy: 0.62 - ETA: 0s - loss: 0.8571 - accuracy: 0.6224\n",
      "Epoch 00741: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8571 - accuracy: 0.6224 - val_loss: 1.0602 - val_accuracy: 0.4925 - lr: 0.0010\n",
      "Epoch 742/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8916 - accuracy: 0.57 - ETA: 0s - loss: 0.8520 - accuracy: 0.61 - ETA: 0s - loss: 0.8718 - accuracy: 0.60 - ETA: 0s - loss: 0.8447 - accuracy: 0.62 - ETA: 0s - loss: 0.8467 - accuracy: 0.62 - ETA: 0s - loss: 0.8400 - accuracy: 0.63 - ETA: 0s - loss: 0.8387 - accuracy: 0.64 - ETA: 0s - loss: 0.8396 - accuracy: 0.64 - ETA: 0s - loss: 0.8410 - accuracy: 0.64 - ETA: 0s - loss: 0.8477 - accuracy: 0.63 - ETA: 0s - loss: 0.8442 - accuracy: 0.64 - ETA: 0s - loss: 0.8364 - accuracy: 0.64 - ETA: 0s - loss: 0.8182 - accuracy: 0.66 - ETA: 0s - loss: 0.8229 - accuracy: 0.65 - ETA: 0s - loss: 0.8360 - accuracy: 0.64 - ETA: 0s - loss: 0.8400 - accuracy: 0.63 - ETA: 0s - loss: 0.8462 - accuracy: 0.63 - ETA: 0s - loss: 0.8481 - accuracy: 0.63 - ETA: 0s - loss: 0.8489 - accuracy: 0.6338\n",
      "Epoch 00742: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8489 - accuracy: 0.6338 - val_loss: 1.0633 - val_accuracy: 0.4915 - lr: 0.0010\n",
      "Epoch 743/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8897 - accuracy: 0.56 - ETA: 0s - loss: 0.8572 - accuracy: 0.60 - ETA: 0s - loss: 0.8734 - accuracy: 0.60 - ETA: 0s - loss: 0.8473 - accuracy: 0.62 - ETA: 0s - loss: 0.8493 - accuracy: 0.62 - ETA: 0s - loss: 0.8441 - accuracy: 0.62 - ETA: 0s - loss: 0.8410 - accuracy: 0.63 - ETA: 0s - loss: 0.8412 - accuracy: 0.63 - ETA: 0s - loss: 0.8430 - accuracy: 0.63 - ETA: 0s - loss: 0.8510 - accuracy: 0.62 - ETA: 0s - loss: 0.8463 - accuracy: 0.63 - ETA: 0s - loss: 0.8398 - accuracy: 0.63 - ETA: 0s - loss: 0.8209 - accuracy: 0.65 - ETA: 0s - loss: 0.8257 - accuracy: 0.64 - ETA: 0s - loss: 0.8364 - accuracy: 0.63 - ETA: 0s - loss: 0.8399 - accuracy: 0.63 - ETA: 0s - loss: 0.8460 - accuracy: 0.62 - ETA: 0s - loss: 0.8492 - accuracy: 0.62 - ETA: 0s - loss: 0.8513 - accuracy: 0.6268\n",
      "Epoch 00743: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8513 - accuracy: 0.6268 - val_loss: 1.0578 - val_accuracy: 0.4899 - lr: 0.0010\n",
      "Epoch 744/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9127 - accuracy: 0.56 - ETA: 0s - loss: 0.8723 - accuracy: 0.60 - ETA: 0s - loss: 0.8836 - accuracy: 0.59 - ETA: 0s - loss: 0.8519 - accuracy: 0.61 - ETA: 0s - loss: 0.8553 - accuracy: 0.62 - ETA: 0s - loss: 0.8478 - accuracy: 0.63 - ETA: 0s - loss: 0.8458 - accuracy: 0.63 - ETA: 0s - loss: 0.8456 - accuracy: 0.63 - ETA: 0s - loss: 0.8491 - accuracy: 0.63 - ETA: 0s - loss: 0.8557 - accuracy: 0.62 - ETA: 0s - loss: 0.8515 - accuracy: 0.63 - ETA: 0s - loss: 0.8438 - accuracy: 0.64 - ETA: 0s - loss: 0.8258 - accuracy: 0.65 - ETA: 0s - loss: 0.8311 - accuracy: 0.64 - ETA: 0s - loss: 0.8416 - accuracy: 0.63 - ETA: 0s - loss: 0.8449 - accuracy: 0.63 - ETA: 0s - loss: 0.8513 - accuracy: 0.63 - ETA: 0s - loss: 0.8524 - accuracy: 0.63 - ETA: 0s - loss: 0.8529 - accuracy: 0.6302\n",
      "Epoch 00744: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8529 - accuracy: 0.6302 - val_loss: 1.0551 - val_accuracy: 0.4984 - lr: 0.0010\n",
      "Epoch 745/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9236 - accuracy: 0.55 - ETA: 0s - loss: 0.8915 - accuracy: 0.58 - ETA: 0s - loss: 0.8985 - accuracy: 0.58 - ETA: 0s - loss: 0.8642 - accuracy: 0.61 - ETA: 0s - loss: 0.8621 - accuracy: 0.61 - ETA: 0s - loss: 0.8528 - accuracy: 0.62 - ETA: 0s - loss: 0.8498 - accuracy: 0.63 - ETA: 0s - loss: 0.8490 - accuracy: 0.63 - ETA: 0s - loss: 0.8507 - accuracy: 0.63 - ETA: 0s - loss: 0.8568 - accuracy: 0.62 - ETA: 0s - loss: 0.8512 - accuracy: 0.63 - ETA: 0s - loss: 0.8453 - accuracy: 0.64 - ETA: 0s - loss: 0.8263 - accuracy: 0.65 - ETA: 0s - loss: 0.8327 - accuracy: 0.65 - ETA: 0s - loss: 0.8431 - accuracy: 0.63 - ETA: 0s - loss: 0.8530 - accuracy: 0.63 - ETA: 0s - loss: 0.8547 - accuracy: 0.63 - ETA: 0s - loss: 0.8562 - accuracy: 0.6305\n",
      "Epoch 00745: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8562 - accuracy: 0.6305 - val_loss: 1.0669 - val_accuracy: 0.4822 - lr: 0.0010\n",
      "Epoch 746/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8837 - accuracy: 0.56 - ETA: 0s - loss: 0.8570 - accuracy: 0.60 - ETA: 0s - loss: 0.8709 - accuracy: 0.60 - ETA: 0s - loss: 0.8490 - accuracy: 0.61 - ETA: 0s - loss: 0.8554 - accuracy: 0.61 - ETA: 0s - loss: 0.8490 - accuracy: 0.62 - ETA: 0s - loss: 0.8464 - accuracy: 0.63 - ETA: 0s - loss: 0.8444 - accuracy: 0.63 - ETA: 0s - loss: 0.8465 - accuracy: 0.63 - ETA: 0s - loss: 0.8524 - accuracy: 0.62 - ETA: 0s - loss: 0.8477 - accuracy: 0.63 - ETA: 0s - loss: 0.8407 - accuracy: 0.63 - ETA: 0s - loss: 0.8226 - accuracy: 0.65 - ETA: 0s - loss: 0.8288 - accuracy: 0.64 - ETA: 0s - loss: 0.8405 - accuracy: 0.63 - ETA: 0s - loss: 0.8447 - accuracy: 0.63 - ETA: 0s - loss: 0.8500 - accuracy: 0.63 - ETA: 0s - loss: 0.8528 - accuracy: 0.63 - ETA: 0s - loss: 0.8539 - accuracy: 0.6294\n",
      "Epoch 00746: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8539 - accuracy: 0.6294 - val_loss: 1.0552 - val_accuracy: 0.4914 - lr: 0.0010\n",
      "Epoch 747/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9096 - accuracy: 0.56 - ETA: 0s - loss: 0.8670 - accuracy: 0.60 - ETA: 0s - loss: 0.8786 - accuracy: 0.60 - ETA: 0s - loss: 0.8492 - accuracy: 0.62 - ETA: 0s - loss: 0.8531 - accuracy: 0.62 - ETA: 0s - loss: 0.8457 - accuracy: 0.63 - ETA: 0s - loss: 0.8443 - accuracy: 0.63 - ETA: 0s - loss: 0.8432 - accuracy: 0.63 - ETA: 0s - loss: 0.8455 - accuracy: 0.63 - ETA: 0s - loss: 0.8510 - accuracy: 0.62 - ETA: 0s - loss: 0.8473 - accuracy: 0.63 - ETA: 0s - loss: 0.8403 - accuracy: 0.64 - ETA: 0s - loss: 0.8219 - accuracy: 0.65 - ETA: 0s - loss: 0.8275 - accuracy: 0.65 - ETA: 0s - loss: 0.8384 - accuracy: 0.63 - ETA: 0s - loss: 0.8417 - accuracy: 0.63 - ETA: 0s - loss: 0.8482 - accuracy: 0.63 - ETA: 0s - loss: 0.8504 - accuracy: 0.63 - ETA: 0s - loss: 0.8520 - accuracy: 0.6293\n",
      "Epoch 00747: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8520 - accuracy: 0.6293 - val_loss: 1.0562 - val_accuracy: 0.4914 - lr: 0.0010\n",
      "Epoch 748/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9034 - accuracy: 0.56 - ETA: 0s - loss: 0.8680 - accuracy: 0.60 - ETA: 0s - loss: 0.8788 - accuracy: 0.60 - ETA: 0s - loss: 0.8499 - accuracy: 0.62 - ETA: 0s - loss: 0.8526 - accuracy: 0.62 - ETA: 0s - loss: 0.8457 - accuracy: 0.63 - ETA: 0s - loss: 0.8440 - accuracy: 0.63 - ETA: 0s - loss: 0.8438 - accuracy: 0.63 - ETA: 0s - loss: 0.8463 - accuracy: 0.63 - ETA: 0s - loss: 0.8520 - accuracy: 0.62 - ETA: 0s - loss: 0.8480 - accuracy: 0.63 - ETA: 0s - loss: 0.8413 - accuracy: 0.64 - ETA: 0s - loss: 0.8226 - accuracy: 0.65 - ETA: 0s - loss: 0.8272 - accuracy: 0.65 - ETA: 0s - loss: 0.8382 - accuracy: 0.63 - ETA: 0s - loss: 0.8418 - accuracy: 0.63 - ETA: 0s - loss: 0.8475 - accuracy: 0.63 - ETA: 0s - loss: 0.8494 - accuracy: 0.63 - ETA: 0s - loss: 0.8518 - accuracy: 0.6314\n",
      "Epoch 00748: val_loss did not improve from 0.99131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8518 - accuracy: 0.6314 - val_loss: 1.0589 - val_accuracy: 0.4909 - lr: 0.0010\n",
      "Epoch 749/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9374 - accuracy: 0.54 - ETA: 0s - loss: 0.8877 - accuracy: 0.59 - ETA: 0s - loss: 0.8910 - accuracy: 0.59 - ETA: 0s - loss: 0.8603 - accuracy: 0.61 - ETA: 0s - loss: 0.8595 - accuracy: 0.61 - ETA: 0s - loss: 0.8526 - accuracy: 0.62 - ETA: 0s - loss: 0.8487 - accuracy: 0.63 - ETA: 0s - loss: 0.8483 - accuracy: 0.63 - ETA: 0s - loss: 0.8495 - accuracy: 0.63 - ETA: 0s - loss: 0.8546 - accuracy: 0.62 - ETA: 0s - loss: 0.8500 - accuracy: 0.63 - ETA: 0s - loss: 0.8427 - accuracy: 0.63 - ETA: 0s - loss: 0.8241 - accuracy: 0.65 - ETA: 0s - loss: 0.8302 - accuracy: 0.64 - ETA: 0s - loss: 0.8393 - accuracy: 0.63 - ETA: 0s - loss: 0.8429 - accuracy: 0.63 - ETA: 0s - loss: 0.8500 - accuracy: 0.63 - ETA: 0s - loss: 0.8531 - accuracy: 0.6285\n",
      "Epoch 00749: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8531 - accuracy: 0.6285 - val_loss: 1.0607 - val_accuracy: 0.4883 - lr: 0.0010\n",
      "Epoch 750/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9126 - accuracy: 0.58 - ETA: 0s - loss: 0.8741 - accuracy: 0.61 - ETA: 0s - loss: 0.8822 - accuracy: 0.60 - ETA: 0s - loss: 0.8538 - accuracy: 0.62 - ETA: 0s - loss: 0.8540 - accuracy: 0.62 - ETA: 0s - loss: 0.8469 - accuracy: 0.63 - ETA: 0s - loss: 0.8450 - accuracy: 0.63 - ETA: 0s - loss: 0.8443 - accuracy: 0.63 - ETA: 0s - loss: 0.8459 - accuracy: 0.63 - ETA: 0s - loss: 0.8518 - accuracy: 0.62 - ETA: 0s - loss: 0.8485 - accuracy: 0.63 - ETA: 0s - loss: 0.8419 - accuracy: 0.64 - ETA: 0s - loss: 0.8225 - accuracy: 0.65 - ETA: 0s - loss: 0.8417 - accuracy: 0.63 - ETA: 0s - loss: 0.8454 - accuracy: 0.63 - ETA: 0s - loss: 0.8534 - accuracy: 0.62 - ETA: 0s - loss: 0.8557 - accuracy: 0.62 - ETA: 0s - loss: 0.8569 - accuracy: 0.6281\n",
      "Epoch 00750: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8569 - accuracy: 0.6281 - val_loss: 1.0562 - val_accuracy: 0.4879 - lr: 0.0010\n",
      "Epoch 751/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8924 - accuracy: 0.57 - ETA: 0s - loss: 0.8640 - accuracy: 0.60 - ETA: 0s - loss: 0.8736 - accuracy: 0.60 - ETA: 0s - loss: 0.8495 - accuracy: 0.62 - ETA: 0s - loss: 0.8502 - accuracy: 0.62 - ETA: 0s - loss: 0.8427 - accuracy: 0.63 - ETA: 0s - loss: 0.8410 - accuracy: 0.63 - ETA: 0s - loss: 0.8379 - accuracy: 0.63 - ETA: 0s - loss: 0.8418 - accuracy: 0.63 - ETA: 0s - loss: 0.8476 - accuracy: 0.62 - ETA: 0s - loss: 0.8432 - accuracy: 0.63 - ETA: 0s - loss: 0.8383 - accuracy: 0.64 - ETA: 0s - loss: 0.8196 - accuracy: 0.65 - ETA: 0s - loss: 0.8250 - accuracy: 0.65 - ETA: 0s - loss: 0.8381 - accuracy: 0.63 - ETA: 0s - loss: 0.8424 - accuracy: 0.63 - ETA: 0s - loss: 0.8507 - accuracy: 0.62 - ETA: 0s - loss: 0.8523 - accuracy: 0.63 - ETA: 0s - loss: 0.8541 - accuracy: 0.6287\n",
      "Epoch 00751: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8541 - accuracy: 0.6287 - val_loss: 1.0543 - val_accuracy: 0.4897 - lr: 0.0010\n",
      "Epoch 752/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9114 - accuracy: 0.56 - ETA: 0s - loss: 0.8734 - accuracy: 0.60 - ETA: 0s - loss: 0.8843 - accuracy: 0.59 - ETA: 0s - loss: 0.8578 - accuracy: 0.61 - ETA: 0s - loss: 0.8591 - accuracy: 0.61 - ETA: 0s - loss: 0.8509 - accuracy: 0.62 - ETA: 0s - loss: 0.8469 - accuracy: 0.63 - ETA: 0s - loss: 0.8457 - accuracy: 0.63 - ETA: 0s - loss: 0.8491 - accuracy: 0.63 - ETA: 0s - loss: 0.8550 - accuracy: 0.62 - ETA: 0s - loss: 0.8498 - accuracy: 0.63 - ETA: 0s - loss: 0.8432 - accuracy: 0.63 - ETA: 0s - loss: 0.8248 - accuracy: 0.65 - ETA: 0s - loss: 0.8296 - accuracy: 0.64 - ETA: 0s - loss: 0.8419 - accuracy: 0.63 - ETA: 0s - loss: 0.8455 - accuracy: 0.63 - ETA: 0s - loss: 0.8509 - accuracy: 0.62 - ETA: 0s - loss: 0.8528 - accuracy: 0.62 - ETA: 0s - loss: 0.8542 - accuracy: 0.6276\n",
      "Epoch 00752: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8542 - accuracy: 0.6276 - val_loss: 1.0546 - val_accuracy: 0.4959 - lr: 0.0010\n",
      "Epoch 753/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9059 - accuracy: 0.56 - ETA: 0s - loss: 0.8658 - accuracy: 0.60 - ETA: 0s - loss: 0.8754 - accuracy: 0.60 - ETA: 0s - loss: 0.8483 - accuracy: 0.62 - ETA: 0s - loss: 0.8499 - accuracy: 0.62 - ETA: 0s - loss: 0.8444 - accuracy: 0.63 - ETA: 0s - loss: 0.8430 - accuracy: 0.63 - ETA: 0s - loss: 0.8423 - accuracy: 0.63 - ETA: 0s - loss: 0.8461 - accuracy: 0.63 - ETA: 0s - loss: 0.8513 - accuracy: 0.62 - ETA: 0s - loss: 0.8465 - accuracy: 0.63 - ETA: 0s - loss: 0.8412 - accuracy: 0.63 - ETA: 0s - loss: 0.8225 - accuracy: 0.65 - ETA: 0s - loss: 0.8307 - accuracy: 0.64 - ETA: 0s - loss: 0.8411 - accuracy: 0.63 - ETA: 0s - loss: 0.8443 - accuracy: 0.63 - ETA: 0s - loss: 0.8498 - accuracy: 0.62 - ETA: 0s - loss: 0.8519 - accuracy: 0.62 - ETA: 0s - loss: 0.8531 - accuracy: 0.6276\n",
      "Epoch 00753: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00753: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8531 - accuracy: 0.6276 - val_loss: 1.0502 - val_accuracy: 0.4927 - lr: 0.0010\n",
      "Epoch 754/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8912 - accuracy: 0.57 - ETA: 0s - loss: 0.8529 - accuracy: 0.61 - ETA: 0s - loss: 0.8685 - accuracy: 0.60 - ETA: 0s - loss: 0.8441 - accuracy: 0.62 - ETA: 0s - loss: 0.8474 - accuracy: 0.62 - ETA: 0s - loss: 0.8421 - accuracy: 0.63 - ETA: 0s - loss: 0.8406 - accuracy: 0.63 - ETA: 0s - loss: 0.8400 - accuracy: 0.63 - ETA: 0s - loss: 0.8454 - accuracy: 0.63 - ETA: 0s - loss: 0.8509 - accuracy: 0.62 - ETA: 0s - loss: 0.8466 - accuracy: 0.63 - ETA: 0s - loss: 0.8404 - accuracy: 0.63 - ETA: 0s - loss: 0.8220 - accuracy: 0.65 - ETA: 0s - loss: 0.8264 - accuracy: 0.64 - ETA: 0s - loss: 0.8356 - accuracy: 0.63 - ETA: 0s - loss: 0.8385 - accuracy: 0.63 - ETA: 0s - loss: 0.8455 - accuracy: 0.63 - ETA: 0s - loss: 0.8475 - accuracy: 0.63 - ETA: 0s - loss: 0.8495 - accuracy: 0.6303\n",
      "Epoch 00754: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8495 - accuracy: 0.6303 - val_loss: 1.0512 - val_accuracy: 0.4949 - lr: 0.0010\n",
      "Epoch 755/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8880 - accuracy: 0.56 - ETA: 0s - loss: 0.8647 - accuracy: 0.59 - ETA: 0s - loss: 0.8753 - accuracy: 0.59 - ETA: 0s - loss: 0.8508 - accuracy: 0.61 - ETA: 0s - loss: 0.8559 - accuracy: 0.61 - ETA: 0s - loss: 0.8489 - accuracy: 0.62 - ETA: 0s - loss: 0.8447 - accuracy: 0.63 - ETA: 0s - loss: 0.8423 - accuracy: 0.63 - ETA: 0s - loss: 0.8449 - accuracy: 0.63 - ETA: 0s - loss: 0.8497 - accuracy: 0.62 - ETA: 0s - loss: 0.8445 - accuracy: 0.63 - ETA: 0s - loss: 0.8381 - accuracy: 0.63 - ETA: 0s - loss: 0.8197 - accuracy: 0.65 - ETA: 0s - loss: 0.8252 - accuracy: 0.64 - ETA: 0s - loss: 0.8370 - accuracy: 0.63 - ETA: 0s - loss: 0.8410 - accuracy: 0.63 - ETA: 0s - loss: 0.8476 - accuracy: 0.62 - ETA: 0s - loss: 0.8502 - accuracy: 0.62 - ETA: 0s - loss: 0.8518 - accuracy: 0.6279\n",
      "Epoch 00755: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8518 - accuracy: 0.6279 - val_loss: 1.0536 - val_accuracy: 0.4897 - lr: 0.0010\n",
      "Epoch 756/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/19 [===========================>..] - ETA: 0s - loss: 0.8970 - accuracy: 0.56 - ETA: 0s - loss: 0.8618 - accuracy: 0.60 - ETA: 0s - loss: 0.8792 - accuracy: 0.59 - ETA: 0s - loss: 0.8511 - accuracy: 0.61 - ETA: 0s - loss: 0.8530 - accuracy: 0.61 - ETA: 0s - loss: 0.8473 - accuracy: 0.62 - ETA: 0s - loss: 0.8443 - accuracy: 0.63 - ETA: 0s - loss: 0.8427 - accuracy: 0.63 - ETA: 0s - loss: 0.8453 - accuracy: 0.63 - ETA: 0s - loss: 0.8506 - accuracy: 0.62 - ETA: 0s - loss: 0.8470 - accuracy: 0.63 - ETA: 0s - loss: 0.8409 - accuracy: 0.64 - ETA: 0s - loss: 0.8221 - accuracy: 0.65 - ETA: 0s - loss: 0.8276 - accuracy: 0.65 - ETA: 0s - loss: 0.8402 - accuracy: 0.63 - ETA: 0s - loss: 0.8438 - accuracy: 0.63 - ETA: 0s - loss: 0.8501 - accuracy: 0.63 - ETA: 0s - loss: 0.8523 - accuracy: 0.6307\n",
      "Epoch 00756: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8532 - accuracy: 0.6296 - val_loss: 1.0607 - val_accuracy: 0.4914 - lr: 0.0010\n",
      "Epoch 757/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8981 - accuracy: 0.54 - ETA: 0s - loss: 0.8658 - accuracy: 0.58 - ETA: 0s - loss: 0.8768 - accuracy: 0.59 - ETA: 0s - loss: 0.8494 - accuracy: 0.61 - ETA: 0s - loss: 0.8508 - accuracy: 0.61 - ETA: 0s - loss: 0.8450 - accuracy: 0.62 - ETA: 0s - loss: 0.8438 - accuracy: 0.62 - ETA: 0s - loss: 0.8428 - accuracy: 0.63 - ETA: 0s - loss: 0.8462 - accuracy: 0.63 - ETA: 0s - loss: 0.8525 - accuracy: 0.62 - ETA: 0s - loss: 0.8484 - accuracy: 0.63 - ETA: 0s - loss: 0.8412 - accuracy: 0.63 - ETA: 0s - loss: 0.8221 - accuracy: 0.65 - ETA: 0s - loss: 0.8269 - accuracy: 0.64 - ETA: 0s - loss: 0.8382 - accuracy: 0.63 - ETA: 0s - loss: 0.8418 - accuracy: 0.63 - ETA: 0s - loss: 0.8482 - accuracy: 0.62 - ETA: 0s - loss: 0.8504 - accuracy: 0.62 - ETA: 0s - loss: 0.8507 - accuracy: 0.6280\n",
      "Epoch 00757: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8507 - accuracy: 0.6280 - val_loss: 1.0592 - val_accuracy: 0.4909 - lr: 0.0010\n",
      "Epoch 758/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9202 - accuracy: 0.55 - ETA: 0s - loss: 0.8657 - accuracy: 0.61 - ETA: 0s - loss: 0.8835 - accuracy: 0.60 - ETA: 0s - loss: 0.8535 - accuracy: 0.62 - ETA: 0s - loss: 0.8533 - accuracy: 0.62 - ETA: 0s - loss: 0.8475 - accuracy: 0.63 - ETA: 0s - loss: 0.8462 - accuracy: 0.63 - ETA: 0s - loss: 0.8456 - accuracy: 0.63 - ETA: 0s - loss: 0.8486 - accuracy: 0.63 - ETA: 0s - loss: 0.8530 - accuracy: 0.62 - ETA: 0s - loss: 0.8482 - accuracy: 0.63 - ETA: 0s - loss: 0.8413 - accuracy: 0.64 - ETA: 0s - loss: 0.8224 - accuracy: 0.65 - ETA: 0s - loss: 0.8284 - accuracy: 0.65 - ETA: 0s - loss: 0.8381 - accuracy: 0.63 - ETA: 0s - loss: 0.8423 - accuracy: 0.63 - ETA: 0s - loss: 0.8485 - accuracy: 0.63 - ETA: 0s - loss: 0.8503 - accuracy: 0.63 - ETA: 0s - loss: 0.8519 - accuracy: 0.6301\n",
      "Epoch 00758: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8519 - accuracy: 0.6301 - val_loss: 1.0611 - val_accuracy: 0.4930 - lr: 0.0010\n",
      "Epoch 759/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9117 - accuracy: 0.56 - ETA: 0s - loss: 0.8695 - accuracy: 0.60 - ETA: 0s - loss: 0.8765 - accuracy: 0.60 - ETA: 0s - loss: 0.8525 - accuracy: 0.62 - ETA: 0s - loss: 0.8543 - accuracy: 0.62 - ETA: 0s - loss: 0.8480 - accuracy: 0.63 - ETA: 0s - loss: 0.8462 - accuracy: 0.63 - ETA: 0s - loss: 0.8462 - accuracy: 0.63 - ETA: 0s - loss: 0.8475 - accuracy: 0.63 - ETA: 0s - loss: 0.8550 - accuracy: 0.62 - ETA: 0s - loss: 0.8516 - accuracy: 0.63 - ETA: 0s - loss: 0.8437 - accuracy: 0.64 - ETA: 0s - loss: 0.8246 - accuracy: 0.65 - ETA: 0s - loss: 0.8314 - accuracy: 0.64 - ETA: 0s - loss: 0.8405 - accuracy: 0.63 - ETA: 0s - loss: 0.8427 - accuracy: 0.63 - ETA: 0s - loss: 0.8486 - accuracy: 0.63 - ETA: 0s - loss: 0.8509 - accuracy: 0.63 - ETA: 0s - loss: 0.8516 - accuracy: 0.6300\n",
      "Epoch 00759: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8516 - accuracy: 0.6300 - val_loss: 1.0710 - val_accuracy: 0.4858 - lr: 0.0010\n",
      "Epoch 760/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9134 - accuracy: 0.56 - ETA: 0s - loss: 0.8765 - accuracy: 0.60 - ETA: 0s - loss: 0.8849 - accuracy: 0.60 - ETA: 0s - loss: 0.8536 - accuracy: 0.62 - ETA: 0s - loss: 0.8512 - accuracy: 0.62 - ETA: 0s - loss: 0.8443 - accuracy: 0.63 - ETA: 0s - loss: 0.8429 - accuracy: 0.63 - ETA: 0s - loss: 0.8414 - accuracy: 0.63 - ETA: 0s - loss: 0.8429 - accuracy: 0.63 - ETA: 0s - loss: 0.8482 - accuracy: 0.62 - ETA: 0s - loss: 0.8443 - accuracy: 0.63 - ETA: 0s - loss: 0.8391 - accuracy: 0.64 - ETA: 0s - loss: 0.8207 - accuracy: 0.65 - ETA: 0s - loss: 0.8267 - accuracy: 0.65 - ETA: 0s - loss: 0.8381 - accuracy: 0.63 - ETA: 0s - loss: 0.8410 - accuracy: 0.63 - ETA: 0s - loss: 0.8462 - accuracy: 0.63 - ETA: 0s - loss: 0.8483 - accuracy: 0.63 - ETA: 0s - loss: 0.8502 - accuracy: 0.6297\n",
      "Epoch 00760: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8502 - accuracy: 0.6297 - val_loss: 1.0685 - val_accuracy: 0.4860 - lr: 0.0010\n",
      "Epoch 761/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9078 - accuracy: 0.54 - ETA: 0s - loss: 0.8626 - accuracy: 0.59 - ETA: 0s - loss: 0.8789 - accuracy: 0.59 - ETA: 0s - loss: 0.8531 - accuracy: 0.61 - ETA: 0s - loss: 0.8536 - accuracy: 0.61 - ETA: 0s - loss: 0.8469 - accuracy: 0.62 - ETA: 0s - loss: 0.8438 - accuracy: 0.62 - ETA: 0s - loss: 0.8412 - accuracy: 0.63 - ETA: 0s - loss: 0.8439 - accuracy: 0.63 - ETA: 0s - loss: 0.8499 - accuracy: 0.62 - ETA: 0s - loss: 0.8450 - accuracy: 0.63 - ETA: 0s - loss: 0.8380 - accuracy: 0.64 - ETA: 0s - loss: 0.8196 - accuracy: 0.65 - ETA: 0s - loss: 0.8227 - accuracy: 0.65 - ETA: 0s - loss: 0.8328 - accuracy: 0.63 - ETA: 0s - loss: 0.8364 - accuracy: 0.63 - ETA: 0s - loss: 0.8430 - accuracy: 0.63 - ETA: 0s - loss: 0.8456 - accuracy: 0.63 - ETA: 0s - loss: 0.8467 - accuracy: 0.6318\n",
      "Epoch 00761: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8467 - accuracy: 0.6318 - val_loss: 1.0625 - val_accuracy: 0.4941 - lr: 0.0010\n",
      "Epoch 762/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8931 - accuracy: 0.57 - ETA: 0s - loss: 0.8664 - accuracy: 0.59 - ETA: 0s - loss: 0.8804 - accuracy: 0.59 - ETA: 0s - loss: 0.8537 - accuracy: 0.61 - ETA: 0s - loss: 0.8542 - accuracy: 0.61 - ETA: 0s - loss: 0.8479 - accuracy: 0.62 - ETA: 0s - loss: 0.8446 - accuracy: 0.63 - ETA: 0s - loss: 0.8433 - accuracy: 0.63 - ETA: 0s - loss: 0.8435 - accuracy: 0.63 - ETA: 0s - loss: 0.8495 - accuracy: 0.62 - ETA: 0s - loss: 0.8440 - accuracy: 0.63 - ETA: 0s - loss: 0.8370 - accuracy: 0.63 - ETA: 0s - loss: 0.8188 - accuracy: 0.65 - ETA: 0s - loss: 0.8248 - accuracy: 0.64 - ETA: 0s - loss: 0.8339 - accuracy: 0.63 - ETA: 0s - loss: 0.8374 - accuracy: 0.63 - ETA: 0s - loss: 0.8440 - accuracy: 0.63 - ETA: 0s - loss: 0.8467 - accuracy: 0.62 - ETA: 0s - loss: 0.8484 - accuracy: 0.6286\n",
      "Epoch 00762: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8484 - accuracy: 0.6286 - val_loss: 1.0517 - val_accuracy: 0.4961 - lr: 0.0010\n",
      "Epoch 763/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8906 - accuracy: 0.57 - ETA: 0s - loss: 0.8498 - accuracy: 0.61 - ETA: 0s - loss: 0.8678 - accuracy: 0.60 - ETA: 0s - loss: 0.8403 - accuracy: 0.62 - ETA: 0s - loss: 0.8432 - accuracy: 0.62 - ETA: 0s - loss: 0.8388 - accuracy: 0.63 - ETA: 0s - loss: 0.8383 - accuracy: 0.63 - ETA: 0s - loss: 0.8377 - accuracy: 0.64 - ETA: 0s - loss: 0.8412 - accuracy: 0.63 - ETA: 0s - loss: 0.8464 - accuracy: 0.63 - ETA: 0s - loss: 0.8429 - accuracy: 0.63 - ETA: 0s - loss: 0.8366 - accuracy: 0.64 - ETA: 0s - loss: 0.8176 - accuracy: 0.65 - ETA: 0s - loss: 0.8225 - accuracy: 0.65 - ETA: 0s - loss: 0.8348 - accuracy: 0.64 - ETA: 0s - loss: 0.8381 - accuracy: 0.63 - ETA: 0s - loss: 0.8452 - accuracy: 0.63 - ETA: 0s - loss: 0.8480 - accuracy: 0.63 - ETA: 0s - loss: 0.8489 - accuracy: 0.6327\n",
      "Epoch 00763: val_loss did not improve from 0.99131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8489 - accuracy: 0.6327 - val_loss: 1.0539 - val_accuracy: 0.4951 - lr: 0.0010\n",
      "Epoch 764/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8939 - accuracy: 0.57 - ETA: 0s - loss: 0.8663 - accuracy: 0.61 - ETA: 0s - loss: 0.8790 - accuracy: 0.61 - ETA: 0s - loss: 0.8534 - accuracy: 0.62 - ETA: 0s - loss: 0.8567 - accuracy: 0.62 - ETA: 0s - loss: 0.8493 - accuracy: 0.63 - ETA: 0s - loss: 0.8471 - accuracy: 0.63 - ETA: 0s - loss: 0.8452 - accuracy: 0.64 - ETA: 0s - loss: 0.8475 - accuracy: 0.63 - ETA: 0s - loss: 0.8534 - accuracy: 0.63 - ETA: 0s - loss: 0.8484 - accuracy: 0.63 - ETA: 0s - loss: 0.8427 - accuracy: 0.64 - ETA: 0s - loss: 0.8234 - accuracy: 0.65 - ETA: 0s - loss: 0.8273 - accuracy: 0.65 - ETA: 0s - loss: 0.8381 - accuracy: 0.64 - ETA: 0s - loss: 0.8416 - accuracy: 0.63 - ETA: 0s - loss: 0.8479 - accuracy: 0.63 - ETA: 0s - loss: 0.8493 - accuracy: 0.63 - ETA: 0s - loss: 0.8502 - accuracy: 0.6317\n",
      "Epoch 00764: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8502 - accuracy: 0.6317 - val_loss: 1.0557 - val_accuracy: 0.4946 - lr: 0.0010\n",
      "Epoch 765/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8806 - accuracy: 0.57 - ETA: 0s - loss: 0.8517 - accuracy: 0.61 - ETA: 0s - loss: 0.8638 - accuracy: 0.60 - ETA: 0s - loss: 0.8396 - accuracy: 0.62 - ETA: 0s - loss: 0.8460 - accuracy: 0.62 - ETA: 0s - loss: 0.8383 - accuracy: 0.63 - ETA: 0s - loss: 0.8367 - accuracy: 0.63 - ETA: 0s - loss: 0.8373 - accuracy: 0.63 - ETA: 0s - loss: 0.8387 - accuracy: 0.63 - ETA: 0s - loss: 0.8460 - accuracy: 0.62 - ETA: 0s - loss: 0.8427 - accuracy: 0.63 - ETA: 0s - loss: 0.8360 - accuracy: 0.63 - ETA: 0s - loss: 0.8173 - accuracy: 0.65 - ETA: 0s - loss: 0.8226 - accuracy: 0.64 - ETA: 0s - loss: 0.8345 - accuracy: 0.63 - ETA: 0s - loss: 0.8377 - accuracy: 0.63 - ETA: 0s - loss: 0.8439 - accuracy: 0.63 - ETA: 0s - loss: 0.8465 - accuracy: 0.63 - ETA: 0s - loss: 0.8488 - accuracy: 0.6296\n",
      "Epoch 00765: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8488 - accuracy: 0.6296 - val_loss: 1.0482 - val_accuracy: 0.4935 - lr: 0.0010\n",
      "Epoch 766/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8917 - accuracy: 0.57 - ETA: 0s - loss: 0.8620 - accuracy: 0.61 - ETA: 0s - loss: 0.8710 - accuracy: 0.60 - ETA: 0s - loss: 0.8424 - accuracy: 0.62 - ETA: 0s - loss: 0.8456 - accuracy: 0.62 - ETA: 0s - loss: 0.8405 - accuracy: 0.63 - ETA: 0s - loss: 0.8394 - accuracy: 0.63 - ETA: 0s - loss: 0.8375 - accuracy: 0.63 - ETA: 0s - loss: 0.8393 - accuracy: 0.63 - ETA: 0s - loss: 0.8463 - accuracy: 0.63 - ETA: 0s - loss: 0.8411 - accuracy: 0.63 - ETA: 0s - loss: 0.8357 - accuracy: 0.64 - ETA: 0s - loss: 0.8176 - accuracy: 0.65 - ETA: 0s - loss: 0.8243 - accuracy: 0.65 - ETA: 0s - loss: 0.8350 - accuracy: 0.64 - ETA: 0s - loss: 0.8389 - accuracy: 0.63 - ETA: 0s - loss: 0.8457 - accuracy: 0.63 - ETA: 0s - loss: 0.8479 - accuracy: 0.63 - ETA: 0s - loss: 0.8495 - accuracy: 0.6320\n",
      "Epoch 00766: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8495 - accuracy: 0.6320 - val_loss: 1.0513 - val_accuracy: 0.4949 - lr: 0.0010\n",
      "Epoch 767/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8977 - accuracy: 0.57 - ETA: 0s - loss: 0.8635 - accuracy: 0.60 - ETA: 0s - loss: 0.8717 - accuracy: 0.60 - ETA: 0s - loss: 0.8452 - accuracy: 0.62 - ETA: 0s - loss: 0.8500 - accuracy: 0.62 - ETA: 0s - loss: 0.8426 - accuracy: 0.63 - ETA: 0s - loss: 0.8393 - accuracy: 0.63 - ETA: 0s - loss: 0.8376 - accuracy: 0.63 - ETA: 0s - loss: 0.8425 - accuracy: 0.63 - ETA: 0s - loss: 0.8485 - accuracy: 0.62 - ETA: 0s - loss: 0.8448 - accuracy: 0.63 - ETA: 0s - loss: 0.8379 - accuracy: 0.64 - ETA: 0s - loss: 0.8194 - accuracy: 0.65 - ETA: 0s - loss: 0.8265 - accuracy: 0.65 - ETA: 0s - loss: 0.8355 - accuracy: 0.64 - ETA: 0s - loss: 0.8395 - accuracy: 0.63 - ETA: 0s - loss: 0.8451 - accuracy: 0.63 - ETA: 0s - loss: 0.8473 - accuracy: 0.63 - ETA: 0s - loss: 0.8485 - accuracy: 0.6326\n",
      "Epoch 00767: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00767: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8485 - accuracy: 0.6326 - val_loss: 1.0625 - val_accuracy: 0.4891 - lr: 0.0010\n",
      "Epoch 768/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8897 - accuracy: 0.57 - ETA: 0s - loss: 0.8532 - accuracy: 0.61 - ETA: 0s - loss: 0.8684 - accuracy: 0.61 - ETA: 0s - loss: 0.8432 - accuracy: 0.62 - ETA: 0s - loss: 0.8471 - accuracy: 0.62 - ETA: 0s - loss: 0.8417 - accuracy: 0.63 - ETA: 0s - loss: 0.8398 - accuracy: 0.63 - ETA: 0s - loss: 0.8391 - accuracy: 0.63 - ETA: 0s - loss: 0.8414 - accuracy: 0.63 - ETA: 0s - loss: 0.8483 - accuracy: 0.62 - ETA: 0s - loss: 0.8434 - accuracy: 0.63 - ETA: 0s - loss: 0.8360 - accuracy: 0.64 - ETA: 0s - loss: 0.8178 - accuracy: 0.65 - ETA: 0s - loss: 0.8231 - accuracy: 0.65 - ETA: 0s - loss: 0.8338 - accuracy: 0.63 - ETA: 0s - loss: 0.8371 - accuracy: 0.63 - ETA: 0s - loss: 0.8424 - accuracy: 0.63 - ETA: 0s - loss: 0.8444 - accuracy: 0.63 - ETA: 0s - loss: 0.8455 - accuracy: 0.6319\n",
      "Epoch 00768: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8455 - accuracy: 0.6319 - val_loss: 1.0576 - val_accuracy: 0.4980 - lr: 0.0010\n",
      "Epoch 769/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8993 - accuracy: 0.58 - ETA: 0s - loss: 0.8622 - accuracy: 0.61 - ETA: 0s - loss: 0.8775 - accuracy: 0.60 - ETA: 0s - loss: 0.8484 - accuracy: 0.62 - ETA: 0s - loss: 0.8483 - accuracy: 0.62 - ETA: 0s - loss: 0.8422 - accuracy: 0.63 - ETA: 0s - loss: 0.8420 - accuracy: 0.63 - ETA: 0s - loss: 0.8407 - accuracy: 0.63 - ETA: 0s - loss: 0.8425 - accuracy: 0.63 - ETA: 0s - loss: 0.8491 - accuracy: 0.62 - ETA: 0s - loss: 0.8442 - accuracy: 0.63 - ETA: 0s - loss: 0.8201 - accuracy: 0.65 - ETA: 0s - loss: 0.8257 - accuracy: 0.64 - ETA: 0s - loss: 0.8361 - accuracy: 0.63 - ETA: 0s - loss: 0.8399 - accuracy: 0.63 - ETA: 0s - loss: 0.8455 - accuracy: 0.63 - ETA: 0s - loss: 0.8478 - accuracy: 0.63 - ETA: 0s - loss: 0.8494 - accuracy: 0.6317\n",
      "Epoch 00769: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8494 - accuracy: 0.6317 - val_loss: 1.0451 - val_accuracy: 0.5008 - lr: 0.0010\n",
      "Epoch 770/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8817 - accuracy: 0.59 - ETA: 0s - loss: 0.8593 - accuracy: 0.62 - ETA: 0s - loss: 0.8755 - accuracy: 0.61 - ETA: 0s - loss: 0.8469 - accuracy: 0.63 - ETA: 0s - loss: 0.8490 - accuracy: 0.63 - ETA: 0s - loss: 0.8411 - accuracy: 0.64 - ETA: 0s - loss: 0.8396 - accuracy: 0.64 - ETA: 0s - loss: 0.8399 - accuracy: 0.64 - ETA: 0s - loss: 0.8434 - accuracy: 0.64 - ETA: 0s - loss: 0.8503 - accuracy: 0.63 - ETA: 0s - loss: 0.8467 - accuracy: 0.63 - ETA: 0s - loss: 0.8404 - accuracy: 0.64 - ETA: 0s - loss: 0.8220 - accuracy: 0.65 - ETA: 0s - loss: 0.8295 - accuracy: 0.65 - ETA: 0s - loss: 0.8392 - accuracy: 0.64 - ETA: 0s - loss: 0.8427 - accuracy: 0.63 - ETA: 0s - loss: 0.8487 - accuracy: 0.63 - ETA: 0s - loss: 0.8509 - accuracy: 0.63 - ETA: 0s - loss: 0.8526 - accuracy: 0.6330\n",
      "Epoch 00770: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8526 - accuracy: 0.6330 - val_loss: 1.0451 - val_accuracy: 0.4984 - lr: 0.0010\n",
      "Epoch 771/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.8830 - accuracy: 0.56 - ETA: 0s - loss: 0.8613 - accuracy: 0.59 - ETA: 0s - loss: 0.8713 - accuracy: 0.59 - ETA: 0s - loss: 0.8446 - accuracy: 0.61 - ETA: 0s - loss: 0.8455 - accuracy: 0.61 - ETA: 0s - loss: 0.8384 - accuracy: 0.63 - ETA: 0s - loss: 0.8347 - accuracy: 0.63 - ETA: 0s - loss: 0.8346 - accuracy: 0.63 - ETA: 0s - loss: 0.8383 - accuracy: 0.63 - ETA: 0s - loss: 0.8434 - accuracy: 0.63 - ETA: 0s - loss: 0.8398 - accuracy: 0.63 - ETA: 0s - loss: 0.8338 - accuracy: 0.64 - ETA: 0s - loss: 0.8160 - accuracy: 0.65 - ETA: 0s - loss: 0.8220 - accuracy: 0.65 - ETA: 0s - loss: 0.8338 - accuracy: 0.64 - ETA: 0s - loss: 0.8379 - accuracy: 0.63 - ETA: 0s - loss: 0.8445 - accuracy: 0.63 - ETA: 0s - loss: 0.8464 - accuracy: 0.63 - ETA: 0s - loss: 0.8485 - accuracy: 0.6320\n",
      "Epoch 00771: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8485 - accuracy: 0.6320 - val_loss: 1.0526 - val_accuracy: 0.4906 - lr: 0.0010\n",
      "Epoch 772/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8947 - accuracy: 0.56 - ETA: 0s - loss: 0.8658 - accuracy: 0.61 - ETA: 0s - loss: 0.8730 - accuracy: 0.60 - ETA: 0s - loss: 0.8451 - accuracy: 0.62 - ETA: 0s - loss: 0.8508 - accuracy: 0.62 - ETA: 0s - loss: 0.8446 - accuracy: 0.63 - ETA: 0s - loss: 0.8425 - accuracy: 0.63 - ETA: 0s - loss: 0.8379 - accuracy: 0.63 - ETA: 0s - loss: 0.8394 - accuracy: 0.63 - ETA: 0s - loss: 0.8437 - accuracy: 0.62 - ETA: 0s - loss: 0.8402 - accuracy: 0.63 - ETA: 0s - loss: 0.8332 - accuracy: 0.64 - ETA: 0s - loss: 0.8152 - accuracy: 0.65 - ETA: 0s - loss: 0.8209 - accuracy: 0.65 - ETA: 0s - loss: 0.8319 - accuracy: 0.63 - ETA: 0s - loss: 0.8356 - accuracy: 0.63 - ETA: 0s - loss: 0.8419 - accuracy: 0.63 - ETA: 0s - loss: 0.8445 - accuracy: 0.63 - ETA: 0s - loss: 0.8469 - accuracy: 0.6317\n",
      "Epoch 00772: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8469 - accuracy: 0.6317 - val_loss: 1.0551 - val_accuracy: 0.4910 - lr: 0.0010\n",
      "Epoch 773/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8925 - accuracy: 0.55 - ETA: 0s - loss: 0.8591 - accuracy: 0.60 - ETA: 0s - loss: 0.8741 - accuracy: 0.60 - ETA: 0s - loss: 0.8490 - accuracy: 0.62 - ETA: 0s - loss: 0.8514 - accuracy: 0.62 - ETA: 0s - loss: 0.8461 - accuracy: 0.63 - ETA: 0s - loss: 0.8410 - accuracy: 0.63 - ETA: 0s - loss: 0.8401 - accuracy: 0.63 - ETA: 0s - loss: 0.8431 - accuracy: 0.63 - ETA: 0s - loss: 0.8478 - accuracy: 0.62 - ETA: 0s - loss: 0.8433 - accuracy: 0.63 - ETA: 0s - loss: 0.8371 - accuracy: 0.64 - ETA: 0s - loss: 0.8190 - accuracy: 0.65 - ETA: 0s - loss: 0.8244 - accuracy: 0.65 - ETA: 0s - loss: 0.8347 - accuracy: 0.64 - ETA: 0s - loss: 0.8377 - accuracy: 0.63 - ETA: 0s - loss: 0.8441 - accuracy: 0.63 - ETA: 0s - loss: 0.8468 - accuracy: 0.63 - ETA: 0s - loss: 0.8485 - accuracy: 0.6310\n",
      "Epoch 00773: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8485 - accuracy: 0.6310 - val_loss: 1.0547 - val_accuracy: 0.4917 - lr: 0.0010\n",
      "Epoch 774/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8982 - accuracy: 0.56 - ETA: 0s - loss: 0.8680 - accuracy: 0.60 - ETA: 0s - loss: 0.8718 - accuracy: 0.60 - ETA: 0s - loss: 0.8464 - accuracy: 0.61 - ETA: 0s - loss: 0.8481 - accuracy: 0.61 - ETA: 0s - loss: 0.8428 - accuracy: 0.62 - ETA: 0s - loss: 0.8391 - accuracy: 0.63 - ETA: 0s - loss: 0.8374 - accuracy: 0.63 - ETA: 0s - loss: 0.8407 - accuracy: 0.63 - ETA: 0s - loss: 0.8468 - accuracy: 0.62 - ETA: 0s - loss: 0.8420 - accuracy: 0.63 - ETA: 0s - loss: 0.8364 - accuracy: 0.63 - ETA: 0s - loss: 0.8182 - accuracy: 0.65 - ETA: 0s - loss: 0.8226 - accuracy: 0.64 - ETA: 0s - loss: 0.8322 - accuracy: 0.63 - ETA: 0s - loss: 0.8366 - accuracy: 0.63 - ETA: 0s - loss: 0.8428 - accuracy: 0.63 - ETA: 0s - loss: 0.8462 - accuracy: 0.63 - ETA: 0s - loss: 0.8481 - accuracy: 0.6288\n",
      "Epoch 00774: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8481 - accuracy: 0.6288 - val_loss: 1.0589 - val_accuracy: 0.4964 - lr: 0.0010\n",
      "Epoch 775/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9050 - accuracy: 0.55 - ETA: 0s - loss: 0.8557 - accuracy: 0.60 - ETA: 0s - loss: 0.8697 - accuracy: 0.60 - ETA: 0s - loss: 0.8432 - accuracy: 0.61 - ETA: 0s - loss: 0.8469 - accuracy: 0.62 - ETA: 0s - loss: 0.8406 - accuracy: 0.63 - ETA: 0s - loss: 0.8396 - accuracy: 0.63 - ETA: 0s - loss: 0.8412 - accuracy: 0.63 - ETA: 0s - loss: 0.8441 - accuracy: 0.63 - ETA: 0s - loss: 0.8493 - accuracy: 0.62 - ETA: 0s - loss: 0.8441 - accuracy: 0.63 - ETA: 0s - loss: 0.8370 - accuracy: 0.63 - ETA: 0s - loss: 0.8186 - accuracy: 0.65 - ETA: 0s - loss: 0.8242 - accuracy: 0.64 - ETA: 0s - loss: 0.8365 - accuracy: 0.63 - ETA: 0s - loss: 0.8403 - accuracy: 0.63 - ETA: 0s - loss: 0.8457 - accuracy: 0.63 - ETA: 0s - loss: 0.8484 - accuracy: 0.63 - ETA: 0s - loss: 0.8497 - accuracy: 0.6300\n",
      "Epoch 00775: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8497 - accuracy: 0.6300 - val_loss: 1.0568 - val_accuracy: 0.4941 - lr: 0.0010\n",
      "Epoch 776/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8890 - accuracy: 0.55 - ETA: 0s - loss: 0.8530 - accuracy: 0.60 - ETA: 0s - loss: 0.8651 - accuracy: 0.61 - ETA: 0s - loss: 0.8430 - accuracy: 0.62 - ETA: 0s - loss: 0.8435 - accuracy: 0.62 - ETA: 0s - loss: 0.8372 - accuracy: 0.63 - ETA: 0s - loss: 0.8364 - accuracy: 0.63 - ETA: 0s - loss: 0.8362 - accuracy: 0.64 - ETA: 0s - loss: 0.8384 - accuracy: 0.63 - ETA: 0s - loss: 0.8438 - accuracy: 0.63 - ETA: 0s - loss: 0.8403 - accuracy: 0.63 - ETA: 0s - loss: 0.8331 - accuracy: 0.64 - ETA: 0s - loss: 0.8141 - accuracy: 0.65 - ETA: 0s - loss: 0.8206 - accuracy: 0.65 - ETA: 0s - loss: 0.8319 - accuracy: 0.64 - ETA: 0s - loss: 0.8351 - accuracy: 0.64 - ETA: 0s - loss: 0.8414 - accuracy: 0.63 - ETA: 0s - loss: 0.8437 - accuracy: 0.63 - ETA: 0s - loss: 0.8448 - accuracy: 0.6359\n",
      "Epoch 00776: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8448 - accuracy: 0.6359 - val_loss: 1.0597 - val_accuracy: 0.4971 - lr: 0.0010\n",
      "Epoch 777/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8859 - accuracy: 0.59 - ETA: 0s - loss: 0.8608 - accuracy: 0.61 - ETA: 0s - loss: 0.8710 - accuracy: 0.61 - ETA: 0s - loss: 0.8444 - accuracy: 0.62 - ETA: 0s - loss: 0.8480 - accuracy: 0.62 - ETA: 0s - loss: 0.8432 - accuracy: 0.63 - ETA: 0s - loss: 0.8418 - accuracy: 0.63 - ETA: 0s - loss: 0.8411 - accuracy: 0.63 - ETA: 0s - loss: 0.8426 - accuracy: 0.63 - ETA: 0s - loss: 0.8490 - accuracy: 0.62 - ETA: 0s - loss: 0.8440 - accuracy: 0.63 - ETA: 0s - loss: 0.8372 - accuracy: 0.64 - ETA: 0s - loss: 0.8189 - accuracy: 0.65 - ETA: 0s - loss: 0.8238 - accuracy: 0.65 - ETA: 0s - loss: 0.8351 - accuracy: 0.64 - ETA: 0s - loss: 0.8385 - accuracy: 0.63 - ETA: 0s - loss: 0.8451 - accuracy: 0.63 - ETA: 0s - loss: 0.8476 - accuracy: 0.63 - ETA: 0s - loss: 0.8497 - accuracy: 0.6321\n",
      "Epoch 00777: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8497 - accuracy: 0.6321 - val_loss: 1.0483 - val_accuracy: 0.4972 - lr: 0.0010\n",
      "Epoch 778/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8827 - accuracy: 0.56 - ETA: 0s - loss: 0.8560 - accuracy: 0.60 - ETA: 0s - loss: 0.8660 - accuracy: 0.60 - ETA: 0s - loss: 0.8436 - accuracy: 0.62 - ETA: 0s - loss: 0.8478 - accuracy: 0.62 - ETA: 0s - loss: 0.8416 - accuracy: 0.63 - ETA: 0s - loss: 0.8406 - accuracy: 0.63 - ETA: 0s - loss: 0.8377 - accuracy: 0.63 - ETA: 0s - loss: 0.8406 - accuracy: 0.63 - ETA: 0s - loss: 0.8492 - accuracy: 0.62 - ETA: 0s - loss: 0.8445 - accuracy: 0.63 - ETA: 0s - loss: 0.8366 - accuracy: 0.63 - ETA: 0s - loss: 0.8180 - accuracy: 0.65 - ETA: 0s - loss: 0.8229 - accuracy: 0.64 - ETA: 0s - loss: 0.8330 - accuracy: 0.63 - ETA: 0s - loss: 0.8366 - accuracy: 0.63 - ETA: 0s - loss: 0.8434 - accuracy: 0.63 - ETA: 0s - loss: 0.8463 - accuracy: 0.63 - ETA: 0s - loss: 0.8479 - accuracy: 0.6316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00778: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8479 - accuracy: 0.6316 - val_loss: 1.0525 - val_accuracy: 0.4871 - lr: 0.0010\n",
      "Epoch 779/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8875 - accuracy: 0.58 - ETA: 0s - loss: 0.8619 - accuracy: 0.61 - ETA: 0s - loss: 0.8773 - accuracy: 0.60 - ETA: 0s - loss: 0.8483 - accuracy: 0.62 - ETA: 0s - loss: 0.8525 - accuracy: 0.62 - ETA: 0s - loss: 0.8438 - accuracy: 0.63 - ETA: 0s - loss: 0.8427 - accuracy: 0.63 - ETA: 0s - loss: 0.8410 - accuracy: 0.63 - ETA: 0s - loss: 0.8429 - accuracy: 0.63 - ETA: 0s - loss: 0.8476 - accuracy: 0.62 - ETA: 0s - loss: 0.8436 - accuracy: 0.63 - ETA: 0s - loss: 0.8367 - accuracy: 0.64 - ETA: 0s - loss: 0.8176 - accuracy: 0.65 - ETA: 0s - loss: 0.8239 - accuracy: 0.65 - ETA: 0s - loss: 0.8354 - accuracy: 0.64 - ETA: 0s - loss: 0.8394 - accuracy: 0.63 - ETA: 0s - loss: 0.8451 - accuracy: 0.63 - ETA: 0s - loss: 0.8475 - accuracy: 0.63 - ETA: 0s - loss: 0.8499 - accuracy: 0.6298\n",
      "Epoch 00779: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8499 - accuracy: 0.6298 - val_loss: 1.0574 - val_accuracy: 0.4899 - lr: 0.0010\n",
      "Epoch 780/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8744 - accuracy: 0.59 - ETA: 0s - loss: 0.8528 - accuracy: 0.61 - ETA: 0s - loss: 0.8660 - accuracy: 0.61 - ETA: 0s - loss: 0.8424 - accuracy: 0.62 - ETA: 0s - loss: 0.8433 - accuracy: 0.62 - ETA: 0s - loss: 0.8385 - accuracy: 0.63 - ETA: 0s - loss: 0.8386 - accuracy: 0.63 - ETA: 0s - loss: 0.8378 - accuracy: 0.63 - ETA: 0s - loss: 0.8398 - accuracy: 0.63 - ETA: 0s - loss: 0.8448 - accuracy: 0.63 - ETA: 0s - loss: 0.8412 - accuracy: 0.63 - ETA: 0s - loss: 0.8354 - accuracy: 0.64 - ETA: 0s - loss: 0.8171 - accuracy: 0.65 - ETA: 0s - loss: 0.8222 - accuracy: 0.65 - ETA: 0s - loss: 0.8333 - accuracy: 0.64 - ETA: 0s - loss: 0.8369 - accuracy: 0.63 - ETA: 0s - loss: 0.8437 - accuracy: 0.63 - ETA: 0s - loss: 0.8455 - accuracy: 0.63 - ETA: 0s - loss: 0.8467 - accuracy: 0.6309\n",
      "Epoch 00780: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8467 - accuracy: 0.6309 - val_loss: 1.0564 - val_accuracy: 0.4951 - lr: 0.0010\n",
      "Epoch 781/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8944 - accuracy: 0.55 - ETA: 0s - loss: 0.8665 - accuracy: 0.59 - ETA: 0s - loss: 0.8843 - accuracy: 0.59 - ETA: 0s - loss: 0.8562 - accuracy: 0.61 - ETA: 0s - loss: 0.8580 - accuracy: 0.61 - ETA: 0s - loss: 0.8501 - accuracy: 0.62 - ETA: 0s - loss: 0.8452 - accuracy: 0.63 - ETA: 0s - loss: 0.8451 - accuracy: 0.63 - ETA: 0s - loss: 0.8472 - accuracy: 0.63 - ETA: 0s - loss: 0.8528 - accuracy: 0.62 - ETA: 0s - loss: 0.8475 - accuracy: 0.63 - ETA: 0s - loss: 0.8405 - accuracy: 0.63 - ETA: 0s - loss: 0.8216 - accuracy: 0.65 - ETA: 0s - loss: 0.8258 - accuracy: 0.64 - ETA: 0s - loss: 0.8373 - accuracy: 0.63 - ETA: 0s - loss: 0.8406 - accuracy: 0.63 - ETA: 0s - loss: 0.8476 - accuracy: 0.63 - ETA: 0s - loss: 0.8495 - accuracy: 0.63 - ETA: 0s - loss: 0.8513 - accuracy: 0.6291\n",
      "Epoch 00781: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00781: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8513 - accuracy: 0.6291 - val_loss: 1.0456 - val_accuracy: 0.4974 - lr: 0.0010\n",
      "Epoch 782/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8920 - accuracy: 0.57 - ETA: 0s - loss: 0.8619 - accuracy: 0.61 - ETA: 0s - loss: 0.8736 - accuracy: 0.60 - ETA: 0s - loss: 0.8462 - accuracy: 0.62 - ETA: 0s - loss: 0.8490 - accuracy: 0.62 - ETA: 0s - loss: 0.8421 - accuracy: 0.63 - ETA: 0s - loss: 0.8380 - accuracy: 0.64 - ETA: 0s - loss: 0.8370 - accuracy: 0.64 - ETA: 0s - loss: 0.8406 - accuracy: 0.63 - ETA: 0s - loss: 0.8461 - accuracy: 0.63 - ETA: 0s - loss: 0.8415 - accuracy: 0.63 - ETA: 0s - loss: 0.8351 - accuracy: 0.64 - ETA: 0s - loss: 0.8170 - accuracy: 0.65 - ETA: 0s - loss: 0.8239 - accuracy: 0.65 - ETA: 0s - loss: 0.8322 - accuracy: 0.64 - ETA: 0s - loss: 0.8367 - accuracy: 0.64 - ETA: 0s - loss: 0.8436 - accuracy: 0.63 - ETA: 0s - loss: 0.8460 - accuracy: 0.63 - ETA: 0s - loss: 0.8478 - accuracy: 0.6337\n",
      "Epoch 00782: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8478 - accuracy: 0.6337 - val_loss: 1.0561 - val_accuracy: 0.4946 - lr: 0.0010\n",
      "Epoch 783/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8889 - accuracy: 0.57 - ETA: 0s - loss: 0.8605 - accuracy: 0.61 - ETA: 0s - loss: 0.8673 - accuracy: 0.61 - ETA: 0s - loss: 0.8403 - accuracy: 0.62 - ETA: 0s - loss: 0.8402 - accuracy: 0.63 - ETA: 0s - loss: 0.8364 - accuracy: 0.63 - ETA: 0s - loss: 0.8351 - accuracy: 0.64 - ETA: 0s - loss: 0.8354 - accuracy: 0.64 - ETA: 0s - loss: 0.8381 - accuracy: 0.63 - ETA: 0s - loss: 0.8440 - accuracy: 0.63 - ETA: 0s - loss: 0.8398 - accuracy: 0.64 - ETA: 0s - loss: 0.8333 - accuracy: 0.64 - ETA: 0s - loss: 0.8153 - accuracy: 0.65 - ETA: 0s - loss: 0.8191 - accuracy: 0.65 - ETA: 0s - loss: 0.8316 - accuracy: 0.64 - ETA: 0s - loss: 0.8358 - accuracy: 0.64 - ETA: 0s - loss: 0.8417 - accuracy: 0.63 - ETA: 0s - loss: 0.8439 - accuracy: 0.63 - ETA: 0s - loss: 0.8461 - accuracy: 0.6342\n",
      "Epoch 00783: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8461 - accuracy: 0.6342 - val_loss: 1.0735 - val_accuracy: 0.4912 - lr: 0.0010\n",
      "Epoch 784/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8971 - accuracy: 0.57 - ETA: 0s - loss: 0.8679 - accuracy: 0.60 - ETA: 0s - loss: 0.8774 - accuracy: 0.60 - ETA: 0s - loss: 0.8491 - accuracy: 0.62 - ETA: 0s - loss: 0.8505 - accuracy: 0.62 - ETA: 0s - loss: 0.8446 - accuracy: 0.63 - ETA: 0s - loss: 0.8426 - accuracy: 0.63 - ETA: 0s - loss: 0.8412 - accuracy: 0.63 - ETA: 0s - loss: 0.8442 - accuracy: 0.63 - ETA: 0s - loss: 0.8514 - accuracy: 0.62 - ETA: 0s - loss: 0.8462 - accuracy: 0.63 - ETA: 0s - loss: 0.8386 - accuracy: 0.64 - ETA: 0s - loss: 0.8201 - accuracy: 0.65 - ETA: 0s - loss: 0.8249 - accuracy: 0.65 - ETA: 0s - loss: 0.8341 - accuracy: 0.64 - ETA: 0s - loss: 0.8373 - accuracy: 0.63 - ETA: 0s - loss: 0.8430 - accuracy: 0.63 - ETA: 0s - loss: 0.8447 - accuracy: 0.63 - ETA: 0s - loss: 0.8464 - accuracy: 0.6314\n",
      "Epoch 00784: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8464 - accuracy: 0.6314 - val_loss: 1.0632 - val_accuracy: 0.4959 - lr: 0.0010\n",
      "Epoch 785/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8889 - accuracy: 0.58 - ETA: 0s - loss: 0.8570 - accuracy: 0.60 - ETA: 0s - loss: 0.8745 - accuracy: 0.60 - ETA: 0s - loss: 0.8449 - accuracy: 0.62 - ETA: 0s - loss: 0.8454 - accuracy: 0.62 - ETA: 0s - loss: 0.8385 - accuracy: 0.63 - ETA: 0s - loss: 0.8354 - accuracy: 0.63 - ETA: 0s - loss: 0.8354 - accuracy: 0.63 - ETA: 0s - loss: 0.8380 - accuracy: 0.63 - ETA: 0s - loss: 0.8434 - accuracy: 0.62 - ETA: 0s - loss: 0.8380 - accuracy: 0.63 - ETA: 0s - loss: 0.8318 - accuracy: 0.64 - ETA: 0s - loss: 0.8132 - accuracy: 0.65 - ETA: 0s - loss: 0.8181 - accuracy: 0.65 - ETA: 0s - loss: 0.8289 - accuracy: 0.64 - ETA: 0s - loss: 0.8319 - accuracy: 0.63 - ETA: 0s - loss: 0.8379 - accuracy: 0.63 - ETA: 0s - loss: 0.8410 - accuracy: 0.63 - ETA: 0s - loss: 0.8428 - accuracy: 0.6323\n",
      "Epoch 00785: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8428 - accuracy: 0.6323 - val_loss: 1.0458 - val_accuracy: 0.4966 - lr: 0.0010\n",
      "Epoch 786/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.8833 - accuracy: 0.56 - ETA: 0s - loss: 0.8567 - accuracy: 0.60 - ETA: 0s - loss: 0.8668 - accuracy: 0.60 - ETA: 0s - loss: 0.8440 - accuracy: 0.62 - ETA: 0s - loss: 0.8495 - accuracy: 0.62 - ETA: 0s - loss: 0.8429 - accuracy: 0.63 - ETA: 0s - loss: 0.8399 - accuracy: 0.63 - ETA: 0s - loss: 0.8391 - accuracy: 0.64 - ETA: 0s - loss: 0.8417 - accuracy: 0.63 - ETA: 0s - loss: 0.8464 - accuracy: 0.63 - ETA: 0s - loss: 0.8420 - accuracy: 0.63 - ETA: 0s - loss: 0.8356 - accuracy: 0.64 - ETA: 0s - loss: 0.8176 - accuracy: 0.65 - ETA: 0s - loss: 0.8232 - accuracy: 0.65 - ETA: 0s - loss: 0.8317 - accuracy: 0.64 - ETA: 0s - loss: 0.8359 - accuracy: 0.63 - ETA: 0s - loss: 0.8421 - accuracy: 0.63 - ETA: 0s - loss: 0.8447 - accuracy: 0.63 - ETA: 0s - loss: 0.8464 - accuracy: 0.6324\n",
      "Epoch 00786: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8464 - accuracy: 0.6324 - val_loss: 1.0578 - val_accuracy: 0.4971 - lr: 0.0010\n",
      "Epoch 787/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8903 - accuracy: 0.57 - ETA: 0s - loss: 0.8562 - accuracy: 0.60 - ETA: 0s - loss: 0.8647 - accuracy: 0.60 - ETA: 0s - loss: 0.8386 - accuracy: 0.62 - ETA: 0s - loss: 0.8415 - accuracy: 0.62 - ETA: 0s - loss: 0.8381 - accuracy: 0.63 - ETA: 0s - loss: 0.8364 - accuracy: 0.63 - ETA: 0s - loss: 0.8358 - accuracy: 0.63 - ETA: 0s - loss: 0.8372 - accuracy: 0.63 - ETA: 0s - loss: 0.8435 - accuracy: 0.62 - ETA: 0s - loss: 0.8395 - accuracy: 0.63 - ETA: 0s - loss: 0.8336 - accuracy: 0.64 - ETA: 0s - loss: 0.8156 - accuracy: 0.65 - ETA: 0s - loss: 0.8213 - accuracy: 0.65 - ETA: 0s - loss: 0.8316 - accuracy: 0.64 - ETA: 0s - loss: 0.8349 - accuracy: 0.63 - ETA: 0s - loss: 0.8413 - accuracy: 0.63 - ETA: 0s - loss: 0.8442 - accuracy: 0.63 - ETA: 0s - loss: 0.8458 - accuracy: 0.6329\n",
      "Epoch 00787: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8458 - accuracy: 0.6329 - val_loss: 1.0572 - val_accuracy: 0.4989 - lr: 0.0010\n",
      "Epoch 788/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8986 - accuracy: 0.55 - ETA: 0s - loss: 0.8627 - accuracy: 0.60 - ETA: 0s - loss: 0.8751 - accuracy: 0.60 - ETA: 0s - loss: 0.8471 - accuracy: 0.62 - ETA: 0s - loss: 0.8491 - accuracy: 0.62 - ETA: 0s - loss: 0.8424 - accuracy: 0.63 - ETA: 0s - loss: 0.8391 - accuracy: 0.63 - ETA: 0s - loss: 0.8358 - accuracy: 0.63 - ETA: 0s - loss: 0.8389 - accuracy: 0.63 - ETA: 0s - loss: 0.8449 - accuracy: 0.63 - ETA: 0s - loss: 0.8412 - accuracy: 0.63 - ETA: 0s - loss: 0.8338 - accuracy: 0.64 - ETA: 0s - loss: 0.8152 - accuracy: 0.65 - ETA: 0s - loss: 0.8219 - accuracy: 0.65 - ETA: 0s - loss: 0.8320 - accuracy: 0.64 - ETA: 0s - loss: 0.8354 - accuracy: 0.63 - ETA: 0s - loss: 0.8420 - accuracy: 0.63 - ETA: 0s - loss: 0.8443 - accuracy: 0.63 - ETA: 0s - loss: 0.8456 - accuracy: 0.6327\n",
      "Epoch 00788: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8456 - accuracy: 0.6327 - val_loss: 1.0491 - val_accuracy: 0.4990 - lr: 0.0010\n",
      "Epoch 789/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8818 - accuracy: 0.59 - ETA: 0s - loss: 0.8481 - accuracy: 0.62 - ETA: 0s - loss: 0.8609 - accuracy: 0.61 - ETA: 0s - loss: 0.8355 - accuracy: 0.63 - ETA: 0s - loss: 0.8407 - accuracy: 0.63 - ETA: 0s - loss: 0.8353 - accuracy: 0.64 - ETA: 0s - loss: 0.8335 - accuracy: 0.64 - ETA: 0s - loss: 0.8330 - accuracy: 0.64 - ETA: 0s - loss: 0.8369 - accuracy: 0.64 - ETA: 0s - loss: 0.8434 - accuracy: 0.63 - ETA: 0s - loss: 0.8381 - accuracy: 0.64 - ETA: 0s - loss: 0.8322 - accuracy: 0.64 - ETA: 0s - loss: 0.8137 - accuracy: 0.65 - ETA: 0s - loss: 0.8182 - accuracy: 0.65 - ETA: 0s - loss: 0.8292 - accuracy: 0.64 - ETA: 0s - loss: 0.8329 - accuracy: 0.64 - ETA: 0s - loss: 0.8395 - accuracy: 0.63 - ETA: 0s - loss: 0.8416 - accuracy: 0.63 - ETA: 0s - loss: 0.8435 - accuracy: 0.6338\n",
      "Epoch 00789: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8435 - accuracy: 0.6338 - val_loss: 1.0570 - val_accuracy: 0.4943 - lr: 0.0010\n",
      "Epoch 790/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9042 - accuracy: 0.58 - ETA: 0s - loss: 0.8575 - accuracy: 0.60 - ETA: 0s - loss: 0.8653 - accuracy: 0.60 - ETA: 0s - loss: 0.8403 - accuracy: 0.62 - ETA: 0s - loss: 0.8447 - accuracy: 0.62 - ETA: 0s - loss: 0.8373 - accuracy: 0.63 - ETA: 0s - loss: 0.8362 - accuracy: 0.64 - ETA: 0s - loss: 0.8352 - accuracy: 0.64 - ETA: 0s - loss: 0.8382 - accuracy: 0.63 - ETA: 0s - loss: 0.8451 - accuracy: 0.63 - ETA: 0s - loss: 0.8409 - accuracy: 0.63 - ETA: 0s - loss: 0.8342 - accuracy: 0.64 - ETA: 0s - loss: 0.8160 - accuracy: 0.65 - ETA: 0s - loss: 0.8226 - accuracy: 0.65 - ETA: 0s - loss: 0.8342 - accuracy: 0.64 - ETA: 0s - loss: 0.8378 - accuracy: 0.64 - ETA: 0s - loss: 0.8440 - accuracy: 0.63 - ETA: 0s - loss: 0.8461 - accuracy: 0.63 - ETA: 0s - loss: 0.8471 - accuracy: 0.6347\n",
      "Epoch 00790: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8471 - accuracy: 0.6347 - val_loss: 1.0632 - val_accuracy: 0.4871 - lr: 0.0010\n",
      "Epoch 791/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9085 - accuracy: 0.56 - ETA: 0s - loss: 0.8602 - accuracy: 0.59 - ETA: 0s - loss: 0.8748 - accuracy: 0.59 - ETA: 0s - loss: 0.8480 - accuracy: 0.61 - ETA: 0s - loss: 0.8527 - accuracy: 0.61 - ETA: 0s - loss: 0.8468 - accuracy: 0.62 - ETA: 0s - loss: 0.8441 - accuracy: 0.63 - ETA: 0s - loss: 0.8442 - accuracy: 0.63 - ETA: 0s - loss: 0.8469 - accuracy: 0.62 - ETA: 0s - loss: 0.8522 - accuracy: 0.62 - ETA: 0s - loss: 0.8469 - accuracy: 0.63 - ETA: 0s - loss: 0.8400 - accuracy: 0.63 - ETA: 0s - loss: 0.8211 - accuracy: 0.65 - ETA: 0s - loss: 0.8251 - accuracy: 0.64 - ETA: 0s - loss: 0.8364 - accuracy: 0.63 - ETA: 0s - loss: 0.8395 - accuracy: 0.63 - ETA: 0s - loss: 0.8447 - accuracy: 0.63 - ETA: 0s - loss: 0.8467 - accuracy: 0.63 - ETA: 0s - loss: 0.8479 - accuracy: 0.6287\n",
      "Epoch 00791: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8479 - accuracy: 0.6287 - val_loss: 1.0533 - val_accuracy: 0.4912 - lr: 0.0010\n",
      "Epoch 792/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8981 - accuracy: 0.55 - ETA: 0s - loss: 0.8583 - accuracy: 0.59 - ETA: 0s - loss: 0.8739 - accuracy: 0.60 - ETA: 0s - loss: 0.8446 - accuracy: 0.62 - ETA: 0s - loss: 0.8484 - accuracy: 0.62 - ETA: 0s - loss: 0.8405 - accuracy: 0.63 - ETA: 0s - loss: 0.8403 - accuracy: 0.63 - ETA: 0s - loss: 0.8398 - accuracy: 0.63 - ETA: 0s - loss: 0.8444 - accuracy: 0.63 - ETA: 0s - loss: 0.8507 - accuracy: 0.62 - ETA: 0s - loss: 0.8465 - accuracy: 0.63 - ETA: 0s - loss: 0.8417 - accuracy: 0.63 - ETA: 0s - loss: 0.8230 - accuracy: 0.65 - ETA: 0s - loss: 0.8285 - accuracy: 0.65 - ETA: 0s - loss: 0.8374 - accuracy: 0.64 - ETA: 0s - loss: 0.8409 - accuracy: 0.63 - ETA: 0s - loss: 0.8470 - accuracy: 0.63 - ETA: 0s - loss: 0.8486 - accuracy: 0.63 - ETA: 0s - loss: 0.8504 - accuracy: 0.6321\n",
      "Epoch 00792: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8504 - accuracy: 0.6321 - val_loss: 1.0474 - val_accuracy: 0.4896 - lr: 0.0010\n",
      "Epoch 793/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9058 - accuracy: 0.56 - ETA: 0s - loss: 0.8696 - accuracy: 0.60 - ETA: 0s - loss: 0.8836 - accuracy: 0.60 - ETA: 0s - loss: 0.8549 - accuracy: 0.62 - ETA: 0s - loss: 0.8543 - accuracy: 0.62 - ETA: 0s - loss: 0.8453 - accuracy: 0.63 - ETA: 0s - loss: 0.8413 - accuracy: 0.63 - ETA: 0s - loss: 0.8414 - accuracy: 0.63 - ETA: 0s - loss: 0.8427 - accuracy: 0.63 - ETA: 0s - loss: 0.8471 - accuracy: 0.63 - ETA: 0s - loss: 0.8436 - accuracy: 0.63 - ETA: 0s - loss: 0.8365 - accuracy: 0.64 - ETA: 0s - loss: 0.8175 - accuracy: 0.65 - ETA: 0s - loss: 0.8228 - accuracy: 0.65 - ETA: 0s - loss: 0.8349 - accuracy: 0.64 - ETA: 0s - loss: 0.8383 - accuracy: 0.63 - ETA: 0s - loss: 0.8456 - accuracy: 0.63 - ETA: 0s - loss: 0.8470 - accuracy: 0.63 - ETA: 0s - loss: 0.8480 - accuracy: 0.6325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00793: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8480 - accuracy: 0.6325 - val_loss: 1.0490 - val_accuracy: 0.4959 - lr: 0.0010\n",
      "Epoch 794/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9104 - accuracy: 0.55 - ETA: 0s - loss: 0.8640 - accuracy: 0.60 - ETA: 0s - loss: 0.8780 - accuracy: 0.59 - ETA: 0s - loss: 0.8511 - accuracy: 0.61 - ETA: 0s - loss: 0.8510 - accuracy: 0.62 - ETA: 0s - loss: 0.8436 - accuracy: 0.63 - ETA: 0s - loss: 0.8411 - accuracy: 0.63 - ETA: 0s - loss: 0.8389 - accuracy: 0.63 - ETA: 0s - loss: 0.8423 - accuracy: 0.63 - ETA: 0s - loss: 0.8475 - accuracy: 0.63 - ETA: 0s - loss: 0.8431 - accuracy: 0.63 - ETA: 0s - loss: 0.8372 - accuracy: 0.64 - ETA: 0s - loss: 0.8185 - accuracy: 0.65 - ETA: 0s - loss: 0.8236 - accuracy: 0.65 - ETA: 0s - loss: 0.8335 - accuracy: 0.63 - ETA: 0s - loss: 0.8376 - accuracy: 0.63 - ETA: 0s - loss: 0.8439 - accuracy: 0.63 - ETA: 0s - loss: 0.8465 - accuracy: 0.63 - ETA: 0s - loss: 0.8475 - accuracy: 0.6309\n",
      "Epoch 00794: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8475 - accuracy: 0.6309 - val_loss: 1.0471 - val_accuracy: 0.4993 - lr: 0.0010\n",
      "Epoch 795/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9257 - accuracy: 0.56 - ETA: 0s - loss: 0.8731 - accuracy: 0.60 - ETA: 0s - loss: 0.8820 - accuracy: 0.60 - ETA: 0s - loss: 0.8505 - accuracy: 0.62 - ETA: 0s - loss: 0.8503 - accuracy: 0.62 - ETA: 0s - loss: 0.8417 - accuracy: 0.63 - ETA: 0s - loss: 0.8379 - accuracy: 0.63 - ETA: 0s - loss: 0.8370 - accuracy: 0.63 - ETA: 0s - loss: 0.8395 - accuracy: 0.63 - ETA: 0s - loss: 0.8438 - accuracy: 0.63 - ETA: 0s - loss: 0.8410 - accuracy: 0.63 - ETA: 0s - loss: 0.8351 - accuracy: 0.64 - ETA: 0s - loss: 0.8182 - accuracy: 0.65 - ETA: 0s - loss: 0.8233 - accuracy: 0.65 - ETA: 0s - loss: 0.8335 - accuracy: 0.64 - ETA: 0s - loss: 0.8365 - accuracy: 0.64 - ETA: 0s - loss: 0.8419 - accuracy: 0.63 - ETA: 0s - loss: 0.8449 - accuracy: 0.63 - ETA: 0s - loss: 0.8461 - accuracy: 0.6358\n",
      "Epoch 00795: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00795: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8461 - accuracy: 0.6358 - val_loss: 1.0437 - val_accuracy: 0.5024 - lr: 0.0010\n",
      "Epoch 796/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8915 - accuracy: 0.58 - ETA: 0s - loss: 0.8652 - accuracy: 0.60 - ETA: 0s - loss: 0.8716 - accuracy: 0.60 - ETA: 0s - loss: 0.8448 - accuracy: 0.62 - ETA: 0s - loss: 0.8470 - accuracy: 0.62 - ETA: 0s - loss: 0.8398 - accuracy: 0.63 - ETA: 0s - loss: 0.8384 - accuracy: 0.64 - ETA: 0s - loss: 0.8364 - accuracy: 0.64 - ETA: 0s - loss: 0.8397 - accuracy: 0.64 - ETA: 0s - loss: 0.8460 - accuracy: 0.63 - ETA: 0s - loss: 0.8415 - accuracy: 0.64 - ETA: 0s - loss: 0.8339 - accuracy: 0.64 - ETA: 0s - loss: 0.8151 - accuracy: 0.65 - ETA: 0s - loss: 0.8216 - accuracy: 0.65 - ETA: 0s - loss: 0.8324 - accuracy: 0.64 - ETA: 0s - loss: 0.8359 - accuracy: 0.63 - ETA: 0s - loss: 0.8414 - accuracy: 0.63 - ETA: 0s - loss: 0.8445 - accuracy: 0.63 - ETA: 0s - loss: 0.8455 - accuracy: 0.6324\n",
      "Epoch 00796: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8455 - accuracy: 0.6324 - val_loss: 1.0490 - val_accuracy: 0.4987 - lr: 0.0010\n",
      "Epoch 797/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8980 - accuracy: 0.56 - ETA: 0s - loss: 0.8594 - accuracy: 0.60 - ETA: 0s - loss: 0.8690 - accuracy: 0.60 - ETA: 0s - loss: 0.8439 - accuracy: 0.62 - ETA: 0s - loss: 0.8450 - accuracy: 0.62 - ETA: 0s - loss: 0.8381 - accuracy: 0.63 - ETA: 0s - loss: 0.8367 - accuracy: 0.63 - ETA: 0s - loss: 0.8347 - accuracy: 0.64 - ETA: 0s - loss: 0.8362 - accuracy: 0.63 - ETA: 0s - loss: 0.8443 - accuracy: 0.63 - ETA: 0s - loss: 0.8416 - accuracy: 0.63 - ETA: 0s - loss: 0.8343 - accuracy: 0.64 - ETA: 0s - loss: 0.8154 - accuracy: 0.65 - ETA: 0s - loss: 0.8205 - accuracy: 0.65 - ETA: 0s - loss: 0.8306 - accuracy: 0.64 - ETA: 0s - loss: 0.8343 - accuracy: 0.63 - ETA: 0s - loss: 0.8410 - accuracy: 0.63 - ETA: 0s - loss: 0.8435 - accuracy: 0.63 - ETA: 0s - loss: 0.8451 - accuracy: 0.6330\n",
      "Epoch 00797: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8451 - accuracy: 0.6330 - val_loss: 1.0477 - val_accuracy: 0.4972 - lr: 0.0010\n",
      "Epoch 798/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9104 - accuracy: 0.55 - ETA: 0s - loss: 0.8752 - accuracy: 0.59 - ETA: 0s - loss: 0.8872 - accuracy: 0.60 - ETA: 0s - loss: 0.8562 - accuracy: 0.62 - ETA: 0s - loss: 0.8555 - accuracy: 0.62 - ETA: 0s - loss: 0.8497 - accuracy: 0.63 - ETA: 0s - loss: 0.8454 - accuracy: 0.63 - ETA: 0s - loss: 0.8439 - accuracy: 0.63 - ETA: 0s - loss: 0.8457 - accuracy: 0.63 - ETA: 0s - loss: 0.8512 - accuracy: 0.62 - ETA: 0s - loss: 0.8463 - accuracy: 0.63 - ETA: 0s - loss: 0.8392 - accuracy: 0.64 - ETA: 0s - loss: 0.8200 - accuracy: 0.65 - ETA: 0s - loss: 0.8243 - accuracy: 0.65 - ETA: 0s - loss: 0.8340 - accuracy: 0.64 - ETA: 0s - loss: 0.8374 - accuracy: 0.63 - ETA: 0s - loss: 0.8437 - accuracy: 0.63 - ETA: 0s - loss: 0.8473 - accuracy: 0.6316\n",
      "Epoch 00798: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8473 - accuracy: 0.6316 - val_loss: 1.0544 - val_accuracy: 0.4989 - lr: 0.0010\n",
      "Epoch 799/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8695 - accuracy: 0.59 - ETA: 0s - loss: 0.8619 - accuracy: 0.61 - ETA: 0s - loss: 0.8758 - accuracy: 0.61 - ETA: 0s - loss: 0.8454 - accuracy: 0.62 - ETA: 0s - loss: 0.8456 - accuracy: 0.63 - ETA: 0s - loss: 0.8390 - accuracy: 0.63 - ETA: 0s - loss: 0.8377 - accuracy: 0.64 - ETA: 0s - loss: 0.8367 - accuracy: 0.64 - ETA: 0s - loss: 0.8392 - accuracy: 0.64 - ETA: 0s - loss: 0.8491 - accuracy: 0.63 - ETA: 0s - loss: 0.8442 - accuracy: 0.63 - ETA: 0s - loss: 0.8367 - accuracy: 0.64 - ETA: 0s - loss: 0.8186 - accuracy: 0.65 - ETA: 0s - loss: 0.8244 - accuracy: 0.65 - ETA: 0s - loss: 0.8344 - accuracy: 0.64 - ETA: 0s - loss: 0.8379 - accuracy: 0.63 - ETA: 0s - loss: 0.8451 - accuracy: 0.63 - ETA: 0s - loss: 0.8469 - accuracy: 0.63 - ETA: 0s - loss: 0.8488 - accuracy: 0.6321\n",
      "Epoch 00799: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8488 - accuracy: 0.6321 - val_loss: 1.0567 - val_accuracy: 0.4953 - lr: 0.0010\n",
      "Epoch 800/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9169 - accuracy: 0.55 - ETA: 0s - loss: 0.8757 - accuracy: 0.59 - ETA: 0s - loss: 0.8793 - accuracy: 0.59 - ETA: 0s - loss: 0.8490 - accuracy: 0.61 - ETA: 0s - loss: 0.8526 - accuracy: 0.61 - ETA: 0s - loss: 0.8442 - accuracy: 0.62 - ETA: 0s - loss: 0.8417 - accuracy: 0.63 - ETA: 0s - loss: 0.8400 - accuracy: 0.63 - ETA: 0s - loss: 0.8427 - accuracy: 0.63 - ETA: 0s - loss: 0.8497 - accuracy: 0.62 - ETA: 0s - loss: 0.8440 - accuracy: 0.63 - ETA: 0s - loss: 0.8373 - accuracy: 0.63 - ETA: 0s - loss: 0.8190 - accuracy: 0.65 - ETA: 0s - loss: 0.8251 - accuracy: 0.64 - ETA: 0s - loss: 0.8343 - accuracy: 0.63 - ETA: 0s - loss: 0.8378 - accuracy: 0.63 - ETA: 0s - loss: 0.8442 - accuracy: 0.63 - ETA: 0s - loss: 0.8460 - accuracy: 0.63 - ETA: 0s - loss: 0.8474 - accuracy: 0.6291\n",
      "Epoch 00800: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8474 - accuracy: 0.6291 - val_loss: 1.0518 - val_accuracy: 0.4961 - lr: 0.0010\n",
      "Epoch 801/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9050 - accuracy: 0.56 - ETA: 0s - loss: 0.8615 - accuracy: 0.61 - ETA: 0s - loss: 0.8686 - accuracy: 0.61 - ETA: 0s - loss: 0.8438 - accuracy: 0.62 - ETA: 0s - loss: 0.8449 - accuracy: 0.62 - ETA: 0s - loss: 0.8385 - accuracy: 0.63 - ETA: 0s - loss: 0.8367 - accuracy: 0.63 - ETA: 0s - loss: 0.8360 - accuracy: 0.63 - ETA: 0s - loss: 0.8396 - accuracy: 0.63 - ETA: 0s - loss: 0.8461 - accuracy: 0.62 - ETA: 0s - loss: 0.8419 - accuracy: 0.63 - ETA: 0s - loss: 0.8351 - accuracy: 0.64 - ETA: 0s - loss: 0.8170 - accuracy: 0.65 - ETA: 0s - loss: 0.8217 - accuracy: 0.65 - ETA: 0s - loss: 0.8329 - accuracy: 0.63 - ETA: 0s - loss: 0.8362 - accuracy: 0.63 - ETA: 0s - loss: 0.8432 - accuracy: 0.63 - ETA: 0s - loss: 0.8457 - accuracy: 0.63 - ETA: 0s - loss: 0.8475 - accuracy: 0.6299\n",
      "Epoch 00801: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8475 - accuracy: 0.6299 - val_loss: 1.0496 - val_accuracy: 0.4904 - lr: 0.0010\n",
      "Epoch 802/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8856 - accuracy: 0.58 - ETA: 0s - loss: 0.8518 - accuracy: 0.62 - ETA: 0s - loss: 0.8645 - accuracy: 0.61 - ETA: 0s - loss: 0.8388 - accuracy: 0.62 - ETA: 0s - loss: 0.8453 - accuracy: 0.62 - ETA: 0s - loss: 0.8389 - accuracy: 0.63 - ETA: 0s - loss: 0.8356 - accuracy: 0.63 - ETA: 0s - loss: 0.8357 - accuracy: 0.64 - ETA: 0s - loss: 0.8383 - accuracy: 0.63 - ETA: 0s - loss: 0.8427 - accuracy: 0.63 - ETA: 0s - loss: 0.8390 - accuracy: 0.63 - ETA: 0s - loss: 0.8325 - accuracy: 0.64 - ETA: 0s - loss: 0.8139 - accuracy: 0.65 - ETA: 0s - loss: 0.8194 - accuracy: 0.65 - ETA: 0s - loss: 0.8299 - accuracy: 0.64 - ETA: 0s - loss: 0.8333 - accuracy: 0.64 - ETA: 0s - loss: 0.8400 - accuracy: 0.63 - ETA: 0s - loss: 0.8422 - accuracy: 0.63 - ETA: 0s - loss: 0.8440 - accuracy: 0.6357\n",
      "Epoch 00802: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8440 - accuracy: 0.6357 - val_loss: 1.0575 - val_accuracy: 0.4933 - lr: 0.0010\n",
      "Epoch 803/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8807 - accuracy: 0.58 - ETA: 0s - loss: 0.8573 - accuracy: 0.60 - ETA: 0s - loss: 0.8662 - accuracy: 0.60 - ETA: 0s - loss: 0.8407 - accuracy: 0.62 - ETA: 0s - loss: 0.8464 - accuracy: 0.62 - ETA: 0s - loss: 0.8411 - accuracy: 0.63 - ETA: 0s - loss: 0.8387 - accuracy: 0.63 - ETA: 0s - loss: 0.8377 - accuracy: 0.63 - ETA: 0s - loss: 0.8406 - accuracy: 0.63 - ETA: 0s - loss: 0.8473 - accuracy: 0.62 - ETA: 0s - loss: 0.8419 - accuracy: 0.63 - ETA: 0s - loss: 0.8355 - accuracy: 0.64 - ETA: 0s - loss: 0.8169 - accuracy: 0.65 - ETA: 0s - loss: 0.8223 - accuracy: 0.65 - ETA: 0s - loss: 0.8321 - accuracy: 0.64 - ETA: 0s - loss: 0.8351 - accuracy: 0.63 - ETA: 0s - loss: 0.8421 - accuracy: 0.63 - ETA: 0s - loss: 0.8437 - accuracy: 0.63 - ETA: 0s - loss: 0.8456 - accuracy: 0.6312\n",
      "Epoch 00803: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8456 - accuracy: 0.6312 - val_loss: 1.0525 - val_accuracy: 0.4949 - lr: 0.0010\n",
      "Epoch 804/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9024 - accuracy: 0.56 - ETA: 0s - loss: 0.8587 - accuracy: 0.61 - ETA: 0s - loss: 0.8682 - accuracy: 0.61 - ETA: 0s - loss: 0.8404 - accuracy: 0.62 - ETA: 0s - loss: 0.8445 - accuracy: 0.62 - ETA: 0s - loss: 0.8379 - accuracy: 0.63 - ETA: 0s - loss: 0.8357 - accuracy: 0.63 - ETA: 0s - loss: 0.8343 - accuracy: 0.64 - ETA: 0s - loss: 0.8361 - accuracy: 0.64 - ETA: 0s - loss: 0.8431 - accuracy: 0.63 - ETA: 0s - loss: 0.8385 - accuracy: 0.64 - ETA: 0s - loss: 0.8310 - accuracy: 0.64 - ETA: 0s - loss: 0.8138 - accuracy: 0.65 - ETA: 0s - loss: 0.8188 - accuracy: 0.65 - ETA: 0s - loss: 0.8301 - accuracy: 0.64 - ETA: 0s - loss: 0.8333 - accuracy: 0.64 - ETA: 0s - loss: 0.8393 - accuracy: 0.63 - ETA: 0s - loss: 0.8413 - accuracy: 0.63 - ETA: 0s - loss: 0.8433 - accuracy: 0.6356\n",
      "Epoch 00804: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8433 - accuracy: 0.6356 - val_loss: 1.0542 - val_accuracy: 0.4945 - lr: 0.0010\n",
      "Epoch 805/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8950 - accuracy: 0.56 - ETA: 0s - loss: 0.8583 - accuracy: 0.60 - ETA: 0s - loss: 0.8795 - accuracy: 0.60 - ETA: 0s - loss: 0.8518 - accuracy: 0.62 - ETA: 0s - loss: 0.8522 - accuracy: 0.62 - ETA: 0s - loss: 0.8472 - accuracy: 0.63 - ETA: 0s - loss: 0.8443 - accuracy: 0.63 - ETA: 0s - loss: 0.8414 - accuracy: 0.63 - ETA: 0s - loss: 0.8432 - accuracy: 0.63 - ETA: 0s - loss: 0.8485 - accuracy: 0.63 - ETA: 0s - loss: 0.8441 - accuracy: 0.63 - ETA: 0s - loss: 0.8380 - accuracy: 0.64 - ETA: 0s - loss: 0.8197 - accuracy: 0.65 - ETA: 0s - loss: 0.8243 - accuracy: 0.65 - ETA: 0s - loss: 0.8373 - accuracy: 0.64 - ETA: 0s - loss: 0.8401 - accuracy: 0.63 - ETA: 0s - loss: 0.8461 - accuracy: 0.63 - ETA: 0s - loss: 0.8476 - accuracy: 0.63 - ETA: 0s - loss: 0.8484 - accuracy: 0.6330\n",
      "Epoch 00805: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8484 - accuracy: 0.6330 - val_loss: 1.0643 - val_accuracy: 0.5037 - lr: 0.0010\n",
      "Epoch 806/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8965 - accuracy: 0.57 - ETA: 0s - loss: 0.8719 - accuracy: 0.60 - ETA: 0s - loss: 0.8812 - accuracy: 0.60 - ETA: 0s - loss: 0.8525 - accuracy: 0.62 - ETA: 0s - loss: 0.8548 - accuracy: 0.62 - ETA: 0s - loss: 0.8486 - accuracy: 0.63 - ETA: 0s - loss: 0.8454 - accuracy: 0.63 - ETA: 0s - loss: 0.8506 - accuracy: 0.63 - ETA: 0s - loss: 0.8555 - accuracy: 0.63 - ETA: 0s - loss: 0.8608 - accuracy: 0.62 - ETA: 0s - loss: 0.8539 - accuracy: 0.63 - ETA: 0s - loss: 0.8463 - accuracy: 0.63 - ETA: 0s - loss: 0.8276 - accuracy: 0.65 - ETA: 0s - loss: 0.8345 - accuracy: 0.64 - ETA: 0s - loss: 0.8432 - accuracy: 0.63 - ETA: 0s - loss: 0.8467 - accuracy: 0.63 - ETA: 0s - loss: 0.8530 - accuracy: 0.62 - ETA: 0s - loss: 0.8550 - accuracy: 0.62 - ETA: 0s - loss: 0.8558 - accuracy: 0.6257\n",
      "Epoch 00806: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8558 - accuracy: 0.6257 - val_loss: 1.0464 - val_accuracy: 0.4985 - lr: 0.0010\n",
      "Epoch 807/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8974 - accuracy: 0.56 - ETA: 0s - loss: 0.8574 - accuracy: 0.61 - ETA: 0s - loss: 0.8725 - accuracy: 0.60 - ETA: 0s - loss: 0.8426 - accuracy: 0.62 - ETA: 0s - loss: 0.8491 - accuracy: 0.62 - ETA: 0s - loss: 0.8444 - accuracy: 0.63 - ETA: 0s - loss: 0.8416 - accuracy: 0.63 - ETA: 0s - loss: 0.8427 - accuracy: 0.63 - ETA: 0s - loss: 0.8451 - accuracy: 0.63 - ETA: 0s - loss: 0.8518 - accuracy: 0.62 - ETA: 0s - loss: 0.8465 - accuracy: 0.63 - ETA: 0s - loss: 0.8385 - accuracy: 0.64 - ETA: 0s - loss: 0.8201 - accuracy: 0.65 - ETA: 0s - loss: 0.8257 - accuracy: 0.64 - ETA: 0s - loss: 0.8356 - accuracy: 0.63 - ETA: 0s - loss: 0.8393 - accuracy: 0.63 - ETA: 0s - loss: 0.8458 - accuracy: 0.63 - ETA: 0s - loss: 0.8477 - accuracy: 0.63 - ETA: 0s - loss: 0.8492 - accuracy: 0.6317\n",
      "Epoch 00807: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8492 - accuracy: 0.6317 - val_loss: 1.0432 - val_accuracy: 0.4998 - lr: 0.0010\n",
      "Epoch 808/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8999 - accuracy: 0.56 - ETA: 0s - loss: 0.8632 - accuracy: 0.61 - ETA: 0s - loss: 0.8685 - accuracy: 0.61 - ETA: 0s - loss: 0.8411 - accuracy: 0.62 - ETA: 0s - loss: 0.8441 - accuracy: 0.63 - ETA: 0s - loss: 0.8403 - accuracy: 0.63 - ETA: 0s - loss: 0.8378 - accuracy: 0.64 - ETA: 0s - loss: 0.8356 - accuracy: 0.64 - ETA: 0s - loss: 0.8387 - accuracy: 0.64 - ETA: 0s - loss: 0.8448 - accuracy: 0.63 - ETA: 0s - loss: 0.8393 - accuracy: 0.63 - ETA: 0s - loss: 0.8326 - accuracy: 0.64 - ETA: 0s - loss: 0.8147 - accuracy: 0.65 - ETA: 0s - loss: 0.8183 - accuracy: 0.65 - ETA: 0s - loss: 0.8271 - accuracy: 0.64 - ETA: 0s - loss: 0.8306 - accuracy: 0.64 - ETA: 0s - loss: 0.8372 - accuracy: 0.63 - ETA: 0s - loss: 0.8396 - accuracy: 0.63 - ETA: 0s - loss: 0.8415 - accuracy: 0.6365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00808: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8415 - accuracy: 0.6365 - val_loss: 1.0385 - val_accuracy: 0.4933 - lr: 0.0010\n",
      "Epoch 809/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9023 - accuracy: 0.57 - ETA: 0s - loss: 0.8640 - accuracy: 0.61 - ETA: 0s - loss: 0.8736 - accuracy: 0.61 - ETA: 0s - loss: 0.8462 - accuracy: 0.62 - ETA: 0s - loss: 0.8518 - accuracy: 0.62 - ETA: 0s - loss: 0.8458 - accuracy: 0.63 - ETA: 0s - loss: 0.8421 - accuracy: 0.64 - ETA: 0s - loss: 0.8411 - accuracy: 0.64 - ETA: 0s - loss: 0.8427 - accuracy: 0.64 - ETA: 0s - loss: 0.8481 - accuracy: 0.63 - ETA: 0s - loss: 0.8432 - accuracy: 0.64 - ETA: 0s - loss: 0.8363 - accuracy: 0.64 - ETA: 0s - loss: 0.8178 - accuracy: 0.66 - ETA: 0s - loss: 0.8238 - accuracy: 0.65 - ETA: 0s - loss: 0.8316 - accuracy: 0.64 - ETA: 0s - loss: 0.8350 - accuracy: 0.64 - ETA: 0s - loss: 0.8412 - accuracy: 0.63 - ETA: 0s - loss: 0.8441 - accuracy: 0.63 - ETA: 0s - loss: 0.8461 - accuracy: 0.6361\n",
      "Epoch 00809: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00809: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8461 - accuracy: 0.6361 - val_loss: 1.0477 - val_accuracy: 0.4941 - lr: 0.0010\n",
      "Epoch 810/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8844 - accuracy: 0.58 - ETA: 0s - loss: 0.8543 - accuracy: 0.61 - ETA: 0s - loss: 0.8663 - accuracy: 0.60 - ETA: 0s - loss: 0.8411 - accuracy: 0.62 - ETA: 0s - loss: 0.8461 - accuracy: 0.62 - ETA: 0s - loss: 0.8396 - accuracy: 0.63 - ETA: 0s - loss: 0.8354 - accuracy: 0.63 - ETA: 0s - loss: 0.8350 - accuracy: 0.63 - ETA: 0s - loss: 0.8366 - accuracy: 0.63 - ETA: 0s - loss: 0.8432 - accuracy: 0.62 - ETA: 0s - loss: 0.8398 - accuracy: 0.63 - ETA: 0s - loss: 0.8348 - accuracy: 0.64 - ETA: 0s - loss: 0.8162 - accuracy: 0.65 - ETA: 0s - loss: 0.8205 - accuracy: 0.65 - ETA: 0s - loss: 0.8278 - accuracy: 0.64 - ETA: 0s - loss: 0.8316 - accuracy: 0.64 - ETA: 0s - loss: 0.8416 - accuracy: 0.63 - ETA: 0s - loss: 0.8417 - accuracy: 0.6350\n",
      "Epoch 00810: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8417 - accuracy: 0.6350 - val_loss: 1.0468 - val_accuracy: 0.4961 - lr: 0.0010\n",
      "Epoch 811/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8913 - accuracy: 0.58 - ETA: 0s - loss: 0.8608 - accuracy: 0.60 - ETA: 0s - loss: 0.8728 - accuracy: 0.60 - ETA: 0s - loss: 0.8437 - accuracy: 0.62 - ETA: 0s - loss: 0.8467 - accuracy: 0.62 - ETA: 0s - loss: 0.8408 - accuracy: 0.63 - ETA: 0s - loss: 0.8387 - accuracy: 0.63 - ETA: 0s - loss: 0.8376 - accuracy: 0.64 - ETA: 0s - loss: 0.8391 - accuracy: 0.63 - ETA: 0s - loss: 0.8464 - accuracy: 0.63 - ETA: 0s - loss: 0.8422 - accuracy: 0.63 - ETA: 0s - loss: 0.8355 - accuracy: 0.64 - ETA: 0s - loss: 0.8171 - accuracy: 0.65 - ETA: 0s - loss: 0.8219 - accuracy: 0.65 - ETA: 0s - loss: 0.8332 - accuracy: 0.64 - ETA: 0s - loss: 0.8380 - accuracy: 0.63 - ETA: 0s - loss: 0.8445 - accuracy: 0.63 - ETA: 0s - loss: 0.8471 - accuracy: 0.63 - ETA: 0s - loss: 0.8487 - accuracy: 0.6320\n",
      "Epoch 00811: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8487 - accuracy: 0.6320 - val_loss: 1.0534 - val_accuracy: 0.4940 - lr: 0.0010\n",
      "Epoch 812/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8985 - accuracy: 0.55 - ETA: 0s - loss: 0.8610 - accuracy: 0.60 - ETA: 0s - loss: 0.8770 - accuracy: 0.59 - ETA: 0s - loss: 0.8490 - accuracy: 0.61 - ETA: 0s - loss: 0.8484 - accuracy: 0.62 - ETA: 0s - loss: 0.8428 - accuracy: 0.63 - ETA: 0s - loss: 0.8407 - accuracy: 0.63 - ETA: 0s - loss: 0.8411 - accuracy: 0.63 - ETA: 0s - loss: 0.8424 - accuracy: 0.63 - ETA: 0s - loss: 0.8491 - accuracy: 0.62 - ETA: 0s - loss: 0.8440 - accuracy: 0.63 - ETA: 0s - loss: 0.8370 - accuracy: 0.64 - ETA: 0s - loss: 0.8189 - accuracy: 0.65 - ETA: 0s - loss: 0.8241 - accuracy: 0.65 - ETA: 0s - loss: 0.8349 - accuracy: 0.64 - ETA: 0s - loss: 0.8385 - accuracy: 0.63 - ETA: 0s - loss: 0.8483 - accuracy: 0.63 - ETA: 0s - loss: 0.8493 - accuracy: 0.6330\n",
      "Epoch 00812: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8493 - accuracy: 0.6330 - val_loss: 1.0510 - val_accuracy: 0.4992 - lr: 0.0010\n",
      "Epoch 813/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9011 - accuracy: 0.57 - ETA: 0s - loss: 0.8635 - accuracy: 0.60 - ETA: 0s - loss: 0.8806 - accuracy: 0.60 - ETA: 0s - loss: 0.8496 - accuracy: 0.62 - ETA: 0s - loss: 0.8472 - accuracy: 0.62 - ETA: 0s - loss: 0.8409 - accuracy: 0.63 - ETA: 0s - loss: 0.8352 - accuracy: 0.63 - ETA: 0s - loss: 0.8362 - accuracy: 0.63 - ETA: 0s - loss: 0.8392 - accuracy: 0.63 - ETA: 0s - loss: 0.8441 - accuracy: 0.63 - ETA: 0s - loss: 0.8390 - accuracy: 0.63 - ETA: 0s - loss: 0.8324 - accuracy: 0.64 - ETA: 0s - loss: 0.8140 - accuracy: 0.65 - ETA: 0s - loss: 0.8189 - accuracy: 0.65 - ETA: 0s - loss: 0.8309 - accuracy: 0.64 - ETA: 0s - loss: 0.8347 - accuracy: 0.64 - ETA: 0s - loss: 0.8406 - accuracy: 0.63 - ETA: 0s - loss: 0.8431 - accuracy: 0.63 - ETA: 0s - loss: 0.8444 - accuracy: 0.6351\n",
      "Epoch 00813: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8444 - accuracy: 0.6351 - val_loss: 1.0503 - val_accuracy: 0.4979 - lr: 0.0010\n",
      "Epoch 814/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8919 - accuracy: 0.55 - ETA: 0s - loss: 0.8537 - accuracy: 0.60 - ETA: 0s - loss: 0.8628 - accuracy: 0.60 - ETA: 0s - loss: 0.8374 - accuracy: 0.62 - ETA: 0s - loss: 0.8406 - accuracy: 0.62 - ETA: 0s - loss: 0.8340 - accuracy: 0.63 - ETA: 0s - loss: 0.8327 - accuracy: 0.63 - ETA: 0s - loss: 0.8334 - accuracy: 0.63 - ETA: 0s - loss: 0.8377 - accuracy: 0.63 - ETA: 0s - loss: 0.8399 - accuracy: 0.63 - ETA: 0s - loss: 0.8328 - accuracy: 0.63 - ETA: 0s - loss: 0.8143 - accuracy: 0.65 - ETA: 0s - loss: 0.8185 - accuracy: 0.64 - ETA: 0s - loss: 0.8291 - accuracy: 0.63 - ETA: 0s - loss: 0.8327 - accuracy: 0.63 - ETA: 0s - loss: 0.8395 - accuracy: 0.63 - ETA: 0s - loss: 0.8423 - accuracy: 0.63 - ETA: 0s - loss: 0.8437 - accuracy: 0.6322\n",
      "Epoch 00814: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8437 - accuracy: 0.6322 - val_loss: 1.0573 - val_accuracy: 0.4906 - lr: 0.0010\n",
      "Epoch 815/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9211 - accuracy: 0.56 - ETA: 0s - loss: 0.8774 - accuracy: 0.59 - ETA: 0s - loss: 0.8870 - accuracy: 0.59 - ETA: 0s - loss: 0.8573 - accuracy: 0.61 - ETA: 0s - loss: 0.8546 - accuracy: 0.62 - ETA: 0s - loss: 0.8490 - accuracy: 0.63 - ETA: 0s - loss: 0.8446 - accuracy: 0.63 - ETA: 0s - loss: 0.8443 - accuracy: 0.63 - ETA: 0s - loss: 0.8461 - accuracy: 0.63 - ETA: 0s - loss: 0.8510 - accuracy: 0.62 - ETA: 0s - loss: 0.8459 - accuracy: 0.63 - ETA: 0s - loss: 0.8375 - accuracy: 0.64 - ETA: 0s - loss: 0.8192 - accuracy: 0.65 - ETA: 0s - loss: 0.8259 - accuracy: 0.65 - ETA: 0s - loss: 0.8351 - accuracy: 0.64 - ETA: 0s - loss: 0.8384 - accuracy: 0.63 - ETA: 0s - loss: 0.8450 - accuracy: 0.63 - ETA: 0s - loss: 0.8465 - accuracy: 0.63 - ETA: 0s - loss: 0.8482 - accuracy: 0.6327\n",
      "Epoch 00815: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8482 - accuracy: 0.6327 - val_loss: 1.0614 - val_accuracy: 0.4951 - lr: 0.0010\n",
      "Epoch 816/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.8857 - accuracy: 0.58 - ETA: 0s - loss: 0.8565 - accuracy: 0.61 - ETA: 0s - loss: 0.8681 - accuracy: 0.61 - ETA: 0s - loss: 0.8438 - accuracy: 0.63 - ETA: 0s - loss: 0.8451 - accuracy: 0.63 - ETA: 0s - loss: 0.8409 - accuracy: 0.64 - ETA: 0s - loss: 0.8388 - accuracy: 0.64 - ETA: 0s - loss: 0.8378 - accuracy: 0.64 - ETA: 0s - loss: 0.8409 - accuracy: 0.64 - ETA: 0s - loss: 0.8453 - accuracy: 0.63 - ETA: 0s - loss: 0.8400 - accuracy: 0.64 - ETA: 0s - loss: 0.8352 - accuracy: 0.64 - ETA: 0s - loss: 0.8165 - accuracy: 0.66 - ETA: 0s - loss: 0.8208 - accuracy: 0.65 - ETA: 0s - loss: 0.8297 - accuracy: 0.64 - ETA: 0s - loss: 0.8336 - accuracy: 0.64 - ETA: 0s - loss: 0.8403 - accuracy: 0.63 - ETA: 0s - loss: 0.8427 - accuracy: 0.63 - ETA: 0s - loss: 0.8443 - accuracy: 0.6373\n",
      "Epoch 00816: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8443 - accuracy: 0.6373 - val_loss: 1.0581 - val_accuracy: 0.4906 - lr: 0.0010\n",
      "Epoch 817/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9206 - accuracy: 0.54 - ETA: 0s - loss: 0.8623 - accuracy: 0.60 - ETA: 0s - loss: 0.8667 - accuracy: 0.59 - ETA: 0s - loss: 0.8408 - accuracy: 0.61 - ETA: 0s - loss: 0.8446 - accuracy: 0.61 - ETA: 0s - loss: 0.8379 - accuracy: 0.63 - ETA: 0s - loss: 0.8345 - accuracy: 0.63 - ETA: 0s - loss: 0.8347 - accuracy: 0.63 - ETA: 0s - loss: 0.8374 - accuracy: 0.63 - ETA: 0s - loss: 0.8432 - accuracy: 0.62 - ETA: 0s - loss: 0.8389 - accuracy: 0.63 - ETA: 0s - loss: 0.8316 - accuracy: 0.64 - ETA: 0s - loss: 0.8135 - accuracy: 0.65 - ETA: 0s - loss: 0.8184 - accuracy: 0.65 - ETA: 0s - loss: 0.8291 - accuracy: 0.64 - ETA: 0s - loss: 0.8330 - accuracy: 0.63 - ETA: 0s - loss: 0.8398 - accuracy: 0.63 - ETA: 0s - loss: 0.8431 - accuracy: 0.63 - ETA: 0s - loss: 0.8455 - accuracy: 0.6321\n",
      "Epoch 00817: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8455 - accuracy: 0.6321 - val_loss: 1.0569 - val_accuracy: 0.4946 - lr: 0.0010\n",
      "Epoch 818/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8846 - accuracy: 0.56 - ETA: 0s - loss: 0.8533 - accuracy: 0.61 - ETA: 0s - loss: 0.8653 - accuracy: 0.61 - ETA: 0s - loss: 0.8404 - accuracy: 0.63 - ETA: 0s - loss: 0.8444 - accuracy: 0.63 - ETA: 0s - loss: 0.8381 - accuracy: 0.64 - ETA: 0s - loss: 0.8341 - accuracy: 0.64 - ETA: 0s - loss: 0.8325 - accuracy: 0.64 - ETA: 0s - loss: 0.8351 - accuracy: 0.64 - ETA: 0s - loss: 0.8414 - accuracy: 0.63 - ETA: 0s - loss: 0.8376 - accuracy: 0.64 - ETA: 0s - loss: 0.8312 - accuracy: 0.64 - ETA: 0s - loss: 0.8135 - accuracy: 0.66 - ETA: 0s - loss: 0.8188 - accuracy: 0.65 - ETA: 0s - loss: 0.8285 - accuracy: 0.64 - ETA: 0s - loss: 0.8319 - accuracy: 0.64 - ETA: 0s - loss: 0.8386 - accuracy: 0.63 - ETA: 0s - loss: 0.8404 - accuracy: 0.63 - ETA: 0s - loss: 0.8422 - accuracy: 0.6375\n",
      "Epoch 00818: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8422 - accuracy: 0.6375 - val_loss: 1.0670 - val_accuracy: 0.4932 - lr: 0.0010\n",
      "Epoch 819/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9022 - accuracy: 0.57 - ETA: 0s - loss: 0.8522 - accuracy: 0.61 - ETA: 0s - loss: 0.8594 - accuracy: 0.61 - ETA: 0s - loss: 0.8381 - accuracy: 0.62 - ETA: 0s - loss: 0.8411 - accuracy: 0.62 - ETA: 0s - loss: 0.8362 - accuracy: 0.63 - ETA: 0s - loss: 0.8329 - accuracy: 0.64 - ETA: 0s - loss: 0.8328 - accuracy: 0.64 - ETA: 0s - loss: 0.8365 - accuracy: 0.63 - ETA: 0s - loss: 0.8410 - accuracy: 0.63 - ETA: 0s - loss: 0.8371 - accuracy: 0.64 - ETA: 0s - loss: 0.8306 - accuracy: 0.64 - ETA: 0s - loss: 0.8120 - accuracy: 0.65 - ETA: 0s - loss: 0.8173 - accuracy: 0.65 - ETA: 0s - loss: 0.8274 - accuracy: 0.64 - ETA: 0s - loss: 0.8308 - accuracy: 0.64 - ETA: 0s - loss: 0.8372 - accuracy: 0.63 - ETA: 0s - loss: 0.8395 - accuracy: 0.63 - ETA: 0s - loss: 0.8414 - accuracy: 0.6330\n",
      "Epoch 00819: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8414 - accuracy: 0.6330 - val_loss: 1.0606 - val_accuracy: 0.4945 - lr: 0.0010\n",
      "Epoch 820/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8898 - accuracy: 0.58 - ETA: 0s - loss: 0.8563 - accuracy: 0.61 - ETA: 0s - loss: 0.8706 - accuracy: 0.61 - ETA: 0s - loss: 0.8431 - accuracy: 0.62 - ETA: 0s - loss: 0.8438 - accuracy: 0.63 - ETA: 0s - loss: 0.8354 - accuracy: 0.64 - ETA: 0s - loss: 0.8325 - accuracy: 0.64 - ETA: 0s - loss: 0.8309 - accuracy: 0.64 - ETA: 0s - loss: 0.8330 - accuracy: 0.64 - ETA: 0s - loss: 0.8416 - accuracy: 0.63 - ETA: 0s - loss: 0.8369 - accuracy: 0.63 - ETA: 0s - loss: 0.8303 - accuracy: 0.64 - ETA: 0s - loss: 0.8117 - accuracy: 0.65 - ETA: 0s - loss: 0.8162 - accuracy: 0.65 - ETA: 0s - loss: 0.8269 - accuracy: 0.64 - ETA: 0s - loss: 0.8309 - accuracy: 0.64 - ETA: 0s - loss: 0.8372 - accuracy: 0.63 - ETA: 0s - loss: 0.8407 - accuracy: 0.63 - ETA: 0s - loss: 0.8424 - accuracy: 0.6347\n",
      "Epoch 00820: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8424 - accuracy: 0.6347 - val_loss: 1.0535 - val_accuracy: 0.4956 - lr: 0.0010\n",
      "Epoch 821/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8964 - accuracy: 0.57 - ETA: 0s - loss: 0.8651 - accuracy: 0.61 - ETA: 0s - loss: 0.8667 - accuracy: 0.61 - ETA: 0s - loss: 0.8403 - accuracy: 0.63 - ETA: 0s - loss: 0.8420 - accuracy: 0.63 - ETA: 0s - loss: 0.8381 - accuracy: 0.64 - ETA: 0s - loss: 0.8344 - accuracy: 0.64 - ETA: 0s - loss: 0.8346 - accuracy: 0.64 - ETA: 0s - loss: 0.8382 - accuracy: 0.64 - ETA: 0s - loss: 0.8450 - accuracy: 0.63 - ETA: 0s - loss: 0.8402 - accuracy: 0.64 - ETA: 0s - loss: 0.8322 - accuracy: 0.64 - ETA: 0s - loss: 0.8146 - accuracy: 0.66 - ETA: 0s - loss: 0.8209 - accuracy: 0.65 - ETA: 0s - loss: 0.8296 - accuracy: 0.64 - ETA: 0s - loss: 0.8329 - accuracy: 0.64 - ETA: 0s - loss: 0.8390 - accuracy: 0.63 - ETA: 0s - loss: 0.8408 - accuracy: 0.63 - ETA: 0s - loss: 0.8428 - accuracy: 0.6374\n",
      "Epoch 00821: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8428 - accuracy: 0.6374 - val_loss: 1.0529 - val_accuracy: 0.4961 - lr: 0.0010\n",
      "Epoch 822/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8736 - accuracy: 0.56 - ETA: 0s - loss: 0.8493 - accuracy: 0.60 - ETA: 0s - loss: 0.8579 - accuracy: 0.60 - ETA: 0s - loss: 0.8323 - accuracy: 0.62 - ETA: 0s - loss: 0.8393 - accuracy: 0.62 - ETA: 0s - loss: 0.8339 - accuracy: 0.63 - ETA: 0s - loss: 0.8322 - accuracy: 0.63 - ETA: 0s - loss: 0.8321 - accuracy: 0.63 - ETA: 0s - loss: 0.8355 - accuracy: 0.63 - ETA: 0s - loss: 0.8398 - accuracy: 0.63 - ETA: 0s - loss: 0.8370 - accuracy: 0.63 - ETA: 0s - loss: 0.8307 - accuracy: 0.64 - ETA: 0s - loss: 0.8127 - accuracy: 0.65 - ETA: 0s - loss: 0.8175 - accuracy: 0.65 - ETA: 0s - loss: 0.8280 - accuracy: 0.64 - ETA: 0s - loss: 0.8308 - accuracy: 0.64 - ETA: 0s - loss: 0.8379 - accuracy: 0.63 - ETA: 0s - loss: 0.8406 - accuracy: 0.63 - ETA: 0s - loss: 0.8434 - accuracy: 0.6325\n",
      "Epoch 00822: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8434 - accuracy: 0.6325 - val_loss: 1.0530 - val_accuracy: 0.4954 - lr: 0.0010\n",
      "Epoch 823/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8876 - accuracy: 0.56 - ETA: 0s - loss: 0.8587 - accuracy: 0.60 - ETA: 0s - loss: 0.8686 - accuracy: 0.60 - ETA: 0s - loss: 0.8416 - accuracy: 0.62 - ETA: 0s - loss: 0.8431 - accuracy: 0.62 - ETA: 0s - loss: 0.8377 - accuracy: 0.63 - ETA: 0s - loss: 0.8357 - accuracy: 0.63 - ETA: 0s - loss: 0.8350 - accuracy: 0.63 - ETA: 0s - loss: 0.8366 - accuracy: 0.63 - ETA: 0s - loss: 0.8433 - accuracy: 0.63 - ETA: 0s - loss: 0.8389 - accuracy: 0.63 - ETA: 0s - loss: 0.8326 - accuracy: 0.64 - ETA: 0s - loss: 0.8140 - accuracy: 0.65 - ETA: 0s - loss: 0.8196 - accuracy: 0.65 - ETA: 0s - loss: 0.8310 - accuracy: 0.64 - ETA: 0s - loss: 0.8345 - accuracy: 0.63 - ETA: 0s - loss: 0.8404 - accuracy: 0.63 - ETA: 0s - loss: 0.8430 - accuracy: 0.63 - ETA: 0s - loss: 0.8445 - accuracy: 0.6319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00823: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00823: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8445 - accuracy: 0.6319 - val_loss: 1.0547 - val_accuracy: 0.4993 - lr: 0.0010\n",
      "Epoch 824/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8996 - accuracy: 0.56 - ETA: 0s - loss: 0.8623 - accuracy: 0.60 - ETA: 0s - loss: 0.8683 - accuracy: 0.60 - ETA: 0s - loss: 0.8430 - accuracy: 0.62 - ETA: 0s - loss: 0.8449 - accuracy: 0.62 - ETA: 0s - loss: 0.8391 - accuracy: 0.63 - ETA: 0s - loss: 0.8366 - accuracy: 0.63 - ETA: 0s - loss: 0.8342 - accuracy: 0.64 - ETA: 0s - loss: 0.8381 - accuracy: 0.63 - ETA: 0s - loss: 0.8421 - accuracy: 0.63 - ETA: 0s - loss: 0.8370 - accuracy: 0.63 - ETA: 0s - loss: 0.8309 - accuracy: 0.64 - ETA: 0s - loss: 0.8133 - accuracy: 0.65 - ETA: 0s - loss: 0.8200 - accuracy: 0.65 - ETA: 0s - loss: 0.8293 - accuracy: 0.64 - ETA: 0s - loss: 0.8336 - accuracy: 0.64 - ETA: 0s - loss: 0.8409 - accuracy: 0.63 - ETA: 0s - loss: 0.8432 - accuracy: 0.63 - ETA: 0s - loss: 0.8438 - accuracy: 0.6348\n",
      "Epoch 00824: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8438 - accuracy: 0.6348 - val_loss: 1.0462 - val_accuracy: 0.5031 - lr: 0.0010\n",
      "Epoch 825/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8737 - accuracy: 0.58 - ETA: 0s - loss: 0.8422 - accuracy: 0.61 - ETA: 0s - loss: 0.8539 - accuracy: 0.61 - ETA: 0s - loss: 0.8323 - accuracy: 0.62 - ETA: 0s - loss: 0.8340 - accuracy: 0.62 - ETA: 0s - loss: 0.8304 - accuracy: 0.63 - ETA: 0s - loss: 0.8278 - accuracy: 0.64 - ETA: 0s - loss: 0.8300 - accuracy: 0.63 - ETA: 0s - loss: 0.8322 - accuracy: 0.63 - ETA: 0s - loss: 0.8398 - accuracy: 0.63 - ETA: 0s - loss: 0.8351 - accuracy: 0.63 - ETA: 0s - loss: 0.8295 - accuracy: 0.64 - ETA: 0s - loss: 0.8113 - accuracy: 0.65 - ETA: 0s - loss: 0.8178 - accuracy: 0.65 - ETA: 0s - loss: 0.8268 - accuracy: 0.64 - ETA: 0s - loss: 0.8310 - accuracy: 0.63 - ETA: 0s - loss: 0.8378 - accuracy: 0.63 - ETA: 0s - loss: 0.8406 - accuracy: 0.63 - ETA: 0s - loss: 0.8416 - accuracy: 0.6327\n",
      "Epoch 00825: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8416 - accuracy: 0.6327 - val_loss: 1.0459 - val_accuracy: 0.5031 - lr: 0.0010\n",
      "Epoch 826/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8838 - accuracy: 0.57 - ETA: 0s - loss: 0.8599 - accuracy: 0.60 - ETA: 0s - loss: 0.8743 - accuracy: 0.60 - ETA: 0s - loss: 0.8467 - accuracy: 0.62 - ETA: 0s - loss: 0.8477 - accuracy: 0.62 - ETA: 0s - loss: 0.8397 - accuracy: 0.63 - ETA: 0s - loss: 0.8361 - accuracy: 0.63 - ETA: 0s - loss: 0.8358 - accuracy: 0.64 - ETA: 0s - loss: 0.8388 - accuracy: 0.63 - ETA: 0s - loss: 0.8438 - accuracy: 0.63 - ETA: 0s - loss: 0.8381 - accuracy: 0.64 - ETA: 0s - loss: 0.8310 - accuracy: 0.64 - ETA: 0s - loss: 0.8126 - accuracy: 0.65 - ETA: 0s - loss: 0.8164 - accuracy: 0.65 - ETA: 0s - loss: 0.8271 - accuracy: 0.64 - ETA: 0s - loss: 0.8314 - accuracy: 0.64 - ETA: 0s - loss: 0.8372 - accuracy: 0.63 - ETA: 0s - loss: 0.8392 - accuracy: 0.63 - ETA: 0s - loss: 0.8411 - accuracy: 0.6342\n",
      "Epoch 00826: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8411 - accuracy: 0.6342 - val_loss: 1.0490 - val_accuracy: 0.5037 - lr: 0.0010\n",
      "Epoch 827/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8732 - accuracy: 0.59 - ETA: 0s - loss: 0.8465 - accuracy: 0.62 - ETA: 0s - loss: 0.8615 - accuracy: 0.61 - ETA: 0s - loss: 0.8350 - accuracy: 0.63 - ETA: 0s - loss: 0.8387 - accuracy: 0.63 - ETA: 0s - loss: 0.8318 - accuracy: 0.64 - ETA: 0s - loss: 0.8309 - accuracy: 0.64 - ETA: 0s - loss: 0.8308 - accuracy: 0.64 - ETA: 0s - loss: 0.8342 - accuracy: 0.63 - ETA: 0s - loss: 0.8398 - accuracy: 0.63 - ETA: 0s - loss: 0.8354 - accuracy: 0.64 - ETA: 0s - loss: 0.8289 - accuracy: 0.64 - ETA: 0s - loss: 0.8109 - accuracy: 0.65 - ETA: 0s - loss: 0.8155 - accuracy: 0.65 - ETA: 0s - loss: 0.8254 - accuracy: 0.64 - ETA: 0s - loss: 0.8296 - accuracy: 0.64 - ETA: 0s - loss: 0.8366 - accuracy: 0.63 - ETA: 0s - loss: 0.8388 - accuracy: 0.63 - ETA: 0s - loss: 0.8404 - accuracy: 0.6347\n",
      "Epoch 00827: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8404 - accuracy: 0.6347 - val_loss: 1.0512 - val_accuracy: 0.4990 - lr: 0.0010\n",
      "Epoch 828/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8962 - accuracy: 0.58 - ETA: 0s - loss: 0.8540 - accuracy: 0.61 - ETA: 0s - loss: 0.8699 - accuracy: 0.61 - ETA: 0s - loss: 0.8411 - accuracy: 0.63 - ETA: 0s - loss: 0.8446 - accuracy: 0.63 - ETA: 0s - loss: 0.8383 - accuracy: 0.64 - ETA: 0s - loss: 0.8334 - accuracy: 0.64 - ETA: 0s - loss: 0.8341 - accuracy: 0.64 - ETA: 0s - loss: 0.8367 - accuracy: 0.64 - ETA: 0s - loss: 0.8433 - accuracy: 0.63 - ETA: 0s - loss: 0.8384 - accuracy: 0.64 - ETA: 0s - loss: 0.8307 - accuracy: 0.64 - ETA: 0s - loss: 0.8124 - accuracy: 0.66 - ETA: 0s - loss: 0.8163 - accuracy: 0.65 - ETA: 0s - loss: 0.8268 - accuracy: 0.64 - ETA: 0s - loss: 0.8318 - accuracy: 0.64 - ETA: 0s - loss: 0.8368 - accuracy: 0.64 - ETA: 0s - loss: 0.8399 - accuracy: 0.63 - ETA: 0s - loss: 0.8423 - accuracy: 0.6375\n",
      "Epoch 00828: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8423 - accuracy: 0.6375 - val_loss: 1.0463 - val_accuracy: 0.4985 - lr: 0.0010\n",
      "Epoch 829/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8976 - accuracy: 0.57 - ETA: 0s - loss: 0.8622 - accuracy: 0.61 - ETA: 0s - loss: 0.8691 - accuracy: 0.61 - ETA: 0s - loss: 0.8403 - accuracy: 0.63 - ETA: 0s - loss: 0.8455 - accuracy: 0.62 - ETA: 0s - loss: 0.8399 - accuracy: 0.63 - ETA: 0s - loss: 0.8402 - accuracy: 0.63 - ETA: 0s - loss: 0.8388 - accuracy: 0.64 - ETA: 0s - loss: 0.8415 - accuracy: 0.63 - ETA: 0s - loss: 0.8461 - accuracy: 0.62 - ETA: 0s - loss: 0.8408 - accuracy: 0.63 - ETA: 0s - loss: 0.8348 - accuracy: 0.64 - ETA: 0s - loss: 0.8163 - accuracy: 0.65 - ETA: 0s - loss: 0.8217 - accuracy: 0.65 - ETA: 0s - loss: 0.8299 - accuracy: 0.64 - ETA: 0s - loss: 0.8346 - accuracy: 0.64 - ETA: 0s - loss: 0.8405 - accuracy: 0.63 - ETA: 0s - loss: 0.8433 - accuracy: 0.63 - ETA: 0s - loss: 0.8448 - accuracy: 0.6340\n",
      "Epoch 00829: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8448 - accuracy: 0.6340 - val_loss: 1.0499 - val_accuracy: 0.4993 - lr: 0.0010\n",
      "Epoch 830/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9067 - accuracy: 0.56 - ETA: 0s - loss: 0.8641 - accuracy: 0.59 - ETA: 0s - loss: 0.8753 - accuracy: 0.60 - ETA: 0s - loss: 0.8447 - accuracy: 0.62 - ETA: 0s - loss: 0.8462 - accuracy: 0.62 - ETA: 0s - loss: 0.8397 - accuracy: 0.63 - ETA: 0s - loss: 0.8348 - accuracy: 0.63 - ETA: 0s - loss: 0.8324 - accuracy: 0.63 - ETA: 0s - loss: 0.8349 - accuracy: 0.63 - ETA: 0s - loss: 0.8409 - accuracy: 0.63 - ETA: 0s - loss: 0.8361 - accuracy: 0.63 - ETA: 0s - loss: 0.8295 - accuracy: 0.64 - ETA: 0s - loss: 0.8108 - accuracy: 0.65 - ETA: 0s - loss: 0.8157 - accuracy: 0.65 - ETA: 0s - loss: 0.8259 - accuracy: 0.64 - ETA: 0s - loss: 0.8288 - accuracy: 0.64 - ETA: 0s - loss: 0.8360 - accuracy: 0.63 - ETA: 0s - loss: 0.8384 - accuracy: 0.63 - ETA: 0s - loss: 0.8402 - accuracy: 0.6340\n",
      "Epoch 00830: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8402 - accuracy: 0.6340 - val_loss: 1.0463 - val_accuracy: 0.5036 - lr: 0.0010\n",
      "Epoch 831/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9155 - accuracy: 0.53 - ETA: 0s - loss: 0.8792 - accuracy: 0.58 - ETA: 0s - loss: 0.8794 - accuracy: 0.59 - ETA: 0s - loss: 0.8495 - accuracy: 0.61 - ETA: 0s - loss: 0.8465 - accuracy: 0.61 - ETA: 0s - loss: 0.8401 - accuracy: 0.63 - ETA: 0s - loss: 0.8368 - accuracy: 0.63 - ETA: 0s - loss: 0.8366 - accuracy: 0.63 - ETA: 0s - loss: 0.8404 - accuracy: 0.63 - ETA: 0s - loss: 0.8464 - accuracy: 0.62 - ETA: 0s - loss: 0.8420 - accuracy: 0.63 - ETA: 0s - loss: 0.8356 - accuracy: 0.64 - ETA: 0s - loss: 0.8173 - accuracy: 0.65 - ETA: 0s - loss: 0.8223 - accuracy: 0.65 - ETA: 0s - loss: 0.8310 - accuracy: 0.64 - ETA: 0s - loss: 0.8337 - accuracy: 0.63 - ETA: 0s - loss: 0.8404 - accuracy: 0.63 - ETA: 0s - loss: 0.8425 - accuracy: 0.63 - ETA: 0s - loss: 0.8437 - accuracy: 0.6323\n",
      "Epoch 00831: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8437 - accuracy: 0.6323 - val_loss: 1.0441 - val_accuracy: 0.4967 - lr: 0.0010\n",
      "Epoch 832/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8826 - accuracy: 0.58 - ETA: 0s - loss: 0.8548 - accuracy: 0.61 - ETA: 0s - loss: 0.8728 - accuracy: 0.60 - ETA: 0s - loss: 0.8430 - accuracy: 0.62 - ETA: 0s - loss: 0.8469 - accuracy: 0.62 - ETA: 0s - loss: 0.8413 - accuracy: 0.63 - ETA: 0s - loss: 0.8373 - accuracy: 0.63 - ETA: 0s - loss: 0.8357 - accuracy: 0.63 - ETA: 0s - loss: 0.8388 - accuracy: 0.63 - ETA: 0s - loss: 0.8441 - accuracy: 0.62 - ETA: 0s - loss: 0.8389 - accuracy: 0.63 - ETA: 0s - loss: 0.8318 - accuracy: 0.64 - ETA: 0s - loss: 0.8134 - accuracy: 0.65 - ETA: 0s - loss: 0.8199 - accuracy: 0.65 - ETA: 0s - loss: 0.8310 - accuracy: 0.64 - ETA: 0s - loss: 0.8341 - accuracy: 0.63 - ETA: 0s - loss: 0.8406 - accuracy: 0.63 - ETA: 0s - loss: 0.8435 - accuracy: 0.63 - ETA: 0s - loss: 0.8450 - accuracy: 0.6336\n",
      "Epoch 00832: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8450 - accuracy: 0.6336 - val_loss: 1.0462 - val_accuracy: 0.4995 - lr: 0.0010\n",
      "Epoch 833/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8775 - accuracy: 0.57 - ETA: 0s - loss: 0.8555 - accuracy: 0.61 - ETA: 0s - loss: 0.8755 - accuracy: 0.60 - ETA: 0s - loss: 0.8447 - accuracy: 0.62 - ETA: 0s - loss: 0.8473 - accuracy: 0.62 - ETA: 0s - loss: 0.8415 - accuracy: 0.63 - ETA: 0s - loss: 0.8387 - accuracy: 0.63 - ETA: 0s - loss: 0.8384 - accuracy: 0.63 - ETA: 0s - loss: 0.8411 - accuracy: 0.63 - ETA: 0s - loss: 0.8468 - accuracy: 0.62 - ETA: 0s - loss: 0.8406 - accuracy: 0.63 - ETA: 0s - loss: 0.8339 - accuracy: 0.64 - ETA: 0s - loss: 0.8153 - accuracy: 0.65 - ETA: 0s - loss: 0.8206 - accuracy: 0.65 - ETA: 0s - loss: 0.8286 - accuracy: 0.64 - ETA: 0s - loss: 0.8319 - accuracy: 0.63 - ETA: 0s - loss: 0.8386 - accuracy: 0.63 - ETA: 0s - loss: 0.8410 - accuracy: 0.63 - ETA: 0s - loss: 0.8430 - accuracy: 0.6327\n",
      "Epoch 00833: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8430 - accuracy: 0.6327 - val_loss: 1.0464 - val_accuracy: 0.4997 - lr: 0.0010\n",
      "Epoch 834/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8983 - accuracy: 0.57 - ETA: 0s - loss: 0.8526 - accuracy: 0.61 - ETA: 0s - loss: 0.8623 - accuracy: 0.62 - ETA: 0s - loss: 0.8356 - accuracy: 0.63 - ETA: 0s - loss: 0.8409 - accuracy: 0.63 - ETA: 0s - loss: 0.8357 - accuracy: 0.64 - ETA: 0s - loss: 0.8336 - accuracy: 0.64 - ETA: 0s - loss: 0.8343 - accuracy: 0.64 - ETA: 0s - loss: 0.8375 - accuracy: 0.64 - ETA: 0s - loss: 0.8428 - accuracy: 0.63 - ETA: 0s - loss: 0.8381 - accuracy: 0.63 - ETA: 0s - loss: 0.8313 - accuracy: 0.64 - ETA: 0s - loss: 0.8123 - accuracy: 0.65 - ETA: 0s - loss: 0.8165 - accuracy: 0.65 - ETA: 0s - loss: 0.8265 - accuracy: 0.64 - ETA: 0s - loss: 0.8302 - accuracy: 0.64 - ETA: 0s - loss: 0.8365 - accuracy: 0.63 - ETA: 0s - loss: 0.8393 - accuracy: 0.63 - ETA: 0s - loss: 0.8408 - accuracy: 0.6354\n",
      "Epoch 00834: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8408 - accuracy: 0.6354 - val_loss: 1.0510 - val_accuracy: 0.4951 - lr: 0.0010\n",
      "Epoch 835/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8942 - accuracy: 0.57 - ETA: 0s - loss: 0.8567 - accuracy: 0.61 - ETA: 0s - loss: 0.8669 - accuracy: 0.61 - ETA: 0s - loss: 0.8411 - accuracy: 0.62 - ETA: 0s - loss: 0.8456 - accuracy: 0.62 - ETA: 0s - loss: 0.8404 - accuracy: 0.63 - ETA: 0s - loss: 0.8358 - accuracy: 0.63 - ETA: 0s - loss: 0.8319 - accuracy: 0.64 - ETA: 0s - loss: 0.8345 - accuracy: 0.64 - ETA: 0s - loss: 0.8407 - accuracy: 0.63 - ETA: 0s - loss: 0.8370 - accuracy: 0.63 - ETA: 0s - loss: 0.8293 - accuracy: 0.64 - ETA: 0s - loss: 0.8112 - accuracy: 0.65 - ETA: 0s - loss: 0.8175 - accuracy: 0.65 - ETA: 0s - loss: 0.8246 - accuracy: 0.64 - ETA: 0s - loss: 0.8281 - accuracy: 0.64 - ETA: 0s - loss: 0.8355 - accuracy: 0.63 - ETA: 0s - loss: 0.8373 - accuracy: 0.63 - ETA: 0s - loss: 0.8399 - accuracy: 0.6348\n",
      "Epoch 00835: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8399 - accuracy: 0.6348 - val_loss: 1.0603 - val_accuracy: 0.4949 - lr: 0.0010\n",
      "Epoch 836/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8866 - accuracy: 0.57 - ETA: 0s - loss: 0.8497 - accuracy: 0.61 - ETA: 0s - loss: 0.8606 - accuracy: 0.61 - ETA: 0s - loss: 0.8345 - accuracy: 0.63 - ETA: 0s - loss: 0.8381 - accuracy: 0.63 - ETA: 0s - loss: 0.8324 - accuracy: 0.64 - ETA: 0s - loss: 0.8280 - accuracy: 0.64 - ETA: 0s - loss: 0.8260 - accuracy: 0.64 - ETA: 0s - loss: 0.8293 - accuracy: 0.64 - ETA: 0s - loss: 0.8346 - accuracy: 0.63 - ETA: 0s - loss: 0.8300 - accuracy: 0.64 - ETA: 0s - loss: 0.8236 - accuracy: 0.65 - ETA: 0s - loss: 0.8052 - accuracy: 0.66 - ETA: 0s - loss: 0.8102 - accuracy: 0.66 - ETA: 0s - loss: 0.8184 - accuracy: 0.65 - ETA: 0s - loss: 0.8235 - accuracy: 0.64 - ETA: 0s - loss: 0.8306 - accuracy: 0.64 - ETA: 0s - loss: 0.8335 - accuracy: 0.64 - ETA: 0s - loss: 0.8359 - accuracy: 0.6405\n",
      "Epoch 00836: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8359 - accuracy: 0.6405 - val_loss: 1.0685 - val_accuracy: 0.4914 - lr: 0.0010\n",
      "Epoch 837/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8789 - accuracy: 0.60 - ETA: 0s - loss: 0.8499 - accuracy: 0.63 - ETA: 0s - loss: 0.8588 - accuracy: 0.62 - ETA: 0s - loss: 0.8343 - accuracy: 0.63 - ETA: 0s - loss: 0.8377 - accuracy: 0.63 - ETA: 0s - loss: 0.8352 - accuracy: 0.64 - ETA: 0s - loss: 0.8315 - accuracy: 0.64 - ETA: 0s - loss: 0.8306 - accuracy: 0.64 - ETA: 0s - loss: 0.8341 - accuracy: 0.64 - ETA: 0s - loss: 0.8419 - accuracy: 0.63 - ETA: 0s - loss: 0.8383 - accuracy: 0.64 - ETA: 0s - loss: 0.8309 - accuracy: 0.64 - ETA: 0s - loss: 0.8128 - accuracy: 0.66 - ETA: 0s - loss: 0.8170 - accuracy: 0.65 - ETA: 0s - loss: 0.8259 - accuracy: 0.64 - ETA: 0s - loss: 0.8296 - accuracy: 0.64 - ETA: 0s - loss: 0.8357 - accuracy: 0.64 - ETA: 0s - loss: 0.8384 - accuracy: 0.64 - ETA: 0s - loss: 0.8403 - accuracy: 0.6391\n",
      "Epoch 00837: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00837: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8403 - accuracy: 0.6391 - val_loss: 1.0540 - val_accuracy: 0.4920 - lr: 0.0010\n",
      "Epoch 838/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.8844 - accuracy: 0.57 - ETA: 0s - loss: 0.8594 - accuracy: 0.61 - ETA: 0s - loss: 0.8714 - accuracy: 0.61 - ETA: 0s - loss: 0.8415 - accuracy: 0.62 - ETA: 0s - loss: 0.8459 - accuracy: 0.62 - ETA: 0s - loss: 0.8386 - accuracy: 0.63 - ETA: 0s - loss: 0.8341 - accuracy: 0.63 - ETA: 0s - loss: 0.8326 - accuracy: 0.64 - ETA: 0s - loss: 0.8360 - accuracy: 0.63 - ETA: 0s - loss: 0.8428 - accuracy: 0.63 - ETA: 0s - loss: 0.8387 - accuracy: 0.63 - ETA: 0s - loss: 0.8321 - accuracy: 0.64 - ETA: 0s - loss: 0.8135 - accuracy: 0.65 - ETA: 0s - loss: 0.8189 - accuracy: 0.65 - ETA: 0s - loss: 0.8284 - accuracy: 0.64 - ETA: 0s - loss: 0.8321 - accuracy: 0.64 - ETA: 0s - loss: 0.8377 - accuracy: 0.63 - ETA: 0s - loss: 0.8399 - accuracy: 0.63 - ETA: 0s - loss: 0.8415 - accuracy: 0.6366\n",
      "Epoch 00838: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8415 - accuracy: 0.6366 - val_loss: 1.0583 - val_accuracy: 0.4940 - lr: 0.0010\n",
      "Epoch 839/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8769 - accuracy: 0.59 - ETA: 0s - loss: 0.8551 - accuracy: 0.61 - ETA: 0s - loss: 0.8677 - accuracy: 0.61 - ETA: 0s - loss: 0.8400 - accuracy: 0.63 - ETA: 0s - loss: 0.8413 - accuracy: 0.63 - ETA: 0s - loss: 0.8343 - accuracy: 0.64 - ETA: 0s - loss: 0.8326 - accuracy: 0.64 - ETA: 0s - loss: 0.8327 - accuracy: 0.64 - ETA: 0s - loss: 0.8369 - accuracy: 0.64 - ETA: 0s - loss: 0.8443 - accuracy: 0.63 - ETA: 0s - loss: 0.8393 - accuracy: 0.64 - ETA: 0s - loss: 0.8320 - accuracy: 0.64 - ETA: 0s - loss: 0.8130 - accuracy: 0.66 - ETA: 0s - loss: 0.8168 - accuracy: 0.65 - ETA: 0s - loss: 0.8276 - accuracy: 0.64 - ETA: 0s - loss: 0.8319 - accuracy: 0.64 - ETA: 0s - loss: 0.8391 - accuracy: 0.64 - ETA: 0s - loss: 0.8417 - accuracy: 0.63 - ETA: 0s - loss: 0.8436 - accuracy: 0.6387\n",
      "Epoch 00839: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8436 - accuracy: 0.6387 - val_loss: 1.0636 - val_accuracy: 0.4894 - lr: 0.0010\n",
      "Epoch 840/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8808 - accuracy: 0.58 - ETA: 0s - loss: 0.8528 - accuracy: 0.61 - ETA: 0s - loss: 0.8661 - accuracy: 0.60 - ETA: 0s - loss: 0.8411 - accuracy: 0.62 - ETA: 0s - loss: 0.8447 - accuracy: 0.62 - ETA: 0s - loss: 0.8388 - accuracy: 0.63 - ETA: 0s - loss: 0.8351 - accuracy: 0.63 - ETA: 0s - loss: 0.8331 - accuracy: 0.63 - ETA: 0s - loss: 0.8356 - accuracy: 0.63 - ETA: 0s - loss: 0.8422 - accuracy: 0.63 - ETA: 0s - loss: 0.8374 - accuracy: 0.63 - ETA: 0s - loss: 0.8309 - accuracy: 0.64 - ETA: 0s - loss: 0.8131 - accuracy: 0.65 - ETA: 0s - loss: 0.8194 - accuracy: 0.65 - ETA: 0s - loss: 0.8300 - accuracy: 0.64 - ETA: 0s - loss: 0.8334 - accuracy: 0.64 - ETA: 0s - loss: 0.8396 - accuracy: 0.63 - ETA: 0s - loss: 0.8427 - accuracy: 0.63 - ETA: 0s - loss: 0.8452 - accuracy: 0.6335\n",
      "Epoch 00840: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8452 - accuracy: 0.6335 - val_loss: 1.0496 - val_accuracy: 0.4876 - lr: 0.0010\n",
      "Epoch 841/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9112 - accuracy: 0.57 - ETA: 0s - loss: 0.8676 - accuracy: 0.60 - ETA: 0s - loss: 0.8753 - accuracy: 0.60 - ETA: 0s - loss: 0.8461 - accuracy: 0.62 - ETA: 0s - loss: 0.8448 - accuracy: 0.62 - ETA: 0s - loss: 0.8408 - accuracy: 0.63 - ETA: 0s - loss: 0.8380 - accuracy: 0.63 - ETA: 0s - loss: 0.8368 - accuracy: 0.63 - ETA: 0s - loss: 0.8395 - accuracy: 0.63 - ETA: 0s - loss: 0.8438 - accuracy: 0.63 - ETA: 0s - loss: 0.8389 - accuracy: 0.63 - ETA: 0s - loss: 0.8319 - accuracy: 0.64 - ETA: 0s - loss: 0.8134 - accuracy: 0.65 - ETA: 0s - loss: 0.8183 - accuracy: 0.65 - ETA: 0s - loss: 0.8276 - accuracy: 0.64 - ETA: 0s - loss: 0.8310 - accuracy: 0.64 - ETA: 0s - loss: 0.8370 - accuracy: 0.63 - ETA: 0s - loss: 0.8389 - accuracy: 0.63 - ETA: 0s - loss: 0.8415 - accuracy: 0.6357\n",
      "Epoch 00841: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8415 - accuracy: 0.6357 - val_loss: 1.0524 - val_accuracy: 0.4853 - lr: 0.0010\n",
      "Epoch 842/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8964 - accuracy: 0.55 - ETA: 0s - loss: 0.8590 - accuracy: 0.59 - ETA: 0s - loss: 0.8649 - accuracy: 0.60 - ETA: 0s - loss: 0.8412 - accuracy: 0.62 - ETA: 0s - loss: 0.8444 - accuracy: 0.62 - ETA: 0s - loss: 0.8385 - accuracy: 0.63 - ETA: 0s - loss: 0.8365 - accuracy: 0.63 - ETA: 0s - loss: 0.8345 - accuracy: 0.63 - ETA: 0s - loss: 0.8372 - accuracy: 0.63 - ETA: 0s - loss: 0.8430 - accuracy: 0.62 - ETA: 0s - loss: 0.8389 - accuracy: 0.63 - ETA: 0s - loss: 0.8311 - accuracy: 0.64 - ETA: 0s - loss: 0.8128 - accuracy: 0.65 - ETA: 0s - loss: 0.8178 - accuracy: 0.65 - ETA: 0s - loss: 0.8279 - accuracy: 0.64 - ETA: 0s - loss: 0.8316 - accuracy: 0.63 - ETA: 0s - loss: 0.8381 - accuracy: 0.63 - ETA: 0s - loss: 0.8404 - accuracy: 0.63 - ETA: 0s - loss: 0.8416 - accuracy: 0.6339\n",
      "Epoch 00842: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8416 - accuracy: 0.6339 - val_loss: 1.0474 - val_accuracy: 0.4953 - lr: 0.0010\n",
      "Epoch 843/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8929 - accuracy: 0.58 - ETA: 0s - loss: 0.8566 - accuracy: 0.61 - ETA: 0s - loss: 0.8702 - accuracy: 0.61 - ETA: 0s - loss: 0.8432 - accuracy: 0.62 - ETA: 0s - loss: 0.8456 - accuracy: 0.62 - ETA: 0s - loss: 0.8378 - accuracy: 0.63 - ETA: 0s - loss: 0.8315 - accuracy: 0.64 - ETA: 0s - loss: 0.8293 - accuracy: 0.64 - ETA: 0s - loss: 0.8317 - accuracy: 0.64 - ETA: 0s - loss: 0.8386 - accuracy: 0.63 - ETA: 0s - loss: 0.8347 - accuracy: 0.64 - ETA: 0s - loss: 0.8288 - accuracy: 0.64 - ETA: 0s - loss: 0.8113 - accuracy: 0.65 - ETA: 0s - loss: 0.8185 - accuracy: 0.65 - ETA: 0s - loss: 0.8287 - accuracy: 0.64 - ETA: 0s - loss: 0.8321 - accuracy: 0.64 - ETA: 0s - loss: 0.8381 - accuracy: 0.63 - ETA: 0s - loss: 0.8403 - accuracy: 0.63 - ETA: 0s - loss: 0.8418 - accuracy: 0.6381\n",
      "Epoch 00843: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8418 - accuracy: 0.6381 - val_loss: 1.0505 - val_accuracy: 0.4992 - lr: 0.0010\n",
      "Epoch 844/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9208 - accuracy: 0.55 - ETA: 0s - loss: 0.8660 - accuracy: 0.60 - ETA: 0s - loss: 0.8716 - accuracy: 0.61 - ETA: 0s - loss: 0.8436 - accuracy: 0.62 - ETA: 0s - loss: 0.8423 - accuracy: 0.62 - ETA: 0s - loss: 0.8375 - accuracy: 0.63 - ETA: 0s - loss: 0.8335 - accuracy: 0.64 - ETA: 0s - loss: 0.8340 - accuracy: 0.64 - ETA: 0s - loss: 0.8366 - accuracy: 0.64 - ETA: 0s - loss: 0.8434 - accuracy: 0.63 - ETA: 0s - loss: 0.8377 - accuracy: 0.64 - ETA: 0s - loss: 0.8304 - accuracy: 0.64 - ETA: 0s - loss: 0.8116 - accuracy: 0.65 - ETA: 0s - loss: 0.8175 - accuracy: 0.65 - ETA: 0s - loss: 0.8273 - accuracy: 0.64 - ETA: 0s - loss: 0.8308 - accuracy: 0.64 - ETA: 0s - loss: 0.8374 - accuracy: 0.63 - ETA: 0s - loss: 0.8396 - accuracy: 0.63 - ETA: 0s - loss: 0.8413 - accuracy: 0.6350\n",
      "Epoch 00844: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8413 - accuracy: 0.6350 - val_loss: 1.0574 - val_accuracy: 0.4938 - lr: 0.0010\n",
      "Epoch 845/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8863 - accuracy: 0.57 - ETA: 0s - loss: 0.8474 - accuracy: 0.60 - ETA: 0s - loss: 0.8582 - accuracy: 0.60 - ETA: 0s - loss: 0.8340 - accuracy: 0.62 - ETA: 0s - loss: 0.8359 - accuracy: 0.62 - ETA: 0s - loss: 0.8303 - accuracy: 0.63 - ETA: 0s - loss: 0.8283 - accuracy: 0.63 - ETA: 0s - loss: 0.8258 - accuracy: 0.64 - ETA: 0s - loss: 0.8293 - accuracy: 0.63 - ETA: 0s - loss: 0.8369 - accuracy: 0.63 - ETA: 0s - loss: 0.8326 - accuracy: 0.63 - ETA: 0s - loss: 0.8278 - accuracy: 0.64 - ETA: 0s - loss: 0.8096 - accuracy: 0.65 - ETA: 0s - loss: 0.8146 - accuracy: 0.65 - ETA: 0s - loss: 0.8230 - accuracy: 0.64 - ETA: 0s - loss: 0.8269 - accuracy: 0.64 - ETA: 0s - loss: 0.8354 - accuracy: 0.63 - ETA: 0s - loss: 0.8370 - accuracy: 0.6368\n",
      "Epoch 00845: val_loss did not improve from 0.99131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8370 - accuracy: 0.6368 - val_loss: 1.0722 - val_accuracy: 0.4871 - lr: 0.0010\n",
      "Epoch 846/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8879 - accuracy: 0.56 - ETA: 0s - loss: 0.8572 - accuracy: 0.60 - ETA: 0s - loss: 0.8696 - accuracy: 0.60 - ETA: 0s - loss: 0.8433 - accuracy: 0.62 - ETA: 0s - loss: 0.8495 - accuracy: 0.62 - ETA: 0s - loss: 0.8425 - accuracy: 0.63 - ETA: 0s - loss: 0.8382 - accuracy: 0.63 - ETA: 0s - loss: 0.8362 - accuracy: 0.63 - ETA: 0s - loss: 0.8395 - accuracy: 0.63 - ETA: 0s - loss: 0.8453 - accuracy: 0.63 - ETA: 0s - loss: 0.8403 - accuracy: 0.63 - ETA: 0s - loss: 0.8332 - accuracy: 0.64 - ETA: 0s - loss: 0.8142 - accuracy: 0.65 - ETA: 0s - loss: 0.8202 - accuracy: 0.65 - ETA: 0s - loss: 0.8316 - accuracy: 0.64 - ETA: 0s - loss: 0.8351 - accuracy: 0.63 - ETA: 0s - loss: 0.8421 - accuracy: 0.63 - ETA: 0s - loss: 0.8447 - accuracy: 0.63 - ETA: 0s - loss: 0.8466 - accuracy: 0.6314\n",
      "Epoch 00846: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8466 - accuracy: 0.6314 - val_loss: 1.0646 - val_accuracy: 0.4896 - lr: 0.0010\n",
      "Epoch 847/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8993 - accuracy: 0.57 - ETA: 0s - loss: 0.8611 - accuracy: 0.61 - ETA: 0s - loss: 0.8635 - accuracy: 0.61 - ETA: 0s - loss: 0.8391 - accuracy: 0.62 - ETA: 0s - loss: 0.8472 - accuracy: 0.62 - ETA: 0s - loss: 0.8392 - accuracy: 0.63 - ETA: 0s - loss: 0.8371 - accuracy: 0.63 - ETA: 0s - loss: 0.8355 - accuracy: 0.63 - ETA: 0s - loss: 0.8378 - accuracy: 0.63 - ETA: 0s - loss: 0.8430 - accuracy: 0.63 - ETA: 0s - loss: 0.8388 - accuracy: 0.63 - ETA: 0s - loss: 0.8315 - accuracy: 0.64 - ETA: 0s - loss: 0.8132 - accuracy: 0.65 - ETA: 0s - loss: 0.8187 - accuracy: 0.65 - ETA: 0s - loss: 0.8303 - accuracy: 0.64 - ETA: 0s - loss: 0.8332 - accuracy: 0.63 - ETA: 0s - loss: 0.8391 - accuracy: 0.63 - ETA: 0s - loss: 0.8411 - accuracy: 0.63 - ETA: 0s - loss: 0.8433 - accuracy: 0.6323\n",
      "Epoch 00847: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8433 - accuracy: 0.6323 - val_loss: 1.0596 - val_accuracy: 0.4927 - lr: 0.0010\n",
      "Epoch 848/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9003 - accuracy: 0.58 - ETA: 0s - loss: 0.8462 - accuracy: 0.62 - ETA: 0s - loss: 0.8575 - accuracy: 0.61 - ETA: 0s - loss: 0.8325 - accuracy: 0.63 - ETA: 0s - loss: 0.8374 - accuracy: 0.63 - ETA: 0s - loss: 0.8311 - accuracy: 0.64 - ETA: 0s - loss: 0.8299 - accuracy: 0.64 - ETA: 0s - loss: 0.8285 - accuracy: 0.64 - ETA: 0s - loss: 0.8321 - accuracy: 0.64 - ETA: 0s - loss: 0.8384 - accuracy: 0.63 - ETA: 0s - loss: 0.8346 - accuracy: 0.64 - ETA: 0s - loss: 0.8282 - accuracy: 0.64 - ETA: 0s - loss: 0.8105 - accuracy: 0.65 - ETA: 0s - loss: 0.8148 - accuracy: 0.65 - ETA: 0s - loss: 0.8249 - accuracy: 0.64 - ETA: 0s - loss: 0.8283 - accuracy: 0.64 - ETA: 0s - loss: 0.8356 - accuracy: 0.63 - ETA: 0s - loss: 0.8377 - accuracy: 0.63 - ETA: 0s - loss: 0.8395 - accuracy: 0.6373\n",
      "Epoch 00848: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8395 - accuracy: 0.6373 - val_loss: 1.0575 - val_accuracy: 0.4904 - lr: 0.0010\n",
      "Epoch 849/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8961 - accuracy: 0.59 - ETA: 0s - loss: 0.8552 - accuracy: 0.62 - ETA: 0s - loss: 0.8640 - accuracy: 0.61 - ETA: 0s - loss: 0.8383 - accuracy: 0.63 - ETA: 0s - loss: 0.8402 - accuracy: 0.63 - ETA: 0s - loss: 0.8347 - accuracy: 0.63 - ETA: 0s - loss: 0.8316 - accuracy: 0.64 - ETA: 0s - loss: 0.8304 - accuracy: 0.64 - ETA: 0s - loss: 0.8341 - accuracy: 0.64 - ETA: 0s - loss: 0.8409 - accuracy: 0.63 - ETA: 0s - loss: 0.8367 - accuracy: 0.64 - ETA: 0s - loss: 0.8306 - accuracy: 0.64 - ETA: 0s - loss: 0.8130 - accuracy: 0.65 - ETA: 0s - loss: 0.8171 - accuracy: 0.65 - ETA: 0s - loss: 0.8252 - accuracy: 0.64 - ETA: 0s - loss: 0.8294 - accuracy: 0.64 - ETA: 0s - loss: 0.8350 - accuracy: 0.64 - ETA: 0s - loss: 0.8371 - accuracy: 0.63 - ETA: 0s - loss: 0.8384 - accuracy: 0.6381\n",
      "Epoch 00849: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8384 - accuracy: 0.6381 - val_loss: 1.0575 - val_accuracy: 0.4899 - lr: 0.0010\n",
      "Epoch 850/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8887 - accuracy: 0.59 - ETA: 0s - loss: 0.8536 - accuracy: 0.61 - ETA: 0s - loss: 0.8678 - accuracy: 0.60 - ETA: 0s - loss: 0.8408 - accuracy: 0.62 - ETA: 0s - loss: 0.8410 - accuracy: 0.62 - ETA: 0s - loss: 0.8364 - accuracy: 0.63 - ETA: 0s - loss: 0.8331 - accuracy: 0.63 - ETA: 0s - loss: 0.8318 - accuracy: 0.63 - ETA: 0s - loss: 0.8337 - accuracy: 0.63 - ETA: 0s - loss: 0.8378 - accuracy: 0.63 - ETA: 0s - loss: 0.8332 - accuracy: 0.64 - ETA: 0s - loss: 0.8278 - accuracy: 0.64 - ETA: 0s - loss: 0.8100 - accuracy: 0.65 - ETA: 0s - loss: 0.8148 - accuracy: 0.65 - ETA: 0s - loss: 0.8237 - accuracy: 0.64 - ETA: 0s - loss: 0.8272 - accuracy: 0.64 - ETA: 0s - loss: 0.8335 - accuracy: 0.63 - ETA: 0s - loss: 0.8364 - accuracy: 0.63 - ETA: 0s - loss: 0.8376 - accuracy: 0.6350\n",
      "Epoch 00850: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8376 - accuracy: 0.6350 - val_loss: 1.0572 - val_accuracy: 0.4897 - lr: 0.0010\n",
      "Epoch 851/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8502 - accuracy: 0.61 - ETA: 0s - loss: 0.8353 - accuracy: 0.63 - ETA: 0s - loss: 0.8521 - accuracy: 0.61 - ETA: 0s - loss: 0.8303 - accuracy: 0.63 - ETA: 0s - loss: 0.8344 - accuracy: 0.63 - ETA: 0s - loss: 0.8302 - accuracy: 0.64 - ETA: 0s - loss: 0.8275 - accuracy: 0.64 - ETA: 0s - loss: 0.8264 - accuracy: 0.64 - ETA: 0s - loss: 0.8288 - accuracy: 0.64 - ETA: 0s - loss: 0.8342 - accuracy: 0.63 - ETA: 0s - loss: 0.8313 - accuracy: 0.64 - ETA: 0s - loss: 0.8247 - accuracy: 0.64 - ETA: 0s - loss: 0.8069 - accuracy: 0.66 - ETA: 0s - loss: 0.8126 - accuracy: 0.65 - ETA: 0s - loss: 0.8212 - accuracy: 0.64 - ETA: 0s - loss: 0.8248 - accuracy: 0.64 - ETA: 0s - loss: 0.8309 - accuracy: 0.63 - ETA: 0s - loss: 0.8347 - accuracy: 0.63 - ETA: 0s - loss: 0.8366 - accuracy: 0.6374\n",
      "Epoch 00851: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00851: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8366 - accuracy: 0.6374 - val_loss: 1.0552 - val_accuracy: 0.4902 - lr: 0.0010\n",
      "Epoch 852/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8917 - accuracy: 0.58 - ETA: 0s - loss: 0.8489 - accuracy: 0.62 - ETA: 0s - loss: 0.8623 - accuracy: 0.61 - ETA: 0s - loss: 0.8361 - accuracy: 0.63 - ETA: 0s - loss: 0.8390 - accuracy: 0.63 - ETA: 0s - loss: 0.8344 - accuracy: 0.64 - ETA: 0s - loss: 0.8343 - accuracy: 0.64 - ETA: 0s - loss: 0.8334 - accuracy: 0.64 - ETA: 0s - loss: 0.8356 - accuracy: 0.64 - ETA: 0s - loss: 0.8410 - accuracy: 0.63 - ETA: 0s - loss: 0.8365 - accuracy: 0.63 - ETA: 0s - loss: 0.8289 - accuracy: 0.64 - ETA: 0s - loss: 0.8109 - accuracy: 0.65 - ETA: 0s - loss: 0.8162 - accuracy: 0.65 - ETA: 0s - loss: 0.8267 - accuracy: 0.64 - ETA: 0s - loss: 0.8307 - accuracy: 0.64 - ETA: 0s - loss: 0.8370 - accuracy: 0.63 - ETA: 0s - loss: 0.8396 - accuracy: 0.63 - ETA: 0s - loss: 0.8407 - accuracy: 0.6364\n",
      "Epoch 00852: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8407 - accuracy: 0.6364 - val_loss: 1.0521 - val_accuracy: 0.4906 - lr: 0.0010\n",
      "Epoch 853/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.8888 - accuracy: 0.57 - ETA: 0s - loss: 0.8588 - accuracy: 0.60 - ETA: 0s - loss: 0.8724 - accuracy: 0.61 - ETA: 0s - loss: 0.8446 - accuracy: 0.62 - ETA: 0s - loss: 0.8453 - accuracy: 0.62 - ETA: 0s - loss: 0.8388 - accuracy: 0.63 - ETA: 0s - loss: 0.8364 - accuracy: 0.64 - ETA: 0s - loss: 0.8367 - accuracy: 0.64 - ETA: 0s - loss: 0.8391 - accuracy: 0.63 - ETA: 0s - loss: 0.8444 - accuracy: 0.63 - ETA: 0s - loss: 0.8402 - accuracy: 0.63 - ETA: 0s - loss: 0.8322 - accuracy: 0.64 - ETA: 0s - loss: 0.8138 - accuracy: 0.65 - ETA: 0s - loss: 0.8180 - accuracy: 0.65 - ETA: 0s - loss: 0.8257 - accuracy: 0.64 - ETA: 0s - loss: 0.8297 - accuracy: 0.64 - ETA: 0s - loss: 0.8364 - accuracy: 0.63 - ETA: 0s - loss: 0.8392 - accuracy: 0.63 - ETA: 0s - loss: 0.8422 - accuracy: 0.6354\n",
      "Epoch 00853: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8422 - accuracy: 0.6354 - val_loss: 1.0486 - val_accuracy: 0.4888 - lr: 0.0010\n",
      "Epoch 854/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8877 - accuracy: 0.56 - ETA: 0s - loss: 0.8454 - accuracy: 0.61 - ETA: 0s - loss: 0.8584 - accuracy: 0.60 - ETA: 0s - loss: 0.8332 - accuracy: 0.62 - ETA: 0s - loss: 0.8365 - accuracy: 0.62 - ETA: 0s - loss: 0.8310 - accuracy: 0.63 - ETA: 0s - loss: 0.8263 - accuracy: 0.64 - ETA: 0s - loss: 0.8262 - accuracy: 0.64 - ETA: 0s - loss: 0.8292 - accuracy: 0.64 - ETA: 0s - loss: 0.8363 - accuracy: 0.63 - ETA: 0s - loss: 0.8318 - accuracy: 0.64 - ETA: 0s - loss: 0.8249 - accuracy: 0.64 - ETA: 0s - loss: 0.8071 - accuracy: 0.66 - ETA: 0s - loss: 0.8124 - accuracy: 0.65 - ETA: 0s - loss: 0.8234 - accuracy: 0.64 - ETA: 0s - loss: 0.8274 - accuracy: 0.64 - ETA: 0s - loss: 0.8340 - accuracy: 0.63 - ETA: 0s - loss: 0.8363 - accuracy: 0.63 - ETA: 0s - loss: 0.8384 - accuracy: 0.6361\n",
      "Epoch 00854: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8384 - accuracy: 0.6361 - val_loss: 1.0604 - val_accuracy: 0.4832 - lr: 0.0010\n",
      "Epoch 855/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8844 - accuracy: 0.56 - ETA: 0s - loss: 0.8517 - accuracy: 0.60 - ETA: 0s - loss: 0.8587 - accuracy: 0.61 - ETA: 0s - loss: 0.8341 - accuracy: 0.62 - ETA: 0s - loss: 0.8373 - accuracy: 0.62 - ETA: 0s - loss: 0.8324 - accuracy: 0.63 - ETA: 0s - loss: 0.8298 - accuracy: 0.64 - ETA: 0s - loss: 0.8303 - accuracy: 0.64 - ETA: 0s - loss: 0.8322 - accuracy: 0.64 - ETA: 0s - loss: 0.8375 - accuracy: 0.63 - ETA: 0s - loss: 0.8336 - accuracy: 0.64 - ETA: 0s - loss: 0.8272 - accuracy: 0.64 - ETA: 0s - loss: 0.8085 - accuracy: 0.65 - ETA: 0s - loss: 0.8138 - accuracy: 0.65 - ETA: 0s - loss: 0.8231 - accuracy: 0.64 - ETA: 0s - loss: 0.8270 - accuracy: 0.64 - ETA: 0s - loss: 0.8337 - accuracy: 0.63 - ETA: 0s - loss: 0.8357 - accuracy: 0.63 - ETA: 0s - loss: 0.8378 - accuracy: 0.6363\n",
      "Epoch 00855: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8378 - accuracy: 0.6363 - val_loss: 1.0443 - val_accuracy: 0.4972 - lr: 0.0010\n",
      "Epoch 856/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8795 - accuracy: 0.59 - ETA: 0s - loss: 0.8469 - accuracy: 0.62 - ETA: 0s - loss: 0.8567 - accuracy: 0.61 - ETA: 0s - loss: 0.8335 - accuracy: 0.63 - ETA: 0s - loss: 0.8361 - accuracy: 0.63 - ETA: 0s - loss: 0.8300 - accuracy: 0.64 - ETA: 0s - loss: 0.8274 - accuracy: 0.64 - ETA: 0s - loss: 0.8241 - accuracy: 0.64 - ETA: 0s - loss: 0.8280 - accuracy: 0.64 - ETA: 0s - loss: 0.8352 - accuracy: 0.63 - ETA: 0s - loss: 0.8313 - accuracy: 0.63 - ETA: 0s - loss: 0.8246 - accuracy: 0.64 - ETA: 0s - loss: 0.8063 - accuracy: 0.65 - ETA: 0s - loss: 0.8102 - accuracy: 0.65 - ETA: 0s - loss: 0.8215 - accuracy: 0.64 - ETA: 0s - loss: 0.8253 - accuracy: 0.64 - ETA: 0s - loss: 0.8318 - accuracy: 0.63 - ETA: 0s - loss: 0.8355 - accuracy: 0.63 - ETA: 0s - loss: 0.8362 - accuracy: 0.6378\n",
      "Epoch 00856: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8362 - accuracy: 0.6378 - val_loss: 1.0446 - val_accuracy: 0.4954 - lr: 0.0010\n",
      "Epoch 857/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8778 - accuracy: 0.59 - ETA: 0s - loss: 0.8456 - accuracy: 0.62 - ETA: 0s - loss: 0.8577 - accuracy: 0.61 - ETA: 0s - loss: 0.8328 - accuracy: 0.63 - ETA: 0s - loss: 0.8385 - accuracy: 0.63 - ETA: 0s - loss: 0.8338 - accuracy: 0.64 - ETA: 0s - loss: 0.8316 - accuracy: 0.64 - ETA: 0s - loss: 0.8283 - accuracy: 0.64 - ETA: 0s - loss: 0.8304 - accuracy: 0.64 - ETA: 0s - loss: 0.8371 - accuracy: 0.63 - ETA: 0s - loss: 0.8338 - accuracy: 0.64 - ETA: 0s - loss: 0.8301 - accuracy: 0.64 - ETA: 0s - loss: 0.8119 - accuracy: 0.66 - ETA: 0s - loss: 0.8171 - accuracy: 0.65 - ETA: 0s - loss: 0.8269 - accuracy: 0.64 - ETA: 0s - loss: 0.8305 - accuracy: 0.64 - ETA: 0s - loss: 0.8362 - accuracy: 0.64 - ETA: 0s - loss: 0.8392 - accuracy: 0.63 - ETA: 0s - loss: 0.8404 - accuracy: 0.6382\n",
      "Epoch 00857: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8404 - accuracy: 0.6382 - val_loss: 1.0465 - val_accuracy: 0.4922 - lr: 0.0010\n",
      "Epoch 858/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9005 - accuracy: 0.56 - ETA: 0s - loss: 0.8506 - accuracy: 0.61 - ETA: 0s - loss: 0.8624 - accuracy: 0.61 - ETA: 0s - loss: 0.8357 - accuracy: 0.63 - ETA: 0s - loss: 0.8397 - accuracy: 0.63 - ETA: 0s - loss: 0.8348 - accuracy: 0.63 - ETA: 0s - loss: 0.8324 - accuracy: 0.64 - ETA: 0s - loss: 0.8309 - accuracy: 0.64 - ETA: 0s - loss: 0.8354 - accuracy: 0.64 - ETA: 0s - loss: 0.8419 - accuracy: 0.63 - ETA: 0s - loss: 0.8380 - accuracy: 0.64 - ETA: 0s - loss: 0.8307 - accuracy: 0.64 - ETA: 0s - loss: 0.8132 - accuracy: 0.65 - ETA: 0s - loss: 0.8176 - accuracy: 0.65 - ETA: 0s - loss: 0.8269 - accuracy: 0.64 - ETA: 0s - loss: 0.8299 - accuracy: 0.64 - ETA: 0s - loss: 0.8362 - accuracy: 0.64 - ETA: 0s - loss: 0.8386 - accuracy: 0.64 - ETA: 0s - loss: 0.8401 - accuracy: 0.6388\n",
      "Epoch 00858: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8401 - accuracy: 0.6388 - val_loss: 1.0423 - val_accuracy: 0.4951 - lr: 0.0010\n",
      "Epoch 859/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8815 - accuracy: 0.57 - ETA: 0s - loss: 0.8443 - accuracy: 0.61 - ETA: 0s - loss: 0.8526 - accuracy: 0.61 - ETA: 0s - loss: 0.8283 - accuracy: 0.63 - ETA: 0s - loss: 0.8330 - accuracy: 0.63 - ETA: 0s - loss: 0.8299 - accuracy: 0.63 - ETA: 0s - loss: 0.8275 - accuracy: 0.64 - ETA: 0s - loss: 0.8240 - accuracy: 0.64 - ETA: 0s - loss: 0.8274 - accuracy: 0.64 - ETA: 0s - loss: 0.8351 - accuracy: 0.63 - ETA: 0s - loss: 0.8320 - accuracy: 0.64 - ETA: 0s - loss: 0.8251 - accuracy: 0.64 - ETA: 0s - loss: 0.8067 - accuracy: 0.66 - ETA: 0s - loss: 0.8119 - accuracy: 0.65 - ETA: 0s - loss: 0.8224 - accuracy: 0.64 - ETA: 0s - loss: 0.8269 - accuracy: 0.64 - ETA: 0s - loss: 0.8340 - accuracy: 0.64 - ETA: 0s - loss: 0.8362 - accuracy: 0.64 - ETA: 0s - loss: 0.8380 - accuracy: 0.6392\n",
      "Epoch 00859: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8380 - accuracy: 0.6392 - val_loss: 1.0390 - val_accuracy: 0.4977 - lr: 0.0010\n",
      "Epoch 860/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8685 - accuracy: 0.61 - ETA: 0s - loss: 0.8358 - accuracy: 0.64 - ETA: 0s - loss: 0.8492 - accuracy: 0.62 - ETA: 0s - loss: 0.8263 - accuracy: 0.63 - ETA: 0s - loss: 0.8323 - accuracy: 0.63 - ETA: 0s - loss: 0.8280 - accuracy: 0.64 - ETA: 0s - loss: 0.8280 - accuracy: 0.64 - ETA: 0s - loss: 0.8279 - accuracy: 0.64 - ETA: 0s - loss: 0.8297 - accuracy: 0.64 - ETA: 0s - loss: 0.8364 - accuracy: 0.63 - ETA: 0s - loss: 0.8318 - accuracy: 0.64 - ETA: 0s - loss: 0.8247 - accuracy: 0.64 - ETA: 0s - loss: 0.8063 - accuracy: 0.66 - ETA: 0s - loss: 0.8121 - accuracy: 0.65 - ETA: 0s - loss: 0.8216 - accuracy: 0.64 - ETA: 0s - loss: 0.8255 - accuracy: 0.64 - ETA: 0s - loss: 0.8320 - accuracy: 0.64 - ETA: 0s - loss: 0.8344 - accuracy: 0.64 - ETA: 0s - loss: 0.8360 - accuracy: 0.6393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00860: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8360 - accuracy: 0.6393 - val_loss: 1.0518 - val_accuracy: 0.4901 - lr: 0.0010\n",
      "Epoch 861/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8820 - accuracy: 0.57 - ETA: 0s - loss: 0.8412 - accuracy: 0.61 - ETA: 0s - loss: 0.8505 - accuracy: 0.61 - ETA: 0s - loss: 0.8277 - accuracy: 0.63 - ETA: 0s - loss: 0.8332 - accuracy: 0.63 - ETA: 0s - loss: 0.8288 - accuracy: 0.63 - ETA: 0s - loss: 0.8264 - accuracy: 0.64 - ETA: 0s - loss: 0.8283 - accuracy: 0.64 - ETA: 0s - loss: 0.8324 - accuracy: 0.64 - ETA: 0s - loss: 0.8373 - accuracy: 0.63 - ETA: 0s - loss: 0.8337 - accuracy: 0.64 - ETA: 0s - loss: 0.8274 - accuracy: 0.64 - ETA: 0s - loss: 0.8090 - accuracy: 0.65 - ETA: 0s - loss: 0.8146 - accuracy: 0.65 - ETA: 0s - loss: 0.8250 - accuracy: 0.64 - ETA: 0s - loss: 0.8285 - accuracy: 0.64 - ETA: 0s - loss: 0.8353 - accuracy: 0.64 - ETA: 0s - loss: 0.8381 - accuracy: 0.63 - ETA: 0s - loss: 0.8400 - accuracy: 0.6383\n",
      "Epoch 00861: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8400 - accuracy: 0.6383 - val_loss: 1.0510 - val_accuracy: 0.4958 - lr: 0.0010\n",
      "Epoch 862/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8737 - accuracy: 0.58 - ETA: 0s - loss: 0.8416 - accuracy: 0.61 - ETA: 0s - loss: 0.8497 - accuracy: 0.61 - ETA: 0s - loss: 0.8275 - accuracy: 0.63 - ETA: 0s - loss: 0.8325 - accuracy: 0.63 - ETA: 0s - loss: 0.8264 - accuracy: 0.64 - ETA: 0s - loss: 0.8271 - accuracy: 0.64 - ETA: 0s - loss: 0.8253 - accuracy: 0.64 - ETA: 0s - loss: 0.8290 - accuracy: 0.64 - ETA: 0s - loss: 0.8354 - accuracy: 0.63 - ETA: 0s - loss: 0.8317 - accuracy: 0.64 - ETA: 0s - loss: 0.8279 - accuracy: 0.64 - ETA: 0s - loss: 0.8098 - accuracy: 0.65 - ETA: 0s - loss: 0.8156 - accuracy: 0.65 - ETA: 0s - loss: 0.8252 - accuracy: 0.64 - ETA: 0s - loss: 0.8290 - accuracy: 0.64 - ETA: 0s - loss: 0.8360 - accuracy: 0.63 - ETA: 0s - loss: 0.8387 - accuracy: 0.63 - ETA: 0s - loss: 0.8404 - accuracy: 0.6371\n",
      "Epoch 00862: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8404 - accuracy: 0.6371 - val_loss: 1.0506 - val_accuracy: 0.4938 - lr: 0.0010\n",
      "Epoch 863/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8691 - accuracy: 0.57 - ETA: 0s - loss: 0.8383 - accuracy: 0.62 - ETA: 0s - loss: 0.8559 - accuracy: 0.61 - ETA: 0s - loss: 0.8297 - accuracy: 0.63 - ETA: 0s - loss: 0.8339 - accuracy: 0.63 - ETA: 0s - loss: 0.8296 - accuracy: 0.64 - ETA: 0s - loss: 0.8283 - accuracy: 0.64 - ETA: 0s - loss: 0.8282 - accuracy: 0.64 - ETA: 0s - loss: 0.8313 - accuracy: 0.64 - ETA: 0s - loss: 0.8367 - accuracy: 0.63 - ETA: 0s - loss: 0.8324 - accuracy: 0.64 - ETA: 0s - loss: 0.8254 - accuracy: 0.64 - ETA: 0s - loss: 0.8070 - accuracy: 0.66 - ETA: 0s - loss: 0.8125 - accuracy: 0.65 - ETA: 0s - loss: 0.8226 - accuracy: 0.64 - ETA: 0s - loss: 0.8263 - accuracy: 0.64 - ETA: 0s - loss: 0.8342 - accuracy: 0.63 - ETA: 0s - loss: 0.8367 - accuracy: 0.63 - ETA: 0s - loss: 0.8381 - accuracy: 0.6374\n",
      "Epoch 00863: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8381 - accuracy: 0.6374 - val_loss: 1.0548 - val_accuracy: 0.4966 - lr: 0.0010\n",
      "Epoch 864/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8823 - accuracy: 0.56 - ETA: 0s - loss: 0.8509 - accuracy: 0.61 - ETA: 0s - loss: 0.8649 - accuracy: 0.61 - ETA: 0s - loss: 0.8410 - accuracy: 0.62 - ETA: 0s - loss: 0.8452 - accuracy: 0.62 - ETA: 0s - loss: 0.8386 - accuracy: 0.63 - ETA: 0s - loss: 0.8344 - accuracy: 0.64 - ETA: 0s - loss: 0.8312 - accuracy: 0.64 - ETA: 0s - loss: 0.8328 - accuracy: 0.64 - ETA: 0s - loss: 0.8385 - accuracy: 0.63 - ETA: 0s - loss: 0.8336 - accuracy: 0.64 - ETA: 0s - loss: 0.8273 - accuracy: 0.64 - ETA: 0s - loss: 0.8092 - accuracy: 0.66 - ETA: 0s - loss: 0.8123 - accuracy: 0.65 - ETA: 0s - loss: 0.8228 - accuracy: 0.64 - ETA: 0s - loss: 0.8259 - accuracy: 0.64 - ETA: 0s - loss: 0.8331 - accuracy: 0.64 - ETA: 0s - loss: 0.8361 - accuracy: 0.64 - ETA: 0s - loss: 0.8374 - accuracy: 0.6408\n",
      "Epoch 00864: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8374 - accuracy: 0.6408 - val_loss: 1.0536 - val_accuracy: 0.4969 - lr: 0.0010\n",
      "Epoch 865/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8614 - accuracy: 0.59 - ETA: 0s - loss: 0.8357 - accuracy: 0.62 - ETA: 0s - loss: 0.8434 - accuracy: 0.61 - ETA: 0s - loss: 0.8216 - accuracy: 0.63 - ETA: 0s - loss: 0.8268 - accuracy: 0.63 - ETA: 0s - loss: 0.8224 - accuracy: 0.64 - ETA: 0s - loss: 0.8227 - accuracy: 0.64 - ETA: 0s - loss: 0.8217 - accuracy: 0.64 - ETA: 0s - loss: 0.8255 - accuracy: 0.64 - ETA: 0s - loss: 0.8323 - accuracy: 0.63 - ETA: 0s - loss: 0.8282 - accuracy: 0.63 - ETA: 0s - loss: 0.8228 - accuracy: 0.64 - ETA: 0s - loss: 0.8060 - accuracy: 0.65 - ETA: 0s - loss: 0.8115 - accuracy: 0.65 - ETA: 0s - loss: 0.8217 - accuracy: 0.64 - ETA: 0s - loss: 0.8254 - accuracy: 0.63 - ETA: 0s - loss: 0.8323 - accuracy: 0.63 - ETA: 0s - loss: 0.8353 - accuracy: 0.63 - ETA: 0s - loss: 0.8373 - accuracy: 0.6325\n",
      "Epoch 00865: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00865: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8373 - accuracy: 0.6325 - val_loss: 1.0578 - val_accuracy: 0.4930 - lr: 0.0010\n",
      "Epoch 866/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8763 - accuracy: 0.56 - ETA: 0s - loss: 0.8387 - accuracy: 0.60 - ETA: 0s - loss: 0.8512 - accuracy: 0.60 - ETA: 0s - loss: 0.8292 - accuracy: 0.62 - ETA: 0s - loss: 0.8352 - accuracy: 0.62 - ETA: 0s - loss: 0.8302 - accuracy: 0.63 - ETA: 0s - loss: 0.8297 - accuracy: 0.63 - ETA: 0s - loss: 0.8291 - accuracy: 0.63 - ETA: 0s - loss: 0.8323 - accuracy: 0.63 - ETA: 0s - loss: 0.8365 - accuracy: 0.63 - ETA: 0s - loss: 0.8318 - accuracy: 0.63 - ETA: 0s - loss: 0.8257 - accuracy: 0.64 - ETA: 0s - loss: 0.8066 - accuracy: 0.65 - ETA: 0s - loss: 0.8109 - accuracy: 0.65 - ETA: 0s - loss: 0.8190 - accuracy: 0.64 - ETA: 0s - loss: 0.8223 - accuracy: 0.64 - ETA: 0s - loss: 0.8286 - accuracy: 0.63 - ETA: 0s - loss: 0.8314 - accuracy: 0.63 - ETA: 0s - loss: 0.8342 - accuracy: 0.6365\n",
      "Epoch 00866: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8342 - accuracy: 0.6365 - val_loss: 1.0542 - val_accuracy: 0.4922 - lr: 0.0010\n",
      "Epoch 867/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8795 - accuracy: 0.58 - ETA: 0s - loss: 0.8475 - accuracy: 0.61 - ETA: 0s - loss: 0.8604 - accuracy: 0.61 - ETA: 0s - loss: 0.8314 - accuracy: 0.63 - ETA: 0s - loss: 0.8346 - accuracy: 0.63 - ETA: 0s - loss: 0.8297 - accuracy: 0.64 - ETA: 0s - loss: 0.8273 - accuracy: 0.64 - ETA: 0s - loss: 0.8244 - accuracy: 0.64 - ETA: 0s - loss: 0.8288 - accuracy: 0.64 - ETA: 0s - loss: 0.8339 - accuracy: 0.63 - ETA: 0s - loss: 0.8300 - accuracy: 0.64 - ETA: 0s - loss: 0.8241 - accuracy: 0.65 - ETA: 0s - loss: 0.8064 - accuracy: 0.66 - ETA: 0s - loss: 0.8102 - accuracy: 0.65 - ETA: 0s - loss: 0.8198 - accuracy: 0.64 - ETA: 0s - loss: 0.8242 - accuracy: 0.64 - ETA: 0s - loss: 0.8342 - accuracy: 0.64 - ETA: 0s - loss: 0.8367 - accuracy: 0.6381\n",
      "Epoch 00867: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8367 - accuracy: 0.6381 - val_loss: 1.0597 - val_accuracy: 0.4894 - lr: 0.0010\n",
      "Epoch 868/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.8860 - accuracy: 0.58 - ETA: 0s - loss: 0.8490 - accuracy: 0.61 - ETA: 0s - loss: 0.8613 - accuracy: 0.61 - ETA: 0s - loss: 0.8334 - accuracy: 0.63 - ETA: 0s - loss: 0.8371 - accuracy: 0.63 - ETA: 0s - loss: 0.8323 - accuracy: 0.63 - ETA: 0s - loss: 0.8322 - accuracy: 0.64 - ETA: 0s - loss: 0.8299 - accuracy: 0.64 - ETA: 0s - loss: 0.8326 - accuracy: 0.64 - ETA: 0s - loss: 0.8376 - accuracy: 0.63 - ETA: 0s - loss: 0.8327 - accuracy: 0.64 - ETA: 0s - loss: 0.8266 - accuracy: 0.64 - ETA: 0s - loss: 0.8085 - accuracy: 0.66 - ETA: 0s - loss: 0.8144 - accuracy: 0.65 - ETA: 0s - loss: 0.8237 - accuracy: 0.64 - ETA: 0s - loss: 0.8276 - accuracy: 0.64 - ETA: 0s - loss: 0.8344 - accuracy: 0.64 - ETA: 0s - loss: 0.8375 - accuracy: 0.64 - ETA: 0s - loss: 0.8384 - accuracy: 0.6389\n",
      "Epoch 00868: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8384 - accuracy: 0.6389 - val_loss: 1.0560 - val_accuracy: 0.4938 - lr: 0.0010\n",
      "Epoch 869/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8780 - accuracy: 0.58 - ETA: 0s - loss: 0.8416 - accuracy: 0.61 - ETA: 0s - loss: 0.8535 - accuracy: 0.61 - ETA: 0s - loss: 0.8287 - accuracy: 0.63 - ETA: 0s - loss: 0.8298 - accuracy: 0.63 - ETA: 0s - loss: 0.8260 - accuracy: 0.64 - ETA: 0s - loss: 0.8251 - accuracy: 0.64 - ETA: 0s - loss: 0.8244 - accuracy: 0.64 - ETA: 0s - loss: 0.8253 - accuracy: 0.63 - ETA: 0s - loss: 0.8317 - accuracy: 0.63 - ETA: 0s - loss: 0.8283 - accuracy: 0.64 - ETA: 0s - loss: 0.8222 - accuracy: 0.64 - ETA: 0s - loss: 0.8047 - accuracy: 0.66 - ETA: 0s - loss: 0.8091 - accuracy: 0.65 - ETA: 0s - loss: 0.8203 - accuracy: 0.64 - ETA: 0s - loss: 0.8254 - accuracy: 0.64 - ETA: 0s - loss: 0.8320 - accuracy: 0.64 - ETA: 0s - loss: 0.8345 - accuracy: 0.63 - ETA: 0s - loss: 0.8364 - accuracy: 0.6383\n",
      "Epoch 00869: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8364 - accuracy: 0.6383 - val_loss: 1.0583 - val_accuracy: 0.4932 - lr: 0.0010\n",
      "Epoch 870/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9008 - accuracy: 0.56 - ETA: 0s - loss: 0.8642 - accuracy: 0.60 - ETA: 0s - loss: 0.8685 - accuracy: 0.60 - ETA: 0s - loss: 0.8412 - accuracy: 0.62 - ETA: 0s - loss: 0.8454 - accuracy: 0.62 - ETA: 0s - loss: 0.8393 - accuracy: 0.63 - ETA: 0s - loss: 0.8347 - accuracy: 0.63 - ETA: 0s - loss: 0.8320 - accuracy: 0.63 - ETA: 0s - loss: 0.8355 - accuracy: 0.63 - ETA: 0s - loss: 0.8401 - accuracy: 0.63 - ETA: 0s - loss: 0.8351 - accuracy: 0.63 - ETA: 0s - loss: 0.8274 - accuracy: 0.64 - ETA: 0s - loss: 0.8087 - accuracy: 0.65 - ETA: 0s - loss: 0.8139 - accuracy: 0.65 - ETA: 0s - loss: 0.8227 - accuracy: 0.64 - ETA: 0s - loss: 0.8266 - accuracy: 0.64 - ETA: 0s - loss: 0.8332 - accuracy: 0.63 - ETA: 0s - loss: 0.8353 - accuracy: 0.6366\n",
      "Epoch 00870: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8353 - accuracy: 0.6366 - val_loss: 1.0702 - val_accuracy: 0.4906 - lr: 0.0010\n",
      "Epoch 871/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8795 - accuracy: 0.58 - ETA: 0s - loss: 0.8471 - accuracy: 0.61 - ETA: 0s - loss: 0.8593 - accuracy: 0.61 - ETA: 0s - loss: 0.8333 - accuracy: 0.63 - ETA: 0s - loss: 0.8350 - accuracy: 0.63 - ETA: 0s - loss: 0.8296 - accuracy: 0.64 - ETA: 0s - loss: 0.8275 - accuracy: 0.64 - ETA: 0s - loss: 0.8297 - accuracy: 0.64 - ETA: 0s - loss: 0.8336 - accuracy: 0.64 - ETA: 0s - loss: 0.8418 - accuracy: 0.62 - ETA: 0s - loss: 0.8362 - accuracy: 0.63 - ETA: 0s - loss: 0.8300 - accuracy: 0.64 - ETA: 0s - loss: 0.8111 - accuracy: 0.65 - ETA: 0s - loss: 0.8162 - accuracy: 0.65 - ETA: 0s - loss: 0.8250 - accuracy: 0.64 - ETA: 0s - loss: 0.8281 - accuracy: 0.63 - ETA: 0s - loss: 0.8342 - accuracy: 0.63 - ETA: 0s - loss: 0.8371 - accuracy: 0.63 - ETA: 0s - loss: 0.8384 - accuracy: 0.6332\n",
      "Epoch 00871: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8384 - accuracy: 0.6332 - val_loss: 1.0768 - val_accuracy: 0.4852 - lr: 0.0010\n",
      "Epoch 872/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8783 - accuracy: 0.57 - ETA: 0s - loss: 0.8400 - accuracy: 0.61 - ETA: 0s - loss: 0.8621 - accuracy: 0.60 - ETA: 0s - loss: 0.8360 - accuracy: 0.62 - ETA: 0s - loss: 0.8403 - accuracy: 0.62 - ETA: 0s - loss: 0.8347 - accuracy: 0.63 - ETA: 0s - loss: 0.8303 - accuracy: 0.63 - ETA: 0s - loss: 0.8332 - accuracy: 0.63 - ETA: 0s - loss: 0.8365 - accuracy: 0.63 - ETA: 0s - loss: 0.8416 - accuracy: 0.62 - ETA: 0s - loss: 0.8362 - accuracy: 0.63 - ETA: 0s - loss: 0.8291 - accuracy: 0.64 - ETA: 0s - loss: 0.8110 - accuracy: 0.65 - ETA: 0s - loss: 0.8152 - accuracy: 0.65 - ETA: 0s - loss: 0.8240 - accuracy: 0.64 - ETA: 0s - loss: 0.8279 - accuracy: 0.64 - ETA: 0s - loss: 0.8352 - accuracy: 0.63 - ETA: 0s - loss: 0.8373 - accuracy: 0.63 - ETA: 0s - loss: 0.8391 - accuracy: 0.6351\n",
      "Epoch 00872: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8391 - accuracy: 0.6351 - val_loss: 1.0715 - val_accuracy: 0.4870 - lr: 0.0010\n",
      "Epoch 873/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8646 - accuracy: 0.58 - ETA: 0s - loss: 0.8413 - accuracy: 0.62 - ETA: 0s - loss: 0.8537 - accuracy: 0.61 - ETA: 0s - loss: 0.8287 - accuracy: 0.63 - ETA: 0s - loss: 0.8362 - accuracy: 0.62 - ETA: 0s - loss: 0.8317 - accuracy: 0.63 - ETA: 0s - loss: 0.8314 - accuracy: 0.63 - ETA: 0s - loss: 0.8292 - accuracy: 0.63 - ETA: 0s - loss: 0.8312 - accuracy: 0.63 - ETA: 0s - loss: 0.8374 - accuracy: 0.63 - ETA: 0s - loss: 0.8331 - accuracy: 0.63 - ETA: 0s - loss: 0.8255 - accuracy: 0.64 - ETA: 0s - loss: 0.8077 - accuracy: 0.65 - ETA: 0s - loss: 0.8123 - accuracy: 0.65 - ETA: 0s - loss: 0.8208 - accuracy: 0.64 - ETA: 0s - loss: 0.8247 - accuracy: 0.64 - ETA: 0s - loss: 0.8306 - accuracy: 0.63 - ETA: 0s - loss: 0.8345 - accuracy: 0.63 - ETA: 0s - loss: 0.8359 - accuracy: 0.6360\n",
      "Epoch 00873: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8359 - accuracy: 0.6360 - val_loss: 1.0517 - val_accuracy: 0.4935 - lr: 0.0010\n",
      "Epoch 874/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8787 - accuracy: 0.56 - ETA: 0s - loss: 0.8441 - accuracy: 0.61 - ETA: 0s - loss: 0.8636 - accuracy: 0.61 - ETA: 0s - loss: 0.8370 - accuracy: 0.63 - ETA: 0s - loss: 0.8372 - accuracy: 0.63 - ETA: 0s - loss: 0.8333 - accuracy: 0.64 - ETA: 0s - loss: 0.8286 - accuracy: 0.64 - ETA: 0s - loss: 0.8256 - accuracy: 0.64 - ETA: 0s - loss: 0.8292 - accuracy: 0.64 - ETA: 0s - loss: 0.8362 - accuracy: 0.63 - ETA: 0s - loss: 0.8320 - accuracy: 0.64 - ETA: 0s - loss: 0.8247 - accuracy: 0.64 - ETA: 0s - loss: 0.8063 - accuracy: 0.66 - ETA: 0s - loss: 0.8121 - accuracy: 0.65 - ETA: 0s - loss: 0.8215 - accuracy: 0.64 - ETA: 0s - loss: 0.8259 - accuracy: 0.64 - ETA: 0s - loss: 0.8326 - accuracy: 0.64 - ETA: 0s - loss: 0.8348 - accuracy: 0.64 - ETA: 0s - loss: 0.8367 - accuracy: 0.6385\n",
      "Epoch 00874: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8367 - accuracy: 0.6385 - val_loss: 1.0841 - val_accuracy: 0.4837 - lr: 0.0010\n",
      "Epoch 875/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9072 - accuracy: 0.56 - ETA: 0s - loss: 0.8544 - accuracy: 0.60 - ETA: 0s - loss: 0.8589 - accuracy: 0.61 - ETA: 0s - loss: 0.8323 - accuracy: 0.63 - ETA: 0s - loss: 0.8367 - accuracy: 0.63 - ETA: 0s - loss: 0.8330 - accuracy: 0.63 - ETA: 0s - loss: 0.8325 - accuracy: 0.64 - ETA: 0s - loss: 0.8305 - accuracy: 0.64 - ETA: 0s - loss: 0.8321 - accuracy: 0.64 - ETA: 0s - loss: 0.8370 - accuracy: 0.63 - ETA: 0s - loss: 0.8322 - accuracy: 0.64 - ETA: 0s - loss: 0.8259 - accuracy: 0.64 - ETA: 0s - loss: 0.8076 - accuracy: 0.65 - ETA: 0s - loss: 0.8120 - accuracy: 0.65 - ETA: 0s - loss: 0.8209 - accuracy: 0.64 - ETA: 0s - loss: 0.8258 - accuracy: 0.64 - ETA: 0s - loss: 0.8330 - accuracy: 0.63 - ETA: 0s - loss: 0.8348 - accuracy: 0.63 - ETA: 0s - loss: 0.8370 - accuracy: 0.6347\n",
      "Epoch 00875: val_loss did not improve from 0.99131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8370 - accuracy: 0.6347 - val_loss: 1.0791 - val_accuracy: 0.4769 - lr: 0.0010\n",
      "Epoch 876/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8861 - accuracy: 0.58 - ETA: 0s - loss: 0.8543 - accuracy: 0.61 - ETA: 0s - loss: 0.8577 - accuracy: 0.61 - ETA: 0s - loss: 0.8343 - accuracy: 0.63 - ETA: 0s - loss: 0.8394 - accuracy: 0.62 - ETA: 0s - loss: 0.8344 - accuracy: 0.63 - ETA: 0s - loss: 0.8330 - accuracy: 0.64 - ETA: 0s - loss: 0.8309 - accuracy: 0.64 - ETA: 0s - loss: 0.8331 - accuracy: 0.63 - ETA: 0s - loss: 0.8378 - accuracy: 0.63 - ETA: 0s - loss: 0.8334 - accuracy: 0.64 - ETA: 0s - loss: 0.8272 - accuracy: 0.64 - ETA: 0s - loss: 0.8089 - accuracy: 0.65 - ETA: 0s - loss: 0.8149 - accuracy: 0.65 - ETA: 0s - loss: 0.8245 - accuracy: 0.64 - ETA: 0s - loss: 0.8284 - accuracy: 0.64 - ETA: 0s - loss: 0.8349 - accuracy: 0.63 - ETA: 0s - loss: 0.8375 - accuracy: 0.63 - ETA: 0s - loss: 0.8388 - accuracy: 0.6347\n",
      "Epoch 00876: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8388 - accuracy: 0.6347 - val_loss: 1.0687 - val_accuracy: 0.4822 - lr: 0.0010\n",
      "Epoch 877/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8972 - accuracy: 0.57 - ETA: 0s - loss: 0.8492 - accuracy: 0.61 - ETA: 0s - loss: 0.8583 - accuracy: 0.61 - ETA: 0s - loss: 0.8316 - accuracy: 0.63 - ETA: 0s - loss: 0.8353 - accuracy: 0.63 - ETA: 0s - loss: 0.8307 - accuracy: 0.63 - ETA: 0s - loss: 0.8291 - accuracy: 0.64 - ETA: 0s - loss: 0.8282 - accuracy: 0.64 - ETA: 0s - loss: 0.8305 - accuracy: 0.64 - ETA: 0s - loss: 0.8355 - accuracy: 0.63 - ETA: 0s - loss: 0.8316 - accuracy: 0.64 - ETA: 0s - loss: 0.8242 - accuracy: 0.64 - ETA: 0s - loss: 0.8055 - accuracy: 0.65 - ETA: 0s - loss: 0.8097 - accuracy: 0.65 - ETA: 0s - loss: 0.8218 - accuracy: 0.64 - ETA: 0s - loss: 0.8247 - accuracy: 0.64 - ETA: 0s - loss: 0.8308 - accuracy: 0.63 - ETA: 0s - loss: 0.8330 - accuracy: 0.63 - ETA: 0s - loss: 0.8345 - accuracy: 0.6370\n",
      "Epoch 00877: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8345 - accuracy: 0.6370 - val_loss: 1.0662 - val_accuracy: 0.4875 - lr: 0.0010\n",
      "Epoch 878/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8908 - accuracy: 0.57 - ETA: 0s - loss: 0.8468 - accuracy: 0.61 - ETA: 0s - loss: 0.8584 - accuracy: 0.60 - ETA: 0s - loss: 0.8313 - accuracy: 0.62 - ETA: 0s - loss: 0.8328 - accuracy: 0.62 - ETA: 0s - loss: 0.8278 - accuracy: 0.63 - ETA: 0s - loss: 0.8258 - accuracy: 0.63 - ETA: 0s - loss: 0.8242 - accuracy: 0.63 - ETA: 0s - loss: 0.8286 - accuracy: 0.63 - ETA: 0s - loss: 0.8338 - accuracy: 0.63 - ETA: 0s - loss: 0.8295 - accuracy: 0.63 - ETA: 0s - loss: 0.8236 - accuracy: 0.64 - ETA: 0s - loss: 0.8052 - accuracy: 0.65 - ETA: 0s - loss: 0.8101 - accuracy: 0.65 - ETA: 0s - loss: 0.8218 - accuracy: 0.64 - ETA: 0s - loss: 0.8248 - accuracy: 0.64 - ETA: 0s - loss: 0.8319 - accuracy: 0.63 - ETA: 0s - loss: 0.8345 - accuracy: 0.63 - ETA: 0s - loss: 0.8359 - accuracy: 0.6350\n",
      "Epoch 00878: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8359 - accuracy: 0.6350 - val_loss: 1.0829 - val_accuracy: 0.4834 - lr: 0.0010\n",
      "Epoch 879/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8989 - accuracy: 0.58 - ETA: 0s - loss: 0.8571 - accuracy: 0.61 - ETA: 0s - loss: 0.8680 - accuracy: 0.61 - ETA: 0s - loss: 0.8428 - accuracy: 0.63 - ETA: 0s - loss: 0.8435 - accuracy: 0.62 - ETA: 0s - loss: 0.8372 - accuracy: 0.63 - ETA: 0s - loss: 0.8342 - accuracy: 0.64 - ETA: 0s - loss: 0.8321 - accuracy: 0.64 - ETA: 0s - loss: 0.8334 - accuracy: 0.64 - ETA: 0s - loss: 0.8376 - accuracy: 0.63 - ETA: 0s - loss: 0.8338 - accuracy: 0.64 - ETA: 0s - loss: 0.8261 - accuracy: 0.64 - ETA: 0s - loss: 0.8077 - accuracy: 0.66 - ETA: 0s - loss: 0.8153 - accuracy: 0.65 - ETA: 0s - loss: 0.8240 - accuracy: 0.64 - ETA: 0s - loss: 0.8279 - accuracy: 0.64 - ETA: 0s - loss: 0.8340 - accuracy: 0.63 - ETA: 0s - loss: 0.8361 - accuracy: 0.63 - ETA: 0s - loss: 0.8383 - accuracy: 0.6366\n",
      "Epoch 00879: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00879: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8383 - accuracy: 0.6366 - val_loss: 1.0685 - val_accuracy: 0.4845 - lr: 0.0010\n",
      "Epoch 880/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9031 - accuracy: 0.56 - ETA: 0s - loss: 0.8488 - accuracy: 0.61 - ETA: 0s - loss: 0.8618 - accuracy: 0.61 - ETA: 0s - loss: 0.8367 - accuracy: 0.62 - ETA: 0s - loss: 0.8400 - accuracy: 0.63 - ETA: 0s - loss: 0.8345 - accuracy: 0.63 - ETA: 0s - loss: 0.8313 - accuracy: 0.64 - ETA: 0s - loss: 0.8302 - accuracy: 0.64 - ETA: 0s - loss: 0.8342 - accuracy: 0.64 - ETA: 0s - loss: 0.8402 - accuracy: 0.63 - ETA: 0s - loss: 0.8363 - accuracy: 0.64 - ETA: 0s - loss: 0.8288 - accuracy: 0.64 - ETA: 0s - loss: 0.8106 - accuracy: 0.65 - ETA: 0s - loss: 0.8156 - accuracy: 0.65 - ETA: 0s - loss: 0.8249 - accuracy: 0.64 - ETA: 0s - loss: 0.8278 - accuracy: 0.64 - ETA: 0s - loss: 0.8340 - accuracy: 0.63 - ETA: 0s - loss: 0.8358 - accuracy: 0.63 - ETA: 0s - loss: 0.8376 - accuracy: 0.6382\n",
      "Epoch 00880: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8376 - accuracy: 0.6382 - val_loss: 1.0703 - val_accuracy: 0.4842 - lr: 0.0010\n",
      "Epoch 881/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9015 - accuracy: 0.55 - ETA: 0s - loss: 0.8567 - accuracy: 0.60 - ETA: 0s - loss: 0.8677 - accuracy: 0.60 - ETA: 0s - loss: 0.8393 - accuracy: 0.62 - ETA: 0s - loss: 0.8408 - accuracy: 0.62 - ETA: 0s - loss: 0.8349 - accuracy: 0.63 - ETA: 0s - loss: 0.8344 - accuracy: 0.63 - ETA: 0s - loss: 0.8305 - accuracy: 0.64 - ETA: 0s - loss: 0.8352 - accuracy: 0.63 - ETA: 0s - loss: 0.8415 - accuracy: 0.63 - ETA: 0s - loss: 0.8373 - accuracy: 0.63 - ETA: 0s - loss: 0.8300 - accuracy: 0.64 - ETA: 0s - loss: 0.8114 - accuracy: 0.65 - ETA: 0s - loss: 0.8146 - accuracy: 0.65 - ETA: 0s - loss: 0.8248 - accuracy: 0.64 - ETA: 0s - loss: 0.8279 - accuracy: 0.64 - ETA: 0s - loss: 0.8347 - accuracy: 0.63 - ETA: 0s - loss: 0.8370 - accuracy: 0.63 - ETA: 0s - loss: 0.8377 - accuracy: 0.6373\n",
      "Epoch 00881: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8377 - accuracy: 0.6373 - val_loss: 1.0636 - val_accuracy: 0.4902 - lr: 0.0010\n",
      "Epoch 882/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8754 - accuracy: 0.58 - ETA: 0s - loss: 0.8525 - accuracy: 0.61 - ETA: 0s - loss: 0.8667 - accuracy: 0.61 - ETA: 0s - loss: 0.8399 - accuracy: 0.63 - ETA: 0s - loss: 0.8464 - accuracy: 0.63 - ETA: 0s - loss: 0.8384 - accuracy: 0.63 - ETA: 0s - loss: 0.8354 - accuracy: 0.64 - ETA: 0s - loss: 0.8311 - accuracy: 0.64 - ETA: 0s - loss: 0.8320 - accuracy: 0.64 - ETA: 0s - loss: 0.8380 - accuracy: 0.63 - ETA: 0s - loss: 0.8334 - accuracy: 0.64 - ETA: 0s - loss: 0.8258 - accuracy: 0.64 - ETA: 0s - loss: 0.8078 - accuracy: 0.66 - ETA: 0s - loss: 0.8122 - accuracy: 0.65 - ETA: 0s - loss: 0.8228 - accuracy: 0.64 - ETA: 0s - loss: 0.8260 - accuracy: 0.64 - ETA: 0s - loss: 0.8321 - accuracy: 0.63 - ETA: 0s - loss: 0.8345 - accuracy: 0.63 - ETA: 0s - loss: 0.8360 - accuracy: 0.6374\n",
      "Epoch 00882: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8360 - accuracy: 0.6374 - val_loss: 1.0704 - val_accuracy: 0.4790 - lr: 0.0010\n",
      "Epoch 883/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.8786 - accuracy: 0.59 - ETA: 0s - loss: 0.8513 - accuracy: 0.62 - ETA: 0s - loss: 0.8659 - accuracy: 0.61 - ETA: 0s - loss: 0.8394 - accuracy: 0.63 - ETA: 0s - loss: 0.8409 - accuracy: 0.63 - ETA: 0s - loss: 0.8347 - accuracy: 0.63 - ETA: 0s - loss: 0.8312 - accuracy: 0.64 - ETA: 0s - loss: 0.8294 - accuracy: 0.64 - ETA: 0s - loss: 0.8322 - accuracy: 0.64 - ETA: 0s - loss: 0.8374 - accuracy: 0.63 - ETA: 0s - loss: 0.8342 - accuracy: 0.64 - ETA: 0s - loss: 0.8266 - accuracy: 0.64 - ETA: 0s - loss: 0.8084 - accuracy: 0.66 - ETA: 0s - loss: 0.8130 - accuracy: 0.65 - ETA: 0s - loss: 0.8206 - accuracy: 0.64 - ETA: 0s - loss: 0.8244 - accuracy: 0.64 - ETA: 0s - loss: 0.8302 - accuracy: 0.64 - ETA: 0s - loss: 0.8332 - accuracy: 0.64 - ETA: 0s - loss: 0.8349 - accuracy: 0.6416\n",
      "Epoch 00883: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8349 - accuracy: 0.6416 - val_loss: 1.0579 - val_accuracy: 0.4896 - lr: 0.0010\n",
      "Epoch 884/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8678 - accuracy: 0.60 - ETA: 0s - loss: 0.8386 - accuracy: 0.62 - ETA: 0s - loss: 0.8636 - accuracy: 0.61 - ETA: 0s - loss: 0.8347 - accuracy: 0.63 - ETA: 0s - loss: 0.8369 - accuracy: 0.63 - ETA: 0s - loss: 0.8314 - accuracy: 0.64 - ETA: 0s - loss: 0.8290 - accuracy: 0.64 - ETA: 0s - loss: 0.8271 - accuracy: 0.64 - ETA: 0s - loss: 0.8305 - accuracy: 0.64 - ETA: 0s - loss: 0.8352 - accuracy: 0.63 - ETA: 0s - loss: 0.8321 - accuracy: 0.64 - ETA: 0s - loss: 0.8260 - accuracy: 0.64 - ETA: 0s - loss: 0.8077 - accuracy: 0.66 - ETA: 0s - loss: 0.8113 - accuracy: 0.65 - ETA: 0s - loss: 0.8202 - accuracy: 0.65 - ETA: 0s - loss: 0.8237 - accuracy: 0.64 - ETA: 0s - loss: 0.8310 - accuracy: 0.64 - ETA: 0s - loss: 0.8340 - accuracy: 0.64 - ETA: 0s - loss: 0.8356 - accuracy: 0.6388\n",
      "Epoch 00884: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8356 - accuracy: 0.6388 - val_loss: 1.0633 - val_accuracy: 0.4844 - lr: 0.0010\n",
      "Epoch 885/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8842 - accuracy: 0.56 - ETA: 0s - loss: 0.8473 - accuracy: 0.60 - ETA: 0s - loss: 0.8617 - accuracy: 0.60 - ETA: 0s - loss: 0.8349 - accuracy: 0.62 - ETA: 0s - loss: 0.8390 - accuracy: 0.62 - ETA: 0s - loss: 0.8322 - accuracy: 0.63 - ETA: 0s - loss: 0.8296 - accuracy: 0.63 - ETA: 0s - loss: 0.8293 - accuracy: 0.64 - ETA: 0s - loss: 0.8312 - accuracy: 0.64 - ETA: 0s - loss: 0.8386 - accuracy: 0.63 - ETA: 0s - loss: 0.8352 - accuracy: 0.64 - ETA: 0s - loss: 0.8278 - accuracy: 0.64 - ETA: 0s - loss: 0.8087 - accuracy: 0.66 - ETA: 0s - loss: 0.8147 - accuracy: 0.65 - ETA: 0s - loss: 0.8245 - accuracy: 0.64 - ETA: 0s - loss: 0.8277 - accuracy: 0.64 - ETA: 0s - loss: 0.8342 - accuracy: 0.63 - ETA: 0s - loss: 0.8356 - accuracy: 0.63 - ETA: 0s - loss: 0.8357 - accuracy: 0.6378\n",
      "Epoch 00885: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8357 - accuracy: 0.6378 - val_loss: 1.0631 - val_accuracy: 0.4844 - lr: 0.0010\n",
      "Epoch 886/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8813 - accuracy: 0.58 - ETA: 0s - loss: 0.8410 - accuracy: 0.61 - ETA: 0s - loss: 0.8579 - accuracy: 0.61 - ETA: 0s - loss: 0.8342 - accuracy: 0.63 - ETA: 0s - loss: 0.8361 - accuracy: 0.63 - ETA: 0s - loss: 0.8313 - accuracy: 0.64 - ETA: 0s - loss: 0.8300 - accuracy: 0.64 - ETA: 0s - loss: 0.8308 - accuracy: 0.64 - ETA: 0s - loss: 0.8328 - accuracy: 0.64 - ETA: 0s - loss: 0.8386 - accuracy: 0.63 - ETA: 0s - loss: 0.8346 - accuracy: 0.64 - ETA: 0s - loss: 0.8275 - accuracy: 0.64 - ETA: 0s - loss: 0.8086 - accuracy: 0.65 - ETA: 0s - loss: 0.8125 - accuracy: 0.65 - ETA: 0s - loss: 0.8254 - accuracy: 0.64 - ETA: 0s - loss: 0.8323 - accuracy: 0.63 - ETA: 0s - loss: 0.8357 - accuracy: 0.63 - ETA: 0s - loss: 0.8368 - accuracy: 0.6385\n",
      "Epoch 00886: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8368 - accuracy: 0.6385 - val_loss: 1.0614 - val_accuracy: 0.4910 - lr: 0.0010\n",
      "Epoch 887/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8874 - accuracy: 0.58 - ETA: 0s - loss: 0.8414 - accuracy: 0.62 - ETA: 0s - loss: 0.8520 - accuracy: 0.62 - ETA: 0s - loss: 0.8277 - accuracy: 0.63 - ETA: 0s - loss: 0.8342 - accuracy: 0.63 - ETA: 0s - loss: 0.8298 - accuracy: 0.64 - ETA: 0s - loss: 0.8285 - accuracy: 0.64 - ETA: 0s - loss: 0.8280 - accuracy: 0.64 - ETA: 0s - loss: 0.8323 - accuracy: 0.64 - ETA: 0s - loss: 0.8387 - accuracy: 0.63 - ETA: 0s - loss: 0.8343 - accuracy: 0.64 - ETA: 0s - loss: 0.8283 - accuracy: 0.64 - ETA: 0s - loss: 0.8097 - accuracy: 0.66 - ETA: 0s - loss: 0.8133 - accuracy: 0.65 - ETA: 0s - loss: 0.8224 - accuracy: 0.64 - ETA: 0s - loss: 0.8256 - accuracy: 0.64 - ETA: 0s - loss: 0.8323 - accuracy: 0.64 - ETA: 0s - loss: 0.8349 - accuracy: 0.63 - ETA: 0s - loss: 0.8362 - accuracy: 0.6392\n",
      "Epoch 00887: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8362 - accuracy: 0.6392 - val_loss: 1.0699 - val_accuracy: 0.4998 - lr: 0.0010\n",
      "Epoch 888/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8799 - accuracy: 0.56 - ETA: 0s - loss: 0.8490 - accuracy: 0.60 - ETA: 0s - loss: 0.8562 - accuracy: 0.60 - ETA: 0s - loss: 0.8292 - accuracy: 0.62 - ETA: 0s - loss: 0.8349 - accuracy: 0.62 - ETA: 0s - loss: 0.8294 - accuracy: 0.63 - ETA: 0s - loss: 0.8286 - accuracy: 0.64 - ETA: 0s - loss: 0.8319 - accuracy: 0.64 - ETA: 0s - loss: 0.8341 - accuracy: 0.63 - ETA: 0s - loss: 0.8379 - accuracy: 0.63 - ETA: 0s - loss: 0.8341 - accuracy: 0.64 - ETA: 0s - loss: 0.8282 - accuracy: 0.64 - ETA: 0s - loss: 0.8095 - accuracy: 0.65 - ETA: 0s - loss: 0.8138 - accuracy: 0.65 - ETA: 0s - loss: 0.8216 - accuracy: 0.64 - ETA: 0s - loss: 0.8264 - accuracy: 0.64 - ETA: 0s - loss: 0.8334 - accuracy: 0.63 - ETA: 0s - loss: 0.8364 - accuracy: 0.63 - ETA: 0s - loss: 0.8380 - accuracy: 0.6344\n",
      "Epoch 00888: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8380 - accuracy: 0.6344 - val_loss: 1.0653 - val_accuracy: 0.4884 - lr: 0.0010\n",
      "Epoch 889/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8813 - accuracy: 0.59 - ETA: 0s - loss: 0.8489 - accuracy: 0.61 - ETA: 0s - loss: 0.8613 - accuracy: 0.61 - ETA: 0s - loss: 0.8331 - accuracy: 0.63 - ETA: 0s - loss: 0.8339 - accuracy: 0.63 - ETA: 0s - loss: 0.8285 - accuracy: 0.64 - ETA: 0s - loss: 0.8271 - accuracy: 0.64 - ETA: 0s - loss: 0.8298 - accuracy: 0.64 - ETA: 0s - loss: 0.8315 - accuracy: 0.64 - ETA: 0s - loss: 0.8384 - accuracy: 0.63 - ETA: 0s - loss: 0.8341 - accuracy: 0.64 - ETA: 0s - loss: 0.8264 - accuracy: 0.65 - ETA: 0s - loss: 0.8085 - accuracy: 0.66 - ETA: 0s - loss: 0.8130 - accuracy: 0.65 - ETA: 0s - loss: 0.8223 - accuracy: 0.65 - ETA: 0s - loss: 0.8260 - accuracy: 0.64 - ETA: 0s - loss: 0.8322 - accuracy: 0.64 - ETA: 0s - loss: 0.8342 - accuracy: 0.64 - ETA: 0s - loss: 0.8362 - accuracy: 0.6425\n",
      "Epoch 00889: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8362 - accuracy: 0.6425 - val_loss: 1.0681 - val_accuracy: 0.4958 - lr: 0.0010\n",
      "Epoch 890/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8726 - accuracy: 0.58 - ETA: 0s - loss: 0.8344 - accuracy: 0.61 - ETA: 0s - loss: 0.8432 - accuracy: 0.61 - ETA: 0s - loss: 0.8212 - accuracy: 0.63 - ETA: 0s - loss: 0.8260 - accuracy: 0.63 - ETA: 0s - loss: 0.8219 - accuracy: 0.63 - ETA: 0s - loss: 0.8226 - accuracy: 0.64 - ETA: 0s - loss: 0.8197 - accuracy: 0.64 - ETA: 0s - loss: 0.8216 - accuracy: 0.64 - ETA: 0s - loss: 0.8288 - accuracy: 0.63 - ETA: 0s - loss: 0.8257 - accuracy: 0.64 - ETA: 0s - loss: 0.8199 - accuracy: 0.64 - ETA: 0s - loss: 0.8020 - accuracy: 0.66 - ETA: 0s - loss: 0.8080 - accuracy: 0.65 - ETA: 0s - loss: 0.8178 - accuracy: 0.64 - ETA: 0s - loss: 0.8284 - accuracy: 0.63 - ETA: 0s - loss: 0.8300 - accuracy: 0.63 - ETA: 0s - loss: 0.8324 - accuracy: 0.6388\n",
      "Epoch 00890: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8324 - accuracy: 0.6388 - val_loss: 1.0645 - val_accuracy: 0.4940 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 891/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8967 - accuracy: 0.57 - ETA: 0s - loss: 0.8490 - accuracy: 0.61 - ETA: 0s - loss: 0.8531 - accuracy: 0.61 - ETA: 0s - loss: 0.8279 - accuracy: 0.63 - ETA: 0s - loss: 0.8310 - accuracy: 0.63 - ETA: 0s - loss: 0.8256 - accuracy: 0.64 - ETA: 0s - loss: 0.8247 - accuracy: 0.64 - ETA: 0s - loss: 0.8234 - accuracy: 0.64 - ETA: 0s - loss: 0.8300 - accuracy: 0.64 - ETA: 0s - loss: 0.8349 - accuracy: 0.64 - ETA: 0s - loss: 0.8306 - accuracy: 0.64 - ETA: 0s - loss: 0.8244 - accuracy: 0.65 - ETA: 0s - loss: 0.8057 - accuracy: 0.66 - ETA: 0s - loss: 0.8104 - accuracy: 0.66 - ETA: 0s - loss: 0.8202 - accuracy: 0.65 - ETA: 0s - loss: 0.8236 - accuracy: 0.64 - ETA: 0s - loss: 0.8308 - accuracy: 0.64 - ETA: 0s - loss: 0.8344 - accuracy: 0.64 - ETA: 0s - loss: 0.8362 - accuracy: 0.6406\n",
      "Epoch 00891: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8362 - accuracy: 0.6406 - val_loss: 1.0654 - val_accuracy: 0.4906 - lr: 0.0010\n",
      "Epoch 892/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8788 - accuracy: 0.58 - ETA: 0s - loss: 0.8488 - accuracy: 0.61 - ETA: 0s - loss: 0.8567 - accuracy: 0.61 - ETA: 0s - loss: 0.8302 - accuracy: 0.62 - ETA: 0s - loss: 0.8348 - accuracy: 0.62 - ETA: 0s - loss: 0.8313 - accuracy: 0.63 - ETA: 0s - loss: 0.8296 - accuracy: 0.63 - ETA: 0s - loss: 0.8280 - accuracy: 0.64 - ETA: 0s - loss: 0.8302 - accuracy: 0.63 - ETA: 0s - loss: 0.8354 - accuracy: 0.63 - ETA: 0s - loss: 0.8317 - accuracy: 0.63 - ETA: 0s - loss: 0.8256 - accuracy: 0.64 - ETA: 0s - loss: 0.8062 - accuracy: 0.65 - ETA: 0s - loss: 0.8111 - accuracy: 0.65 - ETA: 0s - loss: 0.8213 - accuracy: 0.64 - ETA: 0s - loss: 0.8250 - accuracy: 0.64 - ETA: 0s - loss: 0.8313 - accuracy: 0.63 - ETA: 0s - loss: 0.8341 - accuracy: 0.63 - ETA: 0s - loss: 0.8355 - accuracy: 0.6365\n",
      "Epoch 00892: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8355 - accuracy: 0.6365 - val_loss: 1.0601 - val_accuracy: 0.4897 - lr: 0.0010\n",
      "Epoch 893/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8954 - accuracy: 0.57 - ETA: 0s - loss: 0.8520 - accuracy: 0.61 - ETA: 0s - loss: 0.8380 - accuracy: 0.63 - ETA: 0s - loss: 0.8424 - accuracy: 0.63 - ETA: 0s - loss: 0.8356 - accuracy: 0.64 - ETA: 0s - loss: 0.8335 - accuracy: 0.64 - ETA: 0s - loss: 0.8309 - accuracy: 0.64 - ETA: 0s - loss: 0.8326 - accuracy: 0.64 - ETA: 0s - loss: 0.8369 - accuracy: 0.63 - ETA: 0s - loss: 0.8328 - accuracy: 0.64 - ETA: 0s - loss: 0.8265 - accuracy: 0.65 - ETA: 0s - loss: 0.8082 - accuracy: 0.66 - ETA: 0s - loss: 0.8121 - accuracy: 0.65 - ETA: 0s - loss: 0.8204 - accuracy: 0.64 - ETA: 0s - loss: 0.8238 - accuracy: 0.64 - ETA: 0s - loss: 0.8315 - accuracy: 0.64 - ETA: 0s - loss: 0.8345 - accuracy: 0.64 - ETA: 0s - loss: 0.8357 - accuracy: 0.6398\n",
      "Epoch 00893: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00893: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8357 - accuracy: 0.6398 - val_loss: 1.0643 - val_accuracy: 0.4868 - lr: 0.0010\n",
      "Epoch 894/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8807 - accuracy: 0.57 - ETA: 0s - loss: 0.8409 - accuracy: 0.61 - ETA: 0s - loss: 0.8558 - accuracy: 0.61 - ETA: 0s - loss: 0.8268 - accuracy: 0.63 - ETA: 0s - loss: 0.8329 - accuracy: 0.63 - ETA: 0s - loss: 0.8289 - accuracy: 0.64 - ETA: 0s - loss: 0.8250 - accuracy: 0.64 - ETA: 0s - loss: 0.8250 - accuracy: 0.64 - ETA: 0s - loss: 0.8271 - accuracy: 0.64 - ETA: 0s - loss: 0.8328 - accuracy: 0.63 - ETA: 0s - loss: 0.8290 - accuracy: 0.64 - ETA: 0s - loss: 0.8234 - accuracy: 0.65 - ETA: 0s - loss: 0.8042 - accuracy: 0.66 - ETA: 0s - loss: 0.8073 - accuracy: 0.66 - ETA: 0s - loss: 0.8174 - accuracy: 0.64 - ETA: 0s - loss: 0.8208 - accuracy: 0.64 - ETA: 0s - loss: 0.8273 - accuracy: 0.64 - ETA: 0s - loss: 0.8298 - accuracy: 0.64 - ETA: 0s - loss: 0.8327 - accuracy: 0.6397\n",
      "Epoch 00894: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8327 - accuracy: 0.6397 - val_loss: 1.0587 - val_accuracy: 0.4892 - lr: 0.0010\n",
      "Epoch 895/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8791 - accuracy: 0.57 - ETA: 0s - loss: 0.8389 - accuracy: 0.62 - ETA: 0s - loss: 0.8473 - accuracy: 0.62 - ETA: 0s - loss: 0.8224 - accuracy: 0.63 - ETA: 0s - loss: 0.8248 - accuracy: 0.63 - ETA: 0s - loss: 0.8195 - accuracy: 0.64 - ETA: 0s - loss: 0.8166 - accuracy: 0.64 - ETA: 0s - loss: 0.8165 - accuracy: 0.65 - ETA: 0s - loss: 0.8217 - accuracy: 0.64 - ETA: 0s - loss: 0.8282 - accuracy: 0.64 - ETA: 0s - loss: 0.8243 - accuracy: 0.64 - ETA: 0s - loss: 0.8182 - accuracy: 0.65 - ETA: 0s - loss: 0.8008 - accuracy: 0.66 - ETA: 0s - loss: 0.8049 - accuracy: 0.66 - ETA: 0s - loss: 0.8137 - accuracy: 0.65 - ETA: 0s - loss: 0.8185 - accuracy: 0.65 - ETA: 0s - loss: 0.8247 - accuracy: 0.64 - ETA: 0s - loss: 0.8277 - accuracy: 0.64 - ETA: 0s - loss: 0.8293 - accuracy: 0.6435\n",
      "Epoch 00895: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8293 - accuracy: 0.6435 - val_loss: 1.0552 - val_accuracy: 0.4959 - lr: 0.0010\n",
      "Epoch 896/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8584 - accuracy: 0.58 - ETA: 0s - loss: 0.8275 - accuracy: 0.61 - ETA: 0s - loss: 0.8448 - accuracy: 0.61 - ETA: 0s - loss: 0.8230 - accuracy: 0.63 - ETA: 0s - loss: 0.8315 - accuracy: 0.63 - ETA: 0s - loss: 0.8256 - accuracy: 0.64 - ETA: 0s - loss: 0.8226 - accuracy: 0.64 - ETA: 0s - loss: 0.8224 - accuracy: 0.64 - ETA: 0s - loss: 0.8257 - accuracy: 0.64 - ETA: 0s - loss: 0.8313 - accuracy: 0.63 - ETA: 0s - loss: 0.8285 - accuracy: 0.64 - ETA: 0s - loss: 0.8221 - accuracy: 0.64 - ETA: 0s - loss: 0.8035 - accuracy: 0.66 - ETA: 0s - loss: 0.8067 - accuracy: 0.65 - ETA: 0s - loss: 0.8172 - accuracy: 0.64 - ETA: 0s - loss: 0.8282 - accuracy: 0.64 - ETA: 0s - loss: 0.8310 - accuracy: 0.64 - ETA: 0s - loss: 0.8332 - accuracy: 0.6384\n",
      "Epoch 00896: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8332 - accuracy: 0.6384 - val_loss: 1.0611 - val_accuracy: 0.4868 - lr: 0.0010\n",
      "Epoch 897/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8760 - accuracy: 0.58 - ETA: 0s - loss: 0.8405 - accuracy: 0.62 - ETA: 0s - loss: 0.8525 - accuracy: 0.61 - ETA: 0s - loss: 0.8285 - accuracy: 0.63 - ETA: 0s - loss: 0.8313 - accuracy: 0.63 - ETA: 0s - loss: 0.8281 - accuracy: 0.64 - ETA: 0s - loss: 0.8237 - accuracy: 0.64 - ETA: 0s - loss: 0.8224 - accuracy: 0.64 - ETA: 0s - loss: 0.8256 - accuracy: 0.64 - ETA: 0s - loss: 0.8309 - accuracy: 0.63 - ETA: 0s - loss: 0.8281 - accuracy: 0.64 - ETA: 0s - loss: 0.8215 - accuracy: 0.64 - ETA: 0s - loss: 0.8039 - accuracy: 0.66 - ETA: 0s - loss: 0.8090 - accuracy: 0.65 - ETA: 0s - loss: 0.8176 - accuracy: 0.64 - ETA: 0s - loss: 0.8210 - accuracy: 0.64 - ETA: 0s - loss: 0.8284 - accuracy: 0.64 - ETA: 0s - loss: 0.8334 - accuracy: 0.6391\n",
      "Epoch 00897: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8334 - accuracy: 0.6391 - val_loss: 1.0654 - val_accuracy: 0.4953 - lr: 0.0010\n",
      "Epoch 898/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8917 - accuracy: 0.59 - ETA: 0s - loss: 0.8487 - accuracy: 0.62 - ETA: 0s - loss: 0.8576 - accuracy: 0.62 - ETA: 0s - loss: 0.8307 - accuracy: 0.63 - ETA: 0s - loss: 0.8325 - accuracy: 0.64 - ETA: 0s - loss: 0.8293 - accuracy: 0.64 - ETA: 0s - loss: 0.8283 - accuracy: 0.64 - ETA: 0s - loss: 0.8267 - accuracy: 0.65 - ETA: 0s - loss: 0.8296 - accuracy: 0.64 - ETA: 0s - loss: 0.8346 - accuracy: 0.63 - ETA: 0s - loss: 0.8322 - accuracy: 0.64 - ETA: 0s - loss: 0.8248 - accuracy: 0.65 - ETA: 0s - loss: 0.8073 - accuracy: 0.66 - ETA: 0s - loss: 0.8119 - accuracy: 0.65 - ETA: 0s - loss: 0.8184 - accuracy: 0.65 - ETA: 0s - loss: 0.8221 - accuracy: 0.64 - ETA: 0s - loss: 0.8303 - accuracy: 0.64 - ETA: 0s - loss: 0.8329 - accuracy: 0.64 - ETA: 0s - loss: 0.8343 - accuracy: 0.6398\n",
      "Epoch 00898: val_loss did not improve from 0.99131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8343 - accuracy: 0.6398 - val_loss: 1.0620 - val_accuracy: 0.4964 - lr: 0.0010\n",
      "Epoch 899/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8688 - accuracy: 0.59 - ETA: 0s - loss: 0.8412 - accuracy: 0.62 - ETA: 0s - loss: 0.8500 - accuracy: 0.62 - ETA: 0s - loss: 0.8254 - accuracy: 0.63 - ETA: 0s - loss: 0.8256 - accuracy: 0.63 - ETA: 0s - loss: 0.8235 - accuracy: 0.64 - ETA: 0s - loss: 0.8227 - accuracy: 0.64 - ETA: 0s - loss: 0.8222 - accuracy: 0.64 - ETA: 0s - loss: 0.8249 - accuracy: 0.64 - ETA: 0s - loss: 0.8300 - accuracy: 0.63 - ETA: 0s - loss: 0.8258 - accuracy: 0.64 - ETA: 0s - loss: 0.8203 - accuracy: 0.65 - ETA: 0s - loss: 0.8026 - accuracy: 0.66 - ETA: 0s - loss: 0.8078 - accuracy: 0.65 - ETA: 0s - loss: 0.8169 - accuracy: 0.64 - ETA: 0s - loss: 0.8209 - accuracy: 0.64 - ETA: 0s - loss: 0.8270 - accuracy: 0.64 - ETA: 0s - loss: 0.8297 - accuracy: 0.64 - ETA: 0s - loss: 0.8312 - accuracy: 0.6412\n",
      "Epoch 00899: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8312 - accuracy: 0.6412 - val_loss: 1.0685 - val_accuracy: 0.4953 - lr: 0.0010\n",
      "Epoch 900/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8738 - accuracy: 0.58 - ETA: 0s - loss: 0.8390 - accuracy: 0.61 - ETA: 0s - loss: 0.8539 - accuracy: 0.61 - ETA: 0s - loss: 0.8256 - accuracy: 0.63 - ETA: 0s - loss: 0.8297 - accuracy: 0.63 - ETA: 0s - loss: 0.8240 - accuracy: 0.64 - ETA: 0s - loss: 0.8221 - accuracy: 0.64 - ETA: 0s - loss: 0.8214 - accuracy: 0.64 - ETA: 0s - loss: 0.8251 - accuracy: 0.64 - ETA: 0s - loss: 0.8305 - accuracy: 0.63 - ETA: 0s - loss: 0.8270 - accuracy: 0.64 - ETA: 0s - loss: 0.8215 - accuracy: 0.65 - ETA: 0s - loss: 0.8032 - accuracy: 0.66 - ETA: 0s - loss: 0.8076 - accuracy: 0.66 - ETA: 0s - loss: 0.8157 - accuracy: 0.65 - ETA: 0s - loss: 0.8188 - accuracy: 0.64 - ETA: 0s - loss: 0.8252 - accuracy: 0.64 - ETA: 0s - loss: 0.8273 - accuracy: 0.64 - ETA: 0s - loss: 0.8299 - accuracy: 0.6426\n",
      "Epoch 00900: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8299 - accuracy: 0.6426 - val_loss: 1.0629 - val_accuracy: 0.5005 - lr: 0.0010\n",
      "Epoch 901/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8630 - accuracy: 0.59 - ETA: 0s - loss: 0.8437 - accuracy: 0.62 - ETA: 0s - loss: 0.8562 - accuracy: 0.62 - ETA: 0s - loss: 0.8289 - accuracy: 0.63 - ETA: 0s - loss: 0.8275 - accuracy: 0.63 - ETA: 0s - loss: 0.8237 - accuracy: 0.64 - ETA: 0s - loss: 0.8237 - accuracy: 0.64 - ETA: 0s - loss: 0.8218 - accuracy: 0.64 - ETA: 0s - loss: 0.8249 - accuracy: 0.64 - ETA: 0s - loss: 0.8324 - accuracy: 0.63 - ETA: 0s - loss: 0.8285 - accuracy: 0.64 - ETA: 0s - loss: 0.8212 - accuracy: 0.65 - ETA: 0s - loss: 0.8031 - accuracy: 0.66 - ETA: 0s - loss: 0.8082 - accuracy: 0.65 - ETA: 0s - loss: 0.8158 - accuracy: 0.65 - ETA: 0s - loss: 0.8193 - accuracy: 0.64 - ETA: 0s - loss: 0.8253 - accuracy: 0.64 - ETA: 0s - loss: 0.8289 - accuracy: 0.64 - ETA: 0s - loss: 0.8301 - accuracy: 0.6425\n",
      "Epoch 00901: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8301 - accuracy: 0.6425 - val_loss: 1.0673 - val_accuracy: 0.4969 - lr: 0.0010\n",
      "Epoch 902/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8684 - accuracy: 0.58 - ETA: 0s - loss: 0.8343 - accuracy: 0.62 - ETA: 0s - loss: 0.8454 - accuracy: 0.61 - ETA: 0s - loss: 0.8222 - accuracy: 0.63 - ETA: 0s - loss: 0.8256 - accuracy: 0.63 - ETA: 0s - loss: 0.8221 - accuracy: 0.64 - ETA: 0s - loss: 0.8195 - accuracy: 0.64 - ETA: 0s - loss: 0.8227 - accuracy: 0.64 - ETA: 0s - loss: 0.8303 - accuracy: 0.63 - ETA: 0s - loss: 0.8276 - accuracy: 0.64 - ETA: 0s - loss: 0.8210 - accuracy: 0.64 - ETA: 0s - loss: 0.8033 - accuracy: 0.66 - ETA: 0s - loss: 0.8089 - accuracy: 0.65 - ETA: 0s - loss: 0.8178 - accuracy: 0.64 - ETA: 0s - loss: 0.8208 - accuracy: 0.64 - ETA: 0s - loss: 0.8274 - accuracy: 0.64 - ETA: 0s - loss: 0.8309 - accuracy: 0.63 - ETA: 0s - loss: 0.8338 - accuracy: 0.6395\n",
      "Epoch 00902: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8338 - accuracy: 0.6395 - val_loss: 1.0590 - val_accuracy: 0.4995 - lr: 0.0010\n",
      "Epoch 903/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8786 - accuracy: 0.58 - ETA: 0s - loss: 0.8420 - accuracy: 0.62 - ETA: 0s - loss: 0.8533 - accuracy: 0.62 - ETA: 0s - loss: 0.8260 - accuracy: 0.63 - ETA: 0s - loss: 0.8312 - accuracy: 0.63 - ETA: 0s - loss: 0.8262 - accuracy: 0.64 - ETA: 0s - loss: 0.8235 - accuracy: 0.64 - ETA: 0s - loss: 0.8215 - accuracy: 0.64 - ETA: 0s - loss: 0.8236 - accuracy: 0.64 - ETA: 0s - loss: 0.8311 - accuracy: 0.63 - ETA: 0s - loss: 0.8286 - accuracy: 0.64 - ETA: 0s - loss: 0.8217 - accuracy: 0.64 - ETA: 0s - loss: 0.8040 - accuracy: 0.66 - ETA: 0s - loss: 0.8082 - accuracy: 0.65 - ETA: 0s - loss: 0.8151 - accuracy: 0.65 - ETA: 0s - loss: 0.8181 - accuracy: 0.65 - ETA: 0s - loss: 0.8251 - accuracy: 0.64 - ETA: 0s - loss: 0.8277 - accuracy: 0.64 - ETA: 0s - loss: 0.8304 - accuracy: 0.6418\n",
      "Epoch 00903: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8304 - accuracy: 0.6418 - val_loss: 1.0659 - val_accuracy: 0.4940 - lr: 0.0010\n",
      "Epoch 904/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8690 - accuracy: 0.61 - ETA: 0s - loss: 0.8452 - accuracy: 0.62 - ETA: 0s - loss: 0.8598 - accuracy: 0.62 - ETA: 0s - loss: 0.8313 - accuracy: 0.63 - ETA: 0s - loss: 0.8343 - accuracy: 0.63 - ETA: 0s - loss: 0.8285 - accuracy: 0.64 - ETA: 0s - loss: 0.8235 - accuracy: 0.64 - ETA: 0s - loss: 0.8240 - accuracy: 0.65 - ETA: 0s - loss: 0.8283 - accuracy: 0.64 - ETA: 0s - loss: 0.8325 - accuracy: 0.64 - ETA: 0s - loss: 0.8289 - accuracy: 0.64 - ETA: 0s - loss: 0.8215 - accuracy: 0.65 - ETA: 0s - loss: 0.8036 - accuracy: 0.66 - ETA: 0s - loss: 0.8083 - accuracy: 0.66 - ETA: 0s - loss: 0.8164 - accuracy: 0.65 - ETA: 0s - loss: 0.8211 - accuracy: 0.65 - ETA: 0s - loss: 0.8275 - accuracy: 0.64 - ETA: 0s - loss: 0.8305 - accuracy: 0.64 - ETA: 0s - loss: 0.8322 - accuracy: 0.6439\n",
      "Epoch 00904: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8322 - accuracy: 0.6439 - val_loss: 1.0692 - val_accuracy: 0.4941 - lr: 0.0010\n",
      "Epoch 905/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8861 - accuracy: 0.58 - ETA: 0s - loss: 0.8472 - accuracy: 0.61 - ETA: 0s - loss: 0.8548 - accuracy: 0.61 - ETA: 0s - loss: 0.8288 - accuracy: 0.63 - ETA: 0s - loss: 0.8307 - accuracy: 0.63 - ETA: 0s - loss: 0.8275 - accuracy: 0.64 - ETA: 0s - loss: 0.8251 - accuracy: 0.64 - ETA: 0s - loss: 0.8221 - accuracy: 0.64 - ETA: 0s - loss: 0.8246 - accuracy: 0.64 - ETA: 0s - loss: 0.8289 - accuracy: 0.64 - ETA: 0s - loss: 0.8253 - accuracy: 0.64 - ETA: 0s - loss: 0.8193 - accuracy: 0.65 - ETA: 0s - loss: 0.8011 - accuracy: 0.66 - ETA: 0s - loss: 0.8086 - accuracy: 0.66 - ETA: 0s - loss: 0.8177 - accuracy: 0.65 - ETA: 0s - loss: 0.8209 - accuracy: 0.65 - ETA: 0s - loss: 0.8273 - accuracy: 0.64 - ETA: 0s - loss: 0.8303 - accuracy: 0.64 - ETA: 0s - loss: 0.8319 - accuracy: 0.6430\n",
      "Epoch 00905: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8319 - accuracy: 0.6430 - val_loss: 1.0574 - val_accuracy: 0.5020 - lr: 0.0010\n",
      "Epoch 906/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.8767 - accuracy: 0.58 - ETA: 0s - loss: 0.8387 - accuracy: 0.61 - ETA: 0s - loss: 0.8526 - accuracy: 0.61 - ETA: 0s - loss: 0.8259 - accuracy: 0.63 - ETA: 0s - loss: 0.8273 - accuracy: 0.63 - ETA: 0s - loss: 0.8244 - accuracy: 0.64 - ETA: 0s - loss: 0.8266 - accuracy: 0.64 - ETA: 0s - loss: 0.8248 - accuracy: 0.64 - ETA: 0s - loss: 0.8285 - accuracy: 0.64 - ETA: 0s - loss: 0.8331 - accuracy: 0.64 - ETA: 0s - loss: 0.8291 - accuracy: 0.64 - ETA: 0s - loss: 0.8226 - accuracy: 0.65 - ETA: 0s - loss: 0.8042 - accuracy: 0.66 - ETA: 0s - loss: 0.8068 - accuracy: 0.66 - ETA: 0s - loss: 0.8168 - accuracy: 0.65 - ETA: 0s - loss: 0.8216 - accuracy: 0.64 - ETA: 0s - loss: 0.8321 - accuracy: 0.64 - ETA: 0s - loss: 0.8335 - accuracy: 0.6395\n",
      "Epoch 00906: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8335 - accuracy: 0.6395 - val_loss: 1.0543 - val_accuracy: 0.4963 - lr: 0.0010\n",
      "Epoch 907/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8611 - accuracy: 0.59 - ETA: 0s - loss: 0.8309 - accuracy: 0.62 - ETA: 0s - loss: 0.8448 - accuracy: 0.61 - ETA: 0s - loss: 0.8189 - accuracy: 0.63 - ETA: 0s - loss: 0.8236 - accuracy: 0.63 - ETA: 0s - loss: 0.8209 - accuracy: 0.64 - ETA: 0s - loss: 0.8204 - accuracy: 0.64 - ETA: 0s - loss: 0.8190 - accuracy: 0.64 - ETA: 0s - loss: 0.8221 - accuracy: 0.64 - ETA: 0s - loss: 0.8289 - accuracy: 0.63 - ETA: 0s - loss: 0.8248 - accuracy: 0.64 - ETA: 0s - loss: 0.8191 - accuracy: 0.65 - ETA: 0s - loss: 0.8011 - accuracy: 0.66 - ETA: 0s - loss: 0.8057 - accuracy: 0.65 - ETA: 0s - loss: 0.8157 - accuracy: 0.64 - ETA: 0s - loss: 0.8197 - accuracy: 0.64 - ETA: 0s - loss: 0.8266 - accuracy: 0.64 - ETA: 0s - loss: 0.8289 - accuracy: 0.64 - ETA: 0s - loss: 0.8308 - accuracy: 0.6405\n",
      "Epoch 00907: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00907: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8308 - accuracy: 0.6405 - val_loss: 1.0577 - val_accuracy: 0.4990 - lr: 0.0010\n",
      "Epoch 908/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8852 - accuracy: 0.56 - ETA: 0s - loss: 0.8444 - accuracy: 0.60 - ETA: 0s - loss: 0.8536 - accuracy: 0.60 - ETA: 0s - loss: 0.8278 - accuracy: 0.62 - ETA: 0s - loss: 0.8300 - accuracy: 0.63 - ETA: 0s - loss: 0.8256 - accuracy: 0.63 - ETA: 0s - loss: 0.8214 - accuracy: 0.64 - ETA: 0s - loss: 0.8212 - accuracy: 0.64 - ETA: 0s - loss: 0.8241 - accuracy: 0.64 - ETA: 0s - loss: 0.8290 - accuracy: 0.63 - ETA: 0s - loss: 0.8245 - accuracy: 0.64 - ETA: 0s - loss: 0.8176 - accuracy: 0.65 - ETA: 0s - loss: 0.8001 - accuracy: 0.66 - ETA: 0s - loss: 0.8059 - accuracy: 0.65 - ETA: 0s - loss: 0.8153 - accuracy: 0.65 - ETA: 0s - loss: 0.8187 - accuracy: 0.64 - ETA: 0s - loss: 0.8261 - accuracy: 0.64 - ETA: 0s - loss: 0.8290 - accuracy: 0.64 - ETA: 0s - loss: 0.8303 - accuracy: 0.6406\n",
      "Epoch 00908: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8303 - accuracy: 0.6406 - val_loss: 1.0755 - val_accuracy: 0.4964 - lr: 0.0010\n",
      "Epoch 909/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8981 - accuracy: 0.58 - ETA: 0s - loss: 0.8485 - accuracy: 0.61 - ETA: 0s - loss: 0.8497 - accuracy: 0.62 - ETA: 0s - loss: 0.8232 - accuracy: 0.63 - ETA: 0s - loss: 0.8262 - accuracy: 0.63 - ETA: 0s - loss: 0.8196 - accuracy: 0.64 - ETA: 0s - loss: 0.8161 - accuracy: 0.64 - ETA: 0s - loss: 0.8141 - accuracy: 0.65 - ETA: 0s - loss: 0.8165 - accuracy: 0.64 - ETA: 0s - loss: 0.8232 - accuracy: 0.64 - ETA: 0s - loss: 0.8204 - accuracy: 0.64 - ETA: 0s - loss: 0.8153 - accuracy: 0.65 - ETA: 0s - loss: 0.7984 - accuracy: 0.66 - ETA: 0s - loss: 0.8045 - accuracy: 0.66 - ETA: 0s - loss: 0.8147 - accuracy: 0.65 - ETA: 0s - loss: 0.8177 - accuracy: 0.64 - ETA: 0s - loss: 0.8241 - accuracy: 0.64 - ETA: 0s - loss: 0.8268 - accuracy: 0.64 - ETA: 0s - loss: 0.8281 - accuracy: 0.6428\n",
      "Epoch 00909: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8281 - accuracy: 0.6428 - val_loss: 1.0717 - val_accuracy: 0.4995 - lr: 0.0010\n",
      "Epoch 910/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8587 - accuracy: 0.59 - ETA: 0s - loss: 0.8298 - accuracy: 0.62 - ETA: 0s - loss: 0.8466 - accuracy: 0.62 - ETA: 0s - loss: 0.8218 - accuracy: 0.63 - ETA: 0s - loss: 0.8275 - accuracy: 0.63 - ETA: 0s - loss: 0.8225 - accuracy: 0.64 - ETA: 0s - loss: 0.8190 - accuracy: 0.65 - ETA: 0s - loss: 0.8188 - accuracy: 0.65 - ETA: 0s - loss: 0.8240 - accuracy: 0.64 - ETA: 0s - loss: 0.8302 - accuracy: 0.64 - ETA: 0s - loss: 0.8268 - accuracy: 0.64 - ETA: 0s - loss: 0.8196 - accuracy: 0.65 - ETA: 0s - loss: 0.8014 - accuracy: 0.66 - ETA: 0s - loss: 0.8064 - accuracy: 0.66 - ETA: 0s - loss: 0.8158 - accuracy: 0.65 - ETA: 0s - loss: 0.8199 - accuracy: 0.65 - ETA: 0s - loss: 0.8267 - accuracy: 0.64 - ETA: 0s - loss: 0.8288 - accuracy: 0.64 - ETA: 0s - loss: 0.8309 - accuracy: 0.6432\n",
      "Epoch 00910: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8309 - accuracy: 0.6432 - val_loss: 1.0754 - val_accuracy: 0.4969 - lr: 0.0010\n",
      "Epoch 911/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8641 - accuracy: 0.59 - ETA: 0s - loss: 0.8322 - accuracy: 0.62 - ETA: 0s - loss: 0.8468 - accuracy: 0.62 - ETA: 0s - loss: 0.8206 - accuracy: 0.63 - ETA: 0s - loss: 0.8263 - accuracy: 0.63 - ETA: 0s - loss: 0.8239 - accuracy: 0.64 - ETA: 0s - loss: 0.8222 - accuracy: 0.64 - ETA: 0s - loss: 0.8214 - accuracy: 0.64 - ETA: 0s - loss: 0.8242 - accuracy: 0.64 - ETA: 0s - loss: 0.8299 - accuracy: 0.64 - ETA: 0s - loss: 0.8259 - accuracy: 0.64 - ETA: 0s - loss: 0.8199 - accuracy: 0.65 - ETA: 0s - loss: 0.8020 - accuracy: 0.66 - ETA: 0s - loss: 0.8057 - accuracy: 0.66 - ETA: 0s - loss: 0.8147 - accuracy: 0.65 - ETA: 0s - loss: 0.8191 - accuracy: 0.64 - ETA: 0s - loss: 0.8247 - accuracy: 0.64 - ETA: 0s - loss: 0.8278 - accuracy: 0.64 - ETA: 0s - loss: 0.8292 - accuracy: 0.6419\n",
      "Epoch 00911: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8292 - accuracy: 0.6419 - val_loss: 1.0600 - val_accuracy: 0.4987 - lr: 0.0010\n",
      "Epoch 912/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8646 - accuracy: 0.60 - ETA: 0s - loss: 0.8382 - accuracy: 0.62 - ETA: 0s - loss: 0.8557 - accuracy: 0.62 - ETA: 0s - loss: 0.8301 - accuracy: 0.63 - ETA: 0s - loss: 0.8323 - accuracy: 0.63 - ETA: 0s - loss: 0.8282 - accuracy: 0.64 - ETA: 0s - loss: 0.8275 - accuracy: 0.64 - ETA: 0s - loss: 0.8253 - accuracy: 0.64 - ETA: 0s - loss: 0.8282 - accuracy: 0.64 - ETA: 0s - loss: 0.8324 - accuracy: 0.64 - ETA: 0s - loss: 0.8298 - accuracy: 0.64 - ETA: 0s - loss: 0.8227 - accuracy: 0.65 - ETA: 0s - loss: 0.8046 - accuracy: 0.66 - ETA: 0s - loss: 0.8111 - accuracy: 0.66 - ETA: 0s - loss: 0.8186 - accuracy: 0.65 - ETA: 0s - loss: 0.8221 - accuracy: 0.64 - ETA: 0s - loss: 0.8293 - accuracy: 0.64 - ETA: 0s - loss: 0.8318 - accuracy: 0.64 - ETA: 0s - loss: 0.8332 - accuracy: 0.6433\n",
      "Epoch 00912: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8332 - accuracy: 0.6433 - val_loss: 1.0599 - val_accuracy: 0.4985 - lr: 0.0010\n",
      "Epoch 913/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.8706 - accuracy: 0.59 - ETA: 0s - loss: 0.8427 - accuracy: 0.62 - ETA: 0s - loss: 0.8536 - accuracy: 0.61 - ETA: 0s - loss: 0.8283 - accuracy: 0.62 - ETA: 0s - loss: 0.8319 - accuracy: 0.62 - ETA: 0s - loss: 0.8268 - accuracy: 0.63 - ETA: 0s - loss: 0.8275 - accuracy: 0.63 - ETA: 0s - loss: 0.8249 - accuracy: 0.64 - ETA: 0s - loss: 0.8279 - accuracy: 0.63 - ETA: 0s - loss: 0.8325 - accuracy: 0.63 - ETA: 0s - loss: 0.8282 - accuracy: 0.64 - ETA: 0s - loss: 0.8200 - accuracy: 0.64 - ETA: 0s - loss: 0.8020 - accuracy: 0.66 - ETA: 0s - loss: 0.8077 - accuracy: 0.65 - ETA: 0s - loss: 0.8156 - accuracy: 0.64 - ETA: 0s - loss: 0.8190 - accuracy: 0.64 - ETA: 0s - loss: 0.8258 - accuracy: 0.64 - ETA: 0s - loss: 0.8288 - accuracy: 0.63 - ETA: 0s - loss: 0.8307 - accuracy: 0.6383\n",
      "Epoch 00913: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8307 - accuracy: 0.6383 - val_loss: 1.0554 - val_accuracy: 0.5026 - lr: 0.0010\n",
      "Epoch 914/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8648 - accuracy: 0.56 - ETA: 0s - loss: 0.8352 - accuracy: 0.60 - ETA: 0s - loss: 0.8513 - accuracy: 0.60 - ETA: 0s - loss: 0.8279 - accuracy: 0.62 - ETA: 0s - loss: 0.8302 - accuracy: 0.62 - ETA: 0s - loss: 0.8259 - accuracy: 0.63 - ETA: 0s - loss: 0.8223 - accuracy: 0.63 - ETA: 0s - loss: 0.8207 - accuracy: 0.64 - ETA: 0s - loss: 0.8257 - accuracy: 0.64 - ETA: 0s - loss: 0.8296 - accuracy: 0.63 - ETA: 0s - loss: 0.8254 - accuracy: 0.64 - ETA: 0s - loss: 0.8185 - accuracy: 0.64 - ETA: 0s - loss: 0.8008 - accuracy: 0.66 - ETA: 0s - loss: 0.8064 - accuracy: 0.65 - ETA: 0s - loss: 0.8177 - accuracy: 0.64 - ETA: 0s - loss: 0.8212 - accuracy: 0.64 - ETA: 0s - loss: 0.8269 - accuracy: 0.64 - ETA: 0s - loss: 0.8300 - accuracy: 0.63 - ETA: 0s - loss: 0.8322 - accuracy: 0.6391\n",
      "Epoch 00914: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8322 - accuracy: 0.6391 - val_loss: 1.0678 - val_accuracy: 0.4940 - lr: 0.0010\n",
      "Epoch 915/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8723 - accuracy: 0.59 - ETA: 0s - loss: 0.8315 - accuracy: 0.62 - ETA: 0s - loss: 0.8356 - accuracy: 0.63 - ETA: 0s - loss: 0.8175 - accuracy: 0.64 - ETA: 0s - loss: 0.8249 - accuracy: 0.63 - ETA: 0s - loss: 0.8210 - accuracy: 0.64 - ETA: 0s - loss: 0.8192 - accuracy: 0.64 - ETA: 0s - loss: 0.8172 - accuracy: 0.65 - ETA: 0s - loss: 0.8198 - accuracy: 0.64 - ETA: 0s - loss: 0.8238 - accuracy: 0.64 - ETA: 0s - loss: 0.8202 - accuracy: 0.64 - ETA: 0s - loss: 0.8134 - accuracy: 0.65 - ETA: 0s - loss: 0.7953 - accuracy: 0.66 - ETA: 0s - loss: 0.8004 - accuracy: 0.66 - ETA: 0s - loss: 0.8101 - accuracy: 0.65 - ETA: 0s - loss: 0.8141 - accuracy: 0.64 - ETA: 0s - loss: 0.8231 - accuracy: 0.64 - ETA: 0s - loss: 0.8251 - accuracy: 0.64 - ETA: 0s - loss: 0.8272 - accuracy: 0.6422\n",
      "Epoch 00915: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8272 - accuracy: 0.6422 - val_loss: 1.0803 - val_accuracy: 0.4889 - lr: 0.0010\n",
      "Epoch 916/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8804 - accuracy: 0.57 - ETA: 0s - loss: 0.8449 - accuracy: 0.61 - ETA: 0s - loss: 0.8516 - accuracy: 0.61 - ETA: 0s - loss: 0.8253 - accuracy: 0.63 - ETA: 0s - loss: 0.8270 - accuracy: 0.63 - ETA: 0s - loss: 0.8245 - accuracy: 0.64 - ETA: 0s - loss: 0.8210 - accuracy: 0.64 - ETA: 0s - loss: 0.8229 - accuracy: 0.64 - ETA: 0s - loss: 0.8253 - accuracy: 0.64 - ETA: 0s - loss: 0.8325 - accuracy: 0.63 - ETA: 0s - loss: 0.8287 - accuracy: 0.64 - ETA: 0s - loss: 0.8231 - accuracy: 0.64 - ETA: 0s - loss: 0.8047 - accuracy: 0.65 - ETA: 0s - loss: 0.8080 - accuracy: 0.65 - ETA: 0s - loss: 0.8174 - accuracy: 0.64 - ETA: 0s - loss: 0.8204 - accuracy: 0.64 - ETA: 0s - loss: 0.8268 - accuracy: 0.64 - ETA: 0s - loss: 0.8290 - accuracy: 0.64 - ETA: 0s - loss: 0.8301 - accuracy: 0.6393\n",
      "Epoch 00916: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8301 - accuracy: 0.6393 - val_loss: 1.0919 - val_accuracy: 0.4862 - lr: 0.0010\n",
      "Epoch 917/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8737 - accuracy: 0.56 - ETA: 0s - loss: 0.8379 - accuracy: 0.61 - ETA: 0s - loss: 0.8493 - accuracy: 0.62 - ETA: 0s - loss: 0.8289 - accuracy: 0.63 - ETA: 0s - loss: 0.8314 - accuracy: 0.62 - ETA: 0s - loss: 0.8251 - accuracy: 0.63 - ETA: 0s - loss: 0.8232 - accuracy: 0.64 - ETA: 0s - loss: 0.8228 - accuracy: 0.64 - ETA: 0s - loss: 0.8260 - accuracy: 0.64 - ETA: 0s - loss: 0.8300 - accuracy: 0.63 - ETA: 0s - loss: 0.8280 - accuracy: 0.64 - ETA: 0s - loss: 0.8216 - accuracy: 0.64 - ETA: 0s - loss: 0.8033 - accuracy: 0.65 - ETA: 0s - loss: 0.8085 - accuracy: 0.65 - ETA: 0s - loss: 0.8173 - accuracy: 0.64 - ETA: 0s - loss: 0.8212 - accuracy: 0.64 - ETA: 0s - loss: 0.8282 - accuracy: 0.63 - ETA: 0s - loss: 0.8302 - accuracy: 0.63 - ETA: 0s - loss: 0.8318 - accuracy: 0.6378\n",
      "Epoch 00917: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8318 - accuracy: 0.6378 - val_loss: 1.1140 - val_accuracy: 0.4791 - lr: 0.0010\n",
      "Epoch 918/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.9026 - accuracy: 0.57 - ETA: 0s - loss: 0.8492 - accuracy: 0.62 - ETA: 0s - loss: 0.8526 - accuracy: 0.62 - ETA: 0s - loss: 0.8288 - accuracy: 0.63 - ETA: 0s - loss: 0.8327 - accuracy: 0.63 - ETA: 0s - loss: 0.8282 - accuracy: 0.64 - ETA: 0s - loss: 0.8256 - accuracy: 0.64 - ETA: 0s - loss: 0.8246 - accuracy: 0.64 - ETA: 0s - loss: 0.8283 - accuracy: 0.64 - ETA: 0s - loss: 0.8335 - accuracy: 0.63 - ETA: 0s - loss: 0.8300 - accuracy: 0.64 - ETA: 0s - loss: 0.8232 - accuracy: 0.64 - ETA: 0s - loss: 0.8048 - accuracy: 0.66 - ETA: 0s - loss: 0.8090 - accuracy: 0.65 - ETA: 0s - loss: 0.8204 - accuracy: 0.64 - ETA: 0s - loss: 0.8235 - accuracy: 0.64 - ETA: 0s - loss: 0.8298 - accuracy: 0.63 - ETA: 0s - loss: 0.8325 - accuracy: 0.6389\n",
      "Epoch 00918: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8338 - accuracy: 0.6378 - val_loss: 1.1074 - val_accuracy: 0.4831 - lr: 0.0010\n",
      "Epoch 919/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8763 - accuracy: 0.59 - ETA: 0s - loss: 0.8447 - accuracy: 0.62 - ETA: 0s - loss: 0.8523 - accuracy: 0.62 - ETA: 0s - loss: 0.8280 - accuracy: 0.63 - ETA: 0s - loss: 0.8348 - accuracy: 0.63 - ETA: 0s - loss: 0.8293 - accuracy: 0.64 - ETA: 0s - loss: 0.8276 - accuracy: 0.65 - ETA: 0s - loss: 0.8257 - accuracy: 0.65 - ETA: 0s - loss: 0.8289 - accuracy: 0.64 - ETA: 0s - loss: 0.8335 - accuracy: 0.64 - ETA: 0s - loss: 0.8300 - accuracy: 0.64 - ETA: 0s - loss: 0.8048 - accuracy: 0.66 - ETA: 0s - loss: 0.8103 - accuracy: 0.66 - ETA: 0s - loss: 0.8184 - accuracy: 0.65 - ETA: 0s - loss: 0.8219 - accuracy: 0.64 - ETA: 0s - loss: 0.8288 - accuracy: 0.64 - ETA: 0s - loss: 0.8310 - accuracy: 0.64 - ETA: 0s - loss: 0.8326 - accuracy: 0.6423\n",
      "Epoch 00919: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8326 - accuracy: 0.6423 - val_loss: 1.1241 - val_accuracy: 0.4775 - lr: 0.0010\n",
      "Epoch 920/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8797 - accuracy: 0.57 - ETA: 0s - loss: 0.8459 - accuracy: 0.61 - ETA: 0s - loss: 0.8250 - accuracy: 0.63 - ETA: 0s - loss: 0.8285 - accuracy: 0.63 - ETA: 0s - loss: 0.8250 - accuracy: 0.64 - ETA: 0s - loss: 0.8225 - accuracy: 0.64 - ETA: 0s - loss: 0.8270 - accuracy: 0.64 - ETA: 0s - loss: 0.8300 - accuracy: 0.64 - ETA: 0s - loss: 0.8328 - accuracy: 0.63 - ETA: 0s - loss: 0.8299 - accuracy: 0.64 - ETA: 0s - loss: 0.8237 - accuracy: 0.65 - ETA: 0s - loss: 0.8054 - accuracy: 0.66 - ETA: 0s - loss: 0.8098 - accuracy: 0.65 - ETA: 0s - loss: 0.8181 - accuracy: 0.65 - ETA: 0s - loss: 0.8209 - accuracy: 0.64 - ETA: 0s - loss: 0.8270 - accuracy: 0.64 - ETA: 0s - loss: 0.8291 - accuracy: 0.64 - ETA: 0s - loss: 0.8312 - accuracy: 0.6420\n",
      "Epoch 00920: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8312 - accuracy: 0.6420 - val_loss: 1.0870 - val_accuracy: 0.4879 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 921/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8727 - accuracy: 0.58 - ETA: 0s - loss: 0.8431 - accuracy: 0.61 - ETA: 0s - loss: 0.8499 - accuracy: 0.61 - ETA: 0s - loss: 0.8231 - accuracy: 0.63 - ETA: 0s - loss: 0.8248 - accuracy: 0.63 - ETA: 0s - loss: 0.8217 - accuracy: 0.64 - ETA: 0s - loss: 0.8225 - accuracy: 0.64 - ETA: 0s - loss: 0.8203 - accuracy: 0.64 - ETA: 0s - loss: 0.8246 - accuracy: 0.64 - ETA: 0s - loss: 0.8304 - accuracy: 0.63 - ETA: 0s - loss: 0.8266 - accuracy: 0.64 - ETA: 0s - loss: 0.8196 - accuracy: 0.65 - ETA: 0s - loss: 0.8014 - accuracy: 0.66 - ETA: 0s - loss: 0.8056 - accuracy: 0.65 - ETA: 0s - loss: 0.8120 - accuracy: 0.65 - ETA: 0s - loss: 0.8168 - accuracy: 0.64 - ETA: 0s - loss: 0.8243 - accuracy: 0.64 - ETA: 0s - loss: 0.8266 - accuracy: 0.64 - ETA: 0s - loss: 0.8278 - accuracy: 0.6414\n",
      "Epoch 00921: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00921: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8278 - accuracy: 0.6414 - val_loss: 1.0845 - val_accuracy: 0.4876 - lr: 0.0010\n",
      "Epoch 922/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8518 - accuracy: 0.59 - ETA: 0s - loss: 0.8252 - accuracy: 0.62 - ETA: 0s - loss: 0.8395 - accuracy: 0.62 - ETA: 0s - loss: 0.8204 - accuracy: 0.63 - ETA: 0s - loss: 0.8235 - accuracy: 0.64 - ETA: 0s - loss: 0.8214 - accuracy: 0.64 - ETA: 0s - loss: 0.8207 - accuracy: 0.64 - ETA: 0s - loss: 0.8176 - accuracy: 0.65 - ETA: 0s - loss: 0.8210 - accuracy: 0.64 - ETA: 0s - loss: 0.8282 - accuracy: 0.64 - ETA: 0s - loss: 0.8247 - accuracy: 0.64 - ETA: 0s - loss: 0.8187 - accuracy: 0.65 - ETA: 0s - loss: 0.7999 - accuracy: 0.66 - ETA: 0s - loss: 0.8036 - accuracy: 0.66 - ETA: 0s - loss: 0.8117 - accuracy: 0.65 - ETA: 0s - loss: 0.8163 - accuracy: 0.65 - ETA: 0s - loss: 0.8235 - accuracy: 0.64 - ETA: 0s - loss: 0.8254 - accuracy: 0.64 - ETA: 0s - loss: 0.8274 - accuracy: 0.6423\n",
      "Epoch 00922: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8274 - accuracy: 0.6423 - val_loss: 1.0789 - val_accuracy: 0.4915 - lr: 0.0010\n",
      "Epoch 923/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8599 - accuracy: 0.58 - ETA: 0s - loss: 0.8240 - accuracy: 0.63 - ETA: 0s - loss: 0.8391 - accuracy: 0.63 - ETA: 0s - loss: 0.8179 - accuracy: 0.64 - ETA: 0s - loss: 0.8229 - accuracy: 0.64 - ETA: 0s - loss: 0.8201 - accuracy: 0.64 - ETA: 0s - loss: 0.8171 - accuracy: 0.65 - ETA: 0s - loss: 0.8163 - accuracy: 0.65 - ETA: 0s - loss: 0.8222 - accuracy: 0.65 - ETA: 0s - loss: 0.8273 - accuracy: 0.64 - ETA: 0s - loss: 0.8238 - accuracy: 0.64 - ETA: 0s - loss: 0.8180 - accuracy: 0.65 - ETA: 0s - loss: 0.7995 - accuracy: 0.66 - ETA: 0s - loss: 0.8120 - accuracy: 0.65 - ETA: 0s - loss: 0.8173 - accuracy: 0.65 - ETA: 0s - loss: 0.8236 - accuracy: 0.64 - ETA: 0s - loss: 0.8265 - accuracy: 0.64 - ETA: 0s - loss: 0.8292 - accuracy: 0.6438\n",
      "Epoch 00923: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8292 - accuracy: 0.6438 - val_loss: 1.0842 - val_accuracy: 0.4876 - lr: 0.0010\n",
      "Epoch 924/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8735 - accuracy: 0.59 - ETA: 0s - loss: 0.8337 - accuracy: 0.62 - ETA: 0s - loss: 0.8533 - accuracy: 0.61 - ETA: 0s - loss: 0.8254 - accuracy: 0.63 - ETA: 0s - loss: 0.8284 - accuracy: 0.63 - ETA: 0s - loss: 0.8250 - accuracy: 0.64 - ETA: 0s - loss: 0.8234 - accuracy: 0.64 - ETA: 0s - loss: 0.8239 - accuracy: 0.64 - ETA: 0s - loss: 0.8273 - accuracy: 0.64 - ETA: 0s - loss: 0.8327 - accuracy: 0.63 - ETA: 0s - loss: 0.8294 - accuracy: 0.64 - ETA: 0s - loss: 0.8232 - accuracy: 0.64 - ETA: 0s - loss: 0.8047 - accuracy: 0.66 - ETA: 0s - loss: 0.8122 - accuracy: 0.65 - ETA: 0s - loss: 0.8213 - accuracy: 0.64 - ETA: 0s - loss: 0.8234 - accuracy: 0.64 - ETA: 0s - loss: 0.8294 - accuracy: 0.64 - ETA: 0s - loss: 0.8319 - accuracy: 0.64 - ETA: 0s - loss: 0.8327 - accuracy: 0.6405\n",
      "Epoch 00924: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8327 - accuracy: 0.6405 - val_loss: 1.0775 - val_accuracy: 0.4914 - lr: 0.0010\n",
      "Epoch 925/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8582 - accuracy: 0.59 - ETA: 0s - loss: 0.8378 - accuracy: 0.61 - ETA: 0s - loss: 0.8533 - accuracy: 0.61 - ETA: 0s - loss: 0.8257 - accuracy: 0.63 - ETA: 0s - loss: 0.8301 - accuracy: 0.62 - ETA: 0s - loss: 0.8258 - accuracy: 0.63 - ETA: 0s - loss: 0.8242 - accuracy: 0.63 - ETA: 0s - loss: 0.8202 - accuracy: 0.64 - ETA: 0s - loss: 0.8222 - accuracy: 0.64 - ETA: 0s - loss: 0.8287 - accuracy: 0.63 - ETA: 0s - loss: 0.8257 - accuracy: 0.64 - ETA: 0s - loss: 0.8185 - accuracy: 0.64 - ETA: 0s - loss: 0.8005 - accuracy: 0.66 - ETA: 0s - loss: 0.8056 - accuracy: 0.65 - ETA: 0s - loss: 0.8138 - accuracy: 0.65 - ETA: 0s - loss: 0.8175 - accuracy: 0.64 - ETA: 0s - loss: 0.8244 - accuracy: 0.64 - ETA: 0s - loss: 0.8272 - accuracy: 0.64 - ETA: 0s - loss: 0.8292 - accuracy: 0.6397\n",
      "Epoch 00925: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8292 - accuracy: 0.6397 - val_loss: 1.0765 - val_accuracy: 0.4875 - lr: 0.0010\n",
      "Epoch 926/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8522 - accuracy: 0.61 - ETA: 0s - loss: 0.8237 - accuracy: 0.63 - ETA: 0s - loss: 0.8404 - accuracy: 0.62 - ETA: 0s - loss: 0.8167 - accuracy: 0.64 - ETA: 0s - loss: 0.8223 - accuracy: 0.64 - ETA: 0s - loss: 0.8194 - accuracy: 0.65 - ETA: 0s - loss: 0.8191 - accuracy: 0.65 - ETA: 0s - loss: 0.8149 - accuracy: 0.65 - ETA: 0s - loss: 0.8195 - accuracy: 0.65 - ETA: 0s - loss: 0.8245 - accuracy: 0.64 - ETA: 0s - loss: 0.8205 - accuracy: 0.65 - ETA: 0s - loss: 0.8149 - accuracy: 0.65 - ETA: 0s - loss: 0.7964 - accuracy: 0.66 - ETA: 0s - loss: 0.8004 - accuracy: 0.66 - ETA: 0s - loss: 0.8090 - accuracy: 0.65 - ETA: 0s - loss: 0.8135 - accuracy: 0.65 - ETA: 0s - loss: 0.8212 - accuracy: 0.64 - ETA: 0s - loss: 0.8264 - accuracy: 0.6436\n",
      "Epoch 00926: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8264 - accuracy: 0.6436 - val_loss: 1.0656 - val_accuracy: 0.4971 - lr: 0.0010\n",
      "Epoch 927/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8763 - accuracy: 0.58 - ETA: 0s - loss: 0.8505 - accuracy: 0.61 - ETA: 0s - loss: 0.8645 - accuracy: 0.61 - ETA: 0s - loss: 0.8345 - accuracy: 0.63 - ETA: 0s - loss: 0.8338 - accuracy: 0.63 - ETA: 0s - loss: 0.8287 - accuracy: 0.64 - ETA: 0s - loss: 0.8255 - accuracy: 0.64 - ETA: 0s - loss: 0.8229 - accuracy: 0.64 - ETA: 0s - loss: 0.8251 - accuracy: 0.64 - ETA: 0s - loss: 0.8304 - accuracy: 0.64 - ETA: 0s - loss: 0.8270 - accuracy: 0.64 - ETA: 0s - loss: 0.8198 - accuracy: 0.65 - ETA: 0s - loss: 0.8018 - accuracy: 0.66 - ETA: 0s - loss: 0.8166 - accuracy: 0.65 - ETA: 0s - loss: 0.8204 - accuracy: 0.64 - ETA: 0s - loss: 0.8267 - accuracy: 0.64 - ETA: 0s - loss: 0.8283 - accuracy: 0.64 - ETA: 0s - loss: 0.8296 - accuracy: 0.6404\n",
      "Epoch 00927: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8296 - accuracy: 0.6404 - val_loss: 1.0847 - val_accuracy: 0.4897 - lr: 0.0010\n",
      "Epoch 928/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8511 - accuracy: 0.60 - ETA: 0s - loss: 0.8279 - accuracy: 0.62 - ETA: 0s - loss: 0.8462 - accuracy: 0.62 - ETA: 0s - loss: 0.8224 - accuracy: 0.63 - ETA: 0s - loss: 0.8264 - accuracy: 0.63 - ETA: 0s - loss: 0.8226 - accuracy: 0.64 - ETA: 0s - loss: 0.8220 - accuracy: 0.64 - ETA: 0s - loss: 0.8195 - accuracy: 0.64 - ETA: 0s - loss: 0.8218 - accuracy: 0.64 - ETA: 0s - loss: 0.8284 - accuracy: 0.63 - ETA: 0s - loss: 0.8253 - accuracy: 0.64 - ETA: 0s - loss: 0.8198 - accuracy: 0.65 - ETA: 0s - loss: 0.8010 - accuracy: 0.66 - ETA: 0s - loss: 0.8145 - accuracy: 0.65 - ETA: 0s - loss: 0.8181 - accuracy: 0.64 - ETA: 0s - loss: 0.8241 - accuracy: 0.64 - ETA: 0s - loss: 0.8264 - accuracy: 0.64 - ETA: 0s - loss: 0.8288 - accuracy: 0.6424\n",
      "Epoch 00928: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8288 - accuracy: 0.6424 - val_loss: 1.0863 - val_accuracy: 0.4884 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 929/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.8690 - accuracy: 0.59 - ETA: 0s - loss: 0.8332 - accuracy: 0.62 - ETA: 0s - loss: 0.8442 - accuracy: 0.61 - ETA: 0s - loss: 0.8220 - accuracy: 0.63 - ETA: 0s - loss: 0.8255 - accuracy: 0.63 - ETA: 0s - loss: 0.8206 - accuracy: 0.63 - ETA: 0s - loss: 0.8167 - accuracy: 0.64 - ETA: 0s - loss: 0.8155 - accuracy: 0.64 - ETA: 0s - loss: 0.8199 - accuracy: 0.64 - ETA: 0s - loss: 0.8263 - accuracy: 0.63 - ETA: 0s - loss: 0.8228 - accuracy: 0.64 - ETA: 0s - loss: 0.8162 - accuracy: 0.64 - ETA: 0s - loss: 0.7977 - accuracy: 0.66 - ETA: 0s - loss: 0.8029 - accuracy: 0.65 - ETA: 0s - loss: 0.8108 - accuracy: 0.64 - ETA: 0s - loss: 0.8148 - accuracy: 0.64 - ETA: 0s - loss: 0.8214 - accuracy: 0.64 - ETA: 0s - loss: 0.8243 - accuracy: 0.6404\n",
      "Epoch 00929: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8273 - accuracy: 0.6388 - val_loss: 1.0835 - val_accuracy: 0.4902 - lr: 0.0010\n",
      "Epoch 930/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8821 - accuracy: 0.59 - ETA: 0s - loss: 0.8443 - accuracy: 0.62 - ETA: 0s - loss: 0.8570 - accuracy: 0.61 - ETA: 0s - loss: 0.8328 - accuracy: 0.63 - ETA: 0s - loss: 0.8357 - accuracy: 0.63 - ETA: 0s - loss: 0.8300 - accuracy: 0.63 - ETA: 0s - loss: 0.8281 - accuracy: 0.64 - ETA: 0s - loss: 0.8241 - accuracy: 0.64 - ETA: 0s - loss: 0.8271 - accuracy: 0.64 - ETA: 0s - loss: 0.8325 - accuracy: 0.63 - ETA: 0s - loss: 0.8275 - accuracy: 0.64 - ETA: 0s - loss: 0.8206 - accuracy: 0.65 - ETA: 0s - loss: 0.8025 - accuracy: 0.66 - ETA: 0s - loss: 0.8089 - accuracy: 0.65 - ETA: 0s - loss: 0.8164 - accuracy: 0.65 - ETA: 0s - loss: 0.8200 - accuracy: 0.64 - ETA: 0s - loss: 0.8271 - accuracy: 0.64 - ETA: 0s - loss: 0.8294 - accuracy: 0.64 - ETA: 0s - loss: 0.8321 - accuracy: 0.6408\n",
      "Epoch 00930: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8321 - accuracy: 0.6408 - val_loss: 1.0783 - val_accuracy: 0.4878 - lr: 0.0010\n",
      "Epoch 931/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8653 - accuracy: 0.56 - ETA: 0s - loss: 0.8356 - accuracy: 0.60 - ETA: 0s - loss: 0.8463 - accuracy: 0.61 - ETA: 0s - loss: 0.8230 - accuracy: 0.62 - ETA: 0s - loss: 0.8294 - accuracy: 0.62 - ETA: 0s - loss: 0.8246 - accuracy: 0.63 - ETA: 0s - loss: 0.8238 - accuracy: 0.63 - ETA: 0s - loss: 0.8225 - accuracy: 0.64 - ETA: 0s - loss: 0.8253 - accuracy: 0.63 - ETA: 0s - loss: 0.8311 - accuracy: 0.63 - ETA: 0s - loss: 0.8275 - accuracy: 0.63 - ETA: 0s - loss: 0.8197 - accuracy: 0.64 - ETA: 0s - loss: 0.8018 - accuracy: 0.65 - ETA: 0s - loss: 0.8057 - accuracy: 0.65 - ETA: 0s - loss: 0.8125 - accuracy: 0.64 - ETA: 0s - loss: 0.8167 - accuracy: 0.64 - ETA: 0s - loss: 0.8244 - accuracy: 0.64 - ETA: 0s - loss: 0.8274 - accuracy: 0.64 - ETA: 0s - loss: 0.8296 - accuracy: 0.6387\n",
      "Epoch 00931: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8296 - accuracy: 0.6387 - val_loss: 1.0908 - val_accuracy: 0.4818 - lr: 0.0010\n",
      "Epoch 932/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8723 - accuracy: 0.59 - ETA: 0s - loss: 0.8380 - accuracy: 0.63 - ETA: 0s - loss: 0.8510 - accuracy: 0.62 - ETA: 0s - loss: 0.8248 - accuracy: 0.64 - ETA: 0s - loss: 0.8310 - accuracy: 0.63 - ETA: 0s - loss: 0.8258 - accuracy: 0.64 - ETA: 0s - loss: 0.8215 - accuracy: 0.64 - ETA: 0s - loss: 0.8204 - accuracy: 0.64 - ETA: 0s - loss: 0.8232 - accuracy: 0.64 - ETA: 0s - loss: 0.8286 - accuracy: 0.63 - ETA: 0s - loss: 0.8254 - accuracy: 0.64 - ETA: 0s - loss: 0.8197 - accuracy: 0.65 - ETA: 0s - loss: 0.8024 - accuracy: 0.66 - ETA: 0s - loss: 0.8074 - accuracy: 0.65 - ETA: 0s - loss: 0.8160 - accuracy: 0.65 - ETA: 0s - loss: 0.8199 - accuracy: 0.64 - ETA: 0s - loss: 0.8264 - accuracy: 0.64 - ETA: 0s - loss: 0.8293 - accuracy: 0.64 - ETA: 0s - loss: 0.8317 - accuracy: 0.6399\n",
      "Epoch 00932: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8317 - accuracy: 0.6399 - val_loss: 1.1020 - val_accuracy: 0.4791 - lr: 0.0010\n",
      "Epoch 933/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8536 - accuracy: 0.61 - ETA: 0s - loss: 0.8232 - accuracy: 0.62 - ETA: 0s - loss: 0.8454 - accuracy: 0.61 - ETA: 0s - loss: 0.8244 - accuracy: 0.63 - ETA: 0s - loss: 0.8286 - accuracy: 0.63 - ETA: 0s - loss: 0.8248 - accuracy: 0.64 - ETA: 0s - loss: 0.8211 - accuracy: 0.64 - ETA: 0s - loss: 0.8199 - accuracy: 0.64 - ETA: 0s - loss: 0.8243 - accuracy: 0.64 - ETA: 0s - loss: 0.8282 - accuracy: 0.63 - ETA: 0s - loss: 0.8243 - accuracy: 0.64 - ETA: 0s - loss: 0.8174 - accuracy: 0.65 - ETA: 0s - loss: 0.8001 - accuracy: 0.66 - ETA: 0s - loss: 0.8045 - accuracy: 0.66 - ETA: 0s - loss: 0.8111 - accuracy: 0.65 - ETA: 0s - loss: 0.8150 - accuracy: 0.65 - ETA: 0s - loss: 0.8214 - accuracy: 0.64 - ETA: 0s - loss: 0.8243 - accuracy: 0.64 - ETA: 0s - loss: 0.8264 - accuracy: 0.6445\n",
      "Epoch 00933: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8264 - accuracy: 0.6445 - val_loss: 1.0995 - val_accuracy: 0.4826 - lr: 0.0010\n",
      "Epoch 934/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8690 - accuracy: 0.62 - ETA: 0s - loss: 0.8370 - accuracy: 0.63 - ETA: 0s - loss: 0.8493 - accuracy: 0.62 - ETA: 0s - loss: 0.8261 - accuracy: 0.64 - ETA: 0s - loss: 0.8271 - accuracy: 0.63 - ETA: 0s - loss: 0.8237 - accuracy: 0.64 - ETA: 0s - loss: 0.8185 - accuracy: 0.64 - ETA: 0s - loss: 0.8175 - accuracy: 0.65 - ETA: 0s - loss: 0.8221 - accuracy: 0.64 - ETA: 0s - loss: 0.8278 - accuracy: 0.64 - ETA: 0s - loss: 0.8242 - accuracy: 0.64 - ETA: 0s - loss: 0.8177 - accuracy: 0.65 - ETA: 0s - loss: 0.7998 - accuracy: 0.66 - ETA: 0s - loss: 0.8051 - accuracy: 0.66 - ETA: 0s - loss: 0.8149 - accuracy: 0.65 - ETA: 0s - loss: 0.8189 - accuracy: 0.64 - ETA: 0s - loss: 0.8250 - accuracy: 0.64 - ETA: 0s - loss: 0.8272 - accuracy: 0.64 - ETA: 0s - loss: 0.8298 - accuracy: 0.6432\n",
      "Epoch 00934: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8298 - accuracy: 0.6432 - val_loss: 1.1102 - val_accuracy: 0.4757 - lr: 0.0010\n",
      "Epoch 935/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8749 - accuracy: 0.58 - ETA: 0s - loss: 0.8322 - accuracy: 0.62 - ETA: 0s - loss: 0.8477 - accuracy: 0.62 - ETA: 0s - loss: 0.8204 - accuracy: 0.64 - ETA: 0s - loss: 0.8240 - accuracy: 0.64 - ETA: 0s - loss: 0.8194 - accuracy: 0.64 - ETA: 0s - loss: 0.8199 - accuracy: 0.64 - ETA: 0s - loss: 0.8187 - accuracy: 0.64 - ETA: 0s - loss: 0.8215 - accuracy: 0.64 - ETA: 0s - loss: 0.8267 - accuracy: 0.64 - ETA: 0s - loss: 0.8232 - accuracy: 0.64 - ETA: 0s - loss: 0.8185 - accuracy: 0.65 - ETA: 0s - loss: 0.8001 - accuracy: 0.66 - ETA: 0s - loss: 0.8041 - accuracy: 0.66 - ETA: 0s - loss: 0.8112 - accuracy: 0.65 - ETA: 0s - loss: 0.8146 - accuracy: 0.65 - ETA: 0s - loss: 0.8205 - accuracy: 0.64 - ETA: 0s - loss: 0.8233 - accuracy: 0.64 - ETA: 0s - loss: 0.8262 - accuracy: 0.6442\n",
      "Epoch 00935: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00935: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8262 - accuracy: 0.6442 - val_loss: 1.1028 - val_accuracy: 0.4764 - lr: 0.0010\n",
      "Epoch 936/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.8901 - accuracy: 0.55 - ETA: 0s - loss: 0.8437 - accuracy: 0.60 - ETA: 0s - loss: 0.8498 - accuracy: 0.61 - ETA: 0s - loss: 0.8256 - accuracy: 0.63 - ETA: 0s - loss: 0.8266 - accuracy: 0.63 - ETA: 0s - loss: 0.8237 - accuracy: 0.64 - ETA: 0s - loss: 0.8183 - accuracy: 0.64 - ETA: 0s - loss: 0.8167 - accuracy: 0.64 - ETA: 0s - loss: 0.8215 - accuracy: 0.64 - ETA: 0s - loss: 0.8267 - accuracy: 0.64 - ETA: 0s - loss: 0.8232 - accuracy: 0.64 - ETA: 0s - loss: 0.8163 - accuracy: 0.65 - ETA: 0s - loss: 0.7985 - accuracy: 0.66 - ETA: 0s - loss: 0.8020 - accuracy: 0.66 - ETA: 0s - loss: 0.8131 - accuracy: 0.64 - ETA: 0s - loss: 0.8162 - accuracy: 0.64 - ETA: 0s - loss: 0.8230 - accuracy: 0.64 - ETA: 0s - loss: 0.8249 - accuracy: 0.64 - ETA: 0s - loss: 0.8268 - accuracy: 0.6402\n",
      "Epoch 00936: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8268 - accuracy: 0.6402 - val_loss: 1.0924 - val_accuracy: 0.4822 - lr: 0.0010\n",
      "Epoch 937/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8645 - accuracy: 0.58 - ETA: 0s - loss: 0.8204 - accuracy: 0.62 - ETA: 0s - loss: 0.8443 - accuracy: 0.61 - ETA: 0s - loss: 0.8216 - accuracy: 0.63 - ETA: 0s - loss: 0.8248 - accuracy: 0.63 - ETA: 0s - loss: 0.8231 - accuracy: 0.63 - ETA: 0s - loss: 0.8173 - accuracy: 0.64 - ETA: 0s - loss: 0.8174 - accuracy: 0.64 - ETA: 0s - loss: 0.8245 - accuracy: 0.64 - ETA: 0s - loss: 0.8312 - accuracy: 0.63 - ETA: 0s - loss: 0.8274 - accuracy: 0.64 - ETA: 0s - loss: 0.8206 - accuracy: 0.64 - ETA: 0s - loss: 0.8023 - accuracy: 0.66 - ETA: 0s - loss: 0.8077 - accuracy: 0.65 - ETA: 0s - loss: 0.8168 - accuracy: 0.64 - ETA: 0s - loss: 0.8205 - accuracy: 0.64 - ETA: 0s - loss: 0.8280 - accuracy: 0.64 - ETA: 0s - loss: 0.8308 - accuracy: 0.64 - ETA: 0s - loss: 0.8318 - accuracy: 0.6408\n",
      "Epoch 00937: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8318 - accuracy: 0.6408 - val_loss: 1.0761 - val_accuracy: 0.4858 - lr: 0.0010\n",
      "Epoch 938/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8562 - accuracy: 0.60 - ETA: 0s - loss: 0.8274 - accuracy: 0.62 - ETA: 0s - loss: 0.8424 - accuracy: 0.62 - ETA: 0s - loss: 0.8207 - accuracy: 0.63 - ETA: 0s - loss: 0.8251 - accuracy: 0.63 - ETA: 0s - loss: 0.8215 - accuracy: 0.64 - ETA: 0s - loss: 0.8179 - accuracy: 0.64 - ETA: 0s - loss: 0.8151 - accuracy: 0.65 - ETA: 0s - loss: 0.8189 - accuracy: 0.64 - ETA: 0s - loss: 0.8260 - accuracy: 0.64 - ETA: 0s - loss: 0.8230 - accuracy: 0.64 - ETA: 0s - loss: 0.8166 - accuracy: 0.65 - ETA: 0s - loss: 0.7980 - accuracy: 0.66 - ETA: 0s - loss: 0.8009 - accuracy: 0.66 - ETA: 0s - loss: 0.8117 - accuracy: 0.65 - ETA: 0s - loss: 0.8158 - accuracy: 0.65 - ETA: 0s - loss: 0.8231 - accuracy: 0.64 - ETA: 0s - loss: 0.8261 - accuracy: 0.64 - ETA: 0s - loss: 0.8288 - accuracy: 0.6448\n",
      "Epoch 00938: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8288 - accuracy: 0.6448 - val_loss: 1.0974 - val_accuracy: 0.4774 - lr: 0.0010\n",
      "Epoch 939/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.8860 - accuracy: 0.56 - ETA: 0s - loss: 0.8348 - accuracy: 0.61 - ETA: 0s - loss: 0.8428 - accuracy: 0.61 - ETA: 0s - loss: 0.8177 - accuracy: 0.63 - ETA: 0s - loss: 0.8245 - accuracy: 0.63 - ETA: 0s - loss: 0.8207 - accuracy: 0.64 - ETA: 0s - loss: 0.8176 - accuracy: 0.64 - ETA: 0s - loss: 0.8154 - accuracy: 0.64 - ETA: 0s - loss: 0.8191 - accuracy: 0.64 - ETA: 0s - loss: 0.8234 - accuracy: 0.64 - ETA: 0s - loss: 0.8207 - accuracy: 0.64 - ETA: 0s - loss: 0.8140 - accuracy: 0.65 - ETA: 0s - loss: 0.7967 - accuracy: 0.66 - ETA: 0s - loss: 0.8013 - accuracy: 0.66 - ETA: 0s - loss: 0.8093 - accuracy: 0.65 - ETA: 0s - loss: 0.8123 - accuracy: 0.65 - ETA: 0s - loss: 0.8201 - accuracy: 0.64 - ETA: 0s - loss: 0.8228 - accuracy: 0.6457\n",
      "Epoch 00939: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8238 - accuracy: 0.6448 - val_loss: 1.0974 - val_accuracy: 0.4787 - lr: 0.0010\n",
      "Epoch 940/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8659 - accuracy: 0.61 - ETA: 0s - loss: 0.8393 - accuracy: 0.63 - ETA: 0s - loss: 0.8526 - accuracy: 0.62 - ETA: 0s - loss: 0.8251 - accuracy: 0.64 - ETA: 0s - loss: 0.8287 - accuracy: 0.63 - ETA: 0s - loss: 0.8222 - accuracy: 0.64 - ETA: 0s - loss: 0.8215 - accuracy: 0.64 - ETA: 0s - loss: 0.8228 - accuracy: 0.64 - ETA: 0s - loss: 0.8262 - accuracy: 0.64 - ETA: 0s - loss: 0.8297 - accuracy: 0.63 - ETA: 0s - loss: 0.8268 - accuracy: 0.64 - ETA: 0s - loss: 0.8199 - accuracy: 0.65 - ETA: 0s - loss: 0.8012 - accuracy: 0.66 - ETA: 0s - loss: 0.8049 - accuracy: 0.66 - ETA: 0s - loss: 0.8126 - accuracy: 0.65 - ETA: 0s - loss: 0.8159 - accuracy: 0.65 - ETA: 0s - loss: 0.8231 - accuracy: 0.64 - ETA: 0s - loss: 0.8264 - accuracy: 0.64 - ETA: 0s - loss: 0.8277 - accuracy: 0.6476\n",
      "Epoch 00940: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8277 - accuracy: 0.6476 - val_loss: 1.0926 - val_accuracy: 0.4845 - lr: 0.0010\n",
      "Epoch 941/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8987 - accuracy: 0.59 - ETA: 0s - loss: 0.8464 - accuracy: 0.62 - ETA: 0s - loss: 0.8517 - accuracy: 0.62 - ETA: 0s - loss: 0.8230 - accuracy: 0.63 - ETA: 0s - loss: 0.8233 - accuracy: 0.63 - ETA: 0s - loss: 0.8200 - accuracy: 0.64 - ETA: 0s - loss: 0.8182 - accuracy: 0.64 - ETA: 0s - loss: 0.8156 - accuracy: 0.64 - ETA: 0s - loss: 0.8204 - accuracy: 0.64 - ETA: 0s - loss: 0.8260 - accuracy: 0.63 - ETA: 0s - loss: 0.8229 - accuracy: 0.64 - ETA: 0s - loss: 0.8165 - accuracy: 0.65 - ETA: 0s - loss: 0.7991 - accuracy: 0.66 - ETA: 0s - loss: 0.8032 - accuracy: 0.65 - ETA: 0s - loss: 0.8115 - accuracy: 0.64 - ETA: 0s - loss: 0.8164 - accuracy: 0.64 - ETA: 0s - loss: 0.8233 - accuracy: 0.64 - ETA: 0s - loss: 0.8253 - accuracy: 0.64 - ETA: 0s - loss: 0.8265 - accuracy: 0.6400\n",
      "Epoch 00941: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8265 - accuracy: 0.6400 - val_loss: 1.0883 - val_accuracy: 0.4922 - lr: 0.0010\n",
      "Epoch 942/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8602 - accuracy: 0.60 - ETA: 0s - loss: 0.8261 - accuracy: 0.63 - ETA: 0s - loss: 0.8417 - accuracy: 0.62 - ETA: 0s - loss: 0.8189 - accuracy: 0.63 - ETA: 0s - loss: 0.8215 - accuracy: 0.63 - ETA: 0s - loss: 0.8190 - accuracy: 0.64 - ETA: 0s - loss: 0.8158 - accuracy: 0.64 - ETA: 0s - loss: 0.8134 - accuracy: 0.64 - ETA: 0s - loss: 0.8171 - accuracy: 0.64 - ETA: 0s - loss: 0.8222 - accuracy: 0.64 - ETA: 0s - loss: 0.8196 - accuracy: 0.64 - ETA: 0s - loss: 0.8135 - accuracy: 0.65 - ETA: 0s - loss: 0.7960 - accuracy: 0.66 - ETA: 0s - loss: 0.8001 - accuracy: 0.66 - ETA: 0s - loss: 0.8093 - accuracy: 0.65 - ETA: 0s - loss: 0.8127 - accuracy: 0.65 - ETA: 0s - loss: 0.8194 - accuracy: 0.64 - ETA: 0s - loss: 0.8219 - accuracy: 0.64 - ETA: 0s - loss: 0.8243 - accuracy: 0.6458\n",
      "Epoch 00942: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8243 - accuracy: 0.6458 - val_loss: 1.0835 - val_accuracy: 0.4923 - lr: 0.0010\n",
      "Epoch 943/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8782 - accuracy: 0.59 - ETA: 0s - loss: 0.8472 - accuracy: 0.61 - ETA: 0s - loss: 0.8560 - accuracy: 0.62 - ETA: 0s - loss: 0.8285 - accuracy: 0.63 - ETA: 0s - loss: 0.8266 - accuracy: 0.63 - ETA: 0s - loss: 0.8235 - accuracy: 0.64 - ETA: 0s - loss: 0.8203 - accuracy: 0.65 - ETA: 0s - loss: 0.8215 - accuracy: 0.65 - ETA: 0s - loss: 0.8245 - accuracy: 0.64 - ETA: 0s - loss: 0.8296 - accuracy: 0.64 - ETA: 0s - loss: 0.8254 - accuracy: 0.64 - ETA: 0s - loss: 0.8192 - accuracy: 0.65 - ETA: 0s - loss: 0.8009 - accuracy: 0.66 - ETA: 0s - loss: 0.8042 - accuracy: 0.66 - ETA: 0s - loss: 0.8125 - accuracy: 0.65 - ETA: 0s - loss: 0.8165 - accuracy: 0.65 - ETA: 0s - loss: 0.8231 - accuracy: 0.64 - ETA: 0s - loss: 0.8259 - accuracy: 0.64 - ETA: 0s - loss: 0.8278 - accuracy: 0.6441\n",
      "Epoch 00943: val_loss did not improve from 0.99131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8278 - accuracy: 0.6441 - val_loss: 1.0852 - val_accuracy: 0.4873 - lr: 0.0010\n",
      "Epoch 944/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8699 - accuracy: 0.56 - ETA: 0s - loss: 0.8312 - accuracy: 0.61 - ETA: 0s - loss: 0.8436 - accuracy: 0.61 - ETA: 0s - loss: 0.8211 - accuracy: 0.63 - ETA: 0s - loss: 0.8249 - accuracy: 0.63 - ETA: 0s - loss: 0.8208 - accuracy: 0.64 - ETA: 0s - loss: 0.8152 - accuracy: 0.64 - ETA: 0s - loss: 0.8146 - accuracy: 0.64 - ETA: 0s - loss: 0.8192 - accuracy: 0.64 - ETA: 0s - loss: 0.8246 - accuracy: 0.63 - ETA: 0s - loss: 0.8211 - accuracy: 0.64 - ETA: 0s - loss: 0.8145 - accuracy: 0.64 - ETA: 0s - loss: 0.7972 - accuracy: 0.66 - ETA: 0s - loss: 0.8012 - accuracy: 0.65 - ETA: 0s - loss: 0.8100 - accuracy: 0.65 - ETA: 0s - loss: 0.8134 - accuracy: 0.64 - ETA: 0s - loss: 0.8217 - accuracy: 0.64 - ETA: 0s - loss: 0.8235 - accuracy: 0.64 - ETA: 0s - loss: 0.8258 - accuracy: 0.6421\n",
      "Epoch 00944: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8258 - accuracy: 0.6421 - val_loss: 1.0804 - val_accuracy: 0.4902 - lr: 0.0010\n",
      "Epoch 945/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8835 - accuracy: 0.58 - ETA: 0s - loss: 0.8412 - accuracy: 0.61 - ETA: 0s - loss: 0.8465 - accuracy: 0.61 - ETA: 0s - loss: 0.8192 - accuracy: 0.63 - ETA: 0s - loss: 0.8204 - accuracy: 0.63 - ETA: 0s - loss: 0.8164 - accuracy: 0.64 - ETA: 0s - loss: 0.8155 - accuracy: 0.64 - ETA: 0s - loss: 0.8174 - accuracy: 0.64 - ETA: 0s - loss: 0.8210 - accuracy: 0.63 - ETA: 0s - loss: 0.8230 - accuracy: 0.64 - ETA: 0s - loss: 0.8157 - accuracy: 0.64 - ETA: 0s - loss: 0.7981 - accuracy: 0.65 - ETA: 0s - loss: 0.8015 - accuracy: 0.65 - ETA: 0s - loss: 0.8103 - accuracy: 0.64 - ETA: 0s - loss: 0.8138 - accuracy: 0.64 - ETA: 0s - loss: 0.8211 - accuracy: 0.64 - ETA: 0s - loss: 0.8239 - accuracy: 0.64 - ETA: 0s - loss: 0.8258 - accuracy: 0.6409\n",
      "Epoch 00945: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8258 - accuracy: 0.6409 - val_loss: 1.0835 - val_accuracy: 0.4850 - lr: 0.0010\n",
      "Epoch 946/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8633 - accuracy: 0.60 - ETA: 0s - loss: 0.8382 - accuracy: 0.62 - ETA: 0s - loss: 0.8494 - accuracy: 0.62 - ETA: 0s - loss: 0.8255 - accuracy: 0.63 - ETA: 0s - loss: 0.8311 - accuracy: 0.63 - ETA: 0s - loss: 0.8274 - accuracy: 0.64 - ETA: 0s - loss: 0.8249 - accuracy: 0.64 - ETA: 0s - loss: 0.8242 - accuracy: 0.64 - ETA: 0s - loss: 0.8259 - accuracy: 0.64 - ETA: 0s - loss: 0.8293 - accuracy: 0.63 - ETA: 0s - loss: 0.8260 - accuracy: 0.64 - ETA: 0s - loss: 0.8194 - accuracy: 0.65 - ETA: 0s - loss: 0.8011 - accuracy: 0.66 - ETA: 0s - loss: 0.8065 - accuracy: 0.66 - ETA: 0s - loss: 0.8125 - accuracy: 0.65 - ETA: 0s - loss: 0.8168 - accuracy: 0.65 - ETA: 0s - loss: 0.8237 - accuracy: 0.64 - ETA: 0s - loss: 0.8269 - accuracy: 0.64 - ETA: 0s - loss: 0.8292 - accuracy: 0.6431\n",
      "Epoch 00946: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8292 - accuracy: 0.6431 - val_loss: 1.0838 - val_accuracy: 0.4785 - lr: 0.0010\n",
      "Epoch 947/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8642 - accuracy: 0.58 - ETA: 0s - loss: 0.8268 - accuracy: 0.62 - ETA: 0s - loss: 0.8469 - accuracy: 0.61 - ETA: 0s - loss: 0.8210 - accuracy: 0.63 - ETA: 0s - loss: 0.8254 - accuracy: 0.63 - ETA: 0s - loss: 0.8216 - accuracy: 0.64 - ETA: 0s - loss: 0.8186 - accuracy: 0.64 - ETA: 0s - loss: 0.8168 - accuracy: 0.64 - ETA: 0s - loss: 0.8186 - accuracy: 0.64 - ETA: 0s - loss: 0.8259 - accuracy: 0.64 - ETA: 0s - loss: 0.8232 - accuracy: 0.64 - ETA: 0s - loss: 0.8168 - accuracy: 0.65 - ETA: 0s - loss: 0.7979 - accuracy: 0.66 - ETA: 0s - loss: 0.8009 - accuracy: 0.66 - ETA: 0s - loss: 0.8093 - accuracy: 0.65 - ETA: 0s - loss: 0.8134 - accuracy: 0.65 - ETA: 0s - loss: 0.8211 - accuracy: 0.64 - ETA: 0s - loss: 0.8234 - accuracy: 0.64 - ETA: 0s - loss: 0.8253 - accuracy: 0.6441\n",
      "Epoch 00947: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8253 - accuracy: 0.6441 - val_loss: 1.0747 - val_accuracy: 0.4863 - lr: 0.0010\n",
      "Epoch 948/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8377 - accuracy: 0.62 - ETA: 0s - loss: 0.8170 - accuracy: 0.64 - ETA: 0s - loss: 0.8424 - accuracy: 0.62 - ETA: 0s - loss: 0.8171 - accuracy: 0.64 - ETA: 0s - loss: 0.8204 - accuracy: 0.64 - ETA: 0s - loss: 0.8152 - accuracy: 0.65 - ETA: 0s - loss: 0.8147 - accuracy: 0.65 - ETA: 0s - loss: 0.8146 - accuracy: 0.65 - ETA: 0s - loss: 0.8169 - accuracy: 0.64 - ETA: 0s - loss: 0.8221 - accuracy: 0.64 - ETA: 0s - loss: 0.8198 - accuracy: 0.65 - ETA: 0s - loss: 0.8134 - accuracy: 0.65 - ETA: 0s - loss: 0.7959 - accuracy: 0.66 - ETA: 0s - loss: 0.8011 - accuracy: 0.66 - ETA: 0s - loss: 0.8090 - accuracy: 0.65 - ETA: 0s - loss: 0.8127 - accuracy: 0.65 - ETA: 0s - loss: 0.8190 - accuracy: 0.64 - ETA: 0s - loss: 0.8222 - accuracy: 0.64 - ETA: 0s - loss: 0.8234 - accuracy: 0.6452\n",
      "Epoch 00948: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8234 - accuracy: 0.6452 - val_loss: 1.0844 - val_accuracy: 0.4878 - lr: 0.0010\n",
      "Epoch 949/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8640 - accuracy: 0.61 - ETA: 0s - loss: 0.8351 - accuracy: 0.63 - ETA: 0s - loss: 0.8445 - accuracy: 0.63 - ETA: 0s - loss: 0.8217 - accuracy: 0.64 - ETA: 0s - loss: 0.8257 - accuracy: 0.64 - ETA: 0s - loss: 0.8211 - accuracy: 0.64 - ETA: 0s - loss: 0.8198 - accuracy: 0.65 - ETA: 0s - loss: 0.8192 - accuracy: 0.65 - ETA: 0s - loss: 0.8245 - accuracy: 0.64 - ETA: 0s - loss: 0.8303 - accuracy: 0.64 - ETA: 0s - loss: 0.8261 - accuracy: 0.64 - ETA: 0s - loss: 0.8194 - accuracy: 0.65 - ETA: 0s - loss: 0.8014 - accuracy: 0.66 - ETA: 0s - loss: 0.8064 - accuracy: 0.66 - ETA: 0s - loss: 0.8139 - accuracy: 0.65 - ETA: 0s - loss: 0.8180 - accuracy: 0.64 - ETA: 0s - loss: 0.8233 - accuracy: 0.64 - ETA: 0s - loss: 0.8244 - accuracy: 0.64 - ETA: 0s - loss: 0.8267 - accuracy: 0.6439\n",
      "Epoch 00949: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00949: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8267 - accuracy: 0.6439 - val_loss: 1.0832 - val_accuracy: 0.4873 - lr: 0.0010\n",
      "Epoch 950/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8655 - accuracy: 0.58 - ETA: 0s - loss: 0.8284 - accuracy: 0.62 - ETA: 0s - loss: 0.8550 - accuracy: 0.61 - ETA: 0s - loss: 0.8303 - accuracy: 0.62 - ETA: 0s - loss: 0.8306 - accuracy: 0.63 - ETA: 0s - loss: 0.8232 - accuracy: 0.63 - ETA: 0s - loss: 0.8202 - accuracy: 0.64 - ETA: 0s - loss: 0.8177 - accuracy: 0.64 - ETA: 0s - loss: 0.8228 - accuracy: 0.64 - ETA: 0s - loss: 0.8289 - accuracy: 0.63 - ETA: 0s - loss: 0.8250 - accuracy: 0.64 - ETA: 0s - loss: 0.8191 - accuracy: 0.64 - ETA: 0s - loss: 0.8003 - accuracy: 0.66 - ETA: 0s - loss: 0.8049 - accuracy: 0.65 - ETA: 0s - loss: 0.8132 - accuracy: 0.65 - ETA: 0s - loss: 0.8168 - accuracy: 0.64 - ETA: 0s - loss: 0.8233 - accuracy: 0.64 - ETA: 0s - loss: 0.8257 - accuracy: 0.64 - ETA: 0s - loss: 0.8269 - accuracy: 0.6432\n",
      "Epoch 00950: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8269 - accuracy: 0.6432 - val_loss: 1.0859 - val_accuracy: 0.4839 - lr: 0.0010\n",
      "Epoch 951/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.8698 - accuracy: 0.60 - ETA: 0s - loss: 0.8393 - accuracy: 0.62 - ETA: 0s - loss: 0.8561 - accuracy: 0.61 - ETA: 0s - loss: 0.8286 - accuracy: 0.63 - ETA: 0s - loss: 0.8335 - accuracy: 0.63 - ETA: 0s - loss: 0.8285 - accuracy: 0.63 - ETA: 0s - loss: 0.8257 - accuracy: 0.64 - ETA: 0s - loss: 0.8227 - accuracy: 0.64 - ETA: 0s - loss: 0.8248 - accuracy: 0.64 - ETA: 0s - loss: 0.8303 - accuracy: 0.63 - ETA: 0s - loss: 0.8261 - accuracy: 0.64 - ETA: 0s - loss: 0.8197 - accuracy: 0.64 - ETA: 0s - loss: 0.8014 - accuracy: 0.66 - ETA: 0s - loss: 0.8064 - accuracy: 0.65 - ETA: 0s - loss: 0.8144 - accuracy: 0.64 - ETA: 0s - loss: 0.8180 - accuracy: 0.64 - ETA: 0s - loss: 0.8248 - accuracy: 0.64 - ETA: 0s - loss: 0.8277 - accuracy: 0.64 - ETA: 0s - loss: 0.8287 - accuracy: 0.6401\n",
      "Epoch 00951: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8287 - accuracy: 0.6401 - val_loss: 1.0681 - val_accuracy: 0.4940 - lr: 0.0010\n",
      "Epoch 952/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8789 - accuracy: 0.59 - ETA: 0s - loss: 0.8316 - accuracy: 0.62 - ETA: 0s - loss: 0.8208 - accuracy: 0.64 - ETA: 0s - loss: 0.8276 - accuracy: 0.64 - ETA: 0s - loss: 0.8213 - accuracy: 0.65 - ETA: 0s - loss: 0.8210 - accuracy: 0.65 - ETA: 0s - loss: 0.8203 - accuracy: 0.65 - ETA: 0s - loss: 0.8227 - accuracy: 0.64 - ETA: 0s - loss: 0.8264 - accuracy: 0.64 - ETA: 0s - loss: 0.8233 - accuracy: 0.65 - ETA: 0s - loss: 0.8169 - accuracy: 0.65 - ETA: 0s - loss: 0.7988 - accuracy: 0.66 - ETA: 0s - loss: 0.8037 - accuracy: 0.66 - ETA: 0s - loss: 0.8124 - accuracy: 0.65 - ETA: 0s - loss: 0.8157 - accuracy: 0.65 - ETA: 0s - loss: 0.8213 - accuracy: 0.65 - ETA: 0s - loss: 0.8243 - accuracy: 0.64 - ETA: 0s - loss: 0.8258 - accuracy: 0.6479\n",
      "Epoch 00952: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8258 - accuracy: 0.6479 - val_loss: 1.0755 - val_accuracy: 0.4884 - lr: 0.0010\n",
      "Epoch 953/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8729 - accuracy: 0.57 - ETA: 0s - loss: 0.8416 - accuracy: 0.61 - ETA: 0s - loss: 0.8506 - accuracy: 0.61 - ETA: 0s - loss: 0.8266 - accuracy: 0.63 - ETA: 0s - loss: 0.8317 - accuracy: 0.63 - ETA: 0s - loss: 0.8275 - accuracy: 0.64 - ETA: 0s - loss: 0.8258 - accuracy: 0.64 - ETA: 0s - loss: 0.8262 - accuracy: 0.64 - ETA: 0s - loss: 0.8274 - accuracy: 0.64 - ETA: 0s - loss: 0.8328 - accuracy: 0.63 - ETA: 0s - loss: 0.8293 - accuracy: 0.64 - ETA: 0s - loss: 0.8223 - accuracy: 0.65 - ETA: 0s - loss: 0.8037 - accuracy: 0.66 - ETA: 0s - loss: 0.8068 - accuracy: 0.66 - ETA: 0s - loss: 0.8156 - accuracy: 0.65 - ETA: 0s - loss: 0.8184 - accuracy: 0.64 - ETA: 0s - loss: 0.8258 - accuracy: 0.64 - ETA: 0s - loss: 0.8291 - accuracy: 0.64 - ETA: 0s - loss: 0.8302 - accuracy: 0.6425\n",
      "Epoch 00953: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8302 - accuracy: 0.6425 - val_loss: 1.0916 - val_accuracy: 0.4809 - lr: 0.0010\n",
      "Epoch 954/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8835 - accuracy: 0.59 - ETA: 0s - loss: 0.8393 - accuracy: 0.62 - ETA: 0s - loss: 0.8522 - accuracy: 0.62 - ETA: 0s - loss: 0.8262 - accuracy: 0.63 - ETA: 0s - loss: 0.8316 - accuracy: 0.63 - ETA: 0s - loss: 0.8278 - accuracy: 0.64 - ETA: 0s - loss: 0.8238 - accuracy: 0.64 - ETA: 0s - loss: 0.8204 - accuracy: 0.64 - ETA: 0s - loss: 0.8246 - accuracy: 0.64 - ETA: 0s - loss: 0.8302 - accuracy: 0.64 - ETA: 0s - loss: 0.8271 - accuracy: 0.64 - ETA: 0s - loss: 0.8191 - accuracy: 0.65 - ETA: 0s - loss: 0.8015 - accuracy: 0.66 - ETA: 0s - loss: 0.8047 - accuracy: 0.66 - ETA: 0s - loss: 0.8138 - accuracy: 0.65 - ETA: 0s - loss: 0.8179 - accuracy: 0.65 - ETA: 0s - loss: 0.8246 - accuracy: 0.64 - ETA: 0s - loss: 0.8267 - accuracy: 0.64 - ETA: 0s - loss: 0.8276 - accuracy: 0.6453\n",
      "Epoch 00954: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8276 - accuracy: 0.6453 - val_loss: 1.0701 - val_accuracy: 0.4979 - lr: 0.0010\n",
      "Epoch 955/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8846 - accuracy: 0.56 - ETA: 0s - loss: 0.8426 - accuracy: 0.60 - ETA: 0s - loss: 0.8469 - accuracy: 0.60 - ETA: 0s - loss: 0.8223 - accuracy: 0.62 - ETA: 0s - loss: 0.8274 - accuracy: 0.63 - ETA: 0s - loss: 0.8247 - accuracy: 0.63 - ETA: 0s - loss: 0.8225 - accuracy: 0.64 - ETA: 0s - loss: 0.8215 - accuracy: 0.64 - ETA: 0s - loss: 0.8236 - accuracy: 0.64 - ETA: 0s - loss: 0.8274 - accuracy: 0.63 - ETA: 0s - loss: 0.8240 - accuracy: 0.64 - ETA: 0s - loss: 0.8168 - accuracy: 0.65 - ETA: 0s - loss: 0.7984 - accuracy: 0.66 - ETA: 0s - loss: 0.8019 - accuracy: 0.66 - ETA: 0s - loss: 0.8098 - accuracy: 0.65 - ETA: 0s - loss: 0.8139 - accuracy: 0.65 - ETA: 0s - loss: 0.8207 - accuracy: 0.64 - ETA: 0s - loss: 0.8232 - accuracy: 0.64 - ETA: 0s - loss: 0.8243 - accuracy: 0.6442\n",
      "Epoch 00955: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8243 - accuracy: 0.6442 - val_loss: 1.1020 - val_accuracy: 0.4847 - lr: 0.0010\n",
      "Epoch 956/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8728 - accuracy: 0.59 - ETA: 0s - loss: 0.8443 - accuracy: 0.61 - ETA: 0s - loss: 0.8475 - accuracy: 0.61 - ETA: 0s - loss: 0.8241 - accuracy: 0.63 - ETA: 0s - loss: 0.8297 - accuracy: 0.63 - ETA: 0s - loss: 0.8248 - accuracy: 0.64 - ETA: 0s - loss: 0.8211 - accuracy: 0.64 - ETA: 0s - loss: 0.8199 - accuracy: 0.64 - ETA: 0s - loss: 0.8217 - accuracy: 0.64 - ETA: 0s - loss: 0.8297 - accuracy: 0.63 - ETA: 0s - loss: 0.8274 - accuracy: 0.64 - ETA: 0s - loss: 0.8199 - accuracy: 0.64 - ETA: 0s - loss: 0.8017 - accuracy: 0.66 - ETA: 0s - loss: 0.8050 - accuracy: 0.65 - ETA: 0s - loss: 0.8138 - accuracy: 0.64 - ETA: 0s - loss: 0.8177 - accuracy: 0.64 - ETA: 0s - loss: 0.8250 - accuracy: 0.64 - ETA: 0s - loss: 0.8277 - accuracy: 0.64 - ETA: 0s - loss: 0.8295 - accuracy: 0.6389\n",
      "Epoch 00956: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8295 - accuracy: 0.6389 - val_loss: 1.0973 - val_accuracy: 0.4822 - lr: 0.0010\n",
      "Epoch 957/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8707 - accuracy: 0.60 - ETA: 0s - loss: 0.8368 - accuracy: 0.63 - ETA: 0s - loss: 0.8404 - accuracy: 0.63 - ETA: 0s - loss: 0.8155 - accuracy: 0.64 - ETA: 0s - loss: 0.8213 - accuracy: 0.64 - ETA: 0s - loss: 0.8182 - accuracy: 0.64 - ETA: 0s - loss: 0.8179 - accuracy: 0.65 - ETA: 0s - loss: 0.8169 - accuracy: 0.65 - ETA: 0s - loss: 0.8203 - accuracy: 0.64 - ETA: 0s - loss: 0.8258 - accuracy: 0.64 - ETA: 0s - loss: 0.8221 - accuracy: 0.64 - ETA: 0s - loss: 0.8161 - accuracy: 0.65 - ETA: 0s - loss: 0.7978 - accuracy: 0.66 - ETA: 0s - loss: 0.8015 - accuracy: 0.66 - ETA: 0s - loss: 0.8081 - accuracy: 0.65 - ETA: 0s - loss: 0.8123 - accuracy: 0.65 - ETA: 0s - loss: 0.8195 - accuracy: 0.64 - ETA: 0s - loss: 0.8226 - accuracy: 0.64 - ETA: 0s - loss: 0.8255 - accuracy: 0.6466\n",
      "Epoch 00957: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8255 - accuracy: 0.6466 - val_loss: 1.0843 - val_accuracy: 0.4889 - lr: 0.0010\n",
      "Epoch 958/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8552 - accuracy: 0.61 - ETA: 0s - loss: 0.8275 - accuracy: 0.64 - ETA: 0s - loss: 0.8395 - accuracy: 0.63 - ETA: 0s - loss: 0.8161 - accuracy: 0.65 - ETA: 0s - loss: 0.8218 - accuracy: 0.64 - ETA: 0s - loss: 0.8195 - accuracy: 0.65 - ETA: 0s - loss: 0.8180 - accuracy: 0.65 - ETA: 0s - loss: 0.8173 - accuracy: 0.65 - ETA: 0s - loss: 0.8204 - accuracy: 0.65 - ETA: 0s - loss: 0.8287 - accuracy: 0.64 - ETA: 0s - loss: 0.8245 - accuracy: 0.64 - ETA: 0s - loss: 0.8175 - accuracy: 0.65 - ETA: 0s - loss: 0.7989 - accuracy: 0.66 - ETA: 0s - loss: 0.8026 - accuracy: 0.66 - ETA: 0s - loss: 0.8115 - accuracy: 0.65 - ETA: 0s - loss: 0.8154 - accuracy: 0.65 - ETA: 0s - loss: 0.8217 - accuracy: 0.64 - ETA: 0s - loss: 0.8242 - accuracy: 0.64 - ETA: 0s - loss: 0.8259 - accuracy: 0.6458\n",
      "Epoch 00958: val_loss did not improve from 0.99131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8259 - accuracy: 0.6458 - val_loss: 1.0823 - val_accuracy: 0.4875 - lr: 0.0010\n",
      "Epoch 959/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8750 - accuracy: 0.58 - ETA: 0s - loss: 0.8420 - accuracy: 0.62 - ETA: 0s - loss: 0.8510 - accuracy: 0.62 - ETA: 0s - loss: 0.8255 - accuracy: 0.63 - ETA: 0s - loss: 0.8290 - accuracy: 0.63 - ETA: 0s - loss: 0.8241 - accuracy: 0.64 - ETA: 0s - loss: 0.8243 - accuracy: 0.64 - ETA: 0s - loss: 0.8204 - accuracy: 0.65 - ETA: 0s - loss: 0.8231 - accuracy: 0.64 - ETA: 0s - loss: 0.8289 - accuracy: 0.64 - ETA: 0s - loss: 0.8257 - accuracy: 0.65 - ETA: 0s - loss: 0.8195 - accuracy: 0.65 - ETA: 0s - loss: 0.8006 - accuracy: 0.66 - ETA: 0s - loss: 0.8043 - accuracy: 0.66 - ETA: 0s - loss: 0.8118 - accuracy: 0.65 - ETA: 0s - loss: 0.8152 - accuracy: 0.65 - ETA: 0s - loss: 0.8209 - accuracy: 0.64 - ETA: 0s - loss: 0.8241 - accuracy: 0.64 - ETA: 0s - loss: 0.8255 - accuracy: 0.6487\n",
      "Epoch 00959: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8255 - accuracy: 0.6487 - val_loss: 1.0935 - val_accuracy: 0.4881 - lr: 0.0010\n",
      "Epoch 960/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8518 - accuracy: 0.59 - ETA: 0s - loss: 0.8379 - accuracy: 0.61 - ETA: 0s - loss: 0.8433 - accuracy: 0.62 - ETA: 0s - loss: 0.8195 - accuracy: 0.64 - ETA: 0s - loss: 0.8255 - accuracy: 0.63 - ETA: 0s - loss: 0.8186 - accuracy: 0.64 - ETA: 0s - loss: 0.8151 - accuracy: 0.64 - ETA: 0s - loss: 0.8154 - accuracy: 0.64 - ETA: 0s - loss: 0.8191 - accuracy: 0.64 - ETA: 0s - loss: 0.8262 - accuracy: 0.64 - ETA: 0s - loss: 0.8228 - accuracy: 0.64 - ETA: 0s - loss: 0.8165 - accuracy: 0.65 - ETA: 0s - loss: 0.7984 - accuracy: 0.66 - ETA: 0s - loss: 0.8016 - accuracy: 0.66 - ETA: 0s - loss: 0.8112 - accuracy: 0.65 - ETA: 0s - loss: 0.8142 - accuracy: 0.65 - ETA: 0s - loss: 0.8216 - accuracy: 0.64 - ETA: 0s - loss: 0.8250 - accuracy: 0.64 - ETA: 0s - loss: 0.8271 - accuracy: 0.6447\n",
      "Epoch 00960: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8271 - accuracy: 0.6447 - val_loss: 1.0853 - val_accuracy: 0.4884 - lr: 0.0010\n",
      "Epoch 961/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8722 - accuracy: 0.57 - ETA: 0s - loss: 0.8429 - accuracy: 0.61 - ETA: 0s - loss: 0.8489 - accuracy: 0.61 - ETA: 0s - loss: 0.8248 - accuracy: 0.63 - ETA: 0s - loss: 0.8310 - accuracy: 0.63 - ETA: 0s - loss: 0.8250 - accuracy: 0.64 - ETA: 0s - loss: 0.8219 - accuracy: 0.64 - ETA: 0s - loss: 0.8197 - accuracy: 0.64 - ETA: 0s - loss: 0.8219 - accuracy: 0.64 - ETA: 0s - loss: 0.8264 - accuracy: 0.64 - ETA: 0s - loss: 0.8228 - accuracy: 0.64 - ETA: 0s - loss: 0.8165 - accuracy: 0.65 - ETA: 0s - loss: 0.7982 - accuracy: 0.66 - ETA: 0s - loss: 0.8026 - accuracy: 0.65 - ETA: 0s - loss: 0.8104 - accuracy: 0.65 - ETA: 0s - loss: 0.8143 - accuracy: 0.65 - ETA: 0s - loss: 0.8205 - accuracy: 0.64 - ETA: 0s - loss: 0.8238 - accuracy: 0.64 - ETA: 0s - loss: 0.8249 - accuracy: 0.6438\n",
      "Epoch 00961: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8249 - accuracy: 0.6438 - val_loss: 1.0961 - val_accuracy: 0.4818 - lr: 0.0010\n",
      "Epoch 962/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8620 - accuracy: 0.60 - ETA: 0s - loss: 0.8244 - accuracy: 0.63 - ETA: 0s - loss: 0.8380 - accuracy: 0.62 - ETA: 0s - loss: 0.8127 - accuracy: 0.64 - ETA: 0s - loss: 0.8208 - accuracy: 0.64 - ETA: 0s - loss: 0.8164 - accuracy: 0.64 - ETA: 0s - loss: 0.8130 - accuracy: 0.65 - ETA: 0s - loss: 0.8093 - accuracy: 0.65 - ETA: 0s - loss: 0.8130 - accuracy: 0.65 - ETA: 0s - loss: 0.8189 - accuracy: 0.64 - ETA: 0s - loss: 0.8179 - accuracy: 0.65 - ETA: 0s - loss: 0.8119 - accuracy: 0.65 - ETA: 0s - loss: 0.7943 - accuracy: 0.66 - ETA: 0s - loss: 0.7986 - accuracy: 0.66 - ETA: 0s - loss: 0.8078 - accuracy: 0.65 - ETA: 0s - loss: 0.8108 - accuracy: 0.65 - ETA: 0s - loss: 0.8164 - accuracy: 0.65 - ETA: 0s - loss: 0.8203 - accuracy: 0.64 - ETA: 0s - loss: 0.8221 - accuracy: 0.6475\n",
      "Epoch 00962: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8221 - accuracy: 0.6475 - val_loss: 1.0966 - val_accuracy: 0.4881 - lr: 0.0010\n",
      "Epoch 963/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8587 - accuracy: 0.60 - ETA: 0s - loss: 0.8304 - accuracy: 0.63 - ETA: 0s - loss: 0.8437 - accuracy: 0.62 - ETA: 0s - loss: 0.8161 - accuracy: 0.64 - ETA: 0s - loss: 0.8235 - accuracy: 0.64 - ETA: 0s - loss: 0.8210 - accuracy: 0.64 - ETA: 0s - loss: 0.8188 - accuracy: 0.65 - ETA: 0s - loss: 0.8151 - accuracy: 0.65 - ETA: 0s - loss: 0.8187 - accuracy: 0.65 - ETA: 0s - loss: 0.8276 - accuracy: 0.64 - ETA: 0s - loss: 0.8236 - accuracy: 0.64 - ETA: 0s - loss: 0.8164 - accuracy: 0.65 - ETA: 0s - loss: 0.7983 - accuracy: 0.66 - ETA: 0s - loss: 0.8033 - accuracy: 0.66 - ETA: 0s - loss: 0.8118 - accuracy: 0.65 - ETA: 0s - loss: 0.8141 - accuracy: 0.65 - ETA: 0s - loss: 0.8197 - accuracy: 0.64 - ETA: 0s - loss: 0.8224 - accuracy: 0.64 - ETA: 0s - loss: 0.8242 - accuracy: 0.6468\n",
      "Epoch 00963: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00963: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8242 - accuracy: 0.6468 - val_loss: 1.1099 - val_accuracy: 0.4862 - lr: 0.0010\n",
      "Epoch 964/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8534 - accuracy: 0.62 - ETA: 0s - loss: 0.8337 - accuracy: 0.63 - ETA: 0s - loss: 0.8404 - accuracy: 0.63 - ETA: 0s - loss: 0.8162 - accuracy: 0.64 - ETA: 0s - loss: 0.8199 - accuracy: 0.64 - ETA: 0s - loss: 0.8172 - accuracy: 0.65 - ETA: 0s - loss: 0.8132 - accuracy: 0.65 - ETA: 0s - loss: 0.8139 - accuracy: 0.65 - ETA: 0s - loss: 0.8159 - accuracy: 0.65 - ETA: 0s - loss: 0.8218 - accuracy: 0.64 - ETA: 0s - loss: 0.8203 - accuracy: 0.65 - ETA: 0s - loss: 0.8144 - accuracy: 0.65 - ETA: 0s - loss: 0.7957 - accuracy: 0.66 - ETA: 0s - loss: 0.7985 - accuracy: 0.66 - ETA: 0s - loss: 0.8078 - accuracy: 0.65 - ETA: 0s - loss: 0.8122 - accuracy: 0.65 - ETA: 0s - loss: 0.8184 - accuracy: 0.64 - ETA: 0s - loss: 0.8214 - accuracy: 0.64 - ETA: 0s - loss: 0.8235 - accuracy: 0.6455\n",
      "Epoch 00964: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8235 - accuracy: 0.6455 - val_loss: 1.1013 - val_accuracy: 0.4804 - lr: 0.0010\n",
      "Epoch 965/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.8543 - accuracy: 0.59 - ETA: 0s - loss: 0.8289 - accuracy: 0.61 - ETA: 0s - loss: 0.8358 - accuracy: 0.61 - ETA: 0s - loss: 0.8119 - accuracy: 0.63 - ETA: 0s - loss: 0.8193 - accuracy: 0.63 - ETA: 0s - loss: 0.8160 - accuracy: 0.64 - ETA: 0s - loss: 0.8158 - accuracy: 0.64 - ETA: 0s - loss: 0.8128 - accuracy: 0.64 - ETA: 0s - loss: 0.8139 - accuracy: 0.64 - ETA: 0s - loss: 0.8225 - accuracy: 0.64 - ETA: 0s - loss: 0.8210 - accuracy: 0.64 - ETA: 0s - loss: 0.8146 - accuracy: 0.65 - ETA: 0s - loss: 0.7951 - accuracy: 0.66 - ETA: 0s - loss: 0.7984 - accuracy: 0.66 - ETA: 0s - loss: 0.8064 - accuracy: 0.65 - ETA: 0s - loss: 0.8110 - accuracy: 0.65 - ETA: 0s - loss: 0.8174 - accuracy: 0.64 - ETA: 0s - loss: 0.8204 - accuracy: 0.6468\n",
      "Epoch 00965: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8218 - accuracy: 0.6457 - val_loss: 1.1019 - val_accuracy: 0.4840 - lr: 0.0010\n",
      "Epoch 966/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.8823 - accuracy: 0.59 - ETA: 0s - loss: 0.8393 - accuracy: 0.63 - ETA: 0s - loss: 0.8533 - accuracy: 0.62 - ETA: 0s - loss: 0.8298 - accuracy: 0.64 - ETA: 0s - loss: 0.8309 - accuracy: 0.64 - ETA: 0s - loss: 0.8270 - accuracy: 0.64 - ETA: 0s - loss: 0.8274 - accuracy: 0.64 - ETA: 0s - loss: 0.8246 - accuracy: 0.64 - ETA: 0s - loss: 0.8265 - accuracy: 0.64 - ETA: 0s - loss: 0.8304 - accuracy: 0.64 - ETA: 0s - loss: 0.8268 - accuracy: 0.64 - ETA: 0s - loss: 0.8195 - accuracy: 0.65 - ETA: 0s - loss: 0.8008 - accuracy: 0.66 - ETA: 0s - loss: 0.8046 - accuracy: 0.66 - ETA: 0s - loss: 0.8133 - accuracy: 0.65 - ETA: 0s - loss: 0.8166 - accuracy: 0.65 - ETA: 0s - loss: 0.8233 - accuracy: 0.64 - ETA: 0s - loss: 0.8257 - accuracy: 0.64 - ETA: 0s - loss: 0.8276 - accuracy: 0.6433\n",
      "Epoch 00966: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8276 - accuracy: 0.6433 - val_loss: 1.1008 - val_accuracy: 0.4858 - lr: 0.0010\n",
      "Epoch 967/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8626 - accuracy: 0.59 - ETA: 0s - loss: 0.8300 - accuracy: 0.62 - ETA: 0s - loss: 0.8422 - accuracy: 0.62 - ETA: 0s - loss: 0.8189 - accuracy: 0.64 - ETA: 0s - loss: 0.8201 - accuracy: 0.64 - ETA: 0s - loss: 0.8156 - accuracy: 0.64 - ETA: 0s - loss: 0.8117 - accuracy: 0.65 - ETA: 0s - loss: 0.8130 - accuracy: 0.65 - ETA: 0s - loss: 0.8157 - accuracy: 0.65 - ETA: 0s - loss: 0.8213 - accuracy: 0.64 - ETA: 0s - loss: 0.8188 - accuracy: 0.65 - ETA: 0s - loss: 0.8124 - accuracy: 0.65 - ETA: 0s - loss: 0.7939 - accuracy: 0.66 - ETA: 0s - loss: 0.7975 - accuracy: 0.66 - ETA: 0s - loss: 0.8042 - accuracy: 0.65 - ETA: 0s - loss: 0.8087 - accuracy: 0.65 - ETA: 0s - loss: 0.8163 - accuracy: 0.64 - ETA: 0s - loss: 0.8200 - accuracy: 0.64 - ETA: 0s - loss: 0.8215 - accuracy: 0.6467\n",
      "Epoch 00967: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8215 - accuracy: 0.6467 - val_loss: 1.1099 - val_accuracy: 0.4788 - lr: 0.0010\n",
      "Epoch 968/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8699 - accuracy: 0.60 - ETA: 0s - loss: 0.8312 - accuracy: 0.62 - ETA: 0s - loss: 0.8368 - accuracy: 0.62 - ETA: 0s - loss: 0.8110 - accuracy: 0.64 - ETA: 0s - loss: 0.8146 - accuracy: 0.64 - ETA: 0s - loss: 0.8126 - accuracy: 0.65 - ETA: 0s - loss: 0.8111 - accuracy: 0.65 - ETA: 0s - loss: 0.8131 - accuracy: 0.65 - ETA: 0s - loss: 0.8168 - accuracy: 0.64 - ETA: 0s - loss: 0.8200 - accuracy: 0.64 - ETA: 0s - loss: 0.8186 - accuracy: 0.65 - ETA: 0s - loss: 0.8120 - accuracy: 0.65 - ETA: 0s - loss: 0.7942 - accuracy: 0.66 - ETA: 0s - loss: 0.7985 - accuracy: 0.66 - ETA: 0s - loss: 0.8077 - accuracy: 0.65 - ETA: 0s - loss: 0.8109 - accuracy: 0.65 - ETA: 0s - loss: 0.8170 - accuracy: 0.64 - ETA: 0s - loss: 0.8206 - accuracy: 0.64 - ETA: 0s - loss: 0.8231 - accuracy: 0.6452\n",
      "Epoch 00968: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8231 - accuracy: 0.6452 - val_loss: 1.1092 - val_accuracy: 0.4839 - lr: 0.0010\n",
      "Epoch 969/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8654 - accuracy: 0.58 - ETA: 0s - loss: 0.8271 - accuracy: 0.62 - ETA: 0s - loss: 0.8412 - accuracy: 0.62 - ETA: 0s - loss: 0.8181 - accuracy: 0.63 - ETA: 0s - loss: 0.8217 - accuracy: 0.63 - ETA: 0s - loss: 0.8180 - accuracy: 0.64 - ETA: 0s - loss: 0.8174 - accuracy: 0.64 - ETA: 0s - loss: 0.8158 - accuracy: 0.64 - ETA: 0s - loss: 0.8185 - accuracy: 0.64 - ETA: 0s - loss: 0.8245 - accuracy: 0.64 - ETA: 0s - loss: 0.8220 - accuracy: 0.64 - ETA: 0s - loss: 0.8156 - accuracy: 0.65 - ETA: 0s - loss: 0.7976 - accuracy: 0.66 - ETA: 0s - loss: 0.8002 - accuracy: 0.66 - ETA: 0s - loss: 0.8087 - accuracy: 0.65 - ETA: 0s - loss: 0.8115 - accuracy: 0.65 - ETA: 0s - loss: 0.8187 - accuracy: 0.64 - ETA: 0s - loss: 0.8211 - accuracy: 0.64 - ETA: 0s - loss: 0.8230 - accuracy: 0.6445\n",
      "Epoch 00969: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8230 - accuracy: 0.6445 - val_loss: 1.0984 - val_accuracy: 0.4819 - lr: 0.0010\n",
      "Epoch 970/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8561 - accuracy: 0.60 - ETA: 0s - loss: 0.8172 - accuracy: 0.62 - ETA: 0s - loss: 0.8359 - accuracy: 0.62 - ETA: 0s - loss: 0.8137 - accuracy: 0.63 - ETA: 0s - loss: 0.8186 - accuracy: 0.64 - ETA: 0s - loss: 0.8143 - accuracy: 0.64 - ETA: 0s - loss: 0.8123 - accuracy: 0.64 - ETA: 0s - loss: 0.8098 - accuracy: 0.65 - ETA: 0s - loss: 0.8139 - accuracy: 0.64 - ETA: 0s - loss: 0.8205 - accuracy: 0.64 - ETA: 0s - loss: 0.8169 - accuracy: 0.64 - ETA: 0s - loss: 0.8102 - accuracy: 0.65 - ETA: 0s - loss: 0.7930 - accuracy: 0.66 - ETA: 0s - loss: 0.7980 - accuracy: 0.66 - ETA: 0s - loss: 0.8067 - accuracy: 0.65 - ETA: 0s - loss: 0.8111 - accuracy: 0.65 - ETA: 0s - loss: 0.8179 - accuracy: 0.64 - ETA: 0s - loss: 0.8212 - accuracy: 0.64 - ETA: 0s - loss: 0.8227 - accuracy: 0.6442\n",
      "Epoch 00970: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8227 - accuracy: 0.6442 - val_loss: 1.1005 - val_accuracy: 0.4791 - lr: 0.0010\n",
      "Epoch 971/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8896 - accuracy: 0.57 - ETA: 0s - loss: 0.8469 - accuracy: 0.61 - ETA: 0s - loss: 0.8599 - accuracy: 0.60 - ETA: 0s - loss: 0.8298 - accuracy: 0.62 - ETA: 0s - loss: 0.8334 - accuracy: 0.62 - ETA: 0s - loss: 0.8274 - accuracy: 0.63 - ETA: 0s - loss: 0.8231 - accuracy: 0.64 - ETA: 0s - loss: 0.8206 - accuracy: 0.64 - ETA: 0s - loss: 0.8215 - accuracy: 0.64 - ETA: 0s - loss: 0.8298 - accuracy: 0.63 - ETA: 0s - loss: 0.8262 - accuracy: 0.64 - ETA: 0s - loss: 0.8213 - accuracy: 0.64 - ETA: 0s - loss: 0.8032 - accuracy: 0.66 - ETA: 0s - loss: 0.8076 - accuracy: 0.65 - ETA: 0s - loss: 0.8143 - accuracy: 0.65 - ETA: 0s - loss: 0.8183 - accuracy: 0.64 - ETA: 0s - loss: 0.8254 - accuracy: 0.64 - ETA: 0s - loss: 0.8284 - accuracy: 0.64 - ETA: 0s - loss: 0.8300 - accuracy: 0.6403\n",
      "Epoch 00971: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8300 - accuracy: 0.6403 - val_loss: 1.1067 - val_accuracy: 0.4713 - lr: 0.0010\n",
      "Epoch 972/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8706 - accuracy: 0.61 - ETA: 0s - loss: 0.8380 - accuracy: 0.62 - ETA: 0s - loss: 0.8482 - accuracy: 0.62 - ETA: 0s - loss: 0.8241 - accuracy: 0.63 - ETA: 0s - loss: 0.8256 - accuracy: 0.63 - ETA: 0s - loss: 0.8221 - accuracy: 0.64 - ETA: 0s - loss: 0.8194 - accuracy: 0.64 - ETA: 0s - loss: 0.8172 - accuracy: 0.64 - ETA: 0s - loss: 0.8193 - accuracy: 0.64 - ETA: 0s - loss: 0.8267 - accuracy: 0.63 - ETA: 0s - loss: 0.8242 - accuracy: 0.64 - ETA: 0s - loss: 0.8175 - accuracy: 0.65 - ETA: 0s - loss: 0.7994 - accuracy: 0.66 - ETA: 0s - loss: 0.8043 - accuracy: 0.65 - ETA: 0s - loss: 0.8123 - accuracy: 0.65 - ETA: 0s - loss: 0.8163 - accuracy: 0.64 - ETA: 0s - loss: 0.8228 - accuracy: 0.64 - ETA: 0s - loss: 0.8259 - accuracy: 0.64 - ETA: 0s - loss: 0.8278 - accuracy: 0.6437\n",
      "Epoch 00972: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8278 - accuracy: 0.6437 - val_loss: 1.0936 - val_accuracy: 0.4826 - lr: 0.0010\n",
      "Epoch 973/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8659 - accuracy: 0.58 - ETA: 0s - loss: 0.8372 - accuracy: 0.62 - ETA: 0s - loss: 0.8528 - accuracy: 0.61 - ETA: 0s - loss: 0.8245 - accuracy: 0.63 - ETA: 0s - loss: 0.8308 - accuracy: 0.63 - ETA: 0s - loss: 0.8255 - accuracy: 0.64 - ETA: 0s - loss: 0.8233 - accuracy: 0.64 - ETA: 0s - loss: 0.8211 - accuracy: 0.64 - ETA: 0s - loss: 0.8237 - accuracy: 0.64 - ETA: 0s - loss: 0.8303 - accuracy: 0.64 - ETA: 0s - loss: 0.8264 - accuracy: 0.64 - ETA: 0s - loss: 0.8182 - accuracy: 0.65 - ETA: 0s - loss: 0.8001 - accuracy: 0.66 - ETA: 0s - loss: 0.8032 - accuracy: 0.66 - ETA: 0s - loss: 0.8114 - accuracy: 0.65 - ETA: 0s - loss: 0.8146 - accuracy: 0.65 - ETA: 0s - loss: 0.8211 - accuracy: 0.64 - ETA: 0s - loss: 0.8240 - accuracy: 0.64 - ETA: 0s - loss: 0.8253 - accuracy: 0.6446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00973: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8253 - accuracy: 0.6446 - val_loss: 1.1020 - val_accuracy: 0.4881 - lr: 0.0010\n",
      "Epoch 974/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8664 - accuracy: 0.59 - ETA: 0s - loss: 0.8397 - accuracy: 0.61 - ETA: 0s - loss: 0.8539 - accuracy: 0.61 - ETA: 0s - loss: 0.8248 - accuracy: 0.62 - ETA: 0s - loss: 0.8268 - accuracy: 0.63 - ETA: 0s - loss: 0.8206 - accuracy: 0.63 - ETA: 0s - loss: 0.8168 - accuracy: 0.64 - ETA: 0s - loss: 0.8177 - accuracy: 0.64 - ETA: 0s - loss: 0.8204 - accuracy: 0.64 - ETA: 0s - loss: 0.8264 - accuracy: 0.63 - ETA: 0s - loss: 0.8231 - accuracy: 0.64 - ETA: 0s - loss: 0.8163 - accuracy: 0.64 - ETA: 0s - loss: 0.7988 - accuracy: 0.66 - ETA: 0s - loss: 0.8039 - accuracy: 0.65 - ETA: 0s - loss: 0.8123 - accuracy: 0.64 - ETA: 0s - loss: 0.8162 - accuracy: 0.64 - ETA: 0s - loss: 0.8224 - accuracy: 0.64 - ETA: 0s - loss: 0.8251 - accuracy: 0.64 - ETA: 0s - loss: 0.8256 - accuracy: 0.6418\n",
      "Epoch 00974: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8256 - accuracy: 0.6418 - val_loss: 1.0932 - val_accuracy: 0.4818 - lr: 0.0010\n",
      "Epoch 975/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8783 - accuracy: 0.58 - ETA: 0s - loss: 0.8392 - accuracy: 0.61 - ETA: 0s - loss: 0.8528 - accuracy: 0.61 - ETA: 0s - loss: 0.8251 - accuracy: 0.63 - ETA: 0s - loss: 0.8301 - accuracy: 0.63 - ETA: 0s - loss: 0.8246 - accuracy: 0.64 - ETA: 0s - loss: 0.8225 - accuracy: 0.64 - ETA: 0s - loss: 0.8190 - accuracy: 0.64 - ETA: 0s - loss: 0.8221 - accuracy: 0.64 - ETA: 0s - loss: 0.8306 - accuracy: 0.63 - ETA: 0s - loss: 0.8255 - accuracy: 0.64 - ETA: 0s - loss: 0.8197 - accuracy: 0.64 - ETA: 0s - loss: 0.8011 - accuracy: 0.66 - ETA: 0s - loss: 0.8065 - accuracy: 0.65 - ETA: 0s - loss: 0.8152 - accuracy: 0.65 - ETA: 0s - loss: 0.8185 - accuracy: 0.64 - ETA: 0s - loss: 0.8247 - accuracy: 0.64 - ETA: 0s - loss: 0.8277 - accuracy: 0.64 - ETA: 0s - loss: 0.8293 - accuracy: 0.6416\n",
      "Epoch 00975: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8293 - accuracy: 0.6416 - val_loss: 1.0870 - val_accuracy: 0.4865 - lr: 0.0010\n",
      "Epoch 976/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8578 - accuracy: 0.61 - ETA: 0s - loss: 0.8252 - accuracy: 0.63 - ETA: 0s - loss: 0.8390 - accuracy: 0.63 - ETA: 0s - loss: 0.8144 - accuracy: 0.64 - ETA: 0s - loss: 0.8199 - accuracy: 0.64 - ETA: 0s - loss: 0.8174 - accuracy: 0.64 - ETA: 0s - loss: 0.8132 - accuracy: 0.65 - ETA: 0s - loss: 0.8134 - accuracy: 0.65 - ETA: 0s - loss: 0.8180 - accuracy: 0.64 - ETA: 0s - loss: 0.8246 - accuracy: 0.63 - ETA: 0s - loss: 0.8212 - accuracy: 0.64 - ETA: 0s - loss: 0.8152 - accuracy: 0.65 - ETA: 0s - loss: 0.7975 - accuracy: 0.66 - ETA: 0s - loss: 0.8024 - accuracy: 0.66 - ETA: 0s - loss: 0.8105 - accuracy: 0.65 - ETA: 0s - loss: 0.8147 - accuracy: 0.65 - ETA: 0s - loss: 0.8201 - accuracy: 0.64 - ETA: 0s - loss: 0.8229 - accuracy: 0.64 - ETA: 0s - loss: 0.8250 - accuracy: 0.6445\n",
      "Epoch 00976: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8250 - accuracy: 0.6445 - val_loss: 1.0939 - val_accuracy: 0.4811 - lr: 0.0010\n",
      "Epoch 977/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8463 - accuracy: 0.58 - ETA: 0s - loss: 0.8259 - accuracy: 0.62 - ETA: 0s - loss: 0.8370 - accuracy: 0.62 - ETA: 0s - loss: 0.8150 - accuracy: 0.63 - ETA: 0s - loss: 0.8180 - accuracy: 0.64 - ETA: 0s - loss: 0.8149 - accuracy: 0.64 - ETA: 0s - loss: 0.8114 - accuracy: 0.65 - ETA: 0s - loss: 0.8086 - accuracy: 0.65 - ETA: 0s - loss: 0.8118 - accuracy: 0.65 - ETA: 0s - loss: 0.8171 - accuracy: 0.64 - ETA: 0s - loss: 0.8141 - accuracy: 0.65 - ETA: 0s - loss: 0.8080 - accuracy: 0.65 - ETA: 0s - loss: 0.7906 - accuracy: 0.66 - ETA: 0s - loss: 0.7958 - accuracy: 0.66 - ETA: 0s - loss: 0.8051 - accuracy: 0.65 - ETA: 0s - loss: 0.8081 - accuracy: 0.65 - ETA: 0s - loss: 0.8154 - accuracy: 0.65 - ETA: 0s - loss: 0.8187 - accuracy: 0.64 - ETA: 0s - loss: 0.8209 - accuracy: 0.6479\n",
      "Epoch 00977: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00977: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8209 - accuracy: 0.6479 - val_loss: 1.1032 - val_accuracy: 0.4783 - lr: 0.0010\n",
      "Epoch 978/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8480 - accuracy: 0.60 - ETA: 0s - loss: 0.8292 - accuracy: 0.62 - ETA: 0s - loss: 0.8342 - accuracy: 0.62 - ETA: 0s - loss: 0.8134 - accuracy: 0.64 - ETA: 0s - loss: 0.8190 - accuracy: 0.64 - ETA: 0s - loss: 0.8148 - accuracy: 0.64 - ETA: 0s - loss: 0.8098 - accuracy: 0.65 - ETA: 0s - loss: 0.8094 - accuracy: 0.65 - ETA: 0s - loss: 0.8126 - accuracy: 0.65 - ETA: 0s - loss: 0.8199 - accuracy: 0.64 - ETA: 0s - loss: 0.8165 - accuracy: 0.65 - ETA: 0s - loss: 0.8093 - accuracy: 0.65 - ETA: 0s - loss: 0.7906 - accuracy: 0.66 - ETA: 0s - loss: 0.7963 - accuracy: 0.66 - ETA: 0s - loss: 0.8047 - accuracy: 0.65 - ETA: 0s - loss: 0.8091 - accuracy: 0.65 - ETA: 0s - loss: 0.8166 - accuracy: 0.65 - ETA: 0s - loss: 0.8198 - accuracy: 0.64 - ETA: 0s - loss: 0.8214 - accuracy: 0.6482\n",
      "Epoch 00978: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8214 - accuracy: 0.6482 - val_loss: 1.1001 - val_accuracy: 0.4868 - lr: 0.0010\n",
      "Epoch 979/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8787 - accuracy: 0.59 - ETA: 0s - loss: 0.8309 - accuracy: 0.63 - ETA: 0s - loss: 0.8370 - accuracy: 0.63 - ETA: 0s - loss: 0.8109 - accuracy: 0.64 - ETA: 0s - loss: 0.8163 - accuracy: 0.64 - ETA: 0s - loss: 0.8146 - accuracy: 0.65 - ETA: 0s - loss: 0.8118 - accuracy: 0.65 - ETA: 0s - loss: 0.8115 - accuracy: 0.65 - ETA: 0s - loss: 0.8170 - accuracy: 0.65 - ETA: 0s - loss: 0.8236 - accuracy: 0.64 - ETA: 0s - loss: 0.8206 - accuracy: 0.64 - ETA: 0s - loss: 0.8136 - accuracy: 0.65 - ETA: 0s - loss: 0.7951 - accuracy: 0.66 - ETA: 0s - loss: 0.7998 - accuracy: 0.66 - ETA: 0s - loss: 0.8098 - accuracy: 0.65 - ETA: 0s - loss: 0.8135 - accuracy: 0.65 - ETA: 0s - loss: 0.8196 - accuracy: 0.64 - ETA: 0s - loss: 0.8218 - accuracy: 0.64 - ETA: 0s - loss: 0.8232 - accuracy: 0.6464\n",
      "Epoch 00979: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8232 - accuracy: 0.6464 - val_loss: 1.0914 - val_accuracy: 0.4840 - lr: 0.0010\n",
      "Epoch 980/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8764 - accuracy: 0.58 - ETA: 0s - loss: 0.8332 - accuracy: 0.63 - ETA: 0s - loss: 0.8433 - accuracy: 0.63 - ETA: 0s - loss: 0.8185 - accuracy: 0.64 - ETA: 0s - loss: 0.8210 - accuracy: 0.64 - ETA: 0s - loss: 0.8180 - accuracy: 0.65 - ETA: 0s - loss: 0.8147 - accuracy: 0.65 - ETA: 0s - loss: 0.8133 - accuracy: 0.65 - ETA: 0s - loss: 0.8157 - accuracy: 0.65 - ETA: 0s - loss: 0.8224 - accuracy: 0.64 - ETA: 0s - loss: 0.8187 - accuracy: 0.65 - ETA: 0s - loss: 0.8118 - accuracy: 0.65 - ETA: 0s - loss: 0.7947 - accuracy: 0.66 - ETA: 0s - loss: 0.8003 - accuracy: 0.66 - ETA: 0s - loss: 0.8093 - accuracy: 0.65 - ETA: 0s - loss: 0.8139 - accuracy: 0.65 - ETA: 0s - loss: 0.8200 - accuracy: 0.64 - ETA: 0s - loss: 0.8235 - accuracy: 0.64 - ETA: 0s - loss: 0.8251 - accuracy: 0.6462\n",
      "Epoch 00980: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8251 - accuracy: 0.6462 - val_loss: 1.1102 - val_accuracy: 0.4803 - lr: 0.0010\n",
      "Epoch 981/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.9007 - accuracy: 0.57 - ETA: 0s - loss: 0.8562 - accuracy: 0.61 - ETA: 0s - loss: 0.8544 - accuracy: 0.61 - ETA: 0s - loss: 0.8246 - accuracy: 0.63 - ETA: 0s - loss: 0.8291 - accuracy: 0.63 - ETA: 0s - loss: 0.8244 - accuracy: 0.64 - ETA: 0s - loss: 0.8205 - accuracy: 0.64 - ETA: 0s - loss: 0.8162 - accuracy: 0.64 - ETA: 0s - loss: 0.8198 - accuracy: 0.64 - ETA: 0s - loss: 0.8241 - accuracy: 0.64 - ETA: 0s - loss: 0.8196 - accuracy: 0.64 - ETA: 0s - loss: 0.8123 - accuracy: 0.65 - ETA: 0s - loss: 0.7941 - accuracy: 0.66 - ETA: 0s - loss: 0.7994 - accuracy: 0.66 - ETA: 0s - loss: 0.8096 - accuracy: 0.65 - ETA: 0s - loss: 0.8135 - accuracy: 0.64 - ETA: 0s - loss: 0.8192 - accuracy: 0.64 - ETA: 0s - loss: 0.8222 - accuracy: 0.64 - ETA: 0s - loss: 0.8232 - accuracy: 0.6452\n",
      "Epoch 00981: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8232 - accuracy: 0.6452 - val_loss: 1.1042 - val_accuracy: 0.4835 - lr: 0.0010\n",
      "Epoch 982/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8731 - accuracy: 0.59 - ETA: 0s - loss: 0.8351 - accuracy: 0.61 - ETA: 0s - loss: 0.8566 - accuracy: 0.61 - ETA: 0s - loss: 0.8269 - accuracy: 0.63 - ETA: 0s - loss: 0.8296 - accuracy: 0.63 - ETA: 0s - loss: 0.8240 - accuracy: 0.64 - ETA: 0s - loss: 0.8211 - accuracy: 0.64 - ETA: 0s - loss: 0.8199 - accuracy: 0.64 - ETA: 0s - loss: 0.8233 - accuracy: 0.64 - ETA: 0s - loss: 0.8281 - accuracy: 0.63 - ETA: 0s - loss: 0.8252 - accuracy: 0.64 - ETA: 0s - loss: 0.8177 - accuracy: 0.65 - ETA: 0s - loss: 0.7986 - accuracy: 0.66 - ETA: 0s - loss: 0.8034 - accuracy: 0.65 - ETA: 0s - loss: 0.8110 - accuracy: 0.65 - ETA: 0s - loss: 0.8145 - accuracy: 0.65 - ETA: 0s - loss: 0.8213 - accuracy: 0.64 - ETA: 0s - loss: 0.8257 - accuracy: 0.64 - ETA: 0s - loss: 0.8272 - accuracy: 0.6430\n",
      "Epoch 00982: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8272 - accuracy: 0.6430 - val_loss: 1.1107 - val_accuracy: 0.4785 - lr: 0.0010\n",
      "Epoch 983/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8612 - accuracy: 0.59 - ETA: 0s - loss: 0.8277 - accuracy: 0.63 - ETA: 0s - loss: 0.8313 - accuracy: 0.63 - ETA: 0s - loss: 0.8069 - accuracy: 0.64 - ETA: 0s - loss: 0.8118 - accuracy: 0.64 - ETA: 0s - loss: 0.8087 - accuracy: 0.65 - ETA: 0s - loss: 0.8084 - accuracy: 0.65 - ETA: 0s - loss: 0.8064 - accuracy: 0.65 - ETA: 0s - loss: 0.8108 - accuracy: 0.65 - ETA: 0s - loss: 0.8173 - accuracy: 0.64 - ETA: 0s - loss: 0.8143 - accuracy: 0.65 - ETA: 0s - loss: 0.8085 - accuracy: 0.65 - ETA: 0s - loss: 0.7912 - accuracy: 0.66 - ETA: 0s - loss: 0.7964 - accuracy: 0.66 - ETA: 0s - loss: 0.8044 - accuracy: 0.65 - ETA: 0s - loss: 0.8087 - accuracy: 0.65 - ETA: 0s - loss: 0.8162 - accuracy: 0.64 - ETA: 0s - loss: 0.8189 - accuracy: 0.64 - ETA: 0s - loss: 0.8197 - accuracy: 0.6477\n",
      "Epoch 00983: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8197 - accuracy: 0.6477 - val_loss: 1.1204 - val_accuracy: 0.4723 - lr: 0.0010\n",
      "Epoch 984/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8617 - accuracy: 0.59 - ETA: 0s - loss: 0.8304 - accuracy: 0.62 - ETA: 0s - loss: 0.8460 - accuracy: 0.62 - ETA: 0s - loss: 0.8223 - accuracy: 0.64 - ETA: 0s - loss: 0.8227 - accuracy: 0.64 - ETA: 0s - loss: 0.8175 - accuracy: 0.65 - ETA: 0s - loss: 0.8146 - accuracy: 0.65 - ETA: 0s - loss: 0.8137 - accuracy: 0.65 - ETA: 0s - loss: 0.8165 - accuracy: 0.65 - ETA: 0s - loss: 0.8214 - accuracy: 0.64 - ETA: 0s - loss: 0.8191 - accuracy: 0.64 - ETA: 0s - loss: 0.8129 - accuracy: 0.65 - ETA: 0s - loss: 0.7952 - accuracy: 0.66 - ETA: 0s - loss: 0.7994 - accuracy: 0.66 - ETA: 0s - loss: 0.8081 - accuracy: 0.65 - ETA: 0s - loss: 0.8120 - accuracy: 0.65 - ETA: 0s - loss: 0.8193 - accuracy: 0.64 - ETA: 0s - loss: 0.8213 - accuracy: 0.64 - ETA: 0s - loss: 0.8223 - accuracy: 0.6475\n",
      "Epoch 00984: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8223 - accuracy: 0.6475 - val_loss: 1.1136 - val_accuracy: 0.4752 - lr: 0.0010\n",
      "Epoch 985/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8659 - accuracy: 0.58 - ETA: 0s - loss: 0.8279 - accuracy: 0.62 - ETA: 0s - loss: 0.8390 - accuracy: 0.62 - ETA: 0s - loss: 0.8129 - accuracy: 0.64 - ETA: 0s - loss: 0.8148 - accuracy: 0.64 - ETA: 0s - loss: 0.8132 - accuracy: 0.65 - ETA: 0s - loss: 0.8087 - accuracy: 0.65 - ETA: 0s - loss: 0.8084 - accuracy: 0.65 - ETA: 0s - loss: 0.8110 - accuracy: 0.65 - ETA: 0s - loss: 0.8161 - accuracy: 0.64 - ETA: 0s - loss: 0.8143 - accuracy: 0.65 - ETA: 0s - loss: 0.8079 - accuracy: 0.65 - ETA: 0s - loss: 0.7903 - accuracy: 0.67 - ETA: 0s - loss: 0.7941 - accuracy: 0.66 - ETA: 0s - loss: 0.8022 - accuracy: 0.66 - ETA: 0s - loss: 0.8068 - accuracy: 0.65 - ETA: 0s - loss: 0.8144 - accuracy: 0.65 - ETA: 0s - loss: 0.8177 - accuracy: 0.65 - ETA: 0s - loss: 0.8192 - accuracy: 0.6492\n",
      "Epoch 00985: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8192 - accuracy: 0.6492 - val_loss: 1.0906 - val_accuracy: 0.4837 - lr: 0.0010\n",
      "Epoch 986/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8668 - accuracy: 0.60 - ETA: 0s - loss: 0.8430 - accuracy: 0.62 - ETA: 0s - loss: 0.8519 - accuracy: 0.62 - ETA: 0s - loss: 0.8236 - accuracy: 0.64 - ETA: 0s - loss: 0.8283 - accuracy: 0.64 - ETA: 0s - loss: 0.8223 - accuracy: 0.65 - ETA: 0s - loss: 0.8198 - accuracy: 0.65 - ETA: 0s - loss: 0.8188 - accuracy: 0.65 - ETA: 0s - loss: 0.8202 - accuracy: 0.64 - ETA: 0s - loss: 0.8257 - accuracy: 0.64 - ETA: 0s - loss: 0.8220 - accuracy: 0.64 - ETA: 0s - loss: 0.8152 - accuracy: 0.65 - ETA: 0s - loss: 0.7973 - accuracy: 0.66 - ETA: 0s - loss: 0.8016 - accuracy: 0.66 - ETA: 0s - loss: 0.8110 - accuracy: 0.65 - ETA: 0s - loss: 0.8150 - accuracy: 0.65 - ETA: 0s - loss: 0.8223 - accuracy: 0.64 - ETA: 0s - loss: 0.8245 - accuracy: 0.64 - ETA: 0s - loss: 0.8258 - accuracy: 0.6448\n",
      "Epoch 00986: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8258 - accuracy: 0.6448 - val_loss: 1.0912 - val_accuracy: 0.4902 - lr: 0.0010\n",
      "Epoch 987/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8498 - accuracy: 0.60 - ETA: 0s - loss: 0.8263 - accuracy: 0.62 - ETA: 0s - loss: 0.8374 - accuracy: 0.62 - ETA: 0s - loss: 0.8098 - accuracy: 0.64 - ETA: 0s - loss: 0.8164 - accuracy: 0.64 - ETA: 0s - loss: 0.8125 - accuracy: 0.65 - ETA: 0s - loss: 0.8109 - accuracy: 0.65 - ETA: 0s - loss: 0.8088 - accuracy: 0.65 - ETA: 0s - loss: 0.8118 - accuracy: 0.65 - ETA: 0s - loss: 0.8174 - accuracy: 0.65 - ETA: 0s - loss: 0.8143 - accuracy: 0.65 - ETA: 0s - loss: 0.8080 - accuracy: 0.66 - ETA: 0s - loss: 0.7905 - accuracy: 0.67 - ETA: 0s - loss: 0.7970 - accuracy: 0.66 - ETA: 0s - loss: 0.8045 - accuracy: 0.65 - ETA: 0s - loss: 0.8088 - accuracy: 0.65 - ETA: 0s - loss: 0.8160 - accuracy: 0.64 - ETA: 0s - loss: 0.8187 - accuracy: 0.64 - ETA: 0s - loss: 0.8209 - accuracy: 0.6469\n",
      "Epoch 00987: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8209 - accuracy: 0.6469 - val_loss: 1.1064 - val_accuracy: 0.4829 - lr: 0.0010\n",
      "Epoch 988/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8675 - accuracy: 0.58 - ETA: 0s - loss: 0.8223 - accuracy: 0.62 - ETA: 0s - loss: 0.8347 - accuracy: 0.62 - ETA: 0s - loss: 0.8141 - accuracy: 0.63 - ETA: 0s - loss: 0.8206 - accuracy: 0.63 - ETA: 0s - loss: 0.8169 - accuracy: 0.64 - ETA: 0s - loss: 0.8141 - accuracy: 0.64 - ETA: 0s - loss: 0.8108 - accuracy: 0.64 - ETA: 0s - loss: 0.8139 - accuracy: 0.64 - ETA: 0s - loss: 0.8209 - accuracy: 0.64 - ETA: 0s - loss: 0.8181 - accuracy: 0.64 - ETA: 0s - loss: 0.8103 - accuracy: 0.65 - ETA: 0s - loss: 0.7916 - accuracy: 0.66 - ETA: 0s - loss: 0.7963 - accuracy: 0.66 - ETA: 0s - loss: 0.8042 - accuracy: 0.65 - ETA: 0s - loss: 0.8091 - accuracy: 0.65 - ETA: 0s - loss: 0.8162 - accuracy: 0.64 - ETA: 0s - loss: 0.8189 - accuracy: 0.64 - ETA: 0s - loss: 0.8216 - accuracy: 0.6438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00988: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8216 - accuracy: 0.6438 - val_loss: 1.0912 - val_accuracy: 0.4914 - lr: 0.0010\n",
      "Epoch 989/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8791 - accuracy: 0.59 - ETA: 0s - loss: 0.8353 - accuracy: 0.62 - ETA: 0s - loss: 0.8520 - accuracy: 0.61 - ETA: 0s - loss: 0.8228 - accuracy: 0.63 - ETA: 0s - loss: 0.8228 - accuracy: 0.63 - ETA: 0s - loss: 0.8191 - accuracy: 0.64 - ETA: 0s - loss: 0.8166 - accuracy: 0.64 - ETA: 0s - loss: 0.8140 - accuracy: 0.65 - ETA: 0s - loss: 0.8162 - accuracy: 0.64 - ETA: 0s - loss: 0.8209 - accuracy: 0.64 - ETA: 0s - loss: 0.8185 - accuracy: 0.64 - ETA: 0s - loss: 0.8133 - accuracy: 0.65 - ETA: 0s - loss: 0.7951 - accuracy: 0.66 - ETA: 0s - loss: 0.8008 - accuracy: 0.66 - ETA: 0s - loss: 0.8091 - accuracy: 0.65 - ETA: 0s - loss: 0.8130 - accuracy: 0.64 - ETA: 0s - loss: 0.8208 - accuracy: 0.64 - ETA: 0s - loss: 0.8223 - accuracy: 0.64 - ETA: 0s - loss: 0.8247 - accuracy: 0.6432\n",
      "Epoch 00989: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8247 - accuracy: 0.6432 - val_loss: 1.0903 - val_accuracy: 0.4878 - lr: 0.0010\n",
      "Epoch 990/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8653 - accuracy: 0.59 - ETA: 0s - loss: 0.8309 - accuracy: 0.62 - ETA: 0s - loss: 0.8402 - accuracy: 0.62 - ETA: 0s - loss: 0.8161 - accuracy: 0.64 - ETA: 0s - loss: 0.8184 - accuracy: 0.64 - ETA: 0s - loss: 0.8160 - accuracy: 0.64 - ETA: 0s - loss: 0.8142 - accuracy: 0.65 - ETA: 0s - loss: 0.8117 - accuracy: 0.65 - ETA: 0s - loss: 0.8138 - accuracy: 0.65 - ETA: 0s - loss: 0.8186 - accuracy: 0.64 - ETA: 0s - loss: 0.8172 - accuracy: 0.65 - ETA: 0s - loss: 0.8105 - accuracy: 0.65 - ETA: 0s - loss: 0.7930 - accuracy: 0.66 - ETA: 0s - loss: 0.7964 - accuracy: 0.66 - ETA: 0s - loss: 0.8053 - accuracy: 0.65 - ETA: 0s - loss: 0.8091 - accuracy: 0.65 - ETA: 0s - loss: 0.8160 - accuracy: 0.65 - ETA: 0s - loss: 0.8202 - accuracy: 0.64 - ETA: 0s - loss: 0.8218 - accuracy: 0.6484\n",
      "Epoch 00990: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8218 - accuracy: 0.6484 - val_loss: 1.1089 - val_accuracy: 0.4915 - lr: 0.0010\n",
      "Epoch 991/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8533 - accuracy: 0.60 - ETA: 0s - loss: 0.8256 - accuracy: 0.63 - ETA: 0s - loss: 0.8402 - accuracy: 0.62 - ETA: 0s - loss: 0.8192 - accuracy: 0.63 - ETA: 0s - loss: 0.8256 - accuracy: 0.63 - ETA: 0s - loss: 0.8193 - accuracy: 0.64 - ETA: 0s - loss: 0.8170 - accuracy: 0.64 - ETA: 0s - loss: 0.8181 - accuracy: 0.64 - ETA: 0s - loss: 0.8216 - accuracy: 0.64 - ETA: 0s - loss: 0.8260 - accuracy: 0.63 - ETA: 0s - loss: 0.8225 - accuracy: 0.64 - ETA: 0s - loss: 0.8149 - accuracy: 0.65 - ETA: 0s - loss: 0.7972 - accuracy: 0.66 - ETA: 0s - loss: 0.8012 - accuracy: 0.66 - ETA: 0s - loss: 0.8095 - accuracy: 0.65 - ETA: 0s - loss: 0.8126 - accuracy: 0.65 - ETA: 0s - loss: 0.8187 - accuracy: 0.64 - ETA: 0s - loss: 0.8215 - accuracy: 0.64 - ETA: 0s - loss: 0.8230 - accuracy: 0.6445\n",
      "Epoch 00991: val_loss did not improve from 0.99131\n",
      "\n",
      "Epoch 00991: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8230 - accuracy: 0.6445 - val_loss: 1.1076 - val_accuracy: 0.4862 - lr: 0.0010\n",
      "Epoch 992/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8598 - accuracy: 0.59 - ETA: 0s - loss: 0.8287 - accuracy: 0.63 - ETA: 0s - loss: 0.8403 - accuracy: 0.63 - ETA: 0s - loss: 0.8181 - accuracy: 0.64 - ETA: 0s - loss: 0.8211 - accuracy: 0.64 - ETA: 0s - loss: 0.8167 - accuracy: 0.65 - ETA: 0s - loss: 0.8135 - accuracy: 0.65 - ETA: 0s - loss: 0.8133 - accuracy: 0.65 - ETA: 0s - loss: 0.8150 - accuracy: 0.65 - ETA: 0s - loss: 0.8199 - accuracy: 0.64 - ETA: 0s - loss: 0.8171 - accuracy: 0.65 - ETA: 0s - loss: 0.8112 - accuracy: 0.65 - ETA: 0s - loss: 0.7928 - accuracy: 0.66 - ETA: 0s - loss: 0.7965 - accuracy: 0.66 - ETA: 0s - loss: 0.8030 - accuracy: 0.65 - ETA: 0s - loss: 0.8071 - accuracy: 0.65 - ETA: 0s - loss: 0.8141 - accuracy: 0.65 - ETA: 0s - loss: 0.8178 - accuracy: 0.65 - ETA: 0s - loss: 0.8203 - accuracy: 0.6493\n",
      "Epoch 00992: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8203 - accuracy: 0.6493 - val_loss: 1.0981 - val_accuracy: 0.4863 - lr: 0.0010\n",
      "Epoch 993/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8515 - accuracy: 0.58 - ETA: 0s - loss: 0.8230 - accuracy: 0.62 - ETA: 0s - loss: 0.8293 - accuracy: 0.63 - ETA: 0s - loss: 0.8060 - accuracy: 0.64 - ETA: 0s - loss: 0.8122 - accuracy: 0.64 - ETA: 0s - loss: 0.8102 - accuracy: 0.64 - ETA: 0s - loss: 0.8099 - accuracy: 0.65 - ETA: 0s - loss: 0.8085 - accuracy: 0.65 - ETA: 0s - loss: 0.8118 - accuracy: 0.64 - ETA: 0s - loss: 0.8194 - accuracy: 0.64 - ETA: 0s - loss: 0.8162 - accuracy: 0.64 - ETA: 0s - loss: 0.8095 - accuracy: 0.65 - ETA: 0s - loss: 0.7915 - accuracy: 0.66 - ETA: 0s - loss: 0.7948 - accuracy: 0.66 - ETA: 0s - loss: 0.8029 - accuracy: 0.65 - ETA: 0s - loss: 0.8073 - accuracy: 0.65 - ETA: 0s - loss: 0.8134 - accuracy: 0.64 - ETA: 0s - loss: 0.8165 - accuracy: 0.64 - ETA: 0s - loss: 0.8186 - accuracy: 0.6449\n",
      "Epoch 00993: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8186 - accuracy: 0.6449 - val_loss: 1.1053 - val_accuracy: 0.4866 - lr: 0.0010\n",
      "Epoch 994/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8666 - accuracy: 0.61 - ETA: 0s - loss: 0.8348 - accuracy: 0.63 - ETA: 0s - loss: 0.8551 - accuracy: 0.62 - ETA: 0s - loss: 0.8308 - accuracy: 0.64 - ETA: 0s - loss: 0.8333 - accuracy: 0.63 - ETA: 0s - loss: 0.8295 - accuracy: 0.64 - ETA: 0s - loss: 0.8245 - accuracy: 0.64 - ETA: 0s - loss: 0.8232 - accuracy: 0.64 - ETA: 0s - loss: 0.8239 - accuracy: 0.64 - ETA: 0s - loss: 0.8290 - accuracy: 0.64 - ETA: 0s - loss: 0.8245 - accuracy: 0.64 - ETA: 0s - loss: 0.8179 - accuracy: 0.65 - ETA: 0s - loss: 0.7989 - accuracy: 0.66 - ETA: 0s - loss: 0.8026 - accuracy: 0.66 - ETA: 0s - loss: 0.8121 - accuracy: 0.65 - ETA: 0s - loss: 0.8153 - accuracy: 0.64 - ETA: 0s - loss: 0.8217 - accuracy: 0.64 - ETA: 0s - loss: 0.8251 - accuracy: 0.64 - ETA: 0s - loss: 0.8263 - accuracy: 0.6425\n",
      "Epoch 00994: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8263 - accuracy: 0.6425 - val_loss: 1.1084 - val_accuracy: 0.4870 - lr: 0.0010\n",
      "Epoch 995/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8666 - accuracy: 0.59 - ETA: 0s - loss: 0.8303 - accuracy: 0.62 - ETA: 0s - loss: 0.8385 - accuracy: 0.62 - ETA: 0s - loss: 0.8127 - accuracy: 0.63 - ETA: 0s - loss: 0.8156 - accuracy: 0.63 - ETA: 0s - loss: 0.8116 - accuracy: 0.64 - ETA: 0s - loss: 0.8111 - accuracy: 0.64 - ETA: 0s - loss: 0.8130 - accuracy: 0.64 - ETA: 0s - loss: 0.8172 - accuracy: 0.64 - ETA: 0s - loss: 0.8222 - accuracy: 0.64 - ETA: 0s - loss: 0.8196 - accuracy: 0.64 - ETA: 0s - loss: 0.8130 - accuracy: 0.65 - ETA: 0s - loss: 0.7950 - accuracy: 0.66 - ETA: 0s - loss: 0.7993 - accuracy: 0.66 - ETA: 0s - loss: 0.8067 - accuracy: 0.65 - ETA: 0s - loss: 0.8098 - accuracy: 0.65 - ETA: 0s - loss: 0.8165 - accuracy: 0.64 - ETA: 0s - loss: 0.8179 - accuracy: 0.64 - ETA: 0s - loss: 0.8197 - accuracy: 0.6483\n",
      "Epoch 00995: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8197 - accuracy: 0.6483 - val_loss: 1.0885 - val_accuracy: 0.4870 - lr: 0.0010\n",
      "Epoch 996/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.8729 - accuracy: 0.61 - ETA: 0s - loss: 0.8318 - accuracy: 0.63 - ETA: 0s - loss: 0.8410 - accuracy: 0.62 - ETA: 0s - loss: 0.8142 - accuracy: 0.64 - ETA: 0s - loss: 0.8214 - accuracy: 0.64 - ETA: 0s - loss: 0.8150 - accuracy: 0.65 - ETA: 0s - loss: 0.8136 - accuracy: 0.65 - ETA: 0s - loss: 0.8109 - accuracy: 0.65 - ETA: 0s - loss: 0.8129 - accuracy: 0.64 - ETA: 0s - loss: 0.8187 - accuracy: 0.64 - ETA: 0s - loss: 0.8162 - accuracy: 0.65 - ETA: 0s - loss: 0.8097 - accuracy: 0.65 - ETA: 0s - loss: 0.7924 - accuracy: 0.66 - ETA: 0s - loss: 0.7946 - accuracy: 0.66 - ETA: 0s - loss: 0.8022 - accuracy: 0.65 - ETA: 0s - loss: 0.8055 - accuracy: 0.65 - ETA: 0s - loss: 0.8131 - accuracy: 0.64 - ETA: 0s - loss: 0.8175 - accuracy: 0.64 - ETA: 0s - loss: 0.8190 - accuracy: 0.6451\n",
      "Epoch 00996: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.8190 - accuracy: 0.6451 - val_loss: 1.1032 - val_accuracy: 0.4821 - lr: 0.0010\n",
      "Epoch 997/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8531 - accuracy: 0.60 - ETA: 0s - loss: 0.8147 - accuracy: 0.63 - ETA: 0s - loss: 0.8211 - accuracy: 0.63 - ETA: 0s - loss: 0.8024 - accuracy: 0.64 - ETA: 0s - loss: 0.8070 - accuracy: 0.64 - ETA: 0s - loss: 0.8060 - accuracy: 0.65 - ETA: 0s - loss: 0.8069 - accuracy: 0.65 - ETA: 0s - loss: 0.8051 - accuracy: 0.65 - ETA: 0s - loss: 0.8083 - accuracy: 0.65 - ETA: 0s - loss: 0.8125 - accuracy: 0.65 - ETA: 0s - loss: 0.8097 - accuracy: 0.65 - ETA: 0s - loss: 0.8036 - accuracy: 0.66 - ETA: 0s - loss: 0.7851 - accuracy: 0.67 - ETA: 0s - loss: 0.7879 - accuracy: 0.67 - ETA: 0s - loss: 0.7993 - accuracy: 0.66 - ETA: 0s - loss: 0.8039 - accuracy: 0.65 - ETA: 0s - loss: 0.8139 - accuracy: 0.65 - ETA: 0s - loss: 0.8171 - accuracy: 0.6504\n",
      "Epoch 00997: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8171 - accuracy: 0.6504 - val_loss: 1.1076 - val_accuracy: 0.4813 - lr: 0.0010\n",
      "Epoch 998/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8965 - accuracy: 0.58 - ETA: 0s - loss: 0.8539 - accuracy: 0.62 - ETA: 0s - loss: 0.8522 - accuracy: 0.62 - ETA: 0s - loss: 0.8245 - accuracy: 0.64 - ETA: 0s - loss: 0.8256 - accuracy: 0.64 - ETA: 0s - loss: 0.8209 - accuracy: 0.64 - ETA: 0s - loss: 0.8161 - accuracy: 0.65 - ETA: 0s - loss: 0.8132 - accuracy: 0.65 - ETA: 0s - loss: 0.8172 - accuracy: 0.65 - ETA: 0s - loss: 0.8206 - accuracy: 0.64 - ETA: 0s - loss: 0.8178 - accuracy: 0.65 - ETA: 0s - loss: 0.8120 - accuracy: 0.65 - ETA: 0s - loss: 0.7940 - accuracy: 0.66 - ETA: 0s - loss: 0.7996 - accuracy: 0.66 - ETA: 0s - loss: 0.8082 - accuracy: 0.65 - ETA: 0s - loss: 0.8124 - accuracy: 0.65 - ETA: 0s - loss: 0.8193 - accuracy: 0.64 - ETA: 0s - loss: 0.8221 - accuracy: 0.64 - ETA: 0s - loss: 0.8230 - accuracy: 0.6470\n",
      "Epoch 00998: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8230 - accuracy: 0.6470 - val_loss: 1.0888 - val_accuracy: 0.4915 - lr: 0.0010\n",
      "Epoch 999/1000\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.8579 - accuracy: 0.61 - ETA: 0s - loss: 0.8283 - accuracy: 0.64 - ETA: 0s - loss: 0.8365 - accuracy: 0.64 - ETA: 0s - loss: 0.8098 - accuracy: 0.65 - ETA: 0s - loss: 0.8140 - accuracy: 0.64 - ETA: 0s - loss: 0.8106 - accuracy: 0.65 - ETA: 0s - loss: 0.8104 - accuracy: 0.65 - ETA: 0s - loss: 0.8085 - accuracy: 0.65 - ETA: 0s - loss: 0.8125 - accuracy: 0.65 - ETA: 0s - loss: 0.8205 - accuracy: 0.64 - ETA: 0s - loss: 0.8164 - accuracy: 0.65 - ETA: 0s - loss: 0.8095 - accuracy: 0.65 - ETA: 0s - loss: 0.7912 - accuracy: 0.66 - ETA: 0s - loss: 0.7966 - accuracy: 0.66 - ETA: 0s - loss: 0.8050 - accuracy: 0.65 - ETA: 0s - loss: 0.8088 - accuracy: 0.65 - ETA: 0s - loss: 0.8151 - accuracy: 0.65 - ETA: 0s - loss: 0.8175 - accuracy: 0.6501\n",
      "Epoch 00999: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8190 - accuracy: 0.6489 - val_loss: 1.0932 - val_accuracy: 0.4923 - lr: 0.0010\n",
      "Epoch 1000/1000\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8691 - accuracy: 0.59 - ETA: 0s - loss: 0.8406 - accuracy: 0.62 - ETA: 0s - loss: 0.8483 - accuracy: 0.62 - ETA: 0s - loss: 0.8215 - accuracy: 0.63 - ETA: 0s - loss: 0.8240 - accuracy: 0.64 - ETA: 0s - loss: 0.8195 - accuracy: 0.64 - ETA: 0s - loss: 0.8172 - accuracy: 0.65 - ETA: 0s - loss: 0.8171 - accuracy: 0.65 - ETA: 0s - loss: 0.8183 - accuracy: 0.65 - ETA: 0s - loss: 0.8232 - accuracy: 0.64 - ETA: 0s - loss: 0.8198 - accuracy: 0.65 - ETA: 0s - loss: 0.8137 - accuracy: 0.65 - ETA: 0s - loss: 0.7959 - accuracy: 0.66 - ETA: 0s - loss: 0.8000 - accuracy: 0.66 - ETA: 0s - loss: 0.8085 - accuracy: 0.65 - ETA: 0s - loss: 0.8119 - accuracy: 0.65 - ETA: 0s - loss: 0.8185 - accuracy: 0.64 - ETA: 0s - loss: 0.8206 - accuracy: 0.64 - ETA: 0s - loss: 0.8214 - accuracy: 0.6483\n",
      "Epoch 01000: val_loss did not improve from 0.99131\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.8214 - accuracy: 0.6483 - val_loss: 1.1034 - val_accuracy: 0.4860 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24eda800eb8>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scikitplot.metrics import plot_confusion_matrix, plot_roc\n",
    "\n",
    "\n",
    "class PerformanceVisualizationCallback(Callback):\n",
    "    def __init__(self, model, validation_data, image_dir):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.validation_data = validation_data\n",
    "        \n",
    "        os.makedirs(image_dir, exist_ok=True)\n",
    "        self.image_dir = image_dir\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = np.asarray(self.model.predict(self.validation_data[0]))\n",
    "        y_true = self.validation_data[1]             \n",
    "        y_pred_class = np.argmax(y_pred, axis=1)\n",
    "\n",
    "        # plot and save confusion matrix\n",
    "        fig, ax = plt.subplots(figsize=(16,12))\n",
    "        chart = plot_confusion_matrix(y_true, y_pred_class, ax=ax)\n",
    "        fig.savefig(os.path.join(self.image_dir, f'confusion_matrix_epoch_{epoch}'))\n",
    "        plt.display(chart)\n",
    "        plt.show()\n",
    "        \n",
    "       # plot and save roc curve\n",
    "        fig, ax = plt.subplots(figsize=(16,12))\n",
    "        plot_roc(y_true, y_pred, ax=ax)\n",
    "        chart = fig.savefig(os.path.join(self.image_dir, f'roc_curve_epoch_{epoch}'))\n",
    "        plt.display(chart)\n",
    "        plt.show()\n",
    "        \n",
    "logdir = \"logs\\\\scalars\\\\\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "weight_path=\"{}_weights.best.hdf5\".format('stroke_lstm_model')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=10, verbose=1, mode='auto', epsilon=0.0001, cooldown=5, min_lr=0.001)\n",
    "early = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=100) \n",
    "performance_cbk = PerformanceVisualizationCallback(\n",
    "                      model=model,\n",
    "                      validation_data=v_dataset,\n",
    "                      image_dir='performance_vizualizations')\n",
    "\n",
    "callbacks_list = [checkpoint\n",
    "#                   , early\n",
    "                  , reduceLROnPlat\n",
    "                  , tensorboard_callback\n",
    "                  \n",
    "                 ]\n",
    "\n",
    "\n",
    "from IPython.display import clear_output\n",
    "model.fit(train_dataset,\n",
    "                      validation_data = v_dataset, \n",
    "#                       batch_size = 10,\n",
    "                      epochs = 1000,\n",
    "                      use_multiprocessing = True,\n",
    "                      callbacks = callbacks_list)\n",
    "\n",
    "# model.fit([train_X, train_X2], [train_y, train_y],\n",
    "#                       validation_data = ([valid_X, valid_X2], [valid_y, valid_y]), \n",
    "#                       batch_size = batch_size,\n",
    "#                       epochs = 500,\n",
    "#                       callbacks = callbacks_list)\n",
    "\n",
    "#clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9b4790925984514e64ca5a9b46de8b309062e0cf",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] 0.8821 - accuracy: 0.66 - 0s 16ms/step - loss: 0.9204 - accuracy: 0.61 - 0s 16ms/step - loss: 0.9190 - accuracy: 0.61 - 0s 17ms/step - loss: 0.9277 - accuracy: 0.6127\n",
      "{'loss': 0.9277337193489075, 'accuracy': 0.6127402782440186}\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(weight_path)\n",
    "lstm_results = model.evaluate(test_dataset, return_dict=True)\n",
    "print(lstm_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9277337193489075, 'accuracy': 0.6127402782440186}\n"
     ]
    }
   ],
   "source": [
    "print(lstm_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./trained_model.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c3340d6d6ce75585f90c98f1728b1cd664d7f33f"
   },
   "source": [
    "Load and normalize the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test(ts_length = 150000):\n",
    "    base_dir = 'input/test/'\n",
    "    test_files = [f for f in listdir(base_dir) if isfile(join(base_dir, f))]\n",
    "\n",
    "    ts = np.empty([len(test_files), ts_length])\n",
    "    ids = []\n",
    "    \n",
    "    i = 0\n",
    "    for f in tqdm_notebook(test_files):\n",
    "        ids.append(splitext(f)[0])\n",
    "        t_df = pd.read_csv(base_dir + f, dtype={\"acoustic_data\": np.int8})\n",
    "        ts[i, :] = t_df['acoustic_data'].values\n",
    "        i = i + 1\n",
    "\n",
    "    return ts, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0f005579ea08913f4f68a3749bd761df6cef2b1b"
   },
   "outputs": [],
   "source": [
    "test_data, test_ids = load_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0c3b7a864a9f53af142a08883def46c3866c5464"
   },
   "outputs": [],
   "source": [
    "X_test = test_data\n",
    "X_test = np.expand_dims(X_test, 2)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bf9b36929e5228d4d94b3b7ad1b9011bf088ac44"
   },
   "source": [
    "Load best model and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "435449fda2bf96635e67d69f56227e140c4cea99"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9aaf9fb44edba5879a75c68820527d9180d2b3c6"
   },
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({'seg_id': test_ids, 'time_to_failure': y_pred[:, 0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9b9d5c63161f637de2e39b59e8e4d7c2f3049581"
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"submission.csv\"> Download File </a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb.transform([-1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "nn = np.array([[1., 0.,2], [2., 1.,3], [0., 0.,4]])\n",
    "print(nn[1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "print(valid_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(valid_X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset.take(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, \n",
    "                          loss='categorical_crossentropy',\n",
    "                          loss_weights=[1., 1.]\n",
    "#                           loss_weights=[1.]\n",
    "#               \n",
    "                            , metrics=[Recall(thresholds=0.5, class_id=0, top_k=1)\n",
    "                                 , Recall(thresholds=0.5, class_id=2, top_k=1)\n",
    "                                   , Precision(thresholds=0.5, class_id=0, top_k=1)\n",
    "                                  , Precision(thresholds=0.5, class_id=2, top_k=1)\n",
    "                                  ]\n",
    "             )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
