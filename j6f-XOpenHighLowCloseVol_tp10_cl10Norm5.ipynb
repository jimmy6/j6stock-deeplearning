{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xfile = 'F:\\workspace\\j6stock\\XOpenHighLowCloseVol_tp10_cl10.txt'\n",
    "lstm_size = 120         # 3 times the amount of channels\n",
    "lstm_layers = 2        # Number of layers\n",
    "batch_size = 2048       # Batch size\n",
    "learning_rate = 0.001  #0.0001  # Learning rate (default is 0.001)\n",
    "epochs = 140\n",
    "\n",
    "# Fixed\n",
    "#amount_of_features_cvs = 5 # cvs with prefix with feature column\n",
    "#n_channels = amount_of_features\n",
    "seq_len = lstm_size\n",
    "y_column = 6\n",
    "compute_val_at = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "C:\\Users\\lai\\Anaconda3\\lib\\site-packages\\theano\\configdefaults.py:560: UserWarning: DeprecationWarning: there is no c++ compiler.This is deprecated and with Theano 0.11 a c++ compiler will be mandatory\n",
      "  warnings.warn(\"DeprecationWarning: there is no c++ compiler.\"\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt2\n",
    "import pandas as pd\n",
    "from pandas import datetime\n",
    "import math, time\n",
    "import itertools\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import load_model\n",
    "import keras\n",
    "import pandas_datareader.data as web\n",
    "import h5py\n",
    "import os\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stock_data(normalize=True, ma=[]):\n",
    "    \"\"\"\n",
    "    Return a dataframe of that stock and normalize all the values. \n",
    "    (Optional: create moving average)\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filepath_or_buffer  = xfile )\n",
    "    #TODO Use previous close instead of open\n",
    "    df['change'] = df['close'] - df['open']\n",
    "    for i, row in df.iterrows():\n",
    "        df.at[i, 'high'] = df.at[i, 'high'] - (df.at[i, 'open'] if df.at[i, 'open'] > df.at[i, 'close'] else df.at[i, 'close'])\n",
    "        df.at[i, 'low'] = (df.at[i, 'close'] if df.at[i, 'close'] < df.at[i, 'open'] else df.at[i, 'open']) - df.at[i, 'low']\n",
    "    df.dropna(inplace=True)\n",
    "    df = df.drop('open', axis=1)\n",
    "    # Moving Average    \n",
    "    if ma != []:\n",
    "        for moving in ma:\n",
    "            df['{}ma'.format(moving)] = df['close'].rolling(window=moving).mean()\n",
    "    df.dropna(inplace=True)\n",
    "    if normalize:\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        #df['open'] = min_max_scaler.fit_transform(df.open.values.reshape(-1,1))\n",
    "        df['high'] = min_max_scaler.fit_transform(df.high.values.reshape(-1,1))\n",
    "        df['low'] = min_max_scaler.fit_transform(df.low.values.reshape(-1,1))\n",
    "        #df['vol'] = min_max_scaler.fit_transform(df.vol.values.reshape(-1,1))\n",
    "        df['close'] = min_max_scaler.fit_transform(df['close'].values.reshape(-1,1))\n",
    "        #df['change'] = min_max_scaler.fit_transform(df['change'].values.reshape(-1,1))\n",
    "        if ma != []:\n",
    "            for moving in ma:\n",
    "                df['{}ma'.format(moving)] = min_max_scaler.fit_transform(df['{}ma'.format(moving)].values.reshape(-1,1))  \n",
    "    df.dropna(inplace=True)\n",
    "               \n",
    "    # Move y_result to the rightmost for the ease of training\n",
    "    adj_close = df['y_result']\n",
    "    df.drop(labels=['y_result'], axis=1, inplace=True)\n",
    "    df = pd.concat([df, adj_close], axis=1)\n",
    "      \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = get_stock_data( ma=[50, 100, 200])\n",
    "amount_of_features = len(df.columns)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_stock(df):\n",
    "    print(df.head())\n",
    "    plt.subplot(211)\n",
    "    plt.plot(df['close'], color='red', label='Close')\n",
    "    plt.legend(loc='best')\n",
    "    plt.subplot(212)\n",
    "    plt.plot(df['change'], color='blue', label='Percentage change')\n",
    "    plt.legend(loc='best')\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    ax1.plot(df['high'], color='red', label='high')\n",
    "    ax1.legend(loc='best')\n",
    " \n",
    "    ax2.plot(df['low'], color='red', label='low')\n",
    "    ax2.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             high           low     close    change      50ma     100ma  \\\n",
      "199  4.445337e-14  6.182380e-03  0.357085 -0.000150  0.351429  0.351070   \n",
      "200  2.002002e-03  1.545595e-02  0.356606 -0.000060  0.351433  0.351063   \n",
      "201  1.301301e-02  7.727975e-03  0.356893  0.000035  0.351445  0.351060   \n",
      "202  4.445337e-14  1.545595e-03  0.357133  0.000015  0.351502  0.351082   \n",
      "203  6.006006e-03  6.863821e-14  0.358138  0.000095  0.351587  0.351141   \n",
      "\n",
      "        200ma  y_result  \n",
      "199  0.346428         0  \n",
      "200  0.346426         0  \n",
      "201  0.346424         0  \n",
      "202  0.346433         0  \n",
      "203  0.346448         0  \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAD8CAYAAAChHgmuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2PGlFAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_stock(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEaCAYAAADwlvf0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYoizgCZbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr = df.corr()\n",
    "ax = sns.heatmap(corr, cmap=\"YlGnBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(stock, seq_len):\n",
    "    print (\"Amount of features = {}\".format(amount_of_features))\n",
    "    data = stock.as_matrix()\n",
    "    sequence_length = seq_len + 1 # index starting from 0\n",
    "    x_result = []\n",
    "    y_result = []\n",
    "    for index in range(seq_len, len(data) ): # maxmimum date = lastest date - sequence length\n",
    "        x_result.append(data[index-seq_len: index,:-1]) # index : index + 22days\n",
    "        y_result.append(data[index ,amount_of_features]);\n",
    "\n",
    "    #print('---', data[0])\n",
    "    #print('---', x_result[0])\n",
    "    #print('---', y_result[0])\n",
    "    x_result = np.array(x_result)\n",
    "    y_result = np.array(y_result)\n",
    "    row = round(0.6 * y_result.shape[0]) # 80% split\n",
    "    print (\"Amount of training data = {}\".format(0.9 * x_result.shape[0]))\n",
    "    print (\"Amount of testing data = {}\".format(0.1 * y_result.shape[0]))\n",
    "     \n",
    "    X_train = x_result[:int(row), :] # 90% date\n",
    "    y_train = y_result[:int(row)] # 90% date\n",
    "        \n",
    "\n",
    "    X_test = x_result[int(row):, :]\n",
    "    y_test = y_result[int(row):]\n",
    "    # filter for 1 and -1 for validation only\n",
    "    X_test = X_test[y_test[:]!=0,:]\n",
    "    y_test = y_test[y_test[:]!=0]\n",
    "    #print(result.shape[0], len(y_result), int(row), y_result[int(row):])\n",
    "    #X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], amount_of_features-1))\n",
    "    #X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], amount_of_features-1))\n",
    "    \n",
    "    return [X_train, y_train, X_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of features = 7\n",
      "Amount of training data = 261918.9\n",
      "Amount of testing data = 29102.100000000002\n",
      "(174613, 120, 7) (174613,) (70626, 120, 7) (70626,)\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit([1, 0, -1])\n",
    "\n",
    "X_tr, lab_tr, X_vld, lab_vld = load_data(df, seq_len)\n",
    "y_tr = lb.transform(lab_tr)\n",
    "y_vld = lb.transform(lab_vld)\n",
    "print(X_tr.shape, lab_tr.shape, X_vld.shape, lab_vld.shape)\n",
    "print(amount_of_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(X, y, batch_size = 100):\n",
    "\t\"\"\" Return a generator for batches \"\"\"\n",
    "\tn_batches = len(X) // batch_size\n",
    "\tX, y = X[:n_batches*batch_size], y[:n_batches*batch_size]\n",
    "\n",
    "\t# Loop over batches and yield\n",
    "\tfor b in range(0, len(X), batch_size):\n",
    "\t\tyield X[b:b+batch_size], y[b:b+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "n_channels = amount_of_features\n",
    "n_classes = lb.transform([1]).shape[1]\n",
    "# Construct placeholders\n",
    "with graph.as_default():\n",
    "    inputs_ = tf.placeholder(tf.float32, [None, seq_len, n_channels], name = 'inputs')\n",
    "    labels_ = tf.placeholder(tf.float32, [None, n_classes], name = 'labels')\n",
    "    keep_prob_ = tf.placeholder(tf.float32, name = 'keep')\n",
    "    learning_rate_ = tf.placeholder(tf.float32, name = 'learning_rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct inputs to LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    # Construct the LSTM inputs and LSTM cells\n",
    "    lstm_in = tf.transpose(inputs_, [1,0,2]) # reshape into (seq_len, N, channels)\n",
    "    lstm_in = tf.reshape(lstm_in, [-1, n_channels]) # Now (seq_len*N, n_channels)\n",
    "    \n",
    "    # To cells\n",
    "    lstm_in = tf.layers.dense(lstm_in, lstm_size, activation=None) # or tf.nn.relu, tf.nn.sigmoid, tf.nn.tanh?\n",
    "    \n",
    "    # Open up the tensor into a list of seq_len pieces\n",
    "    lstm_in = tf.split(lstm_in, seq_len, 0)\n",
    "    \n",
    "    # Add LSTM layers\n",
    "    lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "    drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob_)\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([drop] * lstm_layers)\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define forward pass, cost function and optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    outputs, final_state = tf.contrib.rnn.static_rnn(cell, lstm_in, dtype=tf.float32,\n",
    "                                                     initial_state = initial_state)\n",
    "    \n",
    "    # We only need the last output tensor to pass into a classifier\n",
    "    logits = tf.layers.dense(outputs[-1], n_classes, name='logits')\n",
    "    \n",
    "    # Cost function and optimizer\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels_))\n",
    "    #optimizer = tf.train.AdamOptimizer(learning_rate_).minimize(cost) # No grad clipping\n",
    "    \n",
    "    # Grad clipping\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate_)\n",
    "\n",
    "    gradients = train_op.compute_gradients(cost)\n",
    "    capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients]\n",
    "    optimizer = train_op.apply_gradients(capped_gradients)\n",
    "    \n",
    "    # Accuracy\n",
    "    correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if (os.path.exists('checkpoints') == False):\n",
    "    !mkdir checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/har-lstm.ckpt\n",
      "Epoch: 0/140 Iteration: 5 Train loss: 0.964708 Train acc: 0.516113\n",
      "Epoch: 0/140 Iteration: 10 Train loss: 0.971878 Train acc: 0.484863\n",
      "Epoch: 0/140 Iteration: 15 Train loss: 1.035203 Train acc: 0.481445\n",
      "Epoch: 0/140 Iteration: 20 Train loss: 0.998256 Train acc: 0.501465\n",
      "Epoch: 0/140 Iteration: 25 Train loss: 1.105992 Train acc: 0.381836\n",
      "Epoch: 0/140 Iteration: 30 Train loss: 0.979583 Train acc: 0.515625\n",
      "Epoch: 0/140 Iteration: 35 Train loss: 0.904767 Train acc: 0.591309\n",
      "Epoch: 0/140 Iteration: 40 Train loss: 0.863788 Train acc: 0.644531\n",
      "Epoch: 0/140 Iteration: 45 Train loss: 1.030351 Train acc: 0.457031\n",
      "Epoch: 0/140 Iteration: 50 Train loss: 0.846309 Train acc: 0.612305\n",
      "Epoch: 0/140 Iteration: 55 Train loss: 0.942745 Train acc: 0.574219\n",
      "Epoch: 0/140 Iteration: 60 Train loss: 1.147146 Train acc: 0.332031\n",
      "Epoch: 0/140 Iteration: 65 Train loss: 0.985348 Train acc: 0.376953\n",
      "Epoch: 0/140 Iteration: 70 Train loss: 0.987117 Train acc: 0.465820\n",
      "Epoch: 0/140 Iteration: 75 Train loss: 0.948612 Train acc: 0.482910\n",
      "Epoch: 0/140 Iteration: 80 Train loss: 1.055750 Train acc: 0.449219\n",
      "Epoch: 0/140 Iteration: 85 Train loss: 1.026112 Train acc: 0.467285\n",
      "Epoch: 1/140 Iteration: 90 Train loss: 0.968811 Train acc: 0.501465\n",
      "Epoch: 1/140 Iteration: 95 Train loss: 0.970581 Train acc: 0.508789\n",
      "Epoch: 1/140 Iteration: 100 Train loss: 1.037083 Train acc: 0.483398\n",
      "Epoch: 1/140 Iteration: 105 Train loss: 1.002481 Train acc: 0.508789\n",
      "Epoch: 1/140 Iteration: 110 Train loss: 1.103352 Train acc: 0.396973\n",
      "Epoch: 1/140 Iteration: 115 Train loss: 1.009060 Train acc: 0.507812\n",
      "Epoch: 1/140 Iteration: 120 Train loss: 0.902480 Train acc: 0.600586\n",
      "Epoch: 1/140 Iteration: 125 Train loss: 0.884706 Train acc: 0.652344\n",
      "Epoch: 1/140 Iteration: 130 Train loss: 1.038885 Train acc: 0.469727\n",
      "Epoch: 1/140 Iteration: 135 Train loss: 0.866973 Train acc: 0.585938\n",
      "Epoch: 1/140 Iteration: 140 Train loss: 0.950087 Train acc: 0.575195\n",
      "Epoch: 1/140 Iteration: 145 Train loss: 1.135399 Train acc: 0.338379\n",
      "Epoch: 1/140 Iteration: 150 Train loss: 0.993216 Train acc: 0.347168\n",
      "Epoch: 1/140 Iteration: 155 Train loss: 0.975863 Train acc: 0.483398\n",
      "Epoch: 1/140 Iteration: 160 Train loss: 0.953509 Train acc: 0.442871\n",
      "Epoch: 1/140 Iteration: 165 Train loss: 1.070855 Train acc: 0.440430\n",
      "Epoch: 1/140 Iteration: 170 Train loss: 1.019335 Train acc: 0.471191\n",
      "Epoch: 2/140 Iteration: 175 Train loss: 0.965897 Train acc: 0.531250\n",
      "Epoch: 2/140 Iteration: 180 Train loss: 0.972284 Train acc: 0.485352\n",
      "Epoch: 2/140 Iteration: 185 Train loss: 1.047928 Train acc: 0.469727\n",
      "Epoch: 2/140 Iteration: 190 Train loss: 0.998084 Train acc: 0.507324\n",
      "Epoch: 2/140 Iteration: 195 Train loss: 1.094709 Train acc: 0.382324\n",
      "Epoch: 2/140 Iteration: 200 Train loss: 0.985224 Train acc: 0.514160\n",
      "Epoch: 2/140 Iteration: 205 Train loss: 0.904175 Train acc: 0.594727\n",
      "Epoch: 2/140 Iteration: 210 Train loss: 0.867719 Train acc: 0.637207\n",
      "Epoch: 2/140 Iteration: 215 Train loss: 1.020457 Train acc: 0.460449\n",
      "Epoch: 2/140 Iteration: 220 Train loss: 0.838587 Train acc: 0.618652\n",
      "Epoch: 2/140 Iteration: 225 Train loss: 0.937039 Train acc: 0.580566\n",
      "Epoch: 2/140 Iteration: 230 Train loss: 1.095993 Train acc: 0.362305\n",
      "Epoch: 2/140 Iteration: 235 Train loss: 0.978139 Train acc: 0.391602\n",
      "Epoch: 2/140 Iteration: 240 Train loss: 0.979441 Train acc: 0.500000\n",
      "Epoch: 2/140 Iteration: 245 Train loss: 0.955637 Train acc: 0.456055\n",
      "Epoch: 2/140 Iteration: 250 Train loss: 1.050363 Train acc: 0.468262\n",
      "Epoch: 2/140 Iteration: 255 Train loss: 1.026760 Train acc: 0.479004\n",
      "Epoch: 3/140 Iteration: 260 Train loss: 0.965270 Train acc: 0.509277\n",
      "Epoch: 3/140 Iteration: 265 Train loss: 0.963196 Train acc: 0.500000\n",
      "Epoch: 3/140 Iteration: 270 Train loss: 1.029198 Train acc: 0.495605\n",
      "Epoch: 3/140 Iteration: 275 Train loss: 1.027932 Train acc: 0.479004\n",
      "Epoch: 3/140 Iteration: 280 Train loss: 1.101443 Train acc: 0.388672\n",
      "Epoch: 3/140 Iteration: 285 Train loss: 0.989572 Train acc: 0.504883\n",
      "Epoch: 3/140 Iteration: 290 Train loss: 0.895217 Train acc: 0.593750\n",
      "Epoch: 3/140 Iteration: 295 Train loss: 0.861377 Train acc: 0.651855\n",
      "Epoch: 3/140 Iteration: 300 Train loss: 1.036239 Train acc: 0.451172\n",
      "Epoch: 3/140 Iteration: 305 Train loss: 0.841911 Train acc: 0.637207\n",
      "Epoch: 3/140 Iteration: 310 Train loss: 0.941385 Train acc: 0.589844\n",
      "Epoch: 3/140 Iteration: 315 Train loss: 1.092557 Train acc: 0.366699\n",
      "Epoch: 3/140 Iteration: 320 Train loss: 0.979996 Train acc: 0.397949\n",
      "Epoch: 3/140 Iteration: 325 Train loss: 0.988337 Train acc: 0.457031\n",
      "Epoch: 3/140 Iteration: 330 Train loss: 0.950251 Train acc: 0.477051\n",
      "Epoch: 3/140 Iteration: 335 Train loss: 1.047445 Train acc: 0.457031\n",
      "Epoch: 3/140 Iteration: 340 Train loss: 1.019362 Train acc: 0.435059\n",
      "Epoch: 4/140 Iteration: 345 Train loss: 0.968359 Train acc: 0.520020\n",
      "Epoch: 4/140 Iteration: 350 Train loss: 0.962857 Train acc: 0.498047\n",
      "Epoch: 4/140 Iteration: 355 Train loss: 1.044286 Train acc: 0.471680\n",
      "Epoch: 4/140 Iteration: 360 Train loss: 1.028564 Train acc: 0.479492\n",
      "Epoch: 4/140 Iteration: 365 Train loss: 1.119695 Train acc: 0.371094\n",
      "Epoch: 4/140 Iteration: 370 Train loss: 0.994002 Train acc: 0.502441\n",
      "Epoch: 4/140 Iteration: 375 Train loss: 0.912625 Train acc: 0.594727\n",
      "Epoch: 4/140 Iteration: 380 Train loss: 0.874797 Train acc: 0.653320\n",
      "Epoch: 4/140 Iteration: 385 Train loss: 1.025319 Train acc: 0.466309\n",
      "Epoch: 4/140 Iteration: 390 Train loss: 0.846487 Train acc: 0.617676\n",
      "Epoch: 4/140 Iteration: 395 Train loss: 0.932026 Train acc: 0.582520\n",
      "Epoch: 4/140 Iteration: 400 Train loss: 1.101760 Train acc: 0.359863\n",
      "Epoch: 4/140 Iteration: 405 Train loss: 0.986161 Train acc: 0.374023\n",
      "Epoch: 4/140 Iteration: 410 Train loss: 0.982061 Train acc: 0.454590\n",
      "Epoch: 4/140 Iteration: 415 Train loss: 0.948088 Train acc: 0.474121\n",
      "Epoch: 4/140 Iteration: 420 Train loss: 1.061085 Train acc: 0.434082\n",
      "Epoch: 4/140 Iteration: 425 Train loss: 1.030194 Train acc: 0.433105\n",
      "Epoch: 5/140 Iteration: 430 Train loss: 0.978620 Train acc: 0.503418\n",
      "Epoch: 5/140 Iteration: 435 Train loss: 0.965194 Train acc: 0.503906\n",
      "Epoch: 5/140 Iteration: 440 Train loss: 1.022263 Train acc: 0.490234\n",
      "Epoch: 5/140 Iteration: 445 Train loss: 1.022832 Train acc: 0.486328\n",
      "Epoch: 5/140 Iteration: 450 Train loss: 1.097906 Train acc: 0.395996\n",
      "Epoch: 5/140 Iteration: 455 Train loss: 0.980281 Train acc: 0.516602\n",
      "Epoch: 5/140 Iteration: 460 Train loss: 0.900441 Train acc: 0.590332\n",
      "Epoch: 5/140 Iteration: 465 Train loss: 0.868053 Train acc: 0.652832\n",
      "Epoch: 5/140 Iteration: 470 Train loss: 1.031440 Train acc: 0.428223\n",
      "Epoch: 5/140 Iteration: 475 Train loss: 0.842318 Train acc: 0.625977\n",
      "Epoch: 5/140 Iteration: 480 Train loss: 0.932159 Train acc: 0.590820\n",
      "Epoch: 5/140 Iteration: 485 Train loss: 1.120889 Train acc: 0.346191\n",
      "Epoch: 5/140 Iteration: 490 Train loss: 0.980734 Train acc: 0.385254\n",
      "Epoch: 5/140 Iteration: 495 Train loss: 0.985426 Train acc: 0.437012\n",
      "Epoch: 5/140 Iteration: 500 Train loss: 0.943197 Train acc: 0.477539\n",
      "Epoch: 5/140 Iteration: 505 Train loss: 1.052946 Train acc: 0.445801\n",
      "Epoch: 5/140 Iteration: 510 Train loss: 1.027705 Train acc: 0.426758\n",
      "Epoch: 6/140 Iteration: 515 Train loss: 0.976865 Train acc: 0.518066\n",
      "Epoch: 6/140 Iteration: 520 Train loss: 0.964468 Train acc: 0.511230\n",
      "Epoch: 6/140 Iteration: 525 Train loss: 1.039362 Train acc: 0.476074\n",
      "Epoch: 6/140 Iteration: 530 Train loss: 1.025340 Train acc: 0.480957\n",
      "Epoch: 6/140 Iteration: 535 Train loss: 1.114335 Train acc: 0.372070\n",
      "Epoch: 6/140 Iteration: 540 Train loss: 0.979939 Train acc: 0.508789\n",
      "Epoch: 6/140 Iteration: 545 Train loss: 0.896347 Train acc: 0.586914\n",
      "Epoch: 6/140 Iteration: 550 Train loss: 0.876743 Train acc: 0.650391\n",
      "Epoch: 6/140 Iteration: 555 Train loss: 1.022213 Train acc: 0.459961\n",
      "Epoch: 6/140 Iteration: 560 Train loss: 0.845651 Train acc: 0.602539\n",
      "Epoch: 6/140 Iteration: 565 Train loss: 0.925942 Train acc: 0.594727\n",
      "Epoch: 6/140 Iteration: 570 Train loss: 1.138310 Train acc: 0.352539\n",
      "Epoch: 6/140 Iteration: 575 Train loss: 0.991643 Train acc: 0.372559\n",
      "Epoch: 6/140 Iteration: 580 Train loss: 0.976176 Train acc: 0.437988\n",
      "Epoch: 6/140 Iteration: 585 Train loss: 0.943293 Train acc: 0.468750\n",
      "Epoch: 6/140 Iteration: 590 Train loss: 1.063415 Train acc: 0.400879\n",
      "Epoch: 6/140 Iteration: 595 Train loss: 1.037457 Train acc: 0.419922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/140 Iteration: 600 Train loss: 0.964768 Train acc: 0.522461\n",
      "Epoch: 7/140 Iteration: 605 Train loss: 0.973223 Train acc: 0.490234\n",
      "Epoch: 7/140 Iteration: 610 Train loss: 1.033633 Train acc: 0.472168\n",
      "Epoch: 7/140 Iteration: 615 Train loss: 1.015894 Train acc: 0.495605\n",
      "Epoch: 7/140 Iteration: 620 Train loss: 1.119873 Train acc: 0.367188\n",
      "Epoch: 7/140 Iteration: 625 Train loss: 0.971027 Train acc: 0.526855\n",
      "Epoch: 7/140 Iteration: 630 Train loss: 0.889301 Train acc: 0.599121\n",
      "Epoch: 7/140 Iteration: 635 Train loss: 0.874935 Train acc: 0.649414\n",
      "Epoch: 7/140 Iteration: 640 Train loss: 1.022703 Train acc: 0.455566\n",
      "Epoch: 7/140 Iteration: 645 Train loss: 0.851677 Train acc: 0.601562\n",
      "Epoch: 7/140 Iteration: 650 Train loss: 0.931145 Train acc: 0.588379\n",
      "Epoch: 7/140 Iteration: 655 Train loss: 1.130613 Train acc: 0.362305\n",
      "Epoch: 7/140 Iteration: 660 Train loss: 0.985632 Train acc: 0.366699\n",
      "Epoch: 7/140 Iteration: 665 Train loss: 0.971425 Train acc: 0.448242\n",
      "Epoch: 7/140 Iteration: 670 Train loss: 0.954140 Train acc: 0.468750\n",
      "Epoch: 7/140 Iteration: 675 Train loss: 1.065694 Train acc: 0.436523\n",
      "Epoch: 7/140 Iteration: 680 Train loss: 1.022086 Train acc: 0.459961\n",
      "Epoch: 8/140 Iteration: 685 Train loss: 0.969697 Train acc: 0.519531\n",
      "Epoch: 8/140 Iteration: 690 Train loss: 0.971807 Train acc: 0.493652\n",
      "Epoch: 8/140 Iteration: 695 Train loss: 1.026335 Train acc: 0.480469\n",
      "Epoch: 8/140 Iteration: 700 Train loss: 0.999959 Train acc: 0.509766\n",
      "Epoch: 8/140 Iteration: 705 Train loss: 1.101923 Train acc: 0.389648\n",
      "Epoch: 8/140 Iteration: 710 Train loss: 0.975918 Train acc: 0.523438\n",
      "Epoch: 8/140 Iteration: 715 Train loss: 0.895182 Train acc: 0.589844\n",
      "Epoch: 8/140 Iteration: 720 Train loss: 0.864120 Train acc: 0.653809\n",
      "Epoch: 8/140 Iteration: 725 Train loss: 1.030252 Train acc: 0.460449\n",
      "Epoch: 8/140 Iteration: 730 Train loss: 0.840140 Train acc: 0.605469\n",
      "Epoch: 8/140 Iteration: 735 Train loss: 0.921831 Train acc: 0.595703\n",
      "Epoch: 8/140 Iteration: 740 Train loss: 1.098776 Train acc: 0.370117\n",
      "Epoch: 8/140 Iteration: 745 Train loss: 0.988132 Train acc: 0.378906\n",
      "Epoch: 8/140 Iteration: 750 Train loss: 0.978885 Train acc: 0.455078\n",
      "Epoch: 8/140 Iteration: 755 Train loss: 0.944224 Train acc: 0.481445\n",
      "Epoch: 8/140 Iteration: 760 Train loss: 1.059791 Train acc: 0.436523\n",
      "Epoch: 8/140 Iteration: 765 Train loss: 1.035492 Train acc: 0.446777\n",
      "Epoch: 9/140 Iteration: 770 Train loss: 0.954392 Train acc: 0.534668\n",
      "Epoch: 9/140 Iteration: 775 Train loss: 0.968133 Train acc: 0.490234\n",
      "Epoch: 9/140 Iteration: 780 Train loss: 1.026353 Train acc: 0.488281\n",
      "Epoch: 9/140 Iteration: 785 Train loss: 0.992633 Train acc: 0.517090\n",
      "Epoch: 9/140 Iteration: 790 Train loss: 1.109898 Train acc: 0.370605\n",
      "Epoch: 9/140 Iteration: 795 Train loss: 1.001490 Train acc: 0.506348\n",
      "Epoch: 9/140 Iteration: 800 Train loss: 0.892875 Train acc: 0.598633\n",
      "Epoch: 9/140 Iteration: 805 Train loss: 0.916468 Train acc: 0.607422\n",
      "Epoch: 9/140 Iteration: 810 Train loss: 1.028145 Train acc: 0.460449\n",
      "Epoch: 9/140 Iteration: 815 Train loss: 0.846781 Train acc: 0.610840\n",
      "Epoch: 9/140 Iteration: 820 Train loss: 0.940644 Train acc: 0.574707\n",
      "Epoch: 9/140 Iteration: 825 Train loss: 1.116897 Train acc: 0.355469\n",
      "Epoch: 9/140 Iteration: 830 Train loss: 0.983890 Train acc: 0.370117\n",
      "Epoch: 9/140 Iteration: 835 Train loss: 0.968846 Train acc: 0.461426\n",
      "Epoch: 9/140 Iteration: 840 Train loss: 0.948032 Train acc: 0.481445\n",
      "Epoch: 9/140 Iteration: 845 Train loss: 1.057252 Train acc: 0.448730\n",
      "Epoch: 9/140 Iteration: 850 Train loss: 1.020737 Train acc: 0.457520\n",
      "Epoch: 10/140 Iteration: 855 Train loss: 0.975769 Train acc: 0.510254\n",
      "Epoch: 10/140 Iteration: 860 Train loss: 0.969341 Train acc: 0.494629\n",
      "Epoch: 10/140 Iteration: 865 Train loss: 1.032823 Train acc: 0.490723\n",
      "Epoch: 10/140 Iteration: 870 Train loss: 1.027765 Train acc: 0.485352\n",
      "Epoch: 10/140 Iteration: 875 Train loss: 1.119643 Train acc: 0.369629\n",
      "Epoch: 10/140 Iteration: 880 Train loss: 0.976963 Train acc: 0.523438\n",
      "Epoch: 10/140 Iteration: 885 Train loss: 0.895527 Train acc: 0.597656\n",
      "Epoch: 10/140 Iteration: 890 Train loss: 0.872132 Train acc: 0.638672\n",
      "Epoch: 10/140 Iteration: 895 Train loss: 1.017629 Train acc: 0.456543\n",
      "Epoch: 10/140 Iteration: 900 Train loss: 0.830408 Train acc: 0.631348\n",
      "Epoch: 10/140 Iteration: 905 Train loss: 0.919837 Train acc: 0.584473\n",
      "Epoch: 10/140 Iteration: 910 Train loss: 1.098423 Train acc: 0.393555\n",
      "Epoch: 10/140 Iteration: 915 Train loss: 0.981414 Train acc: 0.385742\n",
      "Epoch: 10/140 Iteration: 920 Train loss: 0.977621 Train acc: 0.478027\n",
      "Epoch: 10/140 Iteration: 925 Train loss: 0.934207 Train acc: 0.458984\n",
      "Epoch: 10/140 Iteration: 930 Train loss: 1.057019 Train acc: 0.422363\n",
      "Epoch: 10/140 Iteration: 935 Train loss: 1.040236 Train acc: 0.450684\n",
      "Epoch: 11/140 Iteration: 940 Train loss: 0.963222 Train acc: 0.524902\n",
      "Epoch: 11/140 Iteration: 945 Train loss: 0.972255 Train acc: 0.500488\n",
      "Epoch: 11/140 Iteration: 950 Train loss: 1.017322 Train acc: 0.503906\n",
      "Epoch: 11/140 Iteration: 955 Train loss: 0.988954 Train acc: 0.517090\n",
      "Epoch: 11/140 Iteration: 960 Train loss: 1.103866 Train acc: 0.393555\n",
      "Epoch: 11/140 Iteration: 965 Train loss: 0.977428 Train acc: 0.512695\n",
      "Epoch: 11/140 Iteration: 970 Train loss: 0.881024 Train acc: 0.606934\n",
      "Epoch: 11/140 Iteration: 975 Train loss: 0.868643 Train acc: 0.644043\n",
      "Epoch: 11/140 Iteration: 980 Train loss: 1.029379 Train acc: 0.462402\n",
      "Epoch: 11/140 Iteration: 985 Train loss: 0.844475 Train acc: 0.601074\n",
      "Epoch: 11/140 Iteration: 990 Train loss: 0.919662 Train acc: 0.591309\n",
      "Epoch: 11/140 Iteration: 995 Train loss: 1.104040 Train acc: 0.382812\n",
      "Epoch: 11/140 Iteration: 1000 Train loss: 0.990246 Train acc: 0.372559\n",
      "Epoch: 11/140 Iteration: 1005 Train loss: 0.968190 Train acc: 0.449707\n",
      "Epoch: 11/140 Iteration: 1010 Train loss: 0.944353 Train acc: 0.467773\n",
      "Epoch: 11/140 Iteration: 1015 Train loss: 1.058351 Train acc: 0.425293\n",
      "Epoch: 11/140 Iteration: 1020 Train loss: 1.058221 Train acc: 0.402832\n",
      "Epoch: 12/140 Iteration: 1025 Train loss: 0.975911 Train acc: 0.522461\n",
      "Epoch: 12/140 Iteration: 1030 Train loss: 0.973023 Train acc: 0.501953\n",
      "Epoch: 12/140 Iteration: 1035 Train loss: 1.024313 Train acc: 0.464355\n",
      "Epoch: 12/140 Iteration: 1040 Train loss: 0.992857 Train acc: 0.529785\n",
      "Epoch: 12/140 Iteration: 1045 Train loss: 1.104085 Train acc: 0.394043\n",
      "Epoch: 12/140 Iteration: 1050 Train loss: 0.987197 Train acc: 0.529297\n",
      "Epoch: 12/140 Iteration: 1055 Train loss: 0.893694 Train acc: 0.592285\n",
      "Epoch: 12/140 Iteration: 1060 Train loss: 0.864543 Train acc: 0.633789\n",
      "Epoch: 12/140 Iteration: 1065 Train loss: 1.016147 Train acc: 0.464844\n",
      "Epoch: 12/140 Iteration: 1070 Train loss: 0.847048 Train acc: 0.614258\n",
      "Epoch: 12/140 Iteration: 1075 Train loss: 0.929293 Train acc: 0.587402\n",
      "Epoch: 12/140 Iteration: 1080 Train loss: 1.121833 Train acc: 0.360352\n",
      "Epoch: 12/140 Iteration: 1085 Train loss: 0.976849 Train acc: 0.392090\n",
      "Epoch: 12/140 Iteration: 1090 Train loss: 0.971286 Train acc: 0.460449\n",
      "Epoch: 12/140 Iteration: 1095 Train loss: 0.947777 Train acc: 0.473145\n",
      "Epoch: 12/140 Iteration: 1100 Train loss: 1.055762 Train acc: 0.431641\n",
      "Epoch: 12/140 Iteration: 1105 Train loss: 1.032593 Train acc: 0.455566\n",
      "Epoch: 13/140 Iteration: 1110 Train loss: 0.973796 Train acc: 0.515625\n",
      "Epoch: 13/140 Iteration: 1115 Train loss: 0.969193 Train acc: 0.518555\n",
      "Epoch: 13/140 Iteration: 1120 Train loss: 1.027242 Train acc: 0.497070\n",
      "Epoch: 13/140 Iteration: 1125 Train loss: 1.032711 Train acc: 0.484863\n",
      "Epoch: 13/140 Iteration: 1130 Train loss: 1.111117 Train acc: 0.374023\n",
      "Epoch: 13/140 Iteration: 1135 Train loss: 0.996381 Train acc: 0.496582\n",
      "Epoch: 13/140 Iteration: 1140 Train loss: 0.889328 Train acc: 0.605469\n",
      "Epoch: 13/140 Iteration: 1145 Train loss: 0.856081 Train acc: 0.663086\n",
      "Epoch: 13/140 Iteration: 1150 Train loss: 1.012521 Train acc: 0.475586\n",
      "Epoch: 13/140 Iteration: 1155 Train loss: 0.826178 Train acc: 0.636719\n",
      "Epoch: 13/140 Iteration: 1160 Train loss: 0.937340 Train acc: 0.568359\n",
      "Epoch: 13/140 Iteration: 1165 Train loss: 1.087445 Train acc: 0.440918\n",
      "Epoch: 13/140 Iteration: 1170 Train loss: 0.977789 Train acc: 0.400391\n",
      "Epoch: 13/140 Iteration: 1175 Train loss: 0.984781 Train acc: 0.466309\n",
      "Epoch: 13/140 Iteration: 1180 Train loss: 0.945887 Train acc: 0.479980\n",
      "Epoch: 13/140 Iteration: 1185 Train loss: 1.048908 Train acc: 0.436523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/140 Iteration: 1190 Train loss: 1.063239 Train acc: 0.437500\n",
      "Epoch: 14/140 Iteration: 1195 Train loss: 0.973622 Train acc: 0.500000\n",
      "Epoch: 14/140 Iteration: 1200 Train loss: 0.969823 Train acc: 0.483398\n",
      "Epoch: 14/140 Iteration: 1205 Train loss: 1.024764 Train acc: 0.487793\n",
      "Epoch: 14/140 Iteration: 1210 Train loss: 0.996031 Train acc: 0.501953\n",
      "Epoch: 14/140 Iteration: 1215 Train loss: 1.101250 Train acc: 0.391113\n",
      "Epoch: 14/140 Iteration: 1220 Train loss: 0.986007 Train acc: 0.513672\n",
      "Epoch: 14/140 Iteration: 1225 Train loss: 0.908034 Train acc: 0.596680\n",
      "Epoch: 14/140 Iteration: 1230 Train loss: 0.872420 Train acc: 0.660156\n",
      "Epoch: 14/140 Iteration: 1235 Train loss: 1.009660 Train acc: 0.490234\n",
      "Epoch: 14/140 Iteration: 1240 Train loss: 0.856018 Train acc: 0.598633\n",
      "Epoch: 14/140 Iteration: 1245 Train loss: 0.934064 Train acc: 0.575195\n",
      "Epoch: 14/140 Iteration: 1250 Train loss: 1.082708 Train acc: 0.384277\n",
      "Epoch: 14/140 Iteration: 1255 Train loss: 0.988182 Train acc: 0.376465\n",
      "Epoch: 14/140 Iteration: 1260 Train loss: 0.969852 Train acc: 0.460449\n",
      "Epoch: 14/140 Iteration: 1265 Train loss: 0.936219 Train acc: 0.476074\n",
      "Epoch: 14/140 Iteration: 1270 Train loss: 1.056409 Train acc: 0.437500\n",
      "Epoch: 14/140 Iteration: 1275 Train loss: 1.030248 Train acc: 0.431641\n",
      "Epoch: 15/140 Iteration: 1280 Train loss: 0.962653 Train acc: 0.526855\n",
      "Epoch: 15/140 Iteration: 1285 Train loss: 0.964614 Train acc: 0.507324\n",
      "Epoch: 15/140 Iteration: 1290 Train loss: 1.006183 Train acc: 0.506348\n",
      "Epoch: 15/140 Iteration: 1295 Train loss: 1.047611 Train acc: 0.482910\n",
      "Epoch: 15/140 Iteration: 1300 Train loss: 1.095458 Train acc: 0.394043\n",
      "Epoch: 15/140 Iteration: 1305 Train loss: 0.973846 Train acc: 0.515625\n",
      "Epoch: 15/140 Iteration: 1310 Train loss: 0.920680 Train acc: 0.560059\n",
      "Epoch: 15/140 Iteration: 1315 Train loss: 0.870687 Train acc: 0.620117\n",
      "Epoch: 15/140 Iteration: 1320 Train loss: 1.010223 Train acc: 0.455078\n",
      "Epoch: 15/140 Iteration: 1325 Train loss: 0.832784 Train acc: 0.638672\n",
      "Epoch: 15/140 Iteration: 1330 Train loss: 0.930781 Train acc: 0.578613\n",
      "Epoch: 15/140 Iteration: 1335 Train loss: 1.067038 Train acc: 0.431152\n",
      "Epoch: 15/140 Iteration: 1340 Train loss: 0.984547 Train acc: 0.393555\n",
      "Epoch: 15/140 Iteration: 1345 Train loss: 0.970866 Train acc: 0.461914\n",
      "Epoch: 15/140 Iteration: 1350 Train loss: 0.944972 Train acc: 0.465820\n",
      "Epoch: 15/140 Iteration: 1355 Train loss: 1.052878 Train acc: 0.435547\n",
      "Epoch: 15/140 Iteration: 1360 Train loss: 1.031044 Train acc: 0.452637\n",
      "Epoch: 16/140 Iteration: 1365 Train loss: 0.962970 Train acc: 0.518066\n",
      "Epoch: 16/140 Iteration: 1370 Train loss: 0.966086 Train acc: 0.524414\n",
      "Epoch: 16/140 Iteration: 1375 Train loss: 1.019561 Train acc: 0.513672\n",
      "Epoch: 16/140 Iteration: 1380 Train loss: 1.024054 Train acc: 0.499512\n",
      "Epoch: 16/140 Iteration: 1385 Train loss: 1.121368 Train acc: 0.371094\n",
      "Epoch: 16/140 Iteration: 1390 Train loss: 0.964607 Train acc: 0.522461\n",
      "Epoch: 16/140 Iteration: 1395 Train loss: 0.886144 Train acc: 0.584473\n",
      "Epoch: 16/140 Iteration: 1400 Train loss: 0.851361 Train acc: 0.671875\n",
      "Epoch: 16/140 Iteration: 1405 Train loss: 1.015443 Train acc: 0.470703\n",
      "Epoch: 16/140 Iteration: 1410 Train loss: 0.837757 Train acc: 0.636230\n",
      "Epoch: 16/140 Iteration: 1415 Train loss: 0.926900 Train acc: 0.597656\n",
      "Epoch: 16/140 Iteration: 1420 Train loss: 1.068947 Train acc: 0.432129\n",
      "Epoch: 16/140 Iteration: 1425 Train loss: 0.982306 Train acc: 0.391113\n",
      "Epoch: 16/140 Iteration: 1430 Train loss: 0.966163 Train acc: 0.468750\n",
      "Epoch: 16/140 Iteration: 1435 Train loss: 0.936795 Train acc: 0.486816\n",
      "Epoch: 16/140 Iteration: 1440 Train loss: 1.049220 Train acc: 0.438965\n",
      "Epoch: 16/140 Iteration: 1445 Train loss: 1.033759 Train acc: 0.458984\n",
      "Epoch: 17/140 Iteration: 1450 Train loss: 0.953542 Train acc: 0.542480\n",
      "Epoch: 17/140 Iteration: 1455 Train loss: 0.970102 Train acc: 0.507812\n",
      "Epoch: 17/140 Iteration: 1460 Train loss: 1.002405 Train acc: 0.505859\n",
      "Epoch: 17/140 Iteration: 1465 Train loss: 0.998920 Train acc: 0.519531\n",
      "Epoch: 17/140 Iteration: 1470 Train loss: 1.097090 Train acc: 0.386230\n",
      "Epoch: 17/140 Iteration: 1475 Train loss: 0.971334 Train acc: 0.547363\n",
      "Epoch: 17/140 Iteration: 1480 Train loss: 0.859127 Train acc: 0.600586\n",
      "Epoch: 17/140 Iteration: 1485 Train loss: 0.845614 Train acc: 0.668945\n",
      "Epoch: 17/140 Iteration: 1490 Train loss: 1.032908 Train acc: 0.469727\n",
      "Epoch: 17/140 Iteration: 1495 Train loss: 0.865555 Train acc: 0.573730\n",
      "Epoch: 17/140 Iteration: 1500 Train loss: 0.932843 Train acc: 0.596680\n",
      "Epoch: 17/140 Iteration: 1505 Train loss: 1.084186 Train acc: 0.384766\n",
      "Epoch: 17/140 Iteration: 1510 Train loss: 0.982125 Train acc: 0.398438\n",
      "Epoch: 17/140 Iteration: 1515 Train loss: 0.963100 Train acc: 0.465332\n",
      "Epoch: 17/140 Iteration: 1520 Train loss: 0.939487 Train acc: 0.488770\n",
      "Epoch: 17/140 Iteration: 1525 Train loss: 1.043654 Train acc: 0.452637\n",
      "Epoch: 17/140 Iteration: 1530 Train loss: 1.021319 Train acc: 0.470703\n",
      "Epoch: 18/140 Iteration: 1535 Train loss: 0.963495 Train acc: 0.535645\n",
      "Epoch: 18/140 Iteration: 1540 Train loss: 0.970266 Train acc: 0.503418\n",
      "Epoch: 18/140 Iteration: 1545 Train loss: 1.011094 Train acc: 0.499023\n",
      "Epoch: 18/140 Iteration: 1550 Train loss: 1.006717 Train acc: 0.498535\n",
      "Epoch: 18/140 Iteration: 1555 Train loss: 1.101198 Train acc: 0.390625\n",
      "Epoch: 18/140 Iteration: 1560 Train loss: 0.973188 Train acc: 0.520508\n",
      "Epoch: 18/140 Iteration: 1565 Train loss: 0.886963 Train acc: 0.622070\n",
      "Epoch: 18/140 Iteration: 1570 Train loss: 0.872037 Train acc: 0.650391\n",
      "Epoch: 18/140 Iteration: 1575 Train loss: 1.018139 Train acc: 0.481445\n",
      "Epoch: 18/140 Iteration: 1580 Train loss: 0.864480 Train acc: 0.589844\n",
      "Epoch: 18/140 Iteration: 1585 Train loss: 0.932346 Train acc: 0.572266\n",
      "Epoch: 18/140 Iteration: 1590 Train loss: 1.080426 Train acc: 0.427734\n",
      "Epoch: 18/140 Iteration: 1595 Train loss: 0.981048 Train acc: 0.395508\n",
      "Epoch: 18/140 Iteration: 1600 Train loss: 0.968000 Train acc: 0.463379\n",
      "Epoch: 18/140 Iteration: 1605 Train loss: 0.943443 Train acc: 0.477539\n",
      "Epoch: 18/140 Iteration: 1610 Train loss: 1.052044 Train acc: 0.438477\n",
      "Epoch: 18/140 Iteration: 1615 Train loss: 1.031570 Train acc: 0.467285\n",
      "Epoch: 19/140 Iteration: 1620 Train loss: 0.960515 Train acc: 0.531738\n",
      "Epoch: 19/140 Iteration: 1625 Train loss: 0.970338 Train acc: 0.493652\n",
      "Epoch: 19/140 Iteration: 1630 Train loss: 1.024001 Train acc: 0.513672\n",
      "Epoch: 19/140 Iteration: 1635 Train loss: 1.010681 Train acc: 0.482422\n",
      "Epoch: 19/140 Iteration: 1640 Train loss: 1.103903 Train acc: 0.393066\n",
      "Epoch: 19/140 Iteration: 1645 Train loss: 0.987310 Train acc: 0.517090\n",
      "Epoch: 19/140 Iteration: 1650 Train loss: 0.886394 Train acc: 0.608887\n",
      "Epoch: 19/140 Iteration: 1655 Train loss: 0.871878 Train acc: 0.652344\n",
      "Epoch: 19/140 Iteration: 1660 Train loss: 1.009439 Train acc: 0.485352\n",
      "Epoch: 19/140 Iteration: 1665 Train loss: 0.835531 Train acc: 0.638184\n",
      "Epoch: 19/140 Iteration: 1670 Train loss: 0.931925 Train acc: 0.592285\n",
      "Epoch: 19/140 Iteration: 1675 Train loss: 1.081559 Train acc: 0.420410\n",
      "Epoch: 19/140 Iteration: 1680 Train loss: 0.980457 Train acc: 0.391602\n",
      "Epoch: 19/140 Iteration: 1685 Train loss: 0.965690 Train acc: 0.492188\n",
      "Epoch: 19/140 Iteration: 1690 Train loss: 0.941067 Train acc: 0.484375\n",
      "Epoch: 19/140 Iteration: 1695 Train loss: 1.045293 Train acc: 0.439453\n",
      "Epoch: 19/140 Iteration: 1700 Train loss: 1.071545 Train acc: 0.447266\n",
      "Epoch: 20/140 Iteration: 1705 Train loss: 0.951467 Train acc: 0.528809\n",
      "Epoch: 20/140 Iteration: 1710 Train loss: 0.967588 Train acc: 0.502930\n",
      "Epoch: 20/140 Iteration: 1715 Train loss: 1.019749 Train acc: 0.511230\n",
      "Epoch: 20/140 Iteration: 1720 Train loss: 1.012928 Train acc: 0.515625\n",
      "Epoch: 20/140 Iteration: 1725 Train loss: 1.118542 Train acc: 0.372070\n",
      "Epoch: 20/140 Iteration: 1730 Train loss: 0.973579 Train acc: 0.520508\n",
      "Epoch: 20/140 Iteration: 1735 Train loss: 0.873450 Train acc: 0.602539\n",
      "Epoch: 20/140 Iteration: 1740 Train loss: 0.858715 Train acc: 0.656250\n",
      "Epoch: 20/140 Iteration: 1745 Train loss: 1.014630 Train acc: 0.479980\n",
      "Epoch: 20/140 Iteration: 1750 Train loss: 0.849520 Train acc: 0.604004\n",
      "Epoch: 20/140 Iteration: 1755 Train loss: 0.930853 Train acc: 0.569336\n",
      "Epoch: 20/140 Iteration: 1760 Train loss: 1.075606 Train acc: 0.415039\n",
      "Epoch: 20/140 Iteration: 1765 Train loss: 0.981788 Train acc: 0.393066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20/140 Iteration: 1770 Train loss: 0.964190 Train acc: 0.476562\n",
      "Epoch: 20/140 Iteration: 1775 Train loss: 0.943242 Train acc: 0.459961\n",
      "Epoch: 20/140 Iteration: 1780 Train loss: 1.036403 Train acc: 0.453125\n",
      "Epoch: 20/140 Iteration: 1785 Train loss: 1.046227 Train acc: 0.452148\n",
      "Epoch: 21/140 Iteration: 1790 Train loss: 0.952556 Train acc: 0.543945\n",
      "Epoch: 21/140 Iteration: 1795 Train loss: 0.977359 Train acc: 0.505859\n",
      "Epoch: 21/140 Iteration: 1800 Train loss: 1.000875 Train acc: 0.528320\n",
      "Epoch: 21/140 Iteration: 1805 Train loss: 0.991544 Train acc: 0.523438\n",
      "Epoch: 21/140 Iteration: 1810 Train loss: 1.106558 Train acc: 0.381348\n",
      "Epoch: 21/140 Iteration: 1815 Train loss: 0.966952 Train acc: 0.534180\n",
      "Epoch: 21/140 Iteration: 1820 Train loss: 0.861877 Train acc: 0.616211\n",
      "Epoch: 21/140 Iteration: 1825 Train loss: 0.845768 Train acc: 0.670410\n",
      "Epoch: 21/140 Iteration: 1830 Train loss: 1.009121 Train acc: 0.486328\n",
      "Epoch: 21/140 Iteration: 1835 Train loss: 0.831568 Train acc: 0.628418\n",
      "Epoch: 21/140 Iteration: 1840 Train loss: 0.934777 Train acc: 0.586914\n",
      "Epoch: 21/140 Iteration: 1845 Train loss: 1.075868 Train acc: 0.427246\n",
      "Epoch: 21/140 Iteration: 1850 Train loss: 0.992767 Train acc: 0.380371\n",
      "Epoch: 21/140 Iteration: 1855 Train loss: 0.964549 Train acc: 0.463867\n",
      "Epoch: 21/140 Iteration: 1860 Train loss: 0.935697 Train acc: 0.491211\n",
      "Epoch: 21/140 Iteration: 1865 Train loss: 1.039599 Train acc: 0.449707\n",
      "Epoch: 21/140 Iteration: 1870 Train loss: 1.007856 Train acc: 0.486816\n",
      "Epoch: 22/140 Iteration: 1875 Train loss: 0.967890 Train acc: 0.531250\n",
      "Epoch: 22/140 Iteration: 1880 Train loss: 0.979297 Train acc: 0.500488\n",
      "Epoch: 22/140 Iteration: 1885 Train loss: 0.981781 Train acc: 0.539062\n",
      "Epoch: 22/140 Iteration: 1890 Train loss: 0.989428 Train acc: 0.517090\n",
      "Epoch: 22/140 Iteration: 1895 Train loss: 1.103856 Train acc: 0.387695\n",
      "Epoch: 22/140 Iteration: 1900 Train loss: 0.975618 Train acc: 0.526855\n",
      "Epoch: 22/140 Iteration: 1905 Train loss: 0.865862 Train acc: 0.620117\n",
      "Epoch: 22/140 Iteration: 1910 Train loss: 0.846978 Train acc: 0.677246\n",
      "Epoch: 22/140 Iteration: 1915 Train loss: 1.016599 Train acc: 0.465332\n",
      "Epoch: 22/140 Iteration: 1920 Train loss: 0.839126 Train acc: 0.625000\n",
      "Epoch: 22/140 Iteration: 1925 Train loss: 0.937015 Train acc: 0.599121\n",
      "Epoch: 22/140 Iteration: 1930 Train loss: 1.090015 Train acc: 0.417969\n",
      "Epoch: 22/140 Iteration: 1935 Train loss: 0.975270 Train acc: 0.393555\n",
      "Epoch: 22/140 Iteration: 1940 Train loss: 0.958707 Train acc: 0.488281\n",
      "Epoch: 22/140 Iteration: 1945 Train loss: 0.939698 Train acc: 0.484375\n",
      "Epoch: 22/140 Iteration: 1950 Train loss: 1.044605 Train acc: 0.433105\n",
      "Epoch: 22/140 Iteration: 1955 Train loss: 1.010479 Train acc: 0.488770\n",
      "Epoch: 23/140 Iteration: 1960 Train loss: 0.954514 Train acc: 0.542480\n",
      "Epoch: 23/140 Iteration: 1965 Train loss: 0.975843 Train acc: 0.517578\n",
      "Epoch: 23/140 Iteration: 1970 Train loss: 1.032182 Train acc: 0.475098\n",
      "Epoch: 23/140 Iteration: 1975 Train loss: 0.993814 Train acc: 0.506348\n",
      "Epoch: 23/140 Iteration: 1980 Train loss: 1.108789 Train acc: 0.376465\n",
      "Epoch: 23/140 Iteration: 1985 Train loss: 0.969921 Train acc: 0.536621\n",
      "Epoch: 23/140 Iteration: 1990 Train loss: 0.868607 Train acc: 0.616211\n",
      "Epoch: 23/140 Iteration: 1995 Train loss: 0.852528 Train acc: 0.660645\n",
      "Epoch: 23/140 Iteration: 2000 Train loss: 1.004597 Train acc: 0.483887\n",
      "Epoch: 23/140 Iteration: 2005 Train loss: 0.852728 Train acc: 0.600098\n",
      "Epoch: 23/140 Iteration: 2010 Train loss: 0.931591 Train acc: 0.600098\n",
      "Epoch: 23/140 Iteration: 2015 Train loss: 1.088485 Train acc: 0.382812\n",
      "Epoch: 23/140 Iteration: 2020 Train loss: 0.978810 Train acc: 0.403809\n",
      "Epoch: 23/140 Iteration: 2025 Train loss: 0.955285 Train acc: 0.499512\n",
      "Epoch: 23/140 Iteration: 2030 Train loss: 0.937564 Train acc: 0.494141\n",
      "Epoch: 23/140 Iteration: 2035 Train loss: 1.043980 Train acc: 0.427734\n",
      "Epoch: 23/140 Iteration: 2040 Train loss: 0.998637 Train acc: 0.472168\n",
      "Epoch: 24/140 Iteration: 2045 Train loss: 0.954941 Train acc: 0.538574\n",
      "Epoch: 24/140 Iteration: 2050 Train loss: 0.975136 Train acc: 0.496094\n",
      "Epoch: 24/140 Iteration: 2055 Train loss: 1.003799 Train acc: 0.511719\n",
      "Epoch: 24/140 Iteration: 2060 Train loss: 0.979122 Train acc: 0.529297\n",
      "Epoch: 24/140 Iteration: 2065 Train loss: 1.107560 Train acc: 0.380859\n",
      "Epoch: 24/140 Iteration: 2070 Train loss: 0.949720 Train acc: 0.550293\n",
      "Epoch: 24/140 Iteration: 2075 Train loss: 0.876556 Train acc: 0.608398\n",
      "Epoch: 24/140 Iteration: 2080 Train loss: 0.851114 Train acc: 0.655273\n",
      "Epoch: 24/140 Iteration: 2085 Train loss: 1.005776 Train acc: 0.481445\n",
      "Epoch: 24/140 Iteration: 2090 Train loss: 0.825740 Train acc: 0.640625\n",
      "Epoch: 24/140 Iteration: 2095 Train loss: 0.922891 Train acc: 0.604980\n",
      "Epoch: 24/140 Iteration: 2100 Train loss: 1.089714 Train acc: 0.454590\n",
      "Epoch: 24/140 Iteration: 2105 Train loss: 0.983215 Train acc: 0.393555\n",
      "Epoch: 24/140 Iteration: 2110 Train loss: 0.964439 Train acc: 0.520508\n",
      "Epoch: 24/140 Iteration: 2115 Train loss: 0.951208 Train acc: 0.454102\n",
      "Epoch: 24/140 Iteration: 2120 Train loss: 1.039040 Train acc: 0.471191\n",
      "Epoch: 24/140 Iteration: 2125 Train loss: 1.009843 Train acc: 0.475586\n",
      "Epoch: 25/140 Iteration: 2130 Train loss: 0.953724 Train acc: 0.541016\n",
      "Epoch: 25/140 Iteration: 2135 Train loss: 0.969516 Train acc: 0.497070\n",
      "Epoch: 25/140 Iteration: 2140 Train loss: 1.021399 Train acc: 0.486328\n",
      "Epoch: 25/140 Iteration: 2145 Train loss: 0.995057 Train acc: 0.508789\n",
      "Epoch: 25/140 Iteration: 2150 Train loss: 1.096017 Train acc: 0.393555\n",
      "Epoch: 25/140 Iteration: 2155 Train loss: 0.947209 Train acc: 0.567383\n",
      "Epoch: 25/140 Iteration: 2160 Train loss: 0.879318 Train acc: 0.598633\n",
      "Epoch: 25/140 Iteration: 2165 Train loss: 0.850433 Train acc: 0.664551\n",
      "Epoch: 25/140 Iteration: 2170 Train loss: 1.011302 Train acc: 0.498047\n",
      "Epoch: 25/140 Iteration: 2175 Train loss: 0.850735 Train acc: 0.593750\n",
      "Epoch: 25/140 Iteration: 2180 Train loss: 0.933628 Train acc: 0.592773\n",
      "Epoch: 25/140 Iteration: 2185 Train loss: 1.073438 Train acc: 0.461426\n",
      "Epoch: 25/140 Iteration: 2190 Train loss: 0.970155 Train acc: 0.400879\n",
      "Epoch: 25/140 Iteration: 2195 Train loss: 0.942129 Train acc: 0.500000\n",
      "Epoch: 25/140 Iteration: 2200 Train loss: 0.934692 Train acc: 0.450195\n",
      "Epoch: 25/140 Iteration: 2205 Train loss: 1.060069 Train acc: 0.450684\n",
      "Epoch: 25/140 Iteration: 2210 Train loss: 0.988362 Train acc: 0.479004\n",
      "Epoch: 26/140 Iteration: 2215 Train loss: 0.953795 Train acc: 0.541992\n",
      "Epoch: 26/140 Iteration: 2220 Train loss: 0.973707 Train acc: 0.492676\n",
      "Epoch: 26/140 Iteration: 2225 Train loss: 0.979834 Train acc: 0.520996\n",
      "Epoch: 26/140 Iteration: 2230 Train loss: 0.986638 Train acc: 0.506348\n",
      "Epoch: 26/140 Iteration: 2235 Train loss: 1.088992 Train acc: 0.405273\n",
      "Epoch: 26/140 Iteration: 2240 Train loss: 0.935323 Train acc: 0.556641\n",
      "Epoch: 26/140 Iteration: 2245 Train loss: 0.867166 Train acc: 0.613770\n",
      "Epoch: 26/140 Iteration: 2250 Train loss: 0.842107 Train acc: 0.656250\n",
      "Epoch: 26/140 Iteration: 2255 Train loss: 1.012234 Train acc: 0.500977\n",
      "Epoch: 26/140 Iteration: 2260 Train loss: 0.844254 Train acc: 0.610840\n",
      "Epoch: 26/140 Iteration: 2265 Train loss: 0.948960 Train acc: 0.579590\n",
      "Epoch: 26/140 Iteration: 2270 Train loss: 1.103437 Train acc: 0.408691\n",
      "Epoch: 26/140 Iteration: 2275 Train loss: 0.985738 Train acc: 0.382812\n",
      "Epoch: 26/140 Iteration: 2280 Train loss: 0.945586 Train acc: 0.506836\n",
      "Epoch: 26/140 Iteration: 2285 Train loss: 0.934573 Train acc: 0.464844\n",
      "Epoch: 26/140 Iteration: 2290 Train loss: 1.040823 Train acc: 0.446289\n",
      "Epoch: 26/140 Iteration: 2295 Train loss: 0.979531 Train acc: 0.464355\n",
      "Epoch: 27/140 Iteration: 2300 Train loss: 0.950493 Train acc: 0.540527\n",
      "Epoch: 27/140 Iteration: 2305 Train loss: 0.976822 Train acc: 0.484863\n",
      "Epoch: 27/140 Iteration: 2310 Train loss: 1.004731 Train acc: 0.512207\n",
      "Epoch: 27/140 Iteration: 2315 Train loss: 0.998156 Train acc: 0.505859\n",
      "Epoch: 27/140 Iteration: 2320 Train loss: 1.083011 Train acc: 0.403809\n",
      "Epoch: 27/140 Iteration: 2325 Train loss: 0.943855 Train acc: 0.573730\n",
      "Epoch: 27/140 Iteration: 2330 Train loss: 0.869085 Train acc: 0.602051\n",
      "Epoch: 27/140 Iteration: 2335 Train loss: 0.828455 Train acc: 0.679199\n",
      "Epoch: 27/140 Iteration: 2340 Train loss: 1.012061 Train acc: 0.484863\n",
      "Epoch: 27/140 Iteration: 2345 Train loss: 0.842207 Train acc: 0.604492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27/140 Iteration: 2350 Train loss: 0.922317 Train acc: 0.580078\n",
      "Epoch: 27/140 Iteration: 2355 Train loss: 1.066919 Train acc: 0.467285\n",
      "Epoch: 27/140 Iteration: 2360 Train loss: 0.969286 Train acc: 0.410156\n",
      "Epoch: 27/140 Iteration: 2365 Train loss: 0.946959 Train acc: 0.495117\n",
      "Epoch: 27/140 Iteration: 2370 Train loss: 0.933833 Train acc: 0.446777\n",
      "Epoch: 27/140 Iteration: 2375 Train loss: 1.058577 Train acc: 0.443359\n",
      "Epoch: 27/140 Iteration: 2380 Train loss: 0.988222 Train acc: 0.458008\n",
      "Epoch: 28/140 Iteration: 2385 Train loss: 0.950314 Train acc: 0.529297\n",
      "Epoch: 28/140 Iteration: 2390 Train loss: 0.969897 Train acc: 0.491699\n",
      "Epoch: 28/140 Iteration: 2395 Train loss: 1.003203 Train acc: 0.504395\n",
      "Epoch: 28/140 Iteration: 2400 Train loss: 0.975425 Train acc: 0.509766\n",
      "Epoch: 28/140 Iteration: 2405 Train loss: 1.097044 Train acc: 0.396973\n",
      "Epoch: 28/140 Iteration: 2410 Train loss: 0.946770 Train acc: 0.562012\n",
      "Epoch: 28/140 Iteration: 2415 Train loss: 0.875764 Train acc: 0.610840\n",
      "Epoch: 28/140 Iteration: 2420 Train loss: 0.843039 Train acc: 0.628418\n",
      "Epoch: 28/140 Iteration: 2425 Train loss: 1.005189 Train acc: 0.478516\n",
      "Epoch: 28/140 Iteration: 2430 Train loss: 0.824741 Train acc: 0.639648\n",
      "Epoch: 28/140 Iteration: 2435 Train loss: 0.925164 Train acc: 0.577148\n",
      "Epoch: 28/140 Iteration: 2440 Train loss: 1.057183 Train acc: 0.481445\n",
      "Epoch: 28/140 Iteration: 2445 Train loss: 0.983894 Train acc: 0.375000\n",
      "Epoch: 28/140 Iteration: 2450 Train loss: 0.939904 Train acc: 0.514648\n",
      "Epoch: 28/140 Iteration: 2455 Train loss: 0.944721 Train acc: 0.442383\n",
      "Epoch: 28/140 Iteration: 2460 Train loss: 1.044105 Train acc: 0.450195\n",
      "Epoch: 28/140 Iteration: 2465 Train loss: 1.015361 Train acc: 0.451172\n",
      "Epoch: 29/140 Iteration: 2470 Train loss: 0.942663 Train acc: 0.547852\n",
      "Epoch: 29/140 Iteration: 2475 Train loss: 0.969493 Train acc: 0.515625\n",
      "Epoch: 29/140 Iteration: 2480 Train loss: 0.980109 Train acc: 0.522461\n",
      "Epoch: 29/140 Iteration: 2485 Train loss: 1.019253 Train acc: 0.517578\n",
      "Epoch: 29/140 Iteration: 2490 Train loss: 1.072822 Train acc: 0.401855\n",
      "Epoch: 29/140 Iteration: 2495 Train loss: 0.959710 Train acc: 0.538574\n",
      "Epoch: 29/140 Iteration: 2500 Train loss: 0.875220 Train acc: 0.601562\n",
      "Epoch: 29/140 Iteration: 2505 Train loss: 0.830466 Train acc: 0.659180\n",
      "Epoch: 29/140 Iteration: 2510 Train loss: 1.013729 Train acc: 0.480469\n",
      "Epoch: 29/140 Iteration: 2515 Train loss: 0.827959 Train acc: 0.610840\n",
      "Epoch: 29/140 Iteration: 2520 Train loss: 0.936527 Train acc: 0.579590\n",
      "Epoch: 29/140 Iteration: 2525 Train loss: 1.066394 Train acc: 0.470215\n",
      "Epoch: 29/140 Iteration: 2530 Train loss: 0.983941 Train acc: 0.368164\n",
      "Epoch: 29/140 Iteration: 2535 Train loss: 0.942267 Train acc: 0.498047\n",
      "Epoch: 29/140 Iteration: 2540 Train loss: 0.932036 Train acc: 0.484863\n",
      "Epoch: 29/140 Iteration: 2545 Train loss: 1.049497 Train acc: 0.446289\n",
      "Epoch: 29/140 Iteration: 2550 Train loss: 1.010461 Train acc: 0.421875\n",
      "Epoch: 30/140 Iteration: 2555 Train loss: 0.945268 Train acc: 0.558594\n",
      "Epoch: 30/140 Iteration: 2560 Train loss: 0.966578 Train acc: 0.498535\n",
      "Epoch: 30/140 Iteration: 2565 Train loss: 1.006340 Train acc: 0.497070\n",
      "Epoch: 30/140 Iteration: 2570 Train loss: 0.999128 Train acc: 0.500488\n",
      "Epoch: 30/140 Iteration: 2575 Train loss: 1.063618 Train acc: 0.412598\n",
      "Epoch: 30/140 Iteration: 2580 Train loss: 0.932712 Train acc: 0.573730\n",
      "Epoch: 30/140 Iteration: 2585 Train loss: 0.866637 Train acc: 0.617676\n",
      "Epoch: 30/140 Iteration: 2590 Train loss: 0.846353 Train acc: 0.655273\n",
      "Epoch: 30/140 Iteration: 2595 Train loss: 1.008621 Train acc: 0.495117\n",
      "Epoch: 30/140 Iteration: 2600 Train loss: 0.822184 Train acc: 0.627930\n",
      "Epoch: 30/140 Iteration: 2605 Train loss: 0.929469 Train acc: 0.571777\n",
      "Epoch: 30/140 Iteration: 2610 Train loss: 1.107675 Train acc: 0.443848\n",
      "Epoch: 30/140 Iteration: 2615 Train loss: 0.968504 Train acc: 0.402832\n",
      "Epoch: 30/140 Iteration: 2620 Train loss: 0.944696 Train acc: 0.501465\n",
      "Epoch: 30/140 Iteration: 2625 Train loss: 0.940546 Train acc: 0.474121\n",
      "Epoch: 30/140 Iteration: 2630 Train loss: 1.062232 Train acc: 0.431641\n",
      "Epoch: 30/140 Iteration: 2635 Train loss: 1.010762 Train acc: 0.458984\n",
      "Epoch: 31/140 Iteration: 2640 Train loss: 0.957422 Train acc: 0.528809\n",
      "Epoch: 31/140 Iteration: 2645 Train loss: 0.970446 Train acc: 0.506348\n",
      "Epoch: 31/140 Iteration: 2650 Train loss: 0.989631 Train acc: 0.524414\n",
      "Epoch: 31/140 Iteration: 2655 Train loss: 0.980587 Train acc: 0.512207\n",
      "Epoch: 31/140 Iteration: 2660 Train loss: 1.082312 Train acc: 0.406738\n",
      "Epoch: 31/140 Iteration: 2665 Train loss: 0.938486 Train acc: 0.544434\n",
      "Epoch: 31/140 Iteration: 2670 Train loss: 0.853447 Train acc: 0.617676\n",
      "Epoch: 31/140 Iteration: 2675 Train loss: 0.832091 Train acc: 0.655273\n",
      "Epoch: 31/140 Iteration: 2680 Train loss: 0.999855 Train acc: 0.474609\n",
      "Epoch: 31/140 Iteration: 2685 Train loss: 0.824053 Train acc: 0.649414\n",
      "Epoch: 31/140 Iteration: 2690 Train loss: 0.928406 Train acc: 0.577148\n",
      "Epoch: 31/140 Iteration: 2695 Train loss: 1.042669 Train acc: 0.473633\n",
      "Epoch: 31/140 Iteration: 2700 Train loss: 0.975706 Train acc: 0.405762\n",
      "Epoch: 31/140 Iteration: 2705 Train loss: 0.940872 Train acc: 0.504883\n",
      "Epoch: 31/140 Iteration: 2710 Train loss: 0.941949 Train acc: 0.468750\n",
      "Epoch: 31/140 Iteration: 2715 Train loss: 1.073376 Train acc: 0.446289\n",
      "Epoch: 31/140 Iteration: 2720 Train loss: 1.036281 Train acc: 0.472656\n",
      "Epoch: 32/140 Iteration: 2725 Train loss: 0.950037 Train acc: 0.534180\n",
      "Epoch: 32/140 Iteration: 2730 Train loss: 0.974860 Train acc: 0.501465\n",
      "Epoch: 32/140 Iteration: 2735 Train loss: 0.972285 Train acc: 0.533203\n",
      "Epoch: 32/140 Iteration: 2740 Train loss: 0.964625 Train acc: 0.523438\n",
      "Epoch: 32/140 Iteration: 2745 Train loss: 1.076149 Train acc: 0.398438\n",
      "Epoch: 32/140 Iteration: 2750 Train loss: 0.950337 Train acc: 0.572754\n",
      "Epoch: 32/140 Iteration: 2755 Train loss: 0.848963 Train acc: 0.633301\n",
      "Epoch: 32/140 Iteration: 2760 Train loss: 0.818660 Train acc: 0.659668\n",
      "Epoch: 32/140 Iteration: 2765 Train loss: 0.995048 Train acc: 0.478516\n",
      "Epoch: 32/140 Iteration: 2770 Train loss: 0.840266 Train acc: 0.625977\n",
      "Epoch: 32/140 Iteration: 2775 Train loss: 0.927351 Train acc: 0.579590\n",
      "Epoch: 32/140 Iteration: 2780 Train loss: 1.083064 Train acc: 0.440430\n",
      "Epoch: 32/140 Iteration: 2785 Train loss: 0.994737 Train acc: 0.383789\n",
      "Epoch: 32/140 Iteration: 2790 Train loss: 0.949219 Train acc: 0.512695\n",
      "Epoch: 32/140 Iteration: 2795 Train loss: 0.934644 Train acc: 0.442871\n",
      "Epoch: 32/140 Iteration: 2800 Train loss: 1.020920 Train acc: 0.470703\n",
      "Epoch: 32/140 Iteration: 2805 Train loss: 0.995952 Train acc: 0.494629\n",
      "Epoch: 33/140 Iteration: 2810 Train loss: 0.941009 Train acc: 0.544434\n",
      "Epoch: 33/140 Iteration: 2815 Train loss: 0.966249 Train acc: 0.506836\n",
      "Epoch: 33/140 Iteration: 2820 Train loss: 0.983154 Train acc: 0.515137\n",
      "Epoch: 33/140 Iteration: 2825 Train loss: 0.972328 Train acc: 0.505371\n",
      "Epoch: 33/140 Iteration: 2830 Train loss: 1.091720 Train acc: 0.405762\n",
      "Epoch: 33/140 Iteration: 2835 Train loss: 0.932740 Train acc: 0.576660\n",
      "Epoch: 33/140 Iteration: 2840 Train loss: 0.878791 Train acc: 0.622070\n",
      "Epoch: 33/140 Iteration: 2845 Train loss: 0.824112 Train acc: 0.646973\n",
      "Epoch: 33/140 Iteration: 2850 Train loss: 1.001253 Train acc: 0.458984\n",
      "Epoch: 33/140 Iteration: 2855 Train loss: 0.832386 Train acc: 0.617188\n",
      "Epoch: 33/140 Iteration: 2860 Train loss: 0.924050 Train acc: 0.573242\n",
      "Epoch: 33/140 Iteration: 2865 Train loss: 1.055161 Train acc: 0.459473\n",
      "Epoch: 33/140 Iteration: 2870 Train loss: 0.986320 Train acc: 0.386230\n",
      "Epoch: 33/140 Iteration: 2875 Train loss: 0.946983 Train acc: 0.504395\n",
      "Epoch: 33/140 Iteration: 2880 Train loss: 0.929013 Train acc: 0.456543\n",
      "Epoch: 33/140 Iteration: 2885 Train loss: 1.031651 Train acc: 0.470703\n",
      "Epoch: 33/140 Iteration: 2890 Train loss: 0.974254 Train acc: 0.494629\n",
      "Epoch: 34/140 Iteration: 2895 Train loss: 0.950946 Train acc: 0.545410\n",
      "Epoch: 34/140 Iteration: 2900 Train loss: 0.973775 Train acc: 0.507812\n",
      "Epoch: 34/140 Iteration: 2905 Train loss: 0.991948 Train acc: 0.510742\n",
      "Epoch: 34/140 Iteration: 2910 Train loss: 0.963697 Train acc: 0.536621\n",
      "Epoch: 34/140 Iteration: 2915 Train loss: 1.076557 Train acc: 0.415527\n",
      "Epoch: 34/140 Iteration: 2920 Train loss: 0.922497 Train acc: 0.563477\n",
      "Epoch: 34/140 Iteration: 2925 Train loss: 0.857476 Train acc: 0.617188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34/140 Iteration: 2930 Train loss: 0.827949 Train acc: 0.653809\n",
      "Epoch: 34/140 Iteration: 2935 Train loss: 0.986013 Train acc: 0.470703\n",
      "Epoch: 34/140 Iteration: 2940 Train loss: 0.850198 Train acc: 0.609863\n",
      "Epoch: 34/140 Iteration: 2945 Train loss: 0.927040 Train acc: 0.593750\n",
      "Epoch: 34/140 Iteration: 2950 Train loss: 1.043231 Train acc: 0.485352\n",
      "Epoch: 34/140 Iteration: 2955 Train loss: 0.964124 Train acc: 0.404785\n",
      "Epoch: 34/140 Iteration: 2960 Train loss: 0.937960 Train acc: 0.497070\n",
      "Epoch: 34/140 Iteration: 2965 Train loss: 0.921747 Train acc: 0.468750\n",
      "Epoch: 34/140 Iteration: 2970 Train loss: 1.034847 Train acc: 0.452148\n",
      "Epoch: 34/140 Iteration: 2975 Train loss: 0.990725 Train acc: 0.493652\n",
      "Epoch: 35/140 Iteration: 2980 Train loss: 0.938064 Train acc: 0.537598\n",
      "Epoch: 35/140 Iteration: 2985 Train loss: 0.969242 Train acc: 0.499023\n",
      "Epoch: 35/140 Iteration: 2990 Train loss: 0.985815 Train acc: 0.517090\n",
      "Epoch: 35/140 Iteration: 2995 Train loss: 0.992154 Train acc: 0.511719\n",
      "Epoch: 35/140 Iteration: 3000 Train loss: 1.072100 Train acc: 0.413086\n",
      "Epoch: 35/140 Iteration: 3005 Train loss: 0.944219 Train acc: 0.576172\n",
      "Epoch: 35/140 Iteration: 3010 Train loss: 0.871205 Train acc: 0.645508\n",
      "Epoch: 35/140 Iteration: 3015 Train loss: 0.811466 Train acc: 0.659668\n",
      "Epoch: 35/140 Iteration: 3020 Train loss: 0.988464 Train acc: 0.456543\n",
      "Epoch: 35/140 Iteration: 3025 Train loss: 0.830688 Train acc: 0.640137\n",
      "Epoch: 35/140 Iteration: 3030 Train loss: 0.936196 Train acc: 0.585449\n",
      "Epoch: 35/140 Iteration: 3035 Train loss: 1.036536 Train acc: 0.502441\n",
      "Epoch: 35/140 Iteration: 3040 Train loss: 0.966229 Train acc: 0.412109\n",
      "Epoch: 35/140 Iteration: 3045 Train loss: 0.943647 Train acc: 0.506836\n",
      "Epoch: 35/140 Iteration: 3050 Train loss: 0.925505 Train acc: 0.474121\n",
      "Epoch: 35/140 Iteration: 3055 Train loss: 1.029586 Train acc: 0.466309\n",
      "Epoch: 35/140 Iteration: 3060 Train loss: 1.030099 Train acc: 0.486328\n",
      "Epoch: 36/140 Iteration: 3065 Train loss: 0.937414 Train acc: 0.541016\n",
      "Epoch: 36/140 Iteration: 3070 Train loss: 0.989316 Train acc: 0.494141\n",
      "Epoch: 36/140 Iteration: 3075 Train loss: 0.978206 Train acc: 0.526855\n",
      "Epoch: 36/140 Iteration: 3080 Train loss: 0.980797 Train acc: 0.520508\n",
      "Epoch: 36/140 Iteration: 3085 Train loss: 1.073073 Train acc: 0.391113\n",
      "Epoch: 36/140 Iteration: 3090 Train loss: 0.913382 Train acc: 0.601074\n",
      "Epoch: 36/140 Iteration: 3095 Train loss: 0.842590 Train acc: 0.604980\n",
      "Epoch: 36/140 Iteration: 3100 Train loss: 0.809594 Train acc: 0.680176\n",
      "Epoch: 36/140 Iteration: 3105 Train loss: 0.988574 Train acc: 0.508789\n",
      "Epoch: 36/140 Iteration: 3110 Train loss: 0.817492 Train acc: 0.632812\n",
      "Epoch: 36/140 Iteration: 3115 Train loss: 0.908983 Train acc: 0.618652\n",
      "Epoch: 36/140 Iteration: 3120 Train loss: 1.077013 Train acc: 0.419922\n",
      "Epoch: 36/140 Iteration: 3125 Train loss: 0.981979 Train acc: 0.389648\n",
      "Epoch: 36/140 Iteration: 3130 Train loss: 0.952983 Train acc: 0.489746\n",
      "Epoch: 36/140 Iteration: 3135 Train loss: 0.937920 Train acc: 0.468262\n",
      "Epoch: 36/140 Iteration: 3140 Train loss: 1.019830 Train acc: 0.445801\n",
      "Epoch: 36/140 Iteration: 3145 Train loss: 0.974961 Train acc: 0.482910\n",
      "Epoch: 37/140 Iteration: 3150 Train loss: 0.938038 Train acc: 0.552246\n",
      "Epoch: 37/140 Iteration: 3155 Train loss: 0.982398 Train acc: 0.492676\n",
      "Epoch: 37/140 Iteration: 3160 Train loss: 0.965584 Train acc: 0.527344\n",
      "Epoch: 37/140 Iteration: 3165 Train loss: 0.975566 Train acc: 0.538574\n",
      "Epoch: 37/140 Iteration: 3170 Train loss: 1.062474 Train acc: 0.410645\n",
      "Epoch: 37/140 Iteration: 3175 Train loss: 0.898076 Train acc: 0.583496\n",
      "Epoch: 37/140 Iteration: 3180 Train loss: 0.840866 Train acc: 0.630371\n",
      "Epoch: 37/140 Iteration: 3185 Train loss: 0.798846 Train acc: 0.667969\n",
      "Epoch: 37/140 Iteration: 3190 Train loss: 0.997327 Train acc: 0.454102\n",
      "Epoch: 37/140 Iteration: 3195 Train loss: 0.834766 Train acc: 0.617188\n",
      "Epoch: 37/140 Iteration: 3200 Train loss: 0.918195 Train acc: 0.607422\n",
      "Epoch: 37/140 Iteration: 3205 Train loss: 1.048945 Train acc: 0.461426\n",
      "Epoch: 37/140 Iteration: 3210 Train loss: 0.979196 Train acc: 0.401367\n",
      "Epoch: 37/140 Iteration: 3215 Train loss: 0.949573 Train acc: 0.491699\n",
      "Epoch: 37/140 Iteration: 3220 Train loss: 0.940857 Train acc: 0.454102\n",
      "Epoch: 37/140 Iteration: 3225 Train loss: 1.016490 Train acc: 0.462402\n",
      "Epoch: 37/140 Iteration: 3230 Train loss: 0.967646 Train acc: 0.484375\n",
      "Epoch: 38/140 Iteration: 3235 Train loss: 0.933242 Train acc: 0.545410\n",
      "Epoch: 38/140 Iteration: 3240 Train loss: 0.982159 Train acc: 0.491211\n",
      "Epoch: 38/140 Iteration: 3245 Train loss: 0.944885 Train acc: 0.544922\n",
      "Epoch: 38/140 Iteration: 3250 Train loss: 0.963210 Train acc: 0.543945\n",
      "Epoch: 38/140 Iteration: 3255 Train loss: 1.049746 Train acc: 0.419922\n",
      "Epoch: 38/140 Iteration: 3260 Train loss: 0.901459 Train acc: 0.585938\n",
      "Epoch: 38/140 Iteration: 3265 Train loss: 0.818851 Train acc: 0.647461\n",
      "Epoch: 38/140 Iteration: 3270 Train loss: 0.794697 Train acc: 0.656250\n",
      "Epoch: 38/140 Iteration: 3275 Train loss: 0.999114 Train acc: 0.459473\n",
      "Epoch: 38/140 Iteration: 3280 Train loss: 0.809089 Train acc: 0.642090\n",
      "Epoch: 38/140 Iteration: 3285 Train loss: 0.911272 Train acc: 0.633789\n",
      "Epoch: 38/140 Iteration: 3290 Train loss: 1.055088 Train acc: 0.458008\n",
      "Epoch: 38/140 Iteration: 3295 Train loss: 0.971575 Train acc: 0.403320\n",
      "Epoch: 38/140 Iteration: 3300 Train loss: 0.948790 Train acc: 0.478027\n",
      "Epoch: 38/140 Iteration: 3305 Train loss: 0.934867 Train acc: 0.474121\n",
      "Epoch: 38/140 Iteration: 3310 Train loss: 1.009923 Train acc: 0.473633\n",
      "Epoch: 38/140 Iteration: 3315 Train loss: 0.983509 Train acc: 0.497559\n",
      "Epoch: 39/140 Iteration: 3320 Train loss: 0.928328 Train acc: 0.562012\n",
      "Epoch: 39/140 Iteration: 3325 Train loss: 0.980642 Train acc: 0.494629\n",
      "Epoch: 39/140 Iteration: 3330 Train loss: 0.925159 Train acc: 0.566406\n",
      "Epoch: 39/140 Iteration: 3335 Train loss: 0.964146 Train acc: 0.539551\n",
      "Epoch: 39/140 Iteration: 3340 Train loss: 1.058446 Train acc: 0.417480\n",
      "Epoch: 39/140 Iteration: 3345 Train loss: 0.876264 Train acc: 0.610840\n",
      "Epoch: 39/140 Iteration: 3350 Train loss: 0.869558 Train acc: 0.604004\n",
      "Epoch: 39/140 Iteration: 3355 Train loss: 0.826409 Train acc: 0.663086\n",
      "Epoch: 39/140 Iteration: 3360 Train loss: 0.992877 Train acc: 0.460449\n",
      "Epoch: 39/140 Iteration: 3365 Train loss: 0.842205 Train acc: 0.617676\n",
      "Epoch: 39/140 Iteration: 3370 Train loss: 0.917255 Train acc: 0.579102\n",
      "Epoch: 39/140 Iteration: 3375 Train loss: 1.056233 Train acc: 0.477539\n",
      "Epoch: 39/140 Iteration: 3380 Train loss: 0.971385 Train acc: 0.411621\n",
      "Epoch: 39/140 Iteration: 3385 Train loss: 0.943668 Train acc: 0.492188\n",
      "Epoch: 39/140 Iteration: 3390 Train loss: 0.941383 Train acc: 0.460938\n",
      "Epoch: 39/140 Iteration: 3395 Train loss: 1.011921 Train acc: 0.484863\n",
      "Epoch: 39/140 Iteration: 3400 Train loss: 0.987918 Train acc: 0.454102\n",
      "Epoch: 40/140 Iteration: 3405 Train loss: 0.932125 Train acc: 0.559570\n",
      "Epoch: 40/140 Iteration: 3410 Train loss: 0.971949 Train acc: 0.504883\n",
      "Epoch: 40/140 Iteration: 3415 Train loss: 0.989925 Train acc: 0.484863\n",
      "Epoch: 40/140 Iteration: 3420 Train loss: 0.979420 Train acc: 0.540039\n",
      "Epoch: 40/140 Iteration: 3425 Train loss: 1.085253 Train acc: 0.382324\n",
      "Epoch: 40/140 Iteration: 3430 Train loss: 0.951007 Train acc: 0.538574\n",
      "Epoch: 40/140 Iteration: 3435 Train loss: 0.880002 Train acc: 0.595215\n",
      "Epoch: 40/140 Iteration: 3440 Train loss: 0.859885 Train acc: 0.637207\n",
      "Epoch: 40/140 Iteration: 3445 Train loss: 0.986110 Train acc: 0.431152\n",
      "Epoch: 40/140 Iteration: 3450 Train loss: 0.829531 Train acc: 0.654785\n",
      "Epoch: 40/140 Iteration: 3455 Train loss: 0.919001 Train acc: 0.605469\n",
      "Epoch: 40/140 Iteration: 3460 Train loss: 1.059010 Train acc: 0.450684\n",
      "Epoch: 40/140 Iteration: 3465 Train loss: 0.986225 Train acc: 0.395020\n",
      "Epoch: 40/140 Iteration: 3470 Train loss: 0.971102 Train acc: 0.520020\n",
      "Epoch: 40/140 Iteration: 3475 Train loss: 0.946031 Train acc: 0.416016\n",
      "Epoch: 40/140 Iteration: 3480 Train loss: 1.055969 Train acc: 0.441895\n",
      "Epoch: 40/140 Iteration: 3485 Train loss: 1.011484 Train acc: 0.451660\n",
      "Epoch: 41/140 Iteration: 3490 Train loss: 0.943092 Train acc: 0.541504\n",
      "Epoch: 41/140 Iteration: 3495 Train loss: 0.979759 Train acc: 0.495117\n",
      "Epoch: 41/140 Iteration: 3500 Train loss: 0.987855 Train acc: 0.502441\n",
      "Epoch: 41/140 Iteration: 3505 Train loss: 0.978232 Train acc: 0.507324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41/140 Iteration: 3510 Train loss: 1.053163 Train acc: 0.403320\n",
      "Epoch: 41/140 Iteration: 3515 Train loss: 0.909134 Train acc: 0.583984\n",
      "Epoch: 41/140 Iteration: 3520 Train loss: 0.861326 Train acc: 0.619629\n",
      "Epoch: 41/140 Iteration: 3525 Train loss: 0.797077 Train acc: 0.677734\n",
      "Epoch: 41/140 Iteration: 3530 Train loss: 0.988122 Train acc: 0.484863\n",
      "Epoch: 41/140 Iteration: 3535 Train loss: 0.818586 Train acc: 0.632812\n",
      "Epoch: 41/140 Iteration: 3540 Train loss: 0.912408 Train acc: 0.606934\n",
      "Epoch: 41/140 Iteration: 3545 Train loss: 1.063993 Train acc: 0.436035\n",
      "Epoch: 41/140 Iteration: 3550 Train loss: 0.999493 Train acc: 0.385742\n",
      "Epoch: 41/140 Iteration: 3555 Train loss: 0.967916 Train acc: 0.459473\n",
      "Epoch: 41/140 Iteration: 3560 Train loss: 0.946826 Train acc: 0.471191\n",
      "Epoch: 41/140 Iteration: 3565 Train loss: 1.005625 Train acc: 0.462402\n",
      "Epoch: 41/140 Iteration: 3570 Train loss: 0.990704 Train acc: 0.453613\n",
      "Epoch: 42/140 Iteration: 3575 Train loss: 0.948972 Train acc: 0.553711\n",
      "Epoch: 42/140 Iteration: 3580 Train loss: 0.962470 Train acc: 0.522949\n",
      "Epoch: 42/140 Iteration: 3585 Train loss: 0.937600 Train acc: 0.550781\n",
      "Epoch: 42/140 Iteration: 3590 Train loss: 0.968173 Train acc: 0.537598\n",
      "Epoch: 42/140 Iteration: 3595 Train loss: 1.060384 Train acc: 0.415039\n",
      "Epoch: 42/140 Iteration: 3600 Train loss: 0.894607 Train acc: 0.604980\n",
      "Epoch: 42/140 Iteration: 3605 Train loss: 0.795396 Train acc: 0.664062\n",
      "Epoch: 42/140 Iteration: 3610 Train loss: 0.806248 Train acc: 0.663574\n",
      "Epoch: 42/140 Iteration: 3615 Train loss: 0.976946 Train acc: 0.439941\n",
      "Epoch: 42/140 Iteration: 3620 Train loss: 0.802240 Train acc: 0.657227\n",
      "Epoch: 42/140 Iteration: 3625 Train loss: 0.917523 Train acc: 0.590820\n",
      "Epoch: 42/140 Iteration: 3630 Train loss: 1.036821 Train acc: 0.492676\n",
      "Epoch: 42/140 Iteration: 3635 Train loss: 0.972971 Train acc: 0.395508\n",
      "Epoch: 42/140 Iteration: 3640 Train loss: 0.943925 Train acc: 0.541016\n",
      "Epoch: 42/140 Iteration: 3645 Train loss: 0.935331 Train acc: 0.452637\n",
      "Epoch: 42/140 Iteration: 3650 Train loss: 1.020300 Train acc: 0.453613\n",
      "Epoch: 42/140 Iteration: 3655 Train loss: 1.001474 Train acc: 0.469238\n",
      "Epoch: 43/140 Iteration: 3660 Train loss: 0.929474 Train acc: 0.559082\n",
      "Epoch: 43/140 Iteration: 3665 Train loss: 0.959020 Train acc: 0.516113\n",
      "Epoch: 43/140 Iteration: 3670 Train loss: 0.967196 Train acc: 0.513672\n",
      "Epoch: 43/140 Iteration: 3675 Train loss: 0.947976 Train acc: 0.550293\n",
      "Epoch: 43/140 Iteration: 3680 Train loss: 1.054364 Train acc: 0.419922\n",
      "Epoch: 43/140 Iteration: 3685 Train loss: 0.877101 Train acc: 0.600098\n",
      "Epoch: 43/140 Iteration: 3690 Train loss: 0.821366 Train acc: 0.628418\n",
      "Epoch: 43/140 Iteration: 3695 Train loss: 0.809105 Train acc: 0.667969\n",
      "Epoch: 43/140 Iteration: 3700 Train loss: 0.968916 Train acc: 0.464844\n",
      "Epoch: 43/140 Iteration: 3705 Train loss: 0.810384 Train acc: 0.671387\n",
      "Epoch: 43/140 Iteration: 3710 Train loss: 0.919768 Train acc: 0.607910\n",
      "Epoch: 43/140 Iteration: 3715 Train loss: 1.056410 Train acc: 0.475098\n",
      "Epoch: 43/140 Iteration: 3720 Train loss: 0.965103 Train acc: 0.412109\n",
      "Epoch: 43/140 Iteration: 3725 Train loss: 0.932535 Train acc: 0.485840\n",
      "Epoch: 43/140 Iteration: 3730 Train loss: 0.927771 Train acc: 0.475586\n",
      "Epoch: 43/140 Iteration: 3735 Train loss: 1.015169 Train acc: 0.452148\n",
      "Epoch: 43/140 Iteration: 3740 Train loss: 0.995293 Train acc: 0.443848\n",
      "Epoch: 44/140 Iteration: 3745 Train loss: 0.949103 Train acc: 0.542480\n",
      "Epoch: 44/140 Iteration: 3750 Train loss: 0.966140 Train acc: 0.510742\n",
      "Epoch: 44/140 Iteration: 3755 Train loss: 0.964170 Train acc: 0.510742\n",
      "Epoch: 44/140 Iteration: 3760 Train loss: 0.949079 Train acc: 0.531250\n",
      "Epoch: 44/140 Iteration: 3765 Train loss: 1.051207 Train acc: 0.408203\n",
      "Epoch: 44/140 Iteration: 3770 Train loss: 0.881755 Train acc: 0.578125\n",
      "Epoch: 44/140 Iteration: 3775 Train loss: 0.817855 Train acc: 0.643066\n",
      "Epoch: 44/140 Iteration: 3780 Train loss: 0.792364 Train acc: 0.665039\n",
      "Epoch: 44/140 Iteration: 3785 Train loss: 0.979735 Train acc: 0.479980\n",
      "Epoch: 44/140 Iteration: 3790 Train loss: 0.818579 Train acc: 0.630859\n",
      "Epoch: 44/140 Iteration: 3795 Train loss: 0.914186 Train acc: 0.623047\n",
      "Epoch: 44/140 Iteration: 3800 Train loss: 1.048350 Train acc: 0.456543\n",
      "Epoch: 44/140 Iteration: 3805 Train loss: 0.970756 Train acc: 0.402344\n",
      "Epoch: 44/140 Iteration: 3810 Train loss: 0.942639 Train acc: 0.487793\n",
      "Epoch: 44/140 Iteration: 3815 Train loss: 0.938794 Train acc: 0.450195\n",
      "Epoch: 44/140 Iteration: 3820 Train loss: 1.003774 Train acc: 0.475586\n",
      "Epoch: 44/140 Iteration: 3825 Train loss: 0.996460 Train acc: 0.464844\n",
      "Epoch: 45/140 Iteration: 3830 Train loss: 0.927924 Train acc: 0.562012\n",
      "Epoch: 45/140 Iteration: 3835 Train loss: 0.968179 Train acc: 0.494141\n",
      "Epoch: 45/140 Iteration: 3840 Train loss: 0.960543 Train acc: 0.508301\n",
      "Epoch: 45/140 Iteration: 3845 Train loss: 0.954101 Train acc: 0.538574\n",
      "Epoch: 45/140 Iteration: 3850 Train loss: 1.044441 Train acc: 0.430176\n",
      "Epoch: 45/140 Iteration: 3855 Train loss: 0.862754 Train acc: 0.615723\n",
      "Epoch: 45/140 Iteration: 3860 Train loss: 0.836275 Train acc: 0.629883\n",
      "Epoch: 45/140 Iteration: 3865 Train loss: 0.808308 Train acc: 0.669434\n",
      "Epoch: 45/140 Iteration: 3870 Train loss: 0.953074 Train acc: 0.471680\n",
      "Epoch: 45/140 Iteration: 3875 Train loss: 0.816738 Train acc: 0.644531\n",
      "Epoch: 45/140 Iteration: 3880 Train loss: 0.918846 Train acc: 0.606445\n",
      "Epoch: 45/140 Iteration: 3885 Train loss: 1.025891 Train acc: 0.497559\n",
      "Epoch: 45/140 Iteration: 3890 Train loss: 0.976501 Train acc: 0.399414\n",
      "Epoch: 45/140 Iteration: 3895 Train loss: 0.930700 Train acc: 0.482422\n",
      "Epoch: 45/140 Iteration: 3900 Train loss: 0.927822 Train acc: 0.486816\n",
      "Epoch: 45/140 Iteration: 3905 Train loss: 1.012916 Train acc: 0.514648\n",
      "Epoch: 45/140 Iteration: 3910 Train loss: 0.989778 Train acc: 0.444824\n",
      "Epoch: 46/140 Iteration: 3915 Train loss: 0.943300 Train acc: 0.547363\n",
      "Epoch: 46/140 Iteration: 3920 Train loss: 0.974260 Train acc: 0.509766\n",
      "Epoch: 46/140 Iteration: 3925 Train loss: 0.922901 Train acc: 0.531738\n",
      "Epoch: 46/140 Iteration: 3930 Train loss: 0.941379 Train acc: 0.541016\n",
      "Epoch: 46/140 Iteration: 3935 Train loss: 1.049662 Train acc: 0.424316\n",
      "Epoch: 46/140 Iteration: 3940 Train loss: 0.858639 Train acc: 0.613281\n",
      "Epoch: 46/140 Iteration: 3945 Train loss: 0.781747 Train acc: 0.670410\n",
      "Epoch: 46/140 Iteration: 3950 Train loss: 0.797954 Train acc: 0.666016\n",
      "Epoch: 46/140 Iteration: 3955 Train loss: 0.952925 Train acc: 0.481934\n",
      "Epoch: 46/140 Iteration: 3960 Train loss: 0.794267 Train acc: 0.659180\n",
      "Epoch: 46/140 Iteration: 3965 Train loss: 0.916666 Train acc: 0.619141\n",
      "Epoch: 46/140 Iteration: 3970 Train loss: 1.053027 Train acc: 0.468750\n",
      "Epoch: 46/140 Iteration: 3975 Train loss: 1.001628 Train acc: 0.381348\n",
      "Epoch: 46/140 Iteration: 3980 Train loss: 0.930408 Train acc: 0.516113\n",
      "Epoch: 46/140 Iteration: 3985 Train loss: 0.937476 Train acc: 0.458496\n",
      "Epoch: 46/140 Iteration: 3990 Train loss: 0.991209 Train acc: 0.500488\n",
      "Epoch: 46/140 Iteration: 3995 Train loss: 1.000647 Train acc: 0.470215\n",
      "Epoch: 47/140 Iteration: 4000 Train loss: 0.952546 Train acc: 0.544434\n",
      "Epoch: 47/140 Iteration: 4005 Train loss: 0.951311 Train acc: 0.526855\n",
      "Epoch: 47/140 Iteration: 4010 Train loss: 0.970362 Train acc: 0.510742\n",
      "Epoch: 47/140 Iteration: 4015 Train loss: 0.949037 Train acc: 0.547363\n",
      "Epoch: 47/140 Iteration: 4020 Train loss: 1.054243 Train acc: 0.428223\n",
      "Epoch: 47/140 Iteration: 4025 Train loss: 0.884475 Train acc: 0.589844\n",
      "Epoch: 47/140 Iteration: 4030 Train loss: 0.799796 Train acc: 0.667480\n",
      "Epoch: 47/140 Iteration: 4035 Train loss: 0.783205 Train acc: 0.670898\n",
      "Epoch: 47/140 Iteration: 4040 Train loss: 0.968403 Train acc: 0.493164\n",
      "Epoch: 47/140 Iteration: 4045 Train loss: 0.810780 Train acc: 0.663086\n",
      "Epoch: 47/140 Iteration: 4050 Train loss: 0.919103 Train acc: 0.608398\n",
      "Epoch: 47/140 Iteration: 4055 Train loss: 1.070201 Train acc: 0.467285\n",
      "Epoch: 47/140 Iteration: 4060 Train loss: 1.003903 Train acc: 0.384277\n",
      "Epoch: 47/140 Iteration: 4065 Train loss: 0.928334 Train acc: 0.526855\n",
      "Epoch: 47/140 Iteration: 4070 Train loss: 0.946498 Train acc: 0.424805\n",
      "Epoch: 47/140 Iteration: 4075 Train loss: 1.033525 Train acc: 0.476074\n",
      "Epoch: 47/140 Iteration: 4080 Train loss: 1.009319 Train acc: 0.443848\n",
      "Epoch: 48/140 Iteration: 4085 Train loss: 0.928867 Train acc: 0.554199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48/140 Iteration: 4090 Train loss: 0.953896 Train acc: 0.516113\n",
      "Epoch: 48/140 Iteration: 4095 Train loss: 0.954910 Train acc: 0.535156\n",
      "Epoch: 48/140 Iteration: 4100 Train loss: 0.921737 Train acc: 0.567871\n",
      "Epoch: 48/140 Iteration: 4105 Train loss: 1.070127 Train acc: 0.413574\n",
      "Epoch: 48/140 Iteration: 4110 Train loss: 0.846353 Train acc: 0.638184\n",
      "Epoch: 48/140 Iteration: 4115 Train loss: 0.858406 Train acc: 0.610352\n",
      "Epoch: 48/140 Iteration: 4120 Train loss: 0.796465 Train acc: 0.670898\n",
      "Epoch: 48/140 Iteration: 4125 Train loss: 0.948449 Train acc: 0.519043\n",
      "Epoch: 48/140 Iteration: 4130 Train loss: 0.858604 Train acc: 0.607910\n",
      "Epoch: 48/140 Iteration: 4135 Train loss: 0.895866 Train acc: 0.631348\n",
      "Epoch: 48/140 Iteration: 4140 Train loss: 1.048632 Train acc: 0.478027\n",
      "Epoch: 48/140 Iteration: 4145 Train loss: 0.976145 Train acc: 0.384766\n",
      "Epoch: 48/140 Iteration: 4150 Train loss: 0.969722 Train acc: 0.493164\n",
      "Epoch: 48/140 Iteration: 4155 Train loss: 0.925067 Train acc: 0.455078\n",
      "Epoch: 48/140 Iteration: 4160 Train loss: 0.970226 Train acc: 0.492188\n",
      "Epoch: 48/140 Iteration: 4165 Train loss: 0.955699 Train acc: 0.463867\n",
      "Epoch: 49/140 Iteration: 4170 Train loss: 0.924744 Train acc: 0.560547\n",
      "Epoch: 49/140 Iteration: 4175 Train loss: 0.965427 Train acc: 0.508789\n",
      "Epoch: 49/140 Iteration: 4180 Train loss: 0.966508 Train acc: 0.499512\n",
      "Epoch: 49/140 Iteration: 4185 Train loss: 0.936286 Train acc: 0.545898\n",
      "Epoch: 49/140 Iteration: 4190 Train loss: 1.046720 Train acc: 0.415527\n",
      "Epoch: 49/140 Iteration: 4195 Train loss: 0.941299 Train acc: 0.562988\n",
      "Epoch: 49/140 Iteration: 4200 Train loss: 0.911129 Train acc: 0.588867\n",
      "Epoch: 49/140 Iteration: 4205 Train loss: 0.813642 Train acc: 0.681152\n",
      "Epoch: 49/140 Iteration: 4210 Train loss: 0.945355 Train acc: 0.487305\n",
      "Epoch: 49/140 Iteration: 4215 Train loss: 0.826599 Train acc: 0.649414\n",
      "Epoch: 49/140 Iteration: 4220 Train loss: 0.916141 Train acc: 0.621582\n",
      "Epoch: 49/140 Iteration: 4225 Train loss: 1.013686 Train acc: 0.532715\n",
      "Epoch: 49/140 Iteration: 4230 Train loss: 0.969951 Train acc: 0.410156\n",
      "Epoch: 49/140 Iteration: 4235 Train loss: 0.933438 Train acc: 0.493164\n",
      "Epoch: 49/140 Iteration: 4240 Train loss: 0.910540 Train acc: 0.460449\n",
      "Epoch: 49/140 Iteration: 4245 Train loss: 0.985236 Train acc: 0.485840\n",
      "Epoch: 49/140 Iteration: 4250 Train loss: 0.930796 Train acc: 0.496094\n",
      "Epoch: 50/140 Iteration: 4255 Train loss: 0.941492 Train acc: 0.556641\n",
      "Epoch: 50/140 Iteration: 4260 Train loss: 0.967421 Train acc: 0.519531\n",
      "Epoch: 50/140 Iteration: 4265 Train loss: 0.923214 Train acc: 0.550293\n",
      "Epoch: 50/140 Iteration: 4270 Train loss: 0.931323 Train acc: 0.561523\n",
      "Epoch: 50/140 Iteration: 4275 Train loss: 1.051488 Train acc: 0.414062\n",
      "Epoch: 50/140 Iteration: 4280 Train loss: 0.898756 Train acc: 0.591309\n",
      "Epoch: 50/140 Iteration: 4285 Train loss: 0.826555 Train acc: 0.640137\n",
      "Epoch: 50/140 Iteration: 4290 Train loss: 0.780678 Train acc: 0.664551\n",
      "Epoch: 50/140 Iteration: 4295 Train loss: 0.976057 Train acc: 0.472656\n",
      "Epoch: 50/140 Iteration: 4300 Train loss: 0.784964 Train acc: 0.653809\n",
      "Epoch: 50/140 Iteration: 4305 Train loss: 0.908336 Train acc: 0.637207\n",
      "Epoch: 50/140 Iteration: 4310 Train loss: 1.019081 Train acc: 0.519043\n",
      "Epoch: 50/140 Iteration: 4315 Train loss: 0.987702 Train acc: 0.407715\n",
      "Epoch: 50/140 Iteration: 4320 Train loss: 0.927012 Train acc: 0.505859\n",
      "Epoch: 50/140 Iteration: 4325 Train loss: 0.917808 Train acc: 0.453125\n",
      "Epoch: 50/140 Iteration: 4330 Train loss: 0.984298 Train acc: 0.470215\n",
      "Epoch: 50/140 Iteration: 4335 Train loss: 0.961619 Train acc: 0.470215\n",
      "Epoch: 51/140 Iteration: 4340 Train loss: 0.937278 Train acc: 0.551758\n",
      "Epoch: 51/140 Iteration: 4345 Train loss: 0.965141 Train acc: 0.503418\n",
      "Epoch: 51/140 Iteration: 4350 Train loss: 0.924127 Train acc: 0.547852\n",
      "Epoch: 51/140 Iteration: 4355 Train loss: 0.926975 Train acc: 0.569336\n",
      "Epoch: 51/140 Iteration: 4360 Train loss: 1.036411 Train acc: 0.438965\n",
      "Epoch: 51/140 Iteration: 4365 Train loss: 0.876227 Train acc: 0.608398\n",
      "Epoch: 51/140 Iteration: 4370 Train loss: 0.806532 Train acc: 0.666016\n",
      "Epoch: 51/140 Iteration: 4375 Train loss: 0.816556 Train acc: 0.652832\n",
      "Epoch: 51/140 Iteration: 4380 Train loss: 0.972317 Train acc: 0.461914\n",
      "Epoch: 51/140 Iteration: 4385 Train loss: 0.801155 Train acc: 0.664062\n",
      "Epoch: 51/140 Iteration: 4390 Train loss: 0.918874 Train acc: 0.628906\n",
      "Epoch: 51/140 Iteration: 4395 Train loss: 1.032800 Train acc: 0.500000\n",
      "Epoch: 51/140 Iteration: 4400 Train loss: 0.962037 Train acc: 0.416504\n",
      "Epoch: 51/140 Iteration: 4405 Train loss: 0.935954 Train acc: 0.506836\n",
      "Epoch: 51/140 Iteration: 4410 Train loss: 0.925583 Train acc: 0.471680\n",
      "Epoch: 51/140 Iteration: 4415 Train loss: 1.018724 Train acc: 0.460449\n",
      "Epoch: 51/140 Iteration: 4420 Train loss: 0.953399 Train acc: 0.476562\n",
      "Epoch: 52/140 Iteration: 4425 Train loss: 0.938658 Train acc: 0.553223\n",
      "Epoch: 52/140 Iteration: 4430 Train loss: 0.959869 Train acc: 0.513672\n",
      "Epoch: 52/140 Iteration: 4435 Train loss: 0.920455 Train acc: 0.559082\n",
      "Epoch: 52/140 Iteration: 4440 Train loss: 0.939027 Train acc: 0.544922\n",
      "Epoch: 52/140 Iteration: 4445 Train loss: 1.051958 Train acc: 0.407227\n",
      "Epoch: 52/140 Iteration: 4450 Train loss: 0.857870 Train acc: 0.631836\n",
      "Epoch: 52/140 Iteration: 4455 Train loss: 0.809002 Train acc: 0.675781\n",
      "Epoch: 52/140 Iteration: 4460 Train loss: 0.769668 Train acc: 0.683105\n",
      "Epoch: 52/140 Iteration: 4465 Train loss: 0.970429 Train acc: 0.466797\n",
      "Epoch: 52/140 Iteration: 4470 Train loss: 0.812087 Train acc: 0.652344\n",
      "Epoch: 52/140 Iteration: 4475 Train loss: 0.897413 Train acc: 0.640625\n",
      "Epoch: 52/140 Iteration: 4480 Train loss: 1.023511 Train acc: 0.498535\n",
      "Epoch: 52/140 Iteration: 4485 Train loss: 0.948157 Train acc: 0.409180\n",
      "Epoch: 52/140 Iteration: 4490 Train loss: 0.930359 Train acc: 0.494629\n",
      "Epoch: 52/140 Iteration: 4495 Train loss: 0.919013 Train acc: 0.462402\n",
      "Epoch: 52/140 Iteration: 4500 Train loss: 0.987950 Train acc: 0.474609\n",
      "Epoch: 52/140 Iteration: 4505 Train loss: 0.980750 Train acc: 0.474609\n",
      "Epoch: 53/140 Iteration: 4510 Train loss: 0.937816 Train acc: 0.548340\n",
      "Epoch: 53/140 Iteration: 4515 Train loss: 0.966535 Train acc: 0.515137\n",
      "Epoch: 53/140 Iteration: 4520 Train loss: 0.902196 Train acc: 0.559570\n",
      "Epoch: 53/140 Iteration: 4525 Train loss: 0.934791 Train acc: 0.580566\n",
      "Epoch: 53/140 Iteration: 4530 Train loss: 1.048689 Train acc: 0.417969\n",
      "Epoch: 53/140 Iteration: 4535 Train loss: 0.836785 Train acc: 0.617676\n",
      "Epoch: 53/140 Iteration: 4540 Train loss: 0.840096 Train acc: 0.634766\n",
      "Epoch: 53/140 Iteration: 4545 Train loss: 0.767715 Train acc: 0.694824\n",
      "Epoch: 53/140 Iteration: 4550 Train loss: 0.958126 Train acc: 0.502441\n",
      "Epoch: 53/140 Iteration: 4555 Train loss: 0.795811 Train acc: 0.663086\n",
      "Epoch: 53/140 Iteration: 4560 Train loss: 0.875073 Train acc: 0.642578\n",
      "Epoch: 53/140 Iteration: 4565 Train loss: 1.017064 Train acc: 0.496094\n",
      "Epoch: 53/140 Iteration: 4570 Train loss: 0.967621 Train acc: 0.404297\n",
      "Epoch: 53/140 Iteration: 4575 Train loss: 0.942048 Train acc: 0.494629\n",
      "Epoch: 53/140 Iteration: 4580 Train loss: 0.932517 Train acc: 0.478516\n",
      "Epoch: 53/140 Iteration: 4585 Train loss: 0.973005 Train acc: 0.485352\n",
      "Epoch: 53/140 Iteration: 4590 Train loss: 0.960208 Train acc: 0.469727\n",
      "Epoch: 54/140 Iteration: 4595 Train loss: 0.915641 Train acc: 0.574707\n",
      "Epoch: 54/140 Iteration: 4600 Train loss: 0.969751 Train acc: 0.506836\n",
      "Epoch: 54/140 Iteration: 4605 Train loss: 0.969819 Train acc: 0.519531\n",
      "Epoch: 54/140 Iteration: 4610 Train loss: 0.921121 Train acc: 0.566895\n",
      "Epoch: 54/140 Iteration: 4615 Train loss: 1.045212 Train acc: 0.429199\n",
      "Epoch: 54/140 Iteration: 4620 Train loss: 0.860380 Train acc: 0.598145\n",
      "Epoch: 54/140 Iteration: 4625 Train loss: 0.815016 Train acc: 0.637695\n",
      "Epoch: 54/140 Iteration: 4630 Train loss: 0.809313 Train acc: 0.667969\n",
      "Epoch: 54/140 Iteration: 4635 Train loss: 0.958768 Train acc: 0.467773\n",
      "Epoch: 54/140 Iteration: 4640 Train loss: 0.813749 Train acc: 0.642090\n",
      "Epoch: 54/140 Iteration: 4645 Train loss: 0.882437 Train acc: 0.651367\n",
      "Epoch: 54/140 Iteration: 4650 Train loss: 1.012671 Train acc: 0.512207\n",
      "Epoch: 54/140 Iteration: 4655 Train loss: 0.971083 Train acc: 0.390625\n",
      "Epoch: 54/140 Iteration: 4660 Train loss: 0.941955 Train acc: 0.476562\n",
      "Epoch: 54/140 Iteration: 4665 Train loss: 0.932448 Train acc: 0.463867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54/140 Iteration: 4670 Train loss: 1.000009 Train acc: 0.452637\n",
      "Epoch: 54/140 Iteration: 4675 Train loss: 0.965134 Train acc: 0.469238\n",
      "Epoch: 55/140 Iteration: 4680 Train loss: 0.929977 Train acc: 0.567871\n",
      "Epoch: 55/140 Iteration: 4685 Train loss: 0.972121 Train acc: 0.510742\n",
      "Epoch: 55/140 Iteration: 4690 Train loss: 0.932883 Train acc: 0.531738\n",
      "Epoch: 55/140 Iteration: 4695 Train loss: 0.919401 Train acc: 0.578613\n",
      "Epoch: 55/140 Iteration: 4700 Train loss: 1.041097 Train acc: 0.419434\n",
      "Epoch: 55/140 Iteration: 4705 Train loss: 0.841783 Train acc: 0.628418\n",
      "Epoch: 55/140 Iteration: 4710 Train loss: 0.781492 Train acc: 0.703613\n",
      "Epoch: 55/140 Iteration: 4715 Train loss: 0.773801 Train acc: 0.684082\n",
      "Epoch: 55/140 Iteration: 4720 Train loss: 0.949887 Train acc: 0.504395\n",
      "Epoch: 55/140 Iteration: 4725 Train loss: 0.780876 Train acc: 0.682129\n",
      "Epoch: 55/140 Iteration: 4730 Train loss: 0.876559 Train acc: 0.652344\n",
      "Epoch: 55/140 Iteration: 4735 Train loss: 1.003451 Train acc: 0.510742\n",
      "Epoch: 55/140 Iteration: 4740 Train loss: 0.987814 Train acc: 0.390625\n",
      "Epoch: 55/140 Iteration: 4745 Train loss: 0.924976 Train acc: 0.508301\n",
      "Epoch: 55/140 Iteration: 4750 Train loss: 0.935967 Train acc: 0.422363\n",
      "Epoch: 55/140 Iteration: 4755 Train loss: 1.033569 Train acc: 0.456543\n",
      "Epoch: 55/140 Iteration: 4760 Train loss: 1.017501 Train acc: 0.418945\n",
      "Epoch: 56/140 Iteration: 4765 Train loss: 0.955378 Train acc: 0.559570\n",
      "Epoch: 56/140 Iteration: 4770 Train loss: 0.971669 Train acc: 0.510254\n",
      "Epoch: 56/140 Iteration: 4775 Train loss: 0.949352 Train acc: 0.523438\n",
      "Epoch: 56/140 Iteration: 4780 Train loss: 0.921634 Train acc: 0.575684\n",
      "Epoch: 56/140 Iteration: 4785 Train loss: 1.034938 Train acc: 0.428223\n",
      "Epoch: 56/140 Iteration: 4790 Train loss: 0.812489 Train acc: 0.646484\n",
      "Epoch: 56/140 Iteration: 4795 Train loss: 0.762406 Train acc: 0.693359\n",
      "Epoch: 56/140 Iteration: 4800 Train loss: 0.767719 Train acc: 0.684570\n",
      "Epoch: 56/140 Iteration: 4805 Train loss: 0.972887 Train acc: 0.484863\n",
      "Epoch: 56/140 Iteration: 4810 Train loss: 0.766083 Train acc: 0.685059\n",
      "Epoch: 56/140 Iteration: 4815 Train loss: 0.901323 Train acc: 0.608398\n",
      "Epoch: 56/140 Iteration: 4820 Train loss: 1.057511 Train acc: 0.470703\n",
      "Epoch: 56/140 Iteration: 4825 Train loss: 0.977260 Train acc: 0.369629\n",
      "Epoch: 56/140 Iteration: 4830 Train loss: 0.954021 Train acc: 0.466309\n",
      "Epoch: 56/140 Iteration: 4835 Train loss: 0.926680 Train acc: 0.464844\n",
      "Epoch: 56/140 Iteration: 4840 Train loss: 1.029212 Train acc: 0.450195\n",
      "Epoch: 56/140 Iteration: 4845 Train loss: 0.955786 Train acc: 0.472168\n",
      "Epoch: 57/140 Iteration: 4850 Train loss: 0.929304 Train acc: 0.567871\n",
      "Epoch: 57/140 Iteration: 4855 Train loss: 0.984894 Train acc: 0.456543\n",
      "Epoch: 57/140 Iteration: 4860 Train loss: 0.945495 Train acc: 0.512207\n",
      "Epoch: 57/140 Iteration: 4865 Train loss: 0.918054 Train acc: 0.586914\n",
      "Epoch: 57/140 Iteration: 4870 Train loss: 1.008512 Train acc: 0.442871\n",
      "Epoch: 57/140 Iteration: 4875 Train loss: 0.803510 Train acc: 0.637695\n",
      "Epoch: 57/140 Iteration: 4880 Train loss: 0.767219 Train acc: 0.710449\n",
      "Epoch: 57/140 Iteration: 4885 Train loss: 0.781277 Train acc: 0.669434\n",
      "Epoch: 57/140 Iteration: 4890 Train loss: 0.997135 Train acc: 0.455566\n",
      "Epoch: 57/140 Iteration: 4895 Train loss: 0.798133 Train acc: 0.666016\n",
      "Epoch: 57/140 Iteration: 4900 Train loss: 0.887035 Train acc: 0.630859\n",
      "Epoch: 57/140 Iteration: 4905 Train loss: 1.020431 Train acc: 0.499023\n",
      "Epoch: 57/140 Iteration: 4910 Train loss: 0.956817 Train acc: 0.408691\n",
      "Epoch: 57/140 Iteration: 4915 Train loss: 1.009465 Train acc: 0.496582\n",
      "Epoch: 57/140 Iteration: 4920 Train loss: 0.917189 Train acc: 0.455566\n",
      "Epoch: 57/140 Iteration: 4925 Train loss: 1.011621 Train acc: 0.505371\n",
      "Epoch: 57/140 Iteration: 4930 Train loss: 0.960883 Train acc: 0.483398\n",
      "Epoch: 58/140 Iteration: 4935 Train loss: 0.940881 Train acc: 0.559082\n",
      "Epoch: 58/140 Iteration: 4940 Train loss: 0.981699 Train acc: 0.485840\n",
      "Epoch: 58/140 Iteration: 4945 Train loss: 0.906337 Train acc: 0.551270\n",
      "Epoch: 58/140 Iteration: 4950 Train loss: 0.897333 Train acc: 0.598145\n",
      "Epoch: 58/140 Iteration: 4955 Train loss: 1.035878 Train acc: 0.413574\n",
      "Epoch: 58/140 Iteration: 4960 Train loss: 0.816984 Train acc: 0.638672\n",
      "Epoch: 58/140 Iteration: 4965 Train loss: 0.786735 Train acc: 0.670410\n",
      "Epoch: 58/140 Iteration: 4970 Train loss: 0.750897 Train acc: 0.694336\n",
      "Epoch: 58/140 Iteration: 4975 Train loss: 0.943093 Train acc: 0.499023\n",
      "Epoch: 58/140 Iteration: 4980 Train loss: 0.769844 Train acc: 0.688477\n",
      "Epoch: 58/140 Iteration: 4985 Train loss: 0.891532 Train acc: 0.652832\n",
      "Epoch: 58/140 Iteration: 4990 Train loss: 1.024158 Train acc: 0.507812\n",
      "Epoch: 58/140 Iteration: 4995 Train loss: 0.939315 Train acc: 0.444824\n",
      "Epoch: 58/140 Iteration: 5000 Train loss: 0.927760 Train acc: 0.543457\n",
      "Epoch: 58/140 Iteration: 5005 Train loss: 0.934352 Train acc: 0.450195\n",
      "Epoch: 58/140 Iteration: 5010 Train loss: 1.004089 Train acc: 0.467773\n",
      "Epoch: 58/140 Iteration: 5015 Train loss: 0.956011 Train acc: 0.465332\n",
      "Epoch: 59/140 Iteration: 5020 Train loss: 0.938864 Train acc: 0.560059\n",
      "Epoch: 59/140 Iteration: 5025 Train loss: 0.955604 Train acc: 0.531738\n",
      "Epoch: 59/140 Iteration: 5030 Train loss: 0.894109 Train acc: 0.576172\n",
      "Epoch: 59/140 Iteration: 5035 Train loss: 0.899808 Train acc: 0.586426\n",
      "Epoch: 59/140 Iteration: 5040 Train loss: 1.010168 Train acc: 0.435547\n",
      "Epoch: 59/140 Iteration: 5045 Train loss: 0.815489 Train acc: 0.626465\n",
      "Epoch: 59/140 Iteration: 5050 Train loss: 0.767978 Train acc: 0.699219\n",
      "Epoch: 59/140 Iteration: 5055 Train loss: 0.758629 Train acc: 0.700195\n",
      "Epoch: 59/140 Iteration: 5060 Train loss: 0.980841 Train acc: 0.451172\n",
      "Epoch: 59/140 Iteration: 5065 Train loss: 0.799127 Train acc: 0.673828\n",
      "Epoch: 59/140 Iteration: 5070 Train loss: 0.886385 Train acc: 0.622070\n",
      "Epoch: 59/140 Iteration: 5075 Train loss: 1.013116 Train acc: 0.506348\n",
      "Epoch: 59/140 Iteration: 5080 Train loss: 0.969195 Train acc: 0.386719\n",
      "Epoch: 59/140 Iteration: 5085 Train loss: 0.941379 Train acc: 0.453613\n",
      "Epoch: 59/140 Iteration: 5090 Train loss: 0.931558 Train acc: 0.465332\n",
      "Epoch: 59/140 Iteration: 5095 Train loss: 0.996985 Train acc: 0.473633\n",
      "Epoch: 59/140 Iteration: 5100 Train loss: 0.955044 Train acc: 0.502441\n",
      "Epoch: 60/140 Iteration: 5105 Train loss: 0.946455 Train acc: 0.563477\n",
      "Epoch: 60/140 Iteration: 5110 Train loss: 0.961068 Train acc: 0.508301\n",
      "Epoch: 60/140 Iteration: 5115 Train loss: 0.922356 Train acc: 0.562500\n",
      "Epoch: 60/140 Iteration: 5120 Train loss: 0.923521 Train acc: 0.564453\n",
      "Epoch: 60/140 Iteration: 5125 Train loss: 0.992363 Train acc: 0.477051\n",
      "Epoch: 60/140 Iteration: 5130 Train loss: 0.813104 Train acc: 0.625977\n",
      "Epoch: 60/140 Iteration: 5135 Train loss: 0.758002 Train acc: 0.700195\n",
      "Epoch: 60/140 Iteration: 5140 Train loss: 0.772261 Train acc: 0.687988\n",
      "Epoch: 60/140 Iteration: 5145 Train loss: 0.974877 Train acc: 0.476074\n",
      "Epoch: 60/140 Iteration: 5150 Train loss: 0.760188 Train acc: 0.698730\n",
      "Epoch: 60/140 Iteration: 5155 Train loss: 0.871789 Train acc: 0.635254\n",
      "Epoch: 60/140 Iteration: 5160 Train loss: 1.047516 Train acc: 0.456055\n",
      "Epoch: 60/140 Iteration: 5165 Train loss: 0.961118 Train acc: 0.442871\n",
      "Epoch: 60/140 Iteration: 5170 Train loss: 0.937936 Train acc: 0.532715\n",
      "Epoch: 60/140 Iteration: 5175 Train loss: 0.940333 Train acc: 0.429688\n",
      "Epoch: 60/140 Iteration: 5180 Train loss: 1.102168 Train acc: 0.380371\n",
      "Epoch: 60/140 Iteration: 5185 Train loss: 1.021297 Train acc: 0.392090\n",
      "Epoch: 61/140 Iteration: 5190 Train loss: 0.955062 Train acc: 0.560059\n",
      "Epoch: 61/140 Iteration: 5195 Train loss: 0.949654 Train acc: 0.512207\n",
      "Epoch: 61/140 Iteration: 5200 Train loss: 0.959803 Train acc: 0.548340\n",
      "Epoch: 61/140 Iteration: 5205 Train loss: 0.938240 Train acc: 0.571289\n",
      "Epoch: 61/140 Iteration: 5210 Train loss: 1.006772 Train acc: 0.456055\n",
      "Epoch: 61/140 Iteration: 5215 Train loss: 0.803149 Train acc: 0.643066\n",
      "Epoch: 61/140 Iteration: 5220 Train loss: 0.718018 Train acc: 0.720215\n",
      "Epoch: 61/140 Iteration: 5225 Train loss: 0.778660 Train acc: 0.689453\n",
      "Epoch: 61/140 Iteration: 5230 Train loss: 0.985846 Train acc: 0.474121\n",
      "Epoch: 61/140 Iteration: 5235 Train loss: 0.763115 Train acc: 0.701660\n",
      "Epoch: 61/140 Iteration: 5240 Train loss: 0.910614 Train acc: 0.599609\n",
      "Epoch: 61/140 Iteration: 5245 Train loss: 1.028465 Train acc: 0.474121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 61/140 Iteration: 5250 Train loss: 0.960921 Train acc: 0.401367\n",
      "Epoch: 61/140 Iteration: 5255 Train loss: 0.927903 Train acc: 0.464355\n",
      "Epoch: 61/140 Iteration: 5260 Train loss: 0.939445 Train acc: 0.463867\n",
      "Epoch: 61/140 Iteration: 5265 Train loss: 1.043174 Train acc: 0.451172\n",
      "Epoch: 61/140 Iteration: 5270 Train loss: 1.028347 Train acc: 0.402832\n",
      "Epoch: 62/140 Iteration: 5275 Train loss: 0.953412 Train acc: 0.563477\n",
      "Epoch: 62/140 Iteration: 5280 Train loss: 0.959454 Train acc: 0.508301\n",
      "Epoch: 62/140 Iteration: 5285 Train loss: 0.906819 Train acc: 0.548828\n",
      "Epoch: 62/140 Iteration: 5290 Train loss: 0.904126 Train acc: 0.578125\n",
      "Epoch: 62/140 Iteration: 5295 Train loss: 0.998993 Train acc: 0.467773\n",
      "Epoch: 62/140 Iteration: 5300 Train loss: 0.817994 Train acc: 0.616211\n",
      "Epoch: 62/140 Iteration: 5305 Train loss: 0.724550 Train acc: 0.728027\n",
      "Epoch: 62/140 Iteration: 5310 Train loss: 0.792899 Train acc: 0.666992\n",
      "Epoch: 62/140 Iteration: 5315 Train loss: 0.967251 Train acc: 0.500977\n",
      "Epoch: 62/140 Iteration: 5320 Train loss: 0.759029 Train acc: 0.702637\n",
      "Epoch: 62/140 Iteration: 5325 Train loss: 0.846969 Train acc: 0.648438\n",
      "Epoch: 62/140 Iteration: 5330 Train loss: 1.032892 Train acc: 0.476562\n",
      "Epoch: 62/140 Iteration: 5335 Train loss: 0.950512 Train acc: 0.413086\n",
      "Epoch: 62/140 Iteration: 5340 Train loss: 0.928322 Train acc: 0.485840\n",
      "Epoch: 62/140 Iteration: 5345 Train loss: 0.921728 Train acc: 0.487305\n",
      "Epoch: 62/140 Iteration: 5350 Train loss: 1.040732 Train acc: 0.472168\n",
      "Epoch: 62/140 Iteration: 5355 Train loss: 1.012635 Train acc: 0.407715\n",
      "Epoch: 63/140 Iteration: 5360 Train loss: 0.950736 Train acc: 0.577148\n",
      "Epoch: 63/140 Iteration: 5365 Train loss: 0.958407 Train acc: 0.488770\n",
      "Epoch: 63/140 Iteration: 5370 Train loss: 0.891564 Train acc: 0.583984\n",
      "Epoch: 63/140 Iteration: 5375 Train loss: 0.935022 Train acc: 0.554688\n",
      "Epoch: 63/140 Iteration: 5380 Train loss: 0.996548 Train acc: 0.470703\n",
      "Epoch: 63/140 Iteration: 5385 Train loss: 0.821227 Train acc: 0.632324\n",
      "Epoch: 63/140 Iteration: 5390 Train loss: 0.758523 Train acc: 0.710938\n",
      "Epoch: 63/140 Iteration: 5395 Train loss: 0.751530 Train acc: 0.704590\n",
      "Epoch: 63/140 Iteration: 5400 Train loss: 0.977127 Train acc: 0.487305\n",
      "Epoch: 63/140 Iteration: 5405 Train loss: 0.727493 Train acc: 0.743164\n",
      "Epoch: 63/140 Iteration: 5410 Train loss: 0.856354 Train acc: 0.664551\n",
      "Epoch: 63/140 Iteration: 5415 Train loss: 1.043661 Train acc: 0.450195\n",
      "Epoch: 63/140 Iteration: 5420 Train loss: 0.948328 Train acc: 0.430664\n",
      "Epoch: 63/140 Iteration: 5425 Train loss: 0.922585 Train acc: 0.490723\n",
      "Epoch: 63/140 Iteration: 5430 Train loss: 0.918289 Train acc: 0.497559\n",
      "Epoch: 63/140 Iteration: 5435 Train loss: 1.042546 Train acc: 0.460449\n",
      "Epoch: 63/140 Iteration: 5440 Train loss: 1.048164 Train acc: 0.426270\n",
      "Epoch: 64/140 Iteration: 5445 Train loss: 0.955615 Train acc: 0.564941\n",
      "Epoch: 64/140 Iteration: 5450 Train loss: 0.948954 Train acc: 0.484863\n",
      "Epoch: 64/140 Iteration: 5455 Train loss: 0.885403 Train acc: 0.590332\n",
      "Epoch: 64/140 Iteration: 5460 Train loss: 0.877065 Train acc: 0.600098\n",
      "Epoch: 64/140 Iteration: 5465 Train loss: 1.005262 Train acc: 0.460449\n",
      "Epoch: 64/140 Iteration: 5470 Train loss: 0.761616 Train acc: 0.666992\n",
      "Epoch: 64/140 Iteration: 5475 Train loss: 0.708498 Train acc: 0.738281\n",
      "Epoch: 64/140 Iteration: 5480 Train loss: 0.796081 Train acc: 0.670410\n",
      "Epoch: 64/140 Iteration: 5485 Train loss: 0.954462 Train acc: 0.498047\n",
      "Epoch: 64/140 Iteration: 5490 Train loss: 0.764451 Train acc: 0.702637\n",
      "Epoch: 64/140 Iteration: 5495 Train loss: 0.870421 Train acc: 0.634277\n",
      "Epoch: 64/140 Iteration: 5500 Train loss: 1.068301 Train acc: 0.428223\n",
      "Epoch: 64/140 Iteration: 5505 Train loss: 0.959174 Train acc: 0.413086\n",
      "Epoch: 64/140 Iteration: 5510 Train loss: 0.936623 Train acc: 0.471680\n",
      "Epoch: 64/140 Iteration: 5515 Train loss: 0.926211 Train acc: 0.492676\n",
      "Epoch: 64/140 Iteration: 5520 Train loss: 0.995128 Train acc: 0.520996\n",
      "Epoch: 64/140 Iteration: 5525 Train loss: 1.080003 Train acc: 0.395996\n",
      "Epoch: 65/140 Iteration: 5530 Train loss: 0.972566 Train acc: 0.534180\n",
      "Epoch: 65/140 Iteration: 5535 Train loss: 0.948631 Train acc: 0.499512\n",
      "Epoch: 65/140 Iteration: 5540 Train loss: 0.869951 Train acc: 0.589844\n",
      "Epoch: 65/140 Iteration: 5545 Train loss: 0.894459 Train acc: 0.578613\n",
      "Epoch: 65/140 Iteration: 5550 Train loss: 0.981697 Train acc: 0.510254\n",
      "Epoch: 65/140 Iteration: 5555 Train loss: 0.767480 Train acc: 0.648438\n",
      "Epoch: 65/140 Iteration: 5560 Train loss: 0.697734 Train acc: 0.747070\n",
      "Epoch: 65/140 Iteration: 5565 Train loss: 0.796863 Train acc: 0.691895\n",
      "Epoch: 65/140 Iteration: 5570 Train loss: 0.971192 Train acc: 0.470215\n",
      "Epoch: 65/140 Iteration: 5575 Train loss: 0.800238 Train acc: 0.678711\n",
      "Epoch: 65/140 Iteration: 5580 Train loss: 0.847711 Train acc: 0.647461\n",
      "Epoch: 65/140 Iteration: 5585 Train loss: 1.049031 Train acc: 0.440430\n",
      "Epoch: 65/140 Iteration: 5590 Train loss: 0.966220 Train acc: 0.420898\n",
      "Epoch: 65/140 Iteration: 5595 Train loss: 0.955991 Train acc: 0.433105\n",
      "Epoch: 65/140 Iteration: 5600 Train loss: 0.923590 Train acc: 0.492188\n",
      "Epoch: 65/140 Iteration: 5605 Train loss: 1.020683 Train acc: 0.465332\n",
      "Epoch: 65/140 Iteration: 5610 Train loss: 1.032182 Train acc: 0.420410\n",
      "Epoch: 66/140 Iteration: 5615 Train loss: 0.998997 Train acc: 0.563477\n",
      "Epoch: 66/140 Iteration: 5620 Train loss: 0.932306 Train acc: 0.519531\n",
      "Epoch: 66/140 Iteration: 5625 Train loss: 0.851079 Train acc: 0.602539\n",
      "Epoch: 66/140 Iteration: 5630 Train loss: 0.906723 Train acc: 0.572266\n",
      "Epoch: 66/140 Iteration: 5635 Train loss: 0.987180 Train acc: 0.481445\n",
      "Epoch: 66/140 Iteration: 5640 Train loss: 0.801894 Train acc: 0.626953\n",
      "Epoch: 66/140 Iteration: 5645 Train loss: 0.763961 Train acc: 0.705078\n",
      "Epoch: 66/140 Iteration: 5650 Train loss: 0.810362 Train acc: 0.647949\n",
      "Epoch: 66/140 Iteration: 5655 Train loss: 0.966738 Train acc: 0.478516\n",
      "Epoch: 66/140 Iteration: 5660 Train loss: 0.792087 Train acc: 0.704590\n",
      "Epoch: 66/140 Iteration: 5665 Train loss: 0.871188 Train acc: 0.641602\n",
      "Epoch: 66/140 Iteration: 5670 Train loss: 1.108016 Train acc: 0.406738\n",
      "Epoch: 66/140 Iteration: 5675 Train loss: 0.989487 Train acc: 0.410156\n",
      "Epoch: 66/140 Iteration: 5680 Train loss: 0.924731 Train acc: 0.488281\n",
      "Epoch: 66/140 Iteration: 5685 Train loss: 0.902943 Train acc: 0.490723\n",
      "Epoch: 66/140 Iteration: 5690 Train loss: 1.061025 Train acc: 0.447266\n",
      "Epoch: 66/140 Iteration: 5695 Train loss: 1.049323 Train acc: 0.388672\n",
      "Epoch: 67/140 Iteration: 5700 Train loss: 0.995666 Train acc: 0.554688\n",
      "Epoch: 67/140 Iteration: 5705 Train loss: 0.961741 Train acc: 0.505371\n",
      "Epoch: 67/140 Iteration: 5710 Train loss: 0.893360 Train acc: 0.570312\n",
      "Epoch: 67/140 Iteration: 5715 Train loss: 0.867784 Train acc: 0.599609\n",
      "Epoch: 67/140 Iteration: 5720 Train loss: 1.006694 Train acc: 0.469727\n",
      "Epoch: 67/140 Iteration: 5725 Train loss: 0.814435 Train acc: 0.614258\n",
      "Epoch: 67/140 Iteration: 5730 Train loss: 0.715533 Train acc: 0.731934\n",
      "Epoch: 67/140 Iteration: 5735 Train loss: 0.745125 Train acc: 0.692383\n",
      "Epoch: 67/140 Iteration: 5740 Train loss: 0.937763 Train acc: 0.513184\n",
      "Epoch: 67/140 Iteration: 5745 Train loss: 0.805545 Train acc: 0.665527\n",
      "Epoch: 67/140 Iteration: 5750 Train loss: 0.830270 Train acc: 0.666016\n",
      "Epoch: 67/140 Iteration: 5755 Train loss: 1.030818 Train acc: 0.489746\n",
      "Epoch: 67/140 Iteration: 5760 Train loss: 0.960492 Train acc: 0.422363\n",
      "Epoch: 67/140 Iteration: 5765 Train loss: 0.906861 Train acc: 0.503906\n",
      "Epoch: 67/140 Iteration: 5770 Train loss: 0.899497 Train acc: 0.523438\n",
      "Epoch: 67/140 Iteration: 5775 Train loss: 1.028754 Train acc: 0.496094\n",
      "Epoch: 67/140 Iteration: 5780 Train loss: 1.041801 Train acc: 0.396484\n",
      "Epoch: 68/140 Iteration: 5785 Train loss: 0.960727 Train acc: 0.558594\n",
      "Epoch: 68/140 Iteration: 5790 Train loss: 0.940484 Train acc: 0.514648\n",
      "Epoch: 68/140 Iteration: 5795 Train loss: 0.892905 Train acc: 0.570312\n",
      "Epoch: 68/140 Iteration: 5800 Train loss: 0.888973 Train acc: 0.574707\n",
      "Epoch: 68/140 Iteration: 5805 Train loss: 1.017309 Train acc: 0.451660\n",
      "Epoch: 68/140 Iteration: 5810 Train loss: 0.801902 Train acc: 0.631836\n",
      "Epoch: 68/140 Iteration: 5815 Train loss: 0.736027 Train acc: 0.720703\n",
      "Epoch: 68/140 Iteration: 5820 Train loss: 0.842277 Train acc: 0.647461\n",
      "Epoch: 68/140 Iteration: 5825 Train loss: 1.001549 Train acc: 0.476074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68/140 Iteration: 5830 Train loss: 0.779027 Train acc: 0.685059\n",
      "Epoch: 68/140 Iteration: 5835 Train loss: 0.880495 Train acc: 0.621582\n",
      "Epoch: 68/140 Iteration: 5840 Train loss: 1.103148 Train acc: 0.417969\n",
      "Epoch: 68/140 Iteration: 5845 Train loss: 0.963299 Train acc: 0.427246\n",
      "Epoch: 68/140 Iteration: 5850 Train loss: 0.929826 Train acc: 0.470215\n",
      "Epoch: 68/140 Iteration: 5855 Train loss: 0.910926 Train acc: 0.508789\n",
      "Epoch: 68/140 Iteration: 5860 Train loss: 1.029538 Train acc: 0.479004\n",
      "Epoch: 68/140 Iteration: 5865 Train loss: 1.039468 Train acc: 0.434570\n",
      "Epoch: 69/140 Iteration: 5870 Train loss: 0.953766 Train acc: 0.565918\n",
      "Epoch: 69/140 Iteration: 5875 Train loss: 0.933209 Train acc: 0.505859\n",
      "Epoch: 69/140 Iteration: 5880 Train loss: 0.862085 Train acc: 0.580566\n",
      "Epoch: 69/140 Iteration: 5885 Train loss: 0.903928 Train acc: 0.570312\n",
      "Epoch: 69/140 Iteration: 5890 Train loss: 1.006389 Train acc: 0.481934\n",
      "Epoch: 69/140 Iteration: 5895 Train loss: 0.766420 Train acc: 0.647461\n",
      "Epoch: 69/140 Iteration: 5900 Train loss: 0.702707 Train acc: 0.737793\n",
      "Epoch: 69/140 Iteration: 5905 Train loss: 0.779443 Train acc: 0.675293\n",
      "Epoch: 69/140 Iteration: 5910 Train loss: 0.977291 Train acc: 0.482422\n",
      "Epoch: 69/140 Iteration: 5915 Train loss: 0.763170 Train acc: 0.678223\n",
      "Epoch: 69/140 Iteration: 5920 Train loss: 0.866097 Train acc: 0.632324\n",
      "Epoch: 69/140 Iteration: 5925 Train loss: 1.044446 Train acc: 0.456543\n",
      "Epoch: 69/140 Iteration: 5930 Train loss: 0.927159 Train acc: 0.475586\n",
      "Epoch: 69/140 Iteration: 5935 Train loss: 0.903262 Train acc: 0.504395\n",
      "Epoch: 69/140 Iteration: 5940 Train loss: 0.917176 Train acc: 0.487793\n",
      "Epoch: 69/140 Iteration: 5945 Train loss: 1.030559 Train acc: 0.469238\n",
      "Epoch: 69/140 Iteration: 5950 Train loss: 1.025014 Train acc: 0.414062\n",
      "Epoch: 70/140 Iteration: 5955 Train loss: 0.949261 Train acc: 0.562500\n",
      "Epoch: 70/140 Iteration: 5960 Train loss: 0.930792 Train acc: 0.523926\n",
      "Epoch: 70/140 Iteration: 5965 Train loss: 0.870291 Train acc: 0.579102\n",
      "Epoch: 70/140 Iteration: 5970 Train loss: 0.852055 Train acc: 0.596680\n",
      "Epoch: 70/140 Iteration: 5975 Train loss: 1.045916 Train acc: 0.466797\n",
      "Epoch: 70/140 Iteration: 5980 Train loss: 0.770133 Train acc: 0.660645\n",
      "Epoch: 70/140 Iteration: 5985 Train loss: 0.712516 Train acc: 0.733398\n",
      "Epoch: 70/140 Iteration: 5990 Train loss: 0.808429 Train acc: 0.667969\n",
      "Epoch: 70/140 Iteration: 5995 Train loss: 0.940016 Train acc: 0.513672\n",
      "Epoch: 70/140 Iteration: 6000 Train loss: 0.776665 Train acc: 0.682129\n",
      "Epoch: 70/140 Iteration: 6005 Train loss: 0.851751 Train acc: 0.623535\n",
      "Epoch: 70/140 Iteration: 6010 Train loss: 1.002509 Train acc: 0.493652\n",
      "Epoch: 70/140 Iteration: 6015 Train loss: 0.945797 Train acc: 0.434570\n",
      "Epoch: 70/140 Iteration: 6020 Train loss: 0.951976 Train acc: 0.469238\n",
      "Epoch: 70/140 Iteration: 6025 Train loss: 0.908851 Train acc: 0.502441\n",
      "Epoch: 70/140 Iteration: 6030 Train loss: 0.994332 Train acc: 0.500977\n",
      "Epoch: 70/140 Iteration: 6035 Train loss: 1.006008 Train acc: 0.443848\n",
      "Epoch: 71/140 Iteration: 6040 Train loss: 0.926266 Train acc: 0.583008\n",
      "Epoch: 71/140 Iteration: 6045 Train loss: 0.934250 Train acc: 0.528320\n",
      "Epoch: 71/140 Iteration: 6050 Train loss: 0.878793 Train acc: 0.566895\n",
      "Epoch: 71/140 Iteration: 6055 Train loss: 0.847072 Train acc: 0.606934\n",
      "Epoch: 71/140 Iteration: 6060 Train loss: 1.027118 Train acc: 0.458984\n",
      "Epoch: 71/140 Iteration: 6065 Train loss: 0.818545 Train acc: 0.619141\n",
      "Epoch: 71/140 Iteration: 6070 Train loss: 0.739324 Train acc: 0.712891\n",
      "Epoch: 71/140 Iteration: 6075 Train loss: 0.811655 Train acc: 0.658203\n",
      "Epoch: 71/140 Iteration: 6080 Train loss: 0.932643 Train acc: 0.521973\n",
      "Epoch: 71/140 Iteration: 6085 Train loss: 0.787282 Train acc: 0.687988\n",
      "Epoch: 71/140 Iteration: 6090 Train loss: 0.842424 Train acc: 0.646973\n",
      "Epoch: 71/140 Iteration: 6095 Train loss: 1.042873 Train acc: 0.455566\n",
      "Epoch: 71/140 Iteration: 6100 Train loss: 0.927251 Train acc: 0.481934\n",
      "Epoch: 71/140 Iteration: 6105 Train loss: 0.900634 Train acc: 0.503418\n",
      "Epoch: 71/140 Iteration: 6110 Train loss: 0.901920 Train acc: 0.535156\n",
      "Epoch: 71/140 Iteration: 6115 Train loss: 0.994956 Train acc: 0.496582\n",
      "Epoch: 71/140 Iteration: 6120 Train loss: 1.026227 Train acc: 0.422852\n",
      "Epoch: 72/140 Iteration: 6125 Train loss: 0.900479 Train acc: 0.589844\n",
      "Epoch: 72/140 Iteration: 6130 Train loss: 0.930304 Train acc: 0.507324\n",
      "Epoch: 72/140 Iteration: 6135 Train loss: 0.861201 Train acc: 0.564941\n",
      "Epoch: 72/140 Iteration: 6140 Train loss: 0.843100 Train acc: 0.614258\n",
      "Epoch: 72/140 Iteration: 6145 Train loss: 1.047950 Train acc: 0.461914\n",
      "Epoch: 72/140 Iteration: 6150 Train loss: 0.796680 Train acc: 0.636719\n",
      "Epoch: 72/140 Iteration: 6155 Train loss: 0.708713 Train acc: 0.720703\n",
      "Epoch: 72/140 Iteration: 6160 Train loss: 0.774429 Train acc: 0.654785\n",
      "Epoch: 72/140 Iteration: 6165 Train loss: 0.942217 Train acc: 0.517578\n",
      "Epoch: 72/140 Iteration: 6170 Train loss: 0.791132 Train acc: 0.686035\n",
      "Epoch: 72/140 Iteration: 6175 Train loss: 0.878072 Train acc: 0.632812\n",
      "Epoch: 72/140 Iteration: 6180 Train loss: 1.052908 Train acc: 0.444336\n",
      "Epoch: 72/140 Iteration: 6185 Train loss: 0.919113 Train acc: 0.473145\n",
      "Epoch: 72/140 Iteration: 6190 Train loss: 0.920178 Train acc: 0.507812\n",
      "Epoch: 72/140 Iteration: 6195 Train loss: 0.922251 Train acc: 0.516602\n",
      "Epoch: 72/140 Iteration: 6200 Train loss: 1.000466 Train acc: 0.498047\n",
      "Epoch: 72/140 Iteration: 6205 Train loss: 1.024314 Train acc: 0.427246\n",
      "Epoch: 73/140 Iteration: 6210 Train loss: 0.955496 Train acc: 0.590332\n",
      "Epoch: 73/140 Iteration: 6215 Train loss: 0.941241 Train acc: 0.490723\n",
      "Epoch: 73/140 Iteration: 6220 Train loss: 0.897407 Train acc: 0.542969\n",
      "Epoch: 73/140 Iteration: 6225 Train loss: 0.858235 Train acc: 0.608398\n",
      "Epoch: 73/140 Iteration: 6230 Train loss: 1.006944 Train acc: 0.468262\n",
      "Epoch: 73/140 Iteration: 6235 Train loss: 0.762975 Train acc: 0.645020\n",
      "Epoch: 73/140 Iteration: 6240 Train loss: 0.703738 Train acc: 0.706543\n",
      "Epoch: 73/140 Iteration: 6245 Train loss: 0.759402 Train acc: 0.687012\n",
      "Epoch: 73/140 Iteration: 6250 Train loss: 0.929792 Train acc: 0.522461\n",
      "Epoch: 73/140 Iteration: 6255 Train loss: 0.756585 Train acc: 0.697266\n",
      "Epoch: 73/140 Iteration: 6260 Train loss: 0.844674 Train acc: 0.657715\n",
      "Epoch: 73/140 Iteration: 6265 Train loss: 1.028218 Train acc: 0.497559\n",
      "Epoch: 73/140 Iteration: 6270 Train loss: 0.906908 Train acc: 0.505371\n",
      "Epoch: 73/140 Iteration: 6275 Train loss: 0.915300 Train acc: 0.517578\n",
      "Epoch: 73/140 Iteration: 6280 Train loss: 0.883128 Train acc: 0.533691\n",
      "Epoch: 73/140 Iteration: 6285 Train loss: 1.005294 Train acc: 0.479004\n",
      "Epoch: 73/140 Iteration: 6290 Train loss: 0.984905 Train acc: 0.435059\n",
      "Epoch: 74/140 Iteration: 6295 Train loss: 0.908176 Train acc: 0.592285\n",
      "Epoch: 74/140 Iteration: 6300 Train loss: 0.935802 Train acc: 0.513672\n",
      "Epoch: 74/140 Iteration: 6305 Train loss: 0.836502 Train acc: 0.577148\n",
      "Epoch: 74/140 Iteration: 6310 Train loss: 0.846809 Train acc: 0.598145\n",
      "Epoch: 74/140 Iteration: 6315 Train loss: 1.007146 Train acc: 0.487793\n",
      "Epoch: 74/140 Iteration: 6320 Train loss: 0.740792 Train acc: 0.677734\n",
      "Epoch: 74/140 Iteration: 6325 Train loss: 0.663231 Train acc: 0.755371\n",
      "Epoch: 74/140 Iteration: 6330 Train loss: 0.752663 Train acc: 0.687500\n",
      "Epoch: 74/140 Iteration: 6335 Train loss: 0.925460 Train acc: 0.523926\n",
      "Epoch: 74/140 Iteration: 6340 Train loss: 0.748209 Train acc: 0.696289\n",
      "Epoch: 74/140 Iteration: 6345 Train loss: 0.873321 Train acc: 0.644531\n",
      "Epoch: 74/140 Iteration: 6350 Train loss: 1.017917 Train acc: 0.497559\n",
      "Epoch: 74/140 Iteration: 6355 Train loss: 0.911368 Train acc: 0.504883\n",
      "Epoch: 74/140 Iteration: 6360 Train loss: 0.918523 Train acc: 0.501953\n",
      "Epoch: 74/140 Iteration: 6365 Train loss: 0.914808 Train acc: 0.485352\n",
      "Epoch: 74/140 Iteration: 6370 Train loss: 1.011319 Train acc: 0.486816\n",
      "Epoch: 74/140 Iteration: 6375 Train loss: 0.996215 Train acc: 0.451172\n",
      "Epoch: 75/140 Iteration: 6380 Train loss: 0.891755 Train acc: 0.608398\n",
      "Epoch: 75/140 Iteration: 6385 Train loss: 0.933715 Train acc: 0.520508\n",
      "Epoch: 75/140 Iteration: 6390 Train loss: 0.836453 Train acc: 0.573730\n",
      "Epoch: 75/140 Iteration: 6395 Train loss: 0.855994 Train acc: 0.588867\n",
      "Epoch: 75/140 Iteration: 6400 Train loss: 0.993854 Train acc: 0.470703\n",
      "Epoch: 75/140 Iteration: 6405 Train loss: 0.741111 Train acc: 0.661621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75/140 Iteration: 6410 Train loss: 0.708359 Train acc: 0.709473\n",
      "Epoch: 75/140 Iteration: 6415 Train loss: 0.801856 Train acc: 0.656250\n",
      "Epoch: 75/140 Iteration: 6420 Train loss: 0.956553 Train acc: 0.507812\n",
      "Epoch: 75/140 Iteration: 6425 Train loss: 0.768049 Train acc: 0.690918\n",
      "Epoch: 75/140 Iteration: 6430 Train loss: 0.864213 Train acc: 0.642578\n",
      "Epoch: 75/140 Iteration: 6435 Train loss: 0.986715 Train acc: 0.539551\n",
      "Epoch: 75/140 Iteration: 6440 Train loss: 0.918445 Train acc: 0.497559\n",
      "Epoch: 75/140 Iteration: 6445 Train loss: 0.895088 Train acc: 0.530273\n",
      "Epoch: 75/140 Iteration: 6450 Train loss: 0.931824 Train acc: 0.468750\n",
      "Epoch: 75/140 Iteration: 6455 Train loss: 1.034395 Train acc: 0.454590\n",
      "Epoch: 75/140 Iteration: 6460 Train loss: 1.008495 Train acc: 0.428711\n",
      "Epoch: 76/140 Iteration: 6465 Train loss: 0.894205 Train acc: 0.617676\n",
      "Epoch: 76/140 Iteration: 6470 Train loss: 0.926015 Train acc: 0.527832\n",
      "Epoch: 76/140 Iteration: 6475 Train loss: 0.837867 Train acc: 0.586914\n",
      "Epoch: 76/140 Iteration: 6480 Train loss: 0.858479 Train acc: 0.613281\n",
      "Epoch: 76/140 Iteration: 6485 Train loss: 0.951160 Train acc: 0.509766\n",
      "Epoch: 76/140 Iteration: 6490 Train loss: 0.772726 Train acc: 0.658691\n",
      "Epoch: 76/140 Iteration: 6495 Train loss: 0.640812 Train acc: 0.778320\n",
      "Epoch: 76/140 Iteration: 6500 Train loss: 0.710893 Train acc: 0.705566\n",
      "Epoch: 76/140 Iteration: 6505 Train loss: 0.922307 Train acc: 0.537598\n",
      "Epoch: 76/140 Iteration: 6510 Train loss: 0.756653 Train acc: 0.697754\n",
      "Epoch: 76/140 Iteration: 6515 Train loss: 0.842717 Train acc: 0.666504\n",
      "Epoch: 76/140 Iteration: 6520 Train loss: 0.980056 Train acc: 0.541504\n",
      "Epoch: 76/140 Iteration: 6525 Train loss: 0.933593 Train acc: 0.453125\n",
      "Epoch: 76/140 Iteration: 6530 Train loss: 0.926389 Train acc: 0.487793\n",
      "Epoch: 76/140 Iteration: 6535 Train loss: 0.905895 Train acc: 0.500000\n",
      "Epoch: 76/140 Iteration: 6540 Train loss: 0.993044 Train acc: 0.493652\n",
      "Epoch: 76/140 Iteration: 6545 Train loss: 0.987964 Train acc: 0.453613\n",
      "Epoch: 77/140 Iteration: 6550 Train loss: 0.898322 Train acc: 0.592773\n",
      "Epoch: 77/140 Iteration: 6555 Train loss: 0.917701 Train acc: 0.526855\n",
      "Epoch: 77/140 Iteration: 6560 Train loss: 0.864657 Train acc: 0.573242\n",
      "Epoch: 77/140 Iteration: 6565 Train loss: 0.835422 Train acc: 0.608887\n",
      "Epoch: 77/140 Iteration: 6570 Train loss: 0.943527 Train acc: 0.510254\n",
      "Epoch: 77/140 Iteration: 6575 Train loss: 0.750185 Train acc: 0.664551\n",
      "Epoch: 77/140 Iteration: 6580 Train loss: 0.625614 Train acc: 0.777832\n",
      "Epoch: 77/140 Iteration: 6585 Train loss: 0.742727 Train acc: 0.686035\n",
      "Epoch: 77/140 Iteration: 6590 Train loss: 0.916112 Train acc: 0.534668\n",
      "Epoch: 77/140 Iteration: 6595 Train loss: 0.693844 Train acc: 0.744141\n",
      "Epoch: 77/140 Iteration: 6600 Train loss: 0.863724 Train acc: 0.633789\n",
      "Epoch: 77/140 Iteration: 6605 Train loss: 0.979184 Train acc: 0.547852\n",
      "Epoch: 77/140 Iteration: 6610 Train loss: 0.944977 Train acc: 0.441895\n",
      "Epoch: 77/140 Iteration: 6615 Train loss: 0.911867 Train acc: 0.483398\n",
      "Epoch: 77/140 Iteration: 6620 Train loss: 0.908782 Train acc: 0.501465\n",
      "Epoch: 77/140 Iteration: 6625 Train loss: 0.985394 Train acc: 0.487305\n",
      "Epoch: 77/140 Iteration: 6630 Train loss: 0.980247 Train acc: 0.442871\n",
      "Epoch: 78/140 Iteration: 6635 Train loss: 0.920435 Train acc: 0.582031\n",
      "Epoch: 78/140 Iteration: 6640 Train loss: 0.929678 Train acc: 0.530762\n",
      "Epoch: 78/140 Iteration: 6645 Train loss: 0.801207 Train acc: 0.618652\n",
      "Epoch: 78/140 Iteration: 6650 Train loss: 0.862257 Train acc: 0.625000\n",
      "Epoch: 78/140 Iteration: 6655 Train loss: 0.937747 Train acc: 0.526367\n",
      "Epoch: 78/140 Iteration: 6660 Train loss: 0.748500 Train acc: 0.655273\n",
      "Epoch: 78/140 Iteration: 6665 Train loss: 0.663210 Train acc: 0.747070\n",
      "Epoch: 78/140 Iteration: 6670 Train loss: 0.740611 Train acc: 0.699707\n",
      "Epoch: 78/140 Iteration: 6675 Train loss: 0.919858 Train acc: 0.538574\n",
      "Epoch: 78/140 Iteration: 6680 Train loss: 0.768170 Train acc: 0.694824\n",
      "Epoch: 78/140 Iteration: 6685 Train loss: 0.841059 Train acc: 0.648438\n",
      "Epoch: 78/140 Iteration: 6690 Train loss: 0.979428 Train acc: 0.541016\n",
      "Epoch: 78/140 Iteration: 6695 Train loss: 0.936998 Train acc: 0.425293\n",
      "Epoch: 78/140 Iteration: 6700 Train loss: 0.905318 Train acc: 0.488770\n",
      "Epoch: 78/140 Iteration: 6705 Train loss: 0.887660 Train acc: 0.527832\n",
      "Epoch: 78/140 Iteration: 6710 Train loss: 0.979122 Train acc: 0.491211\n",
      "Epoch: 78/140 Iteration: 6715 Train loss: 0.958894 Train acc: 0.447266\n",
      "Epoch: 79/140 Iteration: 6720 Train loss: 0.884435 Train acc: 0.602539\n",
      "Epoch: 79/140 Iteration: 6725 Train loss: 0.913711 Train acc: 0.534180\n",
      "Epoch: 79/140 Iteration: 6730 Train loss: 0.859517 Train acc: 0.572266\n",
      "Epoch: 79/140 Iteration: 6735 Train loss: 0.835256 Train acc: 0.629395\n",
      "Epoch: 79/140 Iteration: 6740 Train loss: 0.969127 Train acc: 0.502441\n",
      "Epoch: 79/140 Iteration: 6745 Train loss: 0.754124 Train acc: 0.660156\n",
      "Epoch: 79/140 Iteration: 6750 Train loss: 0.679967 Train acc: 0.734375\n",
      "Epoch: 79/140 Iteration: 6755 Train loss: 0.738415 Train acc: 0.700195\n",
      "Epoch: 79/140 Iteration: 6760 Train loss: 0.877428 Train acc: 0.554199\n",
      "Epoch: 79/140 Iteration: 6765 Train loss: 0.735187 Train acc: 0.729492\n",
      "Epoch: 79/140 Iteration: 6770 Train loss: 0.855756 Train acc: 0.652344\n",
      "Epoch: 79/140 Iteration: 6775 Train loss: 0.930711 Train acc: 0.560547\n",
      "Epoch: 79/140 Iteration: 6780 Train loss: 0.933802 Train acc: 0.448242\n",
      "Epoch: 79/140 Iteration: 6785 Train loss: 0.901174 Train acc: 0.495605\n",
      "Epoch: 79/140 Iteration: 6790 Train loss: 0.903944 Train acc: 0.498535\n",
      "Epoch: 79/140 Iteration: 6795 Train loss: 0.981084 Train acc: 0.498535\n",
      "Epoch: 79/140 Iteration: 6800 Train loss: 0.959213 Train acc: 0.478027\n",
      "Epoch: 80/140 Iteration: 6805 Train loss: 0.898531 Train acc: 0.590820\n",
      "Epoch: 80/140 Iteration: 6810 Train loss: 0.906715 Train acc: 0.555664\n",
      "Epoch: 80/140 Iteration: 6815 Train loss: 0.764959 Train acc: 0.631836\n",
      "Epoch: 80/140 Iteration: 6820 Train loss: 0.913609 Train acc: 0.576660\n",
      "Epoch: 80/140 Iteration: 6825 Train loss: 0.914287 Train acc: 0.555176\n",
      "Epoch: 80/140 Iteration: 6830 Train loss: 0.715457 Train acc: 0.667480\n",
      "Epoch: 80/140 Iteration: 6835 Train loss: 0.630540 Train acc: 0.769043\n",
      "Epoch: 80/140 Iteration: 6840 Train loss: 0.757161 Train acc: 0.699707\n",
      "Epoch: 80/140 Iteration: 6845 Train loss: 0.910910 Train acc: 0.552734\n",
      "Epoch: 80/140 Iteration: 6850 Train loss: 0.735469 Train acc: 0.715332\n",
      "Epoch: 80/140 Iteration: 6855 Train loss: 0.855685 Train acc: 0.641602\n",
      "Epoch: 80/140 Iteration: 6860 Train loss: 0.958168 Train acc: 0.546875\n",
      "Epoch: 80/140 Iteration: 6865 Train loss: 0.938115 Train acc: 0.456055\n",
      "Epoch: 80/140 Iteration: 6870 Train loss: 0.907490 Train acc: 0.487793\n",
      "Epoch: 80/140 Iteration: 6875 Train loss: 0.895066 Train acc: 0.491211\n",
      "Epoch: 80/140 Iteration: 6880 Train loss: 0.974941 Train acc: 0.509277\n",
      "Epoch: 80/140 Iteration: 6885 Train loss: 0.940246 Train acc: 0.490723\n",
      "Epoch: 81/140 Iteration: 6890 Train loss: 0.884901 Train acc: 0.602051\n",
      "Epoch: 81/140 Iteration: 6895 Train loss: 0.896690 Train acc: 0.550781\n",
      "Epoch: 81/140 Iteration: 6900 Train loss: 0.800045 Train acc: 0.610352\n",
      "Epoch: 81/140 Iteration: 6905 Train loss: 0.921911 Train acc: 0.581543\n",
      "Epoch: 81/140 Iteration: 6910 Train loss: 0.927921 Train acc: 0.532227\n",
      "Epoch: 81/140 Iteration: 6915 Train loss: 0.733669 Train acc: 0.687988\n",
      "Epoch: 81/140 Iteration: 6920 Train loss: 0.753506 Train acc: 0.687988\n",
      "Epoch: 81/140 Iteration: 6925 Train loss: 0.735487 Train acc: 0.713867\n",
      "Epoch: 81/140 Iteration: 6930 Train loss: 0.880308 Train acc: 0.554688\n",
      "Epoch: 81/140 Iteration: 6935 Train loss: 0.734416 Train acc: 0.736816\n",
      "Epoch: 81/140 Iteration: 6940 Train loss: 0.853554 Train acc: 0.662109\n",
      "Epoch: 81/140 Iteration: 6945 Train loss: 0.981689 Train acc: 0.533691\n",
      "Epoch: 81/140 Iteration: 6950 Train loss: 0.942141 Train acc: 0.447754\n",
      "Epoch: 81/140 Iteration: 6955 Train loss: 0.918045 Train acc: 0.497070\n",
      "Epoch: 81/140 Iteration: 6960 Train loss: 0.902183 Train acc: 0.498047\n",
      "Epoch: 81/140 Iteration: 6965 Train loss: 0.953498 Train acc: 0.519043\n",
      "Epoch: 81/140 Iteration: 6970 Train loss: 0.941421 Train acc: 0.474609\n",
      "Epoch: 82/140 Iteration: 6975 Train loss: 0.896366 Train acc: 0.605957\n",
      "Epoch: 82/140 Iteration: 6980 Train loss: 0.914863 Train acc: 0.548340\n",
      "Epoch: 82/140 Iteration: 6985 Train loss: 0.802182 Train acc: 0.617676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 82/140 Iteration: 6990 Train loss: 0.833413 Train acc: 0.641602\n",
      "Epoch: 82/140 Iteration: 6995 Train loss: 0.948155 Train acc: 0.522461\n",
      "Epoch: 82/140 Iteration: 7000 Train loss: 0.729102 Train acc: 0.652832\n",
      "Epoch: 82/140 Iteration: 7005 Train loss: 0.688670 Train acc: 0.751465\n",
      "Epoch: 82/140 Iteration: 7010 Train loss: 0.753807 Train acc: 0.702637\n",
      "Epoch: 82/140 Iteration: 7015 Train loss: 0.910696 Train acc: 0.528320\n",
      "Epoch: 82/140 Iteration: 7020 Train loss: 0.703867 Train acc: 0.739258\n",
      "Epoch: 82/140 Iteration: 7025 Train loss: 0.865134 Train acc: 0.633789\n",
      "Epoch: 82/140 Iteration: 7030 Train loss: 0.953185 Train acc: 0.577637\n",
      "Epoch: 82/140 Iteration: 7035 Train loss: 0.912999 Train acc: 0.492188\n",
      "Epoch: 82/140 Iteration: 7040 Train loss: 0.917230 Train acc: 0.496094\n",
      "Epoch: 82/140 Iteration: 7045 Train loss: 0.880638 Train acc: 0.541992\n",
      "Epoch: 82/140 Iteration: 7050 Train loss: 0.985479 Train acc: 0.504395\n",
      "Epoch: 82/140 Iteration: 7055 Train loss: 0.960515 Train acc: 0.468262\n",
      "Epoch: 83/140 Iteration: 7060 Train loss: 0.914308 Train acc: 0.588379\n",
      "Epoch: 83/140 Iteration: 7065 Train loss: 0.900522 Train acc: 0.557617\n",
      "Epoch: 83/140 Iteration: 7070 Train loss: 0.801867 Train acc: 0.615234\n",
      "Epoch: 83/140 Iteration: 7075 Train loss: 0.833493 Train acc: 0.635254\n",
      "Epoch: 83/140 Iteration: 7080 Train loss: 0.914966 Train acc: 0.544434\n",
      "Epoch: 83/140 Iteration: 7085 Train loss: 0.725820 Train acc: 0.683105\n",
      "Epoch: 83/140 Iteration: 7090 Train loss: 0.711270 Train acc: 0.709961\n",
      "Epoch: 83/140 Iteration: 7095 Train loss: 0.779754 Train acc: 0.686523\n",
      "Epoch: 83/140 Iteration: 7100 Train loss: 0.902730 Train acc: 0.530762\n",
      "Epoch: 83/140 Iteration: 7105 Train loss: 0.713868 Train acc: 0.741699\n",
      "Epoch: 83/140 Iteration: 7110 Train loss: 0.840700 Train acc: 0.653320\n",
      "Epoch: 83/140 Iteration: 7115 Train loss: 0.968887 Train acc: 0.540527\n",
      "Epoch: 83/140 Iteration: 7120 Train loss: 0.918001 Train acc: 0.482910\n",
      "Epoch: 83/140 Iteration: 7125 Train loss: 0.887942 Train acc: 0.538574\n",
      "Epoch: 83/140 Iteration: 7130 Train loss: 0.868272 Train acc: 0.546875\n",
      "Epoch: 83/140 Iteration: 7135 Train loss: 0.938558 Train acc: 0.535156\n",
      "Epoch: 83/140 Iteration: 7140 Train loss: 0.961303 Train acc: 0.483887\n",
      "Epoch: 84/140 Iteration: 7145 Train loss: 0.883454 Train acc: 0.604980\n",
      "Epoch: 84/140 Iteration: 7150 Train loss: 0.874685 Train acc: 0.574219\n",
      "Epoch: 84/140 Iteration: 7155 Train loss: 0.767168 Train acc: 0.632324\n",
      "Epoch: 84/140 Iteration: 7160 Train loss: 0.857770 Train acc: 0.604980\n",
      "Epoch: 84/140 Iteration: 7165 Train loss: 0.940345 Train acc: 0.527832\n",
      "Epoch: 84/140 Iteration: 7170 Train loss: 0.713955 Train acc: 0.693848\n",
      "Epoch: 84/140 Iteration: 7175 Train loss: 0.663526 Train acc: 0.743652\n",
      "Epoch: 84/140 Iteration: 7180 Train loss: 0.768021 Train acc: 0.690918\n",
      "Epoch: 84/140 Iteration: 7185 Train loss: 0.877714 Train acc: 0.552734\n",
      "Epoch: 84/140 Iteration: 7190 Train loss: 0.675823 Train acc: 0.766113\n",
      "Epoch: 84/140 Iteration: 7195 Train loss: 0.837225 Train acc: 0.667969\n",
      "Epoch: 84/140 Iteration: 7200 Train loss: 0.965405 Train acc: 0.532227\n",
      "Epoch: 84/140 Iteration: 7205 Train loss: 0.944211 Train acc: 0.450195\n",
      "Epoch: 84/140 Iteration: 7210 Train loss: 0.883128 Train acc: 0.549805\n",
      "Epoch: 84/140 Iteration: 7215 Train loss: 0.885041 Train acc: 0.532227\n",
      "Epoch: 84/140 Iteration: 7220 Train loss: 0.957459 Train acc: 0.508789\n",
      "Epoch: 84/140 Iteration: 7225 Train loss: 0.930222 Train acc: 0.502930\n",
      "Epoch: 85/140 Iteration: 7230 Train loss: 0.901264 Train acc: 0.588867\n",
      "Epoch: 85/140 Iteration: 7235 Train loss: 0.880264 Train acc: 0.559082\n",
      "Epoch: 85/140 Iteration: 7240 Train loss: 0.749791 Train acc: 0.641113\n",
      "Epoch: 85/140 Iteration: 7245 Train loss: 0.835543 Train acc: 0.637695\n",
      "Epoch: 85/140 Iteration: 7250 Train loss: 0.942912 Train acc: 0.509277\n",
      "Epoch: 85/140 Iteration: 7255 Train loss: 0.725324 Train acc: 0.676758\n",
      "Epoch: 85/140 Iteration: 7260 Train loss: 0.706782 Train acc: 0.720215\n",
      "Epoch: 85/140 Iteration: 7265 Train loss: 0.767137 Train acc: 0.677246\n",
      "Epoch: 85/140 Iteration: 7270 Train loss: 0.904096 Train acc: 0.542480\n",
      "Epoch: 85/140 Iteration: 7275 Train loss: 0.703620 Train acc: 0.735840\n",
      "Epoch: 85/140 Iteration: 7280 Train loss: 0.828410 Train acc: 0.678223\n",
      "Epoch: 85/140 Iteration: 7285 Train loss: 0.988887 Train acc: 0.562012\n",
      "Epoch: 85/140 Iteration: 7290 Train loss: 0.940834 Train acc: 0.458984\n",
      "Epoch: 85/140 Iteration: 7295 Train loss: 0.909035 Train acc: 0.528809\n",
      "Epoch: 85/140 Iteration: 7300 Train loss: 0.918145 Train acc: 0.479980\n",
      "Epoch: 85/140 Iteration: 7305 Train loss: 0.958388 Train acc: 0.499512\n",
      "Epoch: 85/140 Iteration: 7310 Train loss: 0.932064 Train acc: 0.495605\n",
      "Epoch: 86/140 Iteration: 7315 Train loss: 0.862535 Train acc: 0.623535\n",
      "Epoch: 86/140 Iteration: 7320 Train loss: 0.895440 Train acc: 0.553223\n",
      "Epoch: 86/140 Iteration: 7325 Train loss: 0.812921 Train acc: 0.615723\n",
      "Epoch: 86/140 Iteration: 7330 Train loss: 0.828239 Train acc: 0.634766\n",
      "Epoch: 86/140 Iteration: 7335 Train loss: 0.961333 Train acc: 0.506836\n",
      "Epoch: 86/140 Iteration: 7340 Train loss: 0.778189 Train acc: 0.662109\n",
      "Epoch: 86/140 Iteration: 7345 Train loss: 0.688537 Train acc: 0.714355\n",
      "Epoch: 86/140 Iteration: 7350 Train loss: 0.731991 Train acc: 0.705566\n",
      "Epoch: 86/140 Iteration: 7355 Train loss: 0.907492 Train acc: 0.541992\n",
      "Epoch: 86/140 Iteration: 7360 Train loss: 0.714847 Train acc: 0.717773\n",
      "Epoch: 86/140 Iteration: 7365 Train loss: 0.839144 Train acc: 0.661621\n",
      "Epoch: 86/140 Iteration: 7370 Train loss: 0.976075 Train acc: 0.540039\n",
      "Epoch: 86/140 Iteration: 7375 Train loss: 0.957041 Train acc: 0.450684\n",
      "Epoch: 86/140 Iteration: 7380 Train loss: 0.918397 Train acc: 0.499023\n",
      "Epoch: 86/140 Iteration: 7385 Train loss: 0.879142 Train acc: 0.523438\n",
      "Epoch: 86/140 Iteration: 7390 Train loss: 1.035168 Train acc: 0.474609\n",
      "Epoch: 86/140 Iteration: 7395 Train loss: 0.968673 Train acc: 0.451172\n",
      "Epoch: 87/140 Iteration: 7400 Train loss: 0.874066 Train acc: 0.623535\n",
      "Epoch: 87/140 Iteration: 7405 Train loss: 0.897218 Train acc: 0.572266\n",
      "Epoch: 87/140 Iteration: 7410 Train loss: 0.768362 Train acc: 0.635742\n",
      "Epoch: 87/140 Iteration: 7415 Train loss: 0.856391 Train acc: 0.612305\n",
      "Epoch: 87/140 Iteration: 7420 Train loss: 0.901264 Train acc: 0.538574\n",
      "Epoch: 87/140 Iteration: 7425 Train loss: 0.728483 Train acc: 0.670898\n",
      "Epoch: 87/140 Iteration: 7430 Train loss: 0.615340 Train acc: 0.767578\n",
      "Epoch: 87/140 Iteration: 7435 Train loss: 0.741788 Train acc: 0.703613\n",
      "Epoch: 87/140 Iteration: 7440 Train loss: 0.900624 Train acc: 0.542480\n",
      "Epoch: 87/140 Iteration: 7445 Train loss: 0.691854 Train acc: 0.738770\n",
      "Epoch: 87/140 Iteration: 7450 Train loss: 0.853222 Train acc: 0.662109\n",
      "Epoch: 87/140 Iteration: 7455 Train loss: 0.956955 Train acc: 0.555176\n",
      "Epoch: 87/140 Iteration: 7460 Train loss: 0.950506 Train acc: 0.436035\n",
      "Epoch: 87/140 Iteration: 7465 Train loss: 0.952822 Train acc: 0.484375\n",
      "Epoch: 87/140 Iteration: 7470 Train loss: 0.879613 Train acc: 0.526855\n",
      "Epoch: 87/140 Iteration: 7475 Train loss: 0.987940 Train acc: 0.503418\n",
      "Epoch: 87/140 Iteration: 7480 Train loss: 0.956644 Train acc: 0.470215\n",
      "Epoch: 88/140 Iteration: 7485 Train loss: 0.886178 Train acc: 0.597168\n",
      "Epoch: 88/140 Iteration: 7490 Train loss: 0.876720 Train acc: 0.591309\n",
      "Epoch: 88/140 Iteration: 7495 Train loss: 0.807309 Train acc: 0.635254\n",
      "Epoch: 88/140 Iteration: 7500 Train loss: 0.819304 Train acc: 0.627930\n",
      "Epoch: 88/140 Iteration: 7505 Train loss: 0.925464 Train acc: 0.540527\n",
      "Epoch: 88/140 Iteration: 7510 Train loss: 0.718594 Train acc: 0.680176\n",
      "Epoch: 88/140 Iteration: 7515 Train loss: 0.638931 Train acc: 0.761719\n",
      "Epoch: 88/140 Iteration: 7520 Train loss: 0.733472 Train acc: 0.687012\n",
      "Epoch: 88/140 Iteration: 7525 Train loss: 0.898546 Train acc: 0.531250\n",
      "Epoch: 88/140 Iteration: 7530 Train loss: 0.687680 Train acc: 0.740723\n",
      "Epoch: 88/140 Iteration: 7535 Train loss: 0.820231 Train acc: 0.670410\n",
      "Epoch: 88/140 Iteration: 7540 Train loss: 0.949033 Train acc: 0.565918\n",
      "Epoch: 88/140 Iteration: 7545 Train loss: 0.936823 Train acc: 0.459961\n",
      "Epoch: 88/140 Iteration: 7550 Train loss: 0.966382 Train acc: 0.492188\n",
      "Epoch: 88/140 Iteration: 7555 Train loss: 0.917896 Train acc: 0.486328\n",
      "Epoch: 88/140 Iteration: 7560 Train loss: 0.947536 Train acc: 0.526367\n",
      "Epoch: 88/140 Iteration: 7565 Train loss: 0.946992 Train acc: 0.492188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 89/140 Iteration: 7570 Train loss: 0.878282 Train acc: 0.602539\n",
      "Epoch: 89/140 Iteration: 7575 Train loss: 0.875212 Train acc: 0.591797\n",
      "Epoch: 89/140 Iteration: 7580 Train loss: 0.809613 Train acc: 0.622559\n",
      "Epoch: 89/140 Iteration: 7585 Train loss: 0.823801 Train acc: 0.631348\n",
      "Epoch: 89/140 Iteration: 7590 Train loss: 0.926551 Train acc: 0.539551\n",
      "Epoch: 89/140 Iteration: 7595 Train loss: 0.732359 Train acc: 0.665039\n",
      "Epoch: 89/140 Iteration: 7600 Train loss: 0.640098 Train acc: 0.761719\n",
      "Epoch: 89/140 Iteration: 7605 Train loss: 0.706093 Train acc: 0.717773\n",
      "Epoch: 89/140 Iteration: 7610 Train loss: 0.911286 Train acc: 0.520508\n",
      "Epoch: 89/140 Iteration: 7615 Train loss: 0.678766 Train acc: 0.753906\n",
      "Epoch: 89/140 Iteration: 7620 Train loss: 0.819801 Train acc: 0.666504\n",
      "Epoch: 89/140 Iteration: 7625 Train loss: 0.950840 Train acc: 0.567383\n",
      "Epoch: 89/140 Iteration: 7630 Train loss: 0.927982 Train acc: 0.452637\n",
      "Epoch: 89/140 Iteration: 7635 Train loss: 0.928588 Train acc: 0.543457\n",
      "Epoch: 89/140 Iteration: 7640 Train loss: 0.901723 Train acc: 0.506836\n",
      "Epoch: 89/140 Iteration: 7645 Train loss: 0.927050 Train acc: 0.561523\n",
      "Epoch: 89/140 Iteration: 7650 Train loss: 0.929219 Train acc: 0.515137\n",
      "Epoch: 90/140 Iteration: 7655 Train loss: 0.871308 Train acc: 0.604980\n",
      "Epoch: 90/140 Iteration: 7660 Train loss: 0.860906 Train acc: 0.611816\n",
      "Epoch: 90/140 Iteration: 7665 Train loss: 0.766820 Train acc: 0.645020\n",
      "Epoch: 90/140 Iteration: 7670 Train loss: 0.819842 Train acc: 0.642578\n",
      "Epoch: 90/140 Iteration: 7675 Train loss: 0.898661 Train acc: 0.566895\n",
      "Epoch: 90/140 Iteration: 7680 Train loss: 0.726105 Train acc: 0.683105\n",
      "Epoch: 90/140 Iteration: 7685 Train loss: 0.627971 Train acc: 0.760742\n",
      "Epoch: 90/140 Iteration: 7690 Train loss: 0.729360 Train acc: 0.710449\n",
      "Epoch: 90/140 Iteration: 7695 Train loss: 0.899774 Train acc: 0.546387\n",
      "Epoch: 90/140 Iteration: 7700 Train loss: 0.663463 Train acc: 0.758301\n",
      "Epoch: 90/140 Iteration: 7705 Train loss: 0.805053 Train acc: 0.674316\n",
      "Epoch: 90/140 Iteration: 7710 Train loss: 0.927433 Train acc: 0.602539\n",
      "Epoch: 90/140 Iteration: 7715 Train loss: 0.913709 Train acc: 0.495605\n",
      "Epoch: 90/140 Iteration: 7720 Train loss: 0.875298 Train acc: 0.542480\n",
      "Epoch: 90/140 Iteration: 7725 Train loss: 0.881157 Train acc: 0.520996\n",
      "Epoch: 90/140 Iteration: 7730 Train loss: 0.913540 Train acc: 0.549316\n",
      "Epoch: 90/140 Iteration: 7735 Train loss: 0.924123 Train acc: 0.511719\n",
      "Epoch: 91/140 Iteration: 7740 Train loss: 0.856661 Train acc: 0.607422\n",
      "Epoch: 91/140 Iteration: 7745 Train loss: 0.849455 Train acc: 0.601074\n",
      "Epoch: 91/140 Iteration: 7750 Train loss: 0.771956 Train acc: 0.655762\n",
      "Epoch: 91/140 Iteration: 7755 Train loss: 0.819915 Train acc: 0.642090\n",
      "Epoch: 91/140 Iteration: 7760 Train loss: 0.855316 Train acc: 0.579590\n",
      "Epoch: 91/140 Iteration: 7765 Train loss: 0.710523 Train acc: 0.686035\n",
      "Epoch: 91/140 Iteration: 7770 Train loss: 0.589488 Train acc: 0.770020\n",
      "Epoch: 91/140 Iteration: 7775 Train loss: 0.695185 Train acc: 0.718750\n",
      "Epoch: 91/140 Iteration: 7780 Train loss: 0.902758 Train acc: 0.535645\n",
      "Epoch: 91/140 Iteration: 7785 Train loss: 0.663165 Train acc: 0.767578\n",
      "Epoch: 91/140 Iteration: 7790 Train loss: 0.792271 Train acc: 0.695312\n",
      "Epoch: 91/140 Iteration: 7795 Train loss: 0.926263 Train acc: 0.608398\n",
      "Epoch: 91/140 Iteration: 7800 Train loss: 0.924095 Train acc: 0.473145\n",
      "Epoch: 91/140 Iteration: 7805 Train loss: 0.890415 Train acc: 0.554199\n",
      "Epoch: 91/140 Iteration: 7810 Train loss: 0.894141 Train acc: 0.501953\n",
      "Epoch: 91/140 Iteration: 7815 Train loss: 0.951601 Train acc: 0.520020\n",
      "Epoch: 91/140 Iteration: 7820 Train loss: 0.921670 Train acc: 0.505859\n",
      "Epoch: 92/140 Iteration: 7825 Train loss: 0.878658 Train acc: 0.587891\n",
      "Epoch: 92/140 Iteration: 7830 Train loss: 0.858182 Train acc: 0.590820\n",
      "Epoch: 92/140 Iteration: 7835 Train loss: 0.758859 Train acc: 0.655273\n",
      "Epoch: 92/140 Iteration: 7840 Train loss: 0.783794 Train acc: 0.648926\n",
      "Epoch: 92/140 Iteration: 7845 Train loss: 0.922632 Train acc: 0.538086\n",
      "Epoch: 92/140 Iteration: 7850 Train loss: 0.686188 Train acc: 0.711426\n",
      "Epoch: 92/140 Iteration: 7855 Train loss: 0.582045 Train acc: 0.790039\n",
      "Epoch: 92/140 Iteration: 7860 Train loss: 0.711723 Train acc: 0.718262\n",
      "Epoch: 92/140 Iteration: 7865 Train loss: 0.897103 Train acc: 0.529297\n",
      "Epoch: 92/140 Iteration: 7870 Train loss: 0.658959 Train acc: 0.759277\n",
      "Epoch: 92/140 Iteration: 7875 Train loss: 0.819466 Train acc: 0.682617\n",
      "Epoch: 92/140 Iteration: 7880 Train loss: 0.925488 Train acc: 0.598145\n",
      "Epoch: 92/140 Iteration: 7885 Train loss: 0.904042 Train acc: 0.488281\n",
      "Epoch: 92/140 Iteration: 7890 Train loss: 0.858860 Train acc: 0.598145\n",
      "Epoch: 92/140 Iteration: 7895 Train loss: 0.879026 Train acc: 0.521484\n",
      "Epoch: 92/140 Iteration: 7900 Train loss: 0.975009 Train acc: 0.499512\n",
      "Epoch: 92/140 Iteration: 7905 Train loss: 0.906963 Train acc: 0.512695\n",
      "Epoch: 93/140 Iteration: 7910 Train loss: 0.848513 Train acc: 0.627441\n",
      "Epoch: 93/140 Iteration: 7915 Train loss: 0.839932 Train acc: 0.619629\n",
      "Epoch: 93/140 Iteration: 7920 Train loss: 0.764827 Train acc: 0.662109\n",
      "Epoch: 93/140 Iteration: 7925 Train loss: 0.786408 Train acc: 0.653320\n",
      "Epoch: 93/140 Iteration: 7930 Train loss: 0.885585 Train acc: 0.583008\n",
      "Epoch: 93/140 Iteration: 7935 Train loss: 0.705447 Train acc: 0.687012\n",
      "Epoch: 93/140 Iteration: 7940 Train loss: 0.637952 Train acc: 0.750000\n",
      "Epoch: 93/140 Iteration: 7945 Train loss: 0.678735 Train acc: 0.731445\n",
      "Epoch: 93/140 Iteration: 7950 Train loss: 0.830709 Train acc: 0.581055\n",
      "Epoch: 93/140 Iteration: 7955 Train loss: 0.629367 Train acc: 0.784180\n",
      "Epoch: 93/140 Iteration: 7960 Train loss: 0.778424 Train acc: 0.683594\n",
      "Epoch: 93/140 Iteration: 7965 Train loss: 0.920375 Train acc: 0.581543\n",
      "Epoch: 93/140 Iteration: 7970 Train loss: 0.895507 Train acc: 0.488770\n",
      "Epoch: 93/140 Iteration: 7975 Train loss: 0.892850 Train acc: 0.559082\n",
      "Epoch: 93/140 Iteration: 7980 Train loss: 0.892077 Train acc: 0.501953\n",
      "Epoch: 93/140 Iteration: 7985 Train loss: 0.978661 Train acc: 0.492188\n",
      "Epoch: 93/140 Iteration: 7990 Train loss: 0.906259 Train acc: 0.505859\n",
      "Epoch: 94/140 Iteration: 7995 Train loss: 0.837485 Train acc: 0.634277\n",
      "Epoch: 94/140 Iteration: 8000 Train loss: 0.828741 Train acc: 0.625488\n",
      "Epoch: 94/140 Iteration: 8005 Train loss: 0.752639 Train acc: 0.660645\n",
      "Epoch: 94/140 Iteration: 8010 Train loss: 0.801111 Train acc: 0.631348\n",
      "Epoch: 94/140 Iteration: 8015 Train loss: 0.893816 Train acc: 0.592285\n",
      "Epoch: 94/140 Iteration: 8020 Train loss: 0.716535 Train acc: 0.693848\n",
      "Epoch: 94/140 Iteration: 8025 Train loss: 0.594992 Train acc: 0.787109\n",
      "Epoch: 94/140 Iteration: 8030 Train loss: 0.678811 Train acc: 0.718750\n",
      "Epoch: 94/140 Iteration: 8035 Train loss: 0.861001 Train acc: 0.563477\n",
      "Epoch: 94/140 Iteration: 8040 Train loss: 0.665093 Train acc: 0.764160\n",
      "Epoch: 94/140 Iteration: 8045 Train loss: 0.800268 Train acc: 0.665527\n",
      "Epoch: 94/140 Iteration: 8050 Train loss: 0.907368 Train acc: 0.595703\n",
      "Epoch: 94/140 Iteration: 8055 Train loss: 0.875132 Train acc: 0.532715\n",
      "Epoch: 94/140 Iteration: 8060 Train loss: 0.882428 Train acc: 0.528809\n",
      "Epoch: 94/140 Iteration: 8065 Train loss: 0.915138 Train acc: 0.490234\n",
      "Epoch: 94/140 Iteration: 8070 Train loss: 0.976609 Train acc: 0.504395\n",
      "Epoch: 94/140 Iteration: 8075 Train loss: 0.926684 Train acc: 0.491211\n",
      "Epoch: 95/140 Iteration: 8080 Train loss: 0.849360 Train acc: 0.628906\n",
      "Epoch: 95/140 Iteration: 8085 Train loss: 0.818859 Train acc: 0.618164\n",
      "Epoch: 95/140 Iteration: 8090 Train loss: 0.736308 Train acc: 0.667969\n",
      "Epoch: 95/140 Iteration: 8095 Train loss: 0.797588 Train acc: 0.661621\n",
      "Epoch: 95/140 Iteration: 8100 Train loss: 0.856177 Train acc: 0.599609\n",
      "Epoch: 95/140 Iteration: 8105 Train loss: 0.689907 Train acc: 0.712891\n",
      "Epoch: 95/140 Iteration: 8110 Train loss: 0.568942 Train acc: 0.799805\n",
      "Epoch: 95/140 Iteration: 8115 Train loss: 0.668380 Train acc: 0.730469\n",
      "Epoch: 95/140 Iteration: 8120 Train loss: 0.852374 Train acc: 0.591309\n",
      "Epoch: 95/140 Iteration: 8125 Train loss: 0.653516 Train acc: 0.777832\n",
      "Epoch: 95/140 Iteration: 8130 Train loss: 0.786851 Train acc: 0.687012\n",
      "Epoch: 95/140 Iteration: 8135 Train loss: 0.894427 Train acc: 0.613281\n",
      "Epoch: 95/140 Iteration: 8140 Train loss: 0.910661 Train acc: 0.455078\n",
      "Epoch: 95/140 Iteration: 8145 Train loss: 0.877394 Train acc: 0.557617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 95/140 Iteration: 8150 Train loss: 0.908825 Train acc: 0.503906\n",
      "Epoch: 95/140 Iteration: 8155 Train loss: 0.934221 Train acc: 0.545898\n",
      "Epoch: 95/140 Iteration: 8160 Train loss: 0.948716 Train acc: 0.461426\n",
      "Epoch: 96/140 Iteration: 8165 Train loss: 0.833663 Train acc: 0.633789\n",
      "Epoch: 96/140 Iteration: 8170 Train loss: 0.807853 Train acc: 0.623535\n",
      "Epoch: 96/140 Iteration: 8175 Train loss: 0.741645 Train acc: 0.664062\n",
      "Epoch: 96/140 Iteration: 8180 Train loss: 0.775347 Train acc: 0.659180\n",
      "Epoch: 96/140 Iteration: 8185 Train loss: 0.914177 Train acc: 0.565430\n",
      "Epoch: 96/140 Iteration: 8190 Train loss: 0.706852 Train acc: 0.674805\n",
      "Epoch: 96/140 Iteration: 8195 Train loss: 0.555681 Train acc: 0.787598\n",
      "Epoch: 96/140 Iteration: 8200 Train loss: 0.663569 Train acc: 0.741211\n",
      "Epoch: 96/140 Iteration: 8205 Train loss: 0.787464 Train acc: 0.625000\n",
      "Epoch: 96/140 Iteration: 8210 Train loss: 0.629923 Train acc: 0.781250\n",
      "Epoch: 96/140 Iteration: 8215 Train loss: 0.822724 Train acc: 0.648438\n",
      "Epoch: 96/140 Iteration: 8220 Train loss: 0.899612 Train acc: 0.610352\n",
      "Epoch: 96/140 Iteration: 8225 Train loss: 0.886619 Train acc: 0.481445\n",
      "Epoch: 96/140 Iteration: 8230 Train loss: 0.885286 Train acc: 0.550781\n",
      "Epoch: 96/140 Iteration: 8235 Train loss: 0.896432 Train acc: 0.512695\n",
      "Epoch: 96/140 Iteration: 8240 Train loss: 0.941764 Train acc: 0.529785\n",
      "Epoch: 96/140 Iteration: 8245 Train loss: 0.916389 Train acc: 0.500977\n",
      "Epoch: 97/140 Iteration: 8250 Train loss: 0.842228 Train acc: 0.637695\n",
      "Epoch: 97/140 Iteration: 8255 Train loss: 0.812772 Train acc: 0.616211\n",
      "Epoch: 97/140 Iteration: 8260 Train loss: 0.772724 Train acc: 0.663086\n",
      "Epoch: 97/140 Iteration: 8265 Train loss: 0.804707 Train acc: 0.652344\n",
      "Epoch: 97/140 Iteration: 8270 Train loss: 0.879213 Train acc: 0.595703\n",
      "Epoch: 97/140 Iteration: 8275 Train loss: 0.705892 Train acc: 0.692871\n",
      "Epoch: 97/140 Iteration: 8280 Train loss: 0.596128 Train acc: 0.775879\n",
      "Epoch: 97/140 Iteration: 8285 Train loss: 0.681244 Train acc: 0.724121\n",
      "Epoch: 97/140 Iteration: 8290 Train loss: 0.811269 Train acc: 0.614258\n",
      "Epoch: 97/140 Iteration: 8295 Train loss: 0.665905 Train acc: 0.766113\n",
      "Epoch: 97/140 Iteration: 8300 Train loss: 0.822504 Train acc: 0.654785\n",
      "Epoch: 97/140 Iteration: 8305 Train loss: 0.870802 Train acc: 0.620605\n",
      "Epoch: 97/140 Iteration: 8310 Train loss: 0.891528 Train acc: 0.510254\n",
      "Epoch: 97/140 Iteration: 8315 Train loss: 0.869758 Train acc: 0.551270\n",
      "Epoch: 97/140 Iteration: 8320 Train loss: 0.934458 Train acc: 0.480957\n",
      "Epoch: 97/140 Iteration: 8325 Train loss: 0.909348 Train acc: 0.576172\n",
      "Epoch: 97/140 Iteration: 8330 Train loss: 0.942670 Train acc: 0.466797\n",
      "Epoch: 98/140 Iteration: 8335 Train loss: 0.826363 Train acc: 0.640137\n",
      "Epoch: 98/140 Iteration: 8340 Train loss: 0.829907 Train acc: 0.615234\n",
      "Epoch: 98/140 Iteration: 8345 Train loss: 0.741716 Train acc: 0.669434\n",
      "Epoch: 98/140 Iteration: 8350 Train loss: 0.763161 Train acc: 0.666016\n",
      "Epoch: 98/140 Iteration: 8355 Train loss: 0.839724 Train acc: 0.615723\n",
      "Epoch: 98/140 Iteration: 8360 Train loss: 0.689772 Train acc: 0.702148\n",
      "Epoch: 98/140 Iteration: 8365 Train loss: 0.534855 Train acc: 0.816406\n",
      "Epoch: 98/140 Iteration: 8370 Train loss: 0.657308 Train acc: 0.734863\n",
      "Epoch: 98/140 Iteration: 8375 Train loss: 0.812447 Train acc: 0.597168\n",
      "Epoch: 98/140 Iteration: 8380 Train loss: 0.639622 Train acc: 0.782715\n",
      "Epoch: 98/140 Iteration: 8385 Train loss: 0.779670 Train acc: 0.685059\n",
      "Epoch: 98/140 Iteration: 8390 Train loss: 0.866992 Train acc: 0.619141\n",
      "Epoch: 98/140 Iteration: 8395 Train loss: 0.854850 Train acc: 0.535156\n",
      "Epoch: 98/140 Iteration: 8400 Train loss: 0.860848 Train acc: 0.584961\n",
      "Epoch: 98/140 Iteration: 8405 Train loss: 0.901339 Train acc: 0.518555\n",
      "Epoch: 98/140 Iteration: 8410 Train loss: 0.910227 Train acc: 0.574219\n",
      "Epoch: 98/140 Iteration: 8415 Train loss: 0.952875 Train acc: 0.460938\n",
      "Epoch: 99/140 Iteration: 8420 Train loss: 0.810012 Train acc: 0.650391\n",
      "Epoch: 99/140 Iteration: 8425 Train loss: 0.805445 Train acc: 0.639648\n",
      "Epoch: 99/140 Iteration: 8430 Train loss: 0.725090 Train acc: 0.690918\n",
      "Epoch: 99/140 Iteration: 8435 Train loss: 0.766774 Train acc: 0.652832\n",
      "Epoch: 99/140 Iteration: 8440 Train loss: 0.840747 Train acc: 0.618652\n",
      "Epoch: 99/140 Iteration: 8445 Train loss: 0.699039 Train acc: 0.700195\n",
      "Epoch: 99/140 Iteration: 8450 Train loss: 0.551738 Train acc: 0.809082\n",
      "Epoch: 99/140 Iteration: 8455 Train loss: 0.643639 Train acc: 0.742188\n",
      "Epoch: 99/140 Iteration: 8460 Train loss: 0.817393 Train acc: 0.600586\n",
      "Epoch: 99/140 Iteration: 8465 Train loss: 0.662731 Train acc: 0.769043\n",
      "Epoch: 99/140 Iteration: 8470 Train loss: 0.794395 Train acc: 0.674316\n",
      "Epoch: 99/140 Iteration: 8475 Train loss: 0.867860 Train acc: 0.631348\n",
      "Epoch: 99/140 Iteration: 8480 Train loss: 0.879896 Train acc: 0.526855\n",
      "Epoch: 99/140 Iteration: 8485 Train loss: 0.889706 Train acc: 0.564941\n",
      "Epoch: 99/140 Iteration: 8490 Train loss: 0.914253 Train acc: 0.509766\n",
      "Epoch: 99/140 Iteration: 8495 Train loss: 0.947588 Train acc: 0.540527\n",
      "Epoch: 99/140 Iteration: 8500 Train loss: 0.972525 Train acc: 0.444824\n",
      "Epoch: 100/140 Iteration: 8505 Train loss: 0.838994 Train acc: 0.648438\n",
      "Epoch: 100/140 Iteration: 8510 Train loss: 0.817830 Train acc: 0.625000\n",
      "Epoch: 100/140 Iteration: 8515 Train loss: 0.682880 Train acc: 0.699219\n",
      "Epoch: 100/140 Iteration: 8520 Train loss: 0.734152 Train acc: 0.683594\n",
      "Epoch: 100/140 Iteration: 8525 Train loss: 0.848639 Train acc: 0.613770\n",
      "Epoch: 100/140 Iteration: 8530 Train loss: 0.679383 Train acc: 0.711426\n",
      "Epoch: 100/140 Iteration: 8535 Train loss: 0.582189 Train acc: 0.773438\n",
      "Epoch: 100/140 Iteration: 8540 Train loss: 0.672219 Train acc: 0.726074\n",
      "Epoch: 100/140 Iteration: 8545 Train loss: 0.815620 Train acc: 0.606445\n",
      "Epoch: 100/140 Iteration: 8550 Train loss: 0.640567 Train acc: 0.769043\n",
      "Epoch: 100/140 Iteration: 8555 Train loss: 0.814541 Train acc: 0.667480\n",
      "Epoch: 100/140 Iteration: 8560 Train loss: 0.922588 Train acc: 0.570801\n",
      "Epoch: 100/140 Iteration: 8565 Train loss: 0.855837 Train acc: 0.560547\n",
      "Epoch: 100/140 Iteration: 8570 Train loss: 0.872438 Train acc: 0.569336\n",
      "Epoch: 100/140 Iteration: 8575 Train loss: 0.873988 Train acc: 0.526367\n",
      "Epoch: 100/140 Iteration: 8580 Train loss: 0.888714 Train acc: 0.565430\n",
      "Epoch: 100/140 Iteration: 8585 Train loss: 0.894677 Train acc: 0.507812\n",
      "Epoch: 101/140 Iteration: 8590 Train loss: 0.833537 Train acc: 0.650879\n",
      "Epoch: 101/140 Iteration: 8595 Train loss: 0.827585 Train acc: 0.625977\n",
      "Epoch: 101/140 Iteration: 8600 Train loss: 0.758293 Train acc: 0.681152\n",
      "Epoch: 101/140 Iteration: 8605 Train loss: 0.765265 Train acc: 0.670410\n",
      "Epoch: 101/140 Iteration: 8610 Train loss: 0.814989 Train acc: 0.634277\n",
      "Epoch: 101/140 Iteration: 8615 Train loss: 0.689425 Train acc: 0.712402\n",
      "Epoch: 101/140 Iteration: 8620 Train loss: 0.510175 Train acc: 0.808594\n",
      "Epoch: 101/140 Iteration: 8625 Train loss: 0.685741 Train acc: 0.712402\n",
      "Epoch: 101/140 Iteration: 8630 Train loss: 0.809681 Train acc: 0.613281\n",
      "Epoch: 101/140 Iteration: 8635 Train loss: 0.634908 Train acc: 0.786621\n",
      "Epoch: 101/140 Iteration: 8640 Train loss: 0.818183 Train acc: 0.667480\n",
      "Epoch: 101/140 Iteration: 8645 Train loss: 0.896940 Train acc: 0.625488\n",
      "Epoch: 101/140 Iteration: 8650 Train loss: 0.832294 Train acc: 0.589844\n",
      "Epoch: 101/140 Iteration: 8655 Train loss: 0.825858 Train acc: 0.585449\n",
      "Epoch: 101/140 Iteration: 8660 Train loss: 0.901350 Train acc: 0.529785\n",
      "Epoch: 101/140 Iteration: 8665 Train loss: 0.942077 Train acc: 0.549316\n",
      "Epoch: 101/140 Iteration: 8670 Train loss: 0.885862 Train acc: 0.526367\n",
      "Epoch: 102/140 Iteration: 8675 Train loss: 0.825511 Train acc: 0.662598\n",
      "Epoch: 102/140 Iteration: 8680 Train loss: 0.810146 Train acc: 0.659668\n",
      "Epoch: 102/140 Iteration: 8685 Train loss: 0.667233 Train acc: 0.711426\n",
      "Epoch: 102/140 Iteration: 8690 Train loss: 0.804276 Train acc: 0.655273\n",
      "Epoch: 102/140 Iteration: 8695 Train loss: 0.852011 Train acc: 0.607910\n",
      "Epoch: 102/140 Iteration: 8700 Train loss: 0.666595 Train acc: 0.709473\n",
      "Epoch: 102/140 Iteration: 8705 Train loss: 0.520218 Train acc: 0.813965\n",
      "Epoch: 102/140 Iteration: 8710 Train loss: 0.632067 Train acc: 0.750977\n",
      "Epoch: 102/140 Iteration: 8715 Train loss: 0.770175 Train acc: 0.629883\n",
      "Epoch: 102/140 Iteration: 8720 Train loss: 0.624364 Train acc: 0.776855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 102/140 Iteration: 8725 Train loss: 0.772882 Train acc: 0.688477\n",
      "Epoch: 102/140 Iteration: 8730 Train loss: 0.912071 Train acc: 0.607910\n",
      "Epoch: 102/140 Iteration: 8735 Train loss: 0.836686 Train acc: 0.587402\n",
      "Epoch: 102/140 Iteration: 8740 Train loss: 0.841220 Train acc: 0.588867\n",
      "Epoch: 102/140 Iteration: 8745 Train loss: 0.901498 Train acc: 0.512695\n",
      "Epoch: 102/140 Iteration: 8750 Train loss: 0.923373 Train acc: 0.526855\n",
      "Epoch: 102/140 Iteration: 8755 Train loss: 0.900679 Train acc: 0.501465\n",
      "Epoch: 103/140 Iteration: 8760 Train loss: 0.831530 Train acc: 0.646484\n",
      "Epoch: 103/140 Iteration: 8765 Train loss: 0.783062 Train acc: 0.666992\n",
      "Epoch: 103/140 Iteration: 8770 Train loss: 0.694405 Train acc: 0.696777\n",
      "Epoch: 103/140 Iteration: 8775 Train loss: 0.756951 Train acc: 0.665527\n",
      "Epoch: 103/140 Iteration: 8780 Train loss: 0.798059 Train acc: 0.641113\n",
      "Epoch: 103/140 Iteration: 8785 Train loss: 0.680059 Train acc: 0.714355\n",
      "Epoch: 103/140 Iteration: 8790 Train loss: 0.520338 Train acc: 0.813477\n",
      "Epoch: 103/140 Iteration: 8795 Train loss: 0.653458 Train acc: 0.729980\n",
      "Epoch: 103/140 Iteration: 8800 Train loss: 0.792737 Train acc: 0.627930\n",
      "Epoch: 103/140 Iteration: 8805 Train loss: 0.623547 Train acc: 0.775391\n",
      "Epoch: 103/140 Iteration: 8810 Train loss: 0.770920 Train acc: 0.695801\n",
      "Epoch: 103/140 Iteration: 8815 Train loss: 0.932646 Train acc: 0.583008\n",
      "Epoch: 103/140 Iteration: 8820 Train loss: 0.851292 Train acc: 0.561035\n",
      "Epoch: 103/140 Iteration: 8825 Train loss: 0.877146 Train acc: 0.568848\n",
      "Epoch: 103/140 Iteration: 8830 Train loss: 0.895014 Train acc: 0.536133\n",
      "Epoch: 103/140 Iteration: 8835 Train loss: 0.896138 Train acc: 0.591309\n",
      "Epoch: 103/140 Iteration: 8840 Train loss: 0.904564 Train acc: 0.496094\n",
      "Epoch: 104/140 Iteration: 8845 Train loss: 0.824791 Train acc: 0.640137\n",
      "Epoch: 104/140 Iteration: 8850 Train loss: 0.768465 Train acc: 0.673828\n",
      "Epoch: 104/140 Iteration: 8855 Train loss: 0.640059 Train acc: 0.719727\n",
      "Epoch: 104/140 Iteration: 8860 Train loss: 0.738624 Train acc: 0.681152\n",
      "Epoch: 104/140 Iteration: 8865 Train loss: 0.783638 Train acc: 0.652832\n",
      "Epoch: 104/140 Iteration: 8870 Train loss: 0.660438 Train acc: 0.707031\n",
      "Epoch: 104/140 Iteration: 8875 Train loss: 0.499438 Train acc: 0.832520\n",
      "Epoch: 104/140 Iteration: 8880 Train loss: 0.639857 Train acc: 0.742188\n",
      "Epoch: 104/140 Iteration: 8885 Train loss: 0.760985 Train acc: 0.636719\n",
      "Epoch: 104/140 Iteration: 8890 Train loss: 0.609259 Train acc: 0.795410\n",
      "Epoch: 104/140 Iteration: 8895 Train loss: 0.757622 Train acc: 0.693848\n",
      "Epoch: 104/140 Iteration: 8900 Train loss: 0.906688 Train acc: 0.590332\n",
      "Epoch: 104/140 Iteration: 8905 Train loss: 0.853376 Train acc: 0.557617\n",
      "Epoch: 104/140 Iteration: 8910 Train loss: 0.883499 Train acc: 0.552734\n",
      "Epoch: 104/140 Iteration: 8915 Train loss: 0.877061 Train acc: 0.551758\n",
      "Epoch: 104/140 Iteration: 8920 Train loss: 0.909924 Train acc: 0.588867\n",
      "Epoch: 104/140 Iteration: 8925 Train loss: 0.935431 Train acc: 0.474609\n",
      "Epoch: 105/140 Iteration: 8930 Train loss: 0.819054 Train acc: 0.656738\n",
      "Epoch: 105/140 Iteration: 8935 Train loss: 0.794936 Train acc: 0.646484\n",
      "Epoch: 105/140 Iteration: 8940 Train loss: 0.674242 Train acc: 0.691895\n",
      "Epoch: 105/140 Iteration: 8945 Train loss: 0.774539 Train acc: 0.671875\n",
      "Epoch: 105/140 Iteration: 8950 Train loss: 0.767773 Train acc: 0.664062\n",
      "Epoch: 105/140 Iteration: 8955 Train loss: 0.669724 Train acc: 0.709961\n",
      "Epoch: 105/140 Iteration: 8960 Train loss: 0.542027 Train acc: 0.809570\n",
      "Epoch: 105/140 Iteration: 8965 Train loss: 0.653972 Train acc: 0.737305\n",
      "Epoch: 105/140 Iteration: 8970 Train loss: 0.801975 Train acc: 0.617676\n",
      "Epoch: 105/140 Iteration: 8975 Train loss: 0.613409 Train acc: 0.789062\n",
      "Epoch: 105/140 Iteration: 8980 Train loss: 0.740173 Train acc: 0.712891\n",
      "Epoch: 105/140 Iteration: 8985 Train loss: 0.845712 Train acc: 0.651367\n",
      "Epoch: 105/140 Iteration: 8990 Train loss: 0.885118 Train acc: 0.525879\n",
      "Epoch: 105/140 Iteration: 8995 Train loss: 0.873721 Train acc: 0.554688\n",
      "Epoch: 105/140 Iteration: 9000 Train loss: 0.875210 Train acc: 0.556641\n",
      "Epoch: 105/140 Iteration: 9005 Train loss: 0.985359 Train acc: 0.562988\n",
      "Epoch: 105/140 Iteration: 9010 Train loss: 0.972206 Train acc: 0.444824\n",
      "Epoch: 106/140 Iteration: 9015 Train loss: 0.818716 Train acc: 0.635254\n",
      "Epoch: 106/140 Iteration: 9020 Train loss: 0.814420 Train acc: 0.618652\n",
      "Epoch: 106/140 Iteration: 9025 Train loss: 0.632163 Train acc: 0.735352\n",
      "Epoch: 106/140 Iteration: 9030 Train loss: 0.761269 Train acc: 0.669922\n",
      "Epoch: 106/140 Iteration: 9035 Train loss: 0.796818 Train acc: 0.666504\n",
      "Epoch: 106/140 Iteration: 9040 Train loss: 0.668960 Train acc: 0.714355\n",
      "Epoch: 106/140 Iteration: 9045 Train loss: 0.535403 Train acc: 0.796875\n",
      "Epoch: 106/140 Iteration: 9050 Train loss: 0.624522 Train acc: 0.740234\n",
      "Epoch: 106/140 Iteration: 9055 Train loss: 0.780713 Train acc: 0.635254\n",
      "Epoch: 106/140 Iteration: 9060 Train loss: 0.598871 Train acc: 0.795898\n",
      "Epoch: 106/140 Iteration: 9065 Train loss: 0.733165 Train acc: 0.711426\n",
      "Epoch: 106/140 Iteration: 9070 Train loss: 0.879076 Train acc: 0.622070\n",
      "Epoch: 106/140 Iteration: 9075 Train loss: 0.904367 Train acc: 0.493164\n",
      "Epoch: 106/140 Iteration: 9080 Train loss: 0.881631 Train acc: 0.520996\n",
      "Epoch: 106/140 Iteration: 9085 Train loss: 0.904077 Train acc: 0.567383\n",
      "Epoch: 106/140 Iteration: 9090 Train loss: 0.958395 Train acc: 0.564453\n",
      "Epoch: 106/140 Iteration: 9095 Train loss: 1.009126 Train acc: 0.430664\n",
      "Epoch: 107/140 Iteration: 9100 Train loss: 0.828724 Train acc: 0.638184\n",
      "Epoch: 107/140 Iteration: 9105 Train loss: 0.784261 Train acc: 0.660645\n",
      "Epoch: 107/140 Iteration: 9110 Train loss: 0.696895 Train acc: 0.695312\n",
      "Epoch: 107/140 Iteration: 9115 Train loss: 0.681312 Train acc: 0.715820\n",
      "Epoch: 107/140 Iteration: 9120 Train loss: 0.755481 Train acc: 0.666504\n",
      "Epoch: 107/140 Iteration: 9125 Train loss: 0.679398 Train acc: 0.697754\n",
      "Epoch: 107/140 Iteration: 9130 Train loss: 0.549079 Train acc: 0.804688\n",
      "Epoch: 107/140 Iteration: 9135 Train loss: 0.620085 Train acc: 0.750000\n",
      "Epoch: 107/140 Iteration: 9140 Train loss: 0.775310 Train acc: 0.630859\n",
      "Epoch: 107/140 Iteration: 9145 Train loss: 0.630551 Train acc: 0.801758\n",
      "Epoch: 107/140 Iteration: 9150 Train loss: 0.742440 Train acc: 0.712402\n",
      "Epoch: 107/140 Iteration: 9155 Train loss: 0.875149 Train acc: 0.599121\n",
      "Epoch: 107/140 Iteration: 9160 Train loss: 0.886894 Train acc: 0.529785\n",
      "Epoch: 107/140 Iteration: 9165 Train loss: 0.871975 Train acc: 0.541992\n",
      "Epoch: 107/140 Iteration: 9170 Train loss: 0.879248 Train acc: 0.574707\n",
      "Epoch: 107/140 Iteration: 9175 Train loss: 0.932832 Train acc: 0.594238\n",
      "Epoch: 107/140 Iteration: 9180 Train loss: 1.057377 Train acc: 0.431152\n",
      "Epoch: 108/140 Iteration: 9185 Train loss: 0.835604 Train acc: 0.628906\n",
      "Epoch: 108/140 Iteration: 9190 Train loss: 0.816176 Train acc: 0.651367\n",
      "Epoch: 108/140 Iteration: 9195 Train loss: 0.681829 Train acc: 0.684570\n",
      "Epoch: 108/140 Iteration: 9200 Train loss: 0.698807 Train acc: 0.698242\n",
      "Epoch: 108/140 Iteration: 9205 Train loss: 0.738346 Train acc: 0.681152\n",
      "Epoch: 108/140 Iteration: 9210 Train loss: 0.666720 Train acc: 0.705566\n",
      "Epoch: 108/140 Iteration: 9215 Train loss: 0.489584 Train acc: 0.829590\n",
      "Epoch: 108/140 Iteration: 9220 Train loss: 0.608969 Train acc: 0.744629\n",
      "Epoch: 108/140 Iteration: 9225 Train loss: 0.756934 Train acc: 0.639160\n",
      "Epoch: 108/140 Iteration: 9230 Train loss: 0.619497 Train acc: 0.790039\n",
      "Epoch: 108/140 Iteration: 9235 Train loss: 0.730216 Train acc: 0.720215\n",
      "Epoch: 108/140 Iteration: 9240 Train loss: 0.885337 Train acc: 0.583984\n",
      "Epoch: 108/140 Iteration: 9245 Train loss: 0.896429 Train acc: 0.525391\n",
      "Epoch: 108/140 Iteration: 9250 Train loss: 0.866883 Train acc: 0.547852\n",
      "Epoch: 108/140 Iteration: 9255 Train loss: 0.897419 Train acc: 0.534668\n",
      "Epoch: 108/140 Iteration: 9260 Train loss: 0.930855 Train acc: 0.576660\n",
      "Epoch: 108/140 Iteration: 9265 Train loss: 0.990207 Train acc: 0.478027\n",
      "Epoch: 109/140 Iteration: 9270 Train loss: 0.830729 Train acc: 0.634277\n",
      "Epoch: 109/140 Iteration: 9275 Train loss: 0.797699 Train acc: 0.651855\n",
      "Epoch: 109/140 Iteration: 9280 Train loss: 0.717963 Train acc: 0.674805\n",
      "Epoch: 109/140 Iteration: 9285 Train loss: 0.660747 Train acc: 0.728027\n",
      "Epoch: 109/140 Iteration: 9290 Train loss: 0.734455 Train acc: 0.690918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 109/140 Iteration: 9295 Train loss: 0.689035 Train acc: 0.710449\n",
      "Epoch: 109/140 Iteration: 9300 Train loss: 0.683764 Train acc: 0.742676\n",
      "Epoch: 109/140 Iteration: 9305 Train loss: 0.621218 Train acc: 0.740723\n",
      "Epoch: 109/140 Iteration: 9310 Train loss: 0.805364 Train acc: 0.617188\n",
      "Epoch: 109/140 Iteration: 9315 Train loss: 0.648582 Train acc: 0.788574\n",
      "Epoch: 109/140 Iteration: 9320 Train loss: 0.746529 Train acc: 0.709961\n",
      "Epoch: 109/140 Iteration: 9325 Train loss: 0.858454 Train acc: 0.612793\n",
      "Epoch: 109/140 Iteration: 9330 Train loss: 0.851407 Train acc: 0.580078\n",
      "Epoch: 109/140 Iteration: 9335 Train loss: 0.872870 Train acc: 0.539062\n",
      "Epoch: 109/140 Iteration: 9340 Train loss: 0.855401 Train acc: 0.578613\n",
      "Epoch: 109/140 Iteration: 9345 Train loss: 0.921281 Train acc: 0.588379\n",
      "Epoch: 109/140 Iteration: 9350 Train loss: 0.950286 Train acc: 0.502930\n",
      "Epoch: 110/140 Iteration: 9355 Train loss: 0.831263 Train acc: 0.627441\n",
      "Epoch: 110/140 Iteration: 9360 Train loss: 0.789239 Train acc: 0.656250\n",
      "Epoch: 110/140 Iteration: 9365 Train loss: 0.749161 Train acc: 0.671875\n",
      "Epoch: 110/140 Iteration: 9370 Train loss: 0.677266 Train acc: 0.729980\n",
      "Epoch: 110/140 Iteration: 9375 Train loss: 0.728509 Train acc: 0.704590\n",
      "Epoch: 110/140 Iteration: 9380 Train loss: 0.661569 Train acc: 0.732910\n",
      "Epoch: 110/140 Iteration: 9385 Train loss: 0.486416 Train acc: 0.821289\n",
      "Epoch: 110/140 Iteration: 9390 Train loss: 0.605603 Train acc: 0.753906\n",
      "Epoch: 110/140 Iteration: 9395 Train loss: 0.785647 Train acc: 0.630859\n",
      "Epoch: 110/140 Iteration: 9400 Train loss: 0.618739 Train acc: 0.795898\n",
      "Epoch: 110/140 Iteration: 9405 Train loss: 0.741398 Train acc: 0.707520\n",
      "Epoch: 110/140 Iteration: 9410 Train loss: 0.861266 Train acc: 0.615723\n",
      "Epoch: 110/140 Iteration: 9415 Train loss: 0.838160 Train acc: 0.572754\n",
      "Epoch: 110/140 Iteration: 9420 Train loss: 0.879259 Train acc: 0.544434\n",
      "Epoch: 110/140 Iteration: 9425 Train loss: 0.863799 Train acc: 0.569824\n",
      "Epoch: 110/140 Iteration: 9430 Train loss: 0.923984 Train acc: 0.594238\n",
      "Epoch: 110/140 Iteration: 9435 Train loss: 1.003737 Train acc: 0.474609\n",
      "Epoch: 111/140 Iteration: 9440 Train loss: 0.818413 Train acc: 0.664551\n",
      "Epoch: 111/140 Iteration: 9445 Train loss: 0.804003 Train acc: 0.648438\n",
      "Epoch: 111/140 Iteration: 9450 Train loss: 0.711557 Train acc: 0.682129\n",
      "Epoch: 111/140 Iteration: 9455 Train loss: 0.639935 Train acc: 0.741211\n",
      "Epoch: 111/140 Iteration: 9460 Train loss: 0.706700 Train acc: 0.709473\n",
      "Epoch: 111/140 Iteration: 9465 Train loss: 0.675107 Train acc: 0.705566\n",
      "Epoch: 111/140 Iteration: 9470 Train loss: 0.470289 Train acc: 0.828125\n",
      "Epoch: 111/140 Iteration: 9475 Train loss: 0.590635 Train acc: 0.756348\n",
      "Epoch: 111/140 Iteration: 9480 Train loss: 0.783120 Train acc: 0.643066\n",
      "Epoch: 111/140 Iteration: 9485 Train loss: 0.609782 Train acc: 0.797363\n",
      "Epoch: 111/140 Iteration: 9490 Train loss: 0.744542 Train acc: 0.711426\n",
      "Epoch: 111/140 Iteration: 9495 Train loss: 0.904810 Train acc: 0.574707\n",
      "Epoch: 111/140 Iteration: 9500 Train loss: 0.876624 Train acc: 0.541016\n",
      "Epoch: 111/140 Iteration: 9505 Train loss: 0.838064 Train acc: 0.583984\n",
      "Epoch: 111/140 Iteration: 9510 Train loss: 0.858849 Train acc: 0.569824\n",
      "Epoch: 111/140 Iteration: 9515 Train loss: 0.880536 Train acc: 0.611816\n",
      "Epoch: 111/140 Iteration: 9520 Train loss: 0.948715 Train acc: 0.490723\n",
      "Epoch: 112/140 Iteration: 9525 Train loss: 0.822935 Train acc: 0.647949\n",
      "Epoch: 112/140 Iteration: 9530 Train loss: 0.778723 Train acc: 0.670410\n",
      "Epoch: 112/140 Iteration: 9535 Train loss: 0.713171 Train acc: 0.687500\n",
      "Epoch: 112/140 Iteration: 9540 Train loss: 0.667306 Train acc: 0.720215\n",
      "Epoch: 112/140 Iteration: 9545 Train loss: 0.689258 Train acc: 0.710938\n",
      "Epoch: 112/140 Iteration: 9550 Train loss: 0.663307 Train acc: 0.729004\n",
      "Epoch: 112/140 Iteration: 9555 Train loss: 0.467522 Train acc: 0.833008\n",
      "Epoch: 112/140 Iteration: 9560 Train loss: 0.627840 Train acc: 0.739258\n",
      "Epoch: 112/140 Iteration: 9565 Train loss: 0.749588 Train acc: 0.642090\n",
      "Epoch: 112/140 Iteration: 9570 Train loss: 0.629710 Train acc: 0.783203\n",
      "Epoch: 112/140 Iteration: 9575 Train loss: 0.733283 Train acc: 0.710449\n",
      "Epoch: 112/140 Iteration: 9580 Train loss: 0.864767 Train acc: 0.602539\n",
      "Epoch: 112/140 Iteration: 9585 Train loss: 0.831910 Train acc: 0.580566\n",
      "Epoch: 112/140 Iteration: 9590 Train loss: 0.842614 Train acc: 0.568848\n",
      "Epoch: 112/140 Iteration: 9595 Train loss: 0.832137 Train acc: 0.578613\n",
      "Epoch: 112/140 Iteration: 9600 Train loss: 0.906834 Train acc: 0.586426\n",
      "Epoch: 112/140 Iteration: 9605 Train loss: 0.925557 Train acc: 0.510254\n",
      "Epoch: 113/140 Iteration: 9610 Train loss: 0.795599 Train acc: 0.670410\n",
      "Epoch: 113/140 Iteration: 9615 Train loss: 0.810662 Train acc: 0.650391\n",
      "Epoch: 113/140 Iteration: 9620 Train loss: 0.716317 Train acc: 0.698730\n",
      "Epoch: 113/140 Iteration: 9625 Train loss: 0.640715 Train acc: 0.746582\n",
      "Epoch: 113/140 Iteration: 9630 Train loss: 0.704993 Train acc: 0.700195\n",
      "Epoch: 113/140 Iteration: 9635 Train loss: 0.643071 Train acc: 0.728516\n",
      "Epoch: 113/140 Iteration: 9640 Train loss: 0.569351 Train acc: 0.774902\n",
      "Epoch: 113/140 Iteration: 9645 Train loss: 0.653871 Train acc: 0.722656\n",
      "Epoch: 113/140 Iteration: 9650 Train loss: 0.738848 Train acc: 0.671387\n",
      "Epoch: 113/140 Iteration: 9655 Train loss: 0.668469 Train acc: 0.756348\n",
      "Epoch: 113/140 Iteration: 9660 Train loss: 0.743202 Train acc: 0.712891\n",
      "Epoch: 113/140 Iteration: 9665 Train loss: 0.870741 Train acc: 0.605469\n",
      "Epoch: 113/140 Iteration: 9670 Train loss: 0.831381 Train acc: 0.598145\n",
      "Epoch: 113/140 Iteration: 9675 Train loss: 0.837002 Train acc: 0.585938\n",
      "Epoch: 113/140 Iteration: 9680 Train loss: 0.828095 Train acc: 0.585449\n",
      "Epoch: 113/140 Iteration: 9685 Train loss: 0.873112 Train acc: 0.600098\n",
      "Epoch: 113/140 Iteration: 9690 Train loss: 0.890180 Train acc: 0.539062\n",
      "Epoch: 114/140 Iteration: 9695 Train loss: 0.807558 Train acc: 0.658203\n",
      "Epoch: 114/140 Iteration: 9700 Train loss: 0.805099 Train acc: 0.638672\n",
      "Epoch: 114/140 Iteration: 9705 Train loss: 0.779857 Train acc: 0.649902\n",
      "Epoch: 114/140 Iteration: 9710 Train loss: 0.693259 Train acc: 0.713379\n",
      "Epoch: 114/140 Iteration: 9715 Train loss: 0.770305 Train acc: 0.681152\n",
      "Epoch: 114/140 Iteration: 9720 Train loss: 0.665009 Train acc: 0.717285\n",
      "Epoch: 114/140 Iteration: 9725 Train loss: 0.518254 Train acc: 0.811035\n",
      "Epoch: 114/140 Iteration: 9730 Train loss: 0.684353 Train acc: 0.712891\n",
      "Epoch: 114/140 Iteration: 9735 Train loss: 0.761197 Train acc: 0.645020\n",
      "Epoch: 114/140 Iteration: 9740 Train loss: 0.611140 Train acc: 0.780273\n",
      "Epoch: 114/140 Iteration: 9745 Train loss: 0.753161 Train acc: 0.710938\n",
      "Epoch: 114/140 Iteration: 9750 Train loss: 0.856201 Train acc: 0.627441\n",
      "Epoch: 114/140 Iteration: 9755 Train loss: 0.839961 Train acc: 0.603027\n",
      "Epoch: 114/140 Iteration: 9760 Train loss: 0.843024 Train acc: 0.591309\n",
      "Epoch: 114/140 Iteration: 9765 Train loss: 0.822218 Train acc: 0.599121\n",
      "Epoch: 114/140 Iteration: 9770 Train loss: 0.849618 Train acc: 0.614746\n",
      "Epoch: 114/140 Iteration: 9775 Train loss: 0.887854 Train acc: 0.555176\n",
      "Epoch: 115/140 Iteration: 9780 Train loss: 0.796445 Train acc: 0.671875\n",
      "Epoch: 115/140 Iteration: 9785 Train loss: 0.826275 Train acc: 0.639160\n",
      "Epoch: 115/140 Iteration: 9790 Train loss: 0.756626 Train acc: 0.646973\n",
      "Epoch: 115/140 Iteration: 9795 Train loss: 0.666850 Train acc: 0.721680\n",
      "Epoch: 115/140 Iteration: 9800 Train loss: 0.750355 Train acc: 0.688965\n",
      "Epoch: 115/140 Iteration: 9805 Train loss: 0.617257 Train acc: 0.735352\n",
      "Epoch: 115/140 Iteration: 9810 Train loss: 0.501963 Train acc: 0.813965\n",
      "Epoch: 115/140 Iteration: 9815 Train loss: 0.657021 Train acc: 0.719238\n",
      "Epoch: 115/140 Iteration: 9820 Train loss: 0.739715 Train acc: 0.654785\n",
      "Epoch: 115/140 Iteration: 9825 Train loss: 0.615478 Train acc: 0.773926\n",
      "Epoch: 115/140 Iteration: 9830 Train loss: 0.749000 Train acc: 0.713379\n",
      "Epoch: 115/140 Iteration: 9835 Train loss: 0.851516 Train acc: 0.624512\n",
      "Epoch: 115/140 Iteration: 9840 Train loss: 0.806630 Train acc: 0.627441\n",
      "Epoch: 115/140 Iteration: 9845 Train loss: 0.825823 Train acc: 0.614258\n",
      "Epoch: 115/140 Iteration: 9850 Train loss: 0.780246 Train acc: 0.625000\n",
      "Epoch: 115/140 Iteration: 9855 Train loss: 0.854556 Train acc: 0.605957\n",
      "Epoch: 115/140 Iteration: 9860 Train loss: 0.871675 Train acc: 0.550293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 116/140 Iteration: 9865 Train loss: 0.759211 Train acc: 0.683594\n",
      "Epoch: 116/140 Iteration: 9870 Train loss: 0.808845 Train acc: 0.630371\n",
      "Epoch: 116/140 Iteration: 9875 Train loss: 0.806350 Train acc: 0.649902\n",
      "Epoch: 116/140 Iteration: 9880 Train loss: 0.653198 Train acc: 0.725586\n",
      "Epoch: 116/140 Iteration: 9885 Train loss: 0.756971 Train acc: 0.686035\n",
      "Epoch: 116/140 Iteration: 9890 Train loss: 0.624729 Train acc: 0.733398\n",
      "Epoch: 116/140 Iteration: 9895 Train loss: 0.478899 Train acc: 0.819336\n",
      "Epoch: 116/140 Iteration: 9900 Train loss: 0.687907 Train acc: 0.713379\n",
      "Epoch: 116/140 Iteration: 9905 Train loss: 0.710037 Train acc: 0.685059\n",
      "Epoch: 116/140 Iteration: 9910 Train loss: 0.637654 Train acc: 0.760254\n",
      "Epoch: 116/140 Iteration: 9915 Train loss: 0.759035 Train acc: 0.703613\n",
      "Epoch: 116/140 Iteration: 9920 Train loss: 0.865240 Train acc: 0.621582\n",
      "Epoch: 116/140 Iteration: 9925 Train loss: 0.807084 Train acc: 0.628418\n",
      "Epoch: 116/140 Iteration: 9930 Train loss: 0.845932 Train acc: 0.571289\n",
      "Epoch: 116/140 Iteration: 9935 Train loss: 0.824491 Train acc: 0.585449\n",
      "Epoch: 116/140 Iteration: 9940 Train loss: 0.868541 Train acc: 0.605469\n",
      "Epoch: 116/140 Iteration: 9945 Train loss: 0.896373 Train acc: 0.520508\n",
      "Epoch: 117/140 Iteration: 9950 Train loss: 0.745521 Train acc: 0.696289\n",
      "Epoch: 117/140 Iteration: 9955 Train loss: 0.820120 Train acc: 0.626953\n",
      "Epoch: 117/140 Iteration: 9960 Train loss: 0.747812 Train acc: 0.650879\n",
      "Epoch: 117/140 Iteration: 9965 Train loss: 0.677526 Train acc: 0.705566\n",
      "Epoch: 117/140 Iteration: 9970 Train loss: 0.797598 Train acc: 0.662109\n",
      "Epoch: 117/140 Iteration: 9975 Train loss: 0.655161 Train acc: 0.714844\n",
      "Epoch: 117/140 Iteration: 9980 Train loss: 0.481019 Train acc: 0.826660\n",
      "Epoch: 117/140 Iteration: 9985 Train loss: 0.675164 Train acc: 0.713867\n",
      "Epoch: 117/140 Iteration: 9990 Train loss: 0.846830 Train acc: 0.620117\n",
      "Epoch: 117/140 Iteration: 9995 Train loss: 0.650382 Train acc: 0.761719\n",
      "Epoch: 117/140 Iteration: 10000 Train loss: 0.733241 Train acc: 0.721680\n",
      "Epoch: 117/140 Iteration: 10005 Train loss: 0.919938 Train acc: 0.579590\n",
      "Epoch: 117/140 Iteration: 10010 Train loss: 0.815781 Train acc: 0.610352\n",
      "Epoch: 117/140 Iteration: 10015 Train loss: 0.850644 Train acc: 0.597656\n",
      "Epoch: 117/140 Iteration: 10020 Train loss: 0.834845 Train acc: 0.578125\n",
      "Epoch: 117/140 Iteration: 10025 Train loss: 0.899324 Train acc: 0.568848\n",
      "Epoch: 117/140 Iteration: 10030 Train loss: 0.939555 Train acc: 0.500977\n",
      "Epoch: 118/140 Iteration: 10035 Train loss: 0.808703 Train acc: 0.652344\n",
      "Epoch: 118/140 Iteration: 10040 Train loss: 0.820960 Train acc: 0.634766\n",
      "Epoch: 118/140 Iteration: 10045 Train loss: 0.801405 Train acc: 0.612305\n",
      "Epoch: 118/140 Iteration: 10050 Train loss: 0.663364 Train acc: 0.715332\n",
      "Epoch: 118/140 Iteration: 10055 Train loss: 0.824048 Train acc: 0.643066\n",
      "Epoch: 118/140 Iteration: 10060 Train loss: 0.616804 Train acc: 0.727051\n",
      "Epoch: 118/140 Iteration: 10065 Train loss: 0.478958 Train acc: 0.831543\n",
      "Epoch: 118/140 Iteration: 10070 Train loss: 0.686893 Train acc: 0.696777\n",
      "Epoch: 118/140 Iteration: 10075 Train loss: 0.777001 Train acc: 0.642578\n",
      "Epoch: 118/140 Iteration: 10080 Train loss: 0.644455 Train acc: 0.762207\n",
      "Epoch: 118/140 Iteration: 10085 Train loss: 0.747695 Train acc: 0.717285\n",
      "Epoch: 118/140 Iteration: 10090 Train loss: 0.906134 Train acc: 0.562012\n",
      "Epoch: 118/140 Iteration: 10095 Train loss: 0.840226 Train acc: 0.594238\n",
      "Epoch: 118/140 Iteration: 10100 Train loss: 0.909359 Train acc: 0.548340\n",
      "Epoch: 118/140 Iteration: 10105 Train loss: 0.856131 Train acc: 0.572754\n",
      "Epoch: 118/140 Iteration: 10110 Train loss: 0.888999 Train acc: 0.573730\n",
      "Epoch: 118/140 Iteration: 10115 Train loss: 1.015227 Train acc: 0.461914\n",
      "Epoch: 119/140 Iteration: 10120 Train loss: 0.816518 Train acc: 0.663086\n",
      "Epoch: 119/140 Iteration: 10125 Train loss: 0.803054 Train acc: 0.637695\n",
      "Epoch: 119/140 Iteration: 10130 Train loss: 0.818719 Train acc: 0.616211\n",
      "Epoch: 119/140 Iteration: 10135 Train loss: 0.653333 Train acc: 0.718262\n",
      "Epoch: 119/140 Iteration: 10140 Train loss: 0.838225 Train acc: 0.628418\n",
      "Epoch: 119/140 Iteration: 10145 Train loss: 0.649908 Train acc: 0.713867\n",
      "Epoch: 119/140 Iteration: 10150 Train loss: 0.481533 Train acc: 0.825684\n",
      "Epoch: 119/140 Iteration: 10155 Train loss: 0.684217 Train acc: 0.700684\n",
      "Epoch: 119/140 Iteration: 10160 Train loss: 0.749691 Train acc: 0.666504\n",
      "Epoch: 119/140 Iteration: 10165 Train loss: 0.616353 Train acc: 0.777832\n",
      "Epoch: 119/140 Iteration: 10170 Train loss: 0.737498 Train acc: 0.722168\n",
      "Epoch: 119/140 Iteration: 10175 Train loss: 0.872236 Train acc: 0.601562\n",
      "Epoch: 119/140 Iteration: 10180 Train loss: 0.849296 Train acc: 0.587891\n",
      "Epoch: 119/140 Iteration: 10185 Train loss: 0.882775 Train acc: 0.541016\n",
      "Epoch: 119/140 Iteration: 10190 Train loss: 0.843409 Train acc: 0.563965\n",
      "Epoch: 119/140 Iteration: 10195 Train loss: 0.873924 Train acc: 0.605469\n",
      "Epoch: 119/140 Iteration: 10200 Train loss: 0.918425 Train acc: 0.505371\n",
      "Epoch: 120/140 Iteration: 10205 Train loss: 0.779266 Train acc: 0.681641\n",
      "Epoch: 120/140 Iteration: 10210 Train loss: 0.809257 Train acc: 0.623535\n",
      "Epoch: 120/140 Iteration: 10215 Train loss: 0.764111 Train acc: 0.636230\n",
      "Epoch: 120/140 Iteration: 10220 Train loss: 0.662897 Train acc: 0.718262\n",
      "Epoch: 120/140 Iteration: 10225 Train loss: 0.780394 Train acc: 0.643066\n",
      "Epoch: 120/140 Iteration: 10230 Train loss: 0.635602 Train acc: 0.723633\n",
      "Epoch: 120/140 Iteration: 10235 Train loss: 0.468933 Train acc: 0.834473\n",
      "Epoch: 120/140 Iteration: 10240 Train loss: 0.645859 Train acc: 0.722168\n",
      "Epoch: 120/140 Iteration: 10245 Train loss: 0.819604 Train acc: 0.616211\n",
      "Epoch: 120/140 Iteration: 10250 Train loss: 0.668700 Train acc: 0.759277\n",
      "Epoch: 120/140 Iteration: 10255 Train loss: 0.784147 Train acc: 0.697266\n",
      "Epoch: 120/140 Iteration: 10260 Train loss: 0.855196 Train acc: 0.604980\n",
      "Epoch: 120/140 Iteration: 10265 Train loss: 0.832793 Train acc: 0.608398\n",
      "Epoch: 120/140 Iteration: 10270 Train loss: 0.856251 Train acc: 0.554688\n",
      "Epoch: 120/140 Iteration: 10275 Train loss: 0.818820 Train acc: 0.571777\n",
      "Epoch: 120/140 Iteration: 10280 Train loss: 0.846900 Train acc: 0.602539\n",
      "Epoch: 120/140 Iteration: 10285 Train loss: 0.877056 Train acc: 0.543457\n",
      "Epoch: 121/140 Iteration: 10290 Train loss: 0.792118 Train acc: 0.677734\n",
      "Epoch: 121/140 Iteration: 10295 Train loss: 0.817188 Train acc: 0.622070\n",
      "Epoch: 121/140 Iteration: 10300 Train loss: 0.779241 Train acc: 0.628906\n",
      "Epoch: 121/140 Iteration: 10305 Train loss: 0.649740 Train acc: 0.731934\n",
      "Epoch: 121/140 Iteration: 10310 Train loss: 0.769593 Train acc: 0.648438\n",
      "Epoch: 121/140 Iteration: 10315 Train loss: 0.627098 Train acc: 0.723633\n",
      "Epoch: 121/140 Iteration: 10320 Train loss: 0.446278 Train acc: 0.844727\n",
      "Epoch: 121/140 Iteration: 10325 Train loss: 0.621620 Train acc: 0.729980\n",
      "Epoch: 121/140 Iteration: 10330 Train loss: 0.839415 Train acc: 0.625977\n",
      "Epoch: 121/140 Iteration: 10335 Train loss: 0.641376 Train acc: 0.768066\n",
      "Epoch: 121/140 Iteration: 10340 Train loss: 0.764195 Train acc: 0.710938\n",
      "Epoch: 121/140 Iteration: 10345 Train loss: 0.900135 Train acc: 0.578125\n",
      "Epoch: 121/140 Iteration: 10350 Train loss: 0.832220 Train acc: 0.582520\n",
      "Epoch: 121/140 Iteration: 10355 Train loss: 0.833607 Train acc: 0.585449\n",
      "Epoch: 121/140 Iteration: 10360 Train loss: 0.821779 Train acc: 0.579102\n",
      "Epoch: 121/140 Iteration: 10365 Train loss: 0.868965 Train acc: 0.615723\n",
      "Epoch: 121/140 Iteration: 10370 Train loss: 0.887421 Train acc: 0.533691\n",
      "Epoch: 122/140 Iteration: 10375 Train loss: 0.801611 Train acc: 0.648926\n",
      "Epoch: 122/140 Iteration: 10380 Train loss: 0.807319 Train acc: 0.632324\n",
      "Epoch: 122/140 Iteration: 10385 Train loss: 0.760250 Train acc: 0.632812\n",
      "Epoch: 122/140 Iteration: 10390 Train loss: 0.675325 Train acc: 0.717285\n",
      "Epoch: 122/140 Iteration: 10395 Train loss: 0.758999 Train acc: 0.665527\n",
      "Epoch: 122/140 Iteration: 10400 Train loss: 0.611714 Train acc: 0.741211\n",
      "Epoch: 122/140 Iteration: 10405 Train loss: 0.423025 Train acc: 0.847656\n",
      "Epoch: 122/140 Iteration: 10410 Train loss: 0.586093 Train acc: 0.757324\n",
      "Epoch: 122/140 Iteration: 10415 Train loss: 0.739425 Train acc: 0.668457\n",
      "Epoch: 122/140 Iteration: 10420 Train loss: 0.593860 Train acc: 0.795410\n",
      "Epoch: 122/140 Iteration: 10425 Train loss: 0.736528 Train acc: 0.708984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 122/140 Iteration: 10430 Train loss: 0.815235 Train acc: 0.629883\n",
      "Epoch: 122/140 Iteration: 10435 Train loss: 0.807331 Train acc: 0.599609\n",
      "Epoch: 122/140 Iteration: 10440 Train loss: 0.863613 Train acc: 0.562500\n",
      "Epoch: 122/140 Iteration: 10445 Train loss: 0.820372 Train acc: 0.599121\n",
      "Epoch: 122/140 Iteration: 10450 Train loss: 0.963866 Train acc: 0.561523\n",
      "Epoch: 122/140 Iteration: 10455 Train loss: 0.885764 Train acc: 0.534668\n",
      "Epoch: 123/140 Iteration: 10460 Train loss: 0.782653 Train acc: 0.673828\n",
      "Epoch: 123/140 Iteration: 10465 Train loss: 0.796217 Train acc: 0.645020\n",
      "Epoch: 123/140 Iteration: 10470 Train loss: 0.774534 Train acc: 0.641113\n",
      "Epoch: 123/140 Iteration: 10475 Train loss: 0.646497 Train acc: 0.743164\n",
      "Epoch: 123/140 Iteration: 10480 Train loss: 0.706922 Train acc: 0.688477\n",
      "Epoch: 123/140 Iteration: 10485 Train loss: 0.606607 Train acc: 0.732422\n",
      "Epoch: 123/140 Iteration: 10490 Train loss: 0.413821 Train acc: 0.853516\n",
      "Epoch: 123/140 Iteration: 10495 Train loss: 0.570364 Train acc: 0.763184\n",
      "Epoch: 123/140 Iteration: 10500 Train loss: 0.713818 Train acc: 0.687012\n",
      "Epoch: 123/140 Iteration: 10505 Train loss: 0.564985 Train acc: 0.791992\n",
      "Epoch: 123/140 Iteration: 10510 Train loss: 0.752755 Train acc: 0.691895\n",
      "Epoch: 123/140 Iteration: 10515 Train loss: 0.805332 Train acc: 0.638184\n",
      "Epoch: 123/140 Iteration: 10520 Train loss: 0.820455 Train acc: 0.605469\n",
      "Epoch: 123/140 Iteration: 10525 Train loss: 0.857784 Train acc: 0.566406\n",
      "Epoch: 123/140 Iteration: 10530 Train loss: 0.815815 Train acc: 0.585938\n",
      "Epoch: 123/140 Iteration: 10535 Train loss: 0.948184 Train acc: 0.548828\n",
      "Epoch: 123/140 Iteration: 10540 Train loss: 0.981924 Train acc: 0.454590\n",
      "Epoch: 124/140 Iteration: 10545 Train loss: 0.813613 Train acc: 0.660645\n",
      "Epoch: 124/140 Iteration: 10550 Train loss: 0.771392 Train acc: 0.663574\n",
      "Epoch: 124/140 Iteration: 10555 Train loss: 0.769448 Train acc: 0.642090\n",
      "Epoch: 124/140 Iteration: 10560 Train loss: 0.702590 Train acc: 0.704102\n",
      "Epoch: 124/140 Iteration: 10565 Train loss: 0.740553 Train acc: 0.668945\n",
      "Epoch: 124/140 Iteration: 10570 Train loss: 0.584563 Train acc: 0.759277\n",
      "Epoch: 124/140 Iteration: 10575 Train loss: 0.431411 Train acc: 0.844727\n",
      "Epoch: 124/140 Iteration: 10580 Train loss: 0.588257 Train acc: 0.754395\n",
      "Epoch: 124/140 Iteration: 10585 Train loss: 0.747405 Train acc: 0.681641\n",
      "Epoch: 124/140 Iteration: 10590 Train loss: 0.589206 Train acc: 0.782715\n",
      "Epoch: 124/140 Iteration: 10595 Train loss: 0.736584 Train acc: 0.716797\n",
      "Epoch: 124/140 Iteration: 10600 Train loss: 0.784195 Train acc: 0.661621\n",
      "Epoch: 124/140 Iteration: 10605 Train loss: 0.815544 Train acc: 0.603027\n",
      "Epoch: 124/140 Iteration: 10610 Train loss: 0.845775 Train acc: 0.570801\n",
      "Epoch: 124/140 Iteration: 10615 Train loss: 0.848370 Train acc: 0.574219\n",
      "Epoch: 124/140 Iteration: 10620 Train loss: 0.885435 Train acc: 0.583984\n",
      "Epoch: 124/140 Iteration: 10625 Train loss: 0.975136 Train acc: 0.467285\n",
      "Epoch: 125/140 Iteration: 10630 Train loss: 0.817019 Train acc: 0.640137\n",
      "Epoch: 125/140 Iteration: 10635 Train loss: 0.781880 Train acc: 0.661133\n",
      "Epoch: 125/140 Iteration: 10640 Train loss: 0.750843 Train acc: 0.645020\n",
      "Epoch: 125/140 Iteration: 10645 Train loss: 0.627557 Train acc: 0.737305\n",
      "Epoch: 125/140 Iteration: 10650 Train loss: 0.737433 Train acc: 0.669434\n",
      "Epoch: 125/140 Iteration: 10655 Train loss: 0.577252 Train acc: 0.756348\n",
      "Epoch: 125/140 Iteration: 10660 Train loss: 0.411907 Train acc: 0.852051\n",
      "Epoch: 125/140 Iteration: 10665 Train loss: 0.563345 Train acc: 0.772949\n",
      "Epoch: 125/140 Iteration: 10670 Train loss: 0.705464 Train acc: 0.704102\n",
      "Epoch: 125/140 Iteration: 10675 Train loss: 0.593607 Train acc: 0.782227\n",
      "Epoch: 125/140 Iteration: 10680 Train loss: 0.741850 Train acc: 0.711914\n",
      "Epoch: 125/140 Iteration: 10685 Train loss: 0.810291 Train acc: 0.652344\n",
      "Epoch: 125/140 Iteration: 10690 Train loss: 0.817811 Train acc: 0.603516\n",
      "Epoch: 125/140 Iteration: 10695 Train loss: 0.871896 Train acc: 0.563477\n",
      "Epoch: 125/140 Iteration: 10700 Train loss: 0.865608 Train acc: 0.550781\n",
      "Epoch: 125/140 Iteration: 10705 Train loss: 0.879817 Train acc: 0.577637\n",
      "Epoch: 125/140 Iteration: 10710 Train loss: 0.938668 Train acc: 0.541504\n",
      "Epoch: 126/140 Iteration: 10715 Train loss: 0.822585 Train acc: 0.644043\n",
      "Epoch: 126/140 Iteration: 10720 Train loss: 0.752208 Train acc: 0.683105\n",
      "Epoch: 126/140 Iteration: 10725 Train loss: 0.777372 Train acc: 0.650391\n",
      "Epoch: 126/140 Iteration: 10730 Train loss: 0.640536 Train acc: 0.733887\n",
      "Epoch: 126/140 Iteration: 10735 Train loss: 0.717710 Train acc: 0.684082\n",
      "Epoch: 126/140 Iteration: 10740 Train loss: 0.565972 Train acc: 0.760742\n",
      "Epoch: 126/140 Iteration: 10745 Train loss: 0.409974 Train acc: 0.860840\n",
      "Epoch: 126/140 Iteration: 10750 Train loss: 0.588102 Train acc: 0.755371\n",
      "Epoch: 126/140 Iteration: 10755 Train loss: 0.674349 Train acc: 0.712402\n",
      "Epoch: 126/140 Iteration: 10760 Train loss: 0.577857 Train acc: 0.797852\n",
      "Epoch: 126/140 Iteration: 10765 Train loss: 0.740012 Train acc: 0.708008\n",
      "Epoch: 126/140 Iteration: 10770 Train loss: 0.828414 Train acc: 0.641602\n",
      "Epoch: 126/140 Iteration: 10775 Train loss: 0.814391 Train acc: 0.623047\n",
      "Epoch: 126/140 Iteration: 10780 Train loss: 0.834589 Train acc: 0.595215\n",
      "Epoch: 126/140 Iteration: 10785 Train loss: 0.801003 Train acc: 0.602539\n",
      "Epoch: 126/140 Iteration: 10790 Train loss: 0.855334 Train acc: 0.596680\n",
      "Epoch: 126/140 Iteration: 10795 Train loss: 0.861343 Train acc: 0.557617\n",
      "Epoch: 127/140 Iteration: 10800 Train loss: 0.786355 Train acc: 0.673828\n",
      "Epoch: 127/140 Iteration: 10805 Train loss: 0.769786 Train acc: 0.659668\n",
      "Epoch: 127/140 Iteration: 10810 Train loss: 0.741241 Train acc: 0.653809\n",
      "Epoch: 127/140 Iteration: 10815 Train loss: 0.614048 Train acc: 0.753418\n",
      "Epoch: 127/140 Iteration: 10820 Train loss: 0.712415 Train acc: 0.705078\n",
      "Epoch: 127/140 Iteration: 10825 Train loss: 0.593952 Train acc: 0.742188\n",
      "Epoch: 127/140 Iteration: 10830 Train loss: 0.455769 Train acc: 0.839844\n",
      "Epoch: 127/140 Iteration: 10835 Train loss: 0.569503 Train acc: 0.763184\n",
      "Epoch: 127/140 Iteration: 10840 Train loss: 0.715428 Train acc: 0.685059\n",
      "Epoch: 127/140 Iteration: 10845 Train loss: 0.568197 Train acc: 0.803223\n",
      "Epoch: 127/140 Iteration: 10850 Train loss: 0.721169 Train acc: 0.712891\n",
      "Epoch: 127/140 Iteration: 10855 Train loss: 0.885580 Train acc: 0.603516\n",
      "Epoch: 127/140 Iteration: 10860 Train loss: 0.790612 Train acc: 0.632812\n",
      "Epoch: 127/140 Iteration: 10865 Train loss: 0.836641 Train acc: 0.594727\n",
      "Epoch: 127/140 Iteration: 10870 Train loss: 0.790853 Train acc: 0.612793\n",
      "Epoch: 127/140 Iteration: 10875 Train loss: 0.852264 Train acc: 0.594727\n",
      "Epoch: 127/140 Iteration: 10880 Train loss: 0.853576 Train acc: 0.567383\n",
      "Epoch: 128/140 Iteration: 10885 Train loss: 0.784081 Train acc: 0.667480\n",
      "Epoch: 128/140 Iteration: 10890 Train loss: 0.800643 Train acc: 0.641602\n",
      "Epoch: 128/140 Iteration: 10895 Train loss: 0.734132 Train acc: 0.661133\n",
      "Epoch: 128/140 Iteration: 10900 Train loss: 0.583472 Train acc: 0.757812\n",
      "Epoch: 128/140 Iteration: 10905 Train loss: 0.685536 Train acc: 0.712402\n",
      "Epoch: 128/140 Iteration: 10910 Train loss: 0.591381 Train acc: 0.740234\n",
      "Epoch: 128/140 Iteration: 10915 Train loss: 0.494963 Train acc: 0.818848\n",
      "Epoch: 128/140 Iteration: 10920 Train loss: 0.564720 Train acc: 0.780273\n",
      "Epoch: 128/140 Iteration: 10925 Train loss: 0.657911 Train acc: 0.717773\n",
      "Epoch: 128/140 Iteration: 10930 Train loss: 0.555219 Train acc: 0.802246\n",
      "Epoch: 128/140 Iteration: 10935 Train loss: 0.739902 Train acc: 0.705078\n",
      "Epoch: 128/140 Iteration: 10940 Train loss: 0.841779 Train acc: 0.634277\n",
      "Epoch: 128/140 Iteration: 10945 Train loss: 0.797630 Train acc: 0.634277\n",
      "Epoch: 128/140 Iteration: 10950 Train loss: 0.809482 Train acc: 0.619141\n",
      "Epoch: 128/140 Iteration: 10955 Train loss: 0.825577 Train acc: 0.578125\n",
      "Epoch: 128/140 Iteration: 10960 Train loss: 0.859218 Train acc: 0.584473\n",
      "Epoch: 128/140 Iteration: 10965 Train loss: 0.910076 Train acc: 0.533691\n",
      "Epoch: 129/140 Iteration: 10970 Train loss: 0.790522 Train acc: 0.673340\n",
      "Epoch: 129/140 Iteration: 10975 Train loss: 0.809314 Train acc: 0.646973\n",
      "Epoch: 129/140 Iteration: 10980 Train loss: 0.736312 Train acc: 0.656738\n",
      "Epoch: 129/140 Iteration: 10985 Train loss: 0.636425 Train acc: 0.741699\n",
      "Epoch: 129/140 Iteration: 10990 Train loss: 0.701330 Train acc: 0.708008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 129/140 Iteration: 10995 Train loss: 0.607649 Train acc: 0.734375\n",
      "Epoch: 129/140 Iteration: 11000 Train loss: 0.495882 Train acc: 0.813477\n",
      "Epoch: 129/140 Iteration: 11005 Train loss: 0.592375 Train acc: 0.756348\n",
      "Epoch: 129/140 Iteration: 11010 Train loss: 0.692278 Train acc: 0.705078\n",
      "Epoch: 129/140 Iteration: 11015 Train loss: 0.561036 Train acc: 0.807129\n",
      "Epoch: 129/140 Iteration: 11020 Train loss: 0.768434 Train acc: 0.706055\n",
      "Epoch: 129/140 Iteration: 11025 Train loss: 0.853502 Train acc: 0.624023\n",
      "Epoch: 129/140 Iteration: 11030 Train loss: 0.813565 Train acc: 0.613281\n",
      "Epoch: 129/140 Iteration: 11035 Train loss: 0.809278 Train acc: 0.628906\n",
      "Epoch: 129/140 Iteration: 11040 Train loss: 0.842870 Train acc: 0.568359\n",
      "Epoch: 129/140 Iteration: 11045 Train loss: 0.863197 Train acc: 0.586914\n",
      "Epoch: 129/140 Iteration: 11050 Train loss: 0.865237 Train acc: 0.562500\n",
      "Epoch: 130/140 Iteration: 11055 Train loss: 0.741500 Train acc: 0.697266\n",
      "Epoch: 130/140 Iteration: 11060 Train loss: 0.773796 Train acc: 0.669922\n",
      "Epoch: 130/140 Iteration: 11065 Train loss: 0.773929 Train acc: 0.653320\n",
      "Epoch: 130/140 Iteration: 11070 Train loss: 0.601540 Train acc: 0.754395\n",
      "Epoch: 130/140 Iteration: 11075 Train loss: 0.680619 Train acc: 0.708008\n",
      "Epoch: 130/140 Iteration: 11080 Train loss: 0.601610 Train acc: 0.750977\n",
      "Epoch: 130/140 Iteration: 11085 Train loss: 0.397151 Train acc: 0.848633\n",
      "Epoch: 130/140 Iteration: 11090 Train loss: 0.556659 Train acc: 0.774902\n",
      "Epoch: 130/140 Iteration: 11095 Train loss: 0.645134 Train acc: 0.733887\n",
      "Epoch: 130/140 Iteration: 11100 Train loss: 0.575585 Train acc: 0.795898\n",
      "Epoch: 130/140 Iteration: 11105 Train loss: 0.734733 Train acc: 0.716309\n",
      "Epoch: 130/140 Iteration: 11110 Train loss: 0.829261 Train acc: 0.638184\n",
      "Epoch: 130/140 Iteration: 11115 Train loss: 0.810767 Train acc: 0.616699\n",
      "Epoch: 130/140 Iteration: 11120 Train loss: 0.789148 Train acc: 0.638672\n",
      "Epoch: 130/140 Iteration: 11125 Train loss: 0.847053 Train acc: 0.567871\n",
      "Epoch: 130/140 Iteration: 11130 Train loss: 0.888524 Train acc: 0.584473\n",
      "Epoch: 130/140 Iteration: 11135 Train loss: 0.999181 Train acc: 0.479980\n",
      "Epoch: 131/140 Iteration: 11140 Train loss: 0.738567 Train acc: 0.699707\n",
      "Epoch: 131/140 Iteration: 11145 Train loss: 0.773832 Train acc: 0.674316\n",
      "Epoch: 131/140 Iteration: 11150 Train loss: 0.715045 Train acc: 0.664062\n",
      "Epoch: 131/140 Iteration: 11155 Train loss: 0.625088 Train acc: 0.735840\n",
      "Epoch: 131/140 Iteration: 11160 Train loss: 0.682211 Train acc: 0.687988\n",
      "Epoch: 131/140 Iteration: 11165 Train loss: 0.580844 Train acc: 0.757812\n",
      "Epoch: 131/140 Iteration: 11170 Train loss: 0.409015 Train acc: 0.845703\n",
      "Epoch: 131/140 Iteration: 11175 Train loss: 0.540408 Train acc: 0.777344\n",
      "Epoch: 131/140 Iteration: 11180 Train loss: 0.640497 Train acc: 0.736328\n",
      "Epoch: 131/140 Iteration: 11185 Train loss: 0.564376 Train acc: 0.814453\n",
      "Epoch: 131/140 Iteration: 11190 Train loss: 0.796923 Train acc: 0.695312\n",
      "Epoch: 131/140 Iteration: 11195 Train loss: 0.853210 Train acc: 0.639160\n",
      "Epoch: 131/140 Iteration: 11200 Train loss: 0.862139 Train acc: 0.566406\n",
      "Epoch: 131/140 Iteration: 11205 Train loss: 0.889189 Train acc: 0.565918\n",
      "Epoch: 131/140 Iteration: 11210 Train loss: 0.860842 Train acc: 0.535156\n",
      "Epoch: 131/140 Iteration: 11215 Train loss: 0.909821 Train acc: 0.558594\n",
      "Epoch: 131/140 Iteration: 11220 Train loss: 0.947738 Train acc: 0.505371\n",
      "Epoch: 132/140 Iteration: 11225 Train loss: 0.810329 Train acc: 0.646484\n",
      "Epoch: 132/140 Iteration: 11230 Train loss: 0.764089 Train acc: 0.687012\n",
      "Epoch: 132/140 Iteration: 11235 Train loss: 0.807019 Train acc: 0.641602\n",
      "Epoch: 132/140 Iteration: 11240 Train loss: 0.703252 Train acc: 0.700684\n",
      "Epoch: 132/140 Iteration: 11245 Train loss: 0.701816 Train acc: 0.691895\n",
      "Epoch: 132/140 Iteration: 11250 Train loss: 0.580150 Train acc: 0.755371\n",
      "Epoch: 132/140 Iteration: 11255 Train loss: 0.422933 Train acc: 0.838867\n",
      "Epoch: 132/140 Iteration: 11260 Train loss: 0.557174 Train acc: 0.771484\n",
      "Epoch: 132/140 Iteration: 11265 Train loss: 0.626708 Train acc: 0.743652\n",
      "Epoch: 132/140 Iteration: 11270 Train loss: 0.542298 Train acc: 0.823730\n",
      "Epoch: 132/140 Iteration: 11275 Train loss: 0.727992 Train acc: 0.716309\n",
      "Epoch: 132/140 Iteration: 11280 Train loss: 0.829924 Train acc: 0.651367\n",
      "Epoch: 132/140 Iteration: 11285 Train loss: 0.899970 Train acc: 0.544434\n",
      "Epoch: 132/140 Iteration: 11290 Train loss: 0.892231 Train acc: 0.560059\n",
      "Epoch: 132/140 Iteration: 11295 Train loss: 0.871523 Train acc: 0.529785\n",
      "Epoch: 132/140 Iteration: 11300 Train loss: 0.898690 Train acc: 0.572266\n",
      "Epoch: 132/140 Iteration: 11305 Train loss: 0.907978 Train acc: 0.530273\n",
      "Epoch: 133/140 Iteration: 11310 Train loss: 0.787098 Train acc: 0.663086\n",
      "Epoch: 133/140 Iteration: 11315 Train loss: 0.765515 Train acc: 0.689453\n",
      "Epoch: 133/140 Iteration: 11320 Train loss: 0.763337 Train acc: 0.672852\n",
      "Epoch: 133/140 Iteration: 11325 Train loss: 0.617875 Train acc: 0.756348\n",
      "Epoch: 133/140 Iteration: 11330 Train loss: 0.677395 Train acc: 0.703613\n",
      "Epoch: 133/140 Iteration: 11335 Train loss: 0.607556 Train acc: 0.745117\n",
      "Epoch: 133/140 Iteration: 11340 Train loss: 0.422522 Train acc: 0.838867\n",
      "Epoch: 133/140 Iteration: 11345 Train loss: 0.548835 Train acc: 0.779297\n",
      "Epoch: 133/140 Iteration: 11350 Train loss: 0.617379 Train acc: 0.753418\n",
      "Epoch: 133/140 Iteration: 11355 Train loss: 0.533127 Train acc: 0.833008\n",
      "Epoch: 133/140 Iteration: 11360 Train loss: 0.749538 Train acc: 0.708496\n",
      "Epoch: 133/140 Iteration: 11365 Train loss: 0.871951 Train acc: 0.629395\n",
      "Epoch: 133/140 Iteration: 11370 Train loss: 0.848439 Train acc: 0.568359\n",
      "Epoch: 133/140 Iteration: 11375 Train loss: 0.897161 Train acc: 0.548340\n",
      "Epoch: 133/140 Iteration: 11380 Train loss: 0.901559 Train acc: 0.519043\n",
      "Epoch: 133/140 Iteration: 11385 Train loss: 0.872879 Train acc: 0.592773\n",
      "Epoch: 133/140 Iteration: 11390 Train loss: 0.830441 Train acc: 0.606445\n",
      "Epoch: 134/140 Iteration: 11395 Train loss: 0.840107 Train acc: 0.626953\n",
      "Epoch: 134/140 Iteration: 11400 Train loss: 0.825547 Train acc: 0.632324\n",
      "Epoch: 134/140 Iteration: 11405 Train loss: 0.773047 Train acc: 0.656738\n",
      "Epoch: 134/140 Iteration: 11410 Train loss: 0.624376 Train acc: 0.753906\n",
      "Epoch: 134/140 Iteration: 11415 Train loss: 0.683226 Train acc: 0.705078\n",
      "Epoch: 134/140 Iteration: 11420 Train loss: 0.583327 Train acc: 0.751953\n",
      "Epoch: 134/140 Iteration: 11425 Train loss: 0.407151 Train acc: 0.839844\n",
      "Epoch: 134/140 Iteration: 11430 Train loss: 0.566365 Train acc: 0.757812\n",
      "Epoch: 134/140 Iteration: 11435 Train loss: 0.664045 Train acc: 0.732422\n",
      "Epoch: 134/140 Iteration: 11440 Train loss: 0.562764 Train acc: 0.803223\n",
      "Epoch: 134/140 Iteration: 11445 Train loss: 0.692157 Train acc: 0.729492\n",
      "Epoch: 134/140 Iteration: 11450 Train loss: 0.841866 Train acc: 0.641113\n",
      "Epoch: 134/140 Iteration: 11455 Train loss: 0.821436 Train acc: 0.611328\n",
      "Epoch: 134/140 Iteration: 11460 Train loss: 0.830359 Train acc: 0.615234\n",
      "Epoch: 134/140 Iteration: 11465 Train loss: 0.880608 Train acc: 0.525391\n",
      "Epoch: 134/140 Iteration: 11470 Train loss: 0.878108 Train acc: 0.583984\n",
      "Epoch: 134/140 Iteration: 11475 Train loss: 0.820885 Train acc: 0.584473\n",
      "Epoch: 135/140 Iteration: 11480 Train loss: 0.778714 Train acc: 0.675293\n",
      "Epoch: 135/140 Iteration: 11485 Train loss: 0.779206 Train acc: 0.657227\n",
      "Epoch: 135/140 Iteration: 11490 Train loss: 0.707024 Train acc: 0.690430\n",
      "Epoch: 135/140 Iteration: 11495 Train loss: 0.640241 Train acc: 0.728516\n",
      "Epoch: 135/140 Iteration: 11500 Train loss: 0.673601 Train acc: 0.708496\n",
      "Epoch: 135/140 Iteration: 11505 Train loss: 0.559934 Train acc: 0.755859\n",
      "Epoch: 135/140 Iteration: 11510 Train loss: 0.390066 Train acc: 0.853516\n",
      "Epoch: 135/140 Iteration: 11515 Train loss: 0.551161 Train acc: 0.772949\n",
      "Epoch: 135/140 Iteration: 11520 Train loss: 0.641095 Train acc: 0.744629\n",
      "Epoch: 135/140 Iteration: 11525 Train loss: 0.525325 Train acc: 0.836426\n",
      "Epoch: 135/140 Iteration: 11530 Train loss: 0.695535 Train acc: 0.731445\n",
      "Epoch: 135/140 Iteration: 11535 Train loss: 0.820995 Train acc: 0.642578\n",
      "Epoch: 135/140 Iteration: 11540 Train loss: 0.850189 Train acc: 0.563965\n",
      "Epoch: 135/140 Iteration: 11545 Train loss: 0.826046 Train acc: 0.639160\n",
      "Epoch: 135/140 Iteration: 11550 Train loss: 0.880323 Train acc: 0.507324\n",
      "Epoch: 135/140 Iteration: 11555 Train loss: 0.859634 Train acc: 0.591309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 135/140 Iteration: 11560 Train loss: 0.832793 Train acc: 0.582520\n",
      "Epoch: 136/140 Iteration: 11565 Train loss: 0.769377 Train acc: 0.679199\n",
      "Epoch: 136/140 Iteration: 11570 Train loss: 0.778454 Train acc: 0.663086\n",
      "Epoch: 136/140 Iteration: 11575 Train loss: 0.741051 Train acc: 0.680176\n",
      "Epoch: 136/140 Iteration: 11580 Train loss: 0.667129 Train acc: 0.724609\n",
      "Epoch: 136/140 Iteration: 11585 Train loss: 0.710478 Train acc: 0.685059\n",
      "Epoch: 136/140 Iteration: 11590 Train loss: 0.538449 Train acc: 0.778320\n",
      "Epoch: 136/140 Iteration: 11595 Train loss: 0.438289 Train acc: 0.839355\n",
      "Epoch: 136/140 Iteration: 11600 Train loss: 0.558535 Train acc: 0.769531\n",
      "Epoch: 136/140 Iteration: 11605 Train loss: 0.681430 Train acc: 0.726074\n",
      "Epoch: 136/140 Iteration: 11610 Train loss: 0.581345 Train acc: 0.799805\n",
      "Epoch: 136/140 Iteration: 11615 Train loss: 0.719384 Train acc: 0.712891\n",
      "Epoch: 136/140 Iteration: 11620 Train loss: 0.797517 Train acc: 0.651367\n",
      "Epoch: 136/140 Iteration: 11625 Train loss: 0.825979 Train acc: 0.583496\n",
      "Epoch: 136/140 Iteration: 11630 Train loss: 0.829643 Train acc: 0.632324\n",
      "Epoch: 136/140 Iteration: 11635 Train loss: 0.873032 Train acc: 0.523438\n",
      "Epoch: 136/140 Iteration: 11640 Train loss: 0.837379 Train acc: 0.609863\n",
      "Epoch: 136/140 Iteration: 11645 Train loss: 0.807027 Train acc: 0.587891\n",
      "Epoch: 137/140 Iteration: 11650 Train loss: 0.817997 Train acc: 0.656738\n",
      "Epoch: 137/140 Iteration: 11655 Train loss: 0.745965 Train acc: 0.691406\n",
      "Epoch: 137/140 Iteration: 11660 Train loss: 0.835201 Train acc: 0.648438\n",
      "Epoch: 137/140 Iteration: 11665 Train loss: 0.679884 Train acc: 0.714844\n",
      "Epoch: 137/140 Iteration: 11670 Train loss: 0.720308 Train acc: 0.685547\n",
      "Epoch: 137/140 Iteration: 11675 Train loss: 0.564534 Train acc: 0.760254\n",
      "Epoch: 137/140 Iteration: 11680 Train loss: 0.420569 Train acc: 0.850098\n",
      "Epoch: 137/140 Iteration: 11685 Train loss: 0.593866 Train acc: 0.760742\n",
      "Epoch: 137/140 Iteration: 11690 Train loss: 0.668484 Train acc: 0.709473\n",
      "Epoch: 137/140 Iteration: 11695 Train loss: 0.562204 Train acc: 0.817871\n",
      "Epoch: 137/140 Iteration: 11700 Train loss: 0.714005 Train acc: 0.719727\n",
      "Epoch: 137/140 Iteration: 11705 Train loss: 0.815683 Train acc: 0.636230\n",
      "Epoch: 137/140 Iteration: 11710 Train loss: 0.799131 Train acc: 0.599609\n",
      "Epoch: 137/140 Iteration: 11715 Train loss: 0.826604 Train acc: 0.593750\n",
      "Epoch: 137/140 Iteration: 11720 Train loss: 0.846005 Train acc: 0.543945\n",
      "Epoch: 137/140 Iteration: 11725 Train loss: 0.834201 Train acc: 0.607910\n",
      "Epoch: 137/140 Iteration: 11730 Train loss: 0.811247 Train acc: 0.589844\n",
      "Epoch: 138/140 Iteration: 11735 Train loss: 0.807863 Train acc: 0.653809\n",
      "Epoch: 138/140 Iteration: 11740 Train loss: 0.748638 Train acc: 0.673340\n",
      "Epoch: 138/140 Iteration: 11745 Train loss: 0.756619 Train acc: 0.671875\n",
      "Epoch: 138/140 Iteration: 11750 Train loss: 0.692546 Train acc: 0.696777\n",
      "Epoch: 138/140 Iteration: 11755 Train loss: 0.739344 Train acc: 0.657715\n",
      "Epoch: 138/140 Iteration: 11760 Train loss: 0.556566 Train acc: 0.765625\n",
      "Epoch: 138/140 Iteration: 11765 Train loss: 0.384015 Train acc: 0.860352\n",
      "Epoch: 138/140 Iteration: 11770 Train loss: 0.590080 Train acc: 0.744629\n",
      "Epoch: 138/140 Iteration: 11775 Train loss: 0.703068 Train acc: 0.693359\n",
      "Epoch: 138/140 Iteration: 11780 Train loss: 0.611170 Train acc: 0.795410\n",
      "Epoch: 138/140 Iteration: 11785 Train loss: 0.720625 Train acc: 0.716309\n",
      "Epoch: 138/140 Iteration: 11790 Train loss: 0.845568 Train acc: 0.625488\n",
      "Epoch: 138/140 Iteration: 11795 Train loss: 0.788053 Train acc: 0.625977\n",
      "Epoch: 138/140 Iteration: 11800 Train loss: 0.858677 Train acc: 0.562012\n",
      "Epoch: 138/140 Iteration: 11805 Train loss: 0.844509 Train acc: 0.549316\n",
      "Epoch: 138/140 Iteration: 11810 Train loss: 0.880647 Train acc: 0.582031\n",
      "Epoch: 138/140 Iteration: 11815 Train loss: 0.869541 Train acc: 0.554688\n",
      "Epoch: 139/140 Iteration: 11820 Train loss: 0.842458 Train acc: 0.637207\n",
      "Epoch: 139/140 Iteration: 11825 Train loss: 0.814637 Train acc: 0.649902\n",
      "Epoch: 139/140 Iteration: 11830 Train loss: 0.817378 Train acc: 0.651367\n",
      "Epoch: 139/140 Iteration: 11835 Train loss: 0.707501 Train acc: 0.686035\n",
      "Epoch: 139/140 Iteration: 11840 Train loss: 0.742690 Train acc: 0.662109\n",
      "Epoch: 139/140 Iteration: 11845 Train loss: 0.554389 Train acc: 0.763672\n",
      "Epoch: 139/140 Iteration: 11850 Train loss: 0.430265 Train acc: 0.844238\n",
      "Epoch: 139/140 Iteration: 11855 Train loss: 0.560286 Train acc: 0.766602\n",
      "Epoch: 139/140 Iteration: 11860 Train loss: 0.708211 Train acc: 0.689453\n",
      "Epoch: 139/140 Iteration: 11865 Train loss: 0.543887 Train acc: 0.826660\n",
      "Epoch: 139/140 Iteration: 11870 Train loss: 0.721705 Train acc: 0.705566\n",
      "Epoch: 139/140 Iteration: 11875 Train loss: 0.822605 Train acc: 0.633301\n",
      "Epoch: 139/140 Iteration: 11880 Train loss: 0.788965 Train acc: 0.626465\n",
      "Epoch: 139/140 Iteration: 11885 Train loss: 0.863487 Train acc: 0.549316\n",
      "Epoch: 139/140 Iteration: 11890 Train loss: 0.838456 Train acc: 0.553223\n",
      "Epoch: 139/140 Iteration: 11895 Train loss: 0.852197 Train acc: 0.589844\n",
      "Epoch: 139/140 Iteration: 11900 Train loss: 0.819421 Train acc: 0.594727\n"
     ]
    }
   ],
   "source": [
    "interation_compute_val = 1\n",
    "validation_acc = []\n",
    "validation_loss = []\n",
    "\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "\n",
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "    saver.restore(sess, \"checkpoints/har-lstm.ckpt\")\n",
    "    for e in range(epochs):\n",
    "        # Initialize \n",
    "        state = sess.run(initial_state)\n",
    "        \n",
    "        # Loop over batches\n",
    "        for x,y in get_batches(X_tr, y_tr, batch_size):\n",
    "            \n",
    "            # Feed dictionary\n",
    "            feed = {inputs_ : x, labels_ : y, keep_prob_ : 0.5, \n",
    "                    initial_state : state, learning_rate_ : learning_rate}\n",
    "            \n",
    "            loss, _ , state, acc = sess.run([cost, optimizer, final_state, accuracy], \n",
    "                                             feed_dict = feed)\n",
    "            train_acc.append(acc)\n",
    "            train_loss.append(loss)\n",
    "            \n",
    "            # Print at each 5 iters\n",
    "            if (iteration % 5 == 0):\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Train loss: {:6f}\".format(loss),\n",
    "                      \"Train acc: {:.6f}\".format(acc))\n",
    "            \n",
    "            # Compute validation loss at every 25 iterations\n",
    "            if (iteration%interation_compute_val == compute_val_at):\n",
    "                \n",
    "                # Initiate for validation set\n",
    "                val_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "                \n",
    "                val_acc_ = []\n",
    "                val_loss_ = []\n",
    "                for x_v, y_v in get_batches(X_vld, y_vld, batch_size):\n",
    "                    # Feed\n",
    "                    feed = {inputs_ : x_v, labels_ : y_v, keep_prob_ : 1.0, initial_state : val_state}\n",
    "                    \n",
    "                    # Loss\n",
    "                    loss_v, state_v, acc_v = sess.run([cost, final_state, accuracy], feed_dict = feed)\n",
    "                    \n",
    "                    val_acc_.append(acc_v)\n",
    "                    val_loss_.append(loss_v)\n",
    "                \n",
    "                # Print info\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Validation loss: {:6f}\".format(np.mean(val_loss_)),\n",
    "                      \"Validation acc: {:.6f}\".format(np.mean(val_acc_)))\n",
    "                \n",
    "                # Store\n",
    "                validation_acc.append(np.mean(val_acc_))\n",
    "                validation_loss.append(np.mean(val_loss_))\n",
    "            \n",
    "            # Iterate \n",
    "            iteration += 1\n",
    "    \n",
    "    saver.save(sess,\"checkpoints/har-lstm.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7MAAAF3CAYAAAB3+BzkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAjUMwCwAAAABoHIJZAAAAAEDj/H8nlc4nNg3pPwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and test loss\n",
    "t = np.arange(iteration-1)\n",
    "\n",
    "plt.figure(figsize = (16,6))\n",
    "plt.plot(t, np.array(train_loss), 'r-', t[t % interation_compute_val == compute_val_at], np.array(validation_loss), 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7MAAAF3CAYAAAB3+BzkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzsnXfYFcX1x78jFlCwAcaCCnbACCga\nu1gjYoklBEuiJGhU7PFnVxBjojEqNmzYGyKKFaOiEnuBCIigUkRBVIr0Xub3x7K+9713Zu/M7szu\n3nu/n+d5n3vfubNnzu7duztnz5lzhJQShBBCCCGEEEJIJbFG1goQQgghhBBCCCG20JglhBBCCCGE\nEFJx0JglhBBCCCGEEFJx0JglhBBCCCGEEFJx0JglhBBCCCGEEFJx0JglhBBCCCGEEFJx0JglhBBC\nCCGEEFJx0JglhBBCCCGEEFJx0JglhBBCCCGEEFJx0JglhBBCCCGEEFJxrJm1ArY0a9ZMtmzZMms1\nCCGEEEIIIYR4YMSIETOllM3L9as4Y7Zly5YYPnx41moQQgghhBBCCPGAEOJbk34MMyaEEEIIIYQQ\nUnF4NWaFEIcLIb4SQkwQQlym+HxrIcSbQojRQohhQogWPvUhhBBCCCGEEFIdeDNmhRANANwFoDOA\nNgBOFEK0Ker2bwCPSil3AdAHwD996UMIIYQQQgghpHrwuWZ2DwATpJSTAEAIMQDAMQDGFvRpA+DC\n1e/fBvC8R30IIYQQQgghJDbLly/H1KlTsWTJkqxVqQoaNmyIFi1aYK211oq1vU9jdgsAUwr+nwrg\nN0V9RgE4HsBtAI4F0EQI0VRKOcujXoQQQgghhBBizdSpU9GkSRO0bNkSQois1alopJSYNWsWpk6d\nilatWsWS4XPNrOrblUX/XwzgACHEZwAOAPA9gBUlgoQ4QwgxXAgxfMaMGe41JYQQQgghhJAyLFmy\nBE2bNqUh6wAhBJo2bZrIy+3TmJ0KYMuC/1sAmFbYQUo5TUp5nJSyA4ArV7fNLRYkpbxPStlRStmx\nefOy5YYIIYQQQgghxAs0ZN2R9Fj6NGY/BbC9EKKVEGJtAN0AvFjYQQjRTAgR6nA5gAc96kMIIYQQ\nQgghFcucOXPQr18/6+2OOOIIzJkzx4NG2eLNmJVSrgBwDoDXAIwDMFBK+YUQoo8Q4ujV3ToB+EoI\n8TWAXwG43pc+hBBCCCGEEFLJ6IzZlStXRm43ZMgQbLjhhr7UygyfCaAgpRwCYEhR2zUF7wcBGORT\nB0IIIYQQQgipBi677DJMnDgR7du3x1prrYXGjRtjs802w8iRIzF27Fj87ne/w5QpU7BkyRKcf/75\nOOOMMwAALVu2xPDhw7FgwQJ07twZ++67Lz744ANsscUWeOGFF9CoUaOM9yweXo1ZQgghhBBCCKlK\nLrgAGDnSrcz27YG+fbUf33DDDRgzZgxGjhyJYcOGoUuXLhgzZswv2YAffPBBbLzxxli8eDF23313\nHH/88WjatGk9GePHj8dTTz2F+++/H127dsWzzz6LU045xe1+pASNWUIIIYQQQgjJklWrgDXsV4Du\nscce9cra3H777Rg8eDAAYMqUKRg/fnyJMduqVSu0b98eALDbbrth8uTJ8fXOGBqzhBBCCCGEEGJL\nhAfVih9/BKZOBVq3BtZbz2rT9Qr6Dxs2DEOHDsWHH36IddddF506dVKWvVlnnXV+ed+gQQMsXrw4\nvu4Z4zObMSGEEEIIIYSQKBYuDF6XLi3btUmTJpg/f77ys7lz52KjjTbCuuuuiy+//BIfffSRSy1z\nCY1ZQgghhBBCSP6YPh3o0QNQeBdrlaZNm2KfffbBzjvvjP/7v/+r99nhhx+OFStWYJdddsHVV1+N\nPffcMyMt04NhxoQQQgghhJD8ccklwCOPAPvtB5x6atba5IYnn3xS2b7OOuvg1VdfVX4Wrott1qwZ\nxowZ80v7xRdf7Fy/NKFnlhBCCCGEEJI/pKz/SkgRNGYJIYQQQggh6bBwIbB8uVlfIdTtK1YAmnWj\npLagMUsIIYQQQkg1sHIlsGhR1lpE07gxcMgh9dvmzwc22ggYOtRMRvfuwPrru9eNVBw0ZgkhhBBC\nCKkGevYMSrusWpW1JtG88079/8eMAebMAa6+2mz7xx93r1MaSAlMm2bumV60KEiCRbTQmCWEEEII\nIaQauP/+4LV4jemUKcD48aX9H38c+PRT/3olpVrWzC5YEBizq5MxlWXsWOC770rbp0wBvv3WqWqV\nCo1ZQgghhBBCXLNgATByZDZjFxt/W20F7LBDab8//hHYYw8zmQsWANdfH6xXdY3OWNWtma1Uwv1M\n6jn/6Sdgxozk+lQBNGYJIYQQQghxzbHHAh06AMuWpTemT+Pv6quBq64CNGVhSD5p3LgxAGDatGk4\n4YQTlH06deqE4cOHR8rp27cvFhWsxz7iiCMwZ84cd4rGhMYsIYQQQgghrnnvveB15cps9XDFggXB\n69Kl7mWXM8J1ntsKCT/+4QfggAOAH3+KuZ/hsU/A5ptvjkGDBsXevtiYHTJkCDbccMPEeiWFxiwh\nhBBCCCG+qBCDyxjT/ZkxI7DiksiMa+SaMnasn7DpIq67Lni20efGteMJKPDuX3rppej3zDO//N+7\nd29ce+21OPjgg7Fru3b49c4744UXXigRMXnyZOy8884AgMWLF6Nbt27YZZdd8Ic//AGLFy/+pd9Z\nZ52Fjh07om3btujVqxcA4Pbbb8e0adNw4IEH4sADDwQAtGzZEjNnzgQA3HLLLdh5552x8847o2/f\nvr+M17p1a5x++ulo27YtDjvssHrjuILGLCGEEEIIqQ4++CAwgIrXqt54Y9BumkXWBbYhv5deChQY\nKYnwYUCH+2Mqe5NNgM03dzO2bsyPPoovc/x4oG1b4Mor48soQ6NGwWG7++5gmezdD6wDsXtHNGq3\nvZ2ggv3v1q0bnn7jjV/+HzhwILp3747Bgwfjfw88gLf79sXf/vY3yIjv6e6778a6666L0aNH48or\nr8SIESN++ez666/H8OHDMXr0aPz3v//F6NGjcd5552HzzTfH22+/jbfffruerBEjRuChhx7Cxx9/\njI8++gj3338/PvvsMwDA+PHj0bNnT3zxxRfYcMMN8eyzz9rttwE0ZgkhhBBCSDImT053baiOwYOD\n14LJPgDgH/8IXvNcg/Vf/wK6djXrK6U6O3Gt8eKL9f8/8MDAQC3miiuAIUPqt/34Y/D6/vt+dAMw\naRJw0knAuusG/6/bSOLkw2fhm6GT6ne0ePDRoUMHTJ89G9NmzMCoUaOw0UYbYbPNNsMVV1yBXU48\nEYecfTa+//57/PTTT1oZ77zzDk455RQAwC677IJddtnll88GDhyIXXfdFR06dMAXX3yBsWPHRurz\n3nvv4dhjj8V6662Hxo0b47jjjsO7774LAGjVqhXat28PANhtt90w2TSLswU0ZgkhhBBCSHzmzAFa\ntQLOPjtrTeqottDeYh55JMhO/NZb9dtdJYB6+unge00bW/2Lv+dhw4LQ4WL++U+gS5dkY117rfU2\nm20GrL8+sGQJ0LAhsGQpsP56K7Fp82TrqE846CAMevNNPP300+jWrRueeOIJzJgxAyMeewwjn3wS\nv/rVr7BkyZJIGUKxL9988w3+/e9/480338To0aPRpUuXsnKiPMDrrLPOL+8bNGiAFR5CumnMEkII\nIYSQ+MyfH7y+9pof+bfdVupV0+F7jaULnnsOuPfeZDLC2rDjxqk/T7Kf48YB3boBp51Wv113bJct\nC0rF+CBP32fv3rE2++kn4Mwzg4joM/+8HD/OWitxQqtuhx2GAa+/jkGDBuGEE07A3Llzsckmm2Ct\nNdfE28OH49syNWj3339/PPHEEwCAMWPGYPTo0QCAefPmYb311sMGG2yAn376Ca+++uov2zRp0gTz\nw996kaznn38eixYtwsKFCzF48GDst99+RvvhgjVTG4kQQgghhBBbLrggeLUxXPJgtOo4/vjg9a9/\nTS7Lx36GodhTppiNedJJwLPP+j3ms2aZ6ZJDnnuu7v1dtywFvpoIoHH9TqHHcupUoFmzsjLbbrst\n5i9ahC223BKbbbYZTj75ZBx11FHo+OabaL/DDthpp50itz/rrLPQvXt37LLLLmjfvj32WF1ruF27\ndujQoQPatm2LbbbZBvvss88v25xxxhno3LkzNttss3rrZnfddVecdtppv8jo0aMHOnTo4CWkWAWN\nWUIIIYQQkpy0DYuffwY22ABo0CDdcW1JelxmzQI22ghYoyCgMg2PpakMD0l9fmHu3OD10kuBSy7x\nN04hy5YBr7wC/O53fuv2FrJqVfCqC8NVfBefDxgA7LYbAKBZs2b48MMPgbBWbMeOv/RbsLqsT8uW\nLTFmzBgAQKNGjTBgwADlUA8//LCy/dxzz8W55577y/+FxupFF12Eiy66qF7/wvEA4OKLL1bvW0IY\nZkwIIYQQQuKT1oS/kNmzgaZNgcsvN+uv0/Hcc4FDDnGnl2umTw88datLpJTFxXcRV4aPhxlpJBUr\n1rt3b+C444A770wmd8wY89JEcdEd8++/rwivtQtozBJCCCGEkMri55+D12KvoK3H8s47gTffdKeX\na8K1qM8/r/484dpLK+J6g2fPdq9LuTFN0O3Pxx8Hr+edF182EGR9+v77ZDLKodv/H37IR3bxFKAx\nSwghhBBC6nPNNcDRR2etRXlMjbksvMc+x8xif0J0x3zhQnV7+ODBROaHH8bTySUry2QaLpPdNxbl\njPI4RnsYugwE66Cr1LilMUsIIYQQQupz3XXASy9lrYWepCVcKg1b/X2smS13zG+4Qd2epeHtg8WL\nI8vRmMrAzJl1//s4RoU6jh0LrM5YnDeSHksas4QQQggheeann4Cvv85ai/IUT0qlBN57r7R98mT1\nesQffgAmTPCmXmKkBG69FZg2zX47X/jwQMeVkcRjqRvTh8cyoYyG8+Zh1qxZdUbYvHl1iapMWbky\n+B2YUukPYzRIKTFr1iw0bNgwtgxmMyaEEEIIyTObbRZMZittQvvII0D37sCTTwInnljXfsghwMSJ\nQUmXjTeua9988+A1SQkenVHkwsibMAG46CLg6aeDoqFpUqx/nuqvlsPk2LvWd8ECoHHj6D4xz4kW\nw4dj6o47YsaMGUFDWNN1663rdww9ryNHAuusE7xfsqS+RzasE/zjj8DSpfXbCmWsWlW/PFHY/uWX\n9bNcF8oePx5Ye+367bq6xBnSsGFDtGjRIvb2NGYJIYQQQvJMngyTKIqNg/Hjg9dJk+q3hwmBCtf0\nJR2rGB+JkcKyKbZeOBeGdJqJnsphO2aS/U+SdKqcMauTUWb/1lq2DK1atapraNMmeJ0+HWjevLQd\nCAzadu2CSIXOnUvH6tED+OCD4P2iRUCjRvVl3Hkn0LNnqey5c4H111eP+dlnQOvWwKhRdWNWyrXE\nAoYZE0IIIYTkgVtuCSbvukQ6xUyZUt9bkzVZJGPKItFTmutX43qafa6ZXbw4uey4Oth+HoXr0Oao\nhzM//mimEwCcfLK57Chdw89sxq5AaMwSQgghhOSB224LXgtDBaPYaivAJjxv7NjSto8/DkKAfXhJ\nfRpcoew0jXlbQ7lSMyjrZIRG7MUXqz/34fXzaczG3da3AT14cOnnEyfWhSHb6lIYhvzii+X7Vxg0\nZgkhhBBCKhXTpDvPPQe0bQs880z99t/9DhgwoK6eaTmaNQO6drXTsRiXRt6CBer2PJTmCdEZHC6S\neqUZfqwypgrJU9Zin7pkEap7223AaaeVtkfpEh6DQmP2mGOcqpUHaMwSQgghhOQJH5Plzz8PXseM\nSSZn1qxSgzhPuDJiLr0UOPVUN7J0fP11+ZqmOrIwHOOel3kycgsJ9fr2W+A//6lrL7ef06apQ60f\nfzxY7+qL114rbTMJM27QwI8+OYHGLCGEEEJIHsij99Cn7CzGNOVf/wIefdRc9tSppW3h2mdd5uOj\njgKuvdZMnzwk7smjAe3iuPzwgzopk46HH67fP+Tii/Uh2CFJsm3H3dc1qtvcq+69I4QQQgipFLIw\nWLJIxmQz5vz5djJ8Glw62U8/DWy5JfDWW+rPH39cL/PNN5PpZPugICwnY8KoUfb6qHBlqLnSJ8RE\nL90a0//+V93+ww/xxyqH6hg1bRpkSo4ir55xR9CYJYQQQgipFqQErroqqD+ZFj4ny4VlR1zg44FB\n6HktZ1QkwbTObLnvIiyLFIesw4zbtzfva2O0F1O4n67XmCY5Frrj/+ST8WVWATRmCSGEEFJdPPZY\n/TVwlYKLSf9PPwHXXw8ceqj68ywyztpu9/rr6vJEL76o3uaf/yw/lurYfvJJ+e1s+PlndbuPMjlx\n+ycJOc2iTE45dGPuuiswcGBp+yuvxJdpwsSJ8bcth06v5cuj+9MzSwghhBBSQfzpT+o1bXlh8eJg\nbZ2unmySyXRYYmfFivrtadQlNZVdTpff/hb4y19K2485BnjhhVIZV1xRWlpo4kR1KaJCfvOb6M91\nFO9PmMTp+uvjyUtCsS7h/7pSS7pjX/jwJ49rY+Pw6qulbUceCbz/vvuxQsJj99RT6s99PEzQGbPl\ntqsSaMwSQgghhKTJHXcAN98M3HRTemPqJrQ+65Imkf3VV+p2XQmhcKzw9aGHglJEQBByqvOa2qDb\nn3IZbE2Ow/jxdjJ0MsPyOXfcof5cZ0x17gy8/Xa0DnHR6apbd3rwweayly7VZ4QOH+h061a/PTwX\nTGq+2hLKPOmk6M9N0D2oKKb4wVWNQWOWEEIIISRNQk+KzqNSLZ4xH2MWG63Fst55p3SbM88sL/f9\n98vX7FUZDV9+CTzwQHn5OkK9d9jBrJ8p336rbo86t6ZPT6aDbTKqTp3USZ10ibRU3HdfqbFazNNP\nm8sD9F5tn6iOUbGnX3ccv/8+WjbDjAkhhBBCCADg1lvLT55N8VmyxtST5xJTvX3p8uGHwLvvlrYX\nek51Ou67L3DuudHyQ09voYywfq8vyh0r3RpNnQfWVQIiVw8/XHjMBw1KLqOQLIxZFbrSUMXo9K3y\n8OIQGrOEEEIIIaZcdJG9p6eYLMrK5HFim0Sno48ulaUri2I6zujR9nroZOuMtCTZhAsJvcj9+qk/\n1xmzJms2Tc7DZs1K23THokMH4LPP1J9lkaTI5/rxKNkrVsRfpw1kU6+5AqAxSwghhBCSJj4npbYy\nXBoRPtYg6lCVwXE1zhZbRH9u4qE8/fS694XHpWPHeDqNHQscd1zd/4XrRFW1ahs0UMtJkoCoEJWx\nftttwIABpe2zZgGXXRYtz8cDnnLng658lQ/PrBDlEzUVU6x/XL0YZkwIIYQQQioanxPa0PjTeUaL\nmTcveJ082Z0OLg3madPq3pfz1haPG25b6IEt7DNpUvnxb79dbbgMHlz3vvDzQw4pHVP3fR92WPzQ\naJNjfOKJ8WSnzapVwGmnqT/z5enUyR01KgiRdy035LHH4suuALwas0KIw4UQXwkhJgghSh7JCCG2\nEkK8LYT4TAgxWghxhE99CCGEEFKB3HNPMDmfOzdrTdyQRZhxXpgwIShNBAB7712+fE4xUcfIxAhp\n3hw49VTz8dq1A4YNM+8fGvZJDKLzz69vuKpQGbuF5YwKPbA9etS9HzsWOO+8eHpVUzirzsu5apXa\n629KnPNT5Vm32T5kk01K2xYsAO6910x+heLNmBVCNABwF4DOANoAOFEI0aao21UABkopOwDoBkAT\n+E8IIYSQmuW224LXQo8ZADz3HNCrl5kMKYPQz48+qt8+Zw5w7LHlM7nGYdmyYHJ7yy16nWzaTXC9\nBvGJJ4Iw0Th6PPRQafsFF9T/P0yqlCamiXVCdEmWfBJV7mfRIuDBB0vbZ8yoe19ozNpmW1adOxMm\nAM8+aycn6ZhA+gb0E0+o27Mof2MbZlz4/YfoyhZVET49s3sAmCClnCSlXAZgAIBjivpIAOuvfr8B\ngKK7FCGEEEKIhuOPB/r0Meu7YAHQvz9w6KH12++/H3j++dKarytWAFOmJNNv/vzgtbjEho4sPbOF\nE+fQcwoAp5wSL3T0nXeAqVOD9717A61bl44The2xkDK9BDm2WX1/+ql8LVobynltAXdrY8PQcVWW\naBuyOLfDcHYbdNEfF1+cTJcofBrs1eRN1+DTmN0CQOFdYOrqtkJ6AzhFCDEVwBAAZXKiE0IIIYQ4\nYuVK4JJL1J9dcAGw1VbxvJKm6Gql+qS4lqrKyOjSpf7/qjqWQgBff60fZ8GC+v+HyXZ0+1iuxqsJ\nSY+fqQd22bLAQDXV5bXXgH32sdMlal9M9nPWrPoPJWwoPCc239x8zDjEiSQw9TaGD1OKEcJ+f4YO\nNeuXNAw+Tv8az3Ls05hVfZvFR/VEAA9LKVsAOALAY0KIEp2EEGcIIYYLIYbPULnQCSGEEEKiUE3s\nikOOC3n11eB1zhw/+gDZTDaLPdAhhbq8/ba6z5FH1v//tdfsx9ftc+fOZtv7DEc1fXAxdSqw6abR\nfYr1ibsOU7W/Jvv66KPAgQfGGzMLbL7Xa65JJtMnccY0PXezCHWuAHwas1MBbFnwfwuUhhH/BcBA\nAJBSfgigIYCSwlVSyvuklB2llB2bN2/uSV1CCCGE5JJK9zAU659GAqhZs4A33nAnDwBeecW8r+13\nZpNkydWYLvA9pkq+6Zgff+xWFx0HHGDeV2fU2xzH8EFTEmy9mVmEAlf6dS8lfBqznwLYXgjRSgix\nNoIETy8W9fkOwMEAIIRojcCYpeuVEEIIyZpvvw2Mq88+SybnscfcTD7zziOPAK+/7kaWiwRQS5cG\nZVjihprGpdw6xbTLnrigUrJMZ7X2skmT8tsvXBi8dujgRp+k2B4rVai97zF1LFvmR26FsqYvwVLK\nFUKIcwC8BqABgAellF8IIfoAGC6lfBHA3wDcL4S4EEEI8mlS1vg3QgghhOSBl18OXvv3B+66K76c\nP/0peM3L7b3QMHGpU1izUiUzS2MozICaVjmgDTaIDof0lQAqSnYle9Xihhm7HjMpuvq64b7o9kn1\ncCTp/sdZ12qawMvlsdPpstde7saoArwZswAgpRyCILFTYds1Be/HArBcEU8IIYSQ3HHDDUFYq2nN\nxDi4mChmEV5oK8NkP23LxZTTwaWBtGpVNqVW8vLABMhmP10ZUnkJ1x4+HHj//fTG842ra8z//pdc\nlyrCZ5gxIYQQQmqFyy8H3nrLrK+UQLt2wDPP2I2R5gTUhWFQToZuf5YvV9eU/PbbuvfbbRdfrzTw\n9XAgykhO20DJ25i2Xu8JE9Sfl6tnGoc4v6cRI+z62+id9vcWxxvsIptxnh7weILGLCGEEFLLSBmE\nrT37rFn/JUuATz5JNuayZcDo0UEN07QxDbfN0iO7007qTLQ648NGdjE//xy8fvFFfNk21MDkGkBl\n7Of226vbVaVvfK91Vq3NtzXyjjjCbEyXhmVx+HQWSwoq4VzzCI1ZQgghxAXLltl7EtJmyBDgvffq\nt61aFZSo6drVTMbZZwO/+Q0weXJ8PeJOvnxOFJNMCF0khynW4Z13Sj832X+TyXjPnnXvw8Q8//yn\nXmYa6wDzKrfcmHnyzLqicePkMmzrM59zTvIxbUpFuTqGd9+dfMwaN0aTQmOWEEIIccHf/gZ07Ah8\n/XXWmujp0gXYb7/6bbYTqdBgnzvXjU55xcaAa9HCToaN7PHjy/exNTb79bPrH2eynac1s3kObS63\nvY8EUOW2X8OBefDrX9f/P4431Cc+1rHHhUZuImjMEkIIIS4YPjx4tfVI5J20J1qjRuVjEpeGDsOH\n1/cmqSbM7dq5GUslu9BQfu894NBD3YwFpH/e5G19oKku5ZL5DBgQT24cXBqcP/yQTJeoMfP8QCRv\nYcZ5+k14gsYsIYQQ4pJqnzyEkzUf+/nqq0D79sADD7iXrdK3sK1wEvrtt/pSIknHLBzrzTeBww8P\n3i9apB6zsE5s3InykiXANdeUtl96af3/hw61k+uyfI6LMbMI+Y3zWSHFNUOLt+/TJ57cKLIwuFx+\nbz7Xs9vKLi4dlLf9rAFozBJCCCE6evYEhg0z65tlLdG0kDLwnAL1E0YVrsMtNL5sCUO0P/88voy4\nFE4cr7qqfH8h7MN1VWOFFBuWKv74R2DkSPvx3n3XXA8X1NIkvBJCZPNOnjywOnTX9/vuS18XG2rg\nvkRjlhBCCLnnHuDRR0vb+/VTZ5WtJmwmUg89VPf+nnvq3heuwx1Sr7x8NFmsqzShcPwoXW66KVqO\nzURyxozyfb7/Hvj976P7qMI78xQ6aTrmV1/5keuSak0AVS6KoZgpU9yO5ZssIgqiZPgy5vMWeu8J\nGrOEEELIWWcBp56atRbZYjLB+/TT7HWohDHi6JB00jluXPC6557msrPwzJqOGWZZdjGuzwRQtrq4\nwLeBYhKZEDJ/fl20RhS1sh43KumbrewFC8z61YDBGgWNWUIIIaSWsZkImXosXY7pitmzzcfWraX1\nSdJjEuURz9Nklwmg8im3kKefNu87Zkzy8WwNy6VL/YyZN+/+nDnp6lKh0JglhBBCXJKnCbVPfO5n\ncVIcF2O1amXeN4nR3rNnkMypEsizZ1ZH3hJA1fqa2ZNOyloDPXk6ToDfcOIahsYsIYQQ4oI8hK/G\nIa5n1seY4TG89974sv/85+jPXX5PKln9+gF33ulujKREGVyrVvkd16bd13jVRt7W6a5c6Ua+D2wf\nfLg4tnHGTErUb60Gfhc0ZgkhhBCXJJ08vP9+urVqQ31tjbxyBikAnH12PJ2SUJikSsW8eXWZmE2+\nq8L9MZ24F8u1DW12TVLD0qXRW6mTa1vjx1dyLRdjusTFfvo6tlFU6nlISqAxSwghhOSJffcFDjoo\nWx2kBP7+9+Ry7r5bL1/VVlxTsxhXXtUTTjDv+9hjdaVtune3GycqGUwxeTZmw+RSNuNlkak6bQ90\n1L7ESWCVV3x/Z2l767PKou7LG1zj0JglhBBC8sbo0fX/X7ECuOaaIHNoyMKFwNVXA8uXJxtLNZH6\n/HPgxx/N+iahcFL52WfAzJnR/X2OrxunTx9g//2D9489Zif/wQeD1zlzgDZt6jy7xWuCi8d0Sd4m\nylkkgFqyJJnsOA9Rkv4uAXve5L1vAAAgAElEQVTjx+dSh7THdHGexFlf7dPTniePehVBY5YQQkjt\nIKU/L43PieSTTwLXXQdceWVd27XXBt7T0GCKi8rrZhJO6zqbcdSYYUKlFSvij2mqR1S7LRdfXPd+\n3LggxHnKlOAhhK8xVWSxftXXmFklgEo7FDaOx860/8SJdjJ8JvSKklGJ61crNXdCBUNjlhBCSO3w\n+98DDRpkrYWecp6lxYvr2sL3Ki+fDbvtZt43SZbfJEydGrzqDPe99waGDk1PnySMH59s+0mT7Pr7\nTACVp4l7Vt6tLAyupGNGlXyxlW16Drg0LE11jHOcfCaj8vV91rhnl8YsIYSQ2iFM/EOypUmT0jaT\nCZkuXPTDD4FTTy1t//RTvdziJFs332xvnMUx5pJOPCs9GVOlTryz8FjaUokhv1kYnFGGpU9qZSlB\nytCYJYQQQmz46qtgMvTKK+5l20xKovo++SRw5pl2YxeG8JqE/VWCIbTHHsDAgerPfJaliUMlhvxG\njRnnMxOijKI8Tep9hd9mleU37TF9rw326YG11cOXZzZvvwlP0JglhBBCbPjoo+BVZyQVTx6+/BJ4\n6aXAwPz++2RjqyZKqraTT05WqzUJNpM5k76Fx/P114FRo+z0+fpru/7FY6ZFDUw6AdTO2mBX8tMe\n01SPkCwMS5/f5+TJfmSH8itJboWwZtYKEEIIIVWBblLXunXd++23jzauXn/dftxzzwVOOgnYeGP7\nbXXkaS1kYXmfSZOA9u0rNxwwSnY1jZlF+G0WnrwsjNmodlOiSkblxVDOKulU0hwEtmP6XjNbA4Yu\nPbOEEEKIiriTgKjtynlmO3eON+aXX8bbLgmFZYJ8MmJEOuOkRRbGQhYGtA6fCZPyhM/wW5/4Cm3O\nW8ka3X5mcX4xAVQiaMwSQgghcTDJnjtypJuxyk1WktbRNB0vyaTJRd3NQpYuTS6jEo05l2NmsW44\nT/tvSpzkRVl4bCuVtI122+9txQqzcmVR+Ew6pZMxbVpy2RUAjVlCCCEkDrqJQuHEd5993Iz14ovR\nn7s2ZpOgOy5hrVgdtgZ0t25m+tSSJ89WbqWOqTLCo7yHSUNHV63y5z2MeqCQlwRQLuTalpTyyS23\n2B3bCy80l/3BB/rPfH1vYR6HYs47r/oefCigMUsIISQb+vQBWrTIWov69OpV995HmHEcvvkGGDIk\nepzC+rM6Tjst3vhz56rH1HHOOUFJnGLWcDzleP75+v+7LKtTTesgXch2iQtdPv/cTvb//pdsvGuv\ntRuv3GcmZBEePmRIvkJ+feny9tt2Ml5+2byv7uFE2g8gAP01QXV9rmBozBJCCMmGXr2SZ/d1TZ8+\n0V7OxYv1RqFq4lA8yYjjJVy4sPz2JuGijzxiPzYQZGG2ZezY0jbfHlKXk21fE/daMaCz8h76Ooa6\nDLdRY5aLRDDB1ktq+hvT9Xv4YXW7q+USOtJ+2KLb/+nT/Y3Zr19+HhTMm+dvvAygMUsIIYQUEjUh\nnDpV3b5qFfDuu8F7k4nJG28ATzxhr5st//hHUBc3KTrPr034pmvPbDGFdXLTIo6BXusJoHytPfSZ\nhRZQjxn1MM6nYaTD9PucM8dOhurhlCt0Dw+zSHT1wQf+wqx1meor8SFWzqAxSwghhKiwueHfeaed\n7MMOA045BXjtNbd6APU9qVdeCXTqVNpHCDsjd9111e3t26vbTevhuvTWujQeTI/5xInuxswCFwmg\nZs1KLsMFOq+ize/H9nx89VV/hsEPP9h7oF080Enb0LnoIvWYM2em791fuhR48MHkslVElT1isrBE\n0JglhBBSGdx9N/DFF9nqUDwxeP/94DUqDDGKww+3G1832V6+vM7j1b17/c90no84k7bi/Rk3znzb\nTTYpTQITFYp5/PHmsiuJtCe0viezqocIUSVOfOmzYoXfEidpGwVXXqke87XX9LpEeVyT4DuEWyV7\n2DDg22+TydY9aNGdm4U1rV0Tlc04i2iNKoLGLCGEkPwxfTrQqlX9+qlnnw38+tf+x7a50e+7b/IJ\nlw0ffaRO3nHyycCuuwbv8/qUf8EC4KGHzGU/91zyMYH8JUbKk3emUsfMYn90ofZpH8MffrDr72JM\nV7Jtx9RFDpiW5Yq6Nus8s77IKqt6lRmuKmjMEkIISZ9yyVEGDw6e2N96a/120xvzrFnAzTcnu5Gb\nrp2aN69++9lnAzfcELx3MYEplD1qFLDHHkH5m2JdRo9OPlYtUW3JmKLGy5M3OGloc9++duO62kdV\nVEgWXrWocNUs0OURIKWovrf58/2O5/M3kRNozBJCCEmfk0+ue+8js+Kf/wxcfDHw4Yf22yY1QMeO\nBS6/PHifZNIwfLh++6gJUB48szYT3KFD4+lSqfj8fn780W5MF2tmbUm6/7oyO74n6A0aqNt9HsMs\nwlKzMH7ysp8+0T2EeO89v7okTbhWAdCYJYQQYs/TTwMTJsTfvrCw/IwZ9T8bORJ45ZXgvY0n9p57\n6v4P147pMpz6WltWDhtDeffdgf797Sc6pv19hr1deaV530MP9adHOdJe1+l7TabqIccLL/gb8847\nS9dBl8NnKKwOF/Wsddm4fXvWbNoLy3i5HDMLY9bnuEKoE4Zl5bH0eT9SGbP0zBJCCHGClEFG27ff\nzloTe7p1A3beuX6blMCJJ9aVqAn58kugS5f6iYgKb6bFBkWHDsBLL9npc/LJwFlnAZ9/rpZZzDPP\n6D8LdTO94fv0IOhCh6tsMpIZvo6jz7V3towf789YGDcOOPLI0vYhQ/TbVKpXUeeZ9TmmSs777wOX\nXqruH7WeNglZrPd0dQzvu6+0bckS4Jpr0tdFJ8dnqHYW0RcpQ2OWEEKyYtWqoNboIYdkrYme9u0D\nD6GK4gn7vHnAgAGlk9tzzw0mt++8U9dmYyiaEHp3Q09sOPnSbX/DDfpsvg88ELwWTgxPOile2Yuk\nk6CJE/OVpCgL8qSLKb16qdt9rl9dvtze0+zr2H79dRA+meaYvsNS11vPn2wdqv2J8rSrKEyiF3fM\nrDyzLvjrX/OhR5T8tMOMK/GaGgGNWUIIyYpKuKGMGhWs3YzLihXZrIkMJ/W6p9KTJgF/+Yv6s5Ej\ng9ett65re+qpoC5rnhLpZEElZhaO41WqxARQl12ml5vFeTtwoPozF54i2/1xMebaa6vHyypLrSmt\nW9v1z1M247zg+zuOimRICtfMEkII8U7eJ0PF6Gr3qejXr+594YQlKsy4ENVnhSFZ330X9AmTwoRy\nZ88OXv/xD3NdVbqlgevx8j4xzBNZZBfNCwsXVpeBEuWV9mlAJ+2bhhwXVPp1MQkudMkiC7Xu3M/T\nsXUAjVlCCCF2NGtm3tfE8I0yZlXZWbfcEvj+++D9+++rtwu9q2+9VX58G3x4LcqVKUrTUyIE8Nln\n+UqMlDaLFlWmZxaw+95WrUo/E29Uuw06L6mtLjbkJeOu74ef1RZm7JMzz7Trn8V+0pglhJAKYOFC\n4MUXs9bCnjRuKFKWZgsGgKuvBlq2DN7PmQO8+mq0nLfeAn76Kd74IapEHOXQJYKaPt1elinhmtm0\niDIofIbIqupmAsG6Z18TWl3IW/hwIk2ESN9o9+0NVZFVmHGcz0xZc021XJ/7Wetr133+RrN4UOCC\ne+/NWgMCGrOEkGrgr38FjjkGGDMmvTFffjnIbpkkJDG8Uft80n7jjcAmmwCTJ9dv//vfgW+/Dd6f\ncAJwxBHRBuLBBwP77ptMl+eeq3tfOEmZNy9ecqVw20LiHMuePc37Jv2uXBmnNpM8XdmHl1+206P4\nHIqDbdi3b69X2l6o229Xt69YUX3Gkkr2ihXpr5nNIuTX53HNwjMb1U7M0F1vsvo+qwgas4SQymfi\nxODV51q3L78MMnSG9OoVTMoK2/JIWK91yhR9nzDbZblyIqq6smutBYwYod/G5Ebarl1dMqY33yzf\nHwi8h0BpHdmo8Z58Ut1euK43ikGD7D0IJvvv24tVCdx9t7p96lQ3x+Dnn0vbyoV3+0C3L/PnZ5Pl\nN+0xV660G1P3kEtnEPvcT124ZjWtO9aNyTBjN+QlKqPKjjeNWUJI5ZPGhbl1a2DHHd3KLKf34sXx\nMxHeeKPa+IxCiMA4XL7cfJsVK4A776zftnhx+dq5xfv+6KPBq2mZonAtrMlT7XD9rI0HVkXUPvk6\nB7PIxJuFcf39936PoepBza23+hkvijyFTvpOSOPCsNRFD9hO0H16g31mi7Xx5FWywenC4NKVgkqq\nhyt8e2DPPlvdnpfrjUdozBJCapOPPgK22AKYOzc7HcKbzIoVwIEH1rUPHRqsZ113XeDPfy7d7u67\n9esdAWDmzKBMx8EH103iTA2Uhg2BrbYy3oV6fPRR8Lp8OXDQQfb1DW2wmRh06BC8Jr2p6yb/Nrqo\nogfKfTdZhKbZ6FIJqI5X1EObLCbuqvZRo+xk2xg6WX2fNmPqDEWdjO++U/f1uWa2d+/ksm3H9Ele\nEl3Zst9++dDDlfxPPrGTrYtuoWeWEEJSIu6aybj06gVMm1ZngGXNsGF17y+8sG49a+ixLOTss4PQ\n3EJmzQJatQI+/7zuRrVoEfDBB+XHDvv36RO8V2UQLrf9zz8Dhx9ev93lg4JiwzjUOc2bcp7WklWy\nYWlDVvvoy/iJ+t5U18D27ZProdMF8JfNOGo/fXpJb7vNrr+LMX2NB6iNeVcPsmxDtdMmCz18er0b\nNbKTc911yccE1GMedVQ2Sfc84dWYFUIcLoT4SggxQQhRUs1bCHGrEGLk6r+vhRCaLBWEkKrm8ceD\ntZeTJmWtiT2HH163fjNk1SrghhtKkxMVo7rJLF5slsiqeJLzn/8ECXpuuKH8tjruvz/+tosXl7a5\nXKvXunWy7SuVLGoTZkXa3uY8eWEefxx49910dfF9bv3wg7kuttiWG0nbmHXFFluY97XNFq8qb6Rj\n1Srgllvs5NuQxflpqocrrrjCn+wodPtUPG+pYLwZs0KIBgDuAtAZQBsAJwoh2hT2kVJeKKVsL6Vs\nD+AOAM+VSiKEGHPddcCVV/qRPWgQcNxxfmQ//XTwGhU664ukN6+ZM4ETT6zfNngwcPnlwEUX2Y+t\nCiu2xXaf0gwfe+YZf2OVw0WYsQ/Z5bZNe0LnM5FaFLoJ7X//6288XZ1iFaefbi9f1aZqD6+BSVGd\no1msgY6KCLEZ08ZTFtXXZkydx1JVM9vV8dNlHFeh28+77rIb0yaEW5cvYOFCuzF16H4rWSynUOFC\nD1vPrAt+/FH/UKmKUBTqcsYeACZIKScBgBBiAIBjAIzV9D8RQC+P+hBS/VxzTfB6/fXuZf/+93b9\nJ04EmjcH1l/ffBufxkaSvraERuzHH0f3U+1v3LDnhx4KXgtrwSbdR9XkTYVusqhq69rVXYjswoXA\neecll+MCXyHIWXiDZs70G1JtM3GXsi7kPi7Tpql/C0IAr79uLqd//2R6ZIXLCAlTVGtXXY5puw7Q\nZkxdbesw47oJtvvook56gwbJZQBq3cOKAcV07epmTBtdfOIqzPjii81l+DbYfTkhcoTPMOMtABTW\ngpi6uq0EIcTWAFoBeMujPvlhxAjz8hPEH0uXAl26pFubtJbYbjvzuqRZPn2Ne7PUbTdvXt1Ernjt\n6VNPBfvq40lpeE0ZP17fZ/jwYHxTgzluIqhCfE5GZs5Uj/fhh/7G9LE/UTLz4plwicoj5PM8Kc62\nXTjmGpppUBZrZn3iwph1kc3dVeioT2N2yRJ1u6q8UxZkcU343//U7e+840Z+XpIU6caMKm2n4uab\nS9tWrQKOPjq5LrYUl6+rQnwas6pfm+6b6QZgkJRSGfMghDhDCDFcCDF8xowZzhTMjI4d1eUnpk0r\nv8YujwwbFlxcx43LWhM7PvkEGDIEOOusdMd95ZVog8MHF10U7GvafP65XX/Ti/fMmWpDRsV33wXn\nZ/GTb18TgsKELcX7E3p2xo5Vf65rsyFq+1dfDV7D2rPltjGtw5lV+RidDBdeDluqbV2rLlzVxX7q\nvKRpowtjdLWfWSQMstmf+fPt7kU2NbWjjGdfa2ajdLEZU+fhTHM5RhS+fysujpXPMX1iU5bOlt69\n1R7uFi3U/avB3kkJn8bsVABbFvzfAsA0Td9uAJ7SCZJS3iel7Cil7Ni8eXOHKnrm5puDi45pltYt\ntgB+/Ws/uvzrX4EuxU/E5841NwpWrgS6dy81WsO1PoXZWKMYOdIsw6pLPvvMn7fm3XfVayMPPlid\nifLII4EddjCTvXhxED6a9EJ/662BF7ocH38cRA6kje3NuXnz4C8k6viE+xOG4ZpsY4JO52++MZcR\nRwdVoqWkYyU9FnEmAD6NBZ8hlVmsR07ba1GN3mDdPuk8s77IyjOr4pxz/MnOWzKmtJNO2Y5na5yr\nyOJ368qY1ZH2b+Wrr/zJ1mUP1u2jrjRPXq4fOcLnmtlPAWwvhGgF4HsEButJxZ2EEDsC2AiAx7iw\njAjXLy5dCqxpeKij1pkk4eqrg9cVK+pffDbZJAhBMPlxjB4NPPxwYIx+9ll8XVzUfFywIKipdfHF\nZhfwXXfVj1nc9vPPQNOmQaKaE06o32/KlNLQy/33D16LM/295SBq/oorgL59g+/JxBhNyp57Bq+8\nWJbH5BjFmejoPvvqq7qMxVH4SlIUhe4BSFbnUaWdv+X0TXu9o06278nyyy/7kz19urpdtU+vv14X\nxZAEm+8tC0PEtgSXDZVszNqu6XbBX/9q3rdWPLN5evDjk0MPtevvKrS7ivD2SFJKuQLAOQBeAzAO\nwEAp5RdCiD5CiMKg8RMBDJCyFs7YHKKLpX/3XfsyKcVfYd++/lKrN2kCXHIJ8FxRAuwffwRee81M\nhu6GEHqeb721fvt99wFbb21fyNqEWbMCfYoTT4STjeLw82nTgDfecK9HyHrrmfedP98uPH7atPrn\nxMMPuwsLvf56vde/+DzUff9Tprh5EKGicMwFC4AePcy33Wkn4IILgt9VFIUTAF2Y0t//XrpNEnxP\nXHVy83LbiNLFZOLZtClwxx1udfKBz1BYIHhQaso0XaCXBlXUk27N7D332MnWYTNB9/1gIk+/FRde\nSJtjaLv/PmuN6rCJbmnc2J8eQDbGrC6PTF7OW5/YLi/My9rtHOE1vkZKOURKuYOUclsp5fWr266R\nUr5Y0Ke3lLKkBm1VkfTH+OGH6tDFmTP9FTzff39g223Vn5kaBRde6FYnFcVPUPfdN6j7aYOpN/y9\n94JXH2Eoo0cHr6Z13HbfHTjssGRjLl1a+jAgxHStJBBkK95gg/ptunqJI0cG4fSFDwq6d697X3xu\nLVsGzJ5trsvLLwP77FO/zfYpdps2QYh4OZI+He/XDxg40L3crJJm+EzIUsmY7ucll/jVw4Y8fW+6\n8Tp2dCPftpSNDVmsmXVh/PnGxXGZOrW0zVVUigtj1uex3X13dXsW3n3TqMNyqMpeff117dwnbBg8\n2I2cKlpOkvJikRqj3IliuvZt772Bbbap3zZjRrBm8Kqr7HRKcmHI4mklEBgzOqO9eGxd+vgodFnq\nimUnCa2OSxi+WayLrVdCxaWXAscfr1/rbJK86YUX1O26MK3f/S547dOnvGwgyPy38cZmfeMSHtsl\nS4JSLwsW1H327LPAWmupjfs4Ycbh0+coT0G1rYX0tT9xJq4+dfHpga42dN+dzfnpIiO4lEGUj6rd\nBpuHf1mRhTc4zmemfVVlclx5ZrO4Ntvgsw70lVf69cyqdNctobrppvSPefFcO4/k5TzMETRmsySJ\nVzVc/1NsTKxcGXinkpzs5Wpj2pJEl2nTAmPmH/9wp085dBOqL74IXpPsT7n1jsWyfWY9Dms36kJW\nymWuHDq0zji1HXPuXPXnxftvGjIeh+LveYcdSsO3rrgiWGdumpa/+DedJw9X1Jh50sVm+7zo7XMN\noE9DWUcW6659y9Zhew1TURyZEpKXtc4zZtityfSJq9+taWJNILhXLV1q3r9dO3W7Su/WrdV9bTI/\n26J7AK0rn2PD5pv7NWZVdec7ddL3b9PGTn5S1lor3fHi4OqhdBUZxTRmfRI3qYcJ4aRZtU71qKOA\nQYPU25n8CMIkQKa4eMoOBGVLiutfhtnfdB5AH/j8gesy3WbhMQt1ueuueNvrEqoAyffnssuAX/2q\ntP3QQ4P09sWo1jEvWxa9DilM8BJ+3yqDNfzM1JNcvJ41yTrKuMSZQPtcM+sLV14YF2O62Cbq4Wae\nQkRdkPfwNttjqzOsbNbMukIlW7fswydR57PNg3xdhJBqP3/6Sd332mvNxwP0obOqMVX3KQA46CC7\nMSsV39mMVcfX1/I6wO4hSVYwAVQJPrMZkzD06IMPkq9vLOa224LX4jI5oedPl6UwyU009EyahnfZ\njhWumajkSZovfEz+JkwIXnXJjrL8Hm68sbTtjTeCJ+xDh9Zv14Vcr7NOcj3CY/Dkk2b9Q8+ziVyX\nXpusb8CmywBcEuWx9OURizOmjWxbudV2rUzbyM3qIYxpGbsoimtFlxvTpt0FrmRfd515X10kTxZr\noOOWUMsaKe0i4VysmY06rqrj2LNn8jF1xFmqljam84xy5P2hogX0zKZBkvqmYWKgYmxqWQJuTtrb\nbw9edR45nzdMHzddVx7lNDDZ/+IHG+Uo3s80JnZJjq2qli8A7LWX2fZxvKSVYiwUe6tVeuctdNSX\nNzhvv19TfSrlXPN5PU/7GPgeTyX/k0+A++9PLvvII83HTPuhDxD9cMaXoef7vFLJsfX6uggF9snk\nyXbRWjpjduZMJ+ooM/67+P0UJ4okFQ2N2byjW7tRjuKLrs16EVt8GoVZhGOafh6Fbr2Mz/1Jurak\nVy83eiQhzjE3zUatS+AVx/N1xx1qeeEDHxPZOuKcIyYPMnx7+KotFFaHrQfV1zGopmReWeLzvLUJ\nhXU1ZufO5n11Yx5ySHI9KvlcsdFdVyJP9/vcbTd7fXyg0882okkXZmxzDLM4V2yrXpBcQ2M2DdL8\noaouUO+/H/15EtmAvUdQxZgx6va4BmeSY17uGJnI3nHH+OOnRfF+3nuv3fa2x3j27GwnOGFEwVVX\nJTcEzjsv2fa1sn416jOfBnQ1eZp1n/kO4bbRxRbd/mQRZuzz2KrKuPkOyQ+XjySR7aLOtu2Yupr3\nNviuuFDJBroptmtgdbWhdZEDLnBxnTBN6kgqAhqz1YbqYltYj83Hxfjtt6M/NxlTVdDeN1mVGlJx\nxRXZje2Do48ubTN5Ip3G+sBwvblruSqyWO+YtzF9Yjtunn9fUWHTedbbFVmFh/s8tja1cLOMQkoT\n3dIp28z9qmizLMLGK5VNN/UrX5WUUUf//v700HHffemNdffd6Y1Vo9CYzRIfF8Y773QvM0tsvKS2\na1F05WGyIMm6aqAu67PNZzbn3zPP2Omjkm27zts1cX5vLp/oF57Lrj1fhdEXcahEwzqrxEi+DOhK\nmSinnQPB93EZO9av/GLysl7Y95g6D3TSqJYodPszapQbOTZZdPO2dr+YPGVbtn2QsXKlHz184aL8\nF4mE2YyJOTYXZ9+hfioKPX8mIWu6Qt02+/nII+Z9AeC556I/j3vMWrTQf6YL4bZ5UNC1a/Tn1Yor\ng0tVf9bl8UuaUKUSQ5ujxk17nWoW17tw3Erkb3/LWoOAMWNKy8EB+XoYUqlj6siTLjqKM+bXEpXw\n/VSCjiRVaMymgY8fXh6f+hXuZ2Fd2MJ22ydqYdmVJHXFmjWLv205TjvNrv8dd0R/nmY9wOJzyMU5\n9fXX7tLGuybLG6BpOStXpL2vUUYlJx7JyNuDAhc8/HD6Y6ooXIJTi2RxbunWxrqI3HG1P5deqm6v\nNI9gHHi9rh3yaEfEhMZsXli40K7/m29Gf154Qcri4jR/vrrdNo39MccEr7aZaAvbZ82yG9M2EVIa\nJPkOzzxT3V7uQhbnQpc08VUa56pthEESwu0PPDCZHN+42M9KWL+a59Bm3QO7PK2ZzYsersjTOViJ\nScui0D3A062ZPeqo5GM2aZJchiuqyFAgCcnruVBF13OumU0DkxPG9TqSLJ4gmvxgyyWLssXHj7Fc\n6HBaEwNdlkBbJk92I6eYSrsQZrlWbdKk9MaMs5+VGlaZp/WHKpYtSxZVEqLLuOtzP1WZeHW6uMBk\naYhrfGcWTlt2nsbMgr339if7nHPs+s+b50cPV7zzTtYaVB/nn5+1BjULjdksKbzBuA53KpRdOEFI\nclNTrS2y1UXFkiXx5JrIzoJPP3UjZ6+93MiJSxrH9oEH/I+RBJcJoHzJ/vnn/E+cVPjyks6eXZqx\n2tWYtjL++Mfk42WBEMBLL6nbfeHq92Ab5aQij/cVH1Tbfvrcn0aN/MnOAl1pmmo7J9Lkt79Vt+fV\nM1tF0JitVkwuSEmTxsQZU4WuiHwSj0bak9ZC9tjDjTwXHh2fuEinf8YZpW2+vG3hDSXNG0uoc7Hu\nttmMzz1X379p0/Lbm3yWhCy8wTrPZO/eyeRGYfu9DRzoZlzdsfJ1LlfyGugNNjDvm/d9IXb4vMd+\n/rmd7EoliXOh1lGdf3/9a/p6mFJFRjaN2Woli9Bm1xODfv3cyrPFNmlPuf0fNy6+LoW48DyMGpW8\nNFHSMKVVq9STiUGDksnVoTMsfRt/qu/L1iiwKbkVR2df6z3nzwduvjmZbFe6uCALY65WDC5XYcY2\nS2yyOLZ5Cm2utnPr0Uft+g8fbt73P/+xk12ppH29zjO2JRNVv6c11lBf1zbZJJ5OpuicDVde6Xfc\njKAxmzZZrGXV3bAmTMh2/HJE1U5NKtuE776rez9nTnJ5NrpOmqTP+ti4cXJdLrkk2favvWbXf9Gi\n0rYVK0rbpAR+/FEtI+lENwsjT0pg+XJ1u6/JUdRxSvtJ7PXX+5MdVSbHJ1msX7XRxRVZPLXXhXJu\nuGG6evik2s6TPFFt0U8kW2znWjpjVsUppwAvv2yvkylbbKFuX3ttf2NmCI3ZNCg8wYcMyU4PgDe1\nuBx9tB/ZUgJ33VXa3r2ZevIAACAASURBVLlzaT/AzcOQt94CXn89mYzLLrPrf9NNycYD/Gai9YVu\nzAceAD74IP1xfXpoVDJ0D2RcoDMgfRt4aXu5hNCX7MpiMu4zVF2V0VZKoG1bf2PatPskizF1NcgJ\nIfbYGLPnn+83pHu33dTtVRRaXAhL86SNi0RPhR7DQnT1PW1O3iQhrNVgKKv2YdEis/qv5fb/9ttL\n2558Up0lUeXJBIArriivR8iMGcD06aXt//2vur/peRLne1YZNWkbIqtWAe3a6ctGqbDRxyZ8UJdh\nevJks4iEKLJav5qXMV1vYyLD5wRh/Hjg1VfVevgyZrOa8KQ9bhbGbJ4MZVV0TC1RDXMW4o81LU0k\n1fnUoIH6urbVVsCAAfH0SkKVnvP0zKbN2WfXvY+b5VdXOqbQm1coW5dgSUWScNq4E4MkExjXkxFV\njdnu3ePJKmT2bOC++0rbTcvmhMfoX/8yH3P77YGddzbvX4zvtaRZXFR1NQ5d0KBBaZtt+OmhhybX\nI6vJsu3v2Nc55Hv/XRiQffqY9/35Z/1nvvZ17Nj0x8yTkZfFmNVmQBNS6ey4o11/2wedPpcd6sat\nUs8sjdk8Y+NBAuon9Cn8URXWvipsHzYsllpa0rhhLl0aJC9Kim5d5vjxpW2mSSKi9j+LcMCkCZ5C\nir27cb5nlWcpL/g22m1wsTY7K/IU8usCG6PDVo9evZLrofvM9r6hQpe51ffxTtvQy5ORR2OWEL88\n/LBdfxcPaHUJoHT9SSxozKaB7QnrYp1ZXn8kNhcHVd+zzgLat6/7P85+Ll8ObLaZ/XbFHHFEchk6\nisPRs3iaHx7/TTdNLuuzz5LLyIK0Q2Gz+t1mYSzkfQ20Tn4W2Wh1qHTp0sWNbNX1d9Cg/N5bXJKX\nhyS+xySkGrnoInX7rrv6HbdZs9I23ZpZwK+To0o9sDpozPoiiUEalnBJsn41Tydy4Y00qVejOFV6\nuO0TT5jL1K1HnTULuOWW8jqEsl14G7P4nmzXxhYfS1cToyxCRFV8+qnfJ6d52U8d06a5rzkdkqf9\nBOz00X1veTJmVWOarO+Py1NP+ZNtG5LvgmpKoEXssS29QiqD9dZTt/ueb+27r92YaV8LevZMd7wU\noTHrizPPTC7jyCPt+k+blnxMnaFnQuEP809/Sq6LzQ/9lFOSj/fgg2b94jxZ93URrTZPXhb4DIHO\nysDxuU5XlQk7C0MkHDdN2VmENme1fEF1zRo3DnjxRXMZd99tN2baD350slXLTSqZarpeu+Tpp7PW\ngPhAN9+K8pL6IirMWHX9Pvxwf7ocdli+HF0OoTHri4ceKt8nvMEsWaKeIH7xhXo7k5MxbihTkhC1\nPE1mXepi8+MfONDduLWILpHQvHmVOyGzmaBnETprmz35t7/1p4vt9rbGT94Tl6kmN1kZsyovrG3C\nksKEh+WYPl2fbM/XMddd232WzNDti4uH0bZj1jqffJK1BiRNsjDkbMOMX3jBTr4uQaBqX6vUkAVo\nzKZDuRvJVVelo4cJtk+kly8v36dw/21+YHn94em8DVICd9zhZ8w0JiO6pFjF+Awz1vHAA27GtCXv\n6zpnzjTv69vDpSoxlacHXK7kpG3M6li2zM3DsyxCbVXoap76vA/k6fxUlVEjpNZo3tyf7Lx5ZlWs\nvbad/I02Km0bNEivSyF5nWPHgMZsWqxYESQvKiQ8kWxK55iS1k26cJ/SGNPFjy+pjBEjkuvgClfH\n/JVX3MixIS/egjxlM7Y9N1U3fttwdxf7OH06MGSIuezly/NjSHTtat43as2sixriKnTjXXutG/l/\n/7sbOUmJenjg61zJiyHvG1eZ7QnxzVpr+ZOdhfHmorQjAPTvb973oIPMHEd5mYM5oKwxK4RQFE8k\n1rz1FnDPPfXb4p5IV19dvk8oe+JEN2Med5y6vdBjFsr++OPyernCpffERRKgvIcx6rBZn53VBVD1\n/egSF+22m7lc3xl3Z8xwo4sL8rImsUcPN7JtdVcZL888k1yXRx91U+rM5vt56aXk4wF2ZYJ8EpVY\ny8cDXyBYvpA2VTSBJMQ5jRr5k52FMbvuum7G/ctfSttOOMFOhhBV5Y0txMQzO0EIcZMQoo13baqV\nLJKjhCFb332n/twmPBEABg8u32f27OC1eIJQuO/vvVe6XbdudrrYYFtXLAmVkuXXNMmXlEFdX91n\nSXGx3rFdO3Xf//0vmR5RqNa361i5EmhTw5dO3bHVhUH5HLPcZ6Z9Ve2q6xpxQ//+wDffZK2FO2rF\nG1zNNGmStQbVy/bbJ5fhOwHUzju7kZPUsNxyS71crpktYRcAXwPoL4T4SAhxhhBifc961QY+12SV\nK6Fw4YXJxyjmH/+w6//zz0H4dZL0+OWOoYsQD58XANsyOcVMnmy/jzfdZN73scfMdbHFhZwsso66\nSIDkez1m2tEEtrgYM05mYV9roF1dI2rZazdrlrp96NB09fBNkpJ7JB/U8u/UN67uDTbttnz+eXJd\nXKCT3UATUFvcf8oUt/pkSFljVko5X0p5v5RybwCXAOgF4AchxCNCiO28a0iSUXxhCDMkr1hhLsN2\nLZjpxWjWLH0Cqa+/Br780mwsXdZnFVmtHbK5oOlKgvzwQ2n7scf69T7rspemXWooq8mDr3GzCO2t\nNnxHvGTxQGDvvf3J9smnn/qTXQn7T2oLnpPmnHeeun3bbZPL3moru/5ZeSZ9Gde687BBA7Nlc7fe\nmmz8HGG0ZlYIcbQQYjCA2wDcDGAbAC8BUGT8ICWUu/AtWFD/f58/uHvvDV6ffdZ8G9tU4cVhVOH+\n2xjQO+5oFto8f74+C6aKOXPM+9qim1xHZXw29SxKqa6HavOE0JYoY6FS1wariPJ624bj54E8PRDw\nff6o5OhC4+PINx3T1bFVhcdXgidPVx6CkGqkisM1nbPJJur2iy/2O+4TT5S26a7TLVv60yOLcyXK\nM5uXeZdjTMKMxwM4BsBNUsoOUspbpJQ/SSkHAfiPX/WqhHITOp8Gie6HVGxguayr17lzadsnn/jJ\nUqdLXpKniXtUyQVVPWKbSbRP8hQKm8UNwWfxct+oju2SJUCfPmZ9feoRhYv1hOPGJZeho0onArnG\npPwbISSf+F6/quOkk0rbpFTnaxgxAjj9dDO5LVrY65L2/CWqHFCV3sPWNOizi5RygeoDKaUmfoB4\n4z+Wzw9ME+FMnAi0bWuvjwlS6jMw23hVATcTVdsLi2n/Rx6x10WFzph9/3038pPqkgVZGFzz5/sb\nMwtuvFHdnpfvGAA6dPAn2/b7zJOH2wU+9R41yp/s0aP9ySYkig02YFmjpPg0Zm1lSAkcckhp+8Yb\nAzvsYCajXz+7MfO2ZrZS719lMDFmVwghegJoC6Bh2Cil/LM3rYge3YLtZcvU7cWhHC5P5NtuM+t3\n3336z/bYw40uxej2c/RofakU3YXBNGxx0iT9Z0kvaC+/DDz3XDIZrqiUrM1JyZMutqjON10W6zx5\nZm0NFxv5xxyTXPbYseq+NtmzsyKOR8GUSy/1J5uQrNAZSzZLpmodW4PLhWyfXsn11lO3/+1v+jF9\nJ6QylZtFhF9KmDzWeAzApgB+C+C/AFoAqDKXhWdUax2BupOquBYsYO9FuOCC0jbb7MI6zjlH3W5a\nxPmrr9zoYcujj5a2HX20ul5XFC4yviVNJuOqNIVNWRnbNbO6BypR8k1ZssRf+GieLu4+15LqZPss\nFZKnY/vuu8ll6DLuVgLTpmWtASGVhe7aSGO2lC22ULf79syq8o5EGXNJDchOndTt7dvrx0ybqHqy\nebonO8TkbNpOSnk1gIVSykcAdAHwa79qVRlxwqQOPNCu/8cfl7ZdeaWdjCzKnPhEtR7VFaq6kq6e\neqlkuDI4fJaVWbzYTs7XX5vLtj2XbcjT+uo8eUl94tNod0W1hRkTQuzQhRjTmC1lTU2gpwuv5G9/\nq868u8YawHaKoio+r906I7wS7hdVnLjMxJgNsy/MEULsDGADAC29aVRLRJ38I0aoP3ORyvv559Wf\n7bRTMtlRY/pEdUx8T3RtPaW+UrD7ZNkyv+Puuac/2TbUyhPMajOgV6wAunb1p0u1ff+EEDfoQk1r\nGZ0xq0twauOZ7d1bHX2ou3evs4663ec1XedwWLUq/TDjKNlVel8zOZvuE0JsBOAqAC8CGAtAk0mE\nZIbpmi0pgQceUH9m6/2z+SGm/URowAC/8nUXBBf7mZe1pGedpW6vtouhLlvqjz/6G9O3YTl5snnf\nSvBuXnttaduECXYPlXQ1k22ptvOfEGJHu3ZZa5A/dGtgdUubfK6Z1YU8N2yYvmFpM6/eZx872XGS\nmfpcVpQhkQmghBBrAJgnpZwN4B0E9WUJCchz/cORI9Mf05U3WJVIwHY96hlnJNfDZbmmPJPVmm5f\nzJkD7L+/eX/dOWvj9bSVbUvv3m7k2ECjlRCigteGUtZeW92ueojYpk1gWJpiu+725JPV7S1bmuej\n6dvXrF9IVE4KUwP6rrvsxmzSRP8ZPbN1SClXAdBk/yGJiePde/LJZGO6fPpk6rnK6seT9x9tx47q\ndlXqd1uD6/777fWxwZf3OO/fmW/y5CV95hl/ulQyTKRECKlE9t3Xn2ydcdq8eWmbroZ706Z2Y+qW\nzLmY5x58sF3/YcPU7T49oRtsYL9Nlc6xTMKM3xBCXCyE2FIIsXH4512zSsb05P3kE3vZb79tv00h\nLk9k0wtGpfx4fK5rVcnWrYvOO1msga42snhqqktEVym/z7TRHZfTTktVDUKIZ1S1R6sR28SiNujW\nqV5xRWmb7v533XXqdl1/09qwJrKSoivbFuWZLcZWN9tQbSGAI4+026ZCMDFm/wygJ4Iw4xGr/4b7\nVKri6dLFrN9DD7kpF2GLzzqhKqLShPuCE3Q36Moyqb5PX+uFq5E87WeesjnniUrQkRCSHN9rYO+9\nN7mMLbdMLsPnPEznmdUZuXnhgAPcyNHdLzbZxF6W6TZxyhu1bWu/TQVQ9khIKVsp/ozWzgohDhdC\nfCWEmCCEuEzTp6sQYqwQ4gshRMIY2pzwn/+Y9ZPSPi5fxQcfmPd9803glVdK2z/6yG7MBQvUayFU\nKeuzmiynPe78+e6SzOQZn8dWSuDFF/3IzhN5SuNfqdmMCSEkC2yvay5yWOyxR3IZPlEtjwLsHnyn\nkZwp7QRQjRub6xL+b2qkRnlmVeeobYKpCiIyARQACCH+pGqXUj5aZrsGAO4CcCiAqQA+FUK8KKUc\nW9BnewCXA9hHSjlbCBHjEQaxOkF167169LAbU7fwfMgQOzmViupCoVunOm1avpNl5YnHHgseuFQ7\neTJmfaLbH10G6TxRbd8FIUSN7W9988396OGK5s2BGTNK23UGW48eQP/+ZrJ79lQnKooT8quiGnOs\n+DKUbY3Zhg2BpUv96JIxJub/7gV/+wHoDeBog+32ADBBSjlJSrkMwAAAxxT1OR3AXauzJUNKOd1Q\n7+qgGie0Ks+kq/389FN7ffLAHnv4XauSNj7Pz6lT/ckm6VPJ17JDD81aA0JIGuiuU7vvrq6H7qKs\nTJ6wCWE+91w72SovoxDBOuXddittV1EJeTRc3Ots93PvvfWfVfK9NwYmYcbnFvydDqADAE0O7nps\nAWBKwf9TV7cVsgOAHYQQ7wshPhJCaFKcVTG1cMJJ6eZiZBNm88479uuRayFEOO9UaQ00Y6rtelDJ\n+1OpCdoIIXborlO77AK89166urjA1ijMwivZpAnw4Yf+xtWhC+31mQDUlgceMOsXtf61ku+9MYix\nehiLAGxv0E91ZhQf3TVXy+oE4EQA/YUQG5YIEuIMIcRwIcTwGarQiUqlGk82mwuCq6dtKjm6zHJR\nXHJJcl1qBZ9rZmuBaozKIISQtDnllOQydHORU0+tDK9gMT7XpNoej003LW0bOdJOdiV8B1E62iRL\nBYD99kuuT6NGyWVUEGWNWSHES0KIF1f/vQzgKwAvGMieCqAwdqEFgOIFm1MBvCClXC6l/Ga17BJD\nWUp5n5Syo5SyY3NVzapKxdZjeZkyh1a+8FV/NG9U4z6Z4nPf6ZnNWgO3VNv+EEKy4dVXs9bAPaNG\nmfe1uZbqEghlYRSqQmHDhKPF+lTy/WLNsimI0mXtogDaJ55Q91Mlba1ATI7+vwverwDwrZTSZGHb\npwC2F0K0AvA9gG4ATirq8zwCj+zDQohmCMKOJxnIrh5UP17dBefGG/3q4gvfF1DbTMw2VPLF1Rcf\nfmjn+bZJzT+pRn7+ut9EtSVn4O+HEOIC1X2kRw9gyZLksm3nKDb9p0xRt59yShDG7ANbD+dOO/nR\nQ4dtSRmf2YxdyXZV4gfwM2fWzS2WLs2fIR4DkzPqOwAfSyn/K6V8H8AsIUTLchtJKVcAOAfAawDG\nARgopfxCCNFHCBEmkHpttbyxAN4G8H9Sylkx9oPkHZ8G7S23+JNNSjnccmn7smV+9KhkasXIq5X9\nJIS44YIL1O2qCffOO7sZM2otqeozm+taixbq9m23NZfhm/XWM+/rYi6nW6daK/eLVq3U7Vl4zish\nhNsAE2P2GQCFsX8rV7eVRUo5REq5g5RyWynl9avbrpFSvrj6vZRSXiSlbCOl/LWUcoDtDlQMNrW2\n8oRt8oNK2Cfih1q5EbmgVsKpeU4QUjv85jfJZbRsqW7XZcV1wRprAHfc4UaWKTrdo+qSJpWdl/mZ\nT0+4LWkkgNJ9lub3lPdzIiEmxuyaq0vrAABWvzfJZkzKUQlJYGwXolfbmtlK1j1tvvwyaw0IIYRk\nxZAhwI47JpOx9trA+++XtvuedJ9zTmmbrRFig0qGzivtQnaeiNJP9zDD99hJ53qqRFchpqWc6JmN\njYkxO6MgLBhCiGMAzPSnEqk6Bg4MbnLFVLKh2L171hrkj732yloDkjdqxQNNCAE23ji5h/Pww0uT\nBm2zjV1+EVt+9St1e4sW/ib7xx9f2vb993YybrpJ3X7MMep2X0Z4XBmqMOO+fYGDDnI/pm/OPz94\n3W670s8aNqz/f3guF5/TYTKmNPe3Eo6tASbG7JkArhBCfCeE+A7ApQD+6letGkHKyjboVKh+GIsX\np6+HLf37q9ur7fsh+aBWzqta2U9CqpFDDkl/TNV6wg02UPfVTcSLjaFy9Oypbteta3VxXVPVCP30\nUzsZuvwVffuq29u3t5OfBY0aAccdl954OsPa1sgLva9JjMMsEkDWijErpZwopdwTQBsAbaWUe0sp\nJ/hXjVQ977yjbv/ss3T1AIDTT09/TEKqHRqzhFQucSa6pr/5HXawl21Knz7q9pOKC2qsxjQM1DdC\nuLlm6rLTHnFEctkuCNc/myaA8pnNOE/4jGSq9TWzQoh/CCE2lFIukFLOF0JsJIT4exrKVRWqtRC2\ndWarDZ0Bueuu6eoRxV13Za0BqUZqxcirlf0kpFqZNi25jM02K21r1Mh8e10+Bt38SWec7ruv+ZhR\n+Jq3VcJ8MC+hyq5w5Zm12a7cfTHN42NbJimnmOxFZynlnPAfKeVsADl5vJNDttlG3T5unLrd5zoQ\nkpxwHQQhxB6umSWkcuneXW2I2qKqBW8zz1m8WL+u1QWu5lxNmuRDj7xTLglT8ecu7yOmCaDSMGaz\nWBu7/vrq9grHxJhtIIT4pVq1EKIRAEX1agIA+OYbu/4LFvjRgxCSX+ixJITknWOPdSNnq62CLMVJ\n2G474Isv6rdJqQ4p9h1SudFGpW3DhgEjRyaXbXNvqNT7iKtyOC7QHcMsPJY6I/eUU9yN4coDnTNM\nvq3HAbwphPiLEOIvAN4A8IhftWqEl14Chg7NWgtCSNpU6iTEllmzstaAkNpEZXDliTiT6DZt6v+/\nalWQMOrFF83H/OEH+3GL+fe/gX32qd+2ySb6yDxTXBoWLsLDVfgMM9Zl+c2izmz4vyqqwESeCU2b\nmvXr0cNOBxtqxZiVUv4LwN8BtEaQBOo/ALb2rFdtU8kT3TSz0BFCCCG1jC5Dbd7mET48QnESBkXV\nAzWlcWPgwguTyylmjTWAQYOAAw5ILstFeLgvdF7PNM5Z3XmoM6B/85tk8lWEY/3lL+r2Yhmqcj86\n1tEEzlaJ0arD1I/+I4BVAI4HcDAAzQJQ4oS83YRsqGTdCSGEkEqiTRvgk09K210YMy6zGfuYTLua\nb+Rloi8E0Lkz8NZbZv1d7b9NCHgaxyqL7yPN8NuddgpedVmni9liC3PZNToH1xqzQogdhBDXCCHG\nAbgTwBQAQkp5oJTyztQ0rEVcxscTQvIHEyMRQlxw7bXA7ruXtm+8sd9xZ85MLuOSS5Jt//jj6vY0\nypD4DIUtlnX55fq+Nl47AFi+vLTt4IOBXr3MZfTvbzdmMeU8s8XGdblj26FDMn1U+EwAdcUV6vZy\niaGOPjqeTjVAlGf2SwRe2KOklPtKKe8AsDIdtWqcsWOz1oAQ4pMafXpKCHFM0gy6cTH1KkVx443J\nth8/3q6/C4PTZ/iuTr8dd1S3S2m/plP1va2xBnD11eYyisNjbSmXXMnWoePiey0+Lj6N2bh1jS+7\nLN52QH6iDzwRdUYdjyC8+G0hxP1CiIMBVPfRIISQNKjyGwshJCVMS42kNa6r/iboIlzyoFscpk/X\nf3aEpiKmaRKhcpgegzjH6uOP6/9fzjO71lrqz/v2tR87pJyBXGygZ3lO+IgsqPIH6FpjVko5WEr5\nBwA7ARgG4EIAvxJC3C2EOCwl/QghpPqYODFrDQgh1YBugrveenZyVN6iqMlz0smxqqSOLbrstzqy\nSjplys8/62X9+c/AXXclH8OGhg3t+j/7rLp9jz3q/x+37M2668bbDgA22EDdHupiG9rsIjKBOMMk\nm/FCKeUTUsojAbQAMBJAAl83IYQQQkiNc+qpyWXoJt3bbmsnZ+uUi1R06ZJchq1hmRcPbByEADbc\nsH6bb2/boYfa9TetZlHOM2uacdglxTrFzXrt03uaZP8r+dw3wOrxiJTyZynlvVLKg3wpRAghhBBS\n9cRdO1eIjZcrz+Va4pCnbMbVZix06qQ+visdpM7JojSPrQFt65UOSVJbvVwCqCRU2/lZRExfPyGE\nEEIIiY2L5E26Sepee5W2PfqoG9lx8GGo2K6ZdRlmnIc1iC51MD02LsaMG2ac5PsLt/Wd6Gn27Hjy\nknDIIemPmTNozBJCCCGEVCK6SfUf/wg88ED9tuIw1UJsjJTzzwfWX9+8vy+yMCzzYMSmgc7gdPFA\nIAvPbIgQQSmiwv/zQjnPbK2cezGgMUsIIYQQUolEeSFbtvQzZt+++Zhw29br9mm4ZGEU/frX/mQL\nAZxxRmm7i+8362zTLmowH3igup0GZybQmCWEEEJINiStNVpt2B4Pm5DNLI0IH5P8qIRBqpqclZoY\nSnfsXGbUVR2Do44CHnzQ3Rgh5c5ZHw9KXH/HN9+sbl+6NLnsJLruuad7mRUAjVlCCCGEZIMu627H\njv7GHDrUn2wbVJNzlwZnrXiJVPv5z3+mO2YaxkKa36fP/Ym7ZtYVun3r3dtchq4Wrk8Kv/927dR9\nttlG3U5jlhhTKzcOQgghpFLJ8716jTXsMqnaTFKrbUJrW5pH57UipfgMI4+7ZtZFAqio9iR1bF3g\nM5txlUNjlhBCCCHZkIVhmRdjdqedStuEyM8xiTOpzsuxVaE63jo231zdnoXB8cEH6Y+ZhWfW57lj\nYsxmfe5ut11p2733qvsW6k3jl8asU7L+IRBCCCGVhOq+uWyZ3/tpXu7VZ55Z2panJEV5OU46dPrN\nnet/zOKxXayV1PHuu+oxfZKFYekT12P62IdydaALvxMasPWgMeuSvF/4CSGEkDyhum+utVby++kG\nG+g/s82C6wshgC22KG2zlVEJpDk/WrYsvbFCFi/2JzuL8zX8vnbbTd2ehHIhzKqEXi7x+ZtRZYC2\npVJ+0zmCxqxLaMwSQgghyUk6oTv0UP1neTFmXWC7ZvaJJ9Sf7bJLMtnlyGJ+dMkl6Y3VoIE/2arz\n9c47/Y0H1H33qvOimB139KuLC0zOZZu16jp8lktKQpUbyDRmCSGEEFJdxMlmu8MO5n07dbKXb4Lt\nmtmo8iwqOSedVOq17toVePxx8zHzhi6z8F57uZNZDp8Zeg8+uLRt++3r3v/73/7G1tG6dd37QkOp\nWbP4Mm2OuS5rrw4TY26jjexkqjj77OQydCQJM65yZxuNWZdU+clCCCGEOEV330x6P91wQ/sxTSeI\n7doBgweb63Laaea6/OpX6n7XXqtutykREu5f8ZidOgFNmuj7Vxou9NZ575OeO3Ho2jV41RmKm26q\nbk/iLS73+/u//1O3FxrZPtlyy7r3tmVyfCZP8vlQw+SauNVW/sbPMTRmXUJjlhBCCCmle3e7/j7v\np7aGSjEHHhhtLNtQPOYf/qAOIb3mGnOZ++9vp4NuQh9nYp6neVASQ2XlSnW7r4cvUYTfw2GH1bXp\n9u388+ve77uve13K7WeS42CzbWHfp5+ue6+rW63Dp2HbvLlbeSZcdVX6Y+YAGrOEEEII8cvGG6vb\nszB+khqzLrjrLnW7EMDppyeT3apV8KoLvy0mynNcifj0zIakea6EoeQm5WUKeewxYJ99/OhkMr6O\ntddWt8c1Zrfeuu697lzW6ditW7zxs4haMFnrb+ulrhJozLokT08kCSGEkLRZbz11e9oerajJZtIx\nXaxXC9et+pgU28p0kfimHGnOj3Th1DbozmPXvPVW+T6Fxt8hh5R+fvzxde8Lv/sttwTeey++bqbo\nzrc33lC3r7NO8jFtk7jpdDRJcBUX17/twn2+6CK7cVR97r47uU45gcasS2jMEkIIqWXytM5y2DB1\nu89sxjfcYNYvjsFl6nWx9eBVKj7Xr+rWm7p+KFNc+kbF5ptHj7fOOsBDDwXvmzaNp4cpuvI5Klq0\nqHu/ySZ173VJy2y+T5PjfeWV5fv4/E28/rq6vTB5lg2F162jj7bbVnW8bJcj5Bgas4QQQghxQ14e\n6m68MXDAAerPM/ngQQAAIABJREFUCifWhbjQ/ZxzzPrFmURPn+5PdjVSCcehUMfCNcqFRmmhUajb\npz/9Cbj/fuDSS93oZbM21uQ4f/KJXf9ymBi+v/1t+TFV7cVLIuKWHmrXTt1uk/G5cD9167ht2Wkn\nN3JyBI1Zl+TlJk4IIYTkCduanzb30/XXL23TTV579wbWXddOF1PZ119vHp4aZ0JvmnQqNIp0a2b3\n289+7DxjujY4icxiir9n1/M/231YYw2gR4/8rpls3Lh8H5tjaBJdUShPV/9VdZyPOKL+/0nKDbmk\ncJ9dnG+V8LDHEBqzLqExSwghhJSiKzlTfN+0NXptad3a3/rdc8/1I9eWcpNUF2sWdWSR7bcYF2tm\ny+1Hly7xZRdS+F3laQ6pO4dUOtqu2bSRreM3vzHvCwT1lcuRp+OvQhVunoS8768FNGYJIYQQAgwZ\nkrUGwO9+F7zaTLSee868b9eu6SeAisLHhNJnrUsdqsREvon7PQwdqm4vXENY7ntxdQ7o5IQJwrLC\nRWZfn8fo3/9OLkPXHjehkm90YcuExqxTqugpByGEkCrlwguz1qAOmxDR++8vbbvsMuDgg5ONaYut\nZ2m77cxluEBnzPpMfFUuBNrH/KjcukndMVaFpQPx10YW6nLvverPbc/RXr3MxjPhgguAG2+0Gz/u\n93X77ep2155ZXTi1rafbJLlUGnN721Bm2zXLKhhmTJTQmCWEEFKpZDG5sblv9uhR2maacCnumC5Y\na63SzMo+j3U5Y+GEE/yNrcNkzaQryh1bk+8/brh027bqdp03WKdro0Z2/aO49VZ34fvl9n/33dXt\naV1bNtvMrn9aeukyOIf4zkKtoopsFhqzLqmiE4MQQkiN4eIelnYIr8uEN6a6u5gA+0zU07+/uj3c\nvxNP9De2br/69fM3ZqdOdv1NMuHaGrNh+z772OliG6IbPojYYQe7cWyxOcdt9yGuZ1ZnKBdSWFLJ\npOxRWmHGefKC5kkXR9CYJYQQQmqJPCTp0eEieU850t5/KUtlH3qon7EAYNmyunEL8RlmHH5vurWz\nG23kb+xi2aEuSepopvVb+P/27jz+jun+H/jrLRFZZCGSIItE9kRESD6JRhWxJUIs1YQQSzUV65cW\nIYoS2hJKNZSipbWW0tRPwzdq6SakWrFX0JKvqmjpYl/O74+508985s65c87Mme1+Xs/H4/O4986d\ne865986dz3nP2Wy7xR51FPD++8CQIdmVybQsvrzGmG6zjd3+tr0BsvzOXfQWSCOuZbjiGMy6VIaK\nABERURJlumJvWllPUmbd/+qTT7ZPyyTdKH4LUp71hri8li2L3n744eZ5FDH5lI4ugE5zMaOIIDe8\nPe1s1CaTS8V9RrbBke79ZH28PPsssGaN/nmT80fUZxFc+9dE3PvUXWhydeFtv/3s9q+YEp11mgCD\nWSIiihLs/la0LIPWuXPrt5mujwq0lm3hQjfliaL7X73ttmavd9nFMG0A3Ui4W2Zcy6yu5evJJ92U\nJ8o++2SXto7uc9h//9b7tvW5pPW/4LFx6KHJ0rBlMmt5sFwDB9Y/P3u2XRom9026f9saNQoYOlT/\nvMnEVFE22MBunKtuDHRStscbW2aJiIiojSIq4QCw5Zbp03Bx4fWFF6K3R42NbFRJ1JUly8pXVJ5X\nXZV+zKxultyobsY+3XqZs2aZlaWRjTdu+zhpN+NDDklfljLRfRdbbBG/j2vBY+m66/LJs1On+H2C\nwVfU8R5MI02w6fpztk0vr3V+f/Wrxs+nyTvp599EDXCZBrMisqeIPC8ia0Sk7jKriBwuIutE5I+1\nv4ipCiukiQ4MIiJqoHt3u/1d/X8wmdQkD1HLzQD2Qajp0jwnnmiXrk2eADB/fvS+Rx0FbL+9Wbou\nJs3xfeMb5mmZigtmdWUqU6+ComU53jqv1jOTHgiDB7fejwv4bMfM6tIrYgK6pBNA2ewHAGPGNH5e\nV+6PPjLPox3LLJgVkQ4AlgKYDmAMgINEJOrbvFUptU3tTzMFX0UwmCWirDVbK0lVVfl8b1shD3a/\nTKJRpW/ixLaP166N3u/SS73bNJP6+Pr3b/tYtzbmFVdEr22bhzTjIs89N3p73DFbRDAb/i7yUIWx\nsVmyHacaLGNUUKabaClpF96q8N+TbvZwG7rjrVu35K895pjGr2ui7yTLltkWAGuUUi8ppT4EcAsA\nB/1miIiI2qkiguhFi7JLe5NN2j5+4w3vNsv3GWx1AoA99vBuw5W7BQuit9tWArfeun5blhXJrl2j\ntyftZpxlMHvxxdHbH344uzxNji3bz0rXUyGO7fI1rtnmExUI67rK6/LJc8xsnKQTQAXNnJk+H10e\nusnXTGZqjhrrbJJnBWUZzPYH8Grg8dratrADRGS1iNwuIjGffMk10YFBRCVVxHlmxoz88yy7Kl/V\ntq1A69YO9YPAJLbdFnj5ZaBvX7MymD6fhN86mNU6s3vtpQ8wP/MZu7RM6FrebFpmg2Mid9klfZl0\ndBPjfPazrfddB7ZZtMxmufRQlnSt+EFF/CaDbL4LF92M83htmK7c4d+yP/7eZJ3qoi+U5CjLYDbq\n0wp/Wz8HMFgptTWAFQCuj0xIZL6IrBKRVevWrXNcTIcYzBJRM+rTp+gSkEuu/ld17pz8tR071reQ\nAq0VrTwrXLaV9dGj7fNoaYlOU1cpNXn/usnAdMGsTWtjcMKa4cOj9/nRj+LTGTXKPE+dYGD79a9H\n72Mz3vTjj6O3634Xm29unrYt3ffsj43/2c+yyxswmzU86W/RpJux6zGzJubNiy+LiZ//3Ju93cX/\nx003TZ9GWBMGrTpZBrNrAQRbWgcAeC24g1Lq70qpD2oPvw8gcmYLpdTVSqmJSqmJfcpcqWIwS0Tk\nxlElmg/wiCPSp+Hq/4NNBcU22HzvPbv906hSRStc1iQzWWfxfnWzJ5sEDi5stln8PkuWuM07OBmX\nyXqpUUwm1QmWN3jBwfVnqPuuBg3y8ipq1vQgF8duXt2MTdannj4deOQRb+3VqK64pvm1tAA//rGb\ntXLTXLTQdUWu0jk2pSyD2ccADBeRISLSCcAcAG1W5BaR4JlwHwDPZlgeIiIie1GTbjXjxctG6zFG\nKWJJjiwqaM1W6UvaMptmbVXbLuouPBuoMtp8h7bBbNCAAeb5lJk/DtrkO7f9fUQFlHldYNlpJ7P9\nJk8GfvrT6PHg4TKFl7jKQr9+yV97wAHebZOvJdtIZsGsUupjAMcBuBdekHqbUuppETlXRPxLTSeI\nyNMi8gSAEwAcnlV5ctGMlRsiIqpXVACUdBKfIFdru6ZZwkI3W69ftqzGr1ZFFmP5XAezacqSVLCM\nwZZhm3y22souz+BkO1Ontt4Pdx1Poqjjd9kyb8y7yW/etoz+d6R73fjxrfeD30VZ69DXR46ALA//\ncw4H3c16boyQ6TqzSql7lFIjlFJDlVLn17adpZRaVrt/ulJqrFJqvFJqZ6XUc1mWJ3Nl/SESUfMo\n4jzDc1t5fPih+b5l/t6SdhEtooKWdjbjvOnKN2JEPvmk3TdrUWO1Af34zTPPjN7ut4CXZRIhGzNm\nAMuX268RG0U3uZkujbPOar3/la/Ev9bELrvox5DbCr/f8IzrZdOxI3DVVcBvf1t0SQqTaTBLRETU\nlIoKFE26SGbtg9pUF2kq4nHrqJqmncf3UKauzcHAyjbtQYPM88lyjHeaNXRtzZ2b7HXB96+bcdlv\n1Vy2LPp5nVdeSVamsjrttPh9gsdBsGtvsEt8mjGz998PvPhi/H7Nav58/TCRgw/OtywFYDDrUpmv\nghMRUXFc/X+YNs1NOmFbbGHesuFXRosYM5uFMpXF53pZDZPjJsvPwfWstTvv3Pax7nO54QbzNIMz\nyurGA0fd797dPA8gfv3PouiWF4o75sLBfrdu3m0wUC1Ty3x74X/muvG4ZTzvJcRg1qUmOjCIqKTa\nSzfjIvJM2oqTp5kzzfe1+Qz//Gd9C5SLWUZNxY2ZLUM347L/r4/6jE46Kf51ea7RmZbp+G6bmWZ7\n947fx2TSq6q64ILo7bbv8+c/BxYv9i6Q2Sj77ypvJrOFN+J/b+3gc22/U18REREF6bo/lqnS6qJi\nUobKjavZjG2+mwceSFaWqn3/UTO0ZiGLmXBd5p1X+mX4PbnQq1f09iSzGS9aZJ9G0Z+jq/xPPhn4\nwx/SpfG735ktM9SI7frZFcaWWZdMruoRERHFmT+/6BK0SjsBUtT+RSzNo1u2w3b5GL8MxxyTvCxx\nAWea9zlvXrLXue4KrFOmMcg6Jj0D2kvLl+t1ZssubVkvvhj45S/TpTFlSrrleoJ0x2cTHbcMZl3K\ncj01IqL2pOz/aLOsnM2e7VWIys70M9hvv/ptSVtDszguOnVq/Lyuq2rfvsnztOn+aiuqh0HWv6e8\nW4GqNsN01ejGCbtIT6fM5/zjjgPGjXOf7i23ADfd5D5dQH+xpQl/K+xmTEREBJSna2GfPuWqcKQd\nv3rFFeZ57bJL4+eL+FyWLAG23bYcZclSFmNmoyrUZQ5afLqxsUcemX9ZilCmscF55e+fe774xfrn\nLr88mzxnz84mXaD47y1HDGaJiKqkChVByo5NBcX0WOnfP1kZTMsSNVmPrmzDhjV+vogKWp8++efp\nejZjk2OB55ZWUcH3zJnA1Kmt25utm3GWv60qtMxusUXxZchCM76nEHYzJiKixqrwz/D009OnUYX3\nmcUEULazjrrw6af55xnljDPsX1Nki0fS79/kdT16pM/HRNZjZlta0qfnYnKrs85KX44yyOt4r8L5\nN40LLgBuvz2//JrtYksDDGaJiFzLcjycrSlTii5BPnQVri9/Obu0qfpMAvmiv/+0s5oCZhXaZpnE\n0vX8JXHfv+6z/frX3ZYja5Mnt953PWaWvAuuBxyQX37t6HsrUY2LiKjJ3Xxz+jRsr7IuW5Y+T1v/\n93/R27MKrHffPX0aLS3AOedkl+e0aeb7lqUSMn169PqkfvnSXLSpcmtBVmWP6sIKADfckE1+jWS5\n5myazy+v48amZbbKx3LQ4MHAd77j3W+PY2abzaGHev93Fi4suiSZYzBLROSarnIzY0a+5QDcVARc\nVWxtZoO0yfOCC+zKssMO9dtWrrTrbjthAnD88eb7/+xn5vsC2VbgZs0y22/OHOCSS/TPpyljlkvz\nuJ6kxyTPMWPS57P55tHbqxAsxZUxuCxSVZfm0c0KW4XvJ40igsm77269HzXmnuL16gWsWGE/J0IF\nMZglIspLlpWeLGdF1LnyyvzzjGJT2dp0U+Cee9LnaduVsVu39HnOm5e+BUwpYNddzV6fZSXWVTAb\nVcZrr02WdjNzde5JOubPxfEP6I/Jgw/2bl10yTbNs5kF3/Oll3q3WQeVwWN0r72A117zZkLP4jul\nproIw2CWiKhKdP+Ajj3Wbn8busqcbWtUGSqFo0cD3bunT2fUKDfvx2ZM7/XXN1UFpBSSTPSTx3Hs\nKnDwW+FdHTfBMX9Jx1Vm0c34wAO92y23TJ62ST7t0aRJ3m3cslmubbYZsGBBvnlSJTGYJSLKi67C\nFzUu0VaWla8iKnau8nQRiES9RpfOJ5/Yp5+VtLO6xn1WRXQz3ntvN+mU0ciRrfc33dRNmlku5aOj\nGzMf56qrzPd1vXRRWHscMwsAAwd6t0OHtm7r2hVYtQq44462++67r336jYYANNPnSLliMEtEVLQi\nZj+eODH/PLPSoYP+OReV20GDzPd19V2mLffKlebdqZPm5a8JG3b44fGvTVpx3W+/ZK/TCb73wYPj\n99E56KD0ZTn77LaP/bHdWSzH5Nqpp7be14399W2wQfT2CRPM88vq/Wy1lXn6Zehp4tqsWd44yxNO\naLt9u+2ADTdsu+2OO4APPzRP+4MPgO9/X/88g9l8NOFxy2CWiCgvZfpn/dnPmu+bVSupq3233tp8\nf5uucmPGAO+843V3K6sDDgBOPLF+e0sL0LNntnmffHLbx7/8pXc7alT8a/P+LRx3XHw50kyUsmhR\n8tf6wl2LXVQ649I45JDkaftder/9bX0gGszf76J84YXR+6Y5Jjbe2LsdPjx5GgDw29/qn9OVL+2x\nvPXWwNKl6dJwRcSbAdfkotx669nNHdCpU326Lmaip3aPwSwRUdGKuFJa9jxNK4hHHeWla9ot06Zr\nnIjXxa6IiZDClcRvfjN6v9tvb52gJW/hFvGdd/Zus/y8dN3GX3+98eu6dnWXp/++s16LM+43sHix\nu7SS2GIL4J//jL6YEpXvXnt5t5/5TPq8w5/3dtsBy5c3nn3bhB9smSxN46qb8RNPAMccky6NqurX\nD7joIu9+mS72NjP/olK/fsWWwyEGs0REVZJV60BV+TMqR02A9dxz6dJ2HaB89avm+4Zb6eJanD73\nOfvyxEn6/k1e5/p41c2W66/daptfoy6vaQJjl/zgsJGsx8z26GGexxFHAH//u9cSmSZP3b577AF0\n7myeRhSbALUZx8wWwR/yElxnmbJz1lnAP/4B9O1bdEmcYTBLRJSXqo5VKXMA7Qd9UZ/tyJH6ljyT\ntUhdf19RY3tNJ5eK+6yDE7a4ZvI9+7PJukwziu470aUXnjAqzO+eGhZcc7io322SfHXHQVG/1fB7\n0H3eUTbbDDjnHKfFiRUVoPqf6bRp6dJevRp48sl0aTSjnXYC/vY3YP/9iy5J+7DeesBGGxVdCqcY\nzBIR5aWIGYezHjdZduHKtP85jR6dPA1XvvQl4Pzzs0nbhR13NN937ly7tON+C65m8/XpvsPPf94u\nnTQTfH3hC8lfm1RRrYc77WT/mvB39Npr9ZNi6fZ1JSrdUaO8GZpNZ50/++z6yZIAYNy41gmmqK0m\naiWk/DGYJSIqWpZrNHbqlD5PVxVHF+/zV7/KLk9b4bTjJtUKv6errwZ69zbLK+9g5A9/aF2mw4Rt\n+eL2N83bVbdSU/fdlzyvqADHtfDnWqWusGUoo+7z2nxzfS+P8L7nnAP8+9+ZFI+I6jGYJSJyrQrr\nsroILF29zwsucJOOCVfrzAL173/bbaP3W7HCPk8d3bImtu/LpstkFmNgo8Y425blhz/Uj5X1HX20\n1yIaXDomjaJ/2+PHN943z3VWi+Bf5Eg7vvKxx6K3JxkzS0SFYjBLRO7ttlvRJSgnVn6iBSc7KqIr\npo7u+/Jn3zTdPzj+Mim/cu0vh5KWbhIeX/C9ZBHYuBgfN29e6/1G3exvvdW8BbwIullFo44n227R\ncbIKWv0Zi10vazVmDPD888CZZ5q/ZsSI+m26dbaTnKPLGvg3ozff9MbXEgUwmCUiyouu0lPVINe2\n3FH7h1tY9tij9f7ChfZlSlIGW37rqK7bYRY+/bR+W3A2W9sJPeIq4CYVdJNW4pEjzctkIuvlcIqw\ncqUXcJsyWcfXl7SbcUuL3f5h554LPPOMXVkbzSAdNGKE3djlxx4D/vIXs32TDL9gMJuf3r05vpbq\nMJglImoGRUwulTbPW2/11obUrekYNVlK2u7UfiuwTTq6oDWui2vWbrih9f4ZZyRPJ2lQGGxRD36e\nwfsrV5qnd9ll0dvTziKblm0r9e6726W/xRZ2PRIeeQR48UWzfeMCLt13r7tQYapDB/NJ1kaP9roP\n68b3p9WjBzBokNm+DGaJKofBLBG5197/udsGB4cfbr6vq8/2qKPcpBNFd+X86KPbPh4+vH5SHNet\nbeH04tZrtSnL175mt3+afOO+d9uJkHRl9bsf274Xm9m0dcdHmgmSynTOOeUUt+mF31vPnvXdzf0e\nDT16tN1ehdbrZ54BXnml6FJ4ipgYj4hSYTBLRM0h2D21aLbLrbhYhsS0Mv+XvwCvvqrP88orW+8v\nXZqsLFHrqQLejKBBjSqDZQhO4iqr4QBSt39WLThZVKajyhhsgdXJqlUtrAoBRBGzf591lneru6hR\nht9TFdh85n5r+tix2ZSFiIwwmCUici1uxtEiDRoEDBigr7R17dp63x+H6aqbsUlFMW4fVxMgFVG5\nTxPkxJU3TUtqVHfuYHpjxgAXXtg4veD43SKsv76bdG6/vfHzVZvlNq4sp52WTzmqwua7O/RQ4OOP\n3Z2TiCgRBrNE1BzKVIHMUtbL5OTJtsXy/feB/v2T5ZGn7t3zzzONSy+t3xYexxzXdTY4IU/Sz1x3\nHAQnkTK5CJOGzcRCtoYNyy7tOLrPNupCBpnT9UIhotwwmCWi5uAqmPvWt9ykY6OIgCuuS6zJvq7y\njPruorYlmZTGRdnTztrsItCK+jxMZvY1qWynnezHlu1v9ZvfdF+GV18FVq92n24jSde6TXNuay8X\n+VxjkE9UGQxmici9KrQS3nFH9HZdd8WZM83TDr//I46wW6LCZzsralbC72f2bO+2V69s800zi+0h\nh3i3usm18uwu6q+1meZ3EbU0T5CurFdckSy/PIOgQw/1bnWfT3A8rqtyDRgAjBtn/7o0x41tK57L\n76AK5+S83XorcPfd9dt//WvgwQdzLw4RJcNgloiK9/DD+ec5Y4bd/vvskzyv664Dnn3W7jVLlgD7\n7ps8zzgmLbO6fX7wA68SaLouJADMnWvXMivSdpKqF14wzwsAunTxbpNcRAiWAajvehoXZMQFnqb5\n6tjMXBwMoIIXapIEN48/7qbnQjjvvCaPMuF/12XoPuovt7TNNvH7xi29w2C23he+ED3We+pUbz1T\nIqoEgykKiYgs2VacpkzJP88i1mXVCQYvgwZ5Mw4DbWcWdp1nGl262E34c+SRwLXXAm+/3Xa7zWzG\ntuMNXbRqnXmmXVr+fmnzNu12bXLhIch0bVKdCRPsLmDolHnc94wZwHHHtX73Rdptt/SfCYNZImpy\nbJkloupJumRMGllVBvfcs+3juHF1rsphM2bWVYVaJzzZUFI77lifji49k9bT/faL3u56giNbSfMf\nODB9Gi6EPwebgCvrcq+/PnD55UC/fsnTaFTGLl2AxYuTp22bJ4NZImpyDGaJqBjBSXFsK6gu1mXV\nmT8/fRq69xOeaOeww4Bf/KLt/kkrnVm0TLue+Mmmm3ESDz1Un6eOLpjt2zd5/nHvY84cs3TSXlD4\n/vcbp2WbXiM2k1v5+4Z/B1WapMiky2/Qn/7U9vG77wKLFrkrj0/3fS5Z4o3Z99dE9WV5DiUiyhGD\nWSIqxg9+0HrfRSA2dapdGroKdLdu5nkedZT5voDdWEdbtp9h0nGdurFkl12mf02S8XxZt2J+8ond\n/i5st53ZfuHAA4jvZhwUPC5tg1nbz/2114B168z2/clPvNtBg+zyCCo68DVpsfXLuOOOwPDh2ZZH\nl7evXz9vzH743PPoo8CyZfmVi4goIwxmiagYLru9LV1qP8bNRQB91VV2adjmk0WXX59JMDdkiHc7\naVLjMgHAiBHeJE1Rs4P6Ew+FXxsV1IT3Of984Ec/is4zjbSTNDWS5jtSCth++8Zp2gR0Nt3Jk+jZ\nE9hkE7N9N97Yu7UNpIsOYJMqomuvaZ4DBwJ7751tWYiIcsBglojcUyrfCuiwYfUzzgLesiT/+ld2\n+UblmYSLbsa2rb66FuiglhbgqaeAr3yldVuj8g0bZj4x1FVXeYFQXJpnnNG6zI6Nrbf2btOMmdUp\nYnxiXJpZHIuuZR1Y563Zgm8iogpiMEtE2QtPcgSYzcT6wAPR202DhQULgO7dzfbVGTzYW5PWJkDJ\nskXGDwB9It6ENcHJj3SCE8+YLocydqxZ5TzNPsHPyx9X2aNHfHqNHHFE4+d1wazJ+yiixW3w4Ppt\nwbLqlpKxDazyeG9pujgzUGwsy8/HXw+YiKhEGMwSkWfAgOzS7tatfs1Upbwgcd99gY6aVcI+85ns\nymRa6bvhBmD//esr2rff7t3mOf7v4ouB73yn7baePb2lRMJprVgBPP98220mE8/ElclVZVkXuOy3\nnzdpjcl6prrZhoH4SacWLIhPvyyGDQN23rn1sc13oGuxjQscswiKmq1l1maW7qpTyjsXEhGVDINZ\nIvJ897vu0lKqviJ3zTXARRe13bb//sCdd9qlPXu2fmkPG7bdcsN5HnCAd3v55fZ5h5l2Mz75ZK/F\n0mRG1V69vHGsrvjjXseMsX+tzWzG663ndWvecMP4dMeNi89Tp3//+PSTpm1SdhuTJyd/ravuxy5V\nrWXW9lxR1eCciKiCSvhfjogK4boCFu5G3Ls38NWvpivTrFnAzTfXV3qLbAGJquimWd7FRPBz0S2x\nYfN9rl0bv88OO3i3thNtmQi2OtooW/Cz227ebZo1SoPmzfNuGwXtcWyD2csv9y5YpJmF17YFtuxr\noSYdqpDn+9lmG2DkyPoLhkRETS7TYFZE9hSR50VkjYgsbLDf50VEicjELMtDRAkkCcy6dGn7OKoS\nmyTI6NAhm+Ck0ZqL/ljEuIppx47A++8DDz5o3pLmr7eZZgIoP8hM4stfBo4/3mulbGkBrr02/vNN\nMzZTt4/JeF9bNsfJypVu0t59d+/24IPt0tPxg+Jwfi66Get+1zvtBDz9dLbLSDUL/2JDeIhGES2z\n3boBzz2X7dAMIqISyiyYFZEOAJYCmA5gDICDRKSuf5qIdAdwAgDL2gRRO3T88fnnadJqFxZcQ1bH\nZatF2srjzJnR2zt0iF4m5fHH67ftvLMXnH7uc+b5Ro0LzbO18Xvfax2Du3IlcOSRrd2Jsxa+gHDZ\nZcDq1XZpuJqYqqXFLt84p56qfy5q3OH8+Y3TS/Nb0b3/jTbybo8+OnnaeSlrt90ttvC+m1dfLbok\nRETtVpYtsy0A1iilXlJKfQjgFgCzIvY7D8CFAN7PsCxEzSE8+Y/vyivTp62rMCYJbsLdLINpN5q0\nJ65M/rqnusr9KaeYpx20665eK0u4Re2666K7QE6Y0Ho/LtA4+eTo7cOH189M3Mibb0Zvdz2pzqyo\n0zTcd5ncZ5+2j084wb47bVm7pTb67KNmhPXXX7VJB3Bz4aOIQFE35r2s3ycA9Olj/5oyvx8ioiaR\nZTDbH0AUfcfUAAAclUlEQVTwcuXa2rb/EpEJAAYqpe7OsBxEzc+mdWXq1OzKERSsJJ94Yut93czF\nJi64wLsNd530K40zZni348fbrS87ezZw/fXAjTe23R4MPJJWTE1aam2WrDF9bdIxjx07ei3Pa9bY\nvc62lTTrICoq/XfeSfa6rNkeWzbBn65beJZ0F6yqPJvxK6+YHT9ANYJzIqImkWUwG/Xf6b9ndhFZ\nD8C3AXwlNiGR+SKySkRWrVu3zmERm9DZZxddAiq73r2TT7iTVNJxXOFKrr82atwaqb16pV9fNir/\nJIYNs0s7WAFOUxlOM6PuhAnA0KHJX19WugsCtrKcLC3N9qix32kmckpqyy0bP59mNuOiAsTOnd0d\nP0RE5EyWwexaAAMDjwcAeC3wuDuArQA8KCJ/BjAFwLKoSaCUUlcrpSYqpSb2SdLVpz3JO0ih5hFV\nQb7/fv3+Dz4Yvd1vidRVOl0EAptsEp1mlhXdpOtyJlnKxjRPnR//OHmeWapCC5yJvAKq008HvvQl\nbx1hE2vWAG+91XbbqFHR+xYRFFa5ZZaIiEopy2D2MQDDRWSIiHQCMAfAMv9JpdQ/lVKbKKUGK6UG\nA3gEwD5KqVUZlqlY4RkPXTr6aG9sXq9e2eVRJsuWxe9DwEsvAUcc0XabTYWy0cURXffZ5csb5xNX\nidatoRrML66rdBaV4z33jN7uIijQzWb86ad2r/Vn0+3dO32ZbDV7QDJ7duv9ww5Ll9b99wMvvhi/\nX8+ewNVXezPVRgkfe9262f8PKFO36mbplstuxkREucksmFVKfQzgOAD3AngWwG1KqadF5FwR2afx\nqyvsvPP0z40YkV2+48cDF19cjgqlrtK/eHH6tBcs8CaK0c0+2yy23dZNOkOGeJMYhbucmh4nSY4n\n0yU9dGn/+tfR+0ybpk8rj+5/I0c2ft7Vb+9LX2q9r+tyHAxyJ02KL8vf/w784x9uypfmfeZ5fkrb\nqh3usut3u168uH7pKVu77BLfFbcRl59jngGXLsjze1zZTIhGRESEjNeZVUrdo5QaoZQaqpQ6v7bt\nLKVUXbOaUmqnpmiVPfNM/cyU4cllslCGYPauu6K3L1qUPu3Jk70lPETix02aCE5GNGyYvkte3r72\ntaJLkD1dJTrYCmVa0S7j2or33gucdJLdazp3Bnr0aH2sa5n95BPv9rbbvOV0wsKf28Ybty7FUoQi\nzktJJxrzx5immajMVpYXOnXrzJbhf4Xv9NO9ZaIOOcT8NQx8iYgIGQez7ZaukqALcpuNi0rS9tsD\no0enT0fniiuAKVPaXmDo06e19S28tIwvywrgZptll3YwuMlr3FqafN54A3j9dX1FPOjee4vt1qfL\nc/fdgUsuSZdGXDA7ZkzxQYluHoP77mvbygzkW9a0eeV5LPnd+QcNsntdmtmMy9QFtlMn4MtfNgu8\nG5X75JOBW25xW7YkqtzNeN0679xLRFQRDGbL7KijzPd1VUl86CE36bgwdmx2aS9YAPzud/FdR/NU\n5ORFQLJj6JZbgCVLop/TrU9rUpY+fbwLCiZl8seJBule5y/dkwUXv8FwGrrP6uOPvVtdoJJF0Oi3\nAId7L/hrw4bz3G03b/hD1bj+7FascJ+3yzJW6QJDnIsvbju2uShFX2BKY5NN9BdziYhKiMFsFly1\nfEV1H0yad57KUAafzWdoevU/LLwckv/aNLPYuv4MswqUZ8/WL+HyjW94txPrJijP3/77e7dJflOu\nRU1e5X8/psGsP8nPBhu4K1ecQw/1yhPuQTBvnndr0kXf1XG9995u0slDo7HeSfnrNld1qZgqtlgS\nEVEpMZgtM13LVhkFxzm6qrCecw6w1VZtt9mmfe21dvsnKfs559Rve+YZ4De/sU8rK8Huqi6+Hz9Q\nbcRvlUs6+VQWylCJjjom/e8n/NkExxAGy37nncDll3sTfBXtsMO8svXvX/+cH7i7nrCtDBdIwlav\nzi+vc87xPvM8L2a4UKYLnXkow/mGiKjJMZjNQnicWJw5c6K3b7cd8K1vmaXRDJWE4Cy4Il434yef\n1O/vuqLg8jMcPdp+iYwsKz7+GEvAe59R79Xm/S9c2HrfZFyrCyYVd5O1bW+4wZtN1hUX35s/2dDk\nyW23b7pp63jKYJfizTc3X3u0SNts43WJnj696JK4o/u+o4L5Mtt+e++2iO+m2YM8f36MrbcuthxE\nRO0Ag9ksnH++3f433xy9XQQ49dT05bGRxbg/U0VMkBWuVPlLbujGIgb95S/An/5kn2dwyY+8ZuEN\nBrNnnBG9T6PZW9esAV5+Ofq5YDAbHIPsei3JE04w37dRd91DD/XW+XQtzW+nSxfg0Ue9Ftewu+7y\nnjNd8qhsgr+lKl9005XdRetoEcHdttsCH3yQ7zJntt9/o4tu4R4fZTJihLfE2OWXF10SIqKmx2A2\nC1WusBVJt45mni6/3FtCaK+94vcdNKh1GQ8bwffZowfwP//j3e/du3V7lmNmt9uu/vnBgxu3Vg4d\n6u0TJVjWLLtWuwjmyvzbnDSp7bI8vh49oteSpeZv4cuai+XNkkjzvfXqBVx4IfDAA+7Kk4WpU6t7\nAYqIqEIYzOapUUX6scfs0vrc58zTBsy7JNp2jQWAxYvry9K9u306JoLv03Ur8nrreQHl4sX5dZ0V\n8bqSL1/uLRUUVS7ff/6TPB9//LWfbjj9c89N/p6DrzMJyMscUFbdokXepEBlDX5dffd5HEO2PQvS\nlIm/CTunnJLsQiIRETUdBrNlMXGi3cyUWY1zGjcOuOceu9f4LYs+EW+d0HffdVMmXSAeValMk6dJ\nd8g0LQp33x2dT6dOwB57xL8+zcylN9zg3foBs65L8SOPAJdeapd2XoG/ibjvJ4uWPNs0Bw3yWmwu\nuMB9WXbcEXjnneZf0zrLFlkXXWFtsYW5MQb7RESkUaJaaDtx113eOm5Rshiv2revfRouAuXOnVvH\nn8bxF7kPVuiC920+F9M8bfJxNWPoHnt44z6/971kr09zfAwY0DaNa69tXd4jaPLk6O2N+MFseGmW\nIivoRVR+TfPs0gV47z3ggAOyLU8Z5fG9rFgBLF2aXfrh96B7T/5vLk3azaaICwVERNTUGMzmbdYs\nbwKapEaO9GZLDrdW6v7pv/QS8Pbb6SoFceOqwi1ztnlFBfe6wFbnpz8FrrnGLt9Ggnn+6EdegNe9\ne7rPsWNH4LLL2k4AlaVg61y43Jtvbt8Cq+OPpfXXGy2zLCrHfpdemwmqKJ1G3+O0acAxx5ils3Qp\n8P/+XzZlev554K237NJoLy20tu+zvXwuRERkrcH0peSci4p0r17A1Veb79+1q5evbWXgiSda1wmd\nPNkLfm69te0+F17oLUHTpUt+lQ3dZ7jffo1f16kT8OGHydJef30v8Lv0Uvddal2MK502LXr7E0/Y\nlyeJ4cOBV1/1jpGg9tKq0rcvK9umXB0Ttp93v37A3/5Wvz0q6PXH+8+YYZa37j117ZpuaIBLl1xS\n33OiCGyZJSIix9gyWwTbAKalxX1eF1wA/Oxn+td16xafdt++bpZ18Lvjffaz6dOK8otfeK0kUWwr\nS66DFhettCtWRG836eYYdxHA1IAB5Rg7y6CSorzwgjeO30SPHsArrwBXXNF2ex6BVVZ5nHRSudb6\nZcssERE5UoLaJ8W6447W+3EzaZoGyqefDuyzj/nSDHGVrDSVsJEjvcrmWWe1bgu+zy98IV0+e+6p\nX1bGpJKUZUWqUVff5cu9SqgN3ZhhP2jeYYe2200uWrh2+OHe7eTJ2eWRxQRegPd9LF+eLo32rKjZ\njLt3B/r0Md9/4MDWGcBdl6U98z8r098hP1siIorBYDYrZ55p/5pdd02fr0klIRjY7bZb+jxdGDas\nbcUl+D50LbZVulp/7LH127bbDthww+j9RbwJoy65xDyPO+4Annoq+rmhQ4HnngPOP988vaxMn+59\nd7oLDGV2ySVmM09Ttvz1eKPW5c3K2LHe7ejR0c9zVuN4tp9ReOgCERFRCMfMZuW884C5c/UVnyg3\n3RQ9xirpzL46L7/cev+229y0zplWwl56CTjoIGDlysb7lXU22iTjjwHgu9+123/cOPs89t+/8fMj\nR9qn2WzY0tMcjjnG+x1GXSTKypw53vncn0vAx2NKLzyMwe8JFFyPupFf/Qp4+GHzVnIiImp32DKb\np7iuwCbLygQDqbvuAiZMMEvbF25V0k1QYjrJia0hQ4D7749+LpiHPwlLo31cMAlMdS3GUWyW8dG9\nl2uu8dYizUOztQS5ej9PPeVVpMktV7/f9df31rfOO8gJB7KuNVNgrJQ3y3zQ8OHeWOSf/MQsjUGD\ngEMOcV82IiJqGgxms5R1xWTWrNbKlemYVtNJQGyDPBuuxmneeaebdOLYBEjvv59dOXwLFwKLFumf\nP/BAt8sUldmcOdHb0/72xo6tH19MFMXleb7ZLi5FWbDAm12aiIjIAXYzLoLLmRxPPdXrhuViVuEk\n+ftcB+7h9ObMAW65pe02F+9ZV+6ZMxsvgZTXsjdRvvEN7/bGG4HXXqt//rbbzNPK8oKLv35wki7T\nJj75pLlasoiIiIjICltmq270aODFF+tn6hw5su26qltu6d2aLNcC6Lu56paScdGiUHSrRDAw2ntv\n/TqTALDVVtmXJ86aNcC77xZdCr1x47yuukuWZJP+eusxmKXi2c7Qa5IWERERGWEwmyXb9WQB4IMP\n6rfZVJKCY2eD48mOPx649974SYJ8G2wAPPRQ2zRNvPmm+b6NxC1B5Eqjz9b/rGwm8cpThw7eX5nt\nsIP58k8uFH1BhIiIiIhyw2A2S0kmUcqq4r/eesDuu7sNBqPS6tzZXfpFO/JI4F//AkaNqn/O9HOc\nPBlYvNhs3+OO877/8Ljm9Ur0M33hBeCZZ4ouRTy2cFGVbLyxdxtcU5uIiIhiccxss/Er8R0dfrU2\nrV1pWsZcByDhsaOPPgq0tJivrSuin1XZ1COPmO87YUJ0y/zjjwPLl6crhyvDhhVdgsY22si7HTKk\n2HJQ++Gim3HPnsDbb6c/3xAREbUzJWryIS2bStLIkd6kUHfdZf6aK66I3h4VXLruxhmcMbbRerpJ\n8j3wwLaPJ03yKox33x2dT1lb88aPB047rehSVENLi3fsf/vbbbdPm+bdjhiRf5moubkaM9uzZ7l6\nYRAREVUAW2azlGTMrIs8v/Utu9csWAAcc0z99kbBZaP8baxYEb09TcXw4IO9SbGi9OyZLp8RI4A/\n/cl7XfC9Pv008N57dmlRW5tuCrz+ev32W29tO5lZnFmz6rctWADstx+w2WZtt//ud/p1j4lMlPUi\nGBERUTvAYDZPSSs9eUxqc//9Zl0zDzoIuPRS776LStwGG6RPI+zGG92n6XvoIeD3v69vQRkzxjyN\n4cO921NOcVeupPzZqcNB/vnnN17LNgurVgFPPVW/3cU4QpH6QBYApkzx/oiIiIiochjMVkFwUqid\ndsomj112qd8WFaxOnAjMnZttwBjFD+iLbgXZdFNgr73SpdGrV3lm3T3vPGDsWG8poqAzzvD+8tS/\nv/dHVEVl+U0TERG1IxygkyVd4HXqqXbp9O8P3HSTN5nQ+eenL1cSLS3erb9ebdiee3q34YmndGPA\n7rsv2ay4roPZ4OzLRQfKRejcGTj88Pb53olc4G+HiIioMAxmi9Cnj/1rDjrIW+bF5SzFNk44wQs+\nt98+ugXixhu9carhbsPr1kWnt9tuduu39u7t3Xbt2nZ7+LGt0aNbl8754hfTpUVEZmwv6FUBW2aJ\niIhyx27GRenQAfjkk6JL0dikSV7QuWSJ1/oQDj6DLRKdO0e32vrrJ6Z10UXeuNSZM9tuX73aG8Oa\nxqJF+Y8PJWqvmi3oY8ssERFRYRjMZqlfv9b7b7zR9rm//hXo2zff8tjq3NnrDhx2zjleK2w4sMxS\nt27AccfVbx861PsjIipSswXpREREFcBuxlnq0QN45RXgyivruxYn6WpcFsOHe+N3wzPgphVMb/x4\nt2kTEWXh2GO92w03LLYcRERE7ZCoil1Nnjhxolq1alXRxXBj7Vpv/cxw91wRYPp04J57iimXa343\nPJNj7bHHgHfeAaZOBdZfP9tyERGlpZT3p5vsjoiIiKyJyO+VUhPj9mM34yINGBC9/aOP2m/FaNKk\noktARGROhONmiYiICsJgtoyKmrGYiIiIiIioItpp8x8RERERERFVGYNZIiIiIiIiqhwGs0RERERE\nRFQ5HJxJ2bvtNuC994ouBRERERERNREGs5S9Aw8sugRERERERNRk2M2YiIiIiIiIKofBLBERERER\nEVUOg1kiIiIiIiKqnEyDWRHZU0SeF5E1IrIw4vmjReRJEfmjiPxaRMZkWR4iIiIiIiJqDpkFsyLS\nAcBSANMBjAFwUESwepNSapxSahsAFwK4JKvyEBERERERUfPIsmW2BcAapdRLSqkPAdwCYFZwB6XU\nvwIPuwFQGZaHiIiIiIiImkSWS/P0B/Bq4PFaAJPDO4nIsQBOBtAJwC4ZloeIiIiIiIiaRJYtsxKx\nra7lVSm1VCk1FMBpAM6MTEhkvoisEpFV69atc1xMIiIiIiIiqposg9m1AAYGHg8A8FqD/W8BsG/U\nE0qpq5VSE5VSE/v06eOwiERERERERFRFWQazjwEYLiJDRKQTgDkAlgV3EJHhgYd7AXghw/IQERER\nERFRk8hszKxS6mMROQ7AvQA6ALhOKfW0iJwLYJVSahmA40RkVwAfAXgLwGFZlYeIiIiIiIiaR5YT\nQEEpdQ+Ae0LbzgrcPzHL/ImIiIiIiKg5ZdnNmIiIiIiIiCgTolS1lnYVkXUA/lJ0OWJsAuDNogtB\npcXjgxrh8UFxeIxQIzw+KA6PEWqkLMfHFkqp2Jl/KxfMVoGIrFJKTSy6HFROPD6oER4fFIfHCDXC\n44Pi8BihRqp2fLCbMREREREREVUOg1kiIiIiIiKqHAaz2bi66AJQqfH4oEZ4fFAcHiPUCI8PisNj\nhBqp1PHBMbNERERERERUOWyZJSIiIiIiosphMOuQiOwpIs+LyBoRWVh0eSgfIjJQRB4QkWdF5GkR\nObG2fWMR+V8ReaF2u1Ftu4jId2rHyWoR2TaQ1mG1/V8QkcOKek/knoh0EJE/iMjdtcdDRGRl7bu+\nVUQ61bZvUHu8pvb84EAap9e2Py8iexTzTigLItJLRG4Xkedq55LteQ4hn4icVPv/8pSI3CwinXkO\nad9E5DoReUNEngpsc3bOEJHtROTJ2mu+IyKS7zuktDTHyEW1/zOrReROEekVeC7y/KCLb3TnoLwx\nmHVERDoAWApgOoAxAA4SkTHFlopy8jGAryilRgOYAuDY2ne/EMD9SqnhAO6vPQa8Y2R47W8+gCsB\n758QgLMBTAbQAuBs/x8RNYUTATwbePwtAN+uHR9vAfhibfsXAbyllBoG4Nu1/VA7puYAGAtgTwBX\n1M471BwuA7BcKTUKwHh4xwrPIQQR6Q/gBAATlVJbAegA71zAc0j79kN432OQy3PGlbV9/deF86Ly\n+yHqv7f/BbCVUmprAH8CcDqgPz/ExDe6c1CuGMy60wJgjVLqJaXUhwBuATCr4DJRDpRSf1VKPV67\n/294ldD+8L7/62u7XQ9g39r9WQBuUJ5HAPQSkc0A7AHgf5VS/1BKvQXvhMN/Hk1ARAYA2AvANbXH\nAmAXALfXdgkfH/5xczuAabX9ZwG4RSn1gVLqZQBr4J13qOJEpAeAHQFcCwBKqQ+VUm+D5xBq1RFA\nFxHpCKArgL+C55B2TSn1MIB/hDY7OWfUnuuhlPqd8ibXuSGQFlVE1DGilLpPKfVx7eEjAAbU7uvO\nD5HxTUw9JlcMZt3pD+DVwOO1tW3UjtS6c00AsBJAP6XUXwEv4AXQt7ab7ljhMdS8LgVwKoBPa497\nA3g78A8l+F3/9zioPf/P2v48PprXlgDWAfiBeF3RrxGRbuA5hAAopf4PwBIAr8ALYv8J4PfgOYTq\nuTpn9K/dD2+n5nIkgF/U7tseI43qMbliMOtO1FgCThXdjojIhgDuAPA/Sql/Ndo1YptqsJ0qTERm\nAnhDKfX74OaIXVXMczw+mldHANsCuFIpNQHAO2jtHhiFx0g7Uuv2OQvAEACbA+gGr8tfGM8hpGN7\nTPBYaXIisgjeMLkb/U0Ru1XiGGEw685aAAMDjwcAeK2gslDORGR9eIHsjUqpn9Y2/63WVQe12zdq\n23XHCo+h5jQVwD4i8md43XN2gddS26vWZRBo+13/9zioPd8TXjchHh/Nay2AtUqplbXHt8MLbnkO\nIQDYFcDLSql1SqmPAPwUwGfAcwjVc3XOWIvW7qfB7dQEahN9zQQwV7Wu0Wp7jLwJ/TkoVwxm3XkM\nwPDazF6d4A2iXlZwmSgHtXED1wJ4Vil1SeCpZQD8mQEPA/CzwPZ5tdkFpwD4Z6070L0AdheRjWpX\n4nevbaMKU0qdrpQaoJQaDO+88Eul1FwADwD4fG238PHhHzefr+2vatvn1GYqHQJvQo5Hc3oblCGl\n1OsAXhWRkbVN0wA8A55DyPMKgCki0rX2/8Y/PngOoTAn54zac/8WkSm1Y25eIC2qMBHZE8BpAPZR\nSr0beEp3foiMb2rnFN05KF9KKf45+gMwA97MYC8CWFR0efiX2/e+A7yuFasB/LH2NwPeeIL7AbxQ\nu924tr/AmxnuRQBPwpuh0k/rSHiD7tcAOKLo98Y/58fKTgDurt3fEt4/ijUAfgJgg9r2zrXHa2rP\nbxl4/aLacfM8gOlFvx/+OT02tgGwqnYeuQvARjyH8C/wvX4dwHMAngLwIwAb8BzSvv8A3AxvDPVH\n8FrPvujynAFgYu14exHAdwFI0e+Zf06OkTXwxsD69dXvBfaPPD9AE9/ozkF5/0mtMERERERERESV\nwW7GREREREREVDkMZomIiIiIiKhyGMwSERERERFR5TCYJSIiIiIiosphMEtERERERESVw2CWiIjI\nIRH5be12sIgc7DjtM6LyIiIiao+4NA8REVEGRGQnAF9VSs20eE0HpdQnDZ7/j1JqQxflIyIiqjq2\nzBIRETkkIv+p3f0mgM+KyB9F5CQR6SAiF4nIYyKyWkS+XNt/JxF5QERuAvBkbdtdIvJ7EXlaRObX\ntn0TQJdaejcG8xLPRSLylIg8KSKzA2k/KCK3i8hzInKjiEi+nwgREVE2OhZdACIioia1EIGW2VpQ\n+k+l1CQR2QDAb0Tkvtq+LQC2Ukq9XHt8pFLqHyLSBcBjInKHUmqhiBynlNomIq/9AWwDYDyATWqv\nebj23AQAYwG8BuA3AKYC+LX7t0tERJQvtswSERHlY3cA80TkjwBWAugNYHjtuUcDgSwAnCAiTwB4\nBMDAwH46OwC4WSn1iVLqbwAeAjApkPZapdSnAP4IYLCTd0NERFQwtswSERHlQwAcr5S6t81Gb2zt\nO6HHuwLYXin1rog8CKCzQdo6HwTufwL+7ycioibBllkiIqJs/BtA98DjewEsEJH1AUBERohIt4jX\n9QTwVi2QHQVgSuC5j/zXhzwMYHZtXG4fADsCeNTJuyAiIiopXp0lIiLKxmoAH9e6C/8QwGXwuvg+\nXpuEaR2AfSNetxzA0SKyGsDz8Loa+64GsFpEHldKzQ1svxPA9gCeAKAAnKqUer0WDBMRETUlLs1D\nRERERERElcNuxkRERERERFQ5DGaJiIiIiIiochjMEhERERERUeUwmCUiIiIiIqLKYTBLRERERERE\nlcNgloiIiIiIiCqHwSwRERERERFVDoNZIiIiIiIiqpz/D2R4sX7KBdBpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Plot Accuracies# Plot A \n",
    "plt.figure(figsize = (16,6))\n",
    "\n",
    "plt.plot(t, np.array(train_acc), 'r-', t[t % interation_compute_val == compute_val_at], validation_acc, 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Accuray\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints\\har-lstm.ckpt\n",
      "(70626, 3)\n",
      "0.42041\n",
      "0.374512\n",
      "0.375488\n",
      "0.549316\n",
      "0.459961\n",
      "0.35791\n",
      "0.368164\n",
      "0.481934\n",
      "0.421387\n",
      "0.44043\n",
      "0.471191\n",
      "0.473633\n",
      "0.428223\n",
      "0.541504\n",
      "0.350098\n",
      "0.420898\n",
      "0.364258\n",
      "0.304688\n",
      "0.166016\n",
      "0.218262\n",
      "0.222168\n",
      "0.22998\n",
      "0.32373\n",
      "0.282227\n",
      "0.24707\n",
      "0.29248\n",
      "0.253418\n",
      "0.171387\n",
      "0.258789\n",
      "0.408691\n",
      "0.334473\n",
      "0.337891\n",
      "0.243652\n",
      "0.291504\n",
      "Test accuracy: 0.349581\n"
     ]
    }
   ],
   "source": [
    "test_acc = []\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # Restore\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    saver = tf.train.import_meta_graph('checkpoints\\har-lstm.ckpt.meta')\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "\n",
    "    test_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "    print(y_vld.shape)        \n",
    "    for x_t, y_t in get_batches(X_vld, y_vld, batch_size): \n",
    "        feed = {inputs_: x_t,\n",
    "                labels_: y_t,\n",
    "                keep_prob_: 1,\n",
    "                initial_state: test_state}\n",
    "        \n",
    "        batch_acc, test_state = sess.run([ accuracy,final_state], feed_dict=feed)\n",
    "        test_acc.append(batch_acc)\n",
    "        print(batch_acc)\n",
    "    print(\"Test accuracy: {:.6f}\".format(np.mean(test_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  0  4  5  6  7  8 10]\n",
      " [ 0 11  0 13  0 15  0 17 18  0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a = np.array([[ 0,  1,  2,  0,  4,  5,  6,  7,  8,  10],\n",
    "              [ 0, 11,  0, 13,  0, 15,  0, 17, 18,  0]])\n",
    "print (a[a.max(axis=1) >= 10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2 0 4 5 6 7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a = np.array([[ 0,  1,  2,  0,  4,  5,  6,  7,  8,  9],\n",
    "              [ 0, 11,  0, 13,  0, 15,  0, 17, 18,  0]])\n",
    "print (a[a[:,2]!=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ytest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-a2bf8e0aca21>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m Xtest = np.array([[ 0,  1,  2,  0,  4,  5,  6,  7,  8,  9],\n\u001b[0;32m      3\u001b[0m               \u001b[1;33m[\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m13\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m17\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m18\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m              [ 0, 11,  0, 13,  0, 15,  0, 11, 1,  1]])\n\u001b[0;32m      5\u001b[0m \u001b[0mytest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ytest' is not defined"
     ]
    }
   ],
   "source": [
    "print(ytest[:]!=0)\n",
    "Xtest = np.array([[ 0,  1,  2,  0,  4,  5,  6,  7,  8,  9],\n",
    "              [ 0, 11,  0, 13,  0, 15,  0, 17, 18,  0],\n",
    "             [ 0, 11,  0, 13,  0, 15,  0, 11, 1,  1]])\n",
    "ytest = np.array([ 0,  1,  1])\n",
    "Xtest = Xtest[ytest[:]!=0,:]\n",
    "ytest = ytest[ytest[:]!=0]\n",
    "print(Xtest)\n",
    "print(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(50%1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
