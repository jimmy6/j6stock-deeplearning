{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xfile = 'F:\\workspace\\j6stock\\XOpenHighLowCloseVol_tp10_cl10.txt'\n",
    "lstm_size = 120         # 3 times the amount of channels\n",
    "lstm_layers = 2        # Number of layers\n",
    "batch_size = 2048       # Batch size\n",
    "learning_rate = 0.001  #0.0001  # Learning rate (default is 0.001)\n",
    "epochs = 140\n",
    "\n",
    "# Fixed\n",
    "#amount_of_features_cvs = 5 # cvs with prefix with feature column\n",
    "#n_channels = amount_of_features\n",
    "seq_len = lstm_size\n",
    "y_column = 6\n",
    "compute_val_at = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "C:\\Users\\lai\\Anaconda3\\lib\\site-packages\\theano\\configdefaults.py:560: UserWarning: DeprecationWarning: there is no c++ compiler.This is deprecated and with Theano 0.11 a c++ compiler will be mandatory\n",
      "  warnings.warn(\"DeprecationWarning: there is no c++ compiler.\"\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt2\n",
    "import pandas as pd\n",
    "from pandas import datetime\n",
    "import math, time\n",
    "import itertools\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import load_model\n",
    "import keras\n",
    "import pandas_datareader.data as web\n",
    "import h5py\n",
    "import os\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stock_data(normalize=True, ma=[]):\n",
    "    \"\"\"\n",
    "    Return a dataframe of that stock and normalize all the values. \n",
    "    (Optional: create moving average)\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filepath_or_buffer  = xfile )\n",
    "    #TODO Use previous close instead of open\n",
    "    df['change'] = df['close'] - df['open']\n",
    "    for i, row in df.iterrows():\n",
    "        df.at[i, 'high'] = df.at[i, 'high'] - (df.at[i, 'open'] if df.at[i, 'open'] > df.at[i, 'close'] else df.at[i, 'close'])\n",
    "        df.at[i, 'low'] = (df.at[i, 'close'] if df.at[i, 'close'] < df.at[i, 'open'] else df.at[i, 'open']) - df.at[i, 'low']\n",
    "    df.dropna(inplace=True)\n",
    "    df = df.drop('open', axis=1)\n",
    "    # Moving Average    \n",
    "    if ma != []:\n",
    "        for moving in ma:\n",
    "            df['{}ma'.format(moving)] = df['close'].rolling(window=moving).mean()\n",
    "    df.dropna(inplace=True)\n",
    "    if normalize:\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        #df['open'] = min_max_scaler.fit_transform(df.open.values.reshape(-1,1))\n",
    "        df['high'] = min_max_scaler.fit_transform(df.high.values.reshape(-1,1))\n",
    "        df['low'] = min_max_scaler.fit_transform(df.low.values.reshape(-1,1))\n",
    "        #df['vol'] = min_max_scaler.fit_transform(df.vol.values.reshape(-1,1))\n",
    "        df['close'] = min_max_scaler.fit_transform(df['close'].values.reshape(-1,1))\n",
    "        #df['change'] = min_max_scaler.fit_transform(df['change'].values.reshape(-1,1))\n",
    "        if ma != []:\n",
    "            for moving in ma:\n",
    "                df['{}ma'.format(moving)] = min_max_scaler.fit_transform(df['{}ma'.format(moving)].values.reshape(-1,1))  \n",
    "    df.dropna(inplace=True)\n",
    "               \n",
    "    # Move y_result to the rightmost for the ease of training\n",
    "    adj_close = df['y_result']\n",
    "    df.drop(labels=['y_result'], axis=1, inplace=True)\n",
    "    df = pd.concat([df, adj_close], axis=1)\n",
    "      \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = get_stock_data( ma=[50, 100, 200])\n",
    "amount_of_features = len(df.columns)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_stock(df):\n",
    "    print(df.head())\n",
    "    plt.subplot(211)\n",
    "    plt.plot(df['close'], color='red', label='Close')\n",
    "    plt.legend(loc='best')\n",
    "    plt.subplot(212)\n",
    "    plt.plot(df['change'], color='blue', label='Percentage change')\n",
    "    plt.legend(loc='best')\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    ax1.plot(df['high'], color='red', label='high')\n",
    "    ax1.legend(loc='best')\n",
    " \n",
    "    ax2.plot(df['low'], color='red', label='low')\n",
    "    ax2.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             high           low     close    change      50ma     100ma  \\\n",
      "199  4.445337e-14  6.182380e-03  0.357085 -0.000150  0.351429  0.351070   \n",
      "200  2.002002e-03  1.545595e-02  0.356606 -0.000060  0.351433  0.351063   \n",
      "201  1.301301e-02  7.727975e-03  0.356893  0.000035  0.351445  0.351060   \n",
      "202  4.445337e-14  1.545595e-03  0.357133  0.000015  0.351502  0.351082   \n",
      "203  6.006006e-03  6.863821e-14  0.358138  0.000095  0.351587  0.351141   \n",
      "\n",
      "        200ma  y_result  \n",
      "199  0.346428         0  \n",
      "200  0.346426         0  \n",
      "201  0.346424         0  \n",
      "202  0.346433         0  \n",
      "203  0.346448         0  \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAD8CAYAAAChHgmuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2PGlFAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_stock(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEaCAYAAADwlvf0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYoizgCZbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr = df.corr()\n",
    "ax = sns.heatmap(corr, cmap=\"YlGnBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(stock, seq_len):\n",
    "    print (\"Amount of features = {}\".format(amount_of_features))\n",
    "    data = stock.as_matrix()\n",
    "    sequence_length = seq_len + 1 # index starting from 0\n",
    "    x_result = []\n",
    "    y_result = []\n",
    "    for index in range(seq_len, len(data) ): # maxmimum date = lastest date - sequence length\n",
    "        x_result.append(data[index-seq_len: index,:-1]) # index : index + 22days\n",
    "        y_result.append(data[index ,amount_of_features]);\n",
    "\n",
    "    #print('---', data[0])\n",
    "    #print('---', x_result[0])\n",
    "    #print('---', y_result[0])\n",
    "    x_result = np.array(x_result)\n",
    "    y_result = np.array(y_result)\n",
    "    row = round(0.6 * y_result.shape[0]) # 80% split\n",
    "    print (\"Amount of training data = {}\".format(0.9 * x_result.shape[0]))\n",
    "    print (\"Amount of testing data = {}\".format(0.1 * y_result.shape[0]))\n",
    "     \n",
    "    X_train = x_result[:int(row), :] # 90% date\n",
    "    y_train = y_result[:int(row)] # 90% date\n",
    "        \n",
    "\n",
    "    X_test = x_result[int(row):, :]\n",
    "    y_test = y_result[int(row):]\n",
    "    # filter for 1 and -1 for validation only\n",
    "    X_test = X_test[y_test[:]!=0,:]\n",
    "    y_test = y_test[y_test[:]!=0]\n",
    "    #print(result.shape[0], len(y_result), int(row), y_result[int(row):])\n",
    "    #X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], amount_of_features-1))\n",
    "    #X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], amount_of_features-1))\n",
    "    \n",
    "    return [X_train, y_train, X_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of features = 7\n",
      "Amount of training data = 261918.9\n",
      "Amount of testing data = 29102.100000000002\n",
      "(174613, 120, 7) (174613,) (70626, 120, 7) (70626,)\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit([1, 0, -1])\n",
    "\n",
    "X_tr, lab_tr, X_vld, lab_vld = load_data(df, seq_len)\n",
    "y_tr = lb.transform(lab_tr)\n",
    "y_vld = lb.transform(lab_vld)\n",
    "print(X_tr.shape, lab_tr.shape, X_vld.shape, lab_vld.shape)\n",
    "print(amount_of_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(X, y, batch_size = 100):\n",
    "\t\"\"\" Return a generator for batches \"\"\"\n",
    "\tn_batches = len(X) // batch_size\n",
    "\tX, y = X[:n_batches*batch_size], y[:n_batches*batch_size]\n",
    "\n",
    "\t# Loop over batches and yield\n",
    "\tfor b in range(0, len(X), batch_size):\n",
    "\t\tyield X[b:b+batch_size], y[b:b+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "n_channels = amount_of_features\n",
    "n_classes = lb.transform([1]).shape[1]\n",
    "# Construct placeholders\n",
    "with graph.as_default():\n",
    "    inputs_ = tf.placeholder(tf.float32, [None, seq_len, n_channels], name = 'inputs')\n",
    "    labels_ = tf.placeholder(tf.float32, [None, n_classes], name = 'labels')\n",
    "    keep_prob_ = tf.placeholder(tf.float32, name = 'keep')\n",
    "    learning_rate_ = tf.placeholder(tf.float32, name = 'learning_rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct inputs to LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    # Construct the LSTM inputs and LSTM cells\n",
    "    lstm_in = tf.transpose(inputs_, [1,0,2]) # reshape into (seq_len, N, channels)\n",
    "    lstm_in = tf.reshape(lstm_in, [-1, n_channels]) # Now (seq_len*N, n_channels)\n",
    "    \n",
    "    # To cells\n",
    "    lstm_in = tf.layers.dense(lstm_in, lstm_size, activation=None) # or tf.nn.relu, tf.nn.sigmoid, tf.nn.tanh?\n",
    "    \n",
    "    # Open up the tensor into a list of seq_len pieces\n",
    "    lstm_in = tf.split(lstm_in, seq_len, 0)\n",
    "    \n",
    "    # Add LSTM layers\n",
    "    lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "    drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob_)\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([drop] * lstm_layers)\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define forward pass, cost function and optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    outputs, final_state = tf.contrib.rnn.static_rnn(cell, lstm_in, dtype=tf.float32,\n",
    "                                                     initial_state = initial_state)\n",
    "    \n",
    "    # We only need the last output tensor to pass into a classifier\n",
    "    logits = tf.layers.dense(outputs[-1], n_classes, name='logits')\n",
    "    \n",
    "    # Cost function and optimizer\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels_))\n",
    "    #optimizer = tf.train.AdamOptimizer(learning_rate_).minimize(cost) # No grad clipping\n",
    "    \n",
    "    # Grad clipping\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate_)\n",
    "\n",
    "    gradients = train_op.compute_gradients(cost)\n",
    "    capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients]\n",
    "    optimizer = train_op.apply_gradients(capped_gradients)\n",
    "    \n",
    "    # Accuracy\n",
    "    correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if (os.path.exists('checkpoints') == False):\n",
    "    !mkdir checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/har-lstm.ckpt\n",
      "Epoch: 0/140 Iteration: 5 Train loss: 0.671233 Train acc: 0.741211\n",
      "Epoch: 0/140 Iteration: 10 Train loss: 0.623091 Train acc: 0.756836\n",
      "Epoch: 0/140 Iteration: 15 Train loss: 0.621891 Train acc: 0.740234\n",
      "Epoch: 0/140 Iteration: 20 Train loss: 0.479946 Train acc: 0.826660\n",
      "Epoch: 0/140 Iteration: 25 Train loss: 0.602635 Train acc: 0.765625\n",
      "Epoch: 0/140 Iteration: 30 Train loss: 0.473999 Train acc: 0.812500\n",
      "Epoch: 0/140 Iteration: 35 Train loss: 0.362995 Train acc: 0.869629\n",
      "Epoch: 0/140 Iteration: 40 Train loss: 0.495250 Train acc: 0.798340\n",
      "Epoch: 0/140 Iteration: 40 Validation loss: 1.699282 Validation acc: 0.365522\n",
      "Epoch: 0/140 Iteration: 45 Train loss: 0.548381 Train acc: 0.784180\n",
      "Epoch: 0/140 Iteration: 50 Train loss: 0.491166 Train acc: 0.843750\n",
      "Epoch: 0/140 Iteration: 55 Train loss: 0.650931 Train acc: 0.718262\n",
      "Epoch: 0/140 Iteration: 60 Train loss: 0.674822 Train acc: 0.717773\n",
      "Epoch: 0/140 Iteration: 65 Train loss: 0.685397 Train acc: 0.704102\n",
      "Epoch: 0/140 Iteration: 70 Train loss: 0.649297 Train acc: 0.729004\n",
      "Epoch: 0/140 Iteration: 75 Train loss: 0.744483 Train acc: 0.645508\n",
      "Epoch: 0/140 Iteration: 80 Train loss: 0.664565 Train acc: 0.705566\n",
      "Epoch: 0/140 Iteration: 80 Validation loss: 1.622434 Validation acc: 0.395680\n",
      "Epoch: 0/140 Iteration: 85 Train loss: 0.629489 Train acc: 0.726562\n",
      "Epoch: 1/140 Iteration: 90 Train loss: 0.681900 Train acc: 0.721191\n",
      "Epoch: 1/140 Iteration: 95 Train loss: 0.620166 Train acc: 0.750000\n",
      "Epoch: 1/140 Iteration: 100 Train loss: 0.670536 Train acc: 0.724609\n",
      "Epoch: 1/140 Iteration: 105 Train loss: 0.466632 Train acc: 0.835449\n",
      "Epoch: 1/140 Iteration: 110 Train loss: 0.611172 Train acc: 0.750488\n",
      "Epoch: 1/140 Iteration: 115 Train loss: 0.442609 Train acc: 0.829590\n",
      "Epoch: 1/140 Iteration: 120 Train loss: 0.358225 Train acc: 0.866699\n",
      "Epoch: 1/140 Iteration: 120 Validation loss: 1.614013 Validation acc: 0.382281\n",
      "Epoch: 1/140 Iteration: 125 Train loss: 0.542187 Train acc: 0.770508\n",
      "Epoch: 1/140 Iteration: 130 Train loss: 0.550353 Train acc: 0.783203\n",
      "Epoch: 1/140 Iteration: 135 Train loss: 0.455570 Train acc: 0.857422\n",
      "Epoch: 1/140 Iteration: 140 Train loss: 0.629960 Train acc: 0.725098\n",
      "Epoch: 1/140 Iteration: 145 Train loss: 0.662296 Train acc: 0.714355\n",
      "Epoch: 1/140 Iteration: 150 Train loss: 0.669072 Train acc: 0.711426\n",
      "Epoch: 1/140 Iteration: 155 Train loss: 0.649054 Train acc: 0.726562\n",
      "Epoch: 1/140 Iteration: 160 Train loss: 0.724457 Train acc: 0.652832\n",
      "Epoch: 1/140 Iteration: 160 Validation loss: 1.617749 Validation acc: 0.406264\n",
      "Epoch: 1/140 Iteration: 165 Train loss: 0.674541 Train acc: 0.692383\n",
      "Epoch: 1/140 Iteration: 170 Train loss: 0.620847 Train acc: 0.744141\n",
      "Epoch: 2/140 Iteration: 175 Train loss: 0.685394 Train acc: 0.728027\n",
      "Epoch: 2/140 Iteration: 180 Train loss: 0.611884 Train acc: 0.765137\n",
      "Epoch: 2/140 Iteration: 185 Train loss: 0.598486 Train acc: 0.751953\n",
      "Epoch: 2/140 Iteration: 190 Train loss: 0.506771 Train acc: 0.803223\n",
      "Epoch: 2/140 Iteration: 195 Train loss: 0.605949 Train acc: 0.760742\n",
      "Epoch: 2/140 Iteration: 200 Train loss: 0.441011 Train acc: 0.833984\n",
      "Epoch: 2/140 Iteration: 200 Validation loss: 1.737045 Validation acc: 0.338752\n",
      "Epoch: 2/140 Iteration: 205 Train loss: 0.379655 Train acc: 0.861328\n",
      "Epoch: 2/140 Iteration: 210 Train loss: 0.482024 Train acc: 0.802246\n",
      "Epoch: 2/140 Iteration: 215 Train loss: 0.554539 Train acc: 0.782227\n",
      "Epoch: 2/140 Iteration: 220 Train loss: 0.478808 Train acc: 0.838379\n",
      "Epoch: 2/140 Iteration: 225 Train loss: 0.609520 Train acc: 0.743652\n",
      "Epoch: 2/140 Iteration: 230 Train loss: 0.671070 Train acc: 0.714355\n",
      "Epoch: 2/140 Iteration: 235 Train loss: 0.682101 Train acc: 0.704590\n",
      "Epoch: 2/140 Iteration: 240 Train loss: 0.679681 Train acc: 0.710449\n",
      "Epoch: 2/140 Iteration: 240 Validation loss: 1.548959 Validation acc: 0.391444\n",
      "Epoch: 2/140 Iteration: 245 Train loss: 0.713840 Train acc: 0.650391\n",
      "Epoch: 2/140 Iteration: 250 Train loss: 0.699632 Train acc: 0.673828\n",
      "Epoch: 2/140 Iteration: 255 Train loss: 0.631789 Train acc: 0.725586\n",
      "Epoch: 3/140 Iteration: 260 Train loss: 0.641934 Train acc: 0.734375\n",
      "Epoch: 3/140 Iteration: 265 Train loss: 0.644040 Train acc: 0.736816\n",
      "Epoch: 3/140 Iteration: 270 Train loss: 0.609174 Train acc: 0.753906\n",
      "Epoch: 3/140 Iteration: 275 Train loss: 0.462477 Train acc: 0.829590\n",
      "Epoch: 3/140 Iteration: 280 Train loss: 0.572668 Train acc: 0.770508\n",
      "Epoch: 3/140 Iteration: 280 Validation loss: 1.692849 Validation acc: 0.363827\n",
      "Epoch: 3/140 Iteration: 285 Train loss: 0.439069 Train acc: 0.833984\n",
      "Epoch: 3/140 Iteration: 290 Train loss: 0.391427 Train acc: 0.859863\n",
      "Epoch: 3/140 Iteration: 295 Train loss: 0.500255 Train acc: 0.801758\n",
      "Epoch: 3/140 Iteration: 300 Train loss: 0.499614 Train acc: 0.805176\n",
      "Epoch: 3/140 Iteration: 305 Train loss: 0.448057 Train acc: 0.850586\n",
      "Epoch: 3/140 Iteration: 310 Train loss: 0.705426 Train acc: 0.716309\n",
      "Epoch: 3/140 Iteration: 315 Train loss: 0.657267 Train acc: 0.727539\n",
      "Epoch: 3/140 Iteration: 320 Train loss: 0.721896 Train acc: 0.693359\n",
      "Epoch: 3/140 Iteration: 320 Validation loss: 1.666292 Validation acc: 0.387667\n",
      "Epoch: 3/140 Iteration: 325 Train loss: 0.718506 Train acc: 0.687500\n",
      "Epoch: 3/140 Iteration: 330 Train loss: 0.738590 Train acc: 0.658691\n",
      "Epoch: 3/140 Iteration: 335 Train loss: 0.720728 Train acc: 0.684570\n",
      "Epoch: 3/140 Iteration: 340 Train loss: 0.645797 Train acc: 0.719238\n",
      "Epoch: 4/140 Iteration: 345 Train loss: 0.679258 Train acc: 0.719238\n",
      "Epoch: 4/140 Iteration: 350 Train loss: 0.624893 Train acc: 0.741211\n",
      "Epoch: 4/140 Iteration: 355 Train loss: 0.656659 Train acc: 0.733398\n",
      "Epoch: 4/140 Iteration: 360 Train loss: 0.476466 Train acc: 0.822266\n",
      "Epoch: 4/140 Iteration: 360 Validation loss: 1.589208 Validation acc: 0.395996\n",
      "Epoch: 4/140 Iteration: 365 Train loss: 0.600233 Train acc: 0.752930\n",
      "Epoch: 4/140 Iteration: 370 Train loss: 0.479447 Train acc: 0.805664\n",
      "Epoch: 4/140 Iteration: 375 Train loss: 0.455271 Train acc: 0.834473\n",
      "Epoch: 4/140 Iteration: 380 Train loss: 0.535964 Train acc: 0.772949\n",
      "Epoch: 4/140 Iteration: 385 Train loss: 0.504147 Train acc: 0.813965\n",
      "Epoch: 4/140 Iteration: 390 Train loss: 0.426739 Train acc: 0.874023\n",
      "Epoch: 4/140 Iteration: 395 Train loss: 0.627581 Train acc: 0.741699\n",
      "Epoch: 4/140 Iteration: 400 Train loss: 0.709035 Train acc: 0.697754\n",
      "Epoch: 4/140 Iteration: 400 Validation loss: 1.563356 Validation acc: 0.425006\n",
      "Epoch: 4/140 Iteration: 405 Train loss: 0.638719 Train acc: 0.748047\n",
      "Epoch: 4/140 Iteration: 410 Train loss: 0.691686 Train acc: 0.706055\n",
      "Epoch: 4/140 Iteration: 415 Train loss: 0.711690 Train acc: 0.670410\n",
      "Epoch: 4/140 Iteration: 420 Train loss: 0.738265 Train acc: 0.673340\n",
      "Epoch: 4/140 Iteration: 425 Train loss: 0.696744 Train acc: 0.683594\n",
      "Epoch: 5/140 Iteration: 430 Train loss: 0.689563 Train acc: 0.718750\n",
      "Epoch: 5/140 Iteration: 435 Train loss: 0.627557 Train acc: 0.750488\n",
      "Epoch: 5/140 Iteration: 440 Train loss: 0.652224 Train acc: 0.731934\n",
      "Epoch: 5/140 Iteration: 440 Validation loss: 1.396695 Validation acc: 0.414422\n",
      "Epoch: 5/140 Iteration: 445 Train loss: 0.493016 Train acc: 0.820312\n",
      "Epoch: 5/140 Iteration: 450 Train loss: 0.590120 Train acc: 0.765137\n",
      "Epoch: 5/140 Iteration: 455 Train loss: 0.485242 Train acc: 0.800781\n",
      "Epoch: 5/140 Iteration: 460 Train loss: 0.449851 Train acc: 0.828125\n",
      "Epoch: 5/140 Iteration: 465 Train loss: 0.618036 Train acc: 0.762207\n",
      "Epoch: 5/140 Iteration: 470 Train loss: 0.518549 Train acc: 0.797363\n",
      "Epoch: 5/140 Iteration: 475 Train loss: 0.419333 Train acc: 0.863281\n",
      "Epoch: 5/140 Iteration: 480 Train loss: 0.647062 Train acc: 0.740723\n",
      "Epoch: 5/140 Iteration: 480 Validation loss: 1.532261 Validation acc: 0.409711\n",
      "Epoch: 5/140 Iteration: 485 Train loss: 0.713591 Train acc: 0.676758\n",
      "Epoch: 5/140 Iteration: 490 Train loss: 0.651520 Train acc: 0.729492\n",
      "Epoch: 5/140 Iteration: 495 Train loss: 0.737287 Train acc: 0.673828\n",
      "Epoch: 5/140 Iteration: 500 Train loss: 0.722590 Train acc: 0.649414\n",
      "Epoch: 5/140 Iteration: 505 Train loss: 0.675276 Train acc: 0.710938\n",
      "Epoch: 5/140 Iteration: 510 Train loss: 0.753230 Train acc: 0.656738\n",
      "Epoch: 6/140 Iteration: 515 Train loss: 0.723428 Train acc: 0.723633\n",
      "Epoch: 6/140 Iteration: 520 Train loss: 0.648773 Train acc: 0.750000\n",
      "Epoch: 6/140 Iteration: 520 Validation loss: 1.445861 Validation acc: 0.408720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/140 Iteration: 525 Train loss: 0.632214 Train acc: 0.749023\n",
      "Epoch: 6/140 Iteration: 530 Train loss: 0.522541 Train acc: 0.817871\n",
      "Epoch: 6/140 Iteration: 535 Train loss: 0.624333 Train acc: 0.743164\n",
      "Epoch: 6/140 Iteration: 540 Train loss: 0.510484 Train acc: 0.812500\n",
      "Epoch: 6/140 Iteration: 545 Train loss: 0.376363 Train acc: 0.869629\n",
      "Epoch: 6/140 Iteration: 550 Train loss: 0.641640 Train acc: 0.767090\n",
      "Epoch: 6/140 Iteration: 555 Train loss: 0.615374 Train acc: 0.739746\n",
      "Epoch: 6/140 Iteration: 560 Train loss: 0.486927 Train acc: 0.866211\n",
      "Epoch: 6/140 Iteration: 560 Validation loss: 1.515348 Validation acc: 0.411578\n",
      "Epoch: 6/140 Iteration: 565 Train loss: 0.635868 Train acc: 0.728027\n",
      "Epoch: 6/140 Iteration: 570 Train loss: 0.667876 Train acc: 0.715820\n",
      "Epoch: 6/140 Iteration: 575 Train loss: 0.720521 Train acc: 0.678223\n",
      "Epoch: 6/140 Iteration: 580 Train loss: 0.717837 Train acc: 0.702637\n",
      "Epoch: 6/140 Iteration: 585 Train loss: 0.729669 Train acc: 0.647461\n",
      "Epoch: 6/140 Iteration: 590 Train loss: 0.643923 Train acc: 0.728027\n",
      "Epoch: 6/140 Iteration: 595 Train loss: 0.701094 Train acc: 0.686035\n",
      "Epoch: 7/140 Iteration: 600 Train loss: 0.738728 Train acc: 0.696289\n",
      "Epoch: 7/140 Iteration: 600 Validation loss: 1.546319 Validation acc: 0.400103\n",
      "Epoch: 7/140 Iteration: 605 Train loss: 0.648527 Train acc: 0.741699\n",
      "Epoch: 7/140 Iteration: 610 Train loss: 0.604082 Train acc: 0.748535\n",
      "Epoch: 7/140 Iteration: 615 Train loss: 0.493618 Train acc: 0.815918\n",
      "Epoch: 7/140 Iteration: 620 Train loss: 0.602690 Train acc: 0.750000\n",
      "Epoch: 7/140 Iteration: 625 Train loss: 0.466356 Train acc: 0.804688\n",
      "Epoch: 7/140 Iteration: 630 Train loss: 0.375251 Train acc: 0.863770\n",
      "Epoch: 7/140 Iteration: 635 Train loss: 0.541123 Train acc: 0.783691\n",
      "Epoch: 7/140 Iteration: 640 Train loss: 0.616725 Train acc: 0.733887\n",
      "Epoch: 7/140 Iteration: 640 Validation loss: 1.542425 Validation acc: 0.386647\n",
      "Epoch: 7/140 Iteration: 645 Train loss: 0.438586 Train acc: 0.871094\n",
      "Epoch: 7/140 Iteration: 650 Train loss: 0.725380 Train acc: 0.680176\n",
      "Epoch: 7/140 Iteration: 655 Train loss: 0.716706 Train acc: 0.683105\n",
      "Epoch: 7/140 Iteration: 660 Train loss: 0.748136 Train acc: 0.675781\n",
      "Epoch: 7/140 Iteration: 665 Train loss: 0.851932 Train acc: 0.601562\n",
      "Epoch: 7/140 Iteration: 670 Train loss: 0.728865 Train acc: 0.642578\n",
      "Epoch: 7/140 Iteration: 675 Train loss: 0.669922 Train acc: 0.698730\n",
      "Epoch: 7/140 Iteration: 680 Train loss: 0.635958 Train acc: 0.729004\n",
      "Epoch: 7/140 Iteration: 680 Validation loss: 1.735035 Validation acc: 0.392592\n",
      "Epoch: 8/140 Iteration: 685 Train loss: 0.679142 Train acc: 0.731445\n",
      "Epoch: 8/140 Iteration: 690 Train loss: 0.618845 Train acc: 0.743652\n",
      "Epoch: 8/140 Iteration: 695 Train loss: 0.600747 Train acc: 0.757812\n",
      "Epoch: 8/140 Iteration: 700 Train loss: 0.539492 Train acc: 0.802246\n",
      "Epoch: 8/140 Iteration: 705 Train loss: 0.582259 Train acc: 0.770020\n",
      "Epoch: 8/140 Iteration: 710 Train loss: 0.506797 Train acc: 0.808594\n",
      "Epoch: 8/140 Iteration: 715 Train loss: 0.330061 Train acc: 0.887207\n",
      "Epoch: 8/140 Iteration: 720 Train loss: 0.526834 Train acc: 0.795410\n",
      "Epoch: 8/140 Iteration: 720 Validation loss: 1.727135 Validation acc: 0.377743\n",
      "Epoch: 8/140 Iteration: 725 Train loss: 0.551110 Train acc: 0.779297\n",
      "Epoch: 8/140 Iteration: 730 Train loss: 0.464174 Train acc: 0.861816\n",
      "Epoch: 8/140 Iteration: 735 Train loss: 0.649803 Train acc: 0.733398\n",
      "Epoch: 8/140 Iteration: 740 Train loss: 0.713009 Train acc: 0.674805\n",
      "Epoch: 8/140 Iteration: 745 Train loss: 0.710821 Train acc: 0.698730\n",
      "Epoch: 8/140 Iteration: 750 Train loss: 0.664368 Train acc: 0.710938\n",
      "Epoch: 8/140 Iteration: 755 Train loss: 0.700471 Train acc: 0.691895\n",
      "Epoch: 8/140 Iteration: 760 Train loss: 0.655944 Train acc: 0.719727\n",
      "Epoch: 8/140 Iteration: 760 Validation loss: 1.814928 Validation acc: 0.380788\n",
      "Epoch: 8/140 Iteration: 765 Train loss: 0.632910 Train acc: 0.728516\n",
      "Epoch: 9/140 Iteration: 770 Train loss: 0.714081 Train acc: 0.715820\n",
      "Epoch: 9/140 Iteration: 775 Train loss: 0.665817 Train acc: 0.742676\n",
      "Epoch: 9/140 Iteration: 780 Train loss: 0.603241 Train acc: 0.762695\n",
      "Epoch: 9/140 Iteration: 785 Train loss: 0.531533 Train acc: 0.800781\n",
      "Epoch: 9/140 Iteration: 790 Train loss: 0.615068 Train acc: 0.749512\n",
      "Epoch: 9/140 Iteration: 795 Train loss: 0.430400 Train acc: 0.836426\n",
      "Epoch: 9/140 Iteration: 800 Train loss: 0.326029 Train acc: 0.889648\n",
      "Epoch: 9/140 Iteration: 800 Validation loss: 1.682495 Validation acc: 0.359849\n",
      "Epoch: 9/140 Iteration: 805 Train loss: 0.507518 Train acc: 0.789551\n",
      "Epoch: 9/140 Iteration: 810 Train loss: 0.539005 Train acc: 0.764648\n",
      "Epoch: 9/140 Iteration: 815 Train loss: 0.438260 Train acc: 0.862793\n",
      "Epoch: 9/140 Iteration: 820 Train loss: 0.652154 Train acc: 0.734375\n",
      "Epoch: 9/140 Iteration: 825 Train loss: 0.688026 Train acc: 0.698730\n",
      "Epoch: 9/140 Iteration: 830 Train loss: 0.658554 Train acc: 0.719238\n",
      "Epoch: 9/140 Iteration: 835 Train loss: 0.668136 Train acc: 0.707520\n",
      "Epoch: 9/140 Iteration: 840 Train loss: 0.749738 Train acc: 0.645996\n",
      "Epoch: 9/140 Iteration: 840 Validation loss: 1.793585 Validation acc: 0.362965\n",
      "Epoch: 9/140 Iteration: 845 Train loss: 0.714842 Train acc: 0.685059\n",
      "Epoch: 9/140 Iteration: 850 Train loss: 0.589560 Train acc: 0.754395\n",
      "Epoch: 10/140 Iteration: 855 Train loss: 0.639325 Train acc: 0.753906\n",
      "Epoch: 10/140 Iteration: 860 Train loss: 0.639126 Train acc: 0.736816\n",
      "Epoch: 10/140 Iteration: 865 Train loss: 0.598680 Train acc: 0.763672\n",
      "Epoch: 10/140 Iteration: 870 Train loss: 0.593063 Train acc: 0.774414\n",
      "Epoch: 10/140 Iteration: 875 Train loss: 0.604149 Train acc: 0.750000\n",
      "Epoch: 10/140 Iteration: 880 Train loss: 0.468736 Train acc: 0.818359\n",
      "Epoch: 10/140 Iteration: 880 Validation loss: 1.626684 Validation acc: 0.387178\n",
      "Epoch: 10/140 Iteration: 885 Train loss: 0.332123 Train acc: 0.884766\n",
      "Epoch: 10/140 Iteration: 890 Train loss: 0.476775 Train acc: 0.807617\n",
      "Epoch: 10/140 Iteration: 895 Train loss: 0.633763 Train acc: 0.729004\n",
      "Epoch: 10/140 Iteration: 900 Train loss: 0.487646 Train acc: 0.830566\n",
      "Epoch: 10/140 Iteration: 905 Train loss: 0.621549 Train acc: 0.739746\n",
      "Epoch: 10/140 Iteration: 910 Train loss: 0.695520 Train acc: 0.695801\n",
      "Epoch: 10/140 Iteration: 915 Train loss: 0.654821 Train acc: 0.735352\n",
      "Epoch: 10/140 Iteration: 920 Train loss: 0.725476 Train acc: 0.666504\n",
      "Epoch: 10/140 Iteration: 920 Validation loss: 1.765258 Validation acc: 0.363583\n",
      "Epoch: 10/140 Iteration: 925 Train loss: 0.718758 Train acc: 0.654785\n",
      "Epoch: 10/140 Iteration: 930 Train loss: 0.675308 Train acc: 0.704102\n",
      "Epoch: 10/140 Iteration: 935 Train loss: 0.665061 Train acc: 0.707031\n",
      "Epoch: 11/140 Iteration: 940 Train loss: 0.623815 Train acc: 0.747559\n",
      "Epoch: 11/140 Iteration: 945 Train loss: 0.610947 Train acc: 0.749512\n",
      "Epoch: 11/140 Iteration: 950 Train loss: 0.567626 Train acc: 0.772949\n",
      "Epoch: 11/140 Iteration: 955 Train loss: 0.508392 Train acc: 0.801270\n",
      "Epoch: 11/140 Iteration: 960 Train loss: 0.578698 Train acc: 0.765625\n",
      "Epoch: 11/140 Iteration: 960 Validation loss: 1.588444 Validation acc: 0.406049\n",
      "Epoch: 11/140 Iteration: 965 Train loss: 0.453595 Train acc: 0.827637\n",
      "Epoch: 11/140 Iteration: 970 Train loss: 0.364504 Train acc: 0.861816\n",
      "Epoch: 11/140 Iteration: 975 Train loss: 0.466711 Train acc: 0.815430\n",
      "Epoch: 11/140 Iteration: 980 Train loss: 0.623943 Train acc: 0.722168\n",
      "Epoch: 11/140 Iteration: 985 Train loss: 0.486112 Train acc: 0.836426\n",
      "Epoch: 11/140 Iteration: 990 Train loss: 0.644260 Train acc: 0.741699\n",
      "Epoch: 11/140 Iteration: 995 Train loss: 0.658710 Train acc: 0.722656\n",
      "Epoch: 11/140 Iteration: 1000 Train loss: 0.655499 Train acc: 0.752930\n",
      "Epoch: 11/140 Iteration: 1000 Validation loss: 1.638594 Validation acc: 0.383933\n",
      "Epoch: 11/140 Iteration: 1005 Train loss: 0.657789 Train acc: 0.707520\n",
      "Epoch: 11/140 Iteration: 1010 Train loss: 0.715384 Train acc: 0.644531\n",
      "Epoch: 11/140 Iteration: 1015 Train loss: 0.678609 Train acc: 0.699219\n",
      "Epoch: 11/140 Iteration: 1020 Train loss: 0.672083 Train acc: 0.709473\n",
      "Epoch: 12/140 Iteration: 1025 Train loss: 0.656027 Train acc: 0.736816\n",
      "Epoch: 12/140 Iteration: 1030 Train loss: 0.614652 Train acc: 0.759277\n",
      "Epoch: 12/140 Iteration: 1035 Train loss: 0.569607 Train acc: 0.775879\n",
      "Epoch: 12/140 Iteration: 1040 Train loss: 0.474675 Train acc: 0.823730\n",
      "Epoch: 12/140 Iteration: 1040 Validation loss: 1.619418 Validation acc: 0.389289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/140 Iteration: 1045 Train loss: 0.559120 Train acc: 0.772949\n",
      "Epoch: 12/140 Iteration: 1050 Train loss: 0.417205 Train acc: 0.833984\n",
      "Epoch: 12/140 Iteration: 1055 Train loss: 0.318827 Train acc: 0.886230\n",
      "Epoch: 12/140 Iteration: 1060 Train loss: 0.465881 Train acc: 0.817383\n",
      "Epoch: 12/140 Iteration: 1065 Train loss: 0.630602 Train acc: 0.753906\n",
      "Epoch: 12/140 Iteration: 1070 Train loss: 0.464281 Train acc: 0.833984\n",
      "Epoch: 12/140 Iteration: 1075 Train loss: 0.651699 Train acc: 0.740234\n",
      "Epoch: 12/140 Iteration: 1080 Train loss: 0.635655 Train acc: 0.727539\n",
      "Epoch: 12/140 Iteration: 1080 Validation loss: 1.652232 Validation acc: 0.384421\n",
      "Epoch: 12/140 Iteration: 1085 Train loss: 0.627727 Train acc: 0.761719\n",
      "Epoch: 12/140 Iteration: 1090 Train loss: 0.706085 Train acc: 0.682617\n",
      "Epoch: 12/140 Iteration: 1095 Train loss: 0.720327 Train acc: 0.641602\n",
      "Epoch: 12/140 Iteration: 1100 Train loss: 0.638039 Train acc: 0.729004\n",
      "Epoch: 12/140 Iteration: 1105 Train loss: 0.683099 Train acc: 0.709473\n",
      "Epoch: 13/140 Iteration: 1110 Train loss: 0.656822 Train acc: 0.742676\n",
      "Epoch: 13/140 Iteration: 1115 Train loss: 0.589354 Train acc: 0.767578\n",
      "Epoch: 13/140 Iteration: 1120 Train loss: 0.534028 Train acc: 0.797363\n",
      "Epoch: 13/140 Iteration: 1120 Validation loss: 1.714896 Validation acc: 0.386575\n",
      "Epoch: 13/140 Iteration: 1125 Train loss: 0.471865 Train acc: 0.823730\n",
      "Epoch: 13/140 Iteration: 1130 Train loss: 0.572919 Train acc: 0.768066\n",
      "Epoch: 13/140 Iteration: 1135 Train loss: 0.450039 Train acc: 0.836914\n",
      "Epoch: 13/140 Iteration: 1140 Train loss: 0.354588 Train acc: 0.870605\n",
      "Epoch: 13/140 Iteration: 1145 Train loss: 0.466805 Train acc: 0.819824\n",
      "Epoch: 13/140 Iteration: 1150 Train loss: 0.555519 Train acc: 0.771973\n",
      "Epoch: 13/140 Iteration: 1155 Train loss: 0.467903 Train acc: 0.839844\n",
      "Epoch: 13/140 Iteration: 1160 Train loss: 0.661792 Train acc: 0.727539\n",
      "Epoch: 13/140 Iteration: 1160 Validation loss: 1.690838 Validation acc: 0.371955\n",
      "Epoch: 13/140 Iteration: 1165 Train loss: 0.641244 Train acc: 0.737793\n",
      "Epoch: 13/140 Iteration: 1170 Train loss: 0.679758 Train acc: 0.725586\n",
      "Epoch: 13/140 Iteration: 1175 Train loss: 0.681980 Train acc: 0.695801\n",
      "Epoch: 13/140 Iteration: 1180 Train loss: 0.763048 Train acc: 0.627441\n",
      "Epoch: 13/140 Iteration: 1185 Train loss: 0.712517 Train acc: 0.687012\n",
      "Epoch: 13/140 Iteration: 1190 Train loss: 0.668759 Train acc: 0.712402\n",
      "Epoch: 14/140 Iteration: 1195 Train loss: 0.671727 Train acc: 0.732422\n",
      "Epoch: 14/140 Iteration: 1200 Train loss: 0.572525 Train acc: 0.784668\n",
      "Epoch: 14/140 Iteration: 1200 Validation loss: 1.643152 Validation acc: 0.376881\n",
      "Epoch: 14/140 Iteration: 1205 Train loss: 0.530248 Train acc: 0.794922\n",
      "Epoch: 14/140 Iteration: 1210 Train loss: 0.484967 Train acc: 0.811523\n",
      "Epoch: 14/140 Iteration: 1215 Train loss: 0.613440 Train acc: 0.747559\n",
      "Epoch: 14/140 Iteration: 1220 Train loss: 0.456968 Train acc: 0.826172\n",
      "Epoch: 14/140 Iteration: 1225 Train loss: 0.331723 Train acc: 0.886719\n",
      "Epoch: 14/140 Iteration: 1230 Train loss: 0.485223 Train acc: 0.816895\n",
      "Epoch: 14/140 Iteration: 1235 Train loss: 0.587024 Train acc: 0.763672\n",
      "Epoch: 14/140 Iteration: 1240 Train loss: 0.485255 Train acc: 0.820312\n",
      "Epoch: 14/140 Iteration: 1240 Validation loss: 1.802153 Validation acc: 0.371309\n",
      "Epoch: 14/140 Iteration: 1245 Train loss: 0.620971 Train acc: 0.752441\n",
      "Epoch: 14/140 Iteration: 1250 Train loss: 0.624291 Train acc: 0.739258\n",
      "Epoch: 14/140 Iteration: 1255 Train loss: 0.632052 Train acc: 0.746094\n",
      "Epoch: 14/140 Iteration: 1260 Train loss: 0.754803 Train acc: 0.675293\n",
      "Epoch: 14/140 Iteration: 1265 Train loss: 0.742697 Train acc: 0.627441\n",
      "Epoch: 14/140 Iteration: 1270 Train loss: 0.761152 Train acc: 0.650879\n",
      "Epoch: 14/140 Iteration: 1275 Train loss: 0.699981 Train acc: 0.679199\n",
      "Epoch: 15/140 Iteration: 1280 Train loss: 0.662309 Train acc: 0.727539\n",
      "Epoch: 15/140 Iteration: 1280 Validation loss: 1.714643 Validation acc: 0.345531\n",
      "Epoch: 15/140 Iteration: 1285 Train loss: 0.619881 Train acc: 0.756836\n",
      "Epoch: 15/140 Iteration: 1290 Train loss: 0.566097 Train acc: 0.790039\n",
      "Epoch: 15/140 Iteration: 1295 Train loss: 0.509589 Train acc: 0.809082\n",
      "Epoch: 15/140 Iteration: 1300 Train loss: 0.569119 Train acc: 0.764160\n",
      "Epoch: 15/140 Iteration: 1305 Train loss: 0.449273 Train acc: 0.819336\n",
      "Epoch: 15/140 Iteration: 1310 Train loss: 0.346755 Train acc: 0.869629\n",
      "Epoch: 15/140 Iteration: 1315 Train loss: 0.470253 Train acc: 0.812988\n",
      "Epoch: 15/140 Iteration: 1320 Train loss: 0.571613 Train acc: 0.770996\n",
      "Epoch: 15/140 Iteration: 1320 Validation loss: 1.751625 Validation acc: 0.372515\n",
      "Epoch: 15/140 Iteration: 1325 Train loss: 0.524760 Train acc: 0.806641\n",
      "Epoch: 15/140 Iteration: 1330 Train loss: 0.675545 Train acc: 0.730469\n",
      "Epoch: 15/140 Iteration: 1335 Train loss: 0.622390 Train acc: 0.731445\n",
      "Epoch: 15/140 Iteration: 1340 Train loss: 0.646076 Train acc: 0.740234\n",
      "Epoch: 15/140 Iteration: 1345 Train loss: 0.717306 Train acc: 0.699707\n",
      "Epoch: 15/140 Iteration: 1350 Train loss: 0.711963 Train acc: 0.664062\n",
      "Epoch: 15/140 Iteration: 1355 Train loss: 0.701336 Train acc: 0.696777\n",
      "Epoch: 15/140 Iteration: 1360 Train loss: 0.639750 Train acc: 0.735352\n",
      "Epoch: 15/140 Iteration: 1360 Validation loss: 1.716268 Validation acc: 0.371237\n",
      "Epoch: 16/140 Iteration: 1365 Train loss: 0.647128 Train acc: 0.729004\n",
      "Epoch: 16/140 Iteration: 1370 Train loss: 0.603401 Train acc: 0.763672\n",
      "Epoch: 16/140 Iteration: 1375 Train loss: 0.619231 Train acc: 0.756836\n",
      "Epoch: 16/140 Iteration: 1380 Train loss: 0.489428 Train acc: 0.817383\n",
      "Epoch: 16/140 Iteration: 1385 Train loss: 0.570259 Train acc: 0.770020\n",
      "Epoch: 16/140 Iteration: 1390 Train loss: 0.416314 Train acc: 0.840820\n",
      "Epoch: 16/140 Iteration: 1395 Train loss: 0.360417 Train acc: 0.870117\n",
      "Epoch: 16/140 Iteration: 1400 Train loss: 0.458247 Train acc: 0.809570\n",
      "Epoch: 16/140 Iteration: 1400 Validation loss: 1.765920 Validation acc: 0.353559\n",
      "Epoch: 16/140 Iteration: 1405 Train loss: 0.559692 Train acc: 0.785645\n",
      "Epoch: 16/140 Iteration: 1410 Train loss: 0.502578 Train acc: 0.825195\n",
      "Epoch: 16/140 Iteration: 1415 Train loss: 0.673614 Train acc: 0.737305\n",
      "Epoch: 16/140 Iteration: 1420 Train loss: 0.731953 Train acc: 0.687500\n",
      "Epoch: 16/140 Iteration: 1425 Train loss: 0.714105 Train acc: 0.697754\n",
      "Epoch: 16/140 Iteration: 1430 Train loss: 0.789051 Train acc: 0.654785\n",
      "Epoch: 16/140 Iteration: 1435 Train loss: 0.697261 Train acc: 0.675781\n",
      "Epoch: 16/140 Iteration: 1440 Train loss: 0.742958 Train acc: 0.662598\n",
      "Epoch: 16/140 Iteration: 1440 Validation loss: 1.738800 Validation acc: 0.364430\n",
      "Epoch: 16/140 Iteration: 1445 Train loss: 0.755319 Train acc: 0.678223\n",
      "Epoch: 17/140 Iteration: 1450 Train loss: 0.648484 Train acc: 0.730957\n",
      "Epoch: 17/140 Iteration: 1455 Train loss: 0.582118 Train acc: 0.790039\n",
      "Epoch: 17/140 Iteration: 1460 Train loss: 0.570252 Train acc: 0.777344\n",
      "Epoch: 17/140 Iteration: 1465 Train loss: 0.496015 Train acc: 0.807129\n",
      "Epoch: 17/140 Iteration: 1470 Train loss: 0.559193 Train acc: 0.778809\n",
      "Epoch: 17/140 Iteration: 1475 Train loss: 0.455013 Train acc: 0.829590\n",
      "Epoch: 17/140 Iteration: 1480 Train loss: 0.335262 Train acc: 0.876465\n",
      "Epoch: 17/140 Iteration: 1480 Validation loss: 1.754025 Validation acc: 0.365005\n",
      "Epoch: 17/140 Iteration: 1485 Train loss: 0.458938 Train acc: 0.810059\n",
      "Epoch: 17/140 Iteration: 1490 Train loss: 0.565426 Train acc: 0.774902\n",
      "Epoch: 17/140 Iteration: 1495 Train loss: 0.480672 Train acc: 0.830566\n",
      "Epoch: 17/140 Iteration: 1500 Train loss: 0.651111 Train acc: 0.748047\n",
      "Epoch: 17/140 Iteration: 1505 Train loss: 0.763011 Train acc: 0.666504\n",
      "Epoch: 17/140 Iteration: 1510 Train loss: 0.692791 Train acc: 0.698242\n",
      "Epoch: 17/140 Iteration: 1515 Train loss: 0.784410 Train acc: 0.656250\n",
      "Epoch: 17/140 Iteration: 1520 Train loss: 0.715780 Train acc: 0.655762\n",
      "Epoch: 17/140 Iteration: 1520 Validation loss: 1.571658 Validation acc: 0.391472\n",
      "Epoch: 17/140 Iteration: 1525 Train loss: 0.666695 Train acc: 0.714355\n",
      "Epoch: 17/140 Iteration: 1530 Train loss: 0.672538 Train acc: 0.700195\n",
      "Epoch: 18/140 Iteration: 1535 Train loss: 0.725785 Train acc: 0.686523\n",
      "Epoch: 18/140 Iteration: 1540 Train loss: 0.609890 Train acc: 0.762695\n",
      "Epoch: 18/140 Iteration: 1545 Train loss: 0.517401 Train acc: 0.805664\n",
      "Epoch: 18/140 Iteration: 1550 Train loss: 0.518862 Train acc: 0.794922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18/140 Iteration: 1555 Train loss: 0.592841 Train acc: 0.748535\n",
      "Epoch: 18/140 Iteration: 1560 Train loss: 0.406493 Train acc: 0.855469\n",
      "Epoch: 18/140 Iteration: 1560 Validation loss: 1.783611 Validation acc: 0.342572\n",
      "Epoch: 18/140 Iteration: 1565 Train loss: 0.373433 Train acc: 0.858398\n",
      "Epoch: 18/140 Iteration: 1570 Train loss: 0.467694 Train acc: 0.808105\n",
      "Epoch: 18/140 Iteration: 1575 Train loss: 0.522587 Train acc: 0.784180\n",
      "Epoch: 18/140 Iteration: 1580 Train loss: 0.474581 Train acc: 0.838867\n",
      "Epoch: 18/140 Iteration: 1585 Train loss: 0.682292 Train acc: 0.719238\n",
      "Epoch: 18/140 Iteration: 1590 Train loss: 0.725848 Train acc: 0.699219\n",
      "Epoch: 18/140 Iteration: 1595 Train loss: 0.688408 Train acc: 0.713379\n",
      "Epoch: 18/140 Iteration: 1600 Train loss: 0.674450 Train acc: 0.697266\n",
      "Epoch: 18/140 Iteration: 1600 Validation loss: 1.681258 Validation acc: 0.379509\n",
      "Epoch: 18/140 Iteration: 1605 Train loss: 0.755679 Train acc: 0.637207\n",
      "Epoch: 18/140 Iteration: 1610 Train loss: 0.739693 Train acc: 0.674316\n",
      "Epoch: 18/140 Iteration: 1615 Train loss: 0.596584 Train acc: 0.744141\n",
      "Epoch: 19/140 Iteration: 1620 Train loss: 0.650187 Train acc: 0.737793\n",
      "Epoch: 19/140 Iteration: 1625 Train loss: 0.599759 Train acc: 0.772461\n",
      "Epoch: 19/140 Iteration: 1630 Train loss: 0.539122 Train acc: 0.791016\n",
      "Epoch: 19/140 Iteration: 1635 Train loss: 0.468783 Train acc: 0.824219\n",
      "Epoch: 19/140 Iteration: 1640 Train loss: 0.580805 Train acc: 0.764160\n",
      "Epoch: 19/140 Iteration: 1640 Validation loss: 1.760016 Validation acc: 0.355871\n",
      "Epoch: 19/140 Iteration: 1645 Train loss: 0.440129 Train acc: 0.833496\n",
      "Epoch: 19/140 Iteration: 1650 Train loss: 0.331348 Train acc: 0.876465\n",
      "Epoch: 19/140 Iteration: 1655 Train loss: 0.468884 Train acc: 0.801758\n",
      "Epoch: 19/140 Iteration: 1660 Train loss: 0.483354 Train acc: 0.811523\n",
      "Epoch: 19/140 Iteration: 1665 Train loss: 0.448119 Train acc: 0.859863\n",
      "Epoch: 19/140 Iteration: 1670 Train loss: 0.639828 Train acc: 0.733398\n",
      "Epoch: 19/140 Iteration: 1675 Train loss: 0.674698 Train acc: 0.726074\n",
      "Epoch: 19/140 Iteration: 1680 Train loss: 0.693115 Train acc: 0.711426\n",
      "Epoch: 19/140 Iteration: 1680 Validation loss: 1.787274 Validation acc: 0.352711\n",
      "Epoch: 19/140 Iteration: 1685 Train loss: 0.767797 Train acc: 0.628418\n",
      "Epoch: 19/140 Iteration: 1690 Train loss: 0.779899 Train acc: 0.633789\n",
      "Epoch: 19/140 Iteration: 1695 Train loss: 0.764411 Train acc: 0.688965\n",
      "Epoch: 19/140 Iteration: 1700 Train loss: 0.839370 Train acc: 0.604004\n",
      "Epoch: 20/140 Iteration: 1705 Train loss: 0.622969 Train acc: 0.747070\n",
      "Epoch: 20/140 Iteration: 1710 Train loss: 0.575418 Train acc: 0.770996\n",
      "Epoch: 20/140 Iteration: 1715 Train loss: 0.552975 Train acc: 0.791992\n",
      "Epoch: 20/140 Iteration: 1720 Train loss: 0.461540 Train acc: 0.816406\n",
      "Epoch: 20/140 Iteration: 1720 Validation loss: 1.776796 Validation acc: 0.346191\n",
      "Epoch: 20/140 Iteration: 1725 Train loss: 0.555541 Train acc: 0.776367\n",
      "Epoch: 20/140 Iteration: 1730 Train loss: 0.499108 Train acc: 0.806641\n",
      "Epoch: 20/140 Iteration: 1735 Train loss: 0.358831 Train acc: 0.874023\n",
      "Epoch: 20/140 Iteration: 1740 Train loss: 0.443145 Train acc: 0.823242\n",
      "Epoch: 20/140 Iteration: 1745 Train loss: 0.474983 Train acc: 0.818359\n",
      "Epoch: 20/140 Iteration: 1750 Train loss: 0.421064 Train acc: 0.863770\n",
      "Epoch: 20/140 Iteration: 1755 Train loss: 0.641357 Train acc: 0.739258\n",
      "Epoch: 20/140 Iteration: 1760 Train loss: 0.668975 Train acc: 0.718750\n",
      "Epoch: 20/140 Iteration: 1760 Validation loss: 1.842985 Validation acc: 0.309800\n",
      "Epoch: 20/140 Iteration: 1765 Train loss: 0.701676 Train acc: 0.695801\n",
      "Epoch: 20/140 Iteration: 1770 Train loss: 0.755781 Train acc: 0.650879\n",
      "Epoch: 20/140 Iteration: 1775 Train loss: 0.767380 Train acc: 0.632324\n",
      "Epoch: 20/140 Iteration: 1780 Train loss: 0.813002 Train acc: 0.630859\n",
      "Epoch: 20/140 Iteration: 1785 Train loss: 0.894048 Train acc: 0.589355\n",
      "Epoch: 21/140 Iteration: 1790 Train loss: 0.693054 Train acc: 0.703613\n",
      "Epoch: 21/140 Iteration: 1795 Train loss: 0.577204 Train acc: 0.780762\n",
      "Epoch: 21/140 Iteration: 1800 Train loss: 0.589551 Train acc: 0.768066\n",
      "Epoch: 21/140 Iteration: 1800 Validation loss: 1.865994 Validation acc: 0.315214\n",
      "Epoch: 21/140 Iteration: 1805 Train loss: 0.492887 Train acc: 0.812500\n",
      "Epoch: 21/140 Iteration: 1810 Train loss: 0.539421 Train acc: 0.797363\n",
      "Epoch: 21/140 Iteration: 1815 Train loss: 0.459541 Train acc: 0.819336\n",
      "Epoch: 21/140 Iteration: 1820 Train loss: 0.358022 Train acc: 0.879395\n",
      "Epoch: 21/140 Iteration: 1825 Train loss: 0.477795 Train acc: 0.813965\n",
      "Epoch: 21/140 Iteration: 1830 Train loss: 0.444881 Train acc: 0.836914\n",
      "Epoch: 21/140 Iteration: 1835 Train loss: 0.451738 Train acc: 0.833984\n",
      "Epoch: 21/140 Iteration: 1840 Train loss: 0.643614 Train acc: 0.740234\n",
      "Epoch: 21/140 Iteration: 1840 Validation loss: 1.817331 Validation acc: 0.314554\n",
      "Epoch: 21/140 Iteration: 1845 Train loss: 0.672002 Train acc: 0.701660\n",
      "Epoch: 21/140 Iteration: 1850 Train loss: 0.723550 Train acc: 0.692871\n",
      "Epoch: 21/140 Iteration: 1855 Train loss: 0.778590 Train acc: 0.629395\n",
      "Epoch: 21/140 Iteration: 1860 Train loss: 0.743416 Train acc: 0.679199\n",
      "Epoch: 21/140 Iteration: 1865 Train loss: 0.781554 Train acc: 0.662109\n",
      "Epoch: 21/140 Iteration: 1870 Train loss: 0.926371 Train acc: 0.536133\n",
      "Epoch: 22/140 Iteration: 1875 Train loss: 0.716218 Train acc: 0.690918\n",
      "Epoch: 22/140 Iteration: 1880 Train loss: 0.558162 Train acc: 0.791016\n",
      "Epoch: 22/140 Iteration: 1880 Validation loss: 1.716727 Validation acc: 0.380486\n",
      "Epoch: 22/140 Iteration: 1885 Train loss: 0.530931 Train acc: 0.792969\n",
      "Epoch: 22/140 Iteration: 1890 Train loss: 0.495011 Train acc: 0.799316\n",
      "Epoch: 22/140 Iteration: 1895 Train loss: 0.507625 Train acc: 0.796387\n",
      "Epoch: 22/140 Iteration: 1900 Train loss: 0.432841 Train acc: 0.842285\n",
      "Epoch: 22/140 Iteration: 1905 Train loss: 0.326119 Train acc: 0.885254\n",
      "Epoch: 22/140 Iteration: 1910 Train loss: 0.442328 Train acc: 0.820312\n",
      "Epoch: 22/140 Iteration: 1915 Train loss: 0.483909 Train acc: 0.803223\n",
      "Epoch: 22/140 Iteration: 1920 Train loss: 0.454305 Train acc: 0.838867\n",
      "Epoch: 22/140 Iteration: 1920 Validation loss: 1.853041 Validation acc: 0.333166\n",
      "Epoch: 22/140 Iteration: 1925 Train loss: 0.629616 Train acc: 0.735352\n",
      "Epoch: 22/140 Iteration: 1930 Train loss: 0.690900 Train acc: 0.697754\n",
      "Epoch: 22/140 Iteration: 1935 Train loss: 0.702368 Train acc: 0.699219\n",
      "Epoch: 22/140 Iteration: 1940 Train loss: 0.794659 Train acc: 0.630859\n",
      "Epoch: 22/140 Iteration: 1945 Train loss: 0.755902 Train acc: 0.652344\n",
      "Epoch: 22/140 Iteration: 1950 Train loss: 0.738517 Train acc: 0.687988\n",
      "Epoch: 22/140 Iteration: 1955 Train loss: 0.847744 Train acc: 0.575684\n",
      "Epoch: 23/140 Iteration: 1960 Train loss: 0.685207 Train acc: 0.706543\n",
      "Epoch: 23/140 Iteration: 1960 Validation loss: 1.713877 Validation acc: 0.378964\n",
      "Epoch: 23/140 Iteration: 1965 Train loss: 0.537812 Train acc: 0.790527\n",
      "Epoch: 23/140 Iteration: 1970 Train loss: 0.555402 Train acc: 0.793945\n",
      "Epoch: 23/140 Iteration: 1975 Train loss: 0.428867 Train acc: 0.835938\n",
      "Epoch: 23/140 Iteration: 1980 Train loss: 0.520475 Train acc: 0.798828\n",
      "Epoch: 23/140 Iteration: 1985 Train loss: 0.464843 Train acc: 0.818848\n",
      "Epoch: 23/140 Iteration: 1990 Train loss: 0.443359 Train acc: 0.825684\n",
      "Epoch: 23/140 Iteration: 1995 Train loss: 0.475894 Train acc: 0.796875\n",
      "Epoch: 23/140 Iteration: 2000 Train loss: 0.486542 Train acc: 0.815430\n",
      "Epoch: 23/140 Iteration: 2000 Validation loss: 1.774246 Validation acc: 0.337646\n",
      "Epoch: 23/140 Iteration: 2005 Train loss: 0.471520 Train acc: 0.829590\n",
      "Epoch: 23/140 Iteration: 2010 Train loss: 0.665931 Train acc: 0.739746\n",
      "Epoch: 23/140 Iteration: 2015 Train loss: 0.857790 Train acc: 0.607910\n",
      "Epoch: 23/140 Iteration: 2020 Train loss: 0.665508 Train acc: 0.732422\n",
      "Epoch: 23/140 Iteration: 2025 Train loss: 0.739680 Train acc: 0.651855\n",
      "Epoch: 23/140 Iteration: 2030 Train loss: 0.699626 Train acc: 0.708008\n",
      "Epoch: 23/140 Iteration: 2035 Train loss: 0.707575 Train acc: 0.703125\n",
      "Epoch: 23/140 Iteration: 2040 Train loss: 0.785430 Train acc: 0.619629\n",
      "Epoch: 23/140 Iteration: 2040 Validation loss: 1.541037 Validation acc: 0.388026\n",
      "Epoch: 24/140 Iteration: 2045 Train loss: 0.668262 Train acc: 0.716309\n",
      "Epoch: 24/140 Iteration: 2050 Train loss: 0.590927 Train acc: 0.760254\n",
      "Epoch: 24/140 Iteration: 2055 Train loss: 0.572504 Train acc: 0.769531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24/140 Iteration: 2060 Train loss: 0.452274 Train acc: 0.823730\n",
      "Epoch: 24/140 Iteration: 2065 Train loss: 0.530881 Train acc: 0.799316\n",
      "Epoch: 24/140 Iteration: 2070 Train loss: 0.407210 Train acc: 0.845703\n",
      "Epoch: 24/140 Iteration: 2075 Train loss: 0.313774 Train acc: 0.888672\n",
      "Epoch: 24/140 Iteration: 2080 Train loss: 0.437482 Train acc: 0.825195\n",
      "Epoch: 24/140 Iteration: 2080 Validation loss: 1.926260 Validation acc: 0.343089\n",
      "Epoch: 24/140 Iteration: 2085 Train loss: 0.483847 Train acc: 0.822754\n",
      "Epoch: 24/140 Iteration: 2090 Train loss: 0.418723 Train acc: 0.850586\n",
      "Epoch: 24/140 Iteration: 2095 Train loss: 0.611630 Train acc: 0.761719\n",
      "Epoch: 24/140 Iteration: 2100 Train loss: 0.750052 Train acc: 0.670410\n",
      "Epoch: 24/140 Iteration: 2105 Train loss: 0.659727 Train acc: 0.726074\n",
      "Epoch: 24/140 Iteration: 2110 Train loss: 0.763657 Train acc: 0.658203\n",
      "Epoch: 24/140 Iteration: 2115 Train loss: 0.687772 Train acc: 0.710938\n",
      "Epoch: 24/140 Iteration: 2120 Train loss: 0.697066 Train acc: 0.700195\n",
      "Epoch: 24/140 Iteration: 2120 Validation loss: 1.530036 Validation acc: 0.397116\n",
      "Epoch: 24/140 Iteration: 2125 Train loss: 0.722277 Train acc: 0.666992\n",
      "Epoch: 25/140 Iteration: 2130 Train loss: 0.649961 Train acc: 0.734375\n",
      "Epoch: 25/140 Iteration: 2135 Train loss: 0.575986 Train acc: 0.763184\n",
      "Epoch: 25/140 Iteration: 2140 Train loss: 0.493599 Train acc: 0.796875\n",
      "Epoch: 25/140 Iteration: 2145 Train loss: 0.445728 Train acc: 0.826660\n",
      "Epoch: 25/140 Iteration: 2150 Train loss: 0.523341 Train acc: 0.803711\n",
      "Epoch: 25/140 Iteration: 2155 Train loss: 0.458674 Train acc: 0.823730\n",
      "Epoch: 25/140 Iteration: 2160 Train loss: 0.308563 Train acc: 0.887695\n",
      "Epoch: 25/140 Iteration: 2160 Validation loss: 1.739281 Validation acc: 0.379294\n",
      "Epoch: 25/140 Iteration: 2165 Train loss: 0.434250 Train acc: 0.828125\n",
      "Epoch: 25/140 Iteration: 2170 Train loss: 0.476397 Train acc: 0.829590\n",
      "Epoch: 25/140 Iteration: 2175 Train loss: 0.438863 Train acc: 0.851074\n",
      "Epoch: 25/140 Iteration: 2180 Train loss: 0.625940 Train acc: 0.762207\n",
      "Epoch: 25/140 Iteration: 2185 Train loss: 0.780000 Train acc: 0.671875\n",
      "Epoch: 25/140 Iteration: 2190 Train loss: 0.667576 Train acc: 0.728027\n",
      "Epoch: 25/140 Iteration: 2195 Train loss: 0.733056 Train acc: 0.660156\n",
      "Epoch: 25/140 Iteration: 2200 Train loss: 0.701104 Train acc: 0.693848\n",
      "Epoch: 25/140 Iteration: 2200 Validation loss: 1.586848 Validation acc: 0.397605\n",
      "Epoch: 25/140 Iteration: 2205 Train loss: 0.683819 Train acc: 0.713379\n",
      "Epoch: 25/140 Iteration: 2210 Train loss: 0.769049 Train acc: 0.631348\n",
      "Epoch: 26/140 Iteration: 2215 Train loss: 0.659667 Train acc: 0.721191\n",
      "Epoch: 26/140 Iteration: 2220 Train loss: 0.617485 Train acc: 0.760742\n",
      "Epoch: 26/140 Iteration: 2225 Train loss: 0.512491 Train acc: 0.798340\n",
      "Epoch: 26/140 Iteration: 2230 Train loss: 0.439663 Train acc: 0.836426\n",
      "Epoch: 26/140 Iteration: 2235 Train loss: 0.542876 Train acc: 0.782715\n",
      "Epoch: 26/140 Iteration: 2240 Train loss: 0.405545 Train acc: 0.849121\n",
      "Epoch: 26/140 Iteration: 2240 Validation loss: 1.739367 Validation acc: 0.377355\n",
      "Epoch: 26/140 Iteration: 2245 Train loss: 0.300321 Train acc: 0.891113\n",
      "Epoch: 26/140 Iteration: 2250 Train loss: 0.448867 Train acc: 0.813477\n",
      "Epoch: 26/140 Iteration: 2255 Train loss: 0.484354 Train acc: 0.820312\n",
      "Epoch: 26/140 Iteration: 2260 Train loss: 0.407210 Train acc: 0.861816\n",
      "Epoch: 26/140 Iteration: 2265 Train loss: 0.590769 Train acc: 0.772461\n",
      "Epoch: 26/140 Iteration: 2270 Train loss: 0.686756 Train acc: 0.719238\n",
      "Epoch: 26/140 Iteration: 2275 Train loss: 0.668875 Train acc: 0.740723\n",
      "Epoch: 26/140 Iteration: 2280 Train loss: 0.758809 Train acc: 0.650391\n",
      "Epoch: 26/140 Iteration: 2280 Validation loss: 1.608596 Validation acc: 0.384019\n",
      "Epoch: 26/140 Iteration: 2285 Train loss: 0.724478 Train acc: 0.693848\n",
      "Epoch: 26/140 Iteration: 2290 Train loss: 0.691507 Train acc: 0.709961\n",
      "Epoch: 26/140 Iteration: 2295 Train loss: 0.828317 Train acc: 0.608887\n",
      "Epoch: 27/140 Iteration: 2300 Train loss: 0.642951 Train acc: 0.748047\n",
      "Epoch: 27/140 Iteration: 2305 Train loss: 0.589387 Train acc: 0.778809\n",
      "Epoch: 27/140 Iteration: 2310 Train loss: 0.500787 Train acc: 0.805664\n",
      "Epoch: 27/140 Iteration: 2315 Train loss: 0.438945 Train acc: 0.826660\n",
      "Epoch: 27/140 Iteration: 2320 Train loss: 0.555099 Train acc: 0.775879\n",
      "Epoch: 27/140 Iteration: 2320 Validation loss: 1.772809 Validation acc: 0.384464\n",
      "Epoch: 27/140 Iteration: 2325 Train loss: 0.428373 Train acc: 0.840332\n",
      "Epoch: 27/140 Iteration: 2330 Train loss: 0.317354 Train acc: 0.880371\n",
      "Epoch: 27/140 Iteration: 2335 Train loss: 0.442640 Train acc: 0.821777\n",
      "Epoch: 27/140 Iteration: 2340 Train loss: 0.451546 Train acc: 0.831543\n",
      "Epoch: 27/140 Iteration: 2345 Train loss: 0.380760 Train acc: 0.875000\n",
      "Epoch: 27/140 Iteration: 2350 Train loss: 0.592309 Train acc: 0.763672\n",
      "Epoch: 27/140 Iteration: 2355 Train loss: 0.649449 Train acc: 0.748047\n",
      "Epoch: 27/140 Iteration: 2360 Train loss: 0.645611 Train acc: 0.743652\n",
      "Epoch: 27/140 Iteration: 2360 Validation loss: 1.706972 Validation acc: 0.366398\n",
      "Epoch: 27/140 Iteration: 2365 Train loss: 0.727204 Train acc: 0.674805\n",
      "Epoch: 27/140 Iteration: 2370 Train loss: 0.721021 Train acc: 0.676270\n",
      "Epoch: 27/140 Iteration: 2375 Train loss: 0.694472 Train acc: 0.707520\n",
      "Epoch: 27/140 Iteration: 2380 Train loss: 0.725612 Train acc: 0.666016\n",
      "Epoch: 28/140 Iteration: 2385 Train loss: 0.572189 Train acc: 0.786621\n",
      "Epoch: 28/140 Iteration: 2390 Train loss: 0.592224 Train acc: 0.775391\n",
      "Epoch: 28/140 Iteration: 2395 Train loss: 0.497278 Train acc: 0.800293\n",
      "Epoch: 28/140 Iteration: 2400 Train loss: 0.465113 Train acc: 0.818359\n",
      "Epoch: 28/140 Iteration: 2400 Validation loss: 1.764098 Validation acc: 0.399457\n",
      "Epoch: 28/140 Iteration: 2405 Train loss: 0.586566 Train acc: 0.757324\n",
      "Epoch: 28/140 Iteration: 2410 Train loss: 0.410204 Train acc: 0.849121\n",
      "Epoch: 28/140 Iteration: 2415 Train loss: 0.310714 Train acc: 0.889160\n",
      "Epoch: 28/140 Iteration: 2420 Train loss: 0.425423 Train acc: 0.826172\n",
      "Epoch: 28/140 Iteration: 2425 Train loss: 0.486476 Train acc: 0.807129\n",
      "Epoch: 28/140 Iteration: 2430 Train loss: 0.390826 Train acc: 0.873535\n",
      "Epoch: 28/140 Iteration: 2435 Train loss: 0.585030 Train acc: 0.765625\n",
      "Epoch: 28/140 Iteration: 2440 Train loss: 0.618708 Train acc: 0.753418\n",
      "Epoch: 28/140 Iteration: 2440 Validation loss: 1.755722 Validation acc: 0.379754\n",
      "Epoch: 28/140 Iteration: 2445 Train loss: 0.666824 Train acc: 0.734863\n",
      "Epoch: 28/140 Iteration: 2450 Train loss: 0.744661 Train acc: 0.671875\n",
      "Epoch: 28/140 Iteration: 2455 Train loss: 0.753675 Train acc: 0.672852\n",
      "Epoch: 28/140 Iteration: 2460 Train loss: 0.659870 Train acc: 0.732910\n",
      "Epoch: 28/140 Iteration: 2465 Train loss: 0.766106 Train acc: 0.634766\n",
      "Epoch: 29/140 Iteration: 2470 Train loss: 0.593088 Train acc: 0.774902\n",
      "Epoch: 29/140 Iteration: 2475 Train loss: 0.556435 Train acc: 0.791504\n",
      "Epoch: 29/140 Iteration: 2480 Train loss: 0.501149 Train acc: 0.805176\n",
      "Epoch: 29/140 Iteration: 2480 Validation loss: 1.743437 Validation acc: 0.401238\n",
      "Epoch: 29/140 Iteration: 2485 Train loss: 0.437395 Train acc: 0.834473\n",
      "Epoch: 29/140 Iteration: 2490 Train loss: 0.540001 Train acc: 0.787109\n",
      "Epoch: 29/140 Iteration: 2495 Train loss: 0.383406 Train acc: 0.860352\n",
      "Epoch: 29/140 Iteration: 2500 Train loss: 0.295148 Train acc: 0.892578\n",
      "Epoch: 29/140 Iteration: 2505 Train loss: 0.392302 Train acc: 0.843262\n",
      "Epoch: 29/140 Iteration: 2510 Train loss: 0.468550 Train acc: 0.814453\n",
      "Epoch: 29/140 Iteration: 2515 Train loss: 0.434188 Train acc: 0.858398\n",
      "Epoch: 29/140 Iteration: 2520 Train loss: 0.564812 Train acc: 0.780273\n",
      "Epoch: 29/140 Iteration: 2520 Validation loss: 1.877595 Validation acc: 0.386589\n",
      "Epoch: 29/140 Iteration: 2525 Train loss: 0.619315 Train acc: 0.750977\n",
      "Epoch: 29/140 Iteration: 2530 Train loss: 0.649846 Train acc: 0.733398\n",
      "Epoch: 29/140 Iteration: 2535 Train loss: 0.747285 Train acc: 0.675293\n",
      "Epoch: 29/140 Iteration: 2540 Train loss: 0.770204 Train acc: 0.649414\n",
      "Epoch: 29/140 Iteration: 2545 Train loss: 0.659104 Train acc: 0.716797\n",
      "Epoch: 29/140 Iteration: 2550 Train loss: 0.701106 Train acc: 0.681152\n",
      "Epoch: 30/140 Iteration: 2555 Train loss: 0.578101 Train acc: 0.782227\n",
      "Epoch: 30/140 Iteration: 2560 Train loss: 0.553133 Train acc: 0.795898\n",
      "Epoch: 30/140 Iteration: 2560 Validation loss: 1.655971 Validation acc: 0.403507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30/140 Iteration: 2565 Train loss: 0.456690 Train acc: 0.823730\n",
      "Epoch: 30/140 Iteration: 2570 Train loss: 0.456993 Train acc: 0.823242\n",
      "Epoch: 30/140 Iteration: 2575 Train loss: 0.519782 Train acc: 0.808594\n",
      "Epoch: 30/140 Iteration: 2580 Train loss: 0.396200 Train acc: 0.857422\n",
      "Epoch: 30/140 Iteration: 2585 Train loss: 0.295519 Train acc: 0.894043\n",
      "Epoch: 30/140 Iteration: 2590 Train loss: 0.421777 Train acc: 0.838379\n",
      "Epoch: 30/140 Iteration: 2595 Train loss: 0.453508 Train acc: 0.827148\n",
      "Epoch: 30/140 Iteration: 2600 Train loss: 0.397132 Train acc: 0.877441\n",
      "Epoch: 30/140 Iteration: 2600 Validation loss: 1.784188 Validation acc: 0.379107\n",
      "Epoch: 30/140 Iteration: 2605 Train loss: 0.550589 Train acc: 0.781250\n",
      "Epoch: 30/140 Iteration: 2610 Train loss: 0.601070 Train acc: 0.752930\n",
      "Epoch: 30/140 Iteration: 2615 Train loss: 0.614426 Train acc: 0.761719\n",
      "Epoch: 30/140 Iteration: 2620 Train loss: 0.738903 Train acc: 0.667969\n",
      "Epoch: 30/140 Iteration: 2625 Train loss: 0.725596 Train acc: 0.678711\n",
      "Epoch: 30/140 Iteration: 2630 Train loss: 0.632161 Train acc: 0.735352\n",
      "Epoch: 30/140 Iteration: 2635 Train loss: 0.645371 Train acc: 0.704102\n",
      "Epoch: 31/140 Iteration: 2640 Train loss: 0.602162 Train acc: 0.768555\n",
      "Epoch: 31/140 Iteration: 2640 Validation loss: 1.592123 Validation acc: 0.403464\n",
      "Epoch: 31/140 Iteration: 2645 Train loss: 0.531787 Train acc: 0.792480\n",
      "Epoch: 31/140 Iteration: 2650 Train loss: 0.487161 Train acc: 0.808594\n",
      "Epoch: 31/140 Iteration: 2655 Train loss: 0.447023 Train acc: 0.830078\n",
      "Epoch: 31/140 Iteration: 2660 Train loss: 0.530854 Train acc: 0.794922\n",
      "Epoch: 31/140 Iteration: 2665 Train loss: 0.396344 Train acc: 0.859375\n",
      "Epoch: 31/140 Iteration: 2670 Train loss: 0.296158 Train acc: 0.888184\n",
      "Epoch: 31/140 Iteration: 2675 Train loss: 0.390529 Train acc: 0.851074\n",
      "Epoch: 31/140 Iteration: 2680 Train loss: 0.421075 Train acc: 0.838867\n",
      "Epoch: 31/140 Iteration: 2680 Validation loss: 1.810804 Validation acc: 0.390668\n",
      "Epoch: 31/140 Iteration: 2685 Train loss: 0.404993 Train acc: 0.854492\n",
      "Epoch: 31/140 Iteration: 2690 Train loss: 0.577848 Train acc: 0.777832\n",
      "Epoch: 31/140 Iteration: 2695 Train loss: 0.582715 Train acc: 0.774414\n",
      "Epoch: 31/140 Iteration: 2700 Train loss: 0.587903 Train acc: 0.770996\n",
      "Epoch: 31/140 Iteration: 2705 Train loss: 0.719213 Train acc: 0.674316\n",
      "Epoch: 31/140 Iteration: 2710 Train loss: 0.744907 Train acc: 0.680664\n",
      "Epoch: 31/140 Iteration: 2715 Train loss: 0.641437 Train acc: 0.729980\n",
      "Epoch: 31/140 Iteration: 2720 Train loss: 0.622286 Train acc: 0.721191\n",
      "Epoch: 31/140 Iteration: 2720 Validation loss: 1.720061 Validation acc: 0.382425\n",
      "Epoch: 32/140 Iteration: 2725 Train loss: 0.547792 Train acc: 0.789062\n",
      "Epoch: 32/140 Iteration: 2730 Train loss: 0.507354 Train acc: 0.812012\n",
      "Epoch: 32/140 Iteration: 2735 Train loss: 0.488269 Train acc: 0.794434\n",
      "Epoch: 32/140 Iteration: 2740 Train loss: 0.421735 Train acc: 0.833496\n",
      "Epoch: 32/140 Iteration: 2745 Train loss: 0.488347 Train acc: 0.809082\n",
      "Epoch: 32/140 Iteration: 2750 Train loss: 0.382068 Train acc: 0.858398\n",
      "Epoch: 32/140 Iteration: 2755 Train loss: 0.296690 Train acc: 0.892090\n",
      "Epoch: 32/140 Iteration: 2760 Train loss: 0.411142 Train acc: 0.841797\n",
      "Epoch: 32/140 Iteration: 2760 Validation loss: 1.880296 Validation acc: 0.382109\n",
      "Epoch: 32/140 Iteration: 2765 Train loss: 0.450957 Train acc: 0.836426\n",
      "Epoch: 32/140 Iteration: 2770 Train loss: 0.396196 Train acc: 0.871094\n",
      "Epoch: 32/140 Iteration: 2775 Train loss: 0.569643 Train acc: 0.781738\n",
      "Epoch: 32/140 Iteration: 2780 Train loss: 0.536654 Train acc: 0.805664\n",
      "Epoch: 32/140 Iteration: 2785 Train loss: 0.579637 Train acc: 0.774414\n",
      "Epoch: 32/140 Iteration: 2790 Train loss: 0.652127 Train acc: 0.712402\n",
      "Epoch: 32/140 Iteration: 2795 Train loss: 0.680596 Train acc: 0.716797\n",
      "Epoch: 32/140 Iteration: 2800 Train loss: 0.641356 Train acc: 0.726562\n",
      "Epoch: 32/140 Iteration: 2800 Validation loss: 1.802952 Validation acc: 0.391530\n",
      "Epoch: 32/140 Iteration: 2805 Train loss: 0.581885 Train acc: 0.746094\n",
      "Epoch: 33/140 Iteration: 2810 Train loss: 0.588014 Train acc: 0.773438\n",
      "Epoch: 33/140 Iteration: 2815 Train loss: 0.496421 Train acc: 0.820801\n",
      "Epoch: 33/140 Iteration: 2820 Train loss: 0.455118 Train acc: 0.820801\n",
      "Epoch: 33/140 Iteration: 2825 Train loss: 0.434154 Train acc: 0.838867\n",
      "Epoch: 33/140 Iteration: 2830 Train loss: 0.517979 Train acc: 0.803223\n",
      "Epoch: 33/140 Iteration: 2835 Train loss: 0.413434 Train acc: 0.838867\n",
      "Epoch: 33/140 Iteration: 2840 Train loss: 0.299362 Train acc: 0.894043\n",
      "Epoch: 33/140 Iteration: 2840 Validation loss: 1.782449 Validation acc: 0.371367\n",
      "Epoch: 33/140 Iteration: 2845 Train loss: 0.377227 Train acc: 0.849609\n",
      "Epoch: 33/140 Iteration: 2850 Train loss: 0.447702 Train acc: 0.832031\n",
      "Epoch: 33/140 Iteration: 2855 Train loss: 0.405031 Train acc: 0.848633\n",
      "Epoch: 33/140 Iteration: 2860 Train loss: 0.568596 Train acc: 0.773438\n",
      "Epoch: 33/140 Iteration: 2865 Train loss: 0.531090 Train acc: 0.803711\n",
      "Epoch: 33/140 Iteration: 2870 Train loss: 0.563469 Train acc: 0.789062\n",
      "Epoch: 33/140 Iteration: 2875 Train loss: 0.656706 Train acc: 0.721680\n",
      "Epoch: 33/140 Iteration: 2880 Train loss: 0.646224 Train acc: 0.726074\n",
      "Epoch: 33/140 Iteration: 2880 Validation loss: 1.821483 Validation acc: 0.391027\n",
      "Epoch: 33/140 Iteration: 2885 Train loss: 0.598930 Train acc: 0.745117\n",
      "Epoch: 33/140 Iteration: 2890 Train loss: 0.548345 Train acc: 0.775391\n",
      "Epoch: 34/140 Iteration: 2895 Train loss: 0.548757 Train acc: 0.781738\n",
      "Epoch: 34/140 Iteration: 2900 Train loss: 0.485418 Train acc: 0.829102\n",
      "Epoch: 34/140 Iteration: 2905 Train loss: 0.448681 Train acc: 0.822266\n",
      "Epoch: 34/140 Iteration: 2910 Train loss: 0.410560 Train acc: 0.843750\n",
      "Epoch: 34/140 Iteration: 2915 Train loss: 0.507468 Train acc: 0.801758\n",
      "Epoch: 34/140 Iteration: 2920 Train loss: 0.374120 Train acc: 0.861816\n",
      "Epoch: 34/140 Iteration: 2920 Validation loss: 1.820533 Validation acc: 0.362132\n",
      "Epoch: 34/140 Iteration: 2925 Train loss: 0.303692 Train acc: 0.885254\n",
      "Epoch: 34/140 Iteration: 2930 Train loss: 0.378911 Train acc: 0.848145\n",
      "Epoch: 34/140 Iteration: 2935 Train loss: 0.442086 Train acc: 0.831055\n",
      "Epoch: 34/140 Iteration: 2940 Train loss: 0.392169 Train acc: 0.864258\n",
      "Epoch: 34/140 Iteration: 2945 Train loss: 0.568946 Train acc: 0.771484\n",
      "Epoch: 34/140 Iteration: 2950 Train loss: 0.516087 Train acc: 0.811523\n",
      "Epoch: 34/140 Iteration: 2955 Train loss: 0.575404 Train acc: 0.791504\n",
      "Epoch: 34/140 Iteration: 2960 Train loss: 0.658042 Train acc: 0.721191\n",
      "Epoch: 34/140 Iteration: 2960 Validation loss: 1.909417 Validation acc: 0.358068\n",
      "Epoch: 34/140 Iteration: 2965 Train loss: 0.671599 Train acc: 0.723633\n",
      "Epoch: 34/140 Iteration: 2970 Train loss: 0.580451 Train acc: 0.769043\n",
      "Epoch: 34/140 Iteration: 2975 Train loss: 0.568167 Train acc: 0.768066\n",
      "Epoch: 35/140 Iteration: 2980 Train loss: 0.575100 Train acc: 0.777832\n",
      "Epoch: 35/140 Iteration: 2985 Train loss: 0.500375 Train acc: 0.813477\n",
      "Epoch: 35/140 Iteration: 2990 Train loss: 0.434144 Train acc: 0.833008\n",
      "Epoch: 35/140 Iteration: 2995 Train loss: 0.430101 Train acc: 0.839844\n",
      "Epoch: 35/140 Iteration: 3000 Train loss: 0.499090 Train acc: 0.810059\n",
      "Epoch: 35/140 Iteration: 3000 Validation loss: 1.824243 Validation acc: 0.351706\n",
      "Epoch: 35/140 Iteration: 3005 Train loss: 0.381879 Train acc: 0.855469\n",
      "Epoch: 35/140 Iteration: 3010 Train loss: 0.285745 Train acc: 0.896973\n",
      "Epoch: 35/140 Iteration: 3015 Train loss: 0.377432 Train acc: 0.859863\n",
      "Epoch: 35/140 Iteration: 3020 Train loss: 0.401410 Train acc: 0.855957\n",
      "Epoch: 35/140 Iteration: 3025 Train loss: 0.380547 Train acc: 0.867676\n",
      "Epoch: 35/140 Iteration: 3030 Train loss: 0.556008 Train acc: 0.785156\n",
      "Epoch: 35/140 Iteration: 3035 Train loss: 0.533158 Train acc: 0.796875\n",
      "Epoch: 35/140 Iteration: 3040 Train loss: 0.530568 Train acc: 0.793945\n",
      "Epoch: 35/140 Iteration: 3040 Validation loss: 1.911397 Validation acc: 0.352381\n",
      "Epoch: 35/140 Iteration: 3045 Train loss: 0.657834 Train acc: 0.711914\n",
      "Epoch: 35/140 Iteration: 3050 Train loss: 0.646221 Train acc: 0.739746\n",
      "Epoch: 35/140 Iteration: 3055 Train loss: 0.560325 Train acc: 0.764160\n",
      "Epoch: 35/140 Iteration: 3060 Train loss: 0.566465 Train acc: 0.764160\n",
      "Epoch: 36/140 Iteration: 3065 Train loss: 0.583032 Train acc: 0.769531\n",
      "Epoch: 36/140 Iteration: 3070 Train loss: 0.499318 Train acc: 0.812500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36/140 Iteration: 3075 Train loss: 0.444511 Train acc: 0.827637\n",
      "Epoch: 36/140 Iteration: 3080 Train loss: 0.465133 Train acc: 0.821289\n",
      "Epoch: 36/140 Iteration: 3080 Validation loss: 1.804720 Validation acc: 0.350672\n",
      "Epoch: 36/140 Iteration: 3085 Train loss: 0.481774 Train acc: 0.820312\n",
      "Epoch: 36/140 Iteration: 3090 Train loss: 0.357271 Train acc: 0.868164\n",
      "Epoch: 36/140 Iteration: 3095 Train loss: 0.296618 Train acc: 0.896973\n",
      "Epoch: 36/140 Iteration: 3100 Train loss: 0.376960 Train acc: 0.853516\n",
      "Epoch: 36/140 Iteration: 3105 Train loss: 0.426671 Train acc: 0.837402\n",
      "Epoch: 36/140 Iteration: 3110 Train loss: 0.369497 Train acc: 0.869141\n",
      "Epoch: 36/140 Iteration: 3115 Train loss: 0.551906 Train acc: 0.779785\n",
      "Epoch: 36/140 Iteration: 3120 Train loss: 0.539356 Train acc: 0.795410\n",
      "Epoch: 36/140 Iteration: 3120 Validation loss: 1.907542 Validation acc: 0.340389\n",
      "Epoch: 36/140 Iteration: 3125 Train loss: 0.551386 Train acc: 0.789062\n",
      "Epoch: 36/140 Iteration: 3130 Train loss: 0.634714 Train acc: 0.727539\n",
      "Epoch: 36/140 Iteration: 3135 Train loss: 0.643846 Train acc: 0.750000\n",
      "Epoch: 36/140 Iteration: 3140 Train loss: 0.609241 Train acc: 0.749023\n",
      "Epoch: 36/140 Iteration: 3145 Train loss: 0.513346 Train acc: 0.791992\n",
      "Epoch: 37/140 Iteration: 3150 Train loss: 0.626707 Train acc: 0.763672\n",
      "Epoch: 37/140 Iteration: 3155 Train loss: 0.488225 Train acc: 0.817383\n",
      "Epoch: 37/140 Iteration: 3160 Train loss: 0.446522 Train acc: 0.818848\n",
      "Epoch: 37/140 Iteration: 3160 Validation loss: 2.003959 Validation acc: 0.341165\n",
      "Epoch: 37/140 Iteration: 3165 Train loss: 0.444081 Train acc: 0.834473\n",
      "Epoch: 37/140 Iteration: 3170 Train loss: 0.505996 Train acc: 0.814941\n",
      "Epoch: 37/140 Iteration: 3175 Train loss: 0.353818 Train acc: 0.870117\n",
      "Epoch: 37/140 Iteration: 3180 Train loss: 0.273671 Train acc: 0.905762\n",
      "Epoch: 37/140 Iteration: 3185 Train loss: 0.376813 Train acc: 0.861816\n",
      "Epoch: 37/140 Iteration: 3190 Train loss: 0.392935 Train acc: 0.861328\n",
      "Epoch: 37/140 Iteration: 3195 Train loss: 0.396398 Train acc: 0.849609\n",
      "Epoch: 37/140 Iteration: 3200 Train loss: 0.555500 Train acc: 0.782715\n",
      "Epoch: 37/140 Iteration: 3200 Validation loss: 1.977324 Validation acc: 0.342084\n",
      "Epoch: 37/140 Iteration: 3205 Train loss: 0.512328 Train acc: 0.813477\n",
      "Epoch: 37/140 Iteration: 3210 Train loss: 0.528791 Train acc: 0.805664\n",
      "Epoch: 37/140 Iteration: 3215 Train loss: 0.628169 Train acc: 0.725586\n",
      "Epoch: 37/140 Iteration: 3220 Train loss: 0.624838 Train acc: 0.746582\n",
      "Epoch: 37/140 Iteration: 3225 Train loss: 0.574706 Train acc: 0.756836\n",
      "Epoch: 37/140 Iteration: 3230 Train loss: 0.544906 Train acc: 0.790039\n",
      "Epoch: 38/140 Iteration: 3235 Train loss: 0.618591 Train acc: 0.769531\n",
      "Epoch: 38/140 Iteration: 3240 Train loss: 0.467204 Train acc: 0.837891\n",
      "Epoch: 38/140 Iteration: 3240 Validation loss: 2.038319 Validation acc: 0.333941\n",
      "Epoch: 38/140 Iteration: 3245 Train loss: 0.428042 Train acc: 0.825195\n",
      "Epoch: 38/140 Iteration: 3250 Train loss: 0.475661 Train acc: 0.821289\n",
      "Epoch: 38/140 Iteration: 3255 Train loss: 0.493037 Train acc: 0.812500\n",
      "Epoch: 38/140 Iteration: 3260 Train loss: 0.356355 Train acc: 0.865723\n",
      "Epoch: 38/140 Iteration: 3265 Train loss: 0.288147 Train acc: 0.897949\n",
      "Epoch: 38/140 Iteration: 3270 Train loss: 0.421946 Train acc: 0.826660\n",
      "Epoch: 38/140 Iteration: 3275 Train loss: 0.406829 Train acc: 0.853027\n",
      "Epoch: 38/140 Iteration: 3280 Train loss: 0.344564 Train acc: 0.884766\n",
      "Epoch: 38/140 Iteration: 3280 Validation loss: 2.067849 Validation acc: 0.324592\n",
      "Epoch: 38/140 Iteration: 3285 Train loss: 0.533132 Train acc: 0.778809\n",
      "Epoch: 38/140 Iteration: 3290 Train loss: 0.491379 Train acc: 0.829102\n",
      "Epoch: 38/140 Iteration: 3295 Train loss: 0.557914 Train acc: 0.791504\n",
      "Epoch: 38/140 Iteration: 3300 Train loss: 0.624678 Train acc: 0.741699\n",
      "Epoch: 38/140 Iteration: 3305 Train loss: 0.659791 Train acc: 0.719727\n",
      "Epoch: 38/140 Iteration: 3310 Train loss: 0.615713 Train acc: 0.742676\n",
      "Epoch: 38/140 Iteration: 3315 Train loss: 0.584478 Train acc: 0.755371\n",
      "Epoch: 39/140 Iteration: 3320 Train loss: 0.575977 Train acc: 0.781738\n",
      "Epoch: 39/140 Iteration: 3320 Validation loss: 1.823837 Validation acc: 0.366311\n",
      "Epoch: 39/140 Iteration: 3325 Train loss: 0.466277 Train acc: 0.828613\n",
      "Epoch: 39/140 Iteration: 3330 Train loss: 0.452344 Train acc: 0.813477\n",
      "Epoch: 39/140 Iteration: 3335 Train loss: 0.468212 Train acc: 0.828613\n",
      "Epoch: 39/140 Iteration: 3340 Train loss: 0.523984 Train acc: 0.796387\n",
      "Epoch: 39/140 Iteration: 3345 Train loss: 0.379290 Train acc: 0.858398\n",
      "Epoch: 39/140 Iteration: 3350 Train loss: 0.299610 Train acc: 0.897461\n",
      "Epoch: 39/140 Iteration: 3355 Train loss: 0.382597 Train acc: 0.854980\n",
      "Epoch: 39/140 Iteration: 3360 Train loss: 0.413485 Train acc: 0.860352\n",
      "Epoch: 39/140 Iteration: 3360 Validation loss: 2.010237 Validation acc: 0.333295\n",
      "Epoch: 39/140 Iteration: 3365 Train loss: 0.392866 Train acc: 0.849121\n",
      "Epoch: 39/140 Iteration: 3370 Train loss: 0.551390 Train acc: 0.772461\n",
      "Epoch: 39/140 Iteration: 3375 Train loss: 0.556129 Train acc: 0.798340\n",
      "Epoch: 39/140 Iteration: 3380 Train loss: 0.539352 Train acc: 0.784668\n",
      "Epoch: 39/140 Iteration: 3385 Train loss: 0.621671 Train acc: 0.744629\n",
      "Epoch: 39/140 Iteration: 3390 Train loss: 0.657947 Train acc: 0.742676\n",
      "Epoch: 39/140 Iteration: 3395 Train loss: 0.565717 Train acc: 0.764648\n",
      "Epoch: 39/140 Iteration: 3400 Train loss: 0.615846 Train acc: 0.741211\n",
      "Epoch: 39/140 Iteration: 3400 Validation loss: 1.810866 Validation acc: 0.390165\n",
      "Epoch: 40/140 Iteration: 3405 Train loss: 0.596997 Train acc: 0.757812\n",
      "Epoch: 40/140 Iteration: 3410 Train loss: 0.479949 Train acc: 0.823242\n",
      "Epoch: 40/140 Iteration: 3415 Train loss: 0.462445 Train acc: 0.816406\n",
      "Epoch: 40/140 Iteration: 3420 Train loss: 0.411045 Train acc: 0.854492\n",
      "Epoch: 40/140 Iteration: 3425 Train loss: 0.502126 Train acc: 0.813965\n",
      "Epoch: 40/140 Iteration: 3430 Train loss: 0.390351 Train acc: 0.840332\n",
      "Epoch: 40/140 Iteration: 3435 Train loss: 0.312421 Train acc: 0.887207\n",
      "Epoch: 40/140 Iteration: 3440 Train loss: 0.435023 Train acc: 0.824707\n",
      "Epoch: 40/140 Iteration: 3440 Validation loss: 1.814101 Validation acc: 0.374282\n",
      "Epoch: 40/140 Iteration: 3445 Train loss: 0.405920 Train acc: 0.861816\n",
      "Epoch: 40/140 Iteration: 3450 Train loss: 0.400637 Train acc: 0.861328\n",
      "Epoch: 40/140 Iteration: 3455 Train loss: 0.584777 Train acc: 0.764160\n",
      "Epoch: 40/140 Iteration: 3460 Train loss: 0.517657 Train acc: 0.805176\n",
      "Epoch: 40/140 Iteration: 3465 Train loss: 0.535735 Train acc: 0.805664\n",
      "Epoch: 40/140 Iteration: 3470 Train loss: 0.740748 Train acc: 0.683105\n",
      "Epoch: 40/140 Iteration: 3475 Train loss: 0.641471 Train acc: 0.725586\n",
      "Epoch: 40/140 Iteration: 3480 Train loss: 0.578776 Train acc: 0.765625\n",
      "Epoch: 40/140 Iteration: 3480 Validation loss: 1.773341 Validation acc: 0.392377\n",
      "Epoch: 40/140 Iteration: 3485 Train loss: 0.608002 Train acc: 0.738770\n",
      "Epoch: 41/140 Iteration: 3490 Train loss: 0.599018 Train acc: 0.776367\n",
      "Epoch: 41/140 Iteration: 3495 Train loss: 0.466442 Train acc: 0.834961\n",
      "Epoch: 41/140 Iteration: 3500 Train loss: 0.457184 Train acc: 0.827637\n",
      "Epoch: 41/140 Iteration: 3505 Train loss: 0.427588 Train acc: 0.843262\n",
      "Epoch: 41/140 Iteration: 3510 Train loss: 0.525010 Train acc: 0.796387\n",
      "Epoch: 41/140 Iteration: 3515 Train loss: 0.398514 Train acc: 0.850586\n",
      "Epoch: 41/140 Iteration: 3520 Train loss: 0.294209 Train acc: 0.891602\n",
      "Epoch: 41/140 Iteration: 3520 Validation loss: 1.726289 Validation acc: 0.371252\n",
      "Epoch: 41/140 Iteration: 3525 Train loss: 0.387994 Train acc: 0.864746\n",
      "Epoch: 41/140 Iteration: 3530 Train loss: 0.376362 Train acc: 0.868164\n",
      "Epoch: 41/140 Iteration: 3535 Train loss: 0.373052 Train acc: 0.875000\n",
      "Epoch: 41/140 Iteration: 3540 Train loss: 0.537199 Train acc: 0.778809\n",
      "Epoch: 41/140 Iteration: 3545 Train loss: 0.511127 Train acc: 0.805664\n",
      "Epoch: 41/140 Iteration: 3550 Train loss: 0.532193 Train acc: 0.793945\n",
      "Epoch: 41/140 Iteration: 3555 Train loss: 0.623874 Train acc: 0.730957\n",
      "Epoch: 41/140 Iteration: 3560 Train loss: 0.606404 Train acc: 0.752441\n",
      "Epoch: 41/140 Iteration: 3560 Validation loss: 1.888239 Validation acc: 0.376551\n",
      "Epoch: 41/140 Iteration: 3565 Train loss: 0.563619 Train acc: 0.756836\n",
      "Epoch: 41/140 Iteration: 3570 Train loss: 0.574694 Train acc: 0.750488\n",
      "Epoch: 42/140 Iteration: 3575 Train loss: 0.660084 Train acc: 0.761230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42/140 Iteration: 3580 Train loss: 0.488240 Train acc: 0.819824\n",
      "Epoch: 42/140 Iteration: 3585 Train loss: 0.463893 Train acc: 0.820312\n",
      "Epoch: 42/140 Iteration: 3590 Train loss: 0.419725 Train acc: 0.843750\n",
      "Epoch: 42/140 Iteration: 3595 Train loss: 0.493944 Train acc: 0.811523\n",
      "Epoch: 42/140 Iteration: 3600 Train loss: 0.368634 Train acc: 0.869629\n",
      "Epoch: 42/140 Iteration: 3600 Validation loss: 1.884622 Validation acc: 0.348001\n",
      "Epoch: 42/140 Iteration: 3605 Train loss: 0.301917 Train acc: 0.889648\n",
      "Epoch: 42/140 Iteration: 3610 Train loss: 0.382039 Train acc: 0.852051\n",
      "Epoch: 42/140 Iteration: 3615 Train loss: 0.390787 Train acc: 0.857422\n",
      "Epoch: 42/140 Iteration: 3620 Train loss: 0.398636 Train acc: 0.859375\n",
      "Epoch: 42/140 Iteration: 3625 Train loss: 0.546730 Train acc: 0.789551\n",
      "Epoch: 42/140 Iteration: 3630 Train loss: 0.483176 Train acc: 0.829590\n",
      "Epoch: 42/140 Iteration: 3635 Train loss: 0.535206 Train acc: 0.796875\n",
      "Epoch: 42/140 Iteration: 3640 Train loss: 0.565205 Train acc: 0.753418\n",
      "Epoch: 42/140 Iteration: 3640 Validation loss: 1.980099 Validation acc: 0.360940\n",
      "Epoch: 42/140 Iteration: 3645 Train loss: 0.626403 Train acc: 0.740723\n",
      "Epoch: 42/140 Iteration: 3650 Train loss: 0.581500 Train acc: 0.755371\n",
      "Epoch: 42/140 Iteration: 3655 Train loss: 0.591022 Train acc: 0.763672\n",
      "Epoch: 43/140 Iteration: 3660 Train loss: 0.596223 Train acc: 0.768066\n",
      "Epoch: 43/140 Iteration: 3665 Train loss: 0.486112 Train acc: 0.823730\n",
      "Epoch: 43/140 Iteration: 3670 Train loss: 0.450661 Train acc: 0.828613\n",
      "Epoch: 43/140 Iteration: 3675 Train loss: 0.416881 Train acc: 0.843750\n",
      "Epoch: 43/140 Iteration: 3680 Train loss: 0.511116 Train acc: 0.806152\n",
      "Epoch: 43/140 Iteration: 3680 Validation loss: 1.716877 Validation acc: 0.388902\n",
      "Epoch: 43/140 Iteration: 3685 Train loss: 0.364217 Train acc: 0.863770\n",
      "Epoch: 43/140 Iteration: 3690 Train loss: 0.273640 Train acc: 0.898926\n",
      "Epoch: 43/140 Iteration: 3695 Train loss: 0.385733 Train acc: 0.850098\n",
      "Epoch: 43/140 Iteration: 3700 Train loss: 0.394310 Train acc: 0.856934\n",
      "Epoch: 43/140 Iteration: 3705 Train loss: 0.350975 Train acc: 0.889648\n",
      "Epoch: 43/140 Iteration: 3710 Train loss: 0.594236 Train acc: 0.766602\n",
      "Epoch: 43/140 Iteration: 3715 Train loss: 0.553548 Train acc: 0.780762\n",
      "Epoch: 43/140 Iteration: 3720 Train loss: 0.543782 Train acc: 0.775391\n",
      "Epoch: 43/140 Iteration: 3720 Validation loss: 1.872569 Validation acc: 0.374914\n",
      "Epoch: 43/140 Iteration: 3725 Train loss: 0.629917 Train acc: 0.736816\n",
      "Epoch: 43/140 Iteration: 3730 Train loss: 0.609806 Train acc: 0.759277\n",
      "Epoch: 43/140 Iteration: 3735 Train loss: 0.597406 Train acc: 0.742188\n",
      "Epoch: 43/140 Iteration: 3740 Train loss: 0.576212 Train acc: 0.768555\n",
      "Epoch: 44/140 Iteration: 3745 Train loss: 0.633757 Train acc: 0.748535\n",
      "Epoch: 44/140 Iteration: 3750 Train loss: 0.453578 Train acc: 0.838867\n",
      "Epoch: 44/140 Iteration: 3755 Train loss: 0.427199 Train acc: 0.834473\n",
      "Epoch: 44/140 Iteration: 3760 Train loss: 0.404590 Train acc: 0.849121\n",
      "Epoch: 44/140 Iteration: 3760 Validation loss: 1.728000 Validation acc: 0.386848\n",
      "Epoch: 44/140 Iteration: 3765 Train loss: 0.480124 Train acc: 0.826172\n",
      "Epoch: 44/140 Iteration: 3770 Train loss: 0.337998 Train acc: 0.875977\n",
      "Epoch: 44/140 Iteration: 3775 Train loss: 0.279641 Train acc: 0.899902\n",
      "Epoch: 44/140 Iteration: 3780 Train loss: 0.378131 Train acc: 0.852051\n",
      "Epoch: 44/140 Iteration: 3785 Train loss: 0.389728 Train acc: 0.854980\n",
      "Epoch: 44/140 Iteration: 3790 Train loss: 0.375865 Train acc: 0.874512\n",
      "Epoch: 44/140 Iteration: 3795 Train loss: 0.554690 Train acc: 0.767090\n",
      "Epoch: 44/140 Iteration: 3800 Train loss: 0.532960 Train acc: 0.803223\n",
      "Epoch: 44/140 Iteration: 3800 Validation loss: 1.870300 Validation acc: 0.382023\n",
      "Epoch: 44/140 Iteration: 3805 Train loss: 0.582334 Train acc: 0.769531\n",
      "Epoch: 44/140 Iteration: 3810 Train loss: 0.544955 Train acc: 0.761719\n",
      "Epoch: 44/140 Iteration: 3815 Train loss: 0.623878 Train acc: 0.725098\n",
      "Epoch: 44/140 Iteration: 3820 Train loss: 0.565892 Train acc: 0.771484\n",
      "Epoch: 44/140 Iteration: 3825 Train loss: 0.631136 Train acc: 0.735840\n",
      "Epoch: 45/140 Iteration: 3830 Train loss: 0.575744 Train acc: 0.768555\n",
      "Epoch: 45/140 Iteration: 3835 Train loss: 0.465947 Train acc: 0.824219\n",
      "Epoch: 45/140 Iteration: 3840 Train loss: 0.452946 Train acc: 0.819824\n",
      "Epoch: 45/140 Iteration: 3840 Validation loss: 1.712579 Validation acc: 0.384392\n",
      "Epoch: 45/140 Iteration: 3845 Train loss: 0.395841 Train acc: 0.846191\n",
      "Epoch: 45/140 Iteration: 3850 Train loss: 0.488875 Train acc: 0.820801\n",
      "Epoch: 45/140 Iteration: 3855 Train loss: 0.367418 Train acc: 0.859375\n",
      "Epoch: 45/140 Iteration: 3860 Train loss: 0.274971 Train acc: 0.901855\n",
      "Epoch: 45/140 Iteration: 3865 Train loss: 0.392643 Train acc: 0.843262\n",
      "Epoch: 45/140 Iteration: 3870 Train loss: 0.394098 Train acc: 0.855469\n",
      "Epoch: 45/140 Iteration: 3875 Train loss: 0.368209 Train acc: 0.868164\n",
      "Epoch: 45/140 Iteration: 3880 Train loss: 0.526938 Train acc: 0.786621\n",
      "Epoch: 45/140 Iteration: 3880 Validation loss: 1.838511 Validation acc: 0.402631\n",
      "Epoch: 45/140 Iteration: 3885 Train loss: 0.542865 Train acc: 0.791016\n",
      "Epoch: 45/140 Iteration: 3890 Train loss: 0.624367 Train acc: 0.732910\n",
      "Epoch: 45/140 Iteration: 3895 Train loss: 0.598059 Train acc: 0.750977\n",
      "Epoch: 45/140 Iteration: 3900 Train loss: 0.642920 Train acc: 0.721680\n",
      "Epoch: 45/140 Iteration: 3905 Train loss: 0.564139 Train acc: 0.770020\n",
      "Epoch: 45/140 Iteration: 3910 Train loss: 0.532839 Train acc: 0.782227\n",
      "Epoch: 46/140 Iteration: 3915 Train loss: 0.607276 Train acc: 0.766113\n",
      "Epoch: 46/140 Iteration: 3920 Train loss: 0.482406 Train acc: 0.830566\n",
      "Epoch: 46/140 Iteration: 3920 Validation loss: 1.795657 Validation acc: 0.380012\n",
      "Epoch: 46/140 Iteration: 3925 Train loss: 0.463965 Train acc: 0.827637\n",
      "Epoch: 46/140 Iteration: 3930 Train loss: 0.439914 Train acc: 0.845215\n",
      "Epoch: 46/140 Iteration: 3935 Train loss: 0.470262 Train acc: 0.834473\n",
      "Epoch: 46/140 Iteration: 3940 Train loss: 0.349461 Train acc: 0.871094\n",
      "Epoch: 46/140 Iteration: 3945 Train loss: 0.285311 Train acc: 0.895996\n",
      "Epoch: 46/140 Iteration: 3950 Train loss: 0.393986 Train acc: 0.843262\n",
      "Epoch: 46/140 Iteration: 3955 Train loss: 0.411026 Train acc: 0.847656\n",
      "Epoch: 46/140 Iteration: 3960 Train loss: 0.384856 Train acc: 0.875000\n",
      "Epoch: 46/140 Iteration: 3960 Validation loss: 1.919457 Validation acc: 0.359547\n",
      "Epoch: 46/140 Iteration: 3965 Train loss: 0.530310 Train acc: 0.781250\n",
      "Epoch: 46/140 Iteration: 3970 Train loss: 0.561335 Train acc: 0.779297\n",
      "Epoch: 46/140 Iteration: 3975 Train loss: 0.670212 Train acc: 0.712402\n",
      "Epoch: 46/140 Iteration: 3980 Train loss: 0.552331 Train acc: 0.772949\n",
      "Epoch: 46/140 Iteration: 3985 Train loss: 0.677971 Train acc: 0.719238\n",
      "Epoch: 46/140 Iteration: 3990 Train loss: 0.591580 Train acc: 0.754883\n",
      "Epoch: 46/140 Iteration: 3995 Train loss: 0.565370 Train acc: 0.767578\n",
      "Epoch: 47/140 Iteration: 4000 Train loss: 0.589124 Train acc: 0.772461\n",
      "Epoch: 47/140 Iteration: 4000 Validation loss: 1.857563 Validation acc: 0.384478\n",
      "Epoch: 47/140 Iteration: 4005 Train loss: 0.490058 Train acc: 0.826172\n",
      "Epoch: 47/140 Iteration: 4010 Train loss: 0.473306 Train acc: 0.813477\n",
      "Epoch: 47/140 Iteration: 4015 Train loss: 0.394824 Train acc: 0.859375\n",
      "Epoch: 47/140 Iteration: 4020 Train loss: 0.503883 Train acc: 0.805664\n",
      "Epoch: 47/140 Iteration: 4025 Train loss: 0.387758 Train acc: 0.854004\n",
      "Epoch: 47/140 Iteration: 4030 Train loss: 0.319467 Train acc: 0.880859\n",
      "Epoch: 47/140 Iteration: 4035 Train loss: 0.364936 Train acc: 0.858887\n",
      "Epoch: 47/140 Iteration: 4040 Train loss: 0.397789 Train acc: 0.848633\n",
      "Epoch: 47/140 Iteration: 4040 Validation loss: 1.767673 Validation acc: 0.372271\n",
      "Epoch: 47/140 Iteration: 4045 Train loss: 0.360792 Train acc: 0.875488\n",
      "Epoch: 47/140 Iteration: 4050 Train loss: 0.549012 Train acc: 0.789551\n",
      "Epoch: 47/140 Iteration: 4055 Train loss: 0.551589 Train acc: 0.782715\n",
      "Epoch: 47/140 Iteration: 4060 Train loss: 0.586705 Train acc: 0.756836\n",
      "Epoch: 47/140 Iteration: 4065 Train loss: 0.589679 Train acc: 0.751953\n",
      "Epoch: 47/140 Iteration: 4070 Train loss: 0.749098 Train acc: 0.654785\n",
      "Epoch: 47/140 Iteration: 4075 Train loss: 0.557219 Train acc: 0.784180\n",
      "Epoch: 47/140 Iteration: 4080 Train loss: 0.641084 Train acc: 0.719727\n",
      "Epoch: 47/140 Iteration: 4080 Validation loss: 1.867130 Validation acc: 0.379150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48/140 Iteration: 4085 Train loss: 0.569328 Train acc: 0.777344\n",
      "Epoch: 48/140 Iteration: 4090 Train loss: 0.467635 Train acc: 0.833984\n",
      "Epoch: 48/140 Iteration: 4095 Train loss: 0.479960 Train acc: 0.808105\n",
      "Epoch: 48/140 Iteration: 4100 Train loss: 0.425057 Train acc: 0.839844\n",
      "Epoch: 48/140 Iteration: 4105 Train loss: 0.480683 Train acc: 0.819336\n",
      "Epoch: 48/140 Iteration: 4110 Train loss: 0.389692 Train acc: 0.847656\n",
      "Epoch: 48/140 Iteration: 4115 Train loss: 0.303270 Train acc: 0.884766\n",
      "Epoch: 48/140 Iteration: 4120 Train loss: 0.407404 Train acc: 0.842285\n",
      "Epoch: 48/140 Iteration: 4120 Validation loss: 1.676428 Validation acc: 0.384306\n",
      "Epoch: 48/140 Iteration: 4125 Train loss: 0.400631 Train acc: 0.848633\n",
      "Epoch: 48/140 Iteration: 4130 Train loss: 0.389429 Train acc: 0.866211\n",
      "Epoch: 48/140 Iteration: 4135 Train loss: 0.551244 Train acc: 0.782715\n",
      "Epoch: 48/140 Iteration: 4140 Train loss: 0.499479 Train acc: 0.817871\n",
      "Epoch: 48/140 Iteration: 4145 Train loss: 0.579372 Train acc: 0.777832\n",
      "Epoch: 48/140 Iteration: 4150 Train loss: 0.655987 Train acc: 0.717773\n",
      "Epoch: 48/140 Iteration: 4155 Train loss: 0.736559 Train acc: 0.666992\n",
      "Epoch: 48/140 Iteration: 4160 Train loss: 0.561457 Train acc: 0.770508\n",
      "Epoch: 48/140 Iteration: 4160 Validation loss: 1.907284 Validation acc: 0.371367\n",
      "Epoch: 48/140 Iteration: 4165 Train loss: 0.617662 Train acc: 0.733887\n",
      "Epoch: 49/140 Iteration: 4170 Train loss: 0.634977 Train acc: 0.770508\n",
      "Epoch: 49/140 Iteration: 4175 Train loss: 0.501460 Train acc: 0.811523\n",
      "Epoch: 49/140 Iteration: 4180 Train loss: 0.494403 Train acc: 0.804688\n",
      "Epoch: 49/140 Iteration: 4185 Train loss: 0.430928 Train acc: 0.845703\n",
      "Epoch: 49/140 Iteration: 4190 Train loss: 0.558227 Train acc: 0.792480\n",
      "Epoch: 49/140 Iteration: 4195 Train loss: 0.365651 Train acc: 0.865234\n",
      "Epoch: 49/140 Iteration: 4200 Train loss: 0.303303 Train acc: 0.892090\n",
      "Epoch: 49/140 Iteration: 4200 Validation loss: 1.850810 Validation acc: 0.348575\n",
      "Epoch: 49/140 Iteration: 4205 Train loss: 0.418060 Train acc: 0.833984\n",
      "Epoch: 49/140 Iteration: 4210 Train loss: 0.379712 Train acc: 0.861816\n",
      "Epoch: 49/140 Iteration: 4215 Train loss: 0.393319 Train acc: 0.859375\n",
      "Epoch: 49/140 Iteration: 4220 Train loss: 0.551033 Train acc: 0.780762\n",
      "Epoch: 49/140 Iteration: 4225 Train loss: 0.528230 Train acc: 0.791504\n",
      "Epoch: 49/140 Iteration: 4230 Train loss: 0.510958 Train acc: 0.802734\n",
      "Epoch: 49/140 Iteration: 4235 Train loss: 0.740563 Train acc: 0.687988\n",
      "Epoch: 49/140 Iteration: 4240 Train loss: 0.654649 Train acc: 0.715820\n",
      "Epoch: 49/140 Iteration: 4240 Validation loss: 1.876158 Validation acc: 0.357939\n",
      "Epoch: 49/140 Iteration: 4245 Train loss: 0.644461 Train acc: 0.717285\n",
      "Epoch: 49/140 Iteration: 4250 Train loss: 0.589934 Train acc: 0.741211\n",
      "Epoch: 50/140 Iteration: 4255 Train loss: 0.625009 Train acc: 0.760742\n",
      "Epoch: 50/140 Iteration: 4260 Train loss: 0.499814 Train acc: 0.812500\n",
      "Epoch: 50/140 Iteration: 4265 Train loss: 0.479793 Train acc: 0.818359\n",
      "Epoch: 50/140 Iteration: 4270 Train loss: 0.381257 Train acc: 0.871094\n",
      "Epoch: 50/140 Iteration: 4275 Train loss: 0.517894 Train acc: 0.801270\n",
      "Epoch: 50/140 Iteration: 4280 Train loss: 0.378569 Train acc: 0.855469\n",
      "Epoch: 50/140 Iteration: 4280 Validation loss: 1.634685 Validation acc: 0.376249\n",
      "Epoch: 50/140 Iteration: 4285 Train loss: 0.335171 Train acc: 0.881836\n",
      "Epoch: 50/140 Iteration: 4290 Train loss: 0.413169 Train acc: 0.841309\n",
      "Epoch: 50/140 Iteration: 4295 Train loss: 0.417441 Train acc: 0.846191\n",
      "Epoch: 50/140 Iteration: 4300 Train loss: 0.365198 Train acc: 0.874512\n",
      "Epoch: 50/140 Iteration: 4305 Train loss: 0.556207 Train acc: 0.781250\n",
      "Epoch: 50/140 Iteration: 4310 Train loss: 0.521354 Train acc: 0.812500\n",
      "Epoch: 50/140 Iteration: 4315 Train loss: 0.545308 Train acc: 0.781738\n",
      "Epoch: 50/140 Iteration: 4320 Train loss: 0.638209 Train acc: 0.737305\n",
      "Epoch: 50/140 Iteration: 4320 Validation loss: 1.819786 Validation acc: 0.378375\n",
      "Epoch: 50/140 Iteration: 4325 Train loss: 0.656037 Train acc: 0.715820\n",
      "Epoch: 50/140 Iteration: 4330 Train loss: 0.602370 Train acc: 0.744141\n",
      "Epoch: 50/140 Iteration: 4335 Train loss: 0.534758 Train acc: 0.789551\n",
      "Epoch: 51/140 Iteration: 4340 Train loss: 0.579997 Train acc: 0.772461\n",
      "Epoch: 51/140 Iteration: 4345 Train loss: 0.435356 Train acc: 0.840820\n",
      "Epoch: 51/140 Iteration: 4350 Train loss: 0.462068 Train acc: 0.826660\n",
      "Epoch: 51/140 Iteration: 4355 Train loss: 0.370510 Train acc: 0.862305\n",
      "Epoch: 51/140 Iteration: 4360 Train loss: 0.483364 Train acc: 0.816895\n",
      "Epoch: 51/140 Iteration: 4360 Validation loss: 1.689286 Validation acc: 0.380486\n",
      "Epoch: 51/140 Iteration: 4365 Train loss: 0.362847 Train acc: 0.866211\n",
      "Epoch: 51/140 Iteration: 4370 Train loss: 0.325634 Train acc: 0.889160\n",
      "Epoch: 51/140 Iteration: 4375 Train loss: 0.396646 Train acc: 0.838867\n",
      "Epoch: 51/140 Iteration: 4380 Train loss: 0.419066 Train acc: 0.836426\n",
      "Epoch: 51/140 Iteration: 4385 Train loss: 0.345917 Train acc: 0.892090\n",
      "Epoch: 51/140 Iteration: 4390 Train loss: 0.547905 Train acc: 0.791016\n",
      "Epoch: 51/140 Iteration: 4395 Train loss: 0.468239 Train acc: 0.835938\n",
      "Epoch: 51/140 Iteration: 4400 Train loss: 0.537461 Train acc: 0.803711\n",
      "Epoch: 51/140 Iteration: 4400 Validation loss: 1.865483 Validation acc: 0.390654\n",
      "Epoch: 51/140 Iteration: 4405 Train loss: 0.556015 Train acc: 0.784180\n",
      "Epoch: 51/140 Iteration: 4410 Train loss: 0.673683 Train acc: 0.691895\n",
      "Epoch: 51/140 Iteration: 4415 Train loss: 0.582787 Train acc: 0.754395\n",
      "Epoch: 51/140 Iteration: 4420 Train loss: 0.538508 Train acc: 0.789551\n",
      "Epoch: 52/140 Iteration: 4425 Train loss: 0.577546 Train acc: 0.780762\n",
      "Epoch: 52/140 Iteration: 4430 Train loss: 0.449554 Train acc: 0.842285\n",
      "Epoch: 52/140 Iteration: 4435 Train loss: 0.463032 Train acc: 0.814941\n",
      "Epoch: 52/140 Iteration: 4440 Train loss: 0.392966 Train acc: 0.854004\n",
      "Epoch: 52/140 Iteration: 4440 Validation loss: 1.718466 Validation acc: 0.387638\n",
      "Epoch: 52/140 Iteration: 4445 Train loss: 0.482458 Train acc: 0.820801\n",
      "Epoch: 52/140 Iteration: 4450 Train loss: 0.366020 Train acc: 0.864746\n",
      "Epoch: 52/140 Iteration: 4455 Train loss: 0.308336 Train acc: 0.879883\n",
      "Epoch: 52/140 Iteration: 4460 Train loss: 0.379984 Train acc: 0.848633\n",
      "Epoch: 52/140 Iteration: 4465 Train loss: 0.378362 Train acc: 0.862793\n",
      "Epoch: 52/140 Iteration: 4470 Train loss: 0.383167 Train acc: 0.875488\n",
      "Epoch: 52/140 Iteration: 4475 Train loss: 0.507741 Train acc: 0.793457\n",
      "Epoch: 52/140 Iteration: 4480 Train loss: 0.496586 Train acc: 0.826172\n",
      "Epoch: 52/140 Iteration: 4480 Validation loss: 1.847538 Validation acc: 0.381879\n",
      "Epoch: 52/140 Iteration: 4485 Train loss: 0.535028 Train acc: 0.794434\n",
      "Epoch: 52/140 Iteration: 4490 Train loss: 0.564058 Train acc: 0.759766\n",
      "Epoch: 52/140 Iteration: 4495 Train loss: 0.681828 Train acc: 0.703125\n",
      "Epoch: 52/140 Iteration: 4500 Train loss: 0.541198 Train acc: 0.776367\n",
      "Epoch: 52/140 Iteration: 4505 Train loss: 0.608684 Train acc: 0.755859\n",
      "Epoch: 53/140 Iteration: 4510 Train loss: 0.569612 Train acc: 0.775391\n",
      "Epoch: 53/140 Iteration: 4515 Train loss: 0.431977 Train acc: 0.846191\n",
      "Epoch: 53/140 Iteration: 4520 Train loss: 0.486264 Train acc: 0.815430\n",
      "Epoch: 53/140 Iteration: 4520 Validation loss: 1.738261 Validation acc: 0.387178\n",
      "Epoch: 53/140 Iteration: 4525 Train loss: 0.424455 Train acc: 0.845215\n",
      "Epoch: 53/140 Iteration: 4530 Train loss: 0.489438 Train acc: 0.823242\n",
      "Epoch: 53/140 Iteration: 4535 Train loss: 0.351966 Train acc: 0.865723\n",
      "Epoch: 53/140 Iteration: 4540 Train loss: 0.286903 Train acc: 0.892578\n",
      "Epoch: 53/140 Iteration: 4545 Train loss: 0.437641 Train acc: 0.823730\n",
      "Epoch: 53/140 Iteration: 4550 Train loss: 0.383296 Train acc: 0.859863\n",
      "Epoch: 53/140 Iteration: 4555 Train loss: 0.353197 Train acc: 0.879395\n",
      "Epoch: 53/140 Iteration: 4560 Train loss: 0.519918 Train acc: 0.791504\n",
      "Epoch: 53/140 Iteration: 4560 Validation loss: 1.787904 Validation acc: 0.395005\n",
      "Epoch: 53/140 Iteration: 4565 Train loss: 0.527389 Train acc: 0.808594\n",
      "Epoch: 53/140 Iteration: 4570 Train loss: 0.524537 Train acc: 0.799316\n",
      "Epoch: 53/140 Iteration: 4575 Train loss: 0.606836 Train acc: 0.745117\n",
      "Epoch: 53/140 Iteration: 4580 Train loss: 0.684265 Train acc: 0.698242\n",
      "Epoch: 53/140 Iteration: 4585 Train loss: 0.517947 Train acc: 0.791504\n",
      "Epoch: 53/140 Iteration: 4590 Train loss: 0.537871 Train acc: 0.788086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54/140 Iteration: 4595 Train loss: 0.614561 Train acc: 0.754395\n",
      "Epoch: 54/140 Iteration: 4600 Train loss: 0.444178 Train acc: 0.838379\n",
      "Epoch: 54/140 Iteration: 4600 Validation loss: 1.843231 Validation acc: 0.380759\n",
      "Epoch: 54/140 Iteration: 4605 Train loss: 0.512910 Train acc: 0.796875\n",
      "Epoch: 54/140 Iteration: 4610 Train loss: 0.402557 Train acc: 0.859863\n",
      "Epoch: 54/140 Iteration: 4615 Train loss: 0.478156 Train acc: 0.826660\n",
      "Epoch: 54/140 Iteration: 4620 Train loss: 0.339774 Train acc: 0.871094\n",
      "Epoch: 54/140 Iteration: 4625 Train loss: 0.293804 Train acc: 0.892090\n",
      "Epoch: 54/140 Iteration: 4630 Train loss: 0.375866 Train acc: 0.867188\n",
      "Epoch: 54/140 Iteration: 4635 Train loss: 0.407911 Train acc: 0.854004\n",
      "Epoch: 54/140 Iteration: 4640 Train loss: 0.391908 Train acc: 0.866211\n",
      "Epoch: 54/140 Iteration: 4640 Validation loss: 1.715393 Validation acc: 0.381391\n",
      "Epoch: 54/140 Iteration: 4645 Train loss: 0.508329 Train acc: 0.795898\n",
      "Epoch: 54/140 Iteration: 4650 Train loss: 0.491832 Train acc: 0.819824\n",
      "Epoch: 54/140 Iteration: 4655 Train loss: 0.533036 Train acc: 0.802246\n",
      "Epoch: 54/140 Iteration: 4660 Train loss: 0.623948 Train acc: 0.740723\n",
      "Epoch: 54/140 Iteration: 4665 Train loss: 0.641029 Train acc: 0.744629\n",
      "Epoch: 54/140 Iteration: 4670 Train loss: 0.624596 Train acc: 0.744629\n",
      "Epoch: 54/140 Iteration: 4675 Train loss: 0.531032 Train acc: 0.789551\n",
      "Epoch: 55/140 Iteration: 4680 Train loss: 0.607176 Train acc: 0.768066\n",
      "Epoch: 55/140 Iteration: 4680 Validation loss: 1.861436 Validation acc: 0.365177\n",
      "Epoch: 55/140 Iteration: 4685 Train loss: 0.441085 Train acc: 0.849121\n",
      "Epoch: 55/140 Iteration: 4690 Train loss: 0.534591 Train acc: 0.781738\n",
      "Epoch: 55/140 Iteration: 4695 Train loss: 0.423880 Train acc: 0.845703\n",
      "Epoch: 55/140 Iteration: 4700 Train loss: 0.487236 Train acc: 0.823242\n",
      "Epoch: 55/140 Iteration: 4705 Train loss: 0.334612 Train acc: 0.878906\n",
      "Epoch: 55/140 Iteration: 4710 Train loss: 0.285537 Train acc: 0.899414\n",
      "Epoch: 55/140 Iteration: 4715 Train loss: 0.428546 Train acc: 0.838379\n",
      "Epoch: 55/140 Iteration: 4720 Train loss: 0.389472 Train acc: 0.850586\n",
      "Epoch: 55/140 Iteration: 4720 Validation loss: 1.798042 Validation acc: 0.381908\n",
      "Epoch: 55/140 Iteration: 4725 Train loss: 0.358173 Train acc: 0.886719\n",
      "Epoch: 55/140 Iteration: 4730 Train loss: 0.518265 Train acc: 0.780762\n",
      "Epoch: 55/140 Iteration: 4735 Train loss: 0.481041 Train acc: 0.822754\n",
      "Epoch: 55/140 Iteration: 4740 Train loss: 0.495904 Train acc: 0.828613\n",
      "Epoch: 55/140 Iteration: 4745 Train loss: 0.584937 Train acc: 0.744629\n",
      "Epoch: 55/140 Iteration: 4750 Train loss: 0.615006 Train acc: 0.747559\n",
      "Epoch: 55/140 Iteration: 4755 Train loss: 0.567619 Train acc: 0.762695\n",
      "Epoch: 55/140 Iteration: 4760 Train loss: 0.540513 Train acc: 0.785156\n",
      "Epoch: 55/140 Iteration: 4760 Validation loss: 1.991632 Validation acc: 0.369370\n",
      "Epoch: 56/140 Iteration: 4765 Train loss: 0.565490 Train acc: 0.780273\n",
      "Epoch: 56/140 Iteration: 4770 Train loss: 0.451153 Train acc: 0.833984\n",
      "Epoch: 56/140 Iteration: 4775 Train loss: 0.506653 Train acc: 0.797363\n",
      "Epoch: 56/140 Iteration: 4780 Train loss: 0.382297 Train acc: 0.862305\n",
      "Epoch: 56/140 Iteration: 4785 Train loss: 0.486418 Train acc: 0.820801\n",
      "Epoch: 56/140 Iteration: 4790 Train loss: 0.329724 Train acc: 0.876953\n",
      "Epoch: 56/140 Iteration: 4795 Train loss: 0.273819 Train acc: 0.901855\n",
      "Epoch: 56/140 Iteration: 4800 Train loss: 0.403716 Train acc: 0.841309\n",
      "Epoch: 56/140 Iteration: 4800 Validation loss: 1.741737 Validation acc: 0.390381\n",
      "Epoch: 56/140 Iteration: 4805 Train loss: 0.414745 Train acc: 0.848145\n",
      "Epoch: 56/140 Iteration: 4810 Train loss: 0.382870 Train acc: 0.874512\n",
      "Epoch: 56/140 Iteration: 4815 Train loss: 0.511210 Train acc: 0.781250\n",
      "Epoch: 56/140 Iteration: 4820 Train loss: 0.487561 Train acc: 0.829590\n",
      "Epoch: 56/140 Iteration: 4825 Train loss: 0.504547 Train acc: 0.809082\n",
      "Epoch: 56/140 Iteration: 4830 Train loss: 0.535902 Train acc: 0.770996\n",
      "Epoch: 56/140 Iteration: 4835 Train loss: 0.605843 Train acc: 0.737793\n",
      "Epoch: 56/140 Iteration: 4840 Train loss: 0.566091 Train acc: 0.778320\n",
      "Epoch: 56/140 Iteration: 4840 Validation loss: 1.976428 Validation acc: 0.377542\n",
      "Epoch: 56/140 Iteration: 4845 Train loss: 0.538732 Train acc: 0.774414\n",
      "Epoch: 57/140 Iteration: 4850 Train loss: 0.593654 Train acc: 0.766602\n",
      "Epoch: 57/140 Iteration: 4855 Train loss: 0.425526 Train acc: 0.851074\n",
      "Epoch: 57/140 Iteration: 4860 Train loss: 0.497537 Train acc: 0.802734\n",
      "Epoch: 57/140 Iteration: 4865 Train loss: 0.425739 Train acc: 0.848633\n",
      "Epoch: 57/140 Iteration: 4870 Train loss: 0.483682 Train acc: 0.819824\n",
      "Epoch: 57/140 Iteration: 4875 Train loss: 0.375877 Train acc: 0.860352\n",
      "Epoch: 57/140 Iteration: 4880 Train loss: 0.308819 Train acc: 0.887695\n",
      "Epoch: 57/140 Iteration: 4880 Validation loss: 1.640258 Validation acc: 0.395364\n",
      "Epoch: 57/140 Iteration: 4885 Train loss: 0.417934 Train acc: 0.842285\n",
      "Epoch: 57/140 Iteration: 4890 Train loss: 0.412438 Train acc: 0.843262\n",
      "Epoch: 57/140 Iteration: 4895 Train loss: 0.341700 Train acc: 0.880371\n",
      "Epoch: 57/140 Iteration: 4900 Train loss: 0.504296 Train acc: 0.783691\n",
      "Epoch: 57/140 Iteration: 4905 Train loss: 0.581622 Train acc: 0.769531\n",
      "Epoch: 57/140 Iteration: 4910 Train loss: 0.543886 Train acc: 0.784180\n",
      "Epoch: 57/140 Iteration: 4915 Train loss: 0.535540 Train acc: 0.770996\n",
      "Epoch: 57/140 Iteration: 4920 Train loss: 0.581362 Train acc: 0.750977\n",
      "Epoch: 57/140 Iteration: 4920 Validation loss: 1.887786 Validation acc: 0.380673\n",
      "Epoch: 57/140 Iteration: 4925 Train loss: 0.508333 Train acc: 0.799805\n",
      "Epoch: 57/140 Iteration: 4930 Train loss: 0.567487 Train acc: 0.765137\n",
      "Epoch: 58/140 Iteration: 4935 Train loss: 0.652406 Train acc: 0.731445\n",
      "Epoch: 58/140 Iteration: 4940 Train loss: 0.497992 Train acc: 0.830566\n",
      "Epoch: 58/140 Iteration: 4945 Train loss: 0.524677 Train acc: 0.778809\n",
      "Epoch: 58/140 Iteration: 4950 Train loss: 0.375921 Train acc: 0.858398\n",
      "Epoch: 58/140 Iteration: 4955 Train loss: 0.474901 Train acc: 0.815430\n",
      "Epoch: 58/140 Iteration: 4960 Train loss: 0.350712 Train acc: 0.876465\n",
      "Epoch: 58/140 Iteration: 4960 Validation loss: 1.573086 Validation acc: 0.408950\n",
      "Epoch: 58/140 Iteration: 4965 Train loss: 0.259411 Train acc: 0.905762\n",
      "Epoch: 58/140 Iteration: 4970 Train loss: 0.420715 Train acc: 0.835938\n",
      "Epoch: 58/140 Iteration: 4975 Train loss: 0.424320 Train acc: 0.841309\n",
      "Epoch: 58/140 Iteration: 4980 Train loss: 0.370419 Train acc: 0.884277\n",
      "Epoch: 58/140 Iteration: 4985 Train loss: 0.527924 Train acc: 0.783203\n",
      "Epoch: 58/140 Iteration: 4990 Train loss: 0.525543 Train acc: 0.801758\n",
      "Epoch: 58/140 Iteration: 4995 Train loss: 0.549008 Train acc: 0.789551\n",
      "Epoch: 58/140 Iteration: 5000 Train loss: 0.546176 Train acc: 0.776367\n",
      "Epoch: 58/140 Iteration: 5000 Validation loss: 1.898129 Validation acc: 0.385225\n",
      "Epoch: 58/140 Iteration: 5005 Train loss: 0.614097 Train acc: 0.733887\n",
      "Epoch: 58/140 Iteration: 5010 Train loss: 0.504939 Train acc: 0.793457\n",
      "Epoch: 58/140 Iteration: 5015 Train loss: 0.524403 Train acc: 0.788574\n",
      "Epoch: 59/140 Iteration: 5020 Train loss: 0.594498 Train acc: 0.765137\n",
      "Epoch: 59/140 Iteration: 5025 Train loss: 0.489058 Train acc: 0.808594\n",
      "Epoch: 59/140 Iteration: 5030 Train loss: 0.539850 Train acc: 0.784180\n",
      "Epoch: 59/140 Iteration: 5035 Train loss: 0.365537 Train acc: 0.869629\n",
      "Epoch: 59/140 Iteration: 5040 Train loss: 0.497801 Train acc: 0.820312\n",
      "Epoch: 59/140 Iteration: 5040 Validation loss: 1.631613 Validation acc: 0.418457\n",
      "Epoch: 59/140 Iteration: 5045 Train loss: 0.319802 Train acc: 0.879395\n",
      "Epoch: 59/140 Iteration: 5050 Train loss: 0.252800 Train acc: 0.907227\n",
      "Epoch: 59/140 Iteration: 5055 Train loss: 0.389446 Train acc: 0.842773\n",
      "Epoch: 59/140 Iteration: 5060 Train loss: 0.386819 Train acc: 0.845703\n",
      "Epoch: 59/140 Iteration: 5065 Train loss: 0.363408 Train acc: 0.886719\n",
      "Epoch: 59/140 Iteration: 5070 Train loss: 0.532459 Train acc: 0.777344\n",
      "Epoch: 59/140 Iteration: 5075 Train loss: 0.490023 Train acc: 0.825684\n",
      "Epoch: 59/140 Iteration: 5080 Train loss: 0.518886 Train acc: 0.812012\n",
      "Epoch: 59/140 Iteration: 5080 Validation loss: 1.852452 Validation acc: 0.388169\n",
      "Epoch: 59/140 Iteration: 5085 Train loss: 0.552656 Train acc: 0.774414\n",
      "Epoch: 59/140 Iteration: 5090 Train loss: 0.609396 Train acc: 0.744141\n",
      "Epoch: 59/140 Iteration: 5095 Train loss: 0.490099 Train acc: 0.809570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 59/140 Iteration: 5100 Train loss: 0.507108 Train acc: 0.787598\n",
      "Epoch: 60/140 Iteration: 5105 Train loss: 0.585599 Train acc: 0.761230\n",
      "Epoch: 60/140 Iteration: 5110 Train loss: 0.501687 Train acc: 0.812988\n",
      "Epoch: 60/140 Iteration: 5115 Train loss: 0.597113 Train acc: 0.756836\n",
      "Epoch: 60/140 Iteration: 5120 Train loss: 0.376137 Train acc: 0.859863\n",
      "Epoch: 60/140 Iteration: 5120 Validation loss: 1.661712 Validation acc: 0.419534\n",
      "Epoch: 60/140 Iteration: 5125 Train loss: 0.488838 Train acc: 0.812500\n",
      "Epoch: 60/140 Iteration: 5130 Train loss: 0.351715 Train acc: 0.864258\n",
      "Epoch: 60/140 Iteration: 5135 Train loss: 0.293546 Train acc: 0.896484\n",
      "Epoch: 60/140 Iteration: 5140 Train loss: 0.370127 Train acc: 0.858398\n",
      "Epoch: 60/140 Iteration: 5145 Train loss: 0.376638 Train acc: 0.862793\n",
      "Epoch: 60/140 Iteration: 5150 Train loss: 0.365786 Train acc: 0.884277\n",
      "Epoch: 60/140 Iteration: 5155 Train loss: 0.486715 Train acc: 0.803711\n",
      "Epoch: 60/140 Iteration: 5160 Train loss: 0.507710 Train acc: 0.810547\n",
      "Epoch: 60/140 Iteration: 5160 Validation loss: 1.791270 Validation acc: 0.402976\n",
      "Epoch: 60/140 Iteration: 5165 Train loss: 0.515682 Train acc: 0.800293\n",
      "Epoch: 60/140 Iteration: 5170 Train loss: 0.528698 Train acc: 0.793457\n",
      "Epoch: 60/140 Iteration: 5175 Train loss: 0.657007 Train acc: 0.707520\n",
      "Epoch: 60/140 Iteration: 5180 Train loss: 0.519751 Train acc: 0.795410\n",
      "Epoch: 60/140 Iteration: 5185 Train loss: 0.520217 Train acc: 0.785156\n",
      "Epoch: 61/140 Iteration: 5190 Train loss: 0.612426 Train acc: 0.747559\n",
      "Epoch: 61/140 Iteration: 5195 Train loss: 0.542803 Train acc: 0.788574\n",
      "Epoch: 61/140 Iteration: 5200 Train loss: 0.580646 Train acc: 0.764648\n",
      "Epoch: 61/140 Iteration: 5200 Validation loss: 1.738850 Validation acc: 0.416288\n",
      "Epoch: 61/140 Iteration: 5205 Train loss: 0.364759 Train acc: 0.869629\n",
      "Epoch: 61/140 Iteration: 5210 Train loss: 0.454335 Train acc: 0.826172\n",
      "Epoch: 61/140 Iteration: 5215 Train loss: 0.336395 Train acc: 0.877441\n",
      "Epoch: 61/140 Iteration: 5220 Train loss: 0.308371 Train acc: 0.896973\n",
      "Epoch: 61/140 Iteration: 5225 Train loss: 0.422015 Train acc: 0.845703\n",
      "Epoch: 61/140 Iteration: 5230 Train loss: 0.373713 Train acc: 0.859375\n",
      "Epoch: 61/140 Iteration: 5235 Train loss: 0.413928 Train acc: 0.862793\n",
      "Epoch: 61/140 Iteration: 5240 Train loss: 0.490841 Train acc: 0.799316\n",
      "Epoch: 61/140 Iteration: 5240 Validation loss: 1.808424 Validation acc: 0.393813\n",
      "Epoch: 61/140 Iteration: 5245 Train loss: 0.499453 Train acc: 0.814941\n",
      "Epoch: 61/140 Iteration: 5250 Train loss: 0.544359 Train acc: 0.797852\n",
      "Epoch: 61/140 Iteration: 5255 Train loss: 0.555458 Train acc: 0.761230\n",
      "Epoch: 61/140 Iteration: 5260 Train loss: 0.634199 Train acc: 0.722656\n",
      "Epoch: 61/140 Iteration: 5265 Train loss: 0.528098 Train acc: 0.781250\n",
      "Epoch: 61/140 Iteration: 5270 Train loss: 0.467347 Train acc: 0.828613\n",
      "Epoch: 62/140 Iteration: 5275 Train loss: 0.603231 Train acc: 0.746582\n",
      "Epoch: 62/140 Iteration: 5280 Train loss: 0.516770 Train acc: 0.800781\n",
      "Epoch: 62/140 Iteration: 5280 Validation loss: 1.906516 Validation acc: 0.365306\n",
      "Epoch: 62/140 Iteration: 5285 Train loss: 0.584112 Train acc: 0.764160\n",
      "Epoch: 62/140 Iteration: 5290 Train loss: 0.403414 Train acc: 0.853516\n",
      "Epoch: 62/140 Iteration: 5295 Train loss: 0.504427 Train acc: 0.794922\n",
      "Epoch: 62/140 Iteration: 5300 Train loss: 0.338513 Train acc: 0.885742\n",
      "Epoch: 62/140 Iteration: 5305 Train loss: 0.306649 Train acc: 0.886719\n",
      "Epoch: 62/140 Iteration: 5310 Train loss: 0.381939 Train acc: 0.851562\n",
      "Epoch: 62/140 Iteration: 5315 Train loss: 0.383567 Train acc: 0.865723\n",
      "Epoch: 62/140 Iteration: 5320 Train loss: 0.389787 Train acc: 0.871094\n",
      "Epoch: 62/140 Iteration: 5320 Validation loss: 1.689534 Validation acc: 0.397116\n",
      "Epoch: 62/140 Iteration: 5325 Train loss: 0.532014 Train acc: 0.792480\n",
      "Epoch: 62/140 Iteration: 5330 Train loss: 0.500706 Train acc: 0.823242\n",
      "Epoch: 62/140 Iteration: 5335 Train loss: 0.509141 Train acc: 0.807617\n",
      "Epoch: 62/140 Iteration: 5340 Train loss: 0.555543 Train acc: 0.774902\n",
      "Epoch: 62/140 Iteration: 5345 Train loss: 0.596369 Train acc: 0.736816\n",
      "Epoch: 62/140 Iteration: 5350 Train loss: 0.522865 Train acc: 0.785156\n",
      "Epoch: 62/140 Iteration: 5355 Train loss: 0.515771 Train acc: 0.811523\n",
      "Epoch: 63/140 Iteration: 5360 Train loss: 0.667124 Train acc: 0.736328\n",
      "Epoch: 63/140 Iteration: 5360 Validation loss: 1.925525 Validation acc: 0.379782\n",
      "Epoch: 63/140 Iteration: 5365 Train loss: 0.529799 Train acc: 0.788086\n",
      "Epoch: 63/140 Iteration: 5370 Train loss: 0.611028 Train acc: 0.753906\n",
      "Epoch: 63/140 Iteration: 5375 Train loss: 0.414789 Train acc: 0.840820\n",
      "Epoch: 63/140 Iteration: 5380 Train loss: 0.477297 Train acc: 0.820801\n",
      "Epoch: 63/140 Iteration: 5385 Train loss: 0.364162 Train acc: 0.861816\n",
      "Epoch: 63/140 Iteration: 5390 Train loss: 0.301956 Train acc: 0.892090\n",
      "Epoch: 63/140 Iteration: 5395 Train loss: 0.410673 Train acc: 0.847656\n",
      "Epoch: 63/140 Iteration: 5400 Train loss: 0.430911 Train acc: 0.842773\n",
      "Epoch: 63/140 Iteration: 5400 Validation loss: 1.723432 Validation acc: 0.397605\n",
      "Epoch: 63/140 Iteration: 5405 Train loss: 0.396961 Train acc: 0.866211\n",
      "Epoch: 63/140 Iteration: 5410 Train loss: 0.560858 Train acc: 0.766113\n",
      "Epoch: 63/140 Iteration: 5415 Train loss: 0.652283 Train acc: 0.765625\n",
      "Epoch: 63/140 Iteration: 5420 Train loss: 0.558448 Train acc: 0.791992\n",
      "Epoch: 63/140 Iteration: 5425 Train loss: 0.569531 Train acc: 0.768555\n",
      "Epoch: 63/140 Iteration: 5430 Train loss: 0.604194 Train acc: 0.748047\n",
      "Epoch: 63/140 Iteration: 5435 Train loss: 0.552416 Train acc: 0.773438\n",
      "Epoch: 63/140 Iteration: 5440 Train loss: 0.562839 Train acc: 0.771973\n",
      "Epoch: 63/140 Iteration: 5440 Validation loss: 1.837036 Validation acc: 0.397648\n",
      "Epoch: 64/140 Iteration: 5445 Train loss: 0.685316 Train acc: 0.733887\n",
      "Epoch: 64/140 Iteration: 5450 Train loss: 0.561419 Train acc: 0.769531\n",
      "Epoch: 64/140 Iteration: 5455 Train loss: 0.584425 Train acc: 0.760742\n",
      "Epoch: 64/140 Iteration: 5460 Train loss: 0.445772 Train acc: 0.828613\n",
      "Epoch: 64/140 Iteration: 5465 Train loss: 0.491558 Train acc: 0.810547\n",
      "Epoch: 64/140 Iteration: 5470 Train loss: 0.367582 Train acc: 0.854980\n",
      "Epoch: 64/140 Iteration: 5475 Train loss: 0.304940 Train acc: 0.888672\n",
      "Epoch: 64/140 Iteration: 5480 Train loss: 0.423534 Train acc: 0.831543\n",
      "Epoch: 64/140 Iteration: 5480 Validation loss: 1.630112 Validation acc: 0.407858\n",
      "Epoch: 64/140 Iteration: 5485 Train loss: 0.488322 Train acc: 0.813965\n",
      "Epoch: 64/140 Iteration: 5490 Train loss: 0.386449 Train acc: 0.877930\n",
      "Epoch: 64/140 Iteration: 5495 Train loss: 0.587855 Train acc: 0.748535\n",
      "Epoch: 64/140 Iteration: 5500 Train loss: 0.537466 Train acc: 0.791992\n",
      "Epoch: 64/140 Iteration: 5505 Train loss: 0.535466 Train acc: 0.800781\n",
      "Epoch: 64/140 Iteration: 5510 Train loss: 0.544474 Train acc: 0.782715\n",
      "Epoch: 64/140 Iteration: 5515 Train loss: 0.644353 Train acc: 0.722656\n",
      "Epoch: 64/140 Iteration: 5520 Train loss: 0.562004 Train acc: 0.776367\n",
      "Epoch: 64/140 Iteration: 5520 Validation loss: 1.776258 Validation acc: 0.372214\n",
      "Epoch: 64/140 Iteration: 5525 Train loss: 0.582444 Train acc: 0.771484\n",
      "Epoch: 65/140 Iteration: 5530 Train loss: 0.656313 Train acc: 0.748047\n",
      "Epoch: 65/140 Iteration: 5535 Train loss: 0.582530 Train acc: 0.774902\n",
      "Epoch: 65/140 Iteration: 5540 Train loss: 0.624000 Train acc: 0.744141\n",
      "Epoch: 65/140 Iteration: 5545 Train loss: 0.444828 Train acc: 0.834961\n",
      "Epoch: 65/140 Iteration: 5550 Train loss: 0.543002 Train acc: 0.784668\n",
      "Epoch: 65/140 Iteration: 5555 Train loss: 0.451676 Train acc: 0.832031\n",
      "Epoch: 65/140 Iteration: 5560 Train loss: 0.320239 Train acc: 0.880859\n",
      "Epoch: 65/140 Iteration: 5560 Validation loss: 1.605670 Validation acc: 0.390496\n",
      "Epoch: 65/140 Iteration: 5565 Train loss: 0.416576 Train acc: 0.841309\n",
      "Epoch: 65/140 Iteration: 5570 Train loss: 0.432090 Train acc: 0.838379\n",
      "Epoch: 65/140 Iteration: 5575 Train loss: 0.426781 Train acc: 0.852539\n",
      "Epoch: 65/140 Iteration: 5580 Train loss: 0.503353 Train acc: 0.796387\n",
      "Epoch: 65/140 Iteration: 5585 Train loss: 0.521269 Train acc: 0.804199\n",
      "Epoch: 65/140 Iteration: 5590 Train loss: 0.547518 Train acc: 0.791992\n",
      "Epoch: 65/140 Iteration: 5595 Train loss: 0.519116 Train acc: 0.786621\n",
      "Epoch: 65/140 Iteration: 5600 Train loss: 0.574732 Train acc: 0.764160\n",
      "Epoch: 65/140 Iteration: 5600 Validation loss: 1.919304 Validation acc: 0.378518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 65/140 Iteration: 5605 Train loss: 0.532452 Train acc: 0.786621\n",
      "Epoch: 65/140 Iteration: 5610 Train loss: 0.511578 Train acc: 0.803711\n",
      "Epoch: 66/140 Iteration: 5615 Train loss: 0.631501 Train acc: 0.757812\n",
      "Epoch: 66/140 Iteration: 5620 Train loss: 0.532294 Train acc: 0.799805\n",
      "Epoch: 66/140 Iteration: 5625 Train loss: 0.526533 Train acc: 0.783203\n",
      "Epoch: 66/140 Iteration: 5630 Train loss: 0.435244 Train acc: 0.834961\n",
      "Epoch: 66/140 Iteration: 5635 Train loss: 0.549662 Train acc: 0.783203\n",
      "Epoch: 66/140 Iteration: 5640 Train loss: 0.443597 Train acc: 0.824219\n",
      "Epoch: 66/140 Iteration: 5640 Validation loss: 1.630705 Validation acc: 0.400419\n",
      "Epoch: 66/140 Iteration: 5645 Train loss: 0.311881 Train acc: 0.885742\n",
      "Epoch: 66/140 Iteration: 5650 Train loss: 0.398405 Train acc: 0.843262\n",
      "Epoch: 66/140 Iteration: 5655 Train loss: 0.400090 Train acc: 0.850586\n",
      "Epoch: 66/140 Iteration: 5660 Train loss: 0.417837 Train acc: 0.852539\n",
      "Epoch: 66/140 Iteration: 5665 Train loss: 0.531878 Train acc: 0.777832\n",
      "Epoch: 66/140 Iteration: 5670 Train loss: 0.449683 Train acc: 0.847656\n",
      "Epoch: 66/140 Iteration: 5675 Train loss: 0.554867 Train acc: 0.792480\n",
      "Epoch: 66/140 Iteration: 5680 Train loss: 0.536377 Train acc: 0.783691\n",
      "Epoch: 66/140 Iteration: 5680 Validation loss: 1.859225 Validation acc: 0.372243\n",
      "Epoch: 66/140 Iteration: 5685 Train loss: 0.584934 Train acc: 0.752930\n",
      "Epoch: 66/140 Iteration: 5690 Train loss: 0.523026 Train acc: 0.780273\n",
      "Epoch: 66/140 Iteration: 5695 Train loss: 0.482795 Train acc: 0.812012\n",
      "Epoch: 67/140 Iteration: 5700 Train loss: 0.564609 Train acc: 0.780762\n",
      "Epoch: 67/140 Iteration: 5705 Train loss: 0.477057 Train acc: 0.827637\n",
      "Epoch: 67/140 Iteration: 5710 Train loss: 0.545249 Train acc: 0.785156\n",
      "Epoch: 67/140 Iteration: 5715 Train loss: 0.410400 Train acc: 0.854004\n",
      "Epoch: 67/140 Iteration: 5720 Train loss: 0.569948 Train acc: 0.761230\n",
      "Epoch: 67/140 Iteration: 5720 Validation loss: 1.622940 Validation acc: 0.409065\n",
      "Epoch: 67/140 Iteration: 5725 Train loss: 0.348650 Train acc: 0.875000\n",
      "Epoch: 67/140 Iteration: 5730 Train loss: 0.286429 Train acc: 0.897949\n",
      "Epoch: 67/140 Iteration: 5735 Train loss: 0.383003 Train acc: 0.849121\n",
      "Epoch: 67/140 Iteration: 5740 Train loss: 0.409635 Train acc: 0.834961\n",
      "Epoch: 67/140 Iteration: 5745 Train loss: 0.474254 Train acc: 0.823730\n",
      "Epoch: 67/140 Iteration: 5750 Train loss: 0.526767 Train acc: 0.785645\n",
      "Epoch: 67/140 Iteration: 5755 Train loss: 0.477216 Train acc: 0.845703\n",
      "Epoch: 67/140 Iteration: 5760 Train loss: 0.531532 Train acc: 0.802734\n",
      "Epoch: 67/140 Iteration: 5760 Validation loss: 1.838908 Validation acc: 0.378849\n",
      "Epoch: 67/140 Iteration: 5765 Train loss: 0.487945 Train acc: 0.799805\n",
      "Epoch: 67/140 Iteration: 5770 Train loss: 0.555507 Train acc: 0.776855\n",
      "Epoch: 67/140 Iteration: 5775 Train loss: 0.528789 Train acc: 0.788574\n",
      "Epoch: 67/140 Iteration: 5780 Train loss: 0.458665 Train acc: 0.835449\n",
      "Epoch: 68/140 Iteration: 5785 Train loss: 0.570406 Train acc: 0.778320\n",
      "Epoch: 68/140 Iteration: 5790 Train loss: 0.459761 Train acc: 0.833984\n",
      "Epoch: 68/140 Iteration: 5795 Train loss: 0.523495 Train acc: 0.790039\n",
      "Epoch: 68/140 Iteration: 5800 Train loss: 0.403781 Train acc: 0.849121\n",
      "Epoch: 68/140 Iteration: 5800 Validation loss: 1.681631 Validation acc: 0.399314\n",
      "Epoch: 68/140 Iteration: 5805 Train loss: 0.514482 Train acc: 0.796875\n",
      "Epoch: 68/140 Iteration: 5810 Train loss: 0.346414 Train acc: 0.878906\n",
      "Epoch: 68/140 Iteration: 5815 Train loss: 0.282214 Train acc: 0.906250\n",
      "Epoch: 68/140 Iteration: 5820 Train loss: 0.383991 Train acc: 0.853516\n",
      "Epoch: 68/140 Iteration: 5825 Train loss: 0.394112 Train acc: 0.852051\n",
      "Epoch: 68/140 Iteration: 5830 Train loss: 0.443328 Train acc: 0.844238\n",
      "Epoch: 68/140 Iteration: 5835 Train loss: 0.498699 Train acc: 0.793457\n",
      "Epoch: 68/140 Iteration: 5840 Train loss: 0.467048 Train acc: 0.841309\n",
      "Epoch: 68/140 Iteration: 5840 Validation loss: 1.828293 Validation acc: 0.373621\n",
      "Epoch: 68/140 Iteration: 5845 Train loss: 0.544313 Train acc: 0.797363\n",
      "Epoch: 68/140 Iteration: 5850 Train loss: 0.527031 Train acc: 0.791016\n",
      "Epoch: 68/140 Iteration: 5855 Train loss: 0.583014 Train acc: 0.767578\n",
      "Epoch: 68/140 Iteration: 5860 Train loss: 0.523986 Train acc: 0.785645\n",
      "Epoch: 68/140 Iteration: 5865 Train loss: 0.482273 Train acc: 0.814453\n",
      "Epoch: 69/140 Iteration: 5870 Train loss: 0.567066 Train acc: 0.790527\n",
      "Epoch: 69/140 Iteration: 5875 Train loss: 0.429204 Train acc: 0.844727\n",
      "Epoch: 69/140 Iteration: 5880 Train loss: 0.516306 Train acc: 0.793945\n",
      "Epoch: 69/140 Iteration: 5880 Validation loss: 1.794377 Validation acc: 0.377772\n",
      "Epoch: 69/140 Iteration: 5885 Train loss: 0.422648 Train acc: 0.841797\n",
      "Epoch: 69/140 Iteration: 5890 Train loss: 0.517286 Train acc: 0.793457\n",
      "Epoch: 69/140 Iteration: 5895 Train loss: 0.326373 Train acc: 0.882812\n",
      "Epoch: 69/140 Iteration: 5900 Train loss: 0.281896 Train acc: 0.900391\n",
      "Epoch: 69/140 Iteration: 5905 Train loss: 0.387060 Train acc: 0.849121\n",
      "Epoch: 69/140 Iteration: 5910 Train loss: 0.345594 Train acc: 0.879883\n",
      "Epoch: 69/140 Iteration: 5915 Train loss: 0.428509 Train acc: 0.857422\n",
      "Epoch: 69/140 Iteration: 5920 Train loss: 0.480849 Train acc: 0.805176\n",
      "Epoch: 69/140 Iteration: 5920 Validation loss: 1.806832 Validation acc: 0.374081\n",
      "Epoch: 69/140 Iteration: 5925 Train loss: 0.456425 Train acc: 0.840332\n",
      "Epoch: 69/140 Iteration: 5930 Train loss: 0.514502 Train acc: 0.810547\n",
      "Epoch: 69/140 Iteration: 5935 Train loss: 0.514950 Train acc: 0.789551\n",
      "Epoch: 69/140 Iteration: 5940 Train loss: 0.571458 Train acc: 0.762695\n",
      "Epoch: 69/140 Iteration: 5945 Train loss: 0.520273 Train acc: 0.786133\n",
      "Epoch: 69/140 Iteration: 5950 Train loss: 0.455887 Train acc: 0.830566\n",
      "Epoch: 70/140 Iteration: 5955 Train loss: 0.536266 Train acc: 0.799805\n",
      "Epoch: 70/140 Iteration: 5960 Train loss: 0.426990 Train acc: 0.845703\n",
      "Epoch: 70/140 Iteration: 5960 Validation loss: 1.847607 Validation acc: 0.375977\n",
      "Epoch: 70/140 Iteration: 5965 Train loss: 0.488543 Train acc: 0.802246\n",
      "Epoch: 70/140 Iteration: 5970 Train loss: 0.399956 Train acc: 0.854004\n",
      "Epoch: 70/140 Iteration: 5975 Train loss: 0.530686 Train acc: 0.783203\n",
      "Epoch: 70/140 Iteration: 5980 Train loss: 0.333979 Train acc: 0.878418\n",
      "Epoch: 70/140 Iteration: 5985 Train loss: 0.275782 Train acc: 0.904297\n",
      "Epoch: 70/140 Iteration: 5990 Train loss: 0.393627 Train acc: 0.850586\n",
      "Epoch: 70/140 Iteration: 5995 Train loss: 0.371903 Train acc: 0.864746\n",
      "Epoch: 70/140 Iteration: 6000 Train loss: 0.381014 Train acc: 0.871094\n",
      "Epoch: 70/140 Iteration: 6000 Validation loss: 2.035407 Validation acc: 0.339829\n",
      "Epoch: 70/140 Iteration: 6005 Train loss: 0.497611 Train acc: 0.791016\n",
      "Epoch: 70/140 Iteration: 6010 Train loss: 0.436973 Train acc: 0.857910\n",
      "Epoch: 70/140 Iteration: 6015 Train loss: 0.508280 Train acc: 0.814453\n",
      "Epoch: 70/140 Iteration: 6020 Train loss: 0.553834 Train acc: 0.767090\n",
      "Epoch: 70/140 Iteration: 6025 Train loss: 0.568873 Train acc: 0.756348\n",
      "Epoch: 70/140 Iteration: 6030 Train loss: 0.530534 Train acc: 0.786133\n",
      "Epoch: 70/140 Iteration: 6035 Train loss: 0.460165 Train acc: 0.821777\n",
      "Epoch: 71/140 Iteration: 6040 Train loss: 0.557968 Train acc: 0.788086\n",
      "Epoch: 71/140 Iteration: 6040 Validation loss: 1.861361 Validation acc: 0.374943\n",
      "Epoch: 71/140 Iteration: 6045 Train loss: 0.448040 Train acc: 0.852051\n",
      "Epoch: 71/140 Iteration: 6050 Train loss: 0.441810 Train acc: 0.819336\n",
      "Epoch: 71/140 Iteration: 6055 Train loss: 0.410787 Train acc: 0.838379\n",
      "Epoch: 71/140 Iteration: 6060 Train loss: 0.520106 Train acc: 0.786133\n",
      "Epoch: 71/140 Iteration: 6065 Train loss: 0.359747 Train acc: 0.876953\n",
      "Epoch: 71/140 Iteration: 6070 Train loss: 0.271921 Train acc: 0.905762\n",
      "Epoch: 71/140 Iteration: 6075 Train loss: 0.380186 Train acc: 0.853516\n",
      "Epoch: 71/140 Iteration: 6080 Train loss: 0.346424 Train acc: 0.875000\n",
      "Epoch: 71/140 Iteration: 6080 Validation loss: 1.715676 Validation acc: 0.389490\n",
      "Epoch: 71/140 Iteration: 6085 Train loss: 0.406277 Train acc: 0.866699\n",
      "Epoch: 71/140 Iteration: 6090 Train loss: 0.509030 Train acc: 0.790039\n",
      "Epoch: 71/140 Iteration: 6095 Train loss: 0.422228 Train acc: 0.855469\n",
      "Epoch: 71/140 Iteration: 6100 Train loss: 0.485516 Train acc: 0.820801\n",
      "Epoch: 71/140 Iteration: 6105 Train loss: 0.527743 Train acc: 0.786621\n",
      "Epoch: 71/140 Iteration: 6110 Train loss: 0.591538 Train acc: 0.740723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 71/140 Iteration: 6115 Train loss: 0.517688 Train acc: 0.789551\n",
      "Epoch: 71/140 Iteration: 6120 Train loss: 0.465618 Train acc: 0.823730\n",
      "Epoch: 71/140 Iteration: 6120 Validation loss: 1.958196 Validation acc: 0.368810\n",
      "Epoch: 72/140 Iteration: 6125 Train loss: 0.542572 Train acc: 0.799316\n",
      "Epoch: 72/140 Iteration: 6130 Train loss: 0.424814 Train acc: 0.847656\n",
      "Epoch: 72/140 Iteration: 6135 Train loss: 0.491040 Train acc: 0.809570\n",
      "Epoch: 72/140 Iteration: 6140 Train loss: 0.394861 Train acc: 0.847656\n",
      "Epoch: 72/140 Iteration: 6145 Train loss: 0.486616 Train acc: 0.810059\n",
      "Epoch: 72/140 Iteration: 6150 Train loss: 0.326362 Train acc: 0.879395\n",
      "Epoch: 72/140 Iteration: 6155 Train loss: 0.268219 Train acc: 0.903809\n",
      "Epoch: 72/140 Iteration: 6160 Train loss: 0.371121 Train acc: 0.854004\n",
      "Epoch: 72/140 Iteration: 6160 Validation loss: 1.766887 Validation acc: 0.380673\n",
      "Epoch: 72/140 Iteration: 6165 Train loss: 0.340010 Train acc: 0.881836\n",
      "Epoch: 72/140 Iteration: 6170 Train loss: 0.381173 Train acc: 0.869629\n",
      "Epoch: 72/140 Iteration: 6175 Train loss: 0.513651 Train acc: 0.784180\n",
      "Epoch: 72/140 Iteration: 6180 Train loss: 0.434642 Train acc: 0.843262\n",
      "Epoch: 72/140 Iteration: 6185 Train loss: 0.489773 Train acc: 0.811035\n",
      "Epoch: 72/140 Iteration: 6190 Train loss: 0.547875 Train acc: 0.770996\n",
      "Epoch: 72/140 Iteration: 6195 Train loss: 0.587481 Train acc: 0.766602\n",
      "Epoch: 72/140 Iteration: 6200 Train loss: 0.510111 Train acc: 0.789551\n",
      "Epoch: 72/140 Iteration: 6200 Validation loss: 1.965695 Validation acc: 0.352970\n",
      "Epoch: 72/140 Iteration: 6205 Train loss: 0.510401 Train acc: 0.812988\n",
      "Epoch: 73/140 Iteration: 6210 Train loss: 0.530859 Train acc: 0.802734\n",
      "Epoch: 73/140 Iteration: 6215 Train loss: 0.438241 Train acc: 0.841309\n",
      "Epoch: 73/140 Iteration: 6220 Train loss: 0.485206 Train acc: 0.810059\n",
      "Epoch: 73/140 Iteration: 6225 Train loss: 0.395871 Train acc: 0.848145\n",
      "Epoch: 73/140 Iteration: 6230 Train loss: 0.462025 Train acc: 0.826660\n",
      "Epoch: 73/140 Iteration: 6235 Train loss: 0.329704 Train acc: 0.879395\n",
      "Epoch: 73/140 Iteration: 6240 Train loss: 0.264091 Train acc: 0.907227\n",
      "Epoch: 73/140 Iteration: 6240 Validation loss: 1.861087 Validation acc: 0.399213\n",
      "Epoch: 73/140 Iteration: 6245 Train loss: 0.403122 Train acc: 0.850586\n",
      "Epoch: 73/140 Iteration: 6250 Train loss: 0.346023 Train acc: 0.882812\n",
      "Epoch: 73/140 Iteration: 6255 Train loss: 0.356520 Train acc: 0.891113\n",
      "Epoch: 73/140 Iteration: 6260 Train loss: 0.533999 Train acc: 0.780273\n",
      "Epoch: 73/140 Iteration: 6265 Train loss: 0.430756 Train acc: 0.851562\n",
      "Epoch: 73/140 Iteration: 6270 Train loss: 0.528327 Train acc: 0.801270\n",
      "Epoch: 73/140 Iteration: 6275 Train loss: 0.664483 Train acc: 0.721680\n",
      "Epoch: 73/140 Iteration: 6280 Train loss: 0.588590 Train acc: 0.757812\n",
      "Epoch: 73/140 Iteration: 6280 Validation loss: 1.845211 Validation acc: 0.370591\n",
      "Epoch: 73/140 Iteration: 6285 Train loss: 0.489987 Train acc: 0.802734\n",
      "Epoch: 73/140 Iteration: 6290 Train loss: 0.480698 Train acc: 0.812012\n",
      "Epoch: 74/140 Iteration: 6295 Train loss: 0.492145 Train acc: 0.817871\n",
      "Epoch: 74/140 Iteration: 6300 Train loss: 0.434591 Train acc: 0.840820\n",
      "Epoch: 74/140 Iteration: 6305 Train loss: 0.492688 Train acc: 0.800781\n",
      "Epoch: 74/140 Iteration: 6310 Train loss: 0.369029 Train acc: 0.854980\n",
      "Epoch: 74/140 Iteration: 6315 Train loss: 0.459918 Train acc: 0.830078\n",
      "Epoch: 74/140 Iteration: 6320 Train loss: 0.352724 Train acc: 0.872070\n",
      "Epoch: 74/140 Iteration: 6320 Validation loss: 1.828595 Validation acc: 0.409352\n",
      "Epoch: 74/140 Iteration: 6325 Train loss: 0.272583 Train acc: 0.900879\n",
      "Epoch: 74/140 Iteration: 6330 Train loss: 0.370820 Train acc: 0.849121\n",
      "Epoch: 74/140 Iteration: 6335 Train loss: 0.354872 Train acc: 0.872559\n",
      "Epoch: 74/140 Iteration: 6340 Train loss: 0.332876 Train acc: 0.891113\n",
      "Epoch: 74/140 Iteration: 6345 Train loss: 0.461028 Train acc: 0.824707\n",
      "Epoch: 74/140 Iteration: 6350 Train loss: 0.461125 Train acc: 0.843262\n",
      "Epoch: 74/140 Iteration: 6355 Train loss: 0.509487 Train acc: 0.803223\n",
      "Epoch: 74/140 Iteration: 6360 Train loss: 0.544613 Train acc: 0.778320\n",
      "Epoch: 74/140 Iteration: 6360 Validation loss: 1.940783 Validation acc: 0.368379\n",
      "Epoch: 74/140 Iteration: 6365 Train loss: 0.629668 Train acc: 0.739258\n",
      "Epoch: 74/140 Iteration: 6370 Train loss: 0.546111 Train acc: 0.776855\n",
      "Epoch: 74/140 Iteration: 6375 Train loss: 0.468623 Train acc: 0.816406\n",
      "Epoch: 75/140 Iteration: 6380 Train loss: 0.552712 Train acc: 0.803223\n",
      "Epoch: 75/140 Iteration: 6385 Train loss: 0.422934 Train acc: 0.857910\n",
      "Epoch: 75/140 Iteration: 6390 Train loss: 0.433919 Train acc: 0.832031\n",
      "Epoch: 75/140 Iteration: 6395 Train loss: 0.360700 Train acc: 0.869629\n",
      "Epoch: 75/140 Iteration: 6400 Train loss: 0.485187 Train acc: 0.813965\n",
      "Epoch: 75/140 Iteration: 6400 Validation loss: 1.804272 Validation acc: 0.399701\n",
      "Epoch: 75/140 Iteration: 6405 Train loss: 0.330631 Train acc: 0.884766\n",
      "Epoch: 75/140 Iteration: 6410 Train loss: 0.270720 Train acc: 0.899414\n",
      "Epoch: 75/140 Iteration: 6415 Train loss: 0.413364 Train acc: 0.833496\n",
      "Epoch: 75/140 Iteration: 6420 Train loss: 0.321731 Train acc: 0.889648\n",
      "Epoch: 75/140 Iteration: 6425 Train loss: 0.306457 Train acc: 0.904297\n",
      "Epoch: 75/140 Iteration: 6430 Train loss: 0.462948 Train acc: 0.812500\n",
      "Epoch: 75/140 Iteration: 6435 Train loss: 0.421240 Train acc: 0.855957\n",
      "Epoch: 75/140 Iteration: 6440 Train loss: 0.491361 Train acc: 0.829102\n",
      "Epoch: 75/140 Iteration: 6440 Validation loss: 1.990947 Validation acc: 0.388169\n",
      "Epoch: 75/140 Iteration: 6445 Train loss: 0.585234 Train acc: 0.755371\n",
      "Epoch: 75/140 Iteration: 6450 Train loss: 0.656122 Train acc: 0.722168\n",
      "Epoch: 75/140 Iteration: 6455 Train loss: 0.547583 Train acc: 0.782227\n",
      "Epoch: 75/140 Iteration: 6460 Train loss: 0.562282 Train acc: 0.771973\n",
      "Epoch: 76/140 Iteration: 6465 Train loss: 0.512467 Train acc: 0.812988\n",
      "Epoch: 76/140 Iteration: 6470 Train loss: 0.412182 Train acc: 0.862793\n",
      "Epoch: 76/140 Iteration: 6475 Train loss: 0.462573 Train acc: 0.824707\n",
      "Epoch: 76/140 Iteration: 6480 Train loss: 0.389886 Train acc: 0.855469\n",
      "Epoch: 76/140 Iteration: 6480 Validation loss: 1.908581 Validation acc: 0.392578\n",
      "Epoch: 76/140 Iteration: 6485 Train loss: 0.476508 Train acc: 0.814453\n",
      "Epoch: 76/140 Iteration: 6490 Train loss: 0.326607 Train acc: 0.880371\n",
      "Epoch: 76/140 Iteration: 6495 Train loss: 0.262944 Train acc: 0.907715\n",
      "Epoch: 76/140 Iteration: 6500 Train loss: 0.437082 Train acc: 0.834961\n",
      "Epoch: 76/140 Iteration: 6505 Train loss: 0.342086 Train acc: 0.887695\n",
      "Epoch: 76/140 Iteration: 6510 Train loss: 0.355995 Train acc: 0.886719\n",
      "Epoch: 76/140 Iteration: 6515 Train loss: 0.486528 Train acc: 0.805176\n",
      "Epoch: 76/140 Iteration: 6520 Train loss: 0.463455 Train acc: 0.839355\n",
      "Epoch: 76/140 Iteration: 6520 Validation loss: 1.915944 Validation acc: 0.400405\n",
      "Epoch: 76/140 Iteration: 6525 Train loss: 0.519508 Train acc: 0.796875\n",
      "Epoch: 76/140 Iteration: 6530 Train loss: 0.642865 Train acc: 0.737305\n",
      "Epoch: 76/140 Iteration: 6535 Train loss: 0.598576 Train acc: 0.749512\n",
      "Epoch: 76/140 Iteration: 6540 Train loss: 0.541303 Train acc: 0.770996\n",
      "Epoch: 76/140 Iteration: 6545 Train loss: 0.498285 Train acc: 0.801270\n",
      "Epoch: 77/140 Iteration: 6550 Train loss: 0.565641 Train acc: 0.782227\n",
      "Epoch: 77/140 Iteration: 6555 Train loss: 0.411772 Train acc: 0.859375\n",
      "Epoch: 77/140 Iteration: 6560 Train loss: 0.413154 Train acc: 0.831055\n",
      "Epoch: 77/140 Iteration: 6560 Validation loss: 1.853779 Validation acc: 0.390223\n",
      "Epoch: 77/140 Iteration: 6565 Train loss: 0.384393 Train acc: 0.860840\n",
      "Epoch: 77/140 Iteration: 6570 Train loss: 0.453428 Train acc: 0.828125\n",
      "Epoch: 77/140 Iteration: 6575 Train loss: 0.353232 Train acc: 0.872559\n",
      "Epoch: 77/140 Iteration: 6580 Train loss: 0.330013 Train acc: 0.886719\n",
      "Epoch: 77/140 Iteration: 6585 Train loss: 0.382679 Train acc: 0.854004\n",
      "Epoch: 77/140 Iteration: 6590 Train loss: 0.325939 Train acc: 0.892090\n",
      "Epoch: 77/140 Iteration: 6595 Train loss: 0.353127 Train acc: 0.888184\n",
      "Epoch: 77/140 Iteration: 6600 Train loss: 0.480370 Train acc: 0.805176\n",
      "Epoch: 77/140 Iteration: 6600 Validation loss: 1.903007 Validation acc: 0.388040\n",
      "Epoch: 77/140 Iteration: 6605 Train loss: 0.421195 Train acc: 0.847656\n",
      "Epoch: 77/140 Iteration: 6610 Train loss: 0.483948 Train acc: 0.814941\n",
      "Epoch: 77/140 Iteration: 6615 Train loss: 0.513592 Train acc: 0.790527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77/140 Iteration: 6620 Train loss: 0.602345 Train acc: 0.758789\n",
      "Epoch: 77/140 Iteration: 6625 Train loss: 0.497410 Train acc: 0.809082\n",
      "Epoch: 77/140 Iteration: 6630 Train loss: 0.473195 Train acc: 0.812012\n",
      "Epoch: 78/140 Iteration: 6635 Train loss: 0.493358 Train acc: 0.822754\n",
      "Epoch: 78/140 Iteration: 6640 Train loss: 0.399931 Train acc: 0.859375\n",
      "Epoch: 78/140 Iteration: 6640 Validation loss: 2.035206 Validation acc: 0.356575\n",
      "Epoch: 78/140 Iteration: 6645 Train loss: 0.471080 Train acc: 0.819824\n",
      "Epoch: 78/140 Iteration: 6650 Train loss: 0.392496 Train acc: 0.847656\n",
      "Epoch: 78/140 Iteration: 6655 Train loss: 0.464681 Train acc: 0.819824\n",
      "Epoch: 78/140 Iteration: 6660 Train loss: 0.320563 Train acc: 0.880859\n",
      "Epoch: 78/140 Iteration: 6665 Train loss: 0.283130 Train acc: 0.896973\n",
      "Epoch: 78/140 Iteration: 6670 Train loss: 0.385605 Train acc: 0.851074\n",
      "Epoch: 78/140 Iteration: 6675 Train loss: 0.333440 Train acc: 0.894043\n",
      "Epoch: 78/140 Iteration: 6680 Train loss: 0.393549 Train acc: 0.872070\n",
      "Epoch: 78/140 Iteration: 6680 Validation loss: 1.883139 Validation acc: 0.393971\n",
      "Epoch: 78/140 Iteration: 6685 Train loss: 0.465520 Train acc: 0.812500\n",
      "Epoch: 78/140 Iteration: 6690 Train loss: 0.412809 Train acc: 0.857910\n",
      "Epoch: 78/140 Iteration: 6695 Train loss: 0.493301 Train acc: 0.811523\n",
      "Epoch: 78/140 Iteration: 6700 Train loss: 0.527725 Train acc: 0.776855\n",
      "Epoch: 78/140 Iteration: 6705 Train loss: 0.581294 Train acc: 0.751953\n",
      "Epoch: 78/140 Iteration: 6710 Train loss: 0.478195 Train acc: 0.809570\n",
      "Epoch: 78/140 Iteration: 6715 Train loss: 0.450113 Train acc: 0.828613\n",
      "Epoch: 79/140 Iteration: 6720 Train loss: 0.585030 Train acc: 0.804688\n",
      "Epoch: 79/140 Iteration: 6720 Validation loss: 2.139037 Validation acc: 0.337790\n",
      "Epoch: 79/140 Iteration: 6725 Train loss: 0.399383 Train acc: 0.857422\n",
      "Epoch: 79/140 Iteration: 6730 Train loss: 0.459417 Train acc: 0.824219\n",
      "Epoch: 79/140 Iteration: 6735 Train loss: 0.364364 Train acc: 0.874512\n",
      "Epoch: 79/140 Iteration: 6740 Train loss: 0.455230 Train acc: 0.822754\n",
      "Epoch: 79/140 Iteration: 6745 Train loss: 0.326535 Train acc: 0.884277\n",
      "Epoch: 79/140 Iteration: 6750 Train loss: 0.260349 Train acc: 0.905762\n",
      "Epoch: 79/140 Iteration: 6755 Train loss: 0.400110 Train acc: 0.843750\n",
      "Epoch: 79/140 Iteration: 6760 Train loss: 0.342123 Train acc: 0.875488\n",
      "Epoch: 79/140 Iteration: 6760 Validation loss: 1.943204 Validation acc: 0.363942\n",
      "Epoch: 79/140 Iteration: 6765 Train loss: 0.345895 Train acc: 0.886719\n",
      "Epoch: 79/140 Iteration: 6770 Train loss: 0.478936 Train acc: 0.802246\n",
      "Epoch: 79/140 Iteration: 6775 Train loss: 0.423268 Train acc: 0.843750\n",
      "Epoch: 79/140 Iteration: 6780 Train loss: 0.490758 Train acc: 0.813477\n",
      "Epoch: 79/140 Iteration: 6785 Train loss: 0.574598 Train acc: 0.766113\n",
      "Epoch: 79/140 Iteration: 6790 Train loss: 0.595907 Train acc: 0.757812\n",
      "Epoch: 79/140 Iteration: 6795 Train loss: 0.498629 Train acc: 0.799316\n",
      "Epoch: 79/140 Iteration: 6800 Train loss: 0.516855 Train acc: 0.792969\n",
      "Epoch: 79/140 Iteration: 6800 Validation loss: 1.994226 Validation acc: 0.364143\n",
      "Epoch: 80/140 Iteration: 6805 Train loss: 0.527532 Train acc: 0.812988\n",
      "Epoch: 80/140 Iteration: 6810 Train loss: 0.383523 Train acc: 0.866211\n",
      "Epoch: 80/140 Iteration: 6815 Train loss: 0.435279 Train acc: 0.833984\n",
      "Epoch: 80/140 Iteration: 6820 Train loss: 0.352757 Train acc: 0.868164\n",
      "Epoch: 80/140 Iteration: 6825 Train loss: 0.456339 Train acc: 0.828125\n",
      "Epoch: 80/140 Iteration: 6830 Train loss: 0.315429 Train acc: 0.887207\n",
      "Epoch: 80/140 Iteration: 6835 Train loss: 0.291444 Train acc: 0.899902\n",
      "Epoch: 80/140 Iteration: 6840 Train loss: 0.409175 Train acc: 0.838867\n",
      "Epoch: 80/140 Iteration: 6840 Validation loss: 2.010347 Validation acc: 0.357307\n",
      "Epoch: 80/140 Iteration: 6845 Train loss: 0.337088 Train acc: 0.884766\n",
      "Epoch: 80/140 Iteration: 6850 Train loss: 0.309015 Train acc: 0.902344\n",
      "Epoch: 80/140 Iteration: 6855 Train loss: 0.466915 Train acc: 0.808594\n",
      "Epoch: 80/140 Iteration: 6860 Train loss: 0.395806 Train acc: 0.868652\n",
      "Epoch: 80/140 Iteration: 6865 Train loss: 0.477477 Train acc: 0.823242\n",
      "Epoch: 80/140 Iteration: 6870 Train loss: 0.483633 Train acc: 0.804688\n",
      "Epoch: 80/140 Iteration: 6875 Train loss: 0.584027 Train acc: 0.748535\n",
      "Epoch: 80/140 Iteration: 6880 Train loss: 0.478985 Train acc: 0.805176\n",
      "Epoch: 80/140 Iteration: 6880 Validation loss: 2.114155 Validation acc: 0.360179\n",
      "Epoch: 80/140 Iteration: 6885 Train loss: 0.507389 Train acc: 0.805664\n",
      "Epoch: 81/140 Iteration: 6890 Train loss: 0.565133 Train acc: 0.788574\n",
      "Epoch: 81/140 Iteration: 6895 Train loss: 0.393973 Train acc: 0.860352\n",
      "Epoch: 81/140 Iteration: 6900 Train loss: 0.461234 Train acc: 0.829102\n",
      "Epoch: 81/140 Iteration: 6905 Train loss: 0.373656 Train acc: 0.869629\n",
      "Epoch: 81/140 Iteration: 6910 Train loss: 0.443466 Train acc: 0.837891\n",
      "Epoch: 81/140 Iteration: 6915 Train loss: 0.301123 Train acc: 0.890137\n",
      "Epoch: 81/140 Iteration: 6920 Train loss: 0.257542 Train acc: 0.905762\n",
      "Epoch: 81/140 Iteration: 6920 Validation loss: 1.937321 Validation acc: 0.378475\n",
      "Epoch: 81/140 Iteration: 6925 Train loss: 0.369629 Train acc: 0.854492\n",
      "Epoch: 81/140 Iteration: 6930 Train loss: 0.331298 Train acc: 0.887695\n",
      "Epoch: 81/140 Iteration: 6935 Train loss: 0.334732 Train acc: 0.896973\n",
      "Epoch: 81/140 Iteration: 6940 Train loss: 0.475247 Train acc: 0.812012\n",
      "Epoch: 81/140 Iteration: 6945 Train loss: 0.418643 Train acc: 0.852051\n",
      "Epoch: 81/140 Iteration: 6950 Train loss: 0.484554 Train acc: 0.811523\n",
      "Epoch: 81/140 Iteration: 6955 Train loss: 0.456953 Train acc: 0.820801\n",
      "Epoch: 81/140 Iteration: 6960 Train loss: 0.582786 Train acc: 0.750488\n",
      "Epoch: 81/140 Iteration: 6960 Validation loss: 2.117360 Validation acc: 0.366498\n",
      "Epoch: 81/140 Iteration: 6965 Train loss: 0.471751 Train acc: 0.807617\n",
      "Epoch: 81/140 Iteration: 6970 Train loss: 0.513439 Train acc: 0.789551\n",
      "Epoch: 82/140 Iteration: 6975 Train loss: 0.534344 Train acc: 0.794434\n",
      "Epoch: 82/140 Iteration: 6980 Train loss: 0.377742 Train acc: 0.870117\n",
      "Epoch: 82/140 Iteration: 6985 Train loss: 0.429585 Train acc: 0.828125\n",
      "Epoch: 82/140 Iteration: 6990 Train loss: 0.361184 Train acc: 0.869629\n",
      "Epoch: 82/140 Iteration: 6995 Train loss: 0.429959 Train acc: 0.834961\n",
      "Epoch: 82/140 Iteration: 7000 Train loss: 0.299440 Train acc: 0.888184\n",
      "Epoch: 82/140 Iteration: 7000 Validation loss: 2.019750 Validation acc: 0.366355\n",
      "Epoch: 82/140 Iteration: 7005 Train loss: 0.289274 Train acc: 0.893555\n",
      "Epoch: 82/140 Iteration: 7010 Train loss: 0.410633 Train acc: 0.836426\n",
      "Epoch: 82/140 Iteration: 7015 Train loss: 0.360743 Train acc: 0.867676\n",
      "Epoch: 82/140 Iteration: 7020 Train loss: 0.315407 Train acc: 0.891602\n",
      "Epoch: 82/140 Iteration: 7025 Train loss: 0.465184 Train acc: 0.815430\n",
      "Epoch: 82/140 Iteration: 7030 Train loss: 0.390304 Train acc: 0.860840\n",
      "Epoch: 82/140 Iteration: 7035 Train loss: 0.497271 Train acc: 0.815918\n",
      "Epoch: 82/140 Iteration: 7040 Train loss: 0.467376 Train acc: 0.824219\n",
      "Epoch: 82/140 Iteration: 7040 Validation loss: 2.190629 Validation acc: 0.363899\n",
      "Epoch: 82/140 Iteration: 7045 Train loss: 0.584941 Train acc: 0.765137\n",
      "Epoch: 82/140 Iteration: 7050 Train loss: 0.464103 Train acc: 0.817383\n",
      "Epoch: 82/140 Iteration: 7055 Train loss: 0.449238 Train acc: 0.826660\n",
      "Epoch: 83/140 Iteration: 7060 Train loss: 0.476228 Train acc: 0.807129\n",
      "Epoch: 83/140 Iteration: 7065 Train loss: 0.388815 Train acc: 0.872559\n",
      "Epoch: 83/140 Iteration: 7070 Train loss: 0.446995 Train acc: 0.832031\n",
      "Epoch: 83/140 Iteration: 7075 Train loss: 0.350022 Train acc: 0.868164\n",
      "Epoch: 83/140 Iteration: 7080 Train loss: 0.418171 Train acc: 0.843262\n",
      "Epoch: 83/140 Iteration: 7080 Validation loss: 2.091632 Validation acc: 0.342989\n",
      "Epoch: 83/140 Iteration: 7085 Train loss: 0.327154 Train acc: 0.881348\n",
      "Epoch: 83/140 Iteration: 7090 Train loss: 0.358788 Train acc: 0.872559\n",
      "Epoch: 83/140 Iteration: 7095 Train loss: 0.407371 Train acc: 0.847656\n",
      "Epoch: 83/140 Iteration: 7100 Train loss: 0.363491 Train acc: 0.860840\n",
      "Epoch: 83/140 Iteration: 7105 Train loss: 0.313773 Train acc: 0.901367\n",
      "Epoch: 83/140 Iteration: 7110 Train loss: 0.450641 Train acc: 0.822754\n",
      "Epoch: 83/140 Iteration: 7115 Train loss: 0.387045 Train acc: 0.865234\n",
      "Epoch: 83/140 Iteration: 7120 Train loss: 0.487177 Train acc: 0.812500\n",
      "Epoch: 83/140 Iteration: 7120 Validation loss: 2.145341 Validation acc: 0.348504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 83/140 Iteration: 7125 Train loss: 0.441925 Train acc: 0.834473\n",
      "Epoch: 83/140 Iteration: 7130 Train loss: 0.574754 Train acc: 0.755371\n",
      "Epoch: 83/140 Iteration: 7135 Train loss: 0.476047 Train acc: 0.799805\n",
      "Epoch: 83/140 Iteration: 7140 Train loss: 0.441797 Train acc: 0.838867\n",
      "Epoch: 84/140 Iteration: 7145 Train loss: 0.518163 Train acc: 0.811523\n",
      "Epoch: 84/140 Iteration: 7150 Train loss: 0.382726 Train acc: 0.873535\n",
      "Epoch: 84/140 Iteration: 7155 Train loss: 0.425360 Train acc: 0.837402\n",
      "Epoch: 84/140 Iteration: 7160 Train loss: 0.334357 Train acc: 0.884766\n",
      "Epoch: 84/140 Iteration: 7160 Validation loss: 2.144405 Validation acc: 0.312371\n",
      "Epoch: 84/140 Iteration: 7165 Train loss: 0.451291 Train acc: 0.830078\n",
      "Epoch: 84/140 Iteration: 7170 Train loss: 0.324807 Train acc: 0.884766\n",
      "Epoch: 84/140 Iteration: 7175 Train loss: 0.299774 Train acc: 0.897461\n",
      "Epoch: 84/140 Iteration: 7180 Train loss: 0.399718 Train acc: 0.833496\n",
      "Epoch: 84/140 Iteration: 7185 Train loss: 0.340271 Train acc: 0.887207\n",
      "Epoch: 84/140 Iteration: 7190 Train loss: 0.358431 Train acc: 0.877441\n",
      "Epoch: 84/140 Iteration: 7195 Train loss: 0.439075 Train acc: 0.817383\n",
      "Epoch: 84/140 Iteration: 7200 Train loss: 0.408720 Train acc: 0.844727\n",
      "Epoch: 84/140 Iteration: 7200 Validation loss: 2.160045 Validation acc: 0.317469\n",
      "Epoch: 84/140 Iteration: 7205 Train loss: 0.473194 Train acc: 0.819336\n",
      "Epoch: 84/140 Iteration: 7210 Train loss: 0.487818 Train acc: 0.792969\n",
      "Epoch: 84/140 Iteration: 7215 Train loss: 0.590587 Train acc: 0.743652\n",
      "Epoch: 84/140 Iteration: 7220 Train loss: 0.473804 Train acc: 0.812012\n",
      "Epoch: 84/140 Iteration: 7225 Train loss: 0.486716 Train acc: 0.813477\n",
      "Epoch: 85/140 Iteration: 7230 Train loss: 0.533150 Train acc: 0.785156\n",
      "Epoch: 85/140 Iteration: 7235 Train loss: 0.353394 Train acc: 0.882812\n",
      "Epoch: 85/140 Iteration: 7240 Train loss: 0.413339 Train acc: 0.841309\n",
      "Epoch: 85/140 Iteration: 7240 Validation loss: 2.259215 Validation acc: 0.302318\n",
      "Epoch: 85/140 Iteration: 7245 Train loss: 0.322586 Train acc: 0.879883\n",
      "Epoch: 85/140 Iteration: 7250 Train loss: 0.451477 Train acc: 0.834961\n",
      "Epoch: 85/140 Iteration: 7255 Train loss: 0.313921 Train acc: 0.884277\n",
      "Epoch: 85/140 Iteration: 7260 Train loss: 0.280022 Train acc: 0.903320\n",
      "Epoch: 85/140 Iteration: 7265 Train loss: 0.371463 Train acc: 0.850586\n",
      "Epoch: 85/140 Iteration: 7270 Train loss: 0.323127 Train acc: 0.885742\n",
      "Epoch: 85/140 Iteration: 7275 Train loss: 0.373125 Train acc: 0.863281\n",
      "Epoch: 85/140 Iteration: 7280 Train loss: 0.432862 Train acc: 0.827148\n",
      "Epoch: 85/140 Iteration: 7280 Validation loss: 2.248758 Validation acc: 0.312529\n",
      "Epoch: 85/140 Iteration: 7285 Train loss: 0.424815 Train acc: 0.842285\n",
      "Epoch: 85/140 Iteration: 7290 Train loss: 0.502026 Train acc: 0.813477\n",
      "Epoch: 85/140 Iteration: 7295 Train loss: 0.462063 Train acc: 0.819824\n",
      "Epoch: 85/140 Iteration: 7300 Train loss: 0.584810 Train acc: 0.764648\n",
      "Epoch: 85/140 Iteration: 7305 Train loss: 0.473787 Train acc: 0.791992\n",
      "Epoch: 85/140 Iteration: 7310 Train loss: 0.495528 Train acc: 0.801758\n",
      "Epoch: 86/140 Iteration: 7315 Train loss: 0.603675 Train acc: 0.772949\n",
      "Epoch: 86/140 Iteration: 7320 Train loss: 0.368802 Train acc: 0.874512\n",
      "Epoch: 86/140 Iteration: 7320 Validation loss: 2.271300 Validation acc: 0.304688\n",
      "Epoch: 86/140 Iteration: 7325 Train loss: 0.421074 Train acc: 0.846191\n",
      "Epoch: 86/140 Iteration: 7330 Train loss: 0.326773 Train acc: 0.883301\n",
      "Epoch: 86/140 Iteration: 7335 Train loss: 0.439684 Train acc: 0.838379\n",
      "Epoch: 86/140 Iteration: 7340 Train loss: 0.296511 Train acc: 0.893555\n",
      "Epoch: 86/140 Iteration: 7345 Train loss: 0.293053 Train acc: 0.898438\n",
      "Epoch: 86/140 Iteration: 7350 Train loss: 0.394542 Train acc: 0.849609\n",
      "Epoch: 86/140 Iteration: 7355 Train loss: 0.323389 Train acc: 0.877930\n",
      "Epoch: 86/140 Iteration: 7360 Train loss: 0.360583 Train acc: 0.872559\n",
      "Epoch: 86/140 Iteration: 7360 Validation loss: 2.163451 Validation acc: 0.326646\n",
      "Epoch: 86/140 Iteration: 7365 Train loss: 0.442693 Train acc: 0.815918\n",
      "Epoch: 86/140 Iteration: 7370 Train loss: 0.405120 Train acc: 0.849609\n",
      "Epoch: 86/140 Iteration: 7375 Train loss: 0.528867 Train acc: 0.786133\n",
      "Epoch: 86/140 Iteration: 7380 Train loss: 0.486121 Train acc: 0.814941\n",
      "Epoch: 86/140 Iteration: 7385 Train loss: 0.611914 Train acc: 0.735840\n",
      "Epoch: 86/140 Iteration: 7390 Train loss: 0.478395 Train acc: 0.804688\n",
      "Epoch: 86/140 Iteration: 7395 Train loss: 0.548878 Train acc: 0.775879\n",
      "Epoch: 87/140 Iteration: 7400 Train loss: 0.503989 Train acc: 0.814941\n",
      "Epoch: 87/140 Iteration: 7400 Validation loss: 2.145054 Validation acc: 0.343951\n",
      "Epoch: 87/140 Iteration: 7405 Train loss: 0.395729 Train acc: 0.868652\n",
      "Epoch: 87/140 Iteration: 7410 Train loss: 0.401184 Train acc: 0.845703\n",
      "Epoch: 87/140 Iteration: 7415 Train loss: 0.328088 Train acc: 0.870605\n",
      "Epoch: 87/140 Iteration: 7420 Train loss: 0.443105 Train acc: 0.835449\n",
      "Epoch: 87/140 Iteration: 7425 Train loss: 0.329631 Train acc: 0.868652\n",
      "Epoch: 87/140 Iteration: 7430 Train loss: 0.310475 Train acc: 0.891113\n",
      "Epoch: 87/140 Iteration: 7435 Train loss: 0.388677 Train acc: 0.850098\n",
      "Epoch: 87/140 Iteration: 7440 Train loss: 0.358436 Train acc: 0.858887\n",
      "Epoch: 87/140 Iteration: 7440 Validation loss: 2.103539 Validation acc: 0.350141\n",
      "Epoch: 87/140 Iteration: 7445 Train loss: 0.347733 Train acc: 0.881836\n",
      "Epoch: 87/140 Iteration: 7450 Train loss: 0.459325 Train acc: 0.821289\n",
      "Epoch: 87/140 Iteration: 7455 Train loss: 0.439407 Train acc: 0.851074\n",
      "Epoch: 87/140 Iteration: 7460 Train loss: 0.478783 Train acc: 0.814453\n",
      "Epoch: 87/140 Iteration: 7465 Train loss: 0.465898 Train acc: 0.832520\n",
      "Epoch: 87/140 Iteration: 7470 Train loss: 0.606268 Train acc: 0.750488\n",
      "Epoch: 87/140 Iteration: 7475 Train loss: 0.593694 Train acc: 0.742676\n",
      "Epoch: 87/140 Iteration: 7480 Train loss: 0.549963 Train acc: 0.768555\n",
      "Epoch: 87/140 Iteration: 7480 Validation loss: 1.962983 Validation acc: 0.396369\n",
      "Epoch: 88/140 Iteration: 7485 Train loss: 0.513682 Train acc: 0.811035\n",
      "Epoch: 88/140 Iteration: 7490 Train loss: 0.381785 Train acc: 0.868164\n",
      "Epoch: 88/140 Iteration: 7495 Train loss: 0.416295 Train acc: 0.828125\n",
      "Epoch: 88/140 Iteration: 7500 Train loss: 0.340433 Train acc: 0.881348\n",
      "Epoch: 88/140 Iteration: 7505 Train loss: 0.441320 Train acc: 0.830078\n",
      "Epoch: 88/140 Iteration: 7510 Train loss: 0.451128 Train acc: 0.836914\n",
      "Epoch: 88/140 Iteration: 7515 Train loss: 0.341447 Train acc: 0.876465\n",
      "Epoch: 88/140 Iteration: 7520 Train loss: 0.358691 Train acc: 0.868164\n",
      "Epoch: 88/140 Iteration: 7520 Validation loss: 2.123825 Validation acc: 0.350069\n",
      "Epoch: 88/140 Iteration: 7525 Train loss: 0.321022 Train acc: 0.893066\n",
      "Epoch: 88/140 Iteration: 7530 Train loss: 0.358581 Train acc: 0.877930\n",
      "Epoch: 88/140 Iteration: 7535 Train loss: 0.458714 Train acc: 0.815430\n",
      "Epoch: 88/140 Iteration: 7540 Train loss: 0.426277 Train acc: 0.852539\n",
      "Epoch: 88/140 Iteration: 7545 Train loss: 0.497562 Train acc: 0.806641\n",
      "Epoch: 88/140 Iteration: 7550 Train loss: 0.518883 Train acc: 0.805176\n",
      "Epoch: 88/140 Iteration: 7555 Train loss: 0.620704 Train acc: 0.739258\n",
      "Epoch: 88/140 Iteration: 7560 Train loss: 0.736657 Train acc: 0.682129\n",
      "Epoch: 88/140 Iteration: 7560 Validation loss: 1.933634 Validation acc: 0.386776\n",
      "Epoch: 88/140 Iteration: 7565 Train loss: 0.563528 Train acc: 0.781738\n",
      "Epoch: 89/140 Iteration: 7570 Train loss: 0.508452 Train acc: 0.804688\n",
      "Epoch: 89/140 Iteration: 7575 Train loss: 0.416941 Train acc: 0.855957\n",
      "Epoch: 89/140 Iteration: 7580 Train loss: 0.417579 Train acc: 0.844727\n",
      "Epoch: 89/140 Iteration: 7585 Train loss: 0.329976 Train acc: 0.877930\n",
      "Epoch: 89/140 Iteration: 7590 Train loss: 0.440992 Train acc: 0.840332\n",
      "Epoch: 89/140 Iteration: 7595 Train loss: 0.347903 Train acc: 0.871094\n",
      "Epoch: 89/140 Iteration: 7600 Train loss: 0.322277 Train acc: 0.893066\n",
      "Epoch: 89/140 Iteration: 7600 Validation loss: 2.089578 Validation acc: 0.370203\n",
      "Epoch: 89/140 Iteration: 7605 Train loss: 0.354649 Train acc: 0.869141\n",
      "Epoch: 89/140 Iteration: 7610 Train loss: 0.368857 Train acc: 0.866211\n",
      "Epoch: 89/140 Iteration: 7615 Train loss: 0.356282 Train acc: 0.874512\n",
      "Epoch: 89/140 Iteration: 7620 Train loss: 0.459852 Train acc: 0.813477\n",
      "Epoch: 89/140 Iteration: 7625 Train loss: 0.431181 Train acc: 0.848145\n",
      "Epoch: 89/140 Iteration: 7630 Train loss: 0.486540 Train acc: 0.824707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 89/140 Iteration: 7635 Train loss: 0.654354 Train acc: 0.732422\n",
      "Epoch: 89/140 Iteration: 7640 Train loss: 0.679338 Train acc: 0.716797\n",
      "Epoch: 89/140 Iteration: 7640 Validation loss: 1.965274 Validation acc: 0.382970\n",
      "Epoch: 89/140 Iteration: 7645 Train loss: 0.610821 Train acc: 0.736328\n",
      "Epoch: 89/140 Iteration: 7650 Train loss: 0.664291 Train acc: 0.739258\n",
      "Epoch: 90/140 Iteration: 7655 Train loss: 0.518965 Train acc: 0.805176\n",
      "Epoch: 90/140 Iteration: 7660 Train loss: 0.410128 Train acc: 0.861328\n",
      "Epoch: 90/140 Iteration: 7665 Train loss: 0.411554 Train acc: 0.835938\n",
      "Epoch: 90/140 Iteration: 7670 Train loss: 0.333386 Train acc: 0.879395\n",
      "Epoch: 90/140 Iteration: 7675 Train loss: 0.443181 Train acc: 0.828613\n",
      "Epoch: 90/140 Iteration: 7680 Train loss: 0.341809 Train acc: 0.875488\n",
      "Epoch: 90/140 Iteration: 7680 Validation loss: 2.082378 Validation acc: 0.339944\n",
      "Epoch: 90/140 Iteration: 7685 Train loss: 0.277421 Train acc: 0.897461\n",
      "Epoch: 90/140 Iteration: 7690 Train loss: 0.331339 Train acc: 0.870117\n",
      "Epoch: 90/140 Iteration: 7695 Train loss: 0.334877 Train acc: 0.887695\n",
      "Epoch: 90/140 Iteration: 7700 Train loss: 0.336592 Train acc: 0.889160\n",
      "Epoch: 90/140 Iteration: 7705 Train loss: 0.447875 Train acc: 0.813477\n",
      "Epoch: 90/140 Iteration: 7710 Train loss: 0.540202 Train acc: 0.791992\n",
      "Epoch: 90/140 Iteration: 7715 Train loss: 0.504327 Train acc: 0.802246\n",
      "Epoch: 90/140 Iteration: 7720 Train loss: 0.684815 Train acc: 0.719727\n",
      "Epoch: 90/140 Iteration: 7720 Validation loss: 1.991804 Validation acc: 0.365163\n",
      "Epoch: 90/140 Iteration: 7725 Train loss: 0.598083 Train acc: 0.762207\n",
      "Epoch: 90/140 Iteration: 7730 Train loss: 0.587924 Train acc: 0.754883\n",
      "Epoch: 90/140 Iteration: 7735 Train loss: 0.643943 Train acc: 0.733398\n",
      "Epoch: 91/140 Iteration: 7740 Train loss: 0.566138 Train acc: 0.787109\n",
      "Epoch: 91/140 Iteration: 7745 Train loss: 0.412560 Train acc: 0.868164\n",
      "Epoch: 91/140 Iteration: 7750 Train loss: 0.401393 Train acc: 0.856934\n",
      "Epoch: 91/140 Iteration: 7755 Train loss: 0.362034 Train acc: 0.868652\n",
      "Epoch: 91/140 Iteration: 7760 Train loss: 0.449764 Train acc: 0.835449\n",
      "Epoch: 91/140 Iteration: 7760 Validation loss: 1.954770 Validation acc: 0.342687\n",
      "Epoch: 91/140 Iteration: 7765 Train loss: 0.341105 Train acc: 0.871582\n",
      "Epoch: 91/140 Iteration: 7770 Train loss: 0.262255 Train acc: 0.912598\n",
      "Epoch: 91/140 Iteration: 7775 Train loss: 0.338023 Train acc: 0.863281\n",
      "Epoch: 91/140 Iteration: 7780 Train loss: 0.375918 Train acc: 0.870605\n",
      "Epoch: 91/140 Iteration: 7785 Train loss: 0.346083 Train acc: 0.877441\n",
      "Epoch: 91/140 Iteration: 7790 Train loss: 0.446980 Train acc: 0.812988\n",
      "Epoch: 91/140 Iteration: 7795 Train loss: 0.418481 Train acc: 0.859375\n",
      "Epoch: 91/140 Iteration: 7800 Train loss: 0.490113 Train acc: 0.814941\n",
      "Epoch: 91/140 Iteration: 7800 Validation loss: 2.134562 Validation acc: 0.353185\n",
      "Epoch: 91/140 Iteration: 7805 Train loss: 0.633072 Train acc: 0.747070\n",
      "Epoch: 91/140 Iteration: 7810 Train loss: 0.594557 Train acc: 0.750000\n",
      "Epoch: 91/140 Iteration: 7815 Train loss: 0.596701 Train acc: 0.746094\n",
      "Epoch: 91/140 Iteration: 7820 Train loss: 0.644692 Train acc: 0.734863\n",
      "Epoch: 92/140 Iteration: 7825 Train loss: 0.524671 Train acc: 0.802246\n",
      "Epoch: 92/140 Iteration: 7830 Train loss: 0.388518 Train acc: 0.866211\n",
      "Epoch: 92/140 Iteration: 7835 Train loss: 0.420097 Train acc: 0.841309\n",
      "Epoch: 92/140 Iteration: 7840 Train loss: 0.340484 Train acc: 0.872559\n",
      "Epoch: 92/140 Iteration: 7840 Validation loss: 2.070955 Validation acc: 0.319322\n",
      "Epoch: 92/140 Iteration: 7845 Train loss: 0.466538 Train acc: 0.827637\n",
      "Epoch: 92/140 Iteration: 7850 Train loss: 0.327072 Train acc: 0.875488\n",
      "Epoch: 92/140 Iteration: 7855 Train loss: 0.270177 Train acc: 0.904785\n",
      "Epoch: 92/140 Iteration: 7860 Train loss: 0.339564 Train acc: 0.863770\n",
      "Epoch: 92/140 Iteration: 7865 Train loss: 0.333530 Train acc: 0.881836\n",
      "Epoch: 92/140 Iteration: 7870 Train loss: 0.318504 Train acc: 0.900391\n",
      "Epoch: 92/140 Iteration: 7875 Train loss: 0.431158 Train acc: 0.821289\n",
      "Epoch: 92/140 Iteration: 7880 Train loss: 0.428918 Train acc: 0.856445\n",
      "Epoch: 92/140 Iteration: 7880 Validation loss: 2.064564 Validation acc: 0.357637\n",
      "Epoch: 92/140 Iteration: 7885 Train loss: 0.496707 Train acc: 0.810059\n",
      "Epoch: 92/140 Iteration: 7890 Train loss: 0.616637 Train acc: 0.737305\n",
      "Epoch: 92/140 Iteration: 7895 Train loss: 0.564572 Train acc: 0.753906\n",
      "Epoch: 92/140 Iteration: 7900 Train loss: 0.515362 Train acc: 0.801758\n",
      "Epoch: 92/140 Iteration: 7905 Train loss: 0.520013 Train acc: 0.785645\n",
      "Epoch: 93/140 Iteration: 7910 Train loss: 0.579785 Train acc: 0.784180\n",
      "Epoch: 93/140 Iteration: 7915 Train loss: 0.382537 Train acc: 0.870117\n",
      "Epoch: 93/140 Iteration: 7920 Train loss: 0.375917 Train acc: 0.853516\n",
      "Epoch: 93/140 Iteration: 7920 Validation loss: 1.945382 Validation acc: 0.373262\n",
      "Epoch: 93/140 Iteration: 7925 Train loss: 0.368242 Train acc: 0.862305\n",
      "Epoch: 93/140 Iteration: 7930 Train loss: 0.461973 Train acc: 0.822266\n",
      "Epoch: 93/140 Iteration: 7935 Train loss: 0.290162 Train acc: 0.896973\n",
      "Epoch: 93/140 Iteration: 7940 Train loss: 0.275028 Train acc: 0.894043\n",
      "Epoch: 93/140 Iteration: 7945 Train loss: 0.349123 Train acc: 0.866699\n",
      "Epoch: 93/140 Iteration: 7950 Train loss: 0.346639 Train acc: 0.875977\n",
      "Epoch: 93/140 Iteration: 7955 Train loss: 0.320526 Train acc: 0.889160\n",
      "Epoch: 93/140 Iteration: 7960 Train loss: 0.416445 Train acc: 0.835449\n",
      "Epoch: 93/140 Iteration: 7960 Validation loss: 2.081615 Validation acc: 0.358944\n",
      "Epoch: 93/140 Iteration: 7965 Train loss: 0.444077 Train acc: 0.836426\n",
      "Epoch: 93/140 Iteration: 7970 Train loss: 0.479801 Train acc: 0.822754\n",
      "Epoch: 93/140 Iteration: 7975 Train loss: 0.646430 Train acc: 0.718262\n",
      "Epoch: 93/140 Iteration: 7980 Train loss: 0.583063 Train acc: 0.757324\n",
      "Epoch: 93/140 Iteration: 7985 Train loss: 0.578743 Train acc: 0.761719\n",
      "Epoch: 93/140 Iteration: 7990 Train loss: 0.534528 Train acc: 0.789062\n",
      "Epoch: 94/140 Iteration: 7995 Train loss: 0.545220 Train acc: 0.797363\n",
      "Epoch: 94/140 Iteration: 8000 Train loss: 0.396866 Train acc: 0.864258\n",
      "Epoch: 94/140 Iteration: 8000 Validation loss: 2.003942 Validation acc: 0.381204\n",
      "Epoch: 94/140 Iteration: 8005 Train loss: 0.434378 Train acc: 0.840332\n",
      "Epoch: 94/140 Iteration: 8010 Train loss: 0.377699 Train acc: 0.859375\n",
      "Epoch: 94/140 Iteration: 8015 Train loss: 0.431601 Train acc: 0.836914\n",
      "Epoch: 94/140 Iteration: 8020 Train loss: 0.314314 Train acc: 0.886230\n",
      "Epoch: 94/140 Iteration: 8025 Train loss: 0.269506 Train acc: 0.897949\n",
      "Epoch: 94/140 Iteration: 8030 Train loss: 0.320620 Train acc: 0.874512\n",
      "Epoch: 94/140 Iteration: 8035 Train loss: 0.366051 Train acc: 0.869629\n",
      "Epoch: 94/140 Iteration: 8040 Train loss: 0.354168 Train acc: 0.874512\n",
      "Epoch: 94/140 Iteration: 8040 Validation loss: 1.911788 Validation acc: 0.379294\n",
      "Epoch: 94/140 Iteration: 8045 Train loss: 0.410035 Train acc: 0.830566\n",
      "Epoch: 94/140 Iteration: 8050 Train loss: 0.406115 Train acc: 0.863770\n",
      "Epoch: 94/140 Iteration: 8055 Train loss: 0.482423 Train acc: 0.812012\n",
      "Epoch: 94/140 Iteration: 8060 Train loss: 0.663495 Train acc: 0.712891\n",
      "Epoch: 94/140 Iteration: 8065 Train loss: 0.576760 Train acc: 0.753418\n",
      "Epoch: 94/140 Iteration: 8070 Train loss: 0.510279 Train acc: 0.792480\n",
      "Epoch: 94/140 Iteration: 8075 Train loss: 0.506573 Train acc: 0.804199\n",
      "Epoch: 95/140 Iteration: 8080 Train loss: 0.536410 Train acc: 0.800781\n",
      "Epoch: 95/140 Iteration: 8080 Validation loss: 2.103021 Validation acc: 0.361342\n",
      "Epoch: 95/140 Iteration: 8085 Train loss: 0.400507 Train acc: 0.860352\n",
      "Epoch: 95/140 Iteration: 8090 Train loss: 0.408760 Train acc: 0.840820\n",
      "Epoch: 95/140 Iteration: 8095 Train loss: 0.369045 Train acc: 0.876953\n",
      "Epoch: 95/140 Iteration: 8100 Train loss: 0.401269 Train acc: 0.860352\n",
      "Epoch: 95/140 Iteration: 8105 Train loss: 0.322403 Train acc: 0.881836\n",
      "Epoch: 95/140 Iteration: 8110 Train loss: 0.246214 Train acc: 0.914062\n",
      "Epoch: 95/140 Iteration: 8115 Train loss: 0.366552 Train acc: 0.856934\n",
      "Epoch: 95/140 Iteration: 8120 Train loss: 0.305815 Train acc: 0.893555\n",
      "Epoch: 95/140 Iteration: 8120 Validation loss: 2.000893 Validation acc: 0.358599\n",
      "Epoch: 95/140 Iteration: 8125 Train loss: 0.342817 Train acc: 0.882324\n",
      "Epoch: 95/140 Iteration: 8130 Train loss: 0.440964 Train acc: 0.824219\n",
      "Epoch: 95/140 Iteration: 8135 Train loss: 0.393704 Train acc: 0.862793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 95/140 Iteration: 8140 Train loss: 0.492310 Train acc: 0.814453\n",
      "Epoch: 95/140 Iteration: 8145 Train loss: 0.603606 Train acc: 0.731934\n",
      "Epoch: 95/140 Iteration: 8150 Train loss: 0.564015 Train acc: 0.764648\n",
      "Epoch: 95/140 Iteration: 8155 Train loss: 0.500487 Train acc: 0.815430\n",
      "Epoch: 95/140 Iteration: 8160 Train loss: 0.622849 Train acc: 0.730957\n",
      "Epoch: 95/140 Iteration: 8160 Validation loss: 2.020464 Validation acc: 0.371697\n",
      "Epoch: 96/140 Iteration: 8165 Train loss: 0.487644 Train acc: 0.815430\n",
      "Epoch: 96/140 Iteration: 8170 Train loss: 0.393532 Train acc: 0.861328\n",
      "Epoch: 96/140 Iteration: 8175 Train loss: 0.394238 Train acc: 0.846191\n",
      "Epoch: 96/140 Iteration: 8180 Train loss: 0.341376 Train acc: 0.879395\n",
      "Epoch: 96/140 Iteration: 8185 Train loss: 0.391382 Train acc: 0.863281\n",
      "Epoch: 96/140 Iteration: 8190 Train loss: 0.325582 Train acc: 0.883789\n",
      "Epoch: 96/140 Iteration: 8195 Train loss: 0.280649 Train acc: 0.900879\n",
      "Epoch: 96/140 Iteration: 8200 Train loss: 0.351680 Train acc: 0.866699\n",
      "Epoch: 96/140 Iteration: 8200 Validation loss: 2.029676 Validation acc: 0.348216\n",
      "Epoch: 96/140 Iteration: 8205 Train loss: 0.322738 Train acc: 0.889160\n",
      "Epoch: 96/140 Iteration: 8210 Train loss: 0.310207 Train acc: 0.902344\n",
      "Epoch: 96/140 Iteration: 8215 Train loss: 0.463836 Train acc: 0.814453\n",
      "Epoch: 96/140 Iteration: 8220 Train loss: 0.392572 Train acc: 0.860352\n",
      "Epoch: 96/140 Iteration: 8225 Train loss: 0.520088 Train acc: 0.801758\n",
      "Epoch: 96/140 Iteration: 8230 Train loss: 0.582309 Train acc: 0.743164\n",
      "Epoch: 96/140 Iteration: 8235 Train loss: 0.599160 Train acc: 0.756836\n",
      "Epoch: 96/140 Iteration: 8240 Train loss: 0.488080 Train acc: 0.800781\n",
      "Epoch: 96/140 Iteration: 8240 Validation loss: 1.942140 Validation acc: 0.395594\n",
      "Epoch: 96/140 Iteration: 8245 Train loss: 0.718831 Train acc: 0.686035\n",
      "Epoch: 97/140 Iteration: 8250 Train loss: 0.471604 Train acc: 0.818359\n",
      "Epoch: 97/140 Iteration: 8255 Train loss: 0.364285 Train acc: 0.878418\n",
      "Epoch: 97/140 Iteration: 8260 Train loss: 0.391053 Train acc: 0.843262\n",
      "Epoch: 97/140 Iteration: 8265 Train loss: 0.323488 Train acc: 0.880859\n",
      "Epoch: 97/140 Iteration: 8270 Train loss: 0.421644 Train acc: 0.850586\n",
      "Epoch: 97/140 Iteration: 8275 Train loss: 0.306271 Train acc: 0.895020\n",
      "Epoch: 97/140 Iteration: 8280 Train loss: 0.253622 Train acc: 0.913086\n",
      "Epoch: 97/140 Iteration: 8280 Validation loss: 2.073227 Validation acc: 0.342903\n",
      "Epoch: 97/140 Iteration: 8285 Train loss: 0.370415 Train acc: 0.845703\n",
      "Epoch: 97/140 Iteration: 8290 Train loss: 0.311427 Train acc: 0.885254\n",
      "Epoch: 97/140 Iteration: 8295 Train loss: 0.316068 Train acc: 0.891602\n",
      "Epoch: 97/140 Iteration: 8300 Train loss: 0.417992 Train acc: 0.835938\n",
      "Epoch: 97/140 Iteration: 8305 Train loss: 0.397300 Train acc: 0.858887\n",
      "Epoch: 97/140 Iteration: 8310 Train loss: 0.498205 Train acc: 0.808594\n",
      "Epoch: 97/140 Iteration: 8315 Train loss: 0.597239 Train acc: 0.737793\n",
      "Epoch: 97/140 Iteration: 8320 Train loss: 0.529806 Train acc: 0.783691\n",
      "Epoch: 97/140 Iteration: 8320 Validation loss: 2.053802 Validation acc: 0.375776\n",
      "Epoch: 97/140 Iteration: 8325 Train loss: 0.507957 Train acc: 0.797363\n",
      "Epoch: 97/140 Iteration: 8330 Train loss: 0.610039 Train acc: 0.746094\n",
      "Epoch: 98/140 Iteration: 8335 Train loss: 0.506992 Train acc: 0.808594\n",
      "Epoch: 98/140 Iteration: 8340 Train loss: 0.364778 Train acc: 0.875488\n",
      "Epoch: 98/140 Iteration: 8345 Train loss: 0.367750 Train acc: 0.857910\n",
      "Epoch: 98/140 Iteration: 8350 Train loss: 0.326401 Train acc: 0.883301\n",
      "Epoch: 98/140 Iteration: 8355 Train loss: 0.391228 Train acc: 0.849609\n",
      "Epoch: 98/140 Iteration: 8360 Train loss: 0.314936 Train acc: 0.878906\n",
      "Epoch: 98/140 Iteration: 8360 Validation loss: 2.013654 Validation acc: 0.370074\n",
      "Epoch: 98/140 Iteration: 8365 Train loss: 0.255279 Train acc: 0.905273\n",
      "Epoch: 98/140 Iteration: 8370 Train loss: 0.334104 Train acc: 0.875000\n",
      "Epoch: 98/140 Iteration: 8375 Train loss: 0.319033 Train acc: 0.890625\n",
      "Epoch: 98/140 Iteration: 8380 Train loss: 0.315536 Train acc: 0.895508\n",
      "Epoch: 98/140 Iteration: 8385 Train loss: 0.427520 Train acc: 0.822754\n",
      "Epoch: 98/140 Iteration: 8390 Train loss: 0.408674 Train acc: 0.854980\n",
      "Epoch: 98/140 Iteration: 8395 Train loss: 0.516894 Train acc: 0.793457\n",
      "Epoch: 98/140 Iteration: 8400 Train loss: 0.547230 Train acc: 0.773438\n",
      "Epoch: 98/140 Iteration: 8400 Validation loss: 2.006480 Validation acc: 0.361486\n",
      "Epoch: 98/140 Iteration: 8405 Train loss: 0.576534 Train acc: 0.755371\n",
      "Epoch: 98/140 Iteration: 8410 Train loss: 0.534047 Train acc: 0.783691\n",
      "Epoch: 98/140 Iteration: 8415 Train loss: 0.588524 Train acc: 0.742188\n",
      "Epoch: 99/140 Iteration: 8420 Train loss: 0.494800 Train acc: 0.813965\n",
      "Epoch: 99/140 Iteration: 8425 Train loss: 0.401518 Train acc: 0.867188\n",
      "Epoch: 99/140 Iteration: 8430 Train loss: 0.387798 Train acc: 0.843262\n",
      "Epoch: 99/140 Iteration: 8435 Train loss: 0.342276 Train acc: 0.880859\n",
      "Epoch: 99/140 Iteration: 8440 Train loss: 0.495155 Train acc: 0.824219\n",
      "Epoch: 99/140 Iteration: 8440 Validation loss: 2.079376 Validation acc: 0.353530\n",
      "Epoch: 99/140 Iteration: 8445 Train loss: 0.430068 Train acc: 0.852051\n",
      "Epoch: 99/140 Iteration: 8450 Train loss: 0.386269 Train acc: 0.848633\n",
      "Epoch: 99/140 Iteration: 8455 Train loss: 0.383461 Train acc: 0.845703\n",
      "Epoch: 99/140 Iteration: 8460 Train loss: 0.299823 Train acc: 0.900879\n",
      "Epoch: 99/140 Iteration: 8465 Train loss: 0.309321 Train acc: 0.901367\n",
      "Epoch: 99/140 Iteration: 8470 Train loss: 0.439404 Train acc: 0.826172\n",
      "Epoch: 99/140 Iteration: 8475 Train loss: 0.409799 Train acc: 0.851562\n",
      "Epoch: 99/140 Iteration: 8480 Train loss: 0.495683 Train acc: 0.809570\n",
      "Epoch: 99/140 Iteration: 8480 Validation loss: 2.033432 Validation acc: 0.364962\n",
      "Epoch: 99/140 Iteration: 8485 Train loss: 0.572156 Train acc: 0.766602\n",
      "Epoch: 99/140 Iteration: 8490 Train loss: 0.582663 Train acc: 0.764160\n",
      "Epoch: 99/140 Iteration: 8495 Train loss: 0.510182 Train acc: 0.798828\n",
      "Epoch: 99/140 Iteration: 8500 Train loss: 0.496001 Train acc: 0.814453\n",
      "Epoch: 100/140 Iteration: 8505 Train loss: 0.503726 Train acc: 0.806641\n",
      "Epoch: 100/140 Iteration: 8510 Train loss: 0.398208 Train acc: 0.868164\n",
      "Epoch: 100/140 Iteration: 8515 Train loss: 0.385289 Train acc: 0.847168\n",
      "Epoch: 100/140 Iteration: 8520 Train loss: 0.319708 Train acc: 0.887695\n",
      "Epoch: 100/140 Iteration: 8520 Validation loss: 2.058872 Validation acc: 0.357077\n",
      "Epoch: 100/140 Iteration: 8525 Train loss: 0.446371 Train acc: 0.832520\n",
      "Epoch: 100/140 Iteration: 8530 Train loss: 0.325267 Train acc: 0.879883\n",
      "Epoch: 100/140 Iteration: 8535 Train loss: 0.295358 Train acc: 0.891113\n",
      "Epoch: 100/140 Iteration: 8540 Train loss: 0.350146 Train acc: 0.865723\n",
      "Epoch: 100/140 Iteration: 8545 Train loss: 0.317967 Train acc: 0.896484\n",
      "Epoch: 100/140 Iteration: 8550 Train loss: 0.373377 Train acc: 0.866211\n",
      "Epoch: 100/140 Iteration: 8555 Train loss: 0.433418 Train acc: 0.824707\n",
      "Epoch: 100/140 Iteration: 8560 Train loss: 0.420323 Train acc: 0.847656\n",
      "Epoch: 100/140 Iteration: 8560 Validation loss: 2.023079 Validation acc: 0.375144\n",
      "Epoch: 100/140 Iteration: 8565 Train loss: 0.512401 Train acc: 0.813477\n",
      "Epoch: 100/140 Iteration: 8570 Train loss: 0.559414 Train acc: 0.765625\n",
      "Epoch: 100/140 Iteration: 8575 Train loss: 0.542418 Train acc: 0.777832\n",
      "Epoch: 100/140 Iteration: 8580 Train loss: 0.536650 Train acc: 0.777344\n",
      "Epoch: 100/140 Iteration: 8585 Train loss: 0.515821 Train acc: 0.805664\n",
      "Epoch: 101/140 Iteration: 8590 Train loss: 0.513453 Train acc: 0.805176\n",
      "Epoch: 101/140 Iteration: 8595 Train loss: 0.382226 Train acc: 0.873047\n",
      "Epoch: 101/140 Iteration: 8600 Train loss: 0.380773 Train acc: 0.851562\n",
      "Epoch: 101/140 Iteration: 8600 Validation loss: 2.013396 Validation acc: 0.374110\n",
      "Epoch: 101/140 Iteration: 8605 Train loss: 0.341343 Train acc: 0.892578\n",
      "Epoch: 101/140 Iteration: 8610 Train loss: 0.423776 Train acc: 0.836426\n",
      "Epoch: 101/140 Iteration: 8615 Train loss: 0.310626 Train acc: 0.878906\n",
      "Epoch: 101/140 Iteration: 8620 Train loss: 0.291246 Train acc: 0.896484\n",
      "Epoch: 101/140 Iteration: 8625 Train loss: 0.336309 Train acc: 0.863770\n",
      "Epoch: 101/140 Iteration: 8630 Train loss: 0.291422 Train acc: 0.903320\n",
      "Epoch: 101/140 Iteration: 8635 Train loss: 0.336665 Train acc: 0.885254\n",
      "Epoch: 101/140 Iteration: 8640 Train loss: 0.421811 Train acc: 0.824219\n",
      "Epoch: 101/140 Iteration: 8640 Validation loss: 2.051767 Validation acc: 0.376910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 101/140 Iteration: 8645 Train loss: 0.441280 Train acc: 0.841797\n",
      "Epoch: 101/140 Iteration: 8650 Train loss: 0.466516 Train acc: 0.829102\n",
      "Epoch: 101/140 Iteration: 8655 Train loss: 0.538389 Train acc: 0.788086\n",
      "Epoch: 101/140 Iteration: 8660 Train loss: 0.590448 Train acc: 0.769043\n",
      "Epoch: 101/140 Iteration: 8665 Train loss: 0.465658 Train acc: 0.819824\n",
      "Epoch: 101/140 Iteration: 8670 Train loss: 0.504115 Train acc: 0.802734\n",
      "Epoch: 102/140 Iteration: 8675 Train loss: 0.472199 Train acc: 0.825195\n",
      "Epoch: 102/140 Iteration: 8680 Train loss: 0.374652 Train acc: 0.870605\n",
      "Epoch: 102/140 Iteration: 8680 Validation loss: 1.965617 Validation acc: 0.395091\n",
      "Epoch: 102/140 Iteration: 8685 Train loss: 0.390616 Train acc: 0.848633\n",
      "Epoch: 102/140 Iteration: 8690 Train loss: 0.328167 Train acc: 0.877930\n",
      "Epoch: 102/140 Iteration: 8695 Train loss: 0.465825 Train acc: 0.824707\n",
      "Epoch: 102/140 Iteration: 8700 Train loss: 0.319891 Train acc: 0.887695\n",
      "Epoch: 102/140 Iteration: 8705 Train loss: 0.268485 Train acc: 0.899414\n",
      "Epoch: 102/140 Iteration: 8710 Train loss: 0.330034 Train acc: 0.868164\n",
      "Epoch: 102/140 Iteration: 8715 Train loss: 0.282662 Train acc: 0.905762\n",
      "Epoch: 102/140 Iteration: 8720 Train loss: 0.329197 Train acc: 0.890625\n",
      "Epoch: 102/140 Iteration: 8720 Validation loss: 1.997504 Validation acc: 0.389060\n",
      "Epoch: 102/140 Iteration: 8725 Train loss: 0.405682 Train acc: 0.834473\n",
      "Epoch: 102/140 Iteration: 8730 Train loss: 0.393521 Train acc: 0.862305\n",
      "Epoch: 102/140 Iteration: 8735 Train loss: 0.461922 Train acc: 0.831055\n",
      "Epoch: 102/140 Iteration: 8740 Train loss: 0.559568 Train acc: 0.771973\n",
      "Epoch: 102/140 Iteration: 8745 Train loss: 0.585521 Train acc: 0.755859\n",
      "Epoch: 102/140 Iteration: 8750 Train loss: 0.526617 Train acc: 0.778320\n",
      "Epoch: 102/140 Iteration: 8755 Train loss: 0.568800 Train acc: 0.762207\n",
      "Epoch: 103/140 Iteration: 8760 Train loss: 0.476648 Train acc: 0.813477\n",
      "Epoch: 103/140 Iteration: 8760 Validation loss: 2.103351 Validation acc: 0.377398\n",
      "Epoch: 103/140 Iteration: 8765 Train loss: 0.363202 Train acc: 0.877930\n",
      "Epoch: 103/140 Iteration: 8770 Train loss: 0.375594 Train acc: 0.859375\n",
      "Epoch: 103/140 Iteration: 8775 Train loss: 0.322838 Train acc: 0.884766\n",
      "Epoch: 103/140 Iteration: 8780 Train loss: 0.411962 Train acc: 0.847168\n",
      "Epoch: 103/140 Iteration: 8785 Train loss: 0.286397 Train acc: 0.892578\n",
      "Epoch: 103/140 Iteration: 8790 Train loss: 0.255538 Train acc: 0.903809\n",
      "Epoch: 103/140 Iteration: 8795 Train loss: 0.333424 Train acc: 0.865234\n",
      "Epoch: 103/140 Iteration: 8800 Train loss: 0.270771 Train acc: 0.906738\n",
      "Epoch: 103/140 Iteration: 8800 Validation loss: 2.010993 Validation acc: 0.399658\n",
      "Epoch: 103/140 Iteration: 8805 Train loss: 0.329261 Train acc: 0.882812\n",
      "Epoch: 103/140 Iteration: 8810 Train loss: 0.404961 Train acc: 0.828125\n",
      "Epoch: 103/140 Iteration: 8815 Train loss: 0.397105 Train acc: 0.866211\n",
      "Epoch: 103/140 Iteration: 8820 Train loss: 0.521138 Train acc: 0.804688\n",
      "Epoch: 103/140 Iteration: 8825 Train loss: 0.615388 Train acc: 0.750977\n",
      "Epoch: 103/140 Iteration: 8830 Train loss: 0.582711 Train acc: 0.766113\n",
      "Epoch: 103/140 Iteration: 8835 Train loss: 0.593543 Train acc: 0.762207\n",
      "Epoch: 103/140 Iteration: 8840 Train loss: 0.660139 Train acc: 0.711914\n",
      "Epoch: 103/140 Iteration: 8840 Validation loss: 1.846102 Validation acc: 0.405747\n",
      "Epoch: 104/140 Iteration: 8845 Train loss: 0.500787 Train acc: 0.813965\n",
      "Epoch: 104/140 Iteration: 8850 Train loss: 0.370331 Train acc: 0.872559\n",
      "Epoch: 104/140 Iteration: 8855 Train loss: 0.403663 Train acc: 0.842773\n",
      "Epoch: 104/140 Iteration: 8860 Train loss: 0.331245 Train acc: 0.884277\n",
      "Epoch: 104/140 Iteration: 8865 Train loss: 0.398272 Train acc: 0.850098\n",
      "Epoch: 104/140 Iteration: 8870 Train loss: 0.292518 Train acc: 0.891113\n",
      "Epoch: 104/140 Iteration: 8875 Train loss: 0.264212 Train acc: 0.901367\n",
      "Epoch: 104/140 Iteration: 8880 Train loss: 0.339550 Train acc: 0.870117\n",
      "Epoch: 104/140 Iteration: 8880 Validation loss: 2.060442 Validation acc: 0.360423\n",
      "Epoch: 104/140 Iteration: 8885 Train loss: 0.285520 Train acc: 0.899902\n",
      "Epoch: 104/140 Iteration: 8890 Train loss: 0.327281 Train acc: 0.883301\n",
      "Epoch: 104/140 Iteration: 8895 Train loss: 0.430339 Train acc: 0.835449\n",
      "Epoch: 104/140 Iteration: 8900 Train loss: 0.408459 Train acc: 0.854492\n",
      "Epoch: 104/140 Iteration: 8905 Train loss: 0.500948 Train acc: 0.811035\n",
      "Epoch: 104/140 Iteration: 8910 Train loss: 0.575790 Train acc: 0.761719\n",
      "Epoch: 104/140 Iteration: 8915 Train loss: 0.643519 Train acc: 0.733398\n",
      "Epoch: 104/140 Iteration: 8920 Train loss: 0.553910 Train acc: 0.787109\n",
      "Epoch: 104/140 Iteration: 8920 Validation loss: 1.811036 Validation acc: 0.398208\n",
      "Epoch: 104/140 Iteration: 8925 Train loss: 0.696022 Train acc: 0.687500\n",
      "Epoch: 105/140 Iteration: 8930 Train loss: 0.565456 Train acc: 0.773926\n",
      "Epoch: 105/140 Iteration: 8935 Train loss: 0.423160 Train acc: 0.844238\n",
      "Epoch: 105/140 Iteration: 8940 Train loss: 0.377066 Train acc: 0.854980\n",
      "Epoch: 105/140 Iteration: 8945 Train loss: 0.350718 Train acc: 0.876465\n",
      "Epoch: 105/140 Iteration: 8950 Train loss: 0.426657 Train acc: 0.843750\n",
      "Epoch: 105/140 Iteration: 8955 Train loss: 0.310392 Train acc: 0.891602\n",
      "Epoch: 105/140 Iteration: 8960 Train loss: 0.262606 Train acc: 0.900391\n",
      "Epoch: 105/140 Iteration: 8960 Validation loss: 1.993123 Validation acc: 0.346292\n",
      "Epoch: 105/140 Iteration: 8965 Train loss: 0.334371 Train acc: 0.872070\n",
      "Epoch: 105/140 Iteration: 8970 Train loss: 0.304979 Train acc: 0.901367\n",
      "Epoch: 105/140 Iteration: 8975 Train loss: 0.332214 Train acc: 0.880859\n",
      "Epoch: 105/140 Iteration: 8980 Train loss: 0.414439 Train acc: 0.830078\n",
      "Epoch: 105/140 Iteration: 8985 Train loss: 0.433639 Train acc: 0.850098\n",
      "Epoch: 105/140 Iteration: 8990 Train loss: 0.510659 Train acc: 0.794434\n",
      "Epoch: 105/140 Iteration: 8995 Train loss: 0.532325 Train acc: 0.770996\n",
      "Epoch: 105/140 Iteration: 9000 Train loss: 0.584644 Train acc: 0.756348\n",
      "Epoch: 105/140 Iteration: 9000 Validation loss: 1.916351 Validation acc: 0.407442\n",
      "Epoch: 105/140 Iteration: 9005 Train loss: 0.505962 Train acc: 0.812012\n",
      "Epoch: 105/140 Iteration: 9010 Train loss: 0.646588 Train acc: 0.719238\n",
      "Epoch: 106/140 Iteration: 9015 Train loss: 0.504700 Train acc: 0.810547\n",
      "Epoch: 106/140 Iteration: 9020 Train loss: 0.425229 Train acc: 0.850586\n",
      "Epoch: 106/140 Iteration: 9025 Train loss: 0.403091 Train acc: 0.844727\n",
      "Epoch: 106/140 Iteration: 9030 Train loss: 0.330411 Train acc: 0.886230\n",
      "Epoch: 106/140 Iteration: 9035 Train loss: 0.433166 Train acc: 0.833496\n",
      "Epoch: 106/140 Iteration: 9040 Train loss: 0.310042 Train acc: 0.887695\n",
      "Epoch: 106/140 Iteration: 9040 Validation loss: 2.055901 Validation acc: 0.341294\n",
      "Epoch: 106/140 Iteration: 9045 Train loss: 0.304383 Train acc: 0.898438\n",
      "Epoch: 106/140 Iteration: 9050 Train loss: 0.341919 Train acc: 0.866699\n",
      "Epoch: 106/140 Iteration: 9055 Train loss: 0.284723 Train acc: 0.910645\n",
      "Epoch: 106/140 Iteration: 9060 Train loss: 0.309114 Train acc: 0.887695\n",
      "Epoch: 106/140 Iteration: 9065 Train loss: 0.395053 Train acc: 0.848145\n",
      "Epoch: 106/140 Iteration: 9070 Train loss: 0.378536 Train acc: 0.871582\n",
      "Epoch: 106/140 Iteration: 9075 Train loss: 0.487254 Train acc: 0.799316\n",
      "Epoch: 106/140 Iteration: 9080 Train loss: 0.524850 Train acc: 0.792480\n",
      "Epoch: 106/140 Iteration: 9080 Validation loss: 1.970974 Validation acc: 0.376666\n",
      "Epoch: 106/140 Iteration: 9085 Train loss: 0.612126 Train acc: 0.748535\n",
      "Epoch: 106/140 Iteration: 9090 Train loss: 0.477755 Train acc: 0.812988\n",
      "Epoch: 106/140 Iteration: 9095 Train loss: 0.567988 Train acc: 0.771973\n",
      "Epoch: 107/140 Iteration: 9100 Train loss: 0.489173 Train acc: 0.814453\n",
      "Epoch: 107/140 Iteration: 9105 Train loss: 0.428435 Train acc: 0.845703\n",
      "Epoch: 107/140 Iteration: 9110 Train loss: 0.386505 Train acc: 0.850098\n",
      "Epoch: 107/140 Iteration: 9115 Train loss: 0.332736 Train acc: 0.883789\n",
      "Epoch: 107/140 Iteration: 9120 Train loss: 0.466664 Train acc: 0.837402\n",
      "Epoch: 107/140 Iteration: 9120 Validation loss: 2.065319 Validation acc: 0.353602\n",
      "Epoch: 107/140 Iteration: 9125 Train loss: 0.323737 Train acc: 0.888672\n",
      "Epoch: 107/140 Iteration: 9130 Train loss: 0.288969 Train acc: 0.887207\n",
      "Epoch: 107/140 Iteration: 9135 Train loss: 0.312232 Train acc: 0.878418\n",
      "Epoch: 107/140 Iteration: 9140 Train loss: 0.304951 Train acc: 0.902832\n",
      "Epoch: 107/140 Iteration: 9145 Train loss: 0.308148 Train acc: 0.897949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 107/140 Iteration: 9150 Train loss: 0.408902 Train acc: 0.831543\n",
      "Epoch: 107/140 Iteration: 9155 Train loss: 0.371540 Train acc: 0.873047\n",
      "Epoch: 107/140 Iteration: 9160 Train loss: 0.491581 Train acc: 0.815918\n",
      "Epoch: 107/140 Iteration: 9160 Validation loss: 2.143549 Validation acc: 0.363755\n",
      "Epoch: 107/140 Iteration: 9165 Train loss: 0.504404 Train acc: 0.784668\n",
      "Epoch: 107/140 Iteration: 9170 Train loss: 0.609380 Train acc: 0.755859\n",
      "Epoch: 107/140 Iteration: 9175 Train loss: 0.500466 Train acc: 0.812012\n",
      "Epoch: 107/140 Iteration: 9180 Train loss: 0.534448 Train acc: 0.783203\n",
      "Epoch: 108/140 Iteration: 9185 Train loss: 0.461545 Train acc: 0.833008\n",
      "Epoch: 108/140 Iteration: 9190 Train loss: 0.375830 Train acc: 0.865234\n",
      "Epoch: 108/140 Iteration: 9195 Train loss: 0.372464 Train acc: 0.855469\n",
      "Epoch: 108/140 Iteration: 9200 Train loss: 0.323438 Train acc: 0.884277\n",
      "Epoch: 108/140 Iteration: 9200 Validation loss: 2.111292 Validation acc: 0.358944\n",
      "Epoch: 108/140 Iteration: 9205 Train loss: 0.404320 Train acc: 0.845215\n",
      "Epoch: 108/140 Iteration: 9210 Train loss: 0.307081 Train acc: 0.885742\n",
      "Epoch: 108/140 Iteration: 9215 Train loss: 0.287064 Train acc: 0.894531\n",
      "Epoch: 108/140 Iteration: 9220 Train loss: 0.314224 Train acc: 0.877441\n",
      "Epoch: 108/140 Iteration: 9225 Train loss: 0.276447 Train acc: 0.906738\n",
      "Epoch: 108/140 Iteration: 9230 Train loss: 0.281120 Train acc: 0.904785\n",
      "Epoch: 108/140 Iteration: 9235 Train loss: 0.403077 Train acc: 0.840820\n",
      "Epoch: 108/140 Iteration: 9240 Train loss: 0.359594 Train acc: 0.875488\n",
      "Epoch: 108/140 Iteration: 9240 Validation loss: 2.184349 Validation acc: 0.381118\n",
      "Epoch: 108/140 Iteration: 9245 Train loss: 0.494713 Train acc: 0.801758\n",
      "Epoch: 108/140 Iteration: 9250 Train loss: 0.475606 Train acc: 0.805176\n",
      "Epoch: 108/140 Iteration: 9255 Train loss: 0.600829 Train acc: 0.748047\n",
      "Epoch: 108/140 Iteration: 9260 Train loss: 0.496841 Train acc: 0.809082\n",
      "Epoch: 108/140 Iteration: 9265 Train loss: 0.553277 Train acc: 0.777344\n",
      "Epoch: 109/140 Iteration: 9270 Train loss: 0.498007 Train acc: 0.813965\n",
      "Epoch: 109/140 Iteration: 9275 Train loss: 0.393209 Train acc: 0.859863\n",
      "Epoch: 109/140 Iteration: 9280 Train loss: 0.385657 Train acc: 0.853027\n",
      "Epoch: 109/140 Iteration: 9280 Validation loss: 2.177994 Validation acc: 0.368810\n",
      "Epoch: 109/140 Iteration: 9285 Train loss: 0.311735 Train acc: 0.885254\n",
      "Epoch: 109/140 Iteration: 9290 Train loss: 0.414153 Train acc: 0.852539\n",
      "Epoch: 109/140 Iteration: 9295 Train loss: 0.360683 Train acc: 0.873047\n",
      "Epoch: 109/140 Iteration: 9300 Train loss: 0.307556 Train acc: 0.888184\n",
      "Epoch: 109/140 Iteration: 9305 Train loss: 0.309826 Train acc: 0.888672\n",
      "Epoch: 109/140 Iteration: 9310 Train loss: 0.286461 Train acc: 0.898926\n",
      "Epoch: 109/140 Iteration: 9315 Train loss: 0.327344 Train acc: 0.888184\n",
      "Epoch: 109/140 Iteration: 9320 Train loss: 0.394593 Train acc: 0.836914\n",
      "Epoch: 109/140 Iteration: 9320 Validation loss: 2.190493 Validation acc: 0.385699\n",
      "Epoch: 109/140 Iteration: 9325 Train loss: 0.372160 Train acc: 0.879395\n",
      "Epoch: 109/140 Iteration: 9330 Train loss: 0.498932 Train acc: 0.803711\n",
      "Epoch: 109/140 Iteration: 9335 Train loss: 0.521083 Train acc: 0.791992\n",
      "Epoch: 109/140 Iteration: 9340 Train loss: 0.691877 Train acc: 0.713379\n",
      "Epoch: 109/140 Iteration: 9345 Train loss: 0.488978 Train acc: 0.797363\n",
      "Epoch: 109/140 Iteration: 9350 Train loss: 0.513131 Train acc: 0.804688\n",
      "Epoch: 110/140 Iteration: 9355 Train loss: 0.479798 Train acc: 0.824707\n",
      "Epoch: 110/140 Iteration: 9360 Train loss: 0.354445 Train acc: 0.878906\n",
      "Epoch: 110/140 Iteration: 9360 Validation loss: 2.158413 Validation acc: 0.365364\n",
      "Epoch: 110/140 Iteration: 9365 Train loss: 0.384540 Train acc: 0.849121\n",
      "Epoch: 110/140 Iteration: 9370 Train loss: 0.318083 Train acc: 0.884277\n",
      "Epoch: 110/140 Iteration: 9375 Train loss: 0.404006 Train acc: 0.849609\n",
      "Epoch: 110/140 Iteration: 9380 Train loss: 0.315133 Train acc: 0.885254\n",
      "Epoch: 110/140 Iteration: 9385 Train loss: 0.254390 Train acc: 0.906738\n",
      "Epoch: 110/140 Iteration: 9390 Train loss: 0.341779 Train acc: 0.881836\n",
      "Epoch: 110/140 Iteration: 9395 Train loss: 0.256311 Train acc: 0.912598\n",
      "Epoch: 110/140 Iteration: 9400 Train loss: 0.310484 Train acc: 0.892090\n",
      "Epoch: 110/140 Iteration: 9400 Validation loss: 2.156004 Validation acc: 0.365881\n",
      "Epoch: 110/140 Iteration: 9405 Train loss: 0.395842 Train acc: 0.838867\n",
      "Epoch: 110/140 Iteration: 9410 Train loss: 0.377614 Train acc: 0.866211\n",
      "Epoch: 110/140 Iteration: 9415 Train loss: 0.446594 Train acc: 0.834961\n",
      "Epoch: 110/140 Iteration: 9420 Train loss: 0.521279 Train acc: 0.792969\n",
      "Epoch: 110/140 Iteration: 9425 Train loss: 0.608568 Train acc: 0.763672\n",
      "Epoch: 110/140 Iteration: 9430 Train loss: 0.472981 Train acc: 0.808594\n",
      "Epoch: 110/140 Iteration: 9435 Train loss: 0.498966 Train acc: 0.799805\n",
      "Epoch: 111/140 Iteration: 9440 Train loss: 0.480901 Train acc: 0.823730\n",
      "Epoch: 111/140 Iteration: 9440 Validation loss: 2.033669 Validation acc: 0.386072\n",
      "Epoch: 111/140 Iteration: 9445 Train loss: 0.393316 Train acc: 0.853516\n",
      "Epoch: 111/140 Iteration: 9450 Train loss: 0.389836 Train acc: 0.844727\n",
      "Epoch: 111/140 Iteration: 9455 Train loss: 0.294499 Train acc: 0.898926\n",
      "Epoch: 111/140 Iteration: 9460 Train loss: 0.420241 Train acc: 0.845215\n",
      "Epoch: 111/140 Iteration: 9465 Train loss: 0.289816 Train acc: 0.896484\n",
      "Epoch: 111/140 Iteration: 9470 Train loss: 0.251362 Train acc: 0.904297\n",
      "Epoch: 111/140 Iteration: 9475 Train loss: 0.311948 Train acc: 0.895996\n",
      "Epoch: 111/140 Iteration: 9480 Train loss: 0.299340 Train acc: 0.899414\n",
      "Epoch: 111/140 Iteration: 9480 Validation loss: 2.108584 Validation acc: 0.362951\n",
      "Epoch: 111/140 Iteration: 9485 Train loss: 0.319924 Train acc: 0.892578\n",
      "Epoch: 111/140 Iteration: 9490 Train loss: 0.399172 Train acc: 0.832520\n",
      "Epoch: 111/140 Iteration: 9495 Train loss: 0.364329 Train acc: 0.881348\n",
      "Epoch: 111/140 Iteration: 9500 Train loss: 0.445851 Train acc: 0.824707\n",
      "Epoch: 111/140 Iteration: 9505 Train loss: 0.456042 Train acc: 0.819336\n",
      "Epoch: 111/140 Iteration: 9510 Train loss: 0.649090 Train acc: 0.747070\n",
      "Epoch: 111/140 Iteration: 9515 Train loss: 0.482232 Train acc: 0.800293\n",
      "Epoch: 111/140 Iteration: 9520 Train loss: 0.507947 Train acc: 0.805664\n",
      "Epoch: 111/140 Iteration: 9520 Validation loss: 1.977168 Validation acc: 0.412095\n",
      "Epoch: 112/140 Iteration: 9525 Train loss: 0.457499 Train acc: 0.837402\n",
      "Epoch: 112/140 Iteration: 9530 Train loss: 0.358640 Train acc: 0.874023\n",
      "Epoch: 112/140 Iteration: 9535 Train loss: 0.398003 Train acc: 0.845215\n",
      "Epoch: 112/140 Iteration: 9540 Train loss: 0.298169 Train acc: 0.890625\n",
      "Epoch: 112/140 Iteration: 9545 Train loss: 0.413768 Train acc: 0.845703\n",
      "Epoch: 112/140 Iteration: 9550 Train loss: 0.282418 Train acc: 0.899902\n",
      "Epoch: 112/140 Iteration: 9555 Train loss: 0.237559 Train acc: 0.915039\n",
      "Epoch: 112/140 Iteration: 9560 Train loss: 0.296198 Train acc: 0.892090\n",
      "Epoch: 112/140 Iteration: 9560 Validation loss: 2.123041 Validation acc: 0.378131\n",
      "Epoch: 112/140 Iteration: 9565 Train loss: 0.284154 Train acc: 0.903809\n",
      "Epoch: 112/140 Iteration: 9570 Train loss: 0.311632 Train acc: 0.900391\n",
      "Epoch: 112/140 Iteration: 9575 Train loss: 0.413996 Train acc: 0.828125\n",
      "Epoch: 112/140 Iteration: 9580 Train loss: 0.348404 Train acc: 0.880371\n",
      "Epoch: 112/140 Iteration: 9585 Train loss: 0.446485 Train acc: 0.831055\n",
      "Epoch: 112/140 Iteration: 9590 Train loss: 0.464991 Train acc: 0.832031\n",
      "Epoch: 112/140 Iteration: 9595 Train loss: 0.684357 Train acc: 0.734375\n",
      "Epoch: 112/140 Iteration: 9600 Train loss: 0.464149 Train acc: 0.818359\n",
      "Epoch: 112/140 Iteration: 9600 Validation loss: 2.007063 Validation acc: 0.402688\n",
      "Epoch: 112/140 Iteration: 9605 Train loss: 0.506134 Train acc: 0.801270\n",
      "Epoch: 113/140 Iteration: 9610 Train loss: 0.491000 Train acc: 0.820801\n",
      "Epoch: 113/140 Iteration: 9615 Train loss: 0.360862 Train acc: 0.873535\n",
      "Epoch: 113/140 Iteration: 9620 Train loss: 0.355882 Train acc: 0.861328\n",
      "Epoch: 113/140 Iteration: 9625 Train loss: 0.305542 Train acc: 0.888184\n",
      "Epoch: 113/140 Iteration: 9630 Train loss: 0.410030 Train acc: 0.852539\n",
      "Epoch: 113/140 Iteration: 9635 Train loss: 0.330599 Train acc: 0.886230\n",
      "Epoch: 113/140 Iteration: 9640 Train loss: 0.246673 Train acc: 0.911133\n",
      "Epoch: 113/140 Iteration: 9640 Validation loss: 2.006503 Validation acc: 0.390654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 113/140 Iteration: 9645 Train loss: 0.332150 Train acc: 0.879883\n",
      "Epoch: 113/140 Iteration: 9650 Train loss: 0.256971 Train acc: 0.915039\n",
      "Epoch: 113/140 Iteration: 9655 Train loss: 0.285950 Train acc: 0.915527\n",
      "Epoch: 113/140 Iteration: 9660 Train loss: 0.379902 Train acc: 0.857422\n",
      "Epoch: 113/140 Iteration: 9665 Train loss: 0.357272 Train acc: 0.875000\n",
      "Epoch: 113/140 Iteration: 9670 Train loss: 0.443223 Train acc: 0.824219\n",
      "Epoch: 113/140 Iteration: 9675 Train loss: 0.445678 Train acc: 0.838867\n",
      "Epoch: 113/140 Iteration: 9680 Train loss: 0.647880 Train acc: 0.747070\n",
      "Epoch: 113/140 Iteration: 9680 Validation loss: 2.135297 Validation acc: 0.394876\n",
      "Epoch: 113/140 Iteration: 9685 Train loss: 0.463377 Train acc: 0.816406\n",
      "Epoch: 113/140 Iteration: 9690 Train loss: 0.482224 Train acc: 0.814453\n",
      "Epoch: 114/140 Iteration: 9695 Train loss: 0.437478 Train acc: 0.849609\n",
      "Epoch: 114/140 Iteration: 9700 Train loss: 0.375708 Train acc: 0.859375\n",
      "Epoch: 114/140 Iteration: 9705 Train loss: 0.405292 Train acc: 0.847656\n",
      "Epoch: 114/140 Iteration: 9710 Train loss: 0.329603 Train acc: 0.895020\n",
      "Epoch: 114/140 Iteration: 9715 Train loss: 0.398176 Train acc: 0.857910\n",
      "Epoch: 114/140 Iteration: 9720 Train loss: 0.287675 Train acc: 0.893555\n",
      "Epoch: 114/140 Iteration: 9720 Validation loss: 2.078780 Validation acc: 0.365852\n",
      "Epoch: 114/140 Iteration: 9725 Train loss: 0.251397 Train acc: 0.912109\n",
      "Epoch: 114/140 Iteration: 9730 Train loss: 0.295435 Train acc: 0.895508\n",
      "Epoch: 114/140 Iteration: 9735 Train loss: 0.284429 Train acc: 0.910156\n",
      "Epoch: 114/140 Iteration: 9740 Train loss: 0.327479 Train acc: 0.882812\n",
      "Epoch: 114/140 Iteration: 9745 Train loss: 0.420251 Train acc: 0.840332\n",
      "Epoch: 114/140 Iteration: 9750 Train loss: 0.413321 Train acc: 0.858887\n",
      "Epoch: 114/140 Iteration: 9755 Train loss: 0.478941 Train acc: 0.813477\n",
      "Epoch: 114/140 Iteration: 9760 Train loss: 0.504901 Train acc: 0.805664\n",
      "Epoch: 114/140 Iteration: 9760 Validation loss: 2.194334 Validation acc: 0.384521\n",
      "Epoch: 114/140 Iteration: 9765 Train loss: 0.603752 Train acc: 0.761719\n",
      "Epoch: 114/140 Iteration: 9770 Train loss: 0.473681 Train acc: 0.808594\n",
      "Epoch: 114/140 Iteration: 9775 Train loss: 0.593411 Train acc: 0.766113\n",
      "Epoch: 115/140 Iteration: 9780 Train loss: 0.596515 Train acc: 0.777832\n",
      "Epoch: 115/140 Iteration: 9785 Train loss: 0.396154 Train acc: 0.849609\n",
      "Epoch: 115/140 Iteration: 9790 Train loss: 0.414283 Train acc: 0.836914\n",
      "Epoch: 115/140 Iteration: 9795 Train loss: 0.342344 Train acc: 0.874512\n",
      "Epoch: 115/140 Iteration: 9800 Train loss: 0.508618 Train acc: 0.808105\n",
      "Epoch: 115/140 Iteration: 9800 Validation loss: 1.896716 Validation acc: 0.354047\n",
      "Epoch: 115/140 Iteration: 9805 Train loss: 0.310615 Train acc: 0.882324\n",
      "Epoch: 115/140 Iteration: 9810 Train loss: 0.285913 Train acc: 0.900391\n",
      "Epoch: 115/140 Iteration: 9815 Train loss: 0.307401 Train acc: 0.887695\n",
      "Epoch: 115/140 Iteration: 9820 Train loss: 0.328816 Train acc: 0.877930\n",
      "Epoch: 115/140 Iteration: 9825 Train loss: 0.355388 Train acc: 0.887207\n",
      "Epoch: 115/140 Iteration: 9830 Train loss: 0.408291 Train acc: 0.834473\n",
      "Epoch: 115/140 Iteration: 9835 Train loss: 0.379833 Train acc: 0.868164\n",
      "Epoch: 115/140 Iteration: 9840 Train loss: 0.457327 Train acc: 0.827637\n",
      "Epoch: 115/140 Iteration: 9840 Validation loss: 2.094409 Validation acc: 0.364918\n",
      "Epoch: 115/140 Iteration: 9845 Train loss: 0.504705 Train acc: 0.810059\n",
      "Epoch: 115/140 Iteration: 9850 Train loss: 0.602925 Train acc: 0.772949\n",
      "Epoch: 115/140 Iteration: 9855 Train loss: 0.480198 Train acc: 0.812012\n",
      "Epoch: 115/140 Iteration: 9860 Train loss: 0.424862 Train acc: 0.840332\n",
      "Epoch: 116/140 Iteration: 9865 Train loss: 0.455800 Train acc: 0.831543\n",
      "Epoch: 116/140 Iteration: 9870 Train loss: 0.365765 Train acc: 0.870117\n",
      "Epoch: 116/140 Iteration: 9875 Train loss: 0.383518 Train acc: 0.850098\n",
      "Epoch: 116/140 Iteration: 9880 Train loss: 0.300753 Train acc: 0.895508\n",
      "Epoch: 116/140 Iteration: 9880 Validation loss: 1.919080 Validation acc: 0.388686\n",
      "Epoch: 116/140 Iteration: 9885 Train loss: 0.411426 Train acc: 0.855469\n",
      "Epoch: 116/140 Iteration: 9890 Train loss: 0.279118 Train acc: 0.897461\n",
      "Epoch: 116/140 Iteration: 9895 Train loss: 0.259032 Train acc: 0.909668\n",
      "Epoch: 116/140 Iteration: 9900 Train loss: 0.336808 Train acc: 0.872559\n",
      "Epoch: 116/140 Iteration: 9905 Train loss: 0.275977 Train acc: 0.908691\n",
      "Epoch: 116/140 Iteration: 9910 Train loss: 0.302569 Train acc: 0.895020\n",
      "Epoch: 116/140 Iteration: 9915 Train loss: 0.402552 Train acc: 0.845703\n",
      "Epoch: 116/140 Iteration: 9920 Train loss: 0.376246 Train acc: 0.865234\n",
      "Epoch: 116/140 Iteration: 9920 Validation loss: 2.061223 Validation acc: 0.390682\n",
      "Epoch: 116/140 Iteration: 9925 Train loss: 0.443077 Train acc: 0.829590\n",
      "Epoch: 116/140 Iteration: 9930 Train loss: 0.474634 Train acc: 0.814941\n",
      "Epoch: 116/140 Iteration: 9935 Train loss: 0.558596 Train acc: 0.784668\n",
      "Epoch: 116/140 Iteration: 9940 Train loss: 0.426837 Train acc: 0.829590\n",
      "Epoch: 116/140 Iteration: 9945 Train loss: 0.381155 Train acc: 0.858887\n",
      "Epoch: 117/140 Iteration: 9950 Train loss: 0.427991 Train acc: 0.848145\n",
      "Epoch: 117/140 Iteration: 9955 Train loss: 0.348601 Train acc: 0.874512\n",
      "Epoch: 117/140 Iteration: 9960 Train loss: 0.374429 Train acc: 0.858398\n",
      "Epoch: 117/140 Iteration: 9960 Validation loss: 2.047153 Validation acc: 0.392894\n",
      "Epoch: 117/140 Iteration: 9965 Train loss: 0.296534 Train acc: 0.897461\n",
      "Epoch: 117/140 Iteration: 9970 Train loss: 0.398581 Train acc: 0.855469\n",
      "Epoch: 117/140 Iteration: 9975 Train loss: 0.289683 Train acc: 0.892578\n",
      "Epoch: 117/140 Iteration: 9980 Train loss: 0.261989 Train acc: 0.908203\n",
      "Epoch: 117/140 Iteration: 9985 Train loss: 0.326555 Train acc: 0.884766\n",
      "Epoch: 117/140 Iteration: 9990 Train loss: 0.289080 Train acc: 0.900879\n",
      "Epoch: 117/140 Iteration: 9995 Train loss: 0.299977 Train acc: 0.900391\n",
      "Epoch: 117/140 Iteration: 10000 Train loss: 0.393060 Train acc: 0.845703\n",
      "Epoch: 117/140 Iteration: 10000 Validation loss: 2.124213 Validation acc: 0.392664\n",
      "Epoch: 117/140 Iteration: 10005 Train loss: 0.363564 Train acc: 0.878418\n",
      "Epoch: 117/140 Iteration: 10010 Train loss: 0.440871 Train acc: 0.839844\n",
      "Epoch: 117/140 Iteration: 10015 Train loss: 0.424793 Train acc: 0.846191\n",
      "Epoch: 117/140 Iteration: 10020 Train loss: 0.571904 Train acc: 0.775879\n",
      "Epoch: 117/140 Iteration: 10025 Train loss: 0.428760 Train acc: 0.841797\n",
      "Epoch: 117/140 Iteration: 10030 Train loss: 0.386066 Train acc: 0.864258\n",
      "Epoch: 118/140 Iteration: 10035 Train loss: 0.429513 Train acc: 0.836914\n",
      "Epoch: 118/140 Iteration: 10040 Train loss: 0.355692 Train acc: 0.882812\n",
      "Epoch: 118/140 Iteration: 10040 Validation loss: 2.052842 Validation acc: 0.405159\n",
      "Epoch: 118/140 Iteration: 10045 Train loss: 0.352930 Train acc: 0.868164\n",
      "Epoch: 118/140 Iteration: 10050 Train loss: 0.294023 Train acc: 0.910645\n",
      "Epoch: 118/140 Iteration: 10055 Train loss: 0.393017 Train acc: 0.860840\n",
      "Epoch: 118/140 Iteration: 10060 Train loss: 0.290173 Train acc: 0.890625\n",
      "Epoch: 118/140 Iteration: 10065 Train loss: 0.245872 Train acc: 0.906738\n",
      "Epoch: 118/140 Iteration: 10070 Train loss: 0.289028 Train acc: 0.906250\n",
      "Epoch: 118/140 Iteration: 10075 Train loss: 0.276781 Train acc: 0.908691\n",
      "Epoch: 118/140 Iteration: 10080 Train loss: 0.293108 Train acc: 0.902344\n",
      "Epoch: 118/140 Iteration: 10080 Validation loss: 2.072650 Validation acc: 0.390051\n",
      "Epoch: 118/140 Iteration: 10085 Train loss: 0.379084 Train acc: 0.847656\n",
      "Epoch: 118/140 Iteration: 10090 Train loss: 0.346667 Train acc: 0.876465\n",
      "Epoch: 118/140 Iteration: 10095 Train loss: 0.413425 Train acc: 0.844238\n",
      "Epoch: 118/140 Iteration: 10100 Train loss: 0.421568 Train acc: 0.839355\n",
      "Epoch: 118/140 Iteration: 10105 Train loss: 0.515443 Train acc: 0.800781\n",
      "Epoch: 118/140 Iteration: 10110 Train loss: 0.446362 Train acc: 0.829102\n",
      "Epoch: 118/140 Iteration: 10115 Train loss: 0.384096 Train acc: 0.861328\n",
      "Epoch: 119/140 Iteration: 10120 Train loss: 0.412076 Train acc: 0.848145\n",
      "Epoch: 119/140 Iteration: 10120 Validation loss: 2.161483 Validation acc: 0.398007\n",
      "Epoch: 119/140 Iteration: 10125 Train loss: 0.335831 Train acc: 0.893555\n",
      "Epoch: 119/140 Iteration: 10130 Train loss: 0.335261 Train acc: 0.873535\n",
      "Epoch: 119/140 Iteration: 10135 Train loss: 0.277065 Train acc: 0.899414\n",
      "Epoch: 119/140 Iteration: 10140 Train loss: 0.373732 Train acc: 0.866211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 119/140 Iteration: 10145 Train loss: 0.280182 Train acc: 0.900879\n",
      "Epoch: 119/140 Iteration: 10150 Train loss: 0.242775 Train acc: 0.905762\n",
      "Epoch: 119/140 Iteration: 10155 Train loss: 0.309163 Train acc: 0.886719\n",
      "Epoch: 119/140 Iteration: 10160 Train loss: 0.267296 Train acc: 0.912109\n",
      "Epoch: 119/140 Iteration: 10160 Validation loss: 1.951177 Validation acc: 0.397116\n",
      "Epoch: 119/140 Iteration: 10165 Train loss: 0.289060 Train acc: 0.911621\n",
      "Epoch: 119/140 Iteration: 10170 Train loss: 0.363030 Train acc: 0.852539\n",
      "Epoch: 119/140 Iteration: 10175 Train loss: 0.353819 Train acc: 0.885742\n",
      "Epoch: 119/140 Iteration: 10180 Train loss: 0.434544 Train acc: 0.831543\n",
      "Epoch: 119/140 Iteration: 10185 Train loss: 0.422318 Train acc: 0.841309\n",
      "Epoch: 119/140 Iteration: 10190 Train loss: 0.504494 Train acc: 0.797852\n",
      "Epoch: 119/140 Iteration: 10195 Train loss: 0.431875 Train acc: 0.830566\n",
      "Epoch: 119/140 Iteration: 10200 Train loss: 0.365319 Train acc: 0.867676\n",
      "Epoch: 119/140 Iteration: 10200 Validation loss: 2.216202 Validation acc: 0.384866\n",
      "Epoch: 120/140 Iteration: 10205 Train loss: 0.417720 Train acc: 0.853516\n",
      "Epoch: 120/140 Iteration: 10210 Train loss: 0.350268 Train acc: 0.878906\n",
      "Epoch: 120/140 Iteration: 10215 Train loss: 0.345436 Train acc: 0.871582\n",
      "Epoch: 120/140 Iteration: 10220 Train loss: 0.269990 Train acc: 0.904785\n",
      "Epoch: 120/140 Iteration: 10225 Train loss: 0.381443 Train acc: 0.868652\n",
      "Epoch: 120/140 Iteration: 10230 Train loss: 0.280490 Train acc: 0.895020\n",
      "Epoch: 120/140 Iteration: 10235 Train loss: 0.236837 Train acc: 0.916992\n",
      "Epoch: 120/140 Iteration: 10240 Train loss: 0.282781 Train acc: 0.894043\n",
      "Epoch: 120/140 Iteration: 10240 Validation loss: 1.968446 Validation acc: 0.403134\n",
      "Epoch: 120/140 Iteration: 10245 Train loss: 0.249805 Train acc: 0.913086\n",
      "Epoch: 120/140 Iteration: 10250 Train loss: 0.279188 Train acc: 0.911133\n",
      "Epoch: 120/140 Iteration: 10255 Train loss: 0.351715 Train acc: 0.857422\n",
      "Epoch: 120/140 Iteration: 10260 Train loss: 0.322426 Train acc: 0.895996\n",
      "Epoch: 120/140 Iteration: 10265 Train loss: 0.416589 Train acc: 0.845703\n",
      "Epoch: 120/140 Iteration: 10270 Train loss: 0.408643 Train acc: 0.846191\n",
      "Epoch: 120/140 Iteration: 10275 Train loss: 0.514750 Train acc: 0.801270\n",
      "Epoch: 120/140 Iteration: 10280 Train loss: 0.439751 Train acc: 0.825684\n",
      "Epoch: 120/140 Iteration: 10280 Validation loss: 2.212534 Validation acc: 0.380429\n",
      "Epoch: 120/140 Iteration: 10285 Train loss: 0.369074 Train acc: 0.864258\n",
      "Epoch: 121/140 Iteration: 10290 Train loss: 0.400695 Train acc: 0.850586\n",
      "Epoch: 121/140 Iteration: 10295 Train loss: 0.330661 Train acc: 0.894531\n",
      "Epoch: 121/140 Iteration: 10300 Train loss: 0.324176 Train acc: 0.879395\n",
      "Epoch: 121/140 Iteration: 10305 Train loss: 0.279405 Train acc: 0.903809\n",
      "Epoch: 121/140 Iteration: 10310 Train loss: 0.365032 Train acc: 0.863770\n",
      "Epoch: 121/140 Iteration: 10315 Train loss: 0.297296 Train acc: 0.893555\n",
      "Epoch: 121/140 Iteration: 10320 Train loss: 0.232355 Train acc: 0.916992\n",
      "Epoch: 121/140 Iteration: 10320 Validation loss: 1.971131 Validation acc: 0.405446\n",
      "Epoch: 121/140 Iteration: 10325 Train loss: 0.275995 Train acc: 0.901367\n",
      "Epoch: 121/140 Iteration: 10330 Train loss: 0.269066 Train acc: 0.911133\n",
      "Epoch: 121/140 Iteration: 10335 Train loss: 0.293687 Train acc: 0.899902\n",
      "Epoch: 121/140 Iteration: 10340 Train loss: 0.375298 Train acc: 0.857910\n",
      "Epoch: 121/140 Iteration: 10345 Train loss: 0.333499 Train acc: 0.888184\n",
      "Epoch: 121/140 Iteration: 10350 Train loss: 0.412941 Train acc: 0.849609\n",
      "Epoch: 121/140 Iteration: 10355 Train loss: 0.409455 Train acc: 0.848145\n",
      "Epoch: 121/140 Iteration: 10360 Train loss: 0.546375 Train acc: 0.788086\n",
      "Epoch: 121/140 Iteration: 10360 Validation loss: 2.184262 Validation acc: 0.375115\n",
      "Epoch: 121/140 Iteration: 10365 Train loss: 0.410461 Train acc: 0.840820\n",
      "Epoch: 121/140 Iteration: 10370 Train loss: 0.363653 Train acc: 0.865723\n",
      "Epoch: 122/140 Iteration: 10375 Train loss: 0.425439 Train acc: 0.841309\n",
      "Epoch: 122/140 Iteration: 10380 Train loss: 0.343281 Train acc: 0.880371\n",
      "Epoch: 122/140 Iteration: 10385 Train loss: 0.336141 Train acc: 0.868652\n",
      "Epoch: 122/140 Iteration: 10390 Train loss: 0.269317 Train acc: 0.898438\n",
      "Epoch: 122/140 Iteration: 10395 Train loss: 0.393114 Train acc: 0.859375\n",
      "Epoch: 122/140 Iteration: 10400 Train loss: 0.263701 Train acc: 0.903809\n",
      "Epoch: 122/140 Iteration: 10400 Validation loss: 2.096414 Validation acc: 0.387236\n",
      "Epoch: 122/140 Iteration: 10405 Train loss: 0.235110 Train acc: 0.912109\n",
      "Epoch: 122/140 Iteration: 10410 Train loss: 0.276938 Train acc: 0.897949\n",
      "Epoch: 122/140 Iteration: 10415 Train loss: 0.255869 Train acc: 0.911133\n",
      "Epoch: 122/140 Iteration: 10420 Train loss: 0.279381 Train acc: 0.903809\n",
      "Epoch: 122/140 Iteration: 10425 Train loss: 0.375704 Train acc: 0.850586\n",
      "Epoch: 122/140 Iteration: 10430 Train loss: 0.329329 Train acc: 0.888184\n",
      "Epoch: 122/140 Iteration: 10435 Train loss: 0.417900 Train acc: 0.844238\n",
      "Epoch: 122/140 Iteration: 10440 Train loss: 0.426713 Train acc: 0.833496\n",
      "Epoch: 122/140 Iteration: 10440 Validation loss: 2.193850 Validation acc: 0.382138\n",
      "Epoch: 122/140 Iteration: 10445 Train loss: 0.572756 Train acc: 0.777832\n",
      "Epoch: 122/140 Iteration: 10450 Train loss: 0.414566 Train acc: 0.839355\n",
      "Epoch: 122/140 Iteration: 10455 Train loss: 0.377024 Train acc: 0.857422\n",
      "Epoch: 123/140 Iteration: 10460 Train loss: 0.393525 Train acc: 0.867188\n",
      "Epoch: 123/140 Iteration: 10465 Train loss: 0.375412 Train acc: 0.861816\n",
      "Epoch: 123/140 Iteration: 10470 Train loss: 0.312623 Train acc: 0.884766\n",
      "Epoch: 123/140 Iteration: 10475 Train loss: 0.284245 Train acc: 0.888184\n",
      "Epoch: 123/140 Iteration: 10480 Train loss: 0.364145 Train acc: 0.869141\n",
      "Epoch: 123/140 Iteration: 10480 Validation loss: 2.109904 Validation acc: 0.390395\n",
      "Epoch: 123/140 Iteration: 10485 Train loss: 0.273519 Train acc: 0.899414\n",
      "Epoch: 123/140 Iteration: 10490 Train loss: 0.249780 Train acc: 0.909668\n",
      "Epoch: 123/140 Iteration: 10495 Train loss: 0.286330 Train acc: 0.897461\n",
      "Epoch: 123/140 Iteration: 10500 Train loss: 0.245199 Train acc: 0.919434\n",
      "Epoch: 123/140 Iteration: 10505 Train loss: 0.293497 Train acc: 0.898926\n",
      "Epoch: 123/140 Iteration: 10510 Train loss: 0.367148 Train acc: 0.858398\n",
      "Epoch: 123/140 Iteration: 10515 Train loss: 0.346268 Train acc: 0.875488\n",
      "Epoch: 123/140 Iteration: 10520 Train loss: 0.410728 Train acc: 0.842773\n",
      "Epoch: 123/140 Iteration: 10520 Validation loss: 2.204344 Validation acc: 0.395982\n",
      "Epoch: 123/140 Iteration: 10525 Train loss: 0.465409 Train acc: 0.824707\n",
      "Epoch: 123/140 Iteration: 10530 Train loss: 0.564646 Train acc: 0.778809\n",
      "Epoch: 123/140 Iteration: 10535 Train loss: 0.449343 Train acc: 0.814941\n",
      "Epoch: 123/140 Iteration: 10540 Train loss: 0.394306 Train acc: 0.859863\n",
      "Epoch: 124/140 Iteration: 10545 Train loss: 0.427751 Train acc: 0.848145\n",
      "Epoch: 124/140 Iteration: 10550 Train loss: 0.325574 Train acc: 0.883789\n",
      "Epoch: 124/140 Iteration: 10555 Train loss: 0.326128 Train acc: 0.879395\n",
      "Epoch: 124/140 Iteration: 10560 Train loss: 0.302967 Train acc: 0.895020\n",
      "Epoch: 124/140 Iteration: 10560 Validation loss: 2.027339 Validation acc: 0.396886\n",
      "Epoch: 124/140 Iteration: 10565 Train loss: 0.360393 Train acc: 0.861816\n",
      "Epoch: 124/140 Iteration: 10570 Train loss: 0.286540 Train acc: 0.899414\n",
      "Epoch: 124/140 Iteration: 10575 Train loss: 0.239927 Train acc: 0.910156\n",
      "Epoch: 124/140 Iteration: 10580 Train loss: 0.265151 Train acc: 0.905762\n",
      "Epoch: 124/140 Iteration: 10585 Train loss: 0.260578 Train acc: 0.914551\n",
      "Epoch: 124/140 Iteration: 10590 Train loss: 0.276083 Train acc: 0.911621\n",
      "Epoch: 124/140 Iteration: 10595 Train loss: 0.350899 Train acc: 0.868164\n",
      "Epoch: 124/140 Iteration: 10600 Train loss: 0.356136 Train acc: 0.879395\n",
      "Epoch: 124/140 Iteration: 10600 Validation loss: 2.166152 Validation acc: 0.397246\n",
      "Epoch: 124/140 Iteration: 10605 Train loss: 0.437907 Train acc: 0.842285\n",
      "Epoch: 124/140 Iteration: 10610 Train loss: 0.486065 Train acc: 0.816895\n",
      "Epoch: 124/140 Iteration: 10615 Train loss: 0.551232 Train acc: 0.783691\n",
      "Epoch: 124/140 Iteration: 10620 Train loss: 0.518792 Train acc: 0.786621\n",
      "Epoch: 124/140 Iteration: 10625 Train loss: 0.460027 Train acc: 0.824707\n",
      "Epoch: 125/140 Iteration: 10630 Train loss: 0.429752 Train acc: 0.846191\n",
      "Epoch: 125/140 Iteration: 10635 Train loss: 0.354695 Train acc: 0.870605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 125/140 Iteration: 10640 Train loss: 0.320589 Train acc: 0.877930\n",
      "Epoch: 125/140 Iteration: 10640 Validation loss: 2.042475 Validation acc: 0.388859\n",
      "Epoch: 125/140 Iteration: 10645 Train loss: 0.321696 Train acc: 0.879395\n",
      "Epoch: 125/140 Iteration: 10650 Train loss: 0.372111 Train acc: 0.870117\n",
      "Epoch: 125/140 Iteration: 10655 Train loss: 0.296812 Train acc: 0.902832\n",
      "Epoch: 125/140 Iteration: 10660 Train loss: 0.257026 Train acc: 0.907227\n",
      "Epoch: 125/140 Iteration: 10665 Train loss: 0.273993 Train acc: 0.903809\n",
      "Epoch: 125/140 Iteration: 10670 Train loss: 0.274445 Train acc: 0.910645\n",
      "Epoch: 125/140 Iteration: 10675 Train loss: 0.271353 Train acc: 0.903809\n",
      "Epoch: 125/140 Iteration: 10680 Train loss: 0.359199 Train acc: 0.861816\n",
      "Epoch: 125/140 Iteration: 10680 Validation loss: 2.011740 Validation acc: 0.401224\n",
      "Epoch: 125/140 Iteration: 10685 Train loss: 0.358655 Train acc: 0.872070\n",
      "Epoch: 125/140 Iteration: 10690 Train loss: 0.447154 Train acc: 0.819824\n",
      "Epoch: 125/140 Iteration: 10695 Train loss: 0.441546 Train acc: 0.832031\n",
      "Epoch: 125/140 Iteration: 10700 Train loss: 0.517791 Train acc: 0.805664\n",
      "Epoch: 125/140 Iteration: 10705 Train loss: 0.538720 Train acc: 0.778320\n",
      "Epoch: 125/140 Iteration: 10710 Train loss: 0.413015 Train acc: 0.850098\n",
      "Epoch: 126/140 Iteration: 10715 Train loss: 0.479646 Train acc: 0.826660\n",
      "Epoch: 126/140 Iteration: 10720 Train loss: 0.338680 Train acc: 0.882812\n",
      "Epoch: 126/140 Iteration: 10720 Validation loss: 1.919411 Validation acc: 0.397619\n",
      "Epoch: 126/140 Iteration: 10725 Train loss: 0.327053 Train acc: 0.879883\n",
      "Epoch: 126/140 Iteration: 10730 Train loss: 0.367774 Train acc: 0.869141\n",
      "Epoch: 126/140 Iteration: 10735 Train loss: 0.391834 Train acc: 0.862305\n",
      "Epoch: 126/140 Iteration: 10740 Train loss: 0.278684 Train acc: 0.901367\n",
      "Epoch: 126/140 Iteration: 10745 Train loss: 0.250276 Train acc: 0.901855\n",
      "Epoch: 126/140 Iteration: 10750 Train loss: 0.270233 Train acc: 0.899902\n",
      "Epoch: 126/140 Iteration: 10755 Train loss: 0.249520 Train acc: 0.914062\n",
      "Epoch: 126/140 Iteration: 10760 Train loss: 0.268863 Train acc: 0.909180\n",
      "Epoch: 126/140 Iteration: 10760 Validation loss: 2.026329 Validation acc: 0.395264\n",
      "Epoch: 126/140 Iteration: 10765 Train loss: 0.369895 Train acc: 0.867188\n",
      "Epoch: 126/140 Iteration: 10770 Train loss: 0.377926 Train acc: 0.866699\n",
      "Epoch: 126/140 Iteration: 10775 Train loss: 0.450275 Train acc: 0.829102\n",
      "Epoch: 126/140 Iteration: 10780 Train loss: 0.422420 Train acc: 0.845215\n",
      "Epoch: 126/140 Iteration: 10785 Train loss: 0.537280 Train acc: 0.802246\n",
      "Epoch: 126/140 Iteration: 10790 Train loss: 0.475221 Train acc: 0.812988\n",
      "Epoch: 126/140 Iteration: 10795 Train loss: 0.446444 Train acc: 0.825684\n",
      "Epoch: 127/140 Iteration: 10800 Train loss: 0.412711 Train acc: 0.856445\n",
      "Epoch: 127/140 Iteration: 10800 Validation loss: 2.034636 Validation acc: 0.396542\n",
      "Epoch: 127/140 Iteration: 10805 Train loss: 0.368755 Train acc: 0.869629\n",
      "Epoch: 127/140 Iteration: 10810 Train loss: 0.330046 Train acc: 0.869141\n",
      "Epoch: 127/140 Iteration: 10815 Train loss: 0.309397 Train acc: 0.895020\n",
      "Epoch: 127/140 Iteration: 10820 Train loss: 0.378279 Train acc: 0.867188\n",
      "Epoch: 127/140 Iteration: 10825 Train loss: 0.308789 Train acc: 0.882324\n",
      "Epoch: 127/140 Iteration: 10830 Train loss: 0.253458 Train acc: 0.907715\n",
      "Epoch: 127/140 Iteration: 10835 Train loss: 0.295374 Train acc: 0.890625\n",
      "Epoch: 127/140 Iteration: 10840 Train loss: 0.253503 Train acc: 0.912598\n",
      "Epoch: 127/140 Iteration: 10840 Validation loss: 1.925474 Validation acc: 0.398294\n",
      "Epoch: 127/140 Iteration: 10845 Train loss: 0.288691 Train acc: 0.907715\n",
      "Epoch: 127/140 Iteration: 10850 Train loss: 0.387276 Train acc: 0.846680\n",
      "Epoch: 127/140 Iteration: 10855 Train loss: 0.373696 Train acc: 0.866211\n",
      "Epoch: 127/140 Iteration: 10860 Train loss: 0.434576 Train acc: 0.849121\n",
      "Epoch: 127/140 Iteration: 10865 Train loss: 0.418149 Train acc: 0.842285\n",
      "Epoch: 127/140 Iteration: 10870 Train loss: 0.510390 Train acc: 0.808594\n",
      "Epoch: 127/140 Iteration: 10875 Train loss: 0.505957 Train acc: 0.799316\n",
      "Epoch: 127/140 Iteration: 10880 Train loss: 0.421531 Train acc: 0.843750\n",
      "Epoch: 127/140 Iteration: 10880 Validation loss: 2.245482 Validation acc: 0.338738\n",
      "Epoch: 128/140 Iteration: 10885 Train loss: 0.444230 Train acc: 0.826660\n",
      "Epoch: 128/140 Iteration: 10890 Train loss: 0.352816 Train acc: 0.875488\n",
      "Epoch: 128/140 Iteration: 10895 Train loss: 0.324343 Train acc: 0.873535\n",
      "Epoch: 128/140 Iteration: 10900 Train loss: 0.309893 Train acc: 0.892090\n",
      "Epoch: 128/140 Iteration: 10905 Train loss: 0.368929 Train acc: 0.868164\n",
      "Epoch: 128/140 Iteration: 10910 Train loss: 0.290214 Train acc: 0.890625\n",
      "Epoch: 128/140 Iteration: 10915 Train loss: 0.251251 Train acc: 0.909668\n",
      "Epoch: 128/140 Iteration: 10920 Train loss: 0.308460 Train acc: 0.885742\n",
      "Epoch: 128/140 Iteration: 10920 Validation loss: 1.985640 Validation acc: 0.382439\n",
      "Epoch: 128/140 Iteration: 10925 Train loss: 0.240082 Train acc: 0.926270\n",
      "Epoch: 128/140 Iteration: 10930 Train loss: 0.267833 Train acc: 0.907227\n",
      "Epoch: 128/140 Iteration: 10935 Train loss: 0.371513 Train acc: 0.864258\n",
      "Epoch: 128/140 Iteration: 10940 Train loss: 0.373667 Train acc: 0.864746\n",
      "Epoch: 128/140 Iteration: 10945 Train loss: 0.430618 Train acc: 0.835938\n",
      "Epoch: 128/140 Iteration: 10950 Train loss: 0.440259 Train acc: 0.822754\n",
      "Epoch: 128/140 Iteration: 10955 Train loss: 0.498029 Train acc: 0.814941\n",
      "Epoch: 128/140 Iteration: 10960 Train loss: 0.431358 Train acc: 0.831055\n",
      "Epoch: 128/140 Iteration: 10960 Validation loss: 2.415537 Validation acc: 0.361256\n",
      "Epoch: 128/140 Iteration: 10965 Train loss: 0.396054 Train acc: 0.857910\n",
      "Epoch: 129/140 Iteration: 10970 Train loss: 0.474617 Train acc: 0.837402\n",
      "Epoch: 129/140 Iteration: 10975 Train loss: 0.370094 Train acc: 0.868164\n",
      "Epoch: 129/140 Iteration: 10980 Train loss: 0.340308 Train acc: 0.871582\n",
      "Epoch: 129/140 Iteration: 10985 Train loss: 0.292741 Train acc: 0.898438\n",
      "Epoch: 129/140 Iteration: 10990 Train loss: 0.371479 Train acc: 0.863281\n",
      "Epoch: 129/140 Iteration: 10995 Train loss: 0.277858 Train acc: 0.903320\n",
      "Epoch: 129/140 Iteration: 11000 Train loss: 0.248610 Train acc: 0.911133\n",
      "Epoch: 129/140 Iteration: 11000 Validation loss: 2.066387 Validation acc: 0.359849\n",
      "Epoch: 129/140 Iteration: 11005 Train loss: 0.290383 Train acc: 0.890137\n",
      "Epoch: 129/140 Iteration: 11010 Train loss: 0.248023 Train acc: 0.917969\n",
      "Epoch: 129/140 Iteration: 11015 Train loss: 0.257447 Train acc: 0.912109\n",
      "Epoch: 129/140 Iteration: 11020 Train loss: 0.373303 Train acc: 0.860840\n",
      "Epoch: 129/140 Iteration: 11025 Train loss: 0.395757 Train acc: 0.855469\n",
      "Epoch: 129/140 Iteration: 11030 Train loss: 0.441723 Train acc: 0.827637\n",
      "Epoch: 129/140 Iteration: 11035 Train loss: 0.537420 Train acc: 0.797852\n",
      "Epoch: 129/140 Iteration: 11040 Train loss: 0.494386 Train acc: 0.817383\n",
      "Epoch: 129/140 Iteration: 11040 Validation loss: 2.226499 Validation acc: 0.384220\n",
      "Epoch: 129/140 Iteration: 11045 Train loss: 0.452080 Train acc: 0.823730\n",
      "Epoch: 129/140 Iteration: 11050 Train loss: 0.462578 Train acc: 0.840332\n",
      "Epoch: 130/140 Iteration: 11055 Train loss: 0.462327 Train acc: 0.833496\n",
      "Epoch: 130/140 Iteration: 11060 Train loss: 0.362336 Train acc: 0.870605\n",
      "Epoch: 130/140 Iteration: 11065 Train loss: 0.328298 Train acc: 0.875488\n",
      "Epoch: 130/140 Iteration: 11070 Train loss: 0.331147 Train acc: 0.882324\n",
      "Epoch: 130/140 Iteration: 11075 Train loss: 0.388553 Train acc: 0.854492\n",
      "Epoch: 130/140 Iteration: 11080 Train loss: 0.278234 Train acc: 0.901367\n",
      "Epoch: 130/140 Iteration: 11080 Validation loss: 2.031061 Validation acc: 0.357551\n",
      "Epoch: 130/140 Iteration: 11085 Train loss: 0.240903 Train acc: 0.913086\n",
      "Epoch: 130/140 Iteration: 11090 Train loss: 0.276318 Train acc: 0.897461\n",
      "Epoch: 130/140 Iteration: 11095 Train loss: 0.249088 Train acc: 0.918945\n",
      "Epoch: 130/140 Iteration: 11100 Train loss: 0.316484 Train acc: 0.896484\n",
      "Epoch: 130/140 Iteration: 11105 Train loss: 0.369496 Train acc: 0.856934\n",
      "Epoch: 130/140 Iteration: 11110 Train loss: 0.412462 Train acc: 0.855469\n",
      "Epoch: 130/140 Iteration: 11115 Train loss: 0.437664 Train acc: 0.841797\n",
      "Epoch: 130/140 Iteration: 11120 Train loss: 0.467555 Train acc: 0.809082\n",
      "Epoch: 130/140 Iteration: 11120 Validation loss: 2.199299 Validation acc: 0.382138\n",
      "Epoch: 130/140 Iteration: 11125 Train loss: 0.515877 Train acc: 0.804199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 130/140 Iteration: 11130 Train loss: 0.456434 Train acc: 0.818848\n",
      "Epoch: 130/140 Iteration: 11135 Train loss: 0.390665 Train acc: 0.861816\n",
      "Epoch: 131/140 Iteration: 11140 Train loss: 0.475843 Train acc: 0.821777\n",
      "Epoch: 131/140 Iteration: 11145 Train loss: 0.360511 Train acc: 0.875977\n",
      "Epoch: 131/140 Iteration: 11150 Train loss: 0.345483 Train acc: 0.866211\n",
      "Epoch: 131/140 Iteration: 11155 Train loss: 0.302083 Train acc: 0.899414\n",
      "Epoch: 131/140 Iteration: 11160 Train loss: 0.368321 Train acc: 0.859863\n",
      "Epoch: 131/140 Iteration: 11160 Validation loss: 2.142168 Validation acc: 0.352467\n",
      "Epoch: 131/140 Iteration: 11165 Train loss: 0.278558 Train acc: 0.901855\n",
      "Epoch: 131/140 Iteration: 11170 Train loss: 0.255098 Train acc: 0.906738\n",
      "Epoch: 131/140 Iteration: 11175 Train loss: 0.296520 Train acc: 0.898926\n",
      "Epoch: 131/140 Iteration: 11180 Train loss: 0.259795 Train acc: 0.921875\n",
      "Epoch: 131/140 Iteration: 11185 Train loss: 0.297152 Train acc: 0.899902\n",
      "Epoch: 131/140 Iteration: 11190 Train loss: 0.371916 Train acc: 0.854980\n",
      "Epoch: 131/140 Iteration: 11195 Train loss: 0.420740 Train acc: 0.841309\n",
      "Epoch: 131/140 Iteration: 11200 Train loss: 0.493715 Train acc: 0.811523\n",
      "Epoch: 131/140 Iteration: 11200 Validation loss: 2.163717 Validation acc: 0.350557\n",
      "Epoch: 131/140 Iteration: 11205 Train loss: 0.524035 Train acc: 0.781250\n",
      "Epoch: 131/140 Iteration: 11210 Train loss: 0.523216 Train acc: 0.806641\n",
      "Epoch: 131/140 Iteration: 11215 Train loss: 0.528127 Train acc: 0.803223\n",
      "Epoch: 131/140 Iteration: 11220 Train loss: 0.439202 Train acc: 0.837402\n",
      "Epoch: 132/140 Iteration: 11225 Train loss: 0.508723 Train acc: 0.808594\n",
      "Epoch: 132/140 Iteration: 11230 Train loss: 0.357170 Train acc: 0.875000\n",
      "Epoch: 132/140 Iteration: 11235 Train loss: 0.352941 Train acc: 0.864746\n",
      "Epoch: 132/140 Iteration: 11240 Train loss: 0.306352 Train acc: 0.885742\n",
      "Epoch: 132/140 Iteration: 11240 Validation loss: 2.028025 Validation acc: 0.350299\n",
      "Epoch: 132/140 Iteration: 11245 Train loss: 0.395349 Train acc: 0.850098\n",
      "Epoch: 132/140 Iteration: 11250 Train loss: 0.289840 Train acc: 0.900879\n",
      "Epoch: 132/140 Iteration: 11255 Train loss: 0.260178 Train acc: 0.907715\n",
      "Epoch: 132/140 Iteration: 11260 Train loss: 0.301451 Train acc: 0.891113\n",
      "Epoch: 132/140 Iteration: 11265 Train loss: 0.271139 Train acc: 0.908203\n",
      "Epoch: 132/140 Iteration: 11270 Train loss: 0.274981 Train acc: 0.903809\n",
      "Epoch: 132/140 Iteration: 11275 Train loss: 0.367867 Train acc: 0.854004\n",
      "Epoch: 132/140 Iteration: 11280 Train loss: 0.385216 Train acc: 0.860352\n",
      "Epoch: 132/140 Iteration: 11280 Validation loss: 2.276380 Validation acc: 0.344999\n",
      "Epoch: 132/140 Iteration: 11285 Train loss: 0.464230 Train acc: 0.827148\n",
      "Epoch: 132/140 Iteration: 11290 Train loss: 0.478935 Train acc: 0.791016\n",
      "Epoch: 132/140 Iteration: 11295 Train loss: 0.520483 Train acc: 0.810547\n",
      "Epoch: 132/140 Iteration: 11300 Train loss: 0.469914 Train acc: 0.817871\n",
      "Epoch: 132/140 Iteration: 11305 Train loss: 0.453294 Train acc: 0.827637\n",
      "Epoch: 133/140 Iteration: 11310 Train loss: 0.496249 Train acc: 0.809082\n",
      "Epoch: 133/140 Iteration: 11315 Train loss: 0.378609 Train acc: 0.876465\n",
      "Epoch: 133/140 Iteration: 11320 Train loss: 0.344809 Train acc: 0.876953\n",
      "Epoch: 133/140 Iteration: 11320 Validation loss: 2.116137 Validation acc: 0.356747\n",
      "Epoch: 133/140 Iteration: 11325 Train loss: 0.315790 Train acc: 0.883789\n",
      "Epoch: 133/140 Iteration: 11330 Train loss: 0.416065 Train acc: 0.835449\n",
      "Epoch: 133/140 Iteration: 11335 Train loss: 0.305370 Train acc: 0.892090\n",
      "Epoch: 133/140 Iteration: 11340 Train loss: 0.307711 Train acc: 0.886230\n",
      "Epoch: 133/140 Iteration: 11345 Train loss: 0.343997 Train acc: 0.865723\n",
      "Epoch: 133/140 Iteration: 11350 Train loss: 0.261420 Train acc: 0.917480\n",
      "Epoch: 133/140 Iteration: 11355 Train loss: 0.291266 Train acc: 0.901367\n",
      "Epoch: 133/140 Iteration: 11360 Train loss: 0.373688 Train acc: 0.846191\n",
      "Epoch: 133/140 Iteration: 11360 Validation loss: 2.109898 Validation acc: 0.336340\n",
      "Epoch: 133/140 Iteration: 11365 Train loss: 0.386266 Train acc: 0.863281\n",
      "Epoch: 133/140 Iteration: 11370 Train loss: 0.470988 Train acc: 0.825195\n",
      "Epoch: 133/140 Iteration: 11375 Train loss: 0.462065 Train acc: 0.809082\n",
      "Epoch: 133/140 Iteration: 11380 Train loss: 0.481765 Train acc: 0.813965\n",
      "Epoch: 133/140 Iteration: 11385 Train loss: 0.471121 Train acc: 0.804688\n",
      "Epoch: 133/140 Iteration: 11390 Train loss: 0.424758 Train acc: 0.846680\n",
      "Epoch: 134/140 Iteration: 11395 Train loss: 0.529285 Train acc: 0.796387\n",
      "Epoch: 134/140 Iteration: 11400 Train loss: 0.352566 Train acc: 0.877441\n",
      "Epoch: 134/140 Iteration: 11400 Validation loss: 2.117163 Validation acc: 0.359849\n",
      "Epoch: 134/140 Iteration: 11405 Train loss: 0.361909 Train acc: 0.864258\n",
      "Epoch: 134/140 Iteration: 11410 Train loss: 0.334879 Train acc: 0.872559\n",
      "Epoch: 134/140 Iteration: 11415 Train loss: 0.424004 Train acc: 0.846191\n",
      "Epoch: 134/140 Iteration: 11420 Train loss: 0.486227 Train acc: 0.836426\n",
      "Epoch: 134/140 Iteration: 11425 Train loss: 0.274092 Train acc: 0.901367\n",
      "Epoch: 134/140 Iteration: 11430 Train loss: 0.362948 Train acc: 0.872559\n",
      "Epoch: 134/140 Iteration: 11435 Train loss: 0.319274 Train acc: 0.886230\n",
      "Epoch: 134/140 Iteration: 11440 Train loss: 0.278038 Train acc: 0.906250\n",
      "Epoch: 134/140 Iteration: 11440 Validation loss: 2.001969 Validation acc: 0.372616\n",
      "Epoch: 134/140 Iteration: 11445 Train loss: 0.393346 Train acc: 0.845215\n",
      "Epoch: 134/140 Iteration: 11450 Train loss: 0.395877 Train acc: 0.873047\n",
      "Epoch: 134/140 Iteration: 11455 Train loss: 0.447596 Train acc: 0.833984\n",
      "Epoch: 134/140 Iteration: 11460 Train loss: 0.460944 Train acc: 0.818848\n",
      "Epoch: 134/140 Iteration: 11465 Train loss: 0.488351 Train acc: 0.822754\n",
      "Epoch: 134/140 Iteration: 11470 Train loss: 0.421985 Train acc: 0.828613\n",
      "Epoch: 134/140 Iteration: 11475 Train loss: 0.476138 Train acc: 0.825684\n",
      "Epoch: 135/140 Iteration: 11480 Train loss: 0.514718 Train acc: 0.812012\n",
      "Epoch: 135/140 Iteration: 11480 Validation loss: 2.239782 Validation acc: 0.370749\n",
      "Epoch: 135/140 Iteration: 11485 Train loss: 0.371422 Train acc: 0.866699\n",
      "Epoch: 135/140 Iteration: 11490 Train loss: 0.349180 Train acc: 0.874512\n",
      "Epoch: 135/140 Iteration: 11495 Train loss: 0.346861 Train acc: 0.874023\n",
      "Epoch: 135/140 Iteration: 11500 Train loss: 0.415420 Train acc: 0.845215\n",
      "Epoch: 135/140 Iteration: 11505 Train loss: 0.297505 Train acc: 0.893555\n",
      "Epoch: 135/140 Iteration: 11510 Train loss: 0.235573 Train acc: 0.920898\n",
      "Epoch: 135/140 Iteration: 11515 Train loss: 0.303055 Train acc: 0.886719\n",
      "Epoch: 135/140 Iteration: 11520 Train loss: 0.292980 Train acc: 0.896973\n",
      "Epoch: 135/140 Iteration: 11520 Validation loss: 2.088355 Validation acc: 0.347010\n",
      "Epoch: 135/140 Iteration: 11525 Train loss: 0.280219 Train acc: 0.905762\n",
      "Epoch: 135/140 Iteration: 11530 Train loss: 0.391900 Train acc: 0.840332\n",
      "Epoch: 135/140 Iteration: 11535 Train loss: 0.402551 Train acc: 0.860352\n",
      "Epoch: 135/140 Iteration: 11540 Train loss: 0.420928 Train acc: 0.838379\n",
      "Epoch: 135/140 Iteration: 11545 Train loss: 0.436192 Train acc: 0.824219\n",
      "Epoch: 135/140 Iteration: 11550 Train loss: 0.529898 Train acc: 0.787109\n",
      "Epoch: 135/140 Iteration: 11555 Train loss: 0.412347 Train acc: 0.831055\n",
      "Epoch: 135/140 Iteration: 11560 Train loss: 0.413919 Train acc: 0.851074\n",
      "Epoch: 135/140 Iteration: 11560 Validation loss: 2.259904 Validation acc: 0.370419\n",
      "Epoch: 136/140 Iteration: 11565 Train loss: 0.504012 Train acc: 0.810059\n",
      "Epoch: 136/140 Iteration: 11570 Train loss: 0.352301 Train acc: 0.875488\n",
      "Epoch: 136/140 Iteration: 11575 Train loss: 0.349945 Train acc: 0.872070\n",
      "Epoch: 136/140 Iteration: 11580 Train loss: 0.308642 Train acc: 0.887695\n",
      "Epoch: 136/140 Iteration: 11585 Train loss: 0.393460 Train acc: 0.858398\n",
      "Epoch: 136/140 Iteration: 11590 Train loss: 0.299196 Train acc: 0.889160\n",
      "Epoch: 136/140 Iteration: 11595 Train loss: 0.259399 Train acc: 0.908691\n",
      "Epoch: 136/140 Iteration: 11600 Train loss: 0.291550 Train acc: 0.896973\n",
      "Epoch: 136/140 Iteration: 11600 Validation loss: 1.875584 Validation acc: 0.385972\n",
      "Epoch: 136/140 Iteration: 11605 Train loss: 0.266556 Train acc: 0.913574\n",
      "Epoch: 136/140 Iteration: 11610 Train loss: 0.334096 Train acc: 0.878906\n",
      "Epoch: 136/140 Iteration: 11615 Train loss: 0.358956 Train acc: 0.857422\n",
      "Epoch: 136/140 Iteration: 11620 Train loss: 0.383940 Train acc: 0.864746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 136/140 Iteration: 11625 Train loss: 0.430409 Train acc: 0.840332\n",
      "Epoch: 136/140 Iteration: 11630 Train loss: 0.451965 Train acc: 0.828613\n",
      "Epoch: 136/140 Iteration: 11635 Train loss: 0.456592 Train acc: 0.822754\n",
      "Epoch: 136/140 Iteration: 11640 Train loss: 0.421779 Train acc: 0.826660\n",
      "Epoch: 136/140 Iteration: 11640 Validation loss: 2.239351 Validation acc: 0.385642\n",
      "Epoch: 136/140 Iteration: 11645 Train loss: 0.392094 Train acc: 0.873047\n",
      "Epoch: 137/140 Iteration: 11650 Train loss: 0.480301 Train acc: 0.819824\n",
      "Epoch: 137/140 Iteration: 11655 Train loss: 0.367634 Train acc: 0.875488\n",
      "Epoch: 137/140 Iteration: 11660 Train loss: 0.358400 Train acc: 0.861328\n",
      "Epoch: 137/140 Iteration: 11665 Train loss: 0.306041 Train acc: 0.895508\n",
      "Epoch: 137/140 Iteration: 11670 Train loss: 0.416458 Train acc: 0.840820\n",
      "Epoch: 137/140 Iteration: 11675 Train loss: 0.302772 Train acc: 0.894531\n",
      "Epoch: 137/140 Iteration: 11680 Train loss: 0.270238 Train acc: 0.898438\n",
      "Epoch: 137/140 Iteration: 11680 Validation loss: 1.969811 Validation acc: 0.388902\n",
      "Epoch: 137/140 Iteration: 11685 Train loss: 0.303192 Train acc: 0.891113\n",
      "Epoch: 137/140 Iteration: 11690 Train loss: 0.256558 Train acc: 0.913086\n",
      "Epoch: 137/140 Iteration: 11695 Train loss: 0.309006 Train acc: 0.901855\n",
      "Epoch: 137/140 Iteration: 11700 Train loss: 0.381499 Train acc: 0.844727\n",
      "Epoch: 137/140 Iteration: 11705 Train loss: 0.350705 Train acc: 0.876953\n",
      "Epoch: 137/140 Iteration: 11710 Train loss: 0.462548 Train acc: 0.826172\n",
      "Epoch: 137/140 Iteration: 11715 Train loss: 0.406008 Train acc: 0.843262\n",
      "Epoch: 137/140 Iteration: 11720 Train loss: 0.458456 Train acc: 0.818848\n",
      "Epoch: 137/140 Iteration: 11720 Validation loss: 2.171989 Validation acc: 0.377125\n",
      "Epoch: 137/140 Iteration: 11725 Train loss: 0.406381 Train acc: 0.834473\n",
      "Epoch: 137/140 Iteration: 11730 Train loss: 0.369285 Train acc: 0.866211\n",
      "Epoch: 138/140 Iteration: 11735 Train loss: 0.466282 Train acc: 0.830078\n",
      "Epoch: 138/140 Iteration: 11740 Train loss: 0.377060 Train acc: 0.859375\n",
      "Epoch: 138/140 Iteration: 11745 Train loss: 0.341532 Train acc: 0.875488\n",
      "Epoch: 138/140 Iteration: 11750 Train loss: 0.270684 Train acc: 0.910645\n",
      "Epoch: 138/140 Iteration: 11755 Train loss: 0.409843 Train acc: 0.847168\n",
      "Epoch: 138/140 Iteration: 11760 Train loss: 0.301090 Train acc: 0.891602\n",
      "Epoch: 138/140 Iteration: 11760 Validation loss: 1.994854 Validation acc: 0.385527\n",
      "Epoch: 138/140 Iteration: 11765 Train loss: 0.236360 Train acc: 0.912109\n",
      "Epoch: 138/140 Iteration: 11770 Train loss: 0.304545 Train acc: 0.886230\n",
      "Epoch: 138/140 Iteration: 11775 Train loss: 0.243393 Train acc: 0.918945\n",
      "Epoch: 138/140 Iteration: 11780 Train loss: 0.316848 Train acc: 0.894043\n",
      "Epoch: 138/140 Iteration: 11785 Train loss: 0.403067 Train acc: 0.840332\n",
      "Epoch: 138/140 Iteration: 11790 Train loss: 0.352346 Train acc: 0.870605\n",
      "Epoch: 138/140 Iteration: 11795 Train loss: 0.439689 Train acc: 0.843262\n",
      "Epoch: 138/140 Iteration: 11800 Train loss: 0.451024 Train acc: 0.821289\n",
      "Epoch: 138/140 Iteration: 11800 Validation loss: 2.244606 Validation acc: 0.370404\n",
      "Epoch: 138/140 Iteration: 11805 Train loss: 0.462915 Train acc: 0.812500\n",
      "Epoch: 138/140 Iteration: 11810 Train loss: 0.407724 Train acc: 0.836914\n",
      "Epoch: 138/140 Iteration: 11815 Train loss: 0.384672 Train acc: 0.865234\n",
      "Epoch: 139/140 Iteration: 11820 Train loss: 0.491256 Train acc: 0.820801\n",
      "Epoch: 139/140 Iteration: 11825 Train loss: 0.370851 Train acc: 0.861816\n",
      "Epoch: 139/140 Iteration: 11830 Train loss: 0.383366 Train acc: 0.860840\n",
      "Epoch: 139/140 Iteration: 11835 Train loss: 0.310783 Train acc: 0.888184\n",
      "Epoch: 139/140 Iteration: 11840 Train loss: 0.382066 Train acc: 0.857422\n",
      "Epoch: 139/140 Iteration: 11840 Validation loss: 1.969386 Validation acc: 0.397849\n",
      "Epoch: 139/140 Iteration: 11845 Train loss: 0.270121 Train acc: 0.904785\n",
      "Epoch: 139/140 Iteration: 11850 Train loss: 0.233897 Train acc: 0.911133\n",
      "Epoch: 139/140 Iteration: 11855 Train loss: 0.305775 Train acc: 0.882324\n",
      "Epoch: 139/140 Iteration: 11860 Train loss: 0.225691 Train acc: 0.927246\n",
      "Epoch: 139/140 Iteration: 11865 Train loss: 0.313630 Train acc: 0.888672\n",
      "Epoch: 139/140 Iteration: 11870 Train loss: 0.401677 Train acc: 0.843262\n",
      "Epoch: 139/140 Iteration: 11875 Train loss: 0.379468 Train acc: 0.865234\n",
      "Epoch: 139/140 Iteration: 11880 Train loss: 0.436310 Train acc: 0.841797\n",
      "Epoch: 139/140 Iteration: 11880 Validation loss: 2.204881 Validation acc: 0.363612\n",
      "Epoch: 139/140 Iteration: 11885 Train loss: 0.433813 Train acc: 0.832520\n",
      "Epoch: 139/140 Iteration: 11890 Train loss: 0.503533 Train acc: 0.813477\n",
      "Epoch: 139/140 Iteration: 11895 Train loss: 0.451067 Train acc: 0.820312\n",
      "Epoch: 139/140 Iteration: 11900 Train loss: 0.406004 Train acc: 0.850098\n"
     ]
    }
   ],
   "source": [
    "interation_compute_val = 40\n",
    "validation_acc = []\n",
    "validation_loss = []\n",
    "\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "\n",
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "    saver.restore(sess, \"checkpoints/har-lstm.ckpt\")\n",
    "    for e in range(epochs):\n",
    "        # Initialize \n",
    "        state = sess.run(initial_state)\n",
    "        \n",
    "        # Loop over batches\n",
    "        for x,y in get_batches(X_tr, y_tr, batch_size):\n",
    "            \n",
    "            # Feed dictionary\n",
    "            feed = {inputs_ : x, labels_ : y, keep_prob_ : 0.5, \n",
    "                    initial_state : state, learning_rate_ : learning_rate}\n",
    "            \n",
    "            loss, _ , state, acc = sess.run([cost, optimizer, final_state, accuracy], \n",
    "                                             feed_dict = feed)\n",
    "            train_acc.append(acc)\n",
    "            train_loss.append(loss)\n",
    "            \n",
    "            # Print at each 5 iters\n",
    "            if (iteration % 5 == 0):\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Train loss: {:6f}\".format(loss),\n",
    "                      \"Train acc: {:.6f}\".format(acc))\n",
    "            \n",
    "            # Compute validation loss at every 25 iterations\n",
    "            if (iteration%interation_compute_val == compute_val_at):\n",
    "                \n",
    "                # Initiate for validation set\n",
    "                val_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "                \n",
    "                val_acc_ = []\n",
    "                val_loss_ = []\n",
    "                for x_v, y_v in get_batches(X_vld, y_vld, batch_size):\n",
    "                    # Feed\n",
    "                    feed = {inputs_ : x_v, labels_ : y_v, keep_prob_ : 1.0, initial_state : val_state}\n",
    "                    \n",
    "                    # Loss\n",
    "                    loss_v, state_v, acc_v = sess.run([cost, final_state, accuracy], feed_dict = feed)\n",
    "                    \n",
    "                    val_acc_.append(acc_v)\n",
    "                    val_loss_.append(loss_v)\n",
    "                \n",
    "                # Print info\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Validation loss: {:6f}\".format(np.mean(val_loss_)),\n",
    "                      \"Validation acc: {:.6f}\".format(np.mean(val_acc_)))\n",
    "                \n",
    "                # Store\n",
    "                validation_acc.append(np.mean(val_acc_))\n",
    "                validation_loss.append(np.mean(val_loss_))\n",
    "            \n",
    "            # Iterate \n",
    "            iteration += 1\n",
    "    \n",
    "    saver.save(sess,\"checkpoints/har-lstm.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7MAAAF3CAYAAAB3+BzkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and test loss\n",
    "t = np.arange(iteration-1)\n",
    "tt = t[t % interation_compute_val == compute_val_at]\n",
    "tt = tt[1:]\n",
    "plt.figure(figsize = (16,6))\n",
    "plt.plot(t, np.array(train_loss), 'r-', tt, np.array(validation_loss), 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7MAAAF3CAYAAAB3+BzkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Plot Accuracies# Plot A \n",
    "plt.figure(figsize = (16,6))\n",
    "\n",
    "plt.plot(t, np.array(train_acc), 'r-', tt, validation_acc, 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Accuray\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints\\har-lstm.ckpt\n",
      "(70626, 3)\n",
      "0.431152\n",
      "0.381836\n",
      "0.470215\n",
      "0.390137\n",
      "0.455566\n",
      "0.487305\n",
      "0.424316\n",
      "0.531738\n",
      "0.475098\n",
      "0.4375\n",
      "0.361816\n",
      "0.470215\n",
      "0.417969\n",
      "0.443848\n",
      "0.332031\n",
      "0.38916\n",
      "0.376953\n",
      "0.385254\n",
      "0.286621\n",
      "0.260254\n",
      "0.227051\n",
      "0.340332\n",
      "0.336914\n",
      "0.304199\n",
      "0.260254\n",
      "0.256348\n",
      "0.280273\n",
      "0.266113\n",
      "0.289551\n",
      "0.418457\n",
      "0.340332\n",
      "0.325195\n",
      "0.241211\n",
      "0.316406\n",
      "Test accuracy: 0.365048\n"
     ]
    }
   ],
   "source": [
    "test_acc = []\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # Restore\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    saver = tf.train.import_meta_graph('checkpoints\\har-lstm.ckpt.meta')\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "\n",
    "    test_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "    print(y_vld.shape)        \n",
    "    for x_t, y_t in get_batches(X_vld, y_vld, batch_size): \n",
    "        feed = {inputs_: x_t,\n",
    "                labels_: y_t,\n",
    "                keep_prob_: 1,\n",
    "                initial_state: test_state}\n",
    "        \n",
    "        batch_acc, test_state = sess.run([ accuracy,final_state], feed_dict=feed)\n",
    "        test_acc.append(batch_acc)\n",
    "        print(batch_acc)\n",
    "    print(\"Test accuracy: {:.6f}\".format(np.mean(test_acc)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-20-a2d1b987acee>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-20-a2d1b987acee>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    print datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "a = np.array([[ 0,  1,  2,  0,  4,  5,  6,  7,  8,  10],\n",
    "              [ 0, 11,  0, 13,  0, 15,  0, 17, 18,  0]])\n",
    "print (a[a.max(axis=1) >= 10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "a = np.array([[ 0,  1,  2,  0,  4,  5,  6,  7,  8,  9],\n",
    "              [ 0, 11,  0, 13,  0, 15,  0, 17, 18,  0]])\n",
    "print (a[a[:,2]!=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(ytest[:]!=0)\n",
    "Xtest = np.array([[ 0,  1,  2,  0,  4,  5,  6,  7,  8,  9],\n",
    "              [ 0, 11,  0, 13,  0, 15,  0, 17, 18,  0],\n",
    "             [ 0, 11,  0, 13,  0, 15,  0, 11, 1,  1]])\n",
    "ytest = np.array([ 0,  1,  1])\n",
    "Xtest = Xtest[ytest[:]!=0,:]\n",
    "ytest = ytest[ytest[:]!=0]\n",
    "print(Xtest)\n",
    "print(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(50%1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
